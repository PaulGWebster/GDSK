rypto/x509/v3_conf.c"
        ],
        "crypto/x509/libcrypto-lib-v3_cpols.o" => [
            "crypto/x509/v3_cpols.c"
        ],
        "crypto/x509/libcrypto-lib-v3_crld.o" => [
            "crypto/x509/v3_crld.c"
        ],
        "crypto/x509/libcrypto-lib-v3_enum.o" => [
            "crypto/x509/v3_enum.c"
        ],
        "crypto/x509/libcrypto-lib-v3_extku.o" => [
            "crypto/x509/v3_extku.c"
        ],
        "crypto/x509/libcrypto-lib-v3_genn.o" => [
            "crypto/x509/v3_genn.c"
        ],
        "crypto/x509/libcrypto-lib-v3_ia5.o" => [
            "crypto/x509/v3_ia5.c"
        ],
        "crypto/x509/libcrypto-lib-v3_info.o" => [
            "crypto/x509/v3_info.c"
        ],
        "crypto/x509/libcrypto-lib-v3_int.o" => [
            "crypto/x509/v3_int.c"
        ],
        "crypto/x509/libcrypto-lib-v3_ist.o" => [
            "crypto/x509/v3_ist.c"
        ],
        "crypto/x509/libcrypto-lib-v3_lib.o" => [
            "crypto/x509/v3_lib.c"
        ],
        "crypto/x509/libcrypto-lib-v3_ncons.o" => [
            "crypto/x509/v3_ncons.c"
        ],
        "crypto/x509/libcrypto-lib-v3_pci.o" => [
            "crypto/x509/v3_pci.c"
        ],
        "crypto/x509/libcrypto-lib-v3_pcia.o" => [
            "crypto/x509/v3_pcia.c"
        ],
        "crypto/x509/libcrypto-lib-v3_pcons.o" => [
            "crypto/x509/v3_pcons.c"
        ],
        "crypto/x509/libcrypto-lib-v3_pku.o" => [
            "crypto/x509/v3_pku.c"
        ],
        "crypto/x509/libcrypto-lib-v3_pmaps.o" => [
            "crypto/x509/v3_pmaps.c"
        ],
        "crypto/x509/libcrypto-lib-v3_prn.o" => [
            "crypto/x509/v3_prn.c"
        ],
        "crypto/x509/libcrypto-lib-v3_purp.o" => [
            "crypto/x509/v3_purp.c"
        ],
        "crypto/x509/libcrypto-lib-v3_san.o" => [
            "crypto/x509/v3_san.c"
        ],
        "crypto/x509/libcrypto-lib-v3_skid.o" => [
            "crypto/x509/v3_skid.c"
        ],
        "crypto/x509/libcrypto-lib-v3_sxnet.o" => [
            "crypto/x509/v3_sxnet.c"
        ],
        "crypto/x509/libcrypto-lib-v3_tlsf.o" => [
            "crypto/x509/v3_tlsf.c"
        ],
        "crypto/x509/libcrypto-lib-v3_utf8.o" => [
            "crypto/x509/v3_utf8.c"
        ],
        "crypto/x509/libcrypto-lib-v3_utl.o" => [
            "crypto/x509/v3_utl.c"
        ],
        "crypto/x509/libcrypto-lib-v3err.o" => [
            "crypto/x509/v3err.c"
        ],
        "crypto/x509/libcrypto-lib-x509_att.o" => [
            "crypto/x509/x509_att.c"
        ],
        "crypto/x509/libcrypto-lib-x509_cmp.o" => [
            "crypto/x509/x509_cmp.c"
        ],
        "crypto/x509/libcrypto-lib-x509_d2.o" => [
            "crypto/x509/x509_d2.c"
        ],
        "crypto/x509/libcrypto-lib-x509_def.o" => [
            "crypto/x509/x509_def.c"
        ],
        "crypto/x509/libcrypto-lib-x509_err.o" => [
            "crypto/x509/x509_err.c"
        ],
        "crypto/x509/libcrypto-lib-x509_ext.o" => [
            "crypto/x509/x509_ext.c"
        ],
        "crypto/x509/libcrypto-lib-x509_lu.o" => [
            "crypto/x509/x509_lu.c"
        ],
        "crypto/x509/libcrypto-lib-x509_meth.o" => [
            "crypto/x509/x509_meth.c"
        ],
        "crypto/x509/libcrypto-lib-x509_obj.o" => [
            "crypto/x509/x509_obj.c"
        ],
        "crypto/x509/libcrypto-lib-x509_r2x.o" => [
            "crypto/x509/x509_r2x.c"
        ],
        "crypto/x509/libcrypto-lib-x509_req.o" => [
            "crypto/x509/x509_req.c"
        ],
        "crypto/x509/libcrypto-lib-x509_set.o" => [
            "crypto/x509/x509_set.c"
        ],
        "crypto/x509/libcrypto-lib-x509_trust.o" => [
            "crypto/x509/x509_trust.c"
        ],
        "crypto/x509/libcrypto-lib-x509_txt.o" => [
            "crypto/x509/x509_txt.c"
        ],
        "crypto/x509/libcrypto-lib-x509_v3.o" => [
            "crypto/x509/x509_v3.c"
        ],
        "crypto/x509/libcrypto-lib-x509_vfy.o" => [
            "crypto/x509/x509_vfy.c"
        ],
        "crypto/x509/libcrypto-lib-x509_vpm.o" => [
            "crypto/x509/x509_vpm.c"
        ],
        "crypto/x509/libcrypto-lib-x509cset.o" => [
            "crypto/x509/x509cset.c"
        ],
        "crypto/x509/libcrypto-lib-x509name.o" => [
            "crypto/x509/x509name.c"
        ],
        "crypto/x509/libcrypto-lib-x509rset.o" => [
            "crypto/x509/x509rset.c"
        ],
        "crypto/x509/libcrypto-lib-x509spki.o" => [
            "crypto/x509/x509spki.c"
        ],
        "crypto/x509/libcrypto-lib-x509type.o" => [
            "crypto/x509/x509type.c"
        ],
        "crypto/x509/libcrypto-lib-x_all.o" => [
            "crypto/x509/x_all.c"
        ],
        "crypto/x509/libcrypto-lib-x_attrib.o" => [
            "crypto/x509/x_attrib.c"
        ],
        "crypto/x509/libcrypto-lib-x_crl.o" => [
            "crypto/x509/x_crl.c"
        ],
        "crypto/x509/libcrypto-lib-x_exten.o" => [
            "crypto/x509/x_exten.c"
        ],
        "crypto/x509/libcrypto-lib-x_name.o" => [
            "crypto/x509/x_name.c"
        ],
        "crypto/x509/libcrypto-lib-x_pubkey.o" => [
            "crypto/x509/x_pubkey.c"
        ],
        "crypto/x509/libcrypto-lib-x_req.o" => [
            "crypto/x509/x_req.c"
        ],
        "crypto/x509/libcrypto-lib-x_x509.o" => [
            "crypto/x509/x_x509.c"
        ],
        "crypto/x509/libcrypto-lib-x_x509a.o" => [
            "crypto/x509/x_x509a.c"
        ],
        "engines/libcrypto-lib-e_capi.o" => [
            "engines/e_capi.c"
        ],
        "engines/libcrypto-lib-e_padlock-x86_64.o" => [
            "engines/e_padlock-x86_64.s"
        ],
        "engines/libcrypto-lib-e_padlock.o" => [
            "engines/e_padlock.c"
        ],
        "fuzz/asn1-test" => [
            "fuzz/asn1-test-bin-asn1.o",
            "fuzz/asn1-test-bin-fuzz_rand.o",
            "fuzz/asn1-test-bin-test-corpus.o"
        ],
        "fuzz/asn1-test-bin-asn1.o" => [
            "fuzz/asn1.c"
        ],
        "fuzz/asn1-test-bin-fuzz_rand.o" => [
            "fuzz/fuzz_rand.c"
        ],
        "fuzz/asn1-test-bin-test-corpus.o" => [
            "fuzz/test-corpus.c"
        ],
        "fuzz/asn1parse-test" => [
            "fuzz/asn1parse-test-bin-asn1parse.o",
            "fuzz/asn1parse-test-bin-test-corpus.o"
        ],
        "fuzz/asn1parse-test-bin-asn1parse.o" => [
            "fuzz/asn1parse.c"
        ],
        "fuzz/asn1parse-test-bin-test-corpus.o" => [
            "fuzz/test-corpus.c"
        ],
        "fuzz/bignum-test" => [
            "fuzz/bignum-test-bin-bignum.o",
            "fuzz/bignum-test-bin-test-corpus.o"
        ],
        "fuzz/bignum-test-bin-bignum.o" => [
            "fuzz/bignum.c"
        ],
        "fuzz/bignum-test-bin-test-corpus.o" => [
            "fuzz/test-corpus.c"
        ],
        "fuzz/bndiv-test" => [
            "fuzz/bndiv-test-bin-bndiv.o",
            "fuzz/bndiv-test-bin-test-corpus.o"
        ],
        "fuzz/bndiv-test-bin-bndiv.o" => [
            "fuzz/bndiv.c"
        ],
        "fuzz/bndiv-test-bin-test-corpus.o" => [
            "fuzz/test-corpus.c"
        ],
        "fuzz/client-test" => [
            "fuzz/client-test-bin-client.o",
            "fuzz/client-test-bin-fuzz_rand.o",
            "fuzz/client-test-bin-test-corpus.o"
        ],
        "fuzz/client-test-bin-client.o" => [
            "fuzz/client.c"
        ],
        "fuzz/client-test-bin-fuzz_rand.o" => [
            "fuzz/fuzz_rand.c"
        ],
        "fuzz/client-test-bin-test-corpus.o" => [
            "fuzz/test-corpus.c"
        ],
        "fuzz/cmp-test" => [
            "fuzz/cmp-test-bin-cmp.o",
            "fuzz/cmp-test-bin-fuzz_rand.o",
            "fuzz/cmp-test-bin-test-corpus.o"
        ],
        "fuzz/cmp-test-bin-cmp.o" => [
            "fuzz/cmp.c"
        ],
        "fuzz/cmp-test-bin-fuzz_rand.o" => [
            "fuzz/fuzz_rand.c"
        ],
        "fuzz/cmp-test-bin-test-corpus.o" => [
            "fuzz/test-corpus.c"
        ],
        "fuzz/cms-test" => [
            "fuzz/cms-test-bin-cms.o",
            "fuzz/cms-test-bin-test-corpus.o"
        ],
        "fuzz/cms-test-bin-cms.o" => [
            "fuzz/cms.c"
        ],
        "fuzz/cms-test-bin-test-corpus.o" => [
            "fuzz/test-corpus.c"
        ],
        "fuzz/conf-test" => [
            "fuzz/conf-test-bin-conf.o",
            "fuzz/conf-test-bin-test-corpus.o"
        ],
        "fuzz/conf-test-bin-conf.o" => [
            "fuzz/conf.c"
        ],
        "fuzz/conf-test-bin-test-corpus.o" => [
            "fuzz/test-corpus.c"
        ],
        "fuzz/crl-test" => [
            "fuzz/crl-test-bin-crl.o",
            "fuzz/crl-test-bin-test-corpus.o"
        ],
        "fuzz/crl-test-bin-crl.o" => [
            "fuzz/crl.c"
        ],
        "fuzz/crl-test-bin-test-corpus.o" => [
            "fuzz/test-corpus.c"
        ],
        "fuzz/ct-test" => [
            "fuzz/ct-test-bin-ct.o",
            "fuzz/ct-test-bin-test-corpus.o"
        ],
        "fuzz/ct-test-bin-ct.o" => [
            "fuzz/ct.c"
        ],
        "fuzz/ct-test-bin-test-corpus.o" => [
            "fuzz/test-corpus.c"
        ],
        "fuzz/server-test" => [
            "fuzz/server-test-bin-fuzz_rand.o",
            "fuzz/server-test-bin-server.o",
            "fuzz/server-test-bin-test-corpus.o"
        ],
        "fuzz/server-test-bin-fuzz_rand.o" => [
            "fuzz/fuzz_rand.c"
        ],
        "fuzz/server-test-bin-server.o" => [
            "fuzz/server.c"
        ],
        "fuzz/server-test-bin-test-corpus.o" => [
            "fuzz/test-corpus.c"
        ],
        "fuzz/x509-test" => [
            "fuzz/x509-test-bin-fuzz_rand.o",
            "fuzz/x509-test-bin-test-corpus.o",
            "fuzz/x509-test-bin-x509.o"
        ],
        "fuzz/x509-test-bin-fuzz_rand.o" => [
            "fuzz/fuzz_rand.c"
        ],
        "fuzz/x509-test-bin-test-corpus.o" => [
            "fuzz/test-corpus.c"
        ],
        "fuzz/x509-test-bin-x509.o" => [
            "fuzz/x509.c"
        ],
        "libcrypto" => [
            "crypto/aes/libcrypto-lib-aes-x86_64.o",
            "crypto/aes/libcrypto-lib-aes_cfb.o",
            "crypto/aes/libcrypto-lib-aes_ecb.o",
            "crypto/aes/libcrypto-lib-aes_ige.o",
            "crypto/aes/libcrypto-lib-aes_misc.o",
            "crypto/aes/libcrypto-lib-aes_ofb.o",
            "crypto/aes/libcrypto-lib-aes_wrap.o",
            "crypto/aes/libcrypto-lib-aesni-mb-x86_64.o",
            "crypto/aes/libcrypto-lib-aesni-sha1-x86_64.o",
            "crypto/aes/libcrypto-lib-aesni-sha256-x86_64.o",
            "crypto/aes/libcrypto-lib-aesni-x86_64.o",
            "crypto/aes/libcrypto-lib-bsaes-x86_64.o",
            "crypto/aes/libcrypto-lib-vpaes-x86_64.o",
            "crypto/aria/libcrypto-lib-aria.o",
            "crypto/asn1/libcrypto-lib-a_bitstr.o",
            "crypto/asn1/libcrypto-lib-a_d2i_fp.o",
            "crypto/asn1/libcrypto-lib-a_digest.o",
            "crypto/asn1/libcrypto-lib-a_dup.o",
            "crypto/asn1/libcrypto-lib-a_gentm.o",
            "crypto/asn1/libcrypto-lib-a_i2d_fp.o",
            "crypto/asn1/libcrypto-lib-a_int.o",
            "crypto/asn1/libcrypto-lib-a_mbstr.o",
            "crypto/asn1/libcrypto-lib-a_object.o",
            "crypto/asn1/libcrypto-lib-a_octet.o",
            "crypto/asn1/libcrypto-lib-a_print.o",
            "crypto/asn1/libcrypto-lib-a_sign.o",
            "crypto/asn1/libcrypto-lib-a_strex.o",
            "crypto/asn1/libcrypto-lib-a_strnid.o",
            "crypto/asn1/libcrypto-lib-a_time.o",
            "crypto/asn1/libcrypto-lib-a_type.o",
            "crypto/asn1/libcrypto-lib-a_utctm.o",
            "crypto/asn1/libcrypto-lib-a_utf8.o",
            "crypto/asn1/libcrypto-lib-a_verify.o",
            "crypto/asn1/libcrypto-lib-ameth_lib.o",
            "crypto/asn1/libcrypto-lib-asn1_err.o",
            "crypto/asn1/libcrypto-lib-asn1_gen.o",
            "crypto/asn1/libcrypto-lib-asn1_item_list.o",
            "crypto/asn1/libcrypto-lib-asn1_lib.o",
            "crypto/asn1/libcrypto-lib-asn1_parse.o",
            "crypto/asn1/libcrypto-lib-asn_mime.o",
            "crypto/asn1/libcrypto-lib-asn_moid.o",
            "crypto/asn1/libcrypto-lib-asn_mstbl.o",
            "crypto/asn1/libcrypto-lib-asn_pack.o",
            "crypto/asn1/libcrypto-lib-bio_asn1.o",
            "crypto/asn1/libcrypto-lib-bio_ndef.o",
            "crypto/asn1/libcrypto-lib-d2i_param.o",
            "crypto/asn1/libcrypto-lib-d2i_pr.o",
            "crypto/asn1/libcrypto-lib-d2i_pu.o",
            "crypto/asn1/libcrypto-lib-evp_asn1.o",
            "crypto/asn1/libcrypto-lib-f_int.o",
            "crypto/asn1/libcrypto-lib-f_string.o",
            "crypto/asn1/libcrypto-lib-i2d_evp.o",
            "crypto/asn1/libcrypto-lib-n_pkey.o",
            "crypto/asn1/libcrypto-lib-nsseq.o",
            "crypto/asn1/libcrypto-lib-p5_pbe.o",
            "crypto/asn1/libcrypto-lib-p5_pbev2.o",
            "crypto/asn1/libcrypto-lib-p5_scrypt.o",
            "crypto/asn1/libcrypto-lib-p8_pkey.o",
            "crypto/asn1/libcrypto-lib-t_bitst.o",
            "crypto/asn1/libcrypto-lib-t_pkey.o",
            "crypto/asn1/libcrypto-lib-t_spki.o",
            "crypto/asn1/libcrypto-lib-tasn_dec.o",
            "crypto/asn1/libcrypto-lib-tasn_enc.o",
            "crypto/asn1/libcrypto-lib-tasn_fre.o",
            "crypto/asn1/libcrypto-lib-tasn_new.o",
            "crypto/asn1/libcrypto-lib-tasn_prn.o",
            "crypto/asn1/libcrypto-lib-tasn_scn.o",
            "crypto/asn1/libcrypto-lib-tasn_typ.o",
            "crypto/asn1/libcrypto-lib-tasn_utl.o",
            "crypto/asn1/libcrypto-lib-x_algor.o",
            "crypto/asn1/libcrypto-lib-x_bignum.o",
            "crypto/asn1/libcrypto-lib-x_info.o",
            "crypto/asn1/libcrypto-lib-x_int64.o",
            "crypto/asn1/libcrypto-lib-x_long.o",
            "crypto/asn1/libcrypto-lib-x_pkey.o",
            "crypto/asn1/libcrypto-lib-x_sig.o",
            "crypto/asn1/libcrypto-lib-x_spki.o",
            "crypto/asn1/libcrypto-lib-x_val.o",
            "crypto/async/arch/libcrypto-lib-async_null.o",
            "crypto/async/arch/libcrypto-lib-async_posix.o",
            "crypto/async/arch/libcrypto-lib-async_win.o",
            "crypto/async/libcrypto-lib-async.o",
            "crypto/async/libcrypto-lib-async_err.o",
            "crypto/async/libcrypto-lib-async_wait.o",
            "crypto/bf/libcrypto-lib-bf_cfb64.o",
            "crypto/bf/libcrypto-lib-bf_ecb.o",
            "crypto/bf/libcrypto-lib-bf_enc.o",
            "crypto/bf/libcrypto-lib-bf_ofb64.o",
            "crypto/bf/libcrypto-lib-bf_skey.o",
            "crypto/bio/libcrypto-lib-bf_buff.o",
            "crypto/bio/libcrypto-lib-bf_lbuf.o",
            "crypto/bio/libcrypto-lib-bf_nbio.o",
            "crypto/bio/libcrypto-lib-bf_null.o",
            "crypto/bio/libcrypto-lib-bf_prefix.o",
            "crypto/bio/libcrypto-lib-bf_readbuff.o",
            "crypto/bio/libcrypto-lib-bio_addr.o",
            "crypto/bio/libcrypto-lib-bio_cb.o",
            "crypto/bio/libcrypto-lib-bio_dump.o",
            "crypto/bio/libcrypto-lib-bio_err.o",
            "crypto/bio/libcrypto-lib-bio_lib.o",
            "crypto/bio/libcrypto-lib-bio_meth.o",
            "crypto/bio/libcrypto-lib-bio_print.o",
            "crypto/bio/libcrypto-lib-bio_sock.o",
            "crypto/bio/libcrypto-lib-bio_sock2.o",
            "crypto/bio/libcrypto-lib-bss_acpt.o",
            "crypto/bio/libcrypto-lib-bss_bio.o",
            "crypto/bio/libcrypto-lib-bss_conn.o",
            "crypto/bio/libcrypto-lib-bss_core.o",
            "crypto/bio/libcrypto-lib-bss_dgram.o",
            "crypto/bio/libcrypto-lib-bss_fd.o",
            "crypto/bio/libcrypto-lib-bss_file.o",
            "crypto/bio/libcrypto-lib-bss_log.o",
            "crypto/bio/libcrypto-lib-bss_mem.o",
            "crypto/bio/libcrypto-lib-bss_null.o",
            "crypto/bio/libcrypto-lib-bss_sock.o",
            "crypto/bio/libcrypto-lib-ossl_core_bio.o",
            "crypto/bn/asm/libcrypto-lib-x86_64-gcc.o",
            "crypto/bn/libcrypto-lib-bn_add.o",
            "crypto/bn/libcrypto-lib-bn_blind.o",
            "crypto/bn/libcrypto-lib-bn_const.o",
            "crypto/bn/libcrypto-lib-bn_conv.o",
            "crypto/bn/libcrypto-lib-bn_ctx.o",
            "crypto/bn/libcrypto-lib-bn_depr.o",
            "crypto/bn/libcrypto-lib-bn_dh.o",
            "crypto/bn/libcrypto-lib-bn_div.o",
            "crypto/bn/libcrypto-lib-bn_err.o",
            "crypto/bn/libcrypto-lib-bn_exp.o",
            "crypto/bn/libcrypto-lib-bn_exp2.o",
            "crypto/bn/libcrypto-lib-bn_gcd.o",
            "crypto/bn/libcrypto-lib-bn_gf2m.o",
            "crypto/bn/libcrypto-lib-bn_intern.o",
            "crypto/bn/libcrypto-lib-bn_kron.o",
            "crypto/bn/libcrypto-lib-bn_lib.o",
            "crypto/bn/libcrypto-lib-bn_mod.o",
            "crypto/bn/libcrypto-lib-bn_mont.o",
            "crypto/bn/libcrypto-lib-bn_mpi.o",
            "crypto/bn/libcrypto-lib-bn_mul.o",
            "crypto/bn/libcrypto-lib-bn_nist.o",
            "crypto/bn/libcrypto-lib-bn_prime.o",
            "crypto/bn/libcrypto-lib-bn_print.o",
            "crypto/bn/libcrypto-lib-bn_rand.o",
            "crypto/bn/libcrypto-lib-bn_recp.o",
            "crypto/bn/libcrypto-lib-bn_rsa_fips186_4.o",
            "crypto/bn/libcrypto-lib-bn_shift.o",
            "crypto/bn/libcrypto-lib-bn_sqr.o",
            "crypto/bn/libcrypto-lib-bn_sqrt.o",
            "crypto/bn/libcrypto-lib-bn_srp.o",
            "crypto/bn/libcrypto-lib-bn_word.o",
            "crypto/bn/libcrypto-lib-bn_x931p.o",
            "crypto/bn/libcrypto-lib-rsaz-avx2.o",
            "crypto/bn/libcrypto-lib-rsaz-avx512.o",
            "crypto/bn/libcrypto-lib-rsaz-x86_64.o",
            "crypto/bn/libcrypto-lib-rsaz_exp.o",
            "crypto/bn/libcrypto-lib-rsaz_exp_x2.o",
            "crypto/bn/libcrypto-lib-x86_64-gf2m.o",
            "crypto/bn/libcrypto-lib-x86_64-mont.o",
            "crypto/bn/libcrypto-lib-x86_64-mont5.o",
            "crypto/buffer/libcrypto-lib-buf_err.o",
            "crypto/buffer/libcrypto-lib-buffer.o",
            "crypto/camellia/libcrypto-lib-cmll-x86_64.o",
            "crypto/camellia/libcrypto-lib-cmll_cfb.o",
            "crypto/camellia/libcrypto-lib-cmll_ctr.o",
            "crypto/camellia/libcrypto-lib-cmll_ecb.o",
            "crypto/camellia/libcrypto-lib-cmll_misc.o",
            "crypto/camellia/libcrypto-lib-cmll_ofb.o",
            "crypto/cast/libcrypto-lib-c_cfb64.o",
            "crypto/cast/libcrypto-lib-c_ecb.o",
            "crypto/cast/libcrypto-lib-c_enc.o",
            "crypto/cast/libcrypto-lib-c_ofb64.o",
            "crypto/cast/libcrypto-lib-c_skey.o",
            "crypto/chacha/libcrypto-lib-chacha-x86_64.o",
            "crypto/cmac/libcrypto-lib-cmac.o",
            "crypto/cmp/libcrypto-lib-cmp_asn.o",
            "crypto/cmp/libcrypto-lib-cmp_client.o",
            "crypto/cmp/libcrypto-lib-cmp_ctx.o",
            "crypto/cmp/libcrypto-lib-cmp_err.o",
            "crypto/cmp/libcrypto-lib-cmp_hdr.o",
            "crypto/cmp/libcrypto-lib-cmp_http.o",
            "crypto/cmp/libcrypto-lib-cmp_msg.o",
            "crypto/cmp/libcrypto-lib-cmp_protect.o",
            "crypto/cmp/libcrypto-lib-cmp_server.o",
            "crypto/cmp/libcrypto-lib-cmp_status.o",
            "crypto/cmp/libcrypto-lib-cmp_util.o",
            "crypto/cmp/libcrypto-lib-cmp_vfy.o",
            "crypto/cms/libcrypto-lib-cms_asn1.o",
            "crypto/cms/libcrypto-lib-cms_att.o",
            "crypto/cms/libcrypto-lib-cms_cd.o",
            "crypto/cms/libcrypto-lib-cms_dd.o",
            "crypto/cms/libcrypto-lib-cms_dh.o",
            "crypto/cms/libcrypto-lib-cms_ec.o",
            "crypto/cms/libcrypto-lib-cms_enc.o",
            "crypto/cms/libcrypto-lib-cms_env.o",
            "crypto/cms/libcrypto-lib-cms_err.o",
            "crypto/cms/libcrypto-lib-cms_ess.o",
            "crypto/cms/libcrypto-lib-cms_io.o",
            "crypto/cms/libcrypto-lib-cms_kari.o",
            "crypto/cms/libcrypto-lib-cms_lib.o",
            "crypto/cms/libcrypto-lib-cms_pwri.o",
            "crypto/cms/libcrypto-lib-cms_rsa.o",
            "crypto/cms/libcrypto-lib-cms_sd.o",
            "crypto/cms/libcrypto-lib-cms_smime.o",
            "crypto/conf/libcrypto-lib-conf_api.o",
            "crypto/conf/libcrypto-lib-conf_def.o",
            "crypto/conf/libcrypto-lib-conf_err.o",
            "crypto/conf/libcrypto-lib-conf_lib.o",
            "crypto/conf/libcrypto-lib-conf_mall.o",
            "crypto/conf/libcrypto-lib-conf_mod.o",
            "crypto/conf/libcrypto-lib-conf_sap.o",
            "crypto/conf/libcrypto-lib-conf_ssl.o",
            "crypto/crmf/libcrypto-lib-crmf_asn.o",
            "crypto/crmf/libcrypto-lib-crmf_err.o",
            "crypto/crmf/libcrypto-lib-crmf_lib.o",
            "crypto/crmf/libcrypto-lib-crmf_pbm.o",
            "crypto/ct/libcrypto-lib-ct_b64.o",
            "crypto/ct/libcrypto-lib-ct_err.o",
            "crypto/ct/libcrypto-lib-ct_log.o",
            "crypto/ct/libcrypto-lib-ct_oct.o",
            "crypto/ct/libcrypto-lib-ct_policy.o",
            "crypto/ct/libcrypto-lib-ct_prn.o",
            "crypto/ct/libcrypto-lib-ct_sct.o",
            "crypto/ct/libcrypto-lib-ct_sct_ctx.o",
            "crypto/ct/libcrypto-lib-ct_vfy.o",
            "crypto/ct/libcrypto-lib-ct_x509v3.o",
            "crypto/des/libcrypto-lib-cbc_cksm.o",
            "crypto/des/libcrypto-lib-cbc_enc.o",
            "crypto/des/libcrypto-lib-cfb64ede.o",
            "crypto/des/libcrypto-lib-cfb64enc.o",
            "crypto/des/libcrypto-lib-cfb_enc.o",
            "crypto/des/libcrypto-lib-des_enc.o",
            "crypto/des/libcrypto-lib-ecb3_enc.o",
            "crypto/des/libcrypto-lib-ecb_enc.o",
            "crypto/des/libcrypto-lib-fcrypt.o",
            "crypto/des/libcrypto-lib-fcrypt_b.o",
            "crypto/des/libcrypto-lib-ofb64ede.o",
            "crypto/des/libcrypto-lib-ofb64enc.o",
            "crypto/des/libcrypto-lib-ofb_enc.o",
            "crypto/des/libcrypto-lib-pcbc_enc.o",
            "crypto/des/libcrypto-lib-qud_cksm.o",
            "crypto/des/libcrypto-lib-rand_key.o",
            "crypto/des/libcrypto-lib-set_key.o",
            "crypto/des/libcrypto-lib-str2key.o",
            "crypto/des/libcrypto-lib-xcbc_enc.o",
            "crypto/dh/libcrypto-lib-dh_ameth.o",
            "crypto/dh/libcrypto-lib-dh_asn1.o",
            "crypto/dh/libcrypto-lib-dh_backend.o",
            "crypto/dh/libcrypto-lib-dh_check.o",
            "crypto/dh/libcrypto-lib-dh_depr.o",
            "crypto/dh/libcrypto-lib-dh_err.o",
            "crypto/dh/libcrypto-lib-dh_gen.o",
            "crypto/dh/libcrypto-lib-dh_group_params.o",
            "crypto/dh/libcrypto-lib-dh_kdf.o",
            "crypto/dh/libcrypto-lib-dh_key.o",
            "crypto/dh/libcrypto-lib-dh_lib.o",
            "crypto/dh/libcrypto-lib-dh_meth.o",
            "crypto/dh/libcrypto-lib-dh_pmeth.o",
            "crypto/dh/libcrypto-lib-dh_prn.o",
            "crypto/dh/libcrypto-lib-dh_rfc5114.o",
            "crypto/dsa/libcrypto-lib-dsa_ameth.o",
            "crypto/dsa/libcrypto-lib-dsa_asn1.o",
            "crypto/dsa/libcrypto-lib-dsa_backend.o",
            "crypto/dsa/libcrypto-lib-dsa_check.o",
            "crypto/dsa/libcrypto-lib-dsa_depr.o",
            "crypto/dsa/libcrypto-lib-dsa_err.o",
            "crypto/dsa/libcrypto-lib-dsa_gen.o",
            "crypto/dsa/libcrypto-lib-dsa_key.o",
            "crypto/dsa/libcrypto-lib-dsa_lib.o",
            "crypto/dsa/libcrypto-lib-dsa_meth.o",
            "crypto/dsa/libcrypto-lib-dsa_ossl.o",
            "crypto/dsa/libcrypto-lib-dsa_pmeth.o",
            "crypto/dsa/libcrypto-lib-dsa_prn.o",
            "crypto/dsa/libcrypto-lib-dsa_sign.o",
            "crypto/dsa/libcrypto-lib-dsa_vrf.o",
            "crypto/dso/libcrypto-lib-dso_dl.o",
            "crypto/dso/libcrypto-lib-dso_dlfcn.o",
            "crypto/dso/libcrypto-lib-dso_err.o",
            "crypto/dso/libcrypto-lib-dso_lib.o",
            "crypto/dso/libcrypto-lib-dso_openssl.o",
            "crypto/dso/libcrypto-lib-dso_vms.o",
            "crypto/dso/libcrypto-lib-dso_win32.o",
            "crypto/ec/curve448/arch_32/libcrypto-lib-f_impl32.o",
            "crypto/ec/curve448/arch_64/libcrypto-lib-f_impl64.o",
            "crypto/ec/curve448/libcrypto-lib-curve448.o",
            "crypto/ec/curve448/libcrypto-lib-curve448_tables.o",
            "crypto/ec/curve448/libcrypto-lib-eddsa.o",
            "crypto/ec/curve448/libcrypto-lib-f_generic.o",
            "crypto/ec/curve448/libcrypto-lib-scalar.o",
            "crypto/ec/libcrypto-lib-curve25519.o",
            "crypto/ec/libcrypto-lib-ec2_oct.o",
            "crypto/ec/libcrypto-lib-ec2_smpl.o",
            "crypto/ec/libcrypto-lib-ec_ameth.o",
            "crypto/ec/libcrypto-lib-ec_asn1.o",
            "crypto/ec/libcrypto-lib-ec_backend.o",
            "crypto/ec/libcrypto-lib-ec_check.o",
            "crypto/ec/libcrypto-lib-ec_curve.o",
            "crypto/ec/libcrypto-lib-ec_cvt.o",
            "crypto/ec/libcrypto-lib-ec_deprecated.o",
            "crypto/ec/libcrypto-lib-ec_err.o",
            "crypto/ec/libcrypto-lib-ec_key.o",
            "crypto/ec/libcrypto-lib-ec_kmeth.o",
            "crypto/ec/libcrypto-lib-ec_lib.o",
            "crypto/ec/libcrypto-lib-ec_mult.o",
            "crypto/ec/libcrypto-lib-ec_oct.o",
            "crypto/ec/libcrypto-lib-ec_pmeth.o",
            "crypto/ec/libcrypto-lib-ec_print.o",
            "crypto/ec/libcrypto-lib-ecdh_kdf.o",
            "crypto/ec/libcrypto-lib-ecdh_ossl.o",
            "crypto/ec/libcrypto-lib-ecdsa_ossl.o",
            "crypto/ec/libcrypto-lib-ecdsa_sign.o",
            "crypto/ec/libcrypto-lib-ecdsa_vrf.o",
            "crypto/ec/libcrypto-lib-eck_prn.o",
            "crypto/ec/libcrypto-lib-ecp_mont.o",
            "crypto/ec/libcrypto-lib-ecp_nist.o",
            "crypto/ec/libcrypto-lib-ecp_nistz256-x86_64.o",
            "crypto/ec/libcrypto-lib-ecp_nistz256.o",
            "crypto/ec/libcrypto-lib-ecp_oct.o",
            "crypto/ec/libcrypto-lib-ecp_smpl.o",
            "crypto/ec/libcrypto-lib-ecx_backend.o",
            "crypto/ec/libcrypto-lib-ecx_key.o",
            "crypto/ec/libcrypto-lib-ecx_meth.o",
            "crypto/ec/libcrypto-lib-x25519-x86_64.o",
            "crypto/encode_decode/libcrypto-lib-decoder_err.o",
            "crypto/encode_decode/libcrypto-lib-decoder_lib.o",
            "crypto/encode_decode/libcrypto-lib-decoder_meth.o",
            "crypto/encode_decode/libcrypto-lib-decoder_pkey.o",
            "crypto/encode_decode/libcrypto-lib-encoder_err.o",
            "crypto/encode_decode/libcrypto-lib-encoder_lib.o",
            "crypto/encode_decode/libcrypto-lib-encoder_meth.o",
            "crypto/encode_decode/libcrypto-lib-encoder_pkey.o",
            "crypto/engine/libcrypto-lib-eng_all.o",
            "crypto/engine/libcrypto-lib-eng_cnf.o",
            "crypto/engine/libcrypto-lib-eng_ctrl.o",
            "crypto/engine/libcrypto-lib-eng_dyn.o",
            "crypto/engine/libcrypto-lib-eng_err.o",
            "crypto/engine/libcrypto-lib-eng_fat.o",
            "crypto/engine/libcrypto-lib-eng_init.o",
            "crypto/engine/libcrypto-lib-eng_lib.o",
            "crypto/engine/libcrypto-lib-eng_list.o",
            "crypto/engine/libcrypto-lib-eng_openssl.o",
            "crypto/engine/libcrypto-lib-eng_pkey.o",
            "crypto/engine/libcrypto-lib-eng_rdrand.o",
            "crypto/engine/libcrypto-lib-eng_table.o",
            "crypto/engine/libcrypto-lib-tb_asnmth.o",
            "crypto/engine/libcrypto-lib-tb_cipher.o",
            "crypto/engine/libcrypto-lib-tb_dh.o",
            "crypto/engine/libcrypto-lib-tb_digest.o",
            "crypto/engine/libcrypto-lib-tb_dsa.o",
            "crypto/engine/libcrypto-lib-tb_eckey.o",
            "crypto/engine/libcrypto-lib-tb_pkmeth.o",
            "crypto/engine/libcrypto-lib-tb_rand.o",
            "crypto/engine/libcrypto-lib-tb_rsa.o",
            "crypto/err/libcrypto-lib-err.o",
            "crypto/err/libcrypto-lib-err_all.o",
            "crypto/err/libcrypto-lib-err_all_legacy.o",
            "crypto/err/libcrypto-lib-err_blocks.o",
            "crypto/err/libcrypto-lib-err_prn.o",
            "crypto/ess/libcrypto-lib-ess_asn1.o",
            "crypto/ess/libcrypto-lib-ess_err.o",
            "crypto/ess/libcrypto-lib-ess_lib.o",
            "crypto/evp/libcrypto-lib-asymcipher.o",
            "crypto/evp/libcrypto-lib-bio_b64.o",
            "crypto/evp/libcrypto-lib-bio_enc.o",
            "crypto/evp/libcrypto-lib-bio_md.o",
            "crypto/evp/libcrypto-lib-bio_ok.o",
            "crypto/evp/libcrypto-lib-c_allc.o",
            "crypto/evp/libcrypto-lib-c_alld.o",
            "crypto/evp/libcrypto-lib-cmeth_lib.o",
            "crypto/evp/libcrypto-lib-ctrl_params_translate.o",
            "crypto/evp/libcrypto-lib-dh_ctrl.o",
            "crypto/evp/libcrypto-lib-dh_support.o",
            "crypto/evp/libcrypto-lib-digest.o",
            "crypto/evp/libcrypto-lib-dsa_ctrl.o",
            "crypto/evp/libcrypto-lib-e_aes.o",
            "crypto/evp/libcrypto-lib-e_aes_cbc_hmac_sha1.o",
            "crypto/evp/libcrypto-lib-e_aes_cbc_hmac_sha256.o",
            "crypto/evp/libcrypto-lib-e_aria.o",
            "crypto/evp/libcrypto-lib-e_bf.o",
            "crypto/evp/libcrypto-lib-e_camellia.o",
            "crypto/evp/libcrypto-lib-e_cast.o",
            "crypto/evp/libcrypto-lib-e_chacha20_poly1305.o",
            "crypto/evp/libcrypto-lib-e_des.o",
            "crypto/evp/libcrypto-lib-e_des3.o",
            "crypto/evp/libcrypto-lib-e_idea.o",
            "crypto/evp/libcrypto-lib-e_null.o",
            "crypto/evp/libcrypto-lib-e_old.o",
            "crypto/evp/libcrypto-lib-e_rc2.o",
            "crypto/evp/libcrypto-lib-e_rc4.o",
            "crypto/evp/libcrypto-lib-e_rc4_hmac_md5.o",
            "crypto/evp/libcrypto-lib-e_rc5.o",
            "crypto/evp/libcrypto-lib-e_seed.o",
            "crypto/evp/libcrypto-lib-e_sm4.o",
            "crypto/evp/libcrypto-lib-e_xcbc_d.o",
            "crypto/evp/libcrypto-lib-ec_ctrl.o",
            "crypto/evp/libcrypto-lib-ec_support.o",
            "crypto/evp/libcrypto-lib-encode.o",
            "crypto/evp/libcrypto-lib-evp_cnf.o",
            "crypto/evp/libcrypto-lib-evp_enc.o",
            "crypto/evp/libcrypto-lib-evp_err.o",
            "crypto/evp/libcrypto-lib-evp_fetch.o",
            "crypto/evp/libcrypto-lib-evp_key.o",
            "crypto/evp/libcrypto-lib-evp_lib.o",
            "crypto/evp/libcrypto-lib-evp_pbe.o",
            "crypto/evp/libcrypto-lib-evp_pkey.o",
            "crypto/evp/libcrypto-lib-evp_rand.o",
            "crypto/evp/libcrypto-lib-evp_utils.o",
            "crypto/evp/libcrypto-lib-exchange.o",
            "crypto/evp/libcrypto-lib-kdf_lib.o",
            "crypto/evp/libcrypto-lib-kdf_meth.o",
            "crypto/evp/libcrypto-lib-kem.o",
            "crypto/evp/libcrypto-lib-keymgmt_lib.o",
            "crypto/evp/libcrypto-lib-keymgmt_meth.o",
            "crypto/evp/libcrypto-lib-legacy_blake2.o",
            "crypto/evp/libcrypto-lib-legacy_md4.o",
            "crypto/evp/libcrypto-lib-legacy_md5.o",
            "crypto/evp/libcrypto-lib-legacy_md5_sha1.o",
            "crypto/evp/libcrypto-lib-legacy_mdc2.o",
            "crypto/evp/libcrypto-lib-legacy_ripemd.o",
            "crypto/evp/libcrypto-lib-legacy_sha.o",
            "crypto/evp/libcrypto-lib-legacy_wp.o",
            "crypto/evp/libcrypto-lib-m_null.o",
            "crypto/evp/libcrypto-lib-m_sigver.o",
            "crypto/evp/libcrypto-lib-mac_lib.o",
            "crypto/evp/libcrypto-lib-mac_meth.o",
            "crypto/evp/libcrypto-lib-names.o",
            "crypto/evp/libcrypto-lib-p5_crpt.o",
            "crypto/evp/libcrypto-lib-p5_crpt2.o",
            "crypto/evp/libcrypto-lib-p_dec.o",
            "crypto/evp/libcrypto-lib-p_enc.o",
            "crypto/evp/libcrypto-lib-p_legacy.o",
            "crypto/evp/libcrypto-lib-p_lib.o",
            "crypto/evp/libcrypto-lib-p_open.o",
            "crypto/evp/libcrypto-lib-p_seal.o",
            "crypto/evp/libcrypto-lib-p_sign.o",
            "crypto/evp/libcrypto-lib-p_verify.o",
            "crypto/evp/libcrypto-lib-pbe_scrypt.o",
            "crypto/evp/libcrypto-lib-pmeth_check.o",
            "crypto/evp/libcrypto-lib-pmeth_gn.o",
            "crypto/evp/libcrypto-lib-pmeth_lib.o",
            "crypto/evp/libcrypto-lib-signature.o",
            "crypto/ffc/libcrypto-lib-ffc_backend.o",
            "crypto/ffc/libcrypto-lib-ffc_dh.o",
            "crypto/ffc/libcrypto-lib-ffc_key_generate.o",
            "crypto/ffc/libcrypto-lib-ffc_key_validate.o",
            "crypto/ffc/libcrypto-lib-ffc_params.o",
            "crypto/ffc/libcrypto-lib-ffc_params_generate.o",
            "crypto/ffc/libcrypto-lib-ffc_params_validate.o",
            "crypto/hmac/libcrypto-lib-hmac.o",
            "crypto/http/libcrypto-lib-http_client.o",
            "crypto/http/libcrypto-lib-http_err.o",
            "crypto/http/libcrypto-lib-http_lib.o",
            "crypto/idea/libcrypto-lib-i_cbc.o",
            "crypto/idea/libcrypto-lib-i_cfb64.o",
            "crypto/idea/libcrypto-lib-i_ecb.o",
            "crypto/idea/libcrypto-lib-i_ofb64.o",
            "crypto/idea/libcrypto-lib-i_skey.o",
            "crypto/kdf/libcrypto-lib-kdf_err.o",
            "crypto/lhash/libcrypto-lib-lh_stats.o",
            "crypto/lhash/libcrypto-lib-lhash.o",
            "crypto/libcrypto-lib-asn1_dsa.o",
            "crypto/libcrypto-lib-bsearch.o",
            "crypto/libcrypto-lib-context.o",
            "crypto/libcrypto-lib-core_algorithm.o",
            "crypto/libcrypto-lib-core_fetch.o",
            "crypto/libcrypto-lib-core_namemap.o",
            "crypto/libcrypto-lib-cpt_err.o",
            "crypto/libcrypto-lib-cpuid.o",
            "crypto/libcrypto-lib-cryptlib.o",
            "crypto/libcrypto-lib-ctype.o",
            "crypto/libcrypto-lib-cversion.o",
            "crypto/libcrypto-lib-der_writer.o",
            "crypto/libcrypto-lib-ebcdic.o",
            "crypto/libcrypto-lib-ex_data.o",
            "crypto/libcrypto-lib-getenv.o",
            "crypto/libcrypto-lib-info.o",
            "crypto/libcrypto-lib-init.o",
            "crypto/libcrypto-lib-initthread.o",
            "crypto/libcrypto-lib-mem.o",
            "crypto/libcrypto-lib-mem_sec.o",
            "crypto/libcrypto-lib-o_dir.o",
            "crypto/libcrypto-lib-o_fopen.o",
            "crypto/libcrypto-lib-o_init.o",
            "crypto/libcrypto-lib-o_str.o",
            "crypto/libcrypto-lib-o_time.o",
            "crypto/libcrypto-lib-packet.o",
            "crypto/libcrypto-lib-param_build.o",
            "crypto/libcrypto-lib-param_build_set.o",
            "crypto/libcrypto-lib-params.o",
            "crypto/libcrypto-lib-params_dup.o",
            "crypto/libcrypto-lib-params_from_text.o",
            "crypto/libcrypto-lib-passphrase.o",
            "crypto/libcrypto-lib-provider.o",
            "crypto/libcrypto-lib-provider_child.o",
            "crypto/libcrypto-lib-provider_conf.o",
            "crypto/libcrypto-lib-provider_core.o",
            "crypto/libcrypto-lib-provider_predefined.o",
            "crypto/libcrypto-lib-punycode.o",
            "crypto/libcrypto-lib-self_test_core.o",
            "crypto/libcrypto-lib-sparse_array.o",
            "crypto/libcrypto-lib-threads_lib.o",
            "crypto/libcrypto-lib-threads_none.o",
            "crypto/libcrypto-lib-threads_pthread.o",
            "crypto/libcrypto-lib-threads_win.o",
            "crypto/libcrypto-lib-trace.o",
            "crypto/libcrypto-lib-uid.o",
            "crypto/libcrypto-lib-x86_64cpuid.o",
            "crypto/md4/libcrypto-lib-md4_dgst.o",
            "crypto/md4/libcrypto-lib-md4_one.o",
            "crypto/md5/libcrypto-lib-md5-x86_64.o",
            "crypto/md5/libcrypto-lib-md5_dgst.o",
            "crypto/md5/libcrypto-lib-md5_one.o",
            "crypto/md5/libcrypto-lib-md5_sha1.o",
            "crypto/mdc2/libcrypto-lib-mdc2_one.o",
            "crypto/mdc2/libcrypto-lib-mdc2dgst.o",
            "crypto/modes/libcrypto-lib-aesni-gcm-x86_64.o",
            "crypto/modes/libcrypto-lib-cbc128.o",
            "crypto/modes/libcrypto-lib-ccm128.o",
            "crypto/modes/libcrypto-lib-cfb128.o",
            "crypto/modes/libcrypto-lib-ctr128.o",
            "crypto/modes/libcrypto-lib-cts128.o",
            "crypto/modes/libcrypto-lib-gcm128.o",
            "crypto/modes/libcrypto-lib-ghash-x86_64.o",
            "crypto/modes/libcrypto-lib-ocb128.o",
            "crypto/modes/libcrypto-lib-ofb128.o",
            "crypto/modes/libcrypto-lib-siv128.o",
            "crypto/modes/libcrypto-lib-wrap128.o",
            "crypto/modes/libcrypto-lib-xts128.o",
            "crypto/objects/libcrypto-lib-o_names.o",
            "crypto/objects/libcrypto-lib-obj_dat.o",
            "crypto/objects/libcrypto-lib-obj_err.o",
            "crypto/objects/libcrypto-lib-obj_lib.o",
            "crypto/objects/libcrypto-lib-obj_xref.o",
            "crypto/ocsp/libcrypto-lib-ocsp_asn.o",
            "crypto/ocsp/libcrypto-lib-ocsp_cl.o",
            "crypto/ocsp/libcrypto-lib-ocsp_err.o",
            "crypto/ocsp/libcrypto-lib-ocsp_ext.o",
            "crypto/ocsp/libcrypto-lib-ocsp_http.o",
            "crypto/ocsp/libcrypto-lib-ocsp_lib.o",
            "crypto/ocsp/libcrypto-lib-ocsp_prn.o",
            "crypto/ocsp/libcrypto-lib-ocsp_srv.o",
            "crypto/ocsp/libcrypto-lib-ocsp_vfy.o",
            "crypto/ocsp/libcrypto-lib-v3_ocsp.o",
            "crypto/pem/libcrypto-lib-pem_all.o",
            "crypto/pem/libcrypto-lib-pem_err.o",
            "crypto/pem/libcrypto-lib-pem_info.o",
            "crypto/pem/libcrypto-lib-pem_lib.o",
            "crypto/pem/libcrypto-lib-pem_oth.o",
            "crypto/pem/libcrypto-lib-pem_pk8.o",
            "crypto/pem/libcrypto-lib-pem_pkey.o",
            "crypto/pem/libcrypto-lib-pem_sign.o",
            "crypto/pem/libcrypto-lib-pem_x509.o",
            "crypto/pem/libcrypto-lib-pem_xaux.o",
            "crypto/pem/libcrypto-lib-pvkfmt.o",
            "crypto/pkcs12/libcrypto-lib-p12_add.o",
            "crypto/pkcs12/libcrypto-lib-p12_asn.o",
            "crypto/pkcs12/libcrypto-lib-p12_attr.o",
            "crypto/pkcs12/libcrypto-lib-p12_crpt.o",
            "crypto/pkcs12/libcrypto-lib-p12_crt.o",
            "crypto/pkcs12/libcrypto-lib-p12_decr.o",
            "crypto/pkcs12/libcrypto-lib-p12_init.o",
            "crypto/pkcs12/libcrypto-lib-p12_key.o",
            "crypto/pkcs12/libcrypto-lib-p12_kiss.o",
            "crypto/pkcs12/libcrypto-lib-p12_mutl.o",
            "crypto/pkcs12/libcrypto-lib-p12_npas.o",
            "crypto/pkcs12/libcrypto-lib-p12_p8d.o",
            "crypto/pkcs12/libcrypto-lib-p12_p8e.o",
            "crypto/pkcs12/libcrypto-lib-p12_sbag.o",
            "crypto/pkcs12/libcrypto-lib-p12_utl.o",
            "crypto/pkcs12/libcrypto-lib-pk12err.o",
            "crypto/pkcs7/libcrypto-lib-bio_pk7.o",
            "crypto/pkcs7/libcrypto-lib-pk7_asn1.o",
            "crypto/pkcs7/libcrypto-lib-pk7_attr.o",
            "crypto/pkcs7/libcrypto-lib-pk7_doit.o",
            "crypto/pkcs7/libcrypto-lib-pk7_lib.o",
            "crypto/pkcs7/libcrypto-lib-pk7_mime.o",
            "crypto/pkcs7/libcrypto-lib-pk7_smime.o",
            "crypto/pkcs7/libcrypto-lib-pkcs7err.o",
            "crypto/poly1305/libcrypto-lib-poly1305-x86_64.o",
            "crypto/poly1305/libcrypto-lib-poly1305.o",
            "crypto/property/libcrypto-lib-defn_cache.o",
            "crypto/property/libcrypto-lib-property.o",
            "crypto/property/libcrypto-lib-property_err.o",
            "crypto/property/libcrypto-lib-property_parse.o",
            "crypto/property/libcrypto-lib-property_query.o",
            "crypto/property/libcrypto-lib-property_string.o",
            "crypto/rand/libcrypto-lib-prov_seed.o",
            "crypto/rand/libcrypto-lib-rand_deprecated.o",
            "crypto/rand/libcrypto-lib-rand_err.o",
            "crypto/rand/libcrypto-lib-rand_lib.o",
            "crypto/rand/libcrypto-lib-rand_meth.o",
            "crypto/rand/libcrypto-lib-rand_pool.o",
            "crypto/rand/libcrypto-lib-randfile.o",
            "crypto/rc2/libcrypto-lib-rc2_cbc.o",
            "crypto/rc2/libcrypto-lib-rc2_ecb.o",
            "crypto/rc2/libcrypto-lib-rc2_skey.o",
            "crypto/rc2/libcrypto-lib-rc2cfb64.o",
            "crypto/rc2/libcrypto-lib-rc2ofb64.o",
            "crypto/rc4/libcrypto-lib-rc4-md5-x86_64.o",
            "crypto/rc4/libcrypto-lib-rc4-x86_64.o",
            "crypto/ripemd/libcrypto-lib-rmd_dgst.o",
            "crypto/ripemd/libcrypto-lib-rmd_one.o",
            "crypto/rsa/libcrypto-lib-rsa_ameth.o",
            "crypto/rsa/libcrypto-lib-rsa_asn1.o",
            "crypto/rsa/libcrypto-lib-rsa_backend.o",
            "crypto/rsa/libcrypto-lib-rsa_chk.o",
            "crypto/rsa/libcrypto-lib-rsa_crpt.o",
            "crypto/rsa/libcrypto-lib-rsa_depr.o",
            "crypto/rsa/libcrypto-lib-rsa_err.o",
            "crypto/rsa/libcrypto-lib-rsa_gen.o",
            "crypto/rsa/libcrypto-lib-rsa_lib.o",
            "crypto/rsa/libcrypto-lib-rsa_meth.o",
            "crypto/rsa/libcrypto-lib-rsa_mp.o",
            "crypto/rsa/libcrypto-lib-rsa_mp_names.o",
            "crypto/rsa/libcrypto-lib-rsa_none.o",
            "crypto/rsa/libcrypto-lib-rsa_oaep.o",
            "crypto/rsa/libcrypto-lib-rsa_ossl.o",
            "crypto/rsa/libcrypto-lib-rsa_pk1.o",
            "crypto/rsa/libcrypto-lib-rsa_pmeth.o",
            "crypto/rsa/libcrypto-lib-rsa_prn.o",
            "crypto/rsa/libcrypto-lib-rsa_pss.o",
            "crypto/rsa/libcrypto-lib-rsa_saos.o",
            "crypto/rsa/libcrypto-lib-rsa_schemes.o",
            "crypto/rsa/libcrypto-lib-rsa_sign.o",
            "crypto/rsa/libcrypto-lib-rsa_sp800_56b_check.o",
            "crypto/rsa/libcrypto-lib-rsa_sp800_56b_gen.o",
            "crypto/rsa/libcrypto-lib-rsa_x931.o",
            "crypto/rsa/libcrypto-lib-rsa_x931g.o",
            "crypto/seed/libcrypto-lib-seed.o",
            "crypto/seed/libcrypto-lib-seed_cbc.o",
            "crypto/seed/libcrypto-lib-seed_cfb.o",
            "crypto/seed/libcrypto-lib-seed_ecb.o",
            "crypto/seed/libcrypto-lib-seed_ofb.o",
            "crypto/sha/libcrypto-lib-keccak1600-x86_64.o",
            "crypto/sha/libcrypto-lib-sha1-mb-x86_64.o",
            "crypto/sha/libcrypto-lib-sha1-x86_64.o",
            "crypto/sha/libcrypto-lib-sha1_one.o",
            "crypto/sha/libcrypto-lib-sha1dgst.o",
            "crypto/sha/libcrypto-lib-sha256-mb-x86_64.o",
            "crypto/sha/libcrypto-lib-sha256-x86_64.o",
            "crypto/sha/libcrypto-lib-sha256.o",
            "crypto/sha/libcrypto-lib-sha3.o",
            "crypto/sha/libcrypto-lib-sha512-x86_64.o",
            "crypto/sha/libcrypto-lib-sha512.o",
            "crypto/siphash/libcrypto-lib-siphash.o",
            "crypto/sm2/libcrypto-lib-sm2_crypt.o",
            "crypto/sm2/libcrypto-lib-sm2_err.o",
            "crypto/sm2/libcrypto-lib-sm2_key.o",
            "crypto/sm2/libcrypto-lib-sm2_sign.o",
            "crypto/sm3/libcrypto-lib-legacy_sm3.o",
            "crypto/sm3/libcrypto-lib-sm3.o",
            "crypto/sm4/libcrypto-lib-sm4.o",
            "crypto/srp/libcrypto-lib-srp_lib.o",
            "crypto/srp/libcrypto-lib-srp_vfy.o",
            "crypto/stack/libcrypto-lib-stack.o",
            "crypto/store/libcrypto-lib-store_err.o",
            "crypto/store/libcrypto-lib-store_init.o",
            "crypto/store/libcrypto-lib-store_lib.o",
            "crypto/store/libcrypto-lib-store_meth.o",
            "crypto/store/libcrypto-lib-store_register.o",
            "crypto/store/libcrypto-lib-store_result.o",
            "crypto/store/libcrypto-lib-store_strings.o",
            "crypto/ts/libcrypto-lib-ts_asn1.o",
            "crypto/ts/libcrypto-lib-ts_conf.o",
            "crypto/ts/libcrypto-lib-ts_err.o",
            "crypto/ts/libcrypto-lib-ts_lib.o",
            "crypto/ts/libcrypto-lib-ts_req_print.o",
            "crypto/ts/libcrypto-lib-ts_req_utils.o",
            "crypto/ts/libcrypto-lib-ts_rsp_print.o",
            "crypto/ts/libcrypto-lib-ts_rsp_sign.o",
            "crypto/ts/libcrypto-lib-ts_rsp_utils.o",
            "crypto/ts/libcrypto-lib-ts_rsp_verify.o",
            "crypto/ts/libcrypto-lib-ts_verify_ctx.o",
            "crypto/txt_db/libcrypto-lib-txt_db.o",
            "crypto/ui/libcrypto-lib-ui_err.o",
            "crypto/ui/libcrypto-lib-ui_lib.o",
            "crypto/ui/libcrypto-lib-ui_null.o",
            "crypto/ui/libcrypto-lib-ui_openssl.o",
            "crypto/ui/libcrypto-lib-ui_util.o",
            "crypto/whrlpool/libcrypto-lib-wp-x86_64.o",
            "crypto/whrlpool/libcrypto-lib-wp_dgst.o",
            "crypto/x509/libcrypto-lib-by_dir.o",
            "crypto/x509/libcrypto-lib-by_file.o",
            "crypto/x509/libcrypto-lib-by_store.o",
            "crypto/x509/libcrypto-lib-pcy_cache.o",
            "crypto/x509/libcrypto-lib-pcy_data.o",
            "crypto/x509/libcrypto-lib-pcy_lib.o",
            "crypto/x509/libcrypto-lib-pcy_map.o",
            "crypto/x509/libcrypto-lib-pcy_node.o",
            "crypto/x509/libcrypto-lib-pcy_tree.o",
            "crypto/x509/libcrypto-lib-t_crl.o",
            "crypto/x509/libcrypto-lib-t_req.o",
            "crypto/x509/libcrypto-lib-t_x509.o",
            "crypto/x509/libcrypto-lib-v3_addr.o",
            "crypto/x509/libcrypto-lib-v3_admis.o",
            "crypto/x509/libcrypto-lib-v3_akeya.o",
            "crypto/x509/libcrypto-lib-v3_akid.o",
            "crypto/x509/libcrypto-lib-v3_asid.o",
            "crypto/x509/libcrypto-lib-v3_bcons.o",
            "crypto/x509/libcrypto-lib-v3_bitst.o",
            "crypto/x509/libcrypto-lib-v3_conf.o",
            "crypto/x509/libcrypto-lib-v3_cpols.o",
            "crypto/x509/libcrypto-lib-v3_crld.o",
            "crypto/x509/libcrypto-lib-v3_enum.o",
            "crypto/x509/libcrypto-lib-v3_extku.o",
            "crypto/x509/libcrypto-lib-v3_genn.o",
            "crypto/x509/libcrypto-lib-v3_ia5.o",
            "crypto/x509/libcrypto-lib-v3_info.o",
            "crypto/x509/libcrypto-lib-v3_int.o",
            "crypto/x509/libcrypto-lib-v3_ist.o",
            "crypto/x509/libcrypto-lib-v3_lib.o",
            "crypto/x509/libcrypto-lib-v3_ncons.o",
            "crypto/x509/libcrypto-lib-v3_pci.o",
            "crypto/x509/libcrypto-lib-v3_pcia.o",
            "crypto/x509/libcrypto-lib-v3_pcons.o",
            "crypto/x509/libcrypto-lib-v3_pku.o",
            "crypto/x509/libcrypto-lib-v3_pmaps.o",
            "crypto/x509/libcrypto-lib-v3_prn.o",
            "crypto/x509/libcrypto-lib-v3_purp.o",
            "crypto/x509/libcrypto-lib-v3_san.o",
            "crypto/x509/libcrypto-lib-v3_skid.o",
            "crypto/x509/libcrypto-lib-v3_sxnet.o",
            "crypto/x509/libcrypto-lib-v3_tlsf.o",
            "crypto/x509/libcrypto-lib-v3_utf8.o",
            "crypto/x509/libcrypto-lib-v3_utl.o",
            "crypto/x509/libcrypto-lib-v3err.o",
            "crypto/x509/libcrypto-lib-x509_att.o",
            "crypto/x509/libcrypto-lib-x509_cmp.o",
            "crypto/x509/libcrypto-lib-x509_d2.o",
            "crypto/x509/libcrypto-lib-x509_def.o",
            "crypto/x509/libcrypto-lib-x509_err.o",
            "crypto/x509/libcrypto-lib-x509_ext.o",
            "crypto/x509/libcrypto-lib-x509_lu.o",
            "crypto/x509/libcrypto-lib-x509_meth.o",
            "crypto/x509/libcrypto-lib-x509_obj.o",
            "crypto/x509/libcrypto-lib-x509_r2x.o",
            "crypto/x509/libcrypto-lib-x509_req.o",
            "crypto/x509/libcrypto-lib-x509_set.o",
            "crypto/x509/libcrypto-lib-x509_trust.o",
            "crypto/x509/libcrypto-lib-x509_txt.o",
            "crypto/x509/libcrypto-lib-x509_v3.o",
            "crypto/x509/libcrypto-lib-x509_vfy.o",
            "crypto/x509/libcrypto-lib-x509_vpm.o",
            "crypto/x509/libcrypto-lib-x509cset.o",
            "crypto/x509/libcrypto-lib-x509name.o",
            "crypto/x509/libcrypto-lib-x509rset.o",
            "crypto/x509/libcrypto-lib-x509spki.o",
            "crypto/x509/libcrypto-lib-x509type.o",
            "crypto/x509/libcrypto-lib-x_all.o",
            "crypto/x509/libcrypto-lib-x_attrib.o",
            "crypto/x509/libcrypto-lib-x_crl.o",
            "crypto/x509/libcrypto-lib-x_exten.o",
            "crypto/x509/libcrypto-lib-x_name.o",
            "crypto/x509/libcrypto-lib-x_pubkey.o",
            "crypto/x509/libcrypto-lib-x_req.o",
            "crypto/x509/libcrypto-lib-x_x509.o",
            "crypto/x509/libcrypto-lib-x_x509a.o",
            "engines/libcrypto-lib-e_capi.o",
            "engines/libcrypto-lib-e_padlock-x86_64.o",
            "engines/libcrypto-lib-e_padlock.o",
            "providers/libcrypto-lib-baseprov.o",
            "providers/libcrypto-lib-defltprov.o",
            "providers/libcrypto-lib-nullprov.o",
            "providers/libcrypto-lib-prov_running.o",
            "providers/libdefault.a"
        ],
        "libssl" => [
            "ssl/libssl-lib-bio_ssl.o",
            "ssl/libssl-lib-d1_lib.o",
            "ssl/libssl-lib-d1_msg.o",
            "ssl/libssl-lib-d1_srtp.o",
            "ssl/libssl-lib-methods.o",
            "ssl/libssl-lib-pqueue.o",
            "ssl/libssl-lib-s3_enc.o",
            "ssl/libssl-lib-s3_lib.o",
            "ssl/libssl-lib-s3_msg.o",
            "ssl/libssl-lib-ssl_asn1.o",
            "ssl/libssl-lib-ssl_cert.o",
            "ssl/libssl-lib-ssl_ciph.o",
            "ssl/libssl-lib-ssl_conf.o",
            "ssl/libssl-lib-ssl_err.o",
            "ssl/libssl-lib-ssl_err_legacy.o",
            "ssl/libssl-lib-ssl_init.o",
            "ssl/libssl-lib-ssl_lib.o",
            "ssl/libssl-lib-ssl_mcnf.o",
            "ssl/libssl-lib-ssl_quic.o",
            "ssl/libssl-lib-ssl_rsa.o",
            "ssl/libssl-lib-ssl_rsa_legacy.o",
            "ssl/libssl-lib-ssl_sess.o",
            "ssl/libssl-lib-ssl_stat.o",
            "ssl/libssl-lib-ssl_txt.o",
            "ssl/libssl-lib-ssl_utst.o",
            "ssl/libssl-lib-t1_enc.o",
            "ssl/libssl-lib-t1_lib.o",
            "ssl/libssl-lib-t1_trce.o",
            "ssl/libssl-lib-tls13_enc.o",
            "ssl/libssl-lib-tls_depr.o",
            "ssl/libssl-lib-tls_srp.o",
            "ssl/record/libssl-lib-dtls1_bitmap.o",
            "ssl/record/libssl-lib-rec_layer_d1.o",
            "ssl/record/libssl-lib-rec_layer_s3.o",
            "ssl/record/libssl-lib-ssl3_buffer.o",
            "ssl/record/libssl-lib-ssl3_record.o",
            "ssl/record/libssl-lib-ssl3_record_tls13.o",
            "ssl/statem/libssl-lib-extensions.o",
            "ssl/statem/libssl-lib-extensions_clnt.o",
            "ssl/statem/libssl-lib-extensions_cust.o",
            "ssl/statem/libssl-lib-extensions_srvr.o",
            "ssl/statem/libssl-lib-statem.o",
            "ssl/statem/libssl-lib-statem_clnt.o",
            "ssl/statem/libssl-lib-statem_dtls.o",
            "ssl/statem/libssl-lib-statem_lib.o",
            "ssl/statem/libssl-lib-statem_quic.o",
            "ssl/statem/libssl-lib-statem_srvr.o"
        ],
        "providers/common/der/libcommon-lib-der_digests_gen.o" => [
            "providers/common/der/der_digests_gen.c"
        ],
        "providers/common/der/libcommon-lib-der_dsa_gen.o" => [
            "providers/common/der/der_dsa_gen.c"
        ],
        "providers/common/der/libcommon-lib-der_dsa_key.o" => [
            "providers/common/der/der_dsa_key.c"
        ],
        "providers/common/der/libcommon-lib-der_dsa_sig.o" => [
            "providers/common/der/der_dsa_sig.c"
        ],
        "providers/common/der/libcommon-lib-der_ec_gen.o" => [
            "providers/common/der/der_ec_gen.c"
        ],
        "providers/common/der/libcommon-lib-der_ec_key.o" => [
            "providers/common/der/der_ec_key.c"
        ],
        "providers/common/der/libcommon-lib-der_ec_sig.o" => [
            "providers/common/der/der_ec_sig.c"
        ],
        "providers/common/der/libcommon-lib-der_ecx_gen.o" => [
            "providers/common/der/der_ecx_gen.c"
        ],
        "providers/common/der/libcommon-lib-der_ecx_key.o" => [
            "providers/common/der/der_ecx_key.c"
        ],
        "providers/common/der/libcommon-lib-der_rsa_gen.o" => [
            "providers/common/der/der_rsa_gen.c"
        ],
        "providers/common/der/libcommon-lib-der_rsa_key.o" => [
            "providers/common/der/der_rsa_key.c"
        ],
        "providers/common/der/libcommon-lib-der_wrap_gen.o" => [
            "providers/common/der/der_wrap_gen.c"
        ],
        "providers/common/der/libdefault-lib-der_rsa_sig.o" => [
            "providers/common/der/der_rsa_sig.c"
        ],
        "providers/common/der/libdefault-lib-der_sm2_gen.o" => [
            "providers/common/der/der_sm2_gen.c"
        ],
        "providers/common/der/libdefault-lib-der_sm2_key.o" => [
            "providers/common/der/der_sm2_key.c"
        ],
        "providers/common/der/libdefault-lib-der_sm2_sig.o" => [
            "providers/common/der/der_sm2_sig.c"
        ],
        "providers/common/der/libfips-lib-der_rsa_sig.o" => [
            "providers/common/der/der_rsa_sig.c"
        ],
        "providers/common/libcommon-lib-provider_ctx.o" => [
            "providers/common/provider_ctx.c"
        ],
        "providers/common/libcommon-lib-provider_err.o" => [
            "providers/common/provider_err.c"
        ],
        "providers/common/libdefault-lib-bio_prov.o" => [
            "providers/common/bio_prov.c"
        ],
        "providers/common/libdefault-lib-capabilities.o" => [
            "providers/common/capabilities.c"
        ],
        "providers/common/libdefault-lib-digest_to_nid.o" => [
            "providers/common/digest_to_nid.c"
        ],
        "providers/common/libdefault-lib-provider_seeding.o" => [
            "providers/common/provider_seeding.c"
        ],
        "providers/common/libdefault-lib-provider_util.o" => [
            "providers/common/provider_util.c"
        ],
        "providers/common/libdefault-lib-securitycheck.o" => [
            "providers/common/securitycheck.c"
        ],
        "providers/common/libdefault-lib-securitycheck_default.o" => [
            "providers/common/securitycheck_default.c"
        ],
        "providers/common/libfips-lib-bio_prov.o" => [
            "providers/common/bio_prov.c"
        ],
        "providers/common/libfips-lib-capabilities.o" => [
            "providers/common/capabilities.c"
        ],
        "providers/common/libfips-lib-digest_to_nid.o" => [
            "providers/common/digest_to_nid.c"
        ],
        "providers/common/libfips-lib-provider_seeding.o" => [
            "providers/common/provider_seeding.c"
        ],
        "providers/common/libfips-lib-provider_util.o" => [
            "providers/common/provider_util.c"
        ],
        "providers/common/libfips-lib-securitycheck.o" => [
            "providers/common/securitycheck.c"
        ],
        "providers/common/libfips-lib-securitycheck_fips.o" => [
            "providers/common/securitycheck_fips.c"
        ],
        "providers/evp_extra_test-bin-legacyprov.o" => [
            "providers/legacyprov.c"
        ],
        "providers/fips" => [
            "providers/fips.ld",
            "providers/fips/fips-dso-fips_entry.o"
        ],
        "providers/fips/fips-dso-fips_entry.o" => [
            "providers/fips/fips_entry.c"
        ],
        "providers/fips/libfips-lib-fipsprov.o" => [
            "providers/fips/fipsprov.c"
        ],
        "providers/fips/libfips-lib-self_test.o" => [
            "providers/fips/self_test.c"
        ],
        "providers/fips/libfips-lib-self_test_kats.o" => [
            "providers/fips/self_test_kats.c"
        ],
        "providers/implementations/asymciphers/libdefault-lib-rsa_enc.o" => [
            "providers/implementations/asymciphers/rsa_enc.c"
        ],
        "providers/implementations/asymciphers/libdefault-lib-sm2_enc.o" => [
            "providers/implementations/asymciphers/sm2_enc.c"
        ],
        "providers/implementations/asymciphers/libfips-lib-rsa_enc.o" => [
            "providers/implementations/asymciphers/rsa_enc.c"
        ],
        "providers/implementations/ciphers/libcommon-lib-ciphercommon.o" => [
            "providers/implementations/ciphers/ciphercommon.c"
        ],
        "providers/implementations/ciphers/libcommon-lib-ciphercommon_block.o" => [
            "providers/implementations/ciphers/ciphercommon_block.c"
        ],
        "providers/implementations/ciphers/libcommon-lib-ciphercommon_ccm.o" => [
            "providers/implementations/ciphers/ciphercommon_ccm.c"
        ],
        "providers/implementations/ciphers/libcommon-lib-ciphercommon_ccm_hw.o" => [
            "providers/implementations/ciphers/ciphercommon_ccm_hw.c"
        ],
        "providers/implementations/ciphers/libcommon-lib-ciphercommon_gcm.o" => [
            "providers/implementations/ciphers/ciphercommon_gcm.c"
        ],
        "providers/implementations/ciphers/libcommon-lib-ciphercommon_gcm_hw.o" => [
            "providers/implementations/ciphers/ciphercommon_gcm_hw.c"
        ],
        "providers/implementations/ciphers/libcommon-lib-ciphercommon_hw.o" => [
            "providers/implementations/ciphers/ciphercommon_hw.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aes.o" => [
            "providers/implementations/ciphers/cipher_aes.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aes_cbc_hmac_sha.o" => [
            "providers/implementations/ciphers/cipher_aes_cbc_hmac_sha.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aes_cbc_hmac_sha1_hw.o" => [
            "providers/implementations/ciphers/cipher_aes_cbc_hmac_sha1_hw.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aes_cbc_hmac_sha256_hw.o" => [
            "providers/implementations/ciphers/cipher_aes_cbc_hmac_sha256_hw.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aes_ccm.o" => [
            "providers/implementations/ciphers/cipher_aes_ccm.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aes_ccm_hw.o" => [
            "providers/implementations/ciphers/cipher_aes_ccm_hw.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aes_gcm.o" => [
            "providers/implementations/ciphers/cipher_aes_gcm.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aes_gcm_hw.o" => [
            "providers/implementations/ciphers/cipher_aes_gcm_hw.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aes_hw.o" => [
            "providers/implementations/ciphers/cipher_aes_hw.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aes_ocb.o" => [
            "providers/implementations/ciphers/cipher_aes_ocb.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aes_ocb_hw.o" => [
            "providers/implementations/ciphers/cipher_aes_ocb_hw.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aes_siv.o" => [
            "providers/implementations/ciphers/cipher_aes_siv.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aes_siv_hw.o" => [
            "providers/implementations/ciphers/cipher_aes_siv_hw.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aes_wrp.o" => [
            "providers/implementations/ciphers/cipher_aes_wrp.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aes_xts.o" => [
            "providers/implementations/ciphers/cipher_aes_xts.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aes_xts_fips.o" => [
            "providers/implementations/ciphers/cipher_aes_xts_fips.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aes_xts_hw.o" => [
            "providers/implementations/ciphers/cipher_aes_xts_hw.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aria.o" => [
            "providers/implementations/ciphers/cipher_aria.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aria_ccm.o" => [
            "providers/implementations/ciphers/cipher_aria_ccm.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aria_ccm_hw.o" => [
            "providers/implementations/ciphers/cipher_aria_ccm_hw.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aria_gcm.o" => [
            "providers/implementations/ciphers/cipher_aria_gcm.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aria_gcm_hw.o" => [
            "providers/implementations/ciphers/cipher_aria_gcm_hw.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_aria_hw.o" => [
            "providers/implementations/ciphers/cipher_aria_hw.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_camellia.o" => [
            "providers/implementations/ciphers/cipher_camellia.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_camellia_hw.o" => [
            "providers/implementations/ciphers/cipher_camellia_hw.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_chacha20.o" => [
            "providers/implementations/ciphers/cipher_chacha20.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_chacha20_hw.o" => [
            "providers/implementations/ciphers/cipher_chacha20_hw.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_chacha20_poly1305.o" => [
            "providers/implementations/ciphers/cipher_chacha20_poly1305.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_chacha20_poly1305_hw.o" => [
            "providers/implementations/ciphers/cipher_chacha20_poly1305_hw.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_cts.o" => [
            "providers/implementations/ciphers/cipher_cts.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_null.o" => [
            "providers/implementations/ciphers/cipher_null.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_sm4.o" => [
            "providers/implementations/ciphers/cipher_sm4.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_sm4_hw.o" => [
            "providers/implementations/ciphers/cipher_sm4_hw.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_tdes.o" => [
            "providers/implementations/ciphers/cipher_tdes.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_tdes_common.o" => [
            "providers/implementations/ciphers/cipher_tdes_common.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_tdes_default.o" => [
            "providers/implementations/ciphers/cipher_tdes_default.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_tdes_default_hw.o" => [
            "providers/implementations/ciphers/cipher_tdes_default_hw.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_tdes_hw.o" => [
            "providers/implementations/ciphers/cipher_tdes_hw.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_tdes_wrap.o" => [
            "providers/implementations/ciphers/cipher_tdes_wrap.c"
        ],
        "providers/implementations/ciphers/libdefault-lib-cipher_tdes_wrap_hw.o" => [
            "providers/implementations/ciphers/cipher_tdes_wrap_hw.c"
        ],
        "providers/implementations/ciphers/libfips-lib-cipher_aes.o" => [
            "providers/implementations/ciphers/cipher_aes.c"
        ],
        "providers/implementations/ciphers/libfips-lib-cipher_aes_cbc_hmac_sha.o" => [
            "providers/implementations/ciphers/cipher_aes_cbc_hmac_sha.c"
        ],
        "providers/implementations/ciphers/libfips-lib-cipher_aes_cbc_hmac_sha1_hw.o" => [
            "providers/implementations/ciphers/cipher_aes_cbc_hmac_sha1_hw.c"
        ],
        "providers/implementations/ciphers/libfips-lib-cipher_aes_cbc_hmac_sha256_hw.o" => [
            "providers/implementations/ciphers/cipher_aes_cbc_hmac_sha256_hw.c"
        ],
        "providers/implementations/ciphers/libfips-lib-cipher_aes_ccm.o" => [
            "providers/implementations/ciphers/cipher_aes_ccm.c"
        ],
        "providers/implementations/ciphers/libfips-lib-cipher_aes_ccm_hw.o" => [
            "providers/implementations/ciphers/cipher_aes_ccm_hw.c"
        ],
        "providers/implementations/ciphers/libfips-lib-cipher_aes_gcm.o" => [
            "providers/implementations/ciphers/cipher_aes_gcm.c"
        ],
        "providers/implementations/ciphers/libfips-lib-cipher_aes_gcm_hw.o" => [
            "providers/implementations/ciphers/cipher_aes_gcm_hw.c"
        ],
        "providers/implementations/ciphers/libfips-lib-cipher_aes_hw.o" => [
            "providers/implementations/ciphers/cipher_aes_hw.c"
        ],
        "providers/implementations/ciphers/libfips-lib-cipher_aes_ocb.o" => [
            "providers/implementations/ciphers/cipher_aes_ocb.c"
        ],
        "providers/implementations/ciphers/libfips-lib-cipher_aes_ocb_hw.o" => [
            "providers/implementations/ciphers/cipher_aes_ocb_hw.c"
        ],
        "providers/implementations/ciphers/libfips-lib-cipher_aes_wrp.o" => [
            "providers/implementations/ciphers/cipher_aes_wrp.c"
        ],
        "providers/implementations/ciphers/libfips-lib-cipher_aes_xts.o" => [
            "providers/implementations/ciphers/cipher_aes_xts.c"
        ],
        "providers/implementations/ciphers/libfips-lib-cipher_aes_xts_fips.o" => [
            "providers/implementations/ciphers/cipher_aes_xts_fips.c"
        ],
        "providers/implementations/ciphers/libfips-lib-cipher_aes_xts_hw.o" => [
            "providers/implementations/ciphers/cipher_aes_xts_hw.c"
        ],
        "providers/implementations/ciphers/libfips-lib-cipher_cts.o" => [
            "providers/implementations/ciphers/cipher_cts.c"
        ],
        "providers/implementations/ciphers/libfips-lib-cipher_tdes.o" => [
            "providers/implementations/ciphers/cipher_tdes.c"
        ],
        "providers/implementations/ciphers/libfips-lib-cipher_tdes_common.o" => [
            "providers/implementations/ciphers/cipher_tdes_common.c"
        ],
        "providers/implementations/ciphers/libfips-lib-cipher_tdes_hw.o" => [
            "providers/implementations/ciphers/cipher_tdes_hw.c"
        ],
        "providers/implementations/ciphers/liblegacy-lib-cipher_blowfish.o" => [
            "providers/implementations/ciphers/cipher_blowfish.c"
        ],
        "providers/implementations/ciphers/liblegacy-lib-cipher_blowfish_hw.o" => [
            "providers/implementations/ciphers/cipher_blowfish_hw.c"
        ],
        "providers/implementations/ciphers/liblegacy-lib-cipher_cast5.o" => [
            "providers/implementations/ciphers/cipher_cast5.c"
        ],
        "providers/implementations/ciphers/liblegacy-lib-cipher_cast5_hw.o" => [
            "providers/implementations/ciphers/cipher_cast5_hw.c"
        ],
        "providers/implementations/ciphers/liblegacy-lib-cipher_des.o" => [
            "providers/implementations/ciphers/cipher_des.c"
        ],
        "providers/implementations/ciphers/liblegacy-lib-cipher_des_hw.o" => [
            "providers/implementations/ciphers/cipher_des_hw.c"
        ],
        "providers/implementations/ciphers/liblegacy-lib-cipher_desx.o" => [
            "providers/implementations/ciphers/cipher_desx.c"
        ],
        "providers/implementations/ciphers/liblegacy-lib-cipher_desx_hw.o" => [
            "providers/implementations/ciphers/cipher_desx_hw.c"
        ],
        "providers/implementations/ciphers/liblegacy-lib-cipher_idea.o" => [
            "providers/implementations/ciphers/cipher_idea.c"
        ],
        "providers/implementations/ciphers/liblegacy-lib-cipher_idea_hw.o" => [
            "providers/implementations/ciphers/cipher_idea_hw.c"
        ],
        "providers/implementations/ciphers/liblegacy-lib-cipher_rc2.o" => [
            "providers/implementations/ciphers/cipher_rc2.c"
        ],
        "providers/implementations/ciphers/liblegacy-lib-cipher_rc2_hw.o" => [
            "providers/implementations/ciphers/cipher_rc2_hw.c"
        ],
        "providers/implementations/ciphers/liblegacy-lib-cipher_rc4.o" => [
            "providers/implementations/ciphers/cipher_rc4.c"
        ],
        "providers/implementations/ciphers/liblegacy-lib-cipher_rc4_hmac_md5.o" => [
            "providers/implementations/ciphers/cipher_rc4_hmac_md5.c"
        ],
        "providers/implementations/ciphers/liblegacy-lib-cipher_rc4_hmac_md5_hw.o" => [
            "providers/implementations/ciphers/cipher_rc4_hmac_md5_hw.c"
        ],
        "providers/implementations/ciphers/liblegacy-lib-cipher_rc4_hw.o" => [
            "providers/implementations/ciphers/cipher_rc4_hw.c"
        ],
        "providers/implementations/ciphers/liblegacy-lib-cipher_seed.o" => [
            "providers/implementations/ciphers/cipher_seed.c"
        ],
        "providers/implementations/ciphers/liblegacy-lib-cipher_seed_hw.o" => [
            "providers/implementations/ciphers/cipher_seed_hw.c"
        ],
        "providers/implementations/ciphers/liblegacy-lib-cipher_tdes_common.o" => [
            "providers/implementations/ciphers/cipher_tdes_common.c"
        ],
        "providers/implementations/digests/libcommon-lib-digestcommon.o" => [
            "providers/implementations/digests/digestcommon.c"
        ],
        "providers/implementations/digests/libdefault-lib-blake2_prov.o" => [
            "providers/implementations/digests/blake2_prov.c"
        ],
        "providers/implementations/digests/libdefault-lib-blake2b_prov.o" => [
            "providers/implementations/digests/blake2b_prov.c"
        ],
        "providers/implementations/digests/libdefault-lib-blake2s_prov.o" => [
            "providers/implementations/digests/blake2s_prov.c"
        ],
        "providers/implementations/digests/libdefault-lib-md5_prov.o" => [
            "providers/implementations/digests/md5_prov.c"
        ],
        "providers/implementations/digests/libdefault-lib-md5_sha1_prov.o" => [
            "providers/implementations/digests/md5_sha1_prov.c"
        ],
        "providers/implementations/digests/libdefault-lib-null_prov.o" => [
            "providers/implementations/digests/null_prov.c"
        ],
        "providers/implementations/digests/libdefault-lib-ripemd_prov.o" => [
            "providers/implementations/digests/ripemd_prov.c"
        ],
        "providers/implementations/digests/libdefault-lib-sha2_prov.o" => [
            "providers/implementations/digests/sha2_prov.c"
        ],
        "providers/implementations/digests/libdefault-lib-sha3_prov.o" => [
            "providers/implementations/digests/sha3_prov.c"
        ],
        "providers/implementations/digests/libdefault-lib-sm3_prov.o" => [
            "providers/implementations/digests/sm3_prov.c"
        ],
        "providers/implementations/digests/libfips-lib-sha2_prov.o" => [
            "providers/implementations/digests/sha2_prov.c"
        ],
        "providers/implementations/digests/libfips-lib-sha3_prov.o" => [
            "providers/implementations/digests/sha3_prov.c"
        ],
        "providers/implementations/digests/liblegacy-lib-md4_prov.o" => [
            "providers/implementations/digests/md4_prov.c"
        ],
        "providers/implementations/digests/liblegacy-lib-mdc2_prov.o" => [
            "providers/implementations/digests/mdc2_prov.c"
        ],
        "providers/implementations/digests/liblegacy-lib-ripemd_prov.o" => [
            "providers/implementations/digests/ripemd_prov.c"
        ],
        "providers/implementations/digests/liblegacy-lib-wp_prov.o" => [
            "providers/implementations/digests/wp_prov.c"
        ],
        "providers/implementations/encode_decode/libdefault-lib-decode_der2key.o" => [
            "providers/implementations/encode_decode/decode_der2key.c"
        ],
        "providers/implementations/encode_decode/libdefault-lib-decode_epki2pki.o" => [
            "providers/implementations/encode_decode/decode_epki2pki.c"
        ],
        "providers/implementations/encode_decode/libdefault-lib-decode_msblob2key.o" => [
            "providers/implementations/encode_decode/decode_msblob2key.c"
        ],
        "providers/implementations/encode_decode/libdefault-lib-decode_pem2der.o" => [
            "providers/implementations/encode_decode/decode_pem2der.c"
        ],
        "providers/implementations/encode_decode/libdefault-lib-decode_pvk2key.o" => [
            "providers/implementations/encode_decode/decode_pvk2key.c"
        ],
        "providers/implementations/encode_decode/libdefault-lib-decode_spki2typespki.o" => [
            "providers/implementations/encode_decode/decode_spki2typespki.c"
        ],
        "providers/implementations/encode_decode/libdefault-lib-encode_key2any.o" => [
            "providers/implementations/encode_decode/encode_key2any.c"
        ],
        "providers/implementations/encode_decode/libdefault-lib-encode_key2blob.o" => [
            "providers/implementations/encode_decode/encode_key2blob.c"
        ],
        "providers/implementations/encode_decode/libdefault-lib-encode_key2ms.o" => [
            "providers/implementations/encode_decode/encode_key2ms.c"
        ],
        "providers/implementations/encode_decode/libdefault-lib-encode_key2text.o" => [
            "providers/implementations/encode_decode/encode_key2text.c"
        ],
        "providers/implementations/encode_decode/libdefault-lib-endecoder_common.o" => [
            "providers/implementations/encode_decode/endecoder_common.c"
        ],
        "providers/implementations/exchange/libdefault-lib-dh_exch.o" => [
            "providers/implementations/exchange/dh_exch.c"
        ],
        "providers/implementations/exchange/libdefault-lib-ecdh_exch.o" => [
            "providers/implementations/exchange/ecdh_exch.c"
        ],
        "providers/implementations/exchange/libdefault-lib-ecx_exch.o" => [
            "providers/implementations/exchange/ecx_exch.c"
        ],
        "providers/implementations/exchange/libdefault-lib-kdf_exch.o" => [
            "providers/implementations/exchange/kdf_exch.c"
        ],
        "providers/implementations/exchange/libfips-lib-dh_exch.o" => [
            "providers/implementations/exchange/dh_exch.c"
        ],
        "providers/implementations/exchange/libfips-lib-ecdh_exch.o" => [
            "providers/implementations/exchange/ecdh_exch.c"
        ],
        "providers/implementations/exchange/libfips-lib-ecx_exch.o" => [
            "providers/implementations/exchange/ecx_exch.c"
        ],
        "providers/implementations/exchange/libfips-lib-kdf_exch.o" => [
            "providers/implementations/exchange/kdf_exch.c"
        ],
        "providers/implementations/kdfs/libdefault-lib-hkdf.o" => [
            "providers/implementations/kdfs/hkdf.c"
        ],
        "providers/implementations/kdfs/libdefault-lib-kbkdf.o" => [
            "providers/implementations/kdfs/kbkdf.c"
        ],
        "providers/implementations/kdfs/libdefault-lib-krb5kdf.o" => [
            "providers/implementations/kdfs/krb5kdf.c"
        ],
        "providers/implementations/kdfs/libdefault-lib-pbkdf2.o" => [
            "providers/implementations/kdfs/pbkdf2.c"
        ],
        "providers/implementations/kdfs/libdefault-lib-pbkdf2_fips.o" => [
            "providers/implementations/kdfs/pbkdf2_fips.c"
        ],
        "providers/implementations/kdfs/libdefault-lib-pkcs12kdf.o" => [
            "providers/implementations/kdfs/pkcs12kdf.c"
        ],
        "providers/implementations/kdfs/libdefault-lib-scrypt.o" => [
            "providers/implementations/kdfs/scrypt.c"
        ],
        "providers/implementations/kdfs/libdefault-lib-sshkdf.o" => [
            "providers/implementations/kdfs/sshkdf.c"
        ],
        "providers/implementations/kdfs/libdefault-lib-sskdf.o" => [
            "providers/implementations/kdfs/sskdf.c"
        ],
        "providers/implementations/kdfs/libdefault-lib-tls1_prf.o" => [
            "providers/implementations/kdfs/tls1_prf.c"
        ],
        "providers/implementations/kdfs/libdefault-lib-x942kdf.o" => [
            "providers/implementations/kdfs/x942kdf.c"
        ],
        "providers/implementations/kdfs/libfips-lib-hkdf.o" => [
            "providers/implementations/kdfs/hkdf.c"
        ],
        "providers/implementations/kdfs/libfips-lib-kbkdf.o" => [
            "providers/implementations/kdfs/kbkdf.c"
        ],
        "providers/implementations/kdfs/libfips-lib-pbkdf2.o" => [
            "providers/implementations/kdfs/pbkdf2.c"
        ],
        "providers/implementations/kdfs/libfips-lib-pbkdf2_fips.o" => [
            "providers/implementations/kdfs/pbkdf2_fips.c"
        ],
        "providers/implementations/kdfs/libfips-lib-sshkdf.o" => [
            "providers/implementations/kdfs/sshkdf.c"
        ],
        "providers/implementations/kdfs/libfips-lib-sskdf.o" => [
            "providers/implementations/kdfs/sskdf.c"
        ],
        "providers/implementations/kdfs/libfips-lib-tls1_prf.o" => [
            "providers/implementations/kdfs/tls1_prf.c"
        ],
        "providers/implementations/kdfs/libfips-lib-x942kdf.o" => [
            "providers/implementations/kdfs/x942kdf.c"
        ],
        "providers/implementations/kdfs/liblegacy-lib-pbkdf1.o" => [
            "providers/implementations/kdfs/pbkdf1.c"
        ],
        "providers/implementations/kem/libdefault-lib-rsa_kem.o" => [
            "providers/implementations/kem/rsa_kem.c"
        ],
        "providers/implementations/kem/libfips-lib-rsa_kem.o" => [
            "providers/implementations/kem/rsa_kem.c"
        ],
        "providers/implementations/keymgmt/libdefault-lib-dh_kmgmt.o" => [
            "providers/implementations/keymgmt/dh_kmgmt.c"
        ],
        "providers/implementations/keymgmt/libdefault-lib-dsa_kmgmt.o" => [
            "providers/implementations/keymgmt/dsa_kmgmt.c"
        ],
        "providers/implementations/keymgmt/libdefault-lib-ec_kmgmt.o" => [
            "providers/implementations/keymgmt/ec_kmgmt.c"
        ],
        "providers/implementations/keymgmt/libdefault-lib-ecx_kmgmt.o" => [
            "providers/implementations/keymgmt/ecx_kmgmt.c"
        ],
        "providers/implementations/keymgmt/libdefault-lib-kdf_legacy_kmgmt.o" => [
            "providers/implementations/keymgmt/kdf_legacy_kmgmt.c"
        ],
        "providers/implementations/keymgmt/libdefault-lib-mac_legacy_kmgmt.o" => [
            "providers/implementations/keymgmt/mac_legacy_kmgmt.c"
        ],
        "providers/implementations/keymgmt/libdefault-lib-rsa_kmgmt.o" => [
            "providers/implementations/keymgmt/rsa_kmgmt.c"
        ],
        "providers/implementations/keymgmt/libfips-lib-dh_kmgmt.o" => [
            "providers/implementations/keymgmt/dh_kmgmt.c"
        ],
        "providers/implementations/keymgmt/libfips-lib-dsa_kmgmt.o" => [
            "providers/implementations/keymgmt/dsa_kmgmt.c"
        ],
        "providers/implementations/keymgmt/libfips-lib-ec_kmgmt.o" => [
            "providers/implementations/keymgmt/ec_kmgmt.c"
        ],
        "providers/implementations/keymgmt/libfips-lib-ecx_kmgmt.o" => [
            "providers/implementations/keymgmt/ecx_kmgmt.c"
        ],
        "providers/implementations/keymgmt/libfips-lib-kdf_legacy_kmgmt.o" => [
            "providers/implementations/keymgmt/kdf_legacy_kmgmt.c"
        ],
        "providers/implementations/keymgmt/libfips-lib-mac_legacy_kmgmt.o" => [
            "providers/implementations/keymgmt/mac_legacy_kmgmt.c"
        ],
        "providers/implementations/keymgmt/libfips-lib-rsa_kmgmt.o" => [
            "providers/implementations/keymgmt/rsa_kmgmt.c"
        ],
        "providers/implementations/macs/libdefault-lib-blake2b_mac.o" => [
            "providers/implementations/macs/blake2b_mac.c"
        ],
        "providers/implementations/macs/libdefault-lib-blake2s_mac.o" => [
            "providers/implementations/macs/blake2s_mac.c"
        ],
        "providers/implementations/macs/libdefault-lib-cmac_prov.o" => [
            "providers/implementations/macs/cmac_prov.c"
        ],
        "providers/implementations/macs/libdefault-lib-gmac_prov.o" => [
            "providers/implementations/macs/gmac_prov.c"
        ],
        "providers/implementations/macs/libdefault-lib-hmac_prov.o" => [
            "providers/implementations/macs/hmac_prov.c"
        ],
        "providers/implementations/macs/libdefault-lib-kmac_prov.o" => [
            "providers/implementations/macs/kmac_prov.c"
        ],
        "providers/implementations/macs/libdefault-lib-poly1305_prov.o" => [
            "providers/implementations/macs/poly1305_prov.c"
        ],
        "providers/implementations/macs/libdefault-lib-siphash_prov.o" => [
            "providers/implementations/macs/siphash_prov.c"
        ],
        "providers/implementations/macs/libfips-lib-cmac_prov.o" => [
            "providers/implementations/macs/cmac_prov.c"
        ],
        "providers/implementations/macs/libfips-lib-gmac_prov.o" => [
            "providers/implementations/macs/gmac_prov.c"
        ],
        "providers/implementations/macs/libfips-lib-hmac_prov.o" => [
            "providers/implementations/macs/hmac_prov.c"
        ],
        "providers/implementations/macs/libfips-lib-kmac_prov.o" => [
            "providers/implementations/macs/kmac_prov.c"
        ],
        "providers/implementations/rands/libdefault-lib-crngt.o" => [
            "providers/implementations/rands/crngt.c"
        ],
        "providers/implementations/rands/libdefault-lib-drbg.o" => [
            "providers/implementations/rands/drbg.c"
        ],
        "providers/implementations/rands/libdefault-lib-drbg_ctr.o" => [
            "providers/implementations/rands/drbg_ctr.c"
        ],
        "providers/implementations/rands/libdefault-lib-drbg_hash.o" => [
            "providers/implementations/rands/drbg_hash.c"
        ],
        "providers/implementations/rands/libdefault-lib-drbg_hmac.o" => [
            "providers/implementations/rands/drbg_hmac.c"
        ],
        "providers/implementations/rands/libdefault-lib-seed_src.o" => [
            "providers/implementations/rands/seed_src.c"
        ],
        "providers/implementations/rands/libdefault-lib-test_rng.o" => [
            "providers/implementations/rands/test_rng.c"
        ],
        "providers/implementations/rands/libfips-lib-crngt.o" => [
            "providers/implementations/rands/crngt.c"
        ],
        "providers/implementations/rands/libfips-lib-drbg.o" => [
            "providers/implementations/rands/drbg.c"
        ],
        "providers/implementations/rands/libfips-lib-drbg_ctr.o" => [
            "providers/implementations/rands/drbg_ctr.c"
        ],
        "providers/implementations/rands/libfips-lib-drbg_hash.o" => [
            "providers/implementations/rands/drbg_hash.c"
        ],
        "providers/implementations/rands/libfips-lib-drbg_hmac.o" => [
            "providers/implementations/rands/drbg_hmac.c"
        ],
        "providers/implementations/rands/libfips-lib-test_rng.o" => [
            "providers/implementations/rands/test_rng.c"
        ],
        "providers/implementations/rands/seeding/libdefault-lib-rand_cpu_x86.o" => [
            "providers/implementations/rands/seeding/rand_cpu_x86.c"
        ],
        "providers/implementations/rands/seeding/libdefault-lib-rand_tsc.o" => [
            "providers/implementations/rands/seeding/rand_tsc.c"
        ],
        "providers/implementations/rands/seeding/libdefault-lib-rand_unix.o" => [
            "providers/implementations/rands/seeding/rand_unix.c"
        ],
        "providers/implementations/rands/seeding/libdefault-lib-rand_win.o" => [
            "providers/implementations/rands/seeding/rand_win.c"
        ],
        "providers/implementations/signature/libdefault-lib-dsa_sig.o" => [
            "providers/implementations/signature/dsa_sig.c"
        ],
        "providers/implementations/signature/libdefault-lib-ecdsa_sig.o" => [
            "providers/implementations/signature/ecdsa_sig.c"
        ],
        "providers/implementations/signature/libdefault-lib-eddsa_sig.o" => [
            "providers/implementations/signature/eddsa_sig.c"
        ],
        "providers/implementations/signature/libdefault-lib-mac_legacy_sig.o" => [
            "providers/implementations/signature/mac_legacy_sig.c"
        ],
        "providers/implementations/signature/libdefault-lib-rsa_sig.o" => [
            "providers/implementations/signature/rsa_sig.c"
        ],
        "providers/implementations/signature/libdefault-lib-sm2_sig.o" => [
            "providers/implementations/signature/sm2_sig.c"
        ],
        "providers/implementations/signature/libfips-lib-dsa_sig.o" => [
            "providers/implementations/signature/dsa_sig.c"
        ],
        "providers/implementations/signature/libfips-lib-ecdsa_sig.o" => [
            "providers/implementations/signature/ecdsa_sig.c"
        ],
        "providers/implementations/signature/libfips-lib-eddsa_sig.o" => [
            "providers/implementations/signature/eddsa_sig.c"
        ],
        "providers/implementations/signature/libfips-lib-mac_legacy_sig.o" => [
            "providers/implementations/signature/mac_legacy_sig.c"
        ],
        "providers/implementations/signature/libfips-lib-rsa_sig.o" => [
            "providers/implementations/signature/rsa_sig.c"
        ],
        "providers/implementations/storemgmt/libdefault-lib-file_store.o" => [
            "providers/implementations/storemgmt/file_store.c"
        ],
        "providers/implementations/storemgmt/libdefault-lib-file_store_any2obj.o" => [
            "providers/implementations/storemgmt/file_store_any2obj.c"
        ],
        "providers/legacy" => [
            "providers/legacy-dso-legacyprov.o",
            "providers/legacy.ld"
        ],
        "providers/legacy-dso-legacyprov.o" => [
            "providers/legacyprov.c"
        ],
        "providers/libcommon.a" => [
            "providers/common/der/libcommon-lib-der_digests_gen.o",
            "providers/common/der/libcommon-lib-der_dsa_gen.o",
            "providers/common/der/libcommon-lib-der_dsa_key.o",
            "providers/common/der/libcommon-lib-der_dsa_sig.o",
            "providers/common/der/libcommon-lib-der_ec_gen.o",
            "providers/common/der/libcommon-lib-der_ec_key.o",
            "providers/common/der/libcommon-lib-der_ec_sig.o",
            "providers/common/der/libcommon-lib-der_ecx_gen.o",
            "providers/common/der/libcommon-lib-der_ecx_key.o",
            "providers/common/der/libcommon-lib-der_rsa_gen.o",
            "providers/common/der/libcommon-lib-der_rsa_key.o",
            "providers/common/der/libcommon-lib-der_wrap_gen.o",
            "providers/common/libcommon-lib-provider_ctx.o",
            "providers/common/libcommon-lib-provider_err.o",
            "providers/implementations/ciphers/libcommon-lib-ciphercommon.o",
            "providers/implementations/ciphers/libcommon-lib-ciphercommon_block.o",
            "providers/implementations/ciphers/libcommon-lib-ciphercommon_ccm.o",
            "providers/implementations/ciphers/libcommon-lib-ciphercommon_ccm_hw.o",
            "providers/implementations/ciphers/libcommon-lib-ciphercommon_gcm.o",
            "providers/implementations/ciphers/libcommon-lib-ciphercommon_gcm_hw.o",
            "providers/implementations/ciphers/libcommon-lib-ciphercommon_hw.o",
            "providers/implementations/digests/libcommon-lib-digestcommon.o",
            "ssl/record/libcommon-lib-tls_pad.o"
        ],
        "providers/libcrypto-lib-baseprov.o" => [
            "providers/baseprov.c"
        ],
        "providers/libcrypto-lib-defltprov.o" => [
            "providers/defltprov.c"
        ],
        "providers/libcrypto-lib-nullprov.o" => [
            "providers/nullprov.c"
        ],
        "providers/libcrypto-lib-prov_running.o" => [
            "providers/prov_running.c"
        ],
        "providers/libdefault.a" => [
            "providers/common/der/libdefault-lib-der_rsa_sig.o",
            "providers/common/der/libdefault-lib-der_sm2_gen.o",
            "providers/common/der/libdefault-lib-der_sm2_key.o",
            "providers/common/der/libdefault-lib-der_sm2_sig.o",
            "providers/common/libdefault-lib-bio_prov.o",
            "providers/common/libdefault-lib-capabilities.o",
            "providers/common/libdefault-lib-digest_to_nid.o",
            "providers/common/libdefault-lib-provider_seeding.o",
            "providers/common/libdefault-lib-provider_util.o",
            "providers/common/libdefault-lib-securitycheck.o",
            "providers/common/libdefault-lib-securitycheck_default.o",
            "providers/implementations/asymciphers/libdefault-lib-rsa_enc.o",
            "providers/implementations/asymciphers/libdefault-lib-sm2_enc.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aes.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aes_cbc_hmac_sha.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aes_cbc_hmac_sha1_hw.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aes_cbc_hmac_sha256_hw.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aes_ccm.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aes_ccm_hw.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aes_gcm.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aes_gcm_hw.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aes_hw.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aes_ocb.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aes_ocb_hw.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aes_siv.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aes_siv_hw.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aes_wrp.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aes_xts.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aes_xts_fips.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aes_xts_hw.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aria.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aria_ccm.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aria_ccm_hw.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aria_gcm.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aria_gcm_hw.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_aria_hw.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_camellia.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_camellia_hw.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_chacha20.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_chacha20_hw.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_chacha20_poly1305.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_chacha20_poly1305_hw.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_cts.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_null.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_sm4.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_sm4_hw.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_tdes.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_tdes_common.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_tdes_default.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_tdes_default_hw.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_tdes_hw.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_tdes_wrap.o",
            "providers/implementations/ciphers/libdefault-lib-cipher_tdes_wrap_hw.o",
            "providers/implementations/digests/libdefault-lib-blake2_prov.o",
            "providers/implementations/digests/libdefault-lib-blake2b_prov.o",
            "providers/implementations/digests/libdefault-lib-blake2s_prov.o",
            "providers/implementations/digests/libdefault-lib-md5_prov.o",
            "providers/implementations/digests/libdefault-lib-md5_sha1_prov.o",
            "providers/implementations/digests/libdefault-lib-null_prov.o",
            "providers/implementations/digests/libdefault-lib-ripemd_prov.o",
            "providers/implementations/digests/libdefault-lib-sha2_prov.o",
            "providers/implementations/digests/libdefault-lib-sha3_prov.o",
            "providers/implementations/digests/libdefault-lib-sm3_prov.o",
            "providers/implementations/encode_decode/libdefault-lib-decode_der2key.o",
            "providers/implementations/encode_decode/libdefault-lib-decode_epki2pki.o",
            "providers/implementations/encode_decode/libdefault-lib-decode_msblob2key.o",
            "providers/implementations/encode_decode/libdefault-lib-decode_pem2der.o",
            "providers/implementations/encode_decode/libdefault-lib-decode_pvk2key.o",
            "providers/implementations/encode_decode/libdefault-lib-decode_spki2typespki.o",
            "providers/implementations/encode_decode/libdefault-lib-encode_key2any.o",
            "providers/implementations/encode_decode/libdefault-lib-encode_key2blob.o",
            "providers/implementations/encode_decode/libdefault-lib-encode_key2ms.o",
            "providers/implementations/encode_decode/libdefault-lib-encode_key2text.o",
            "providers/implementations/encode_decode/libdefault-lib-endecoder_common.o",
            "providers/implementations/exchange/libdefault-lib-dh_exch.o",
            "providers/implementations/exchange/libdefault-lib-ecdh_exch.o",
            "providers/implementations/exchange/libdefault-lib-ecx_exch.o",
            "providers/implementations/exchange/libdefault-lib-kdf_exch.o",
            "providers/implementations/kdfs/libdefault-lib-hkdf.o",
            "providers/implementations/kdfs/libdefault-lib-kbkdf.o",
            "providers/implementations/kdfs/libdefault-lib-krb5kdf.o",
            "providers/implementations/kdfs/libdefault-lib-pbkdf2.o",
            "providers/implementations/kdfs/libdefault-lib-pbkdf2_fips.o",
            "providers/implementations/kdfs/libdefault-lib-pkcs12kdf.o",
            "providers/implementations/kdfs/libdefault-lib-scrypt.o",
            "providers/implementations/kdfs/libdefault-lib-sshkdf.o",
            "providers/implementations/kdfs/libdefault-lib-sskdf.o",
            "providers/implementations/kdfs/libdefault-lib-tls1_prf.o",
            "providers/implementations/kdfs/libdefault-lib-x942kdf.o",
            "providers/implementations/kem/libdefault-lib-rsa_kem.o",
            "providers/implementations/keymgmt/libdefault-lib-dh_kmgmt.o",
            "providers/implementations/keymgmt/libdefault-lib-dsa_kmgmt.o",
            "providers/implementations/keymgmt/libdefault-lib-ec_kmgmt.o",
            "providers/implementations/keymgmt/libdefault-lib-ecx_kmgmt.o",
            "providers/implementations/keymgmt/libdefault-lib-kdf_legacy_kmgmt.o",
            "providers/implementations/keymgmt/libdefault-lib-mac_legacy_kmgmt.o",
            "providers/implementations/keymgmt/libdefault-lib-rsa_kmgmt.o",
            "providers/implementations/macs/libdefault-lib-blake2b_mac.o",
            "providers/implementations/macs/libdefault-lib-blake2s_mac.o",
            "providers/implementations/macs/libdefault-lib-cmac_prov.o",
            "providers/implementations/macs/libdefault-lib-gmac_prov.o",
            "providers/implementations/macs/libdefault-lib-hmac_prov.o",
            "providers/implementations/macs/libdefault-lib-kmac_prov.o",
            "providers/implementations/macs/libdefault-lib-poly1305_prov.o",
            "providers/implementations/macs/libdefault-lib-siphash_prov.o",
            "providers/implementations/rands/libdefault-lib-crngt.o",
            "providers/implementations/rands/libdefault-lib-drbg.o",
            "providers/implementations/rands/libdefault-lib-drbg_ctr.o",
            "providers/implementations/rands/libdefault-lib-drbg_hash.o",
            "providers/implementations/rands/libdefault-lib-drbg_hmac.o",
            "providers/implementations/rands/libdefault-lib-seed_src.o",
            "providers/implementations/rands/libdefault-lib-test_rng.o",
            "providers/implementations/rands/seeding/libdefault-lib-rand_cpu_x86.o",
            "providers/implementations/rands/seeding/libdefault-lib-rand_tsc.o",
            "providers/implementations/rands/seeding/libdefault-lib-rand_unix.o",
            "providers/implementations/rands/seeding/libdefault-lib-rand_win.o",
            "providers/implementations/signature/libdefault-lib-dsa_sig.o",
            "providers/implementations/signature/libdefault-lib-ecdsa_sig.o",
            "providers/implementations/signature/libdefault-lib-eddsa_sig.o",
            "providers/implementations/signature/libdefault-lib-mac_legacy_sig.o",
            "providers/implementations/signature/libdefault-lib-rsa_sig.o",
            "providers/implementations/signature/libdefault-lib-sm2_sig.o",
            "providers/implementations/storemgmt/libdefault-lib-file_store.o",
            "providers/implementations/storemgmt/libdefault-lib-file_store_any2obj.o",
            "ssl/libdefault-lib-s3_cbc.o"
        ],
        "providers/libfips.a" => [
            "crypto/aes/libfips-lib-aes-x86_64.o",
            "crypto/aes/libfips-lib-aes_ecb.o",
            "crypto/aes/libfips-lib-aes_misc.o",
            "crypto/aes/libfips-lib-aesni-mb-x86_64.o",
            "crypto/aes/libfips-lib-aesni-sha1-x86_64.o",
            "crypto/aes/libfips-lib-aesni-sha256-x86_64.o",
            "crypto/aes/libfips-lib-aesni-x86_64.o",
            "crypto/aes/libfips-lib-bsaes-x86_64.o",
            "crypto/aes/libfips-lib-vpaes-x86_64.o",
            "crypto/bn/asm/libfips-lib-x86_64-gcc.o",
            "crypto/bn/libfips-lib-bn_add.o",
            "crypto/bn/libfips-lib-bn_blind.o",
            "crypto/bn/libfips-lib-bn_const.o",
            "crypto/bn/libfips-lib-bn_conv.o",
            "crypto/bn/libfips-lib-bn_ctx.o",
            "crypto/bn/libfips-lib-bn_dh.o",
            "crypto/bn/libfips-lib-bn_div.o",
            "crypto/bn/libfips-lib-bn_exp.o",
            "crypto/bn/libfips-lib-bn_exp2.o",
            "crypto/bn/libfips-lib-bn_gcd.o",
            "crypto/bn/libfips-lib-bn_gf2m.o",
            "crypto/bn/libfips-lib-bn_intern.o",
            "crypto/bn/libfips-lib-bn_kron.o",
            "crypto/bn/libfips-lib-bn_lib.o",
            "crypto/bn/libfips-lib-bn_mod.o",
            "crypto/bn/libfips-lib-bn_mont.o",
            "crypto/bn/libfips-lib-bn_mpi.o",
            "crypto/bn/libfips-lib-bn_mul.o",
            "crypto/bn/libfips-lib-bn_nist.o",
            "crypto/bn/libfips-lib-bn_prime.o",
            "crypto/bn/libfips-lib-bn_rand.o",
            "crypto/bn/libfips-lib-bn_recp.o",
            "crypto/bn/libfips-lib-bn_rsa_fips186_4.o",
            "crypto/bn/libfips-lib-bn_shift.o",
            "crypto/bn/libfips-lib-bn_sqr.o",
            "crypto/bn/libfips-lib-bn_sqrt.o",
            "crypto/bn/libfips-lib-bn_word.o",
            "crypto/bn/libfips-lib-rsaz-avx2.o",
            "crypto/bn/libfips-lib-rsaz-avx512.o",
            "crypto/bn/libfips-lib-rsaz-x86_64.o",
            "crypto/bn/libfips-lib-rsaz_exp.o",
            "crypto/bn/libfips-lib-rsaz_exp_x2.o",
            "crypto/bn/libfips-lib-x86_64-gf2m.o",
            "crypto/bn/libfips-lib-x86_64-mont.o",
            "crypto/bn/libfips-lib-x86_64-mont5.o",
            "crypto/buffer/libfips-lib-buffer.o",
            "crypto/cmac/libfips-lib-cmac.o",
            "crypto/des/libfips-lib-des_enc.o",
            "crypto/des/libfips-lib-ecb3_enc.o",
            "crypto/des/libfips-lib-fcrypt_b.o",
            "crypto/des/libfips-lib-set_key.o",
            "crypto/dh/libfips-lib-dh_backend.o",
            "crypto/dh/libfips-lib-dh_check.o",
            "crypto/dh/libfips-lib-dh_gen.o",
            "crypto/dh/libfips-lib-dh_group_params.o",
            "crypto/dh/libfips-lib-dh_kdf.o",
            "crypto/dh/libfips-lib-dh_key.o",
            "crypto/dh/libfips-lib-dh_lib.o",
            "crypto/dsa/libfips-lib-dsa_backend.o",
            "crypto/dsa/libfips-lib-dsa_check.o",
            "crypto/dsa/libfips-lib-dsa_gen.o",
            "crypto/dsa/libfips-lib-dsa_key.o",
            "crypto/dsa/libfips-lib-dsa_lib.o",
            "crypto/dsa/libfips-lib-dsa_ossl.o",
            "crypto/dsa/libfips-lib-dsa_sign.o",
            "crypto/dsa/libfips-lib-dsa_vrf.o",
            "crypto/ec/curve448/arch_32/libfips-lib-f_impl32.o",
            "crypto/ec/curve448/arch_64/libfips-lib-f_impl64.o",
            "crypto/ec/curve448/libfips-lib-curve448.o",
            "crypto/ec/curve448/libfips-lib-curve448_tables.o",
            "crypto/ec/curve448/libfips-lib-eddsa.o",
            "crypto/ec/curve448/libfips-lib-f_generic.o",
            "crypto/ec/curve448/libfips-lib-scalar.o",
            "crypto/ec/libfips-lib-curve25519.o",
            "crypto/ec/libfips-lib-ec2_oct.o",
            "crypto/ec/libfips-lib-ec2_smpl.o",
            "crypto/ec/libfips-lib-ec_asn1.o",
            "crypto/ec/libfips-lib-ec_backend.o",
            "crypto/ec/libfips-lib-ec_check.o",
            "crypto/ec/libfips-lib-ec_curve.o",
            "crypto/ec/libfips-lib-ec_cvt.o",
            "crypto/ec/libfips-lib-ec_key.o",
            "crypto/ec/libfips-lib-ec_kmeth.o",
            "crypto/ec/libfips-lib-ec_lib.o",
            "crypto/ec/libfips-lib-ec_mult.o",
            "crypto/ec/libfips-lib-ec_oct.o",
            "crypto/ec/libfips-lib-ecdh_kdf.o",
            "crypto/ec/libfips-lib-ecdh_ossl.o",
            "crypto/ec/libfips-lib-ecdsa_ossl.o",
            "crypto/ec/libfips-lib-ecdsa_sign.o",
            "crypto/ec/libfips-lib-ecdsa_vrf.o",
            "crypto/ec/libfips-lib-ecp_mont.o",
            "crypto/ec/libfips-lib-ecp_nist.o",
            "crypto/ec/libfips-lib-ecp_nistz256-x86_64.o",
            "crypto/ec/libfips-lib-ecp_nistz256.o",
            "crypto/ec/libfips-lib-ecp_oct.o",
            "crypto/ec/libfips-lib-ecp_smpl.o",
            "crypto/ec/libfips-lib-ecx_backend.o",
            "crypto/ec/libfips-lib-ecx_key.o",
            "crypto/ec/libfips-lib-x25519-x86_64.o",
            "crypto/evp/libfips-lib-asymcipher.o",
            "crypto/evp/libfips-lib-dh_support.o",
            "crypto/evp/libfips-lib-digest.o",
            "crypto/evp/libfips-lib-ec_support.o",
            "crypto/evp/libfips-lib-evp_enc.o",
            "crypto/evp/libfips-lib-evp_fetch.o",
            "crypto/evp/libfips-lib-evp_lib.o",
            "crypto/evp/libfips-lib-evp_rand.o",
            "crypto/evp/libfips-lib-evp_utils.o",
            "crypto/evp/libfips-lib-exchange.o",
            "crypto/evp/libfips-lib-kdf_lib.o",
            "crypto/evp/libfips-lib-kdf_meth.o",
            "crypto/evp/libfips-lib-kem.o",
            "crypto/evp/libfips-lib-keymgmt_lib.o",
            "crypto/evp/libfips-lib-keymgmt_meth.o",
            "crypto/evp/libfips-lib-m_sigver.o",
            "crypto/evp/libfips-lib-mac_lib.o",
            "crypto/evp/libfips-lib-mac_meth.o",
            "crypto/evp/libfips-lib-p_lib.o",
            "crypto/evp/libfips-lib-pmeth_check.o",
            "crypto/evp/libfips-lib-pmeth_gn.o",
            "crypto/evp/libfips-lib-pmeth_lib.o",
            "crypto/evp/libfips-lib-signature.o",
            "crypto/ffc/libfips-lib-ffc_backend.o",
            "crypto/ffc/libfips-lib-ffc_dh.o",
            "crypto/ffc/libfips-lib-ffc_key_generate.o",
            "crypto/ffc/libfips-lib-ffc_key_validate.o",
            "crypto/ffc/libfips-lib-ffc_params.o",
            "crypto/ffc/libfips-lib-ffc_params_generate.o",
            "crypto/ffc/libfips-lib-ffc_params_validate.o",
            "crypto/hmac/libfips-lib-hmac.o",
            "crypto/lhash/libfips-lib-lhash.o",
            "crypto/libfips-lib-asn1_dsa.o",
            "crypto/libfips-lib-bsearch.o",
            "crypto/libfips-lib-context.o",
            "crypto/libfips-lib-core_algorithm.o",
            "crypto/libfips-lib-core_fetch.o",
            "crypto/libfips-lib-core_namemap.o",
            "crypto/libfips-lib-cpuid.o",
            "crypto/libfips-lib-cryptlib.o",
            "crypto/libfips-lib-ctype.o",
            "crypto/libfips-lib-der_writer.o",
            "crypto/libfips-lib-ex_data.o",
            "crypto/libfips-lib-initthread.o",
            "crypto/libfips-lib-o_str.o",
            "crypto/libfips-lib-packet.o",
            "crypto/libfips-lib-param_build.o",
            "crypto/libfips-lib-param_build_set.o",
            "crypto/libfips-lib-params.o",
            "crypto/libfips-lib-params_dup.o",
            "crypto/libfips-lib-params_from_text.o",
            "crypto/libfips-lib-provider_core.o",
            "crypto/libfips-lib-provider_predefined.o",
            "crypto/libfips-lib-self_test_core.o",
            "crypto/libfips-lib-sparse_array.o",
            "crypto/libfips-lib-threads_lib.o",
            "crypto/libfips-lib-threads_none.o",
            "crypto/libfips-lib-threads_pthread.o",
            "crypto/libfips-lib-threads_win.o",
            "crypto/libfips-lib-x86_64cpuid.o",
            "crypto/modes/libfips-lib-aesni-gcm-x86_64.o",
            "crypto/modes/libfips-lib-cbc128.o",
            "crypto/modes/libfips-lib-ccm128.o",
            "crypto/modes/libfips-lib-cfb128.o",
            "crypto/modes/libfips-lib-ctr128.o",
            "crypto/modes/libfips-lib-gcm128.o",
            "crypto/modes/libfips-lib-ghash-x86_64.o",
            "crypto/modes/libfips-lib-ofb128.o",
            "crypto/modes/libfips-lib-wrap128.o",
            "crypto/modes/libfips-lib-xts128.o",
            "crypto/property/libfips-lib-defn_cache.o",
            "crypto/property/libfips-lib-property.o",
            "crypto/property/libfips-lib-property_parse.o",
            "crypto/property/libfips-lib-property_query.o",
            "crypto/property/libfips-lib-property_string.o",
            "crypto/rand/libfips-lib-rand_lib.o",
            "crypto/rsa/libfips-lib-rsa_acvp_test_params.o",
            "crypto/rsa/libfips-lib-rsa_backend.o",
            "crypto/rsa/libfips-lib-rsa_chk.o",
            "crypto/rsa/libfips-lib-rsa_crpt.o",
            "crypto/rsa/libfips-lib-rsa_gen.o",
            "crypto/rsa/libfips-lib-rsa_lib.o",
            "crypto/rsa/libfips-lib-rsa_mp_names.o",
            "crypto/rsa/libfips-lib-rsa_none.o",
            "crypto/rsa/libfips-lib-rsa_oaep.o",
            "crypto/rsa/libfips-lib-rsa_ossl.o",
            "crypto/rsa/libfips-lib-rsa_pk1.o",
            "crypto/rsa/libfips-lib-rsa_pss.o",
            "crypto/rsa/libfips-lib-rsa_schemes.o",
            "crypto/rsa/libfips-lib-rsa_sign.o",
            "crypto/rsa/libfips-lib-rsa_sp800_56b_check.o",
            "crypto/rsa/libfips-lib-rsa_sp800_56b_gen.o",
            "crypto/rsa/libfips-lib-rsa_x931.o",
            "crypto/sha/libfips-lib-keccak1600-x86_64.o",
            "crypto/sha/libfips-lib-sha1-mb-x86_64.o",
            "crypto/sha/libfips-lib-sha1-x86_64.o",
            "crypto/sha/libfips-lib-sha1dgst.o",
            "crypto/sha/libfips-lib-sha256-mb-x86_64.o",
            "crypto/sha/libfips-lib-sha256-x86_64.o",
            "crypto/sha/libfips-lib-sha256.o",
            "crypto/sha/libfips-lib-sha3.o",
            "crypto/sha/libfips-lib-sha512-x86_64.o",
            "crypto/sha/libfips-lib-sha512.o",
            "crypto/stack/libfips-lib-stack.o",
            "providers/common/der/libfips-lib-der_rsa_sig.o",
            "providers/common/libfips-lib-bio_prov.o",
            "providers/common/libfips-lib-capabilities.o",
            "providers/common/libfips-lib-digest_to_nid.o",
            "providers/common/libfips-lib-provider_seeding.o",
            "providers/common/libfips-lib-provider_util.o",
            "providers/common/libfips-lib-securitycheck.o",
            "providers/common/libfips-lib-securitycheck_fips.o",
            "providers/fips/libfips-lib-fipsprov.o",
            "providers/fips/libfips-lib-self_test.o",
            "providers/fips/libfips-lib-self_test_kats.o",
            "providers/implementations/asymciphers/libfips-lib-rsa_enc.o",
            "providers/implementations/ciphers/libfips-lib-cipher_aes.o",
            "providers/implementations/ciphers/libfips-lib-cipher_aes_cbc_hmac_sha.o",
            "providers/implementations/ciphers/libfips-lib-cipher_aes_cbc_hmac_sha1_hw.o",
            "providers/implementations/ciphers/libfips-lib-cipher_aes_cbc_hmac_sha256_hw.o",
            "providers/implementations/ciphers/libfips-lib-cipher_aes_ccm.o",
            "providers/implementations/ciphers/libfips-lib-cipher_aes_ccm_hw.o",
            "providers/implementations/ciphers/libfips-lib-cipher_aes_gcm.o",
            "providers/implementations/ciphers/libfips-lib-cipher_aes_gcm_hw.o",
            "providers/implementations/ciphers/libfips-lib-cipher_aes_hw.o",
            "providers/implementations/ciphers/libfips-lib-cipher_aes_ocb.o",
            "providers/implementations/ciphers/libfips-lib-cipher_aes_ocb_hw.o",
            "providers/implementations/ciphers/libfips-lib-cipher_aes_wrp.o",
            "providers/implementations/ciphers/libfips-lib-cipher_aes_xts.o",
            "providers/implementations/ciphers/libfips-lib-cipher_aes_xts_fips.o",
            "providers/implementations/ciphers/libfips-lib-cipher_aes_xts_hw.o",
            "providers/implementations/ciphers/libfips-lib-cipher_cts.o",
            "providers/implementations/ciphers/libfips-lib-cipher_tdes.o",
            "providers/implementations/ciphers/libfips-lib-cipher_tdes_common.o",
            "providers/implementations/ciphers/libfips-lib-cipher_tdes_hw.o",
            "providers/implementations/digests/libfips-lib-sha2_prov.o",
            "providers/implementations/digests/libfips-lib-sha3_prov.o",
            "providers/implementations/exchange/libfips-lib-dh_exch.o",
            "providers/implementations/exchange/libfips-lib-ecdh_exch.o",
            "providers/implementations/exchange/libfips-lib-ecx_exch.o",
            "providers/implementations/exchange/libfips-lib-kdf_exch.o",
            "providers/implementations/kdfs/libfips-lib-hkdf.o",
            "providers/implementations/kdfs/libfips-lib-kbkdf.o",
            "providers/implementations/kdfs/libfips-lib-pbkdf2.o",
            "providers/implementations/kdfs/libfips-lib-pbkdf2_fips.o",
            "providers/implementations/kdfs/libfips-lib-sshkdf.o",
            "providers/implementations/kdfs/libfips-lib-sskdf.o",
            "providers/implementations/kdfs/libfips-lib-tls1_prf.o",
            "providers/implementations/kdfs/libfips-lib-x942kdf.o",
            "providers/implementations/kem/libfips-lib-rsa_kem.o",
            "providers/implementations/keymgmt/libfips-lib-dh_kmgmt.o",
            "providers/implementations/keymgmt/libfips-lib-dsa_kmgmt.o",
            "providers/implementations/keymgmt/libfips-lib-ec_kmgmt.o",
            "providers/implementations/keymgmt/libfips-lib-ecx_kmgmt.o",
            "providers/implementations/keymgmt/libfips-lib-kdf_legacy_kmgmt.o",
            "providers/implementations/keymgmt/libfips-lib-mac_legacy_kmgmt.o",
            "providers/implementations/keymgmt/libfips-lib-rsa_kmgmt.o",
            "providers/implementations/macs/libfips-lib-cmac_prov.o",
            "providers/implementations/macs/libfips-lib-gmac_prov.o",
            "providers/implementations/macs/libfips-lib-hmac_prov.o",
            "providers/implementations/macs/libfips-lib-kmac_prov.o",
            "providers/implementations/rands/libfips-lib-crngt.o",
            "providers/implementations/rands/libfips-lib-drbg.o",
            "providers/implementations/rands/libfips-lib-drbg_ctr.o",
            "providers/implementations/rands/libfips-lib-drbg_hash.o",
            "providers/implementations/rands/libfips-lib-drbg_hmac.o",
            "providers/implementations/rands/libfips-lib-test_rng.o",
            "providers/implementations/signature/libfips-lib-dsa_sig.o",
            "providers/implementations/signature/libfips-lib-ecdsa_sig.o",
            "providers/implementations/signature/libfips-lib-eddsa_sig.o",
            "providers/implementations/signature/libfips-lib-mac_legacy_sig.o",
            "providers/implementations/signature/libfips-lib-rsa_sig.o",
            "providers/libcommon.a",
            "ssl/libfips-lib-s3_cbc.o"
        ],
        "providers/liblegacy-lib-prov_running.o" => [
            "providers/prov_running.c"
        ],
        "providers/liblegacy.a" => [
            "providers/implementations/ciphers/liblegacy-lib-cipher_blowfish.o",
            "providers/implementations/ciphers/liblegacy-lib-cipher_blowfish_hw.o",
            "providers/implementations/ciphers/liblegacy-lib-cipher_cast5.o",
            "providers/implementations/ciphers/liblegacy-lib-cipher_cast5_hw.o",
            "providers/implementations/ciphers/liblegacy-lib-cipher_des.o",
            "providers/implementations/ciphers/liblegacy-lib-cipher_des_hw.o",
            "providers/implementations/ciphers/liblegacy-lib-cipher_desx.o",
            "providers/implementations/ciphers/liblegacy-lib-cipher_desx_hw.o",
            "providers/implementations/ciphers/liblegacy-lib-cipher_idea.o",
            "providers/implementations/ciphers/liblegacy-lib-cipher_idea_hw.o",
            "providers/implementations/ciphers/liblegacy-lib-cipher_rc2.o",
            "providers/implementations/ciphers/liblegacy-lib-cipher_rc2_hw.o",
            "providers/implementations/ciphers/liblegacy-lib-cipher_rc4.o",
            "providers/implementations/ciphers/liblegacy-lib-cipher_rc4_hmac_md5.o",
            "providers/implementations/ciphers/liblegacy-lib-cipher_rc4_hmac_md5_hw.o",
            "providers/implementations/ciphers/liblegacy-lib-cipher_rc4_hw.o",
            "providers/implementations/ciphers/liblegacy-lib-cipher_seed.o",
            "providers/implementations/ciphers/liblegacy-lib-cipher_seed_hw.o",
            "providers/implementations/ciphers/liblegacy-lib-cipher_tdes_common.o",
            "providers/implementations/digests/liblegacy-lib-md4_prov.o",
            "providers/implementations/digests/liblegacy-lib-mdc2_prov.o",
            "providers/implementations/digests/liblegacy-lib-ripemd_prov.o",
            "providers/implementations/digests/liblegacy-lib-wp_prov.o",
            "providers/implementations/kdfs/liblegacy-lib-pbkdf1.o",
            "providers/liblegacy-lib-prov_running.o"
        ],
        "ssl/libdefault-lib-s3_cbc.o" => [
            "ssl/s3_cbc.c"
        ],
        "ssl/libfips-lib-s3_cbc.o" => [
            "ssl/s3_cbc.c"
        ],
        "ssl/libssl-lib-bio_ssl.o" => [
            "ssl/bio_ssl.c"
        ],
        "ssl/libssl-lib-d1_lib.o" => [
            "ssl/d1_lib.c"
        ],
        "ssl/libssl-lib-d1_msg.o" => [
            "ssl/d1_msg.c"
        ],
        "ssl/libssl-lib-d1_srtp.o" => [
            "ssl/d1_srtp.c"
        ],
        "ssl/libssl-lib-methods.o" => [
            "ssl/methods.c"
        ],
        "ssl/libssl-lib-pqueue.o" => [
            "ssl/pqueue.c"
        ],
        "ssl/libssl-lib-s3_enc.o" => [
            "ssl/s3_enc.c"
        ],
        "ssl/libssl-lib-s3_lib.o" => [
            "ssl/s3_lib.c"
        ],
        "ssl/libssl-lib-s3_msg.o" => [
            "ssl/s3_msg.c"
        ],
        "ssl/libssl-lib-ssl_asn1.o" => [
            "ssl/ssl_asn1.c"
        ],
        "ssl/libssl-lib-ssl_cert.o" => [
            "ssl/ssl_cert.c"
        ],
        "ssl/libssl-lib-ssl_ciph.o" => [
            "ssl/ssl_ciph.c"
        ],
        "ssl/libssl-lib-ssl_conf.o" => [
            "ssl/ssl_conf.c"
        ],
        "ssl/libssl-lib-ssl_err.o" => [
            "ssl/ssl_err.c"
        ],
        "ssl/libssl-lib-ssl_err_legacy.o" => [
            "ssl/ssl_err_legacy.c"
        ],
        "ssl/libssl-lib-ssl_init.o" => [
            "ssl/ssl_init.c"
        ],
        "ssl/libssl-lib-ssl_lib.o" => [
            "ssl/ssl_lib.c"
        ],
        "ssl/libssl-lib-ssl_mcnf.o" => [
            "ssl/ssl_mcnf.c"
        ],
        "ssl/libssl-lib-ssl_quic.o" => [
            "ssl/ssl_quic.c"
        ],
        "ssl/libssl-lib-ssl_rsa.o" => [
            "ssl/ssl_rsa.c"
        ],
        "ssl/libssl-lib-ssl_rsa_legacy.o" => [
            "ssl/ssl_rsa_legacy.c"
        ],
        "ssl/libssl-lib-ssl_sess.o" => [
            "ssl/ssl_sess.c"
        ],
        "ssl/libssl-lib-ssl_stat.o" => [
            "ssl/ssl_stat.c"
        ],
        "ssl/libssl-lib-ssl_txt.o" => [
            "ssl/ssl_txt.c"
        ],
        "ssl/libssl-lib-ssl_utst.o" => [
            "ssl/ssl_utst.c"
        ],
        "ssl/libssl-lib-t1_enc.o" => [
            "ssl/t1_enc.c"
        ],
        "ssl/libssl-lib-t1_lib.o" => [
            "ssl/t1_lib.c"
        ],
        "ssl/libssl-lib-t1_trce.o" => [
            "ssl/t1_trce.c"
        ],
        "ssl/libssl-lib-tls13_enc.o" => [
            "ssl/tls13_enc.c"
        ],
        "ssl/libssl-lib-tls_depr.o" => [
            "ssl/tls_depr.c"
        ],
        "ssl/libssl-lib-tls_srp.o" => [
            "ssl/tls_srp.c"
        ],
        "ssl/record/libcommon-lib-tls_pad.o" => [
            "ssl/record/tls_pad.c"
        ],
        "ssl/record/libssl-lib-dtls1_bitmap.o" => [
            "ssl/record/dtls1_bitmap.c"
        ],
        "ssl/record/libssl-lib-rec_layer_d1.o" => [
            "ssl/record/rec_layer_d1.c"
        ],
        "ssl/record/libssl-lib-rec_layer_s3.o" => [
            "ssl/record/rec_layer_s3.c"
        ],
        "ssl/record/libssl-lib-ssl3_buffer.o" => [
            "ssl/record/ssl3_buffer.c"
        ],
        "ssl/record/libssl-lib-ssl3_record.o" => [
            "ssl/record/ssl3_record.c"
        ],
        "ssl/record/libssl-lib-ssl3_record_tls13.o" => [
            "ssl/record/ssl3_record_tls13.c"
        ],
        "ssl/statem/libssl-lib-extensions.o" => [
            "ssl/statem/extensions.c"
        ],
        "ssl/statem/libssl-lib-extensions_clnt.o" => [
            "ssl/statem/extensions_clnt.c"
        ],
        "ssl/statem/libssl-lib-extensions_cust.o" => [
            "ssl/statem/extensions_cust.c"
        ],
        "ssl/statem/libssl-lib-extensions_srvr.o" => [
            "ssl/statem/extensions_srvr.c"
        ],
        "ssl/statem/libssl-lib-statem.o" => [
            "ssl/statem/statem.c"
        ],
        "ssl/statem/libssl-lib-statem_clnt.o" => [
            "ssl/statem/statem_clnt.c"
        ],
        "ssl/statem/libssl-lib-statem_dtls.o" => [
            "ssl/statem/statem_dtls.c"
        ],
        "ssl/statem/libssl-lib-statem_lib.o" => [
            "ssl/statem/statem_lib.c"
        ],
        "ssl/statem/libssl-lib-statem_quic.o" => [
            "ssl/statem/statem_quic.c"
        ],
        "ssl/statem/libssl-lib-statem_srvr.o" => [
            "ssl/statem/statem_srvr.c"
        ],
        "test/aborttest" => [
            "test/aborttest-bin-aborttest.o"
        ],
        "test/aborttest-bin-aborttest.o" => [
            "test/aborttest.c"
        ],
        "test/acvp_test" => [
            "test/acvp_test-bin-acvp_test.o"
        ],
        "test/acvp_test-bin-acvp_test.o" => [
            "test/acvp_test.c"
        ],
        "test/aesgcmtest" => [
            "test/aesgcmtest-bin-aesgcmtest.o"
        ],
        "test/aesgcmtest-bin-aesgcmtest.o" => [
            "test/aesgcmtest.c"
        ],
        "test/afalgtest" => [
            "test/afalgtest-bin-afalgtest.o"
        ],
        "test/afalgtest-bin-afalgtest.o" => [
            "test/afalgtest.c"
        ],
        "test/algorithmid_test" => [
            "test/algorithmid_test-bin-algorithmid_test.o"
        ],
        "test/algorithmid_test-bin-algorithmid_test.o" => [
            "test/algorithmid_test.c"
        ],
        "test/asn1_decode_test" => [
            "test/asn1_decode_test-bin-asn1_decode_test.o"
        ],
        "test/asn1_decode_test-bin-asn1_decode_test.o" => [
            "test/asn1_decode_test.c"
        ],
        "test/asn1_dsa_internal_test" => [
            "test/asn1_dsa_internal_test-bin-asn1_dsa_internal_test.o"
        ],
        "test/asn1_dsa_internal_test-bin-asn1_dsa_internal_test.o" => [
            "test/asn1_dsa_internal_test.c"
        ],
        "test/asn1_encode_test" => [
            "test/asn1_encode_test-bin-asn1_encode_test.o"
        ],
        "test/asn1_encode_test-bin-asn1_encode_test.o" => [
            "test/asn1_encode_test.c"
        ],
        "test/asn1_internal_test" => [
            "test/asn1_internal_test-bin-asn1_internal_test.o"
        ],
        "test/asn1_internal_test-bin-asn1_internal_test.o" => [
            "test/asn1_internal_test.c"
        ],
        "test/asn1_stable_parse_test" => [
            "test/asn1_stable_parse_test-bin-asn1_stable_parse_test.o"
        ],
        "test/asn1_stable_parse_test-bin-asn1_stable_parse_test.o" => [
            "test/asn1_stable_parse_test.c"
        ],
        "test/asn1_string_table_test" => [
            "test/asn1_string_table_test-bin-asn1_string_table_test.o"
        ],
        "test/asn1_string_table_test-bin-asn1_string_table_test.o" => [
            "test/asn1_string_table_test.c"
        ],
        "test/asn1_time_test" => [
            "test/asn1_time_test-bin-asn1_time_test.o"
        ],
        "test/asn1_time_test-bin-asn1_time_test.o" => [
            "test/asn1_time_test.c"
        ],
        "test/asynciotest" => [
            "test/asynciotest-bin-asynciotest.o",
            "test/helpers/asynciotest-bin-ssltestlib.o"
        ],
        "test/asynciotest-bin-asynciotest.o" => [
            "test/asynciotest.c"
        ],
        "test/asynctest" => [
            "test/asynctest-bin-asynctest.o"
        ],
        "test/asynctest-bin-asynctest.o" => [
            "test/asynctest.c"
        ],
        "test/bad_dtls_test" => [
            "test/bad_dtls_test-bin-bad_dtls_test.o"
        ],
        "test/bad_dtls_test-bin-bad_dtls_test.o" => [
            "test/bad_dtls_test.c"
        ],
        "test/bftest" => [
            "test/bftest-bin-bftest.o"
        ],
        "test/bftest-bin-bftest.o" => [
            "test/bftest.c"
        ],
        "test/bio_callback_test" => [
            "test/bio_callback_test-bin-bio_callback_test.o"
        ],
        "test/bio_callback_test-bin-bio_callback_test.o" => [
            "test/bio_callback_test.c"
        ],
        "test/bio_core_test" => [
            "test/bio_core_test-bin-bio_core_test.o"
        ],
        "test/bio_core_test-bin-bio_core_test.o" => [
            "test/bio_core_test.c"
        ],
        "test/bio_enc_test" => [
            "test/bio_enc_test-bin-bio_enc_test.o"
        ],
        "test/bio_enc_test-bin-bio_enc_test.o" => [
            "test/bio_enc_test.c"
        ],
        "test/bio_memleak_test" => [
            "test/bio_memleak_test-bin-bio_memleak_test.o"
        ],
        "test/bio_memleak_test-bin-bio_memleak_test.o" => [
            "test/bio_memleak_test.c"
        ],
        "test/bio_prefix_text" => [
            "test/bio_prefix_text-bin-bio_prefix_text.o"
        ],
        "test/bio_prefix_text-bin-bio_prefix_text.o" => [
            "test/bio_prefix_text.c"
        ],
        "test/bio_readbuffer_test" => [
            "test/bio_readbuffer_test-bin-bio_readbuffer_test.o"
        ],
        "test/bio_readbuffer_test-bin-bio_readbuffer_test.o" => [
            "test/bio_readbuffer_test.c"
        ],
        "test/bioprinttest" => [
            "test/bioprinttest-bin-bioprinttest.o"
        ],
        "test/bioprinttest-bin-bioprinttest.o" => [
            "test/bioprinttest.c"
        ],
        "test/bn_internal_test" => [
            "test/bn_internal_test-bin-bn_internal_test.o"
        ],
        "test/bn_internal_test-bin-bn_internal_test.o" => [
            "test/bn_internal_test.c"
        ],
        "test/bntest" => [
            "test/bntest-bin-bntest.o"
        ],
        "test/bntest-bin-bntest.o" => [
            "test/bntest.c"
        ],
        "test/buildtest_c_aes" => [
            "test/buildtest_c_aes-bin-buildtest_aes.o"
        ],
        "test/buildtest_c_aes-bin-buildtest_aes.o" => [
            "test/buildtest_aes.c"
        ],
        "test/buildtest_c_async" => [
            "test/buildtest_c_async-bin-buildtest_async.o"
        ],
        "test/buildtest_c_async-bin-buildtest_async.o" => [
            "test/buildtest_async.c"
        ],
        "test/buildtest_c_blowfish" => [
            "test/buildtest_c_blowfish-bin-buildtest_blowfish.o"
        ],
        "test/buildtest_c_blowfish-bin-buildtest_blowfish.o" => [
            "test/buildtest_blowfish.c"
        ],
        "test/buildtest_c_bn" => [
            "test/buildtest_c_bn-bin-buildtest_bn.o"
        ],
        "test/buildtest_c_bn-bin-buildtest_bn.o" => [
            "test/buildtest_bn.c"
        ],
        "test/buildtest_c_buffer" => [
            "test/buildtest_c_buffer-bin-buildtest_buffer.o"
        ],
        "test/buildtest_c_buffer-bin-buildtest_buffer.o" => [
            "test/buildtest_buffer.c"
        ],
        "test/buildtest_c_camellia" => [
            "test/buildtest_c_camellia-bin-buildtest_camellia.o"
        ],
        "test/buildtest_c_camellia-bin-buildtest_camellia.o" => [
            "test/buildtest_camellia.c"
        ],
        "test/buildtest_c_cast" => [
            "test/buildtest_c_cast-bin-buildtest_cast.o"
        ],
        "test/buildtest_c_cast-bin-buildtest_cast.o" => [
            "test/buildtest_cast.c"
        ],
        "test/buildtest_c_cmac" => [
            "test/buildtest_c_cmac-bin-buildtest_cmac.o"
        ],
        "test/buildtest_c_cmac-bin-buildtest_cmac.o" => [
            "test/buildtest_cmac.c"
        ],
        "test/buildtest_c_cmp_util" => [
            "test/buildtest_c_cmp_util-bin-buildtest_cmp_util.o"
        ],
        "test/buildtest_c_cmp_util-bin-buildtest_cmp_util.o" => [
            "test/buildtest_cmp_util.c"
        ],
        "test/buildtest_c_conf_api" => [
            "test/buildtest_c_conf_api-bin-buildtest_conf_api.o"
        ],
        "test/buildtest_c_conf_api-bin-buildtest_conf_api.o" => [
            "test/buildtest_conf_api.c"
        ],
        "test/buildtest_c_conftypes" => [
            "test/buildtest_c_conftypes-bin-buildtest_conftypes.o"
        ],
        "test/buildtest_c_conftypes-bin-buildtest_conftypes.o" => [
            "test/buildtest_conftypes.c"
        ],
        "test/buildtest_c_core" => [
            "test/buildtest_c_core-bin-buildtest_core.o"
        ],
        "test/buildtest_c_core-bin-buildtest_core.o" => [
            "test/buildtest_core.c"
        ],
        "test/buildtest_c_core_dispatch" => [
            "test/buildtest_c_core_dispatch-bin-buildtest_core_dispatch.o"
        ],
        "test/buildtest_c_core_dispatch-bin-buildtest_core_dispatch.o" => [
            "test/buildtest_core_dispatch.c"
        ],
        "test/buildtest_c_core_names" => [
            "test/buildtest_c_core_names-bin-buildtest_core_names.o"
        ],
        "test/buildtest_c_core_names-bin-buildtest_core_names.o" => [
            "test/buildtest_core_names.c"
        ],
        "test/buildtest_c_core_object" => [
            "test/buildtest_c_core_object-bin-buildtest_core_object.o"
        ],
        "test/buildtest_c_core_object-bin-buildtest_core_object.o" => [
            "test/buildtest_core_object.c"
        ],
        "test/buildtest_c_cryptoerr_legacy" => [
            "test/buildtest_c_cryptoerr_legacy-bin-buildtest_cryptoerr_legacy.o"
        ],
        "test/buildtest_c_cryptoerr_legacy-bin-buildtest_cryptoerr_legacy.o" => [
            "test/buildtest_cryptoerr_legacy.c"
        ],
        "test/buildtest_c_decoder" => [
            "test/buildtest_c_decoder-bin-buildtest_decoder.o"
        ],
        "test/buildtest_c_decoder-bin-buildtest_decoder.o" => [
            "test/buildtest_decoder.c"
        ],
        "test/buildtest_c_des" => [
            "test/buildtest_c_des-bin-buildtest_des.o"
        ],
        "test/buildtest_c_des-bin-buildtest_des.o" => [
            "test/buildtest_des.c"
        ],
        "test/buildtest_c_dh" => [
            "test/buildtest_c_dh-bin-buildtest_dh.o"
        ],
        "test/buildtest_c_dh-bin-buildtest_dh.o" => [
            "test/buildtest_dh.c"
        ],
        "test/buildtest_c_dsa" => [
            "test/buildtest_c_dsa-bin-buildtest_dsa.o"
        ],
        "test/buildtest_c_dsa-bin-buildtest_dsa.o" => [
            "test/buildtest_dsa.c"
        ],
        "test/buildtest_c_dtls1" => [
            "test/buildtest_c_dtls1-bin-buildtest_dtls1.o"
        ],
        "test/buildtest_c_dtls1-bin-buildtest_dtls1.o" => [
            "test/buildtest_dtls1.c"
        ],
        "test/buildtest_c_e_os2" => [
            "test/buildtest_c_e_os2-bin-buildtest_e_os2.o"
        ],
        "test/buildtest_c_e_os2-bin-buildtest_e_os2.o" => [
            "test/buildtest_e_os2.c"
        ],
        "test/buildtest_c_ebcdic" => [
            "test/buildtest_c_ebcdic-bin-buildtest_ebcdic.o"
        ],
        "test/buildtest_c_ebcdic-bin-buildtest_ebcdic.o" => [
            "test/buildtest_ebcdic.c"
        ],
        "test/buildtest_c_ec" => [
            "test/buildtest_c_ec-bin-buildtest_ec.o"
        ],
        "test/buildtest_c_ec-bin-buildtest_ec.o" => [
            "test/buildtest_ec.c"
        ],
        "test/buildtest_c_ecdh" => [
            "test/buildtest_c_ecdh-bin-buildtest_ecdh.o"
        ],
        "test/buildtest_c_ecdh-bin-buildtest_ecdh.o" => [
            "test/buildtest_ecdh.c"
        ],
        "test/buildtest_c_ecdsa" => [
            "test/buildtest_c_ecdsa-bin-buildtest_ecdsa.o"
        ],
        "test/buildtest_c_ecdsa-bin-buildtest_ecdsa.o" => [
            "test/buildtest_ecdsa.c"
        ],
        "test/buildtest_c_encoder" => [
            "test/buildtest_c_encoder-bin-buildtest_encoder.o"
        ],
        "test/buildtest_c_encoder-bin-buildtest_encoder.o" => [
            "test/buildtest_encoder.c"
        ],
        "test/buildtest_c_engine" => [
            "test/buildtest_c_engine-bin-buildtest_engine.o"
        ],
        "test/buildtest_c_engine-bin-buildtest_engine.o" => [
            "test/buildtest_engine.c"
        ],
        "test/buildtest_c_evp" => [
            "test/buildtest_c_evp-bin-buildtest_evp.o"
        ],
        "test/buildtest_c_evp-bin-buildtest_evp.o" => [
            "test/buildtest_evp.c"
        ],
        "test/buildtest_c_fips_names" => [
            "test/buildtest_c_fips_names-bin-buildtest_fips_names.o"
        ],
        "test/buildtest_c_fips_names-bin-buildtest_fips_names.o" => [
            "test/buildtest_fips_names.c"
        ],
        "test/buildtest_c_hmac" => [
            "test/buildtest_c_hmac-bin-buildtest_hmac.o"
        ],
        "test/buildtest_c_hmac-bin-buildtest_hmac.o" => [
            "test/buildtest_hmac.c"
        ],
        "test/buildtest_c_http" => [
            "test/buildtest_c_http-bin-buildtest_http.o"
        ],
        "test/buildtest_c_http-bin-buildtest_http.o" => [
            "test/buildtest_http.c"
        ],
        "test/buildtest_c_idea" => [
            "test/buildtest_c_idea-bin-buildtest_idea.o"
        ],
        "test/buildtest_c_idea-bin-buildtest_idea.o" => [
            "test/buildtest_idea.c"
        ],
        "test/buildtest_c_kdf" => [
            "test/buildtest_c_kdf-bin-buildtest_kdf.o"
        ],
        "test/buildtest_c_kdf-bin-buildtest_kdf.o" => [
            "test/buildtest_kdf.c"
        ],
        "test/buildtest_c_macros" => [
            "test/buildtest_c_macros-bin-buildtest_macros.o"
        ],
        "test/buildtest_c_macros-bin-buildtest_macros.o" => [
            "test/buildtest_macros.c"
        ],
        "test/buildtest_c_md4" => [
            "test/buildtest_c_md4-bin-buildtest_md4.o"
        ],
        "test/buildtest_c_md4-bin-buildtest_md4.o" => [
            "test/buildtest_md4.c"
        ],
        "test/buildtest_c_md5" => [
            "test/buildtest_c_md5-bin-buildtest_md5.o"
        ],
        "test/buildtest_c_md5-bin-buildtest_md5.o" => [
            "test/buildtest_md5.c"
        ],
        "test/buildtest_c_mdc2" => [
            "test/buildtest_c_mdc2-bin-buildtest_mdc2.o"
        ],
        "test/buildtest_c_mdc2-bin-buildtest_mdc2.o" => [
            "test/buildtest_mdc2.c"
        ],
        "test/buildtest_c_modes" => [
            "test/buildtest_c_modes-bin-buildtest_modes.o"
        ],
        "test/buildtest_c_modes-bin-buildtest_modes.o" => [
            "test/buildtest_modes.c"
        ],
        "test/buildtest_c_obj_mac" => [
            "test/buildtest_c_obj_mac-bin-buildtest_obj_mac.o"
        ],
        "test/buildtest_c_obj_mac-bin-buildtest_obj_mac.o" => [
            "test/buildtest_obj_mac.c"
        ],
        "test/buildtest_c_objects" => [
            "test/buildtest_c_objects-bin-buildtest_objects.o"
        ],
        "test/buildtest_c_objects-bin-buildtest_objects.o" => [
            "test/buildtest_objects.c"
        ],
        "test/buildtest_c_ossl_typ" => [
            "test/buildtest_c_ossl_typ-bin-buildtest_ossl_typ.o"
        ],
        "test/buildtest_c_ossl_typ-bin-buildtest_ossl_typ.o" => [
            "test/buildtest_ossl_typ.c"
        ],
        "test/buildtest_c_param_build" => [
            "test/buildtest_c_param_build-bin-buildtest_param_build.o"
        ],
        "test/buildtest_c_param_build-bin-buildtest_param_build.o" => [
            "test/buildtest_param_build.c"
        ],
        "test/buildtest_c_params" => [
            "test/buildtest_c_params-bin-buildtest_params.o"
        ],
        "test/buildtest_c_params-bin-buildtest_params.o" => [
            "test/buildtest_params.c"
        ],
        "test/buildtest_c_pem" => [
            "test/buildtest_c_pem-bin-buildtest_pem.o"
        ],
        "test/buildtest_c_pem-bin-buildtest_pem.o" => [
            "test/buildtest_pem.c"
        ],
        "test/buildtest_c_pem2" => [
            "test/buildtest_c_pem2-bin-buildtest_pem2.o"
        ],
        "test/buildtest_c_pem2-bin-buildtest_pem2.o" => [
            "test/buildtest_pem2.c"
        ],
        "test/buildtest_c_prov_ssl" => [
            "test/buildtest_c_prov_ssl-bin-buildtest_prov_ssl.o"
        ],
        "test/buildtest_c_prov_ssl-bin-buildtest_prov_ssl.o" => [
            "test/buildtest_prov_ssl.c"
        ],
        "test/buildtest_c_provider" => [
            "test/buildtest_c_provider-bin-buildtest_provider.o"
        ],
        "test/buildtest_c_provider-bin-buildtest_provider.o" => [
            "test/buildtest_provider.c"
        ],
        "test/buildtest_c_quic" => [
            "test/buildtest_c_quic-bin-buildtest_quic.o"
        ],
        "test/buildtest_c_quic-bin-buildtest_quic.o" => [
            "test/buildtest_quic.c"
        ],
        "test/buildtest_c_rand" => [
            "test/buildtest_c_rand-bin-buildtest_rand.o"
        ],
        "test/buildtest_c_rand-bin-buildtest_rand.o" => [
            "test/buildtest_rand.c"
        ],
        "test/buildtest_c_rc2" => [
            "test/buildtest_c_rc2-bin-buildtest_rc2.o"
        ],
        "test/buildtest_c_rc2-bin-buildtest_rc2.o" => [
            "test/buildtest_rc2.c"
        ],
        "test/buildtest_c_rc4" => [
            "test/buildtest_c_rc4-bin-buildtest_rc4.o"
        ],
        "test/buildtest_c_rc4-bin-buildtest_rc4.o" => [
            "test/buildtest_rc4.c"
        ],
        "test/buildtest_c_ripemd" => [
            "test/buildtest_c_ripemd-bin-buildtest_ripemd.o"
        ],
        "test/buildtest_c_ripemd-bin-buildtest_ripemd.o" => [
            "test/buildtest_ripemd.c"
        ],
        "test/buildtest_c_rsa" => [
            "test/buildtest_c_rsa-bin-buildtest_rsa.o"
        ],
        "test/buildtest_c_rsa-bin-buildtest_rsa.o" => [
            "test/buildtest_rsa.c"
        ],
        "test/buildtest_c_seed" => [
            "test/buildtest_c_seed-bin-buildtest_seed.o"
        ],
        "test/buildtest_c_seed-bin-buildtest_seed.o" => [
            "test/buildtest_seed.c"
        ],
        "test/buildtest_c_self_test" => [
            "test/buildtest_c_self_test-bin-buildtest_self_test.o"
        ],
        "test/buildtest_c_self_test-bin-buildtest_self_test.o" => [
            "test/buildtest_self_test.c"
        ],
        "test/buildtest_c_sha" => [
            "test/buildtest_c_sha-bin-buildtest_sha.o"
        ],
        "test/buildtest_c_sha-bin-buildtest_sha.o" => [
            "test/buildtest_sha.c"
        ],
        "test/buildtest_c_srtp" => [
            "test/buildtest_c_srtp-bin-buildtest_srtp.o"
        ],
        "test/buildtest_c_srtp-bin-buildtest_srtp.o" => [
            "test/buildtest_srtp.c"
        ],
        "test/buildtest_c_ssl2" => [
            "test/buildtest_c_ssl2-bin-buildtest_ssl2.o"
        ],
        "test/buildtest_c_ssl2-bin-buildtest_ssl2.o" => [
            "test/buildtest_ssl2.c"
        ],
        "test/buildtest_c_sslerr_legacy" => [
            "test/buildtest_c_sslerr_legacy-bin-buildtest_sslerr_legacy.o"
        ],
        "test/buildtest_c_sslerr_legacy-bin-buildtest_sslerr_legacy.o" => [
            "test/buildtest_sslerr_legacy.c"
        ],
        "test/buildtest_c_stack" => [
            "test/buildtest_c_stack-bin-buildtest_stack.o"
        ],
        "test/buildtest_c_stack-bin-buildtest_stack.o" => [
            "test/buildtest_stack.c"
        ],
        "test/buildtest_c_store" => [
            "test/buildtest_c_store-bin-buildtest_store.o"
        ],
        "test/buildtest_c_store-bin-buildtest_store.o" => [
            "test/buildtest_store.c"
        ],
        "test/buildtest_c_symhacks" => [
            "test/buildtest_c_symhacks-bin-buildtest_symhacks.o"
        ],
        "test/buildtest_c_symhacks-bin-buildtest_symhacks.o" => [
            "test/buildtest_symhacks.c"
        ],
        "test/buildtest_c_tls1" => [
            "test/buildtest_c_tls1-bin-buildtest_tls1.o"
        ],
        "test/buildtest_c_tls1-bin-buildtest_tls1.o" => [
            "test/buildtest_tls1.c"
        ],
        "test/buildtest_c_ts" => [
            "test/buildtest_c_ts-bin-buildtest_ts.o"
        ],
        "test/buildtest_c_ts-bin-buildtest_ts.o" => [
            "test/buildtest_ts.c"
        ],
        "test/buildtest_c_txt_db" => [
            "test/buildtest_c_txt_db-bin-buildtest_txt_db.o"
        ],
        "test/buildtest_c_txt_db-bin-buildtest_txt_db.o" => [
            "test/buildtest_txt_db.c"
        ],
        "test/buildtest_c_types" => [
            "test/buildtest_c_types-bin-buildtest_types.o"
        ],
        "test/buildtest_c_types-bin-buildtest_types.o" => [
            "test/buildtest_types.c"
        ],
        "test/buildtest_c_whrlpool" => [
            "test/buildtest_c_whrlpool-bin-buildtest_whrlpool.o"
        ],
        "test/buildtest_c_whrlpool-bin-buildtest_whrlpool.o" => [
            "test/buildtest_whrlpool.c"
        ],
        "test/casttest" => [
            "test/casttest-bin-casttest.o"
        ],
        "test/casttest-bin-casttest.o" => [
            "test/casttest.c"
        ],
        "test/chacha_internal_test" => [
            "test/chacha_internal_test-bin-chacha_internal_test.o"
        ],
        "test/chacha_internal_test-bin-chacha_internal_test.o" => [
            "test/chacha_internal_test.c"
        ],
        "test/cipher_overhead_test" => [
            "test/cipher_overhead_test-bin-cipher_overhead_test.o"
        ],
        "test/cipher_overhead_test-bin-cipher_overhead_test.o" => [
            "test/cipher_overhead_test.c"
        ],
        "test/cipherbytes_test" => [
            "test/cipherbytes_test-bin-cipherbytes_test.o"
        ],
        "test/cipherbytes_test-bin-cipherbytes_test.o" => [
            "test/cipherbytes_test.c"
        ],
        "test/cipherlist_test" => [
            "test/cipherlist_test-bin-cipherlist_test.o"
        ],
        "test/cipherlist_test-bin-cipherlist_test.o" => [
            "test/cipherlist_test.c"
        ],
        "test/ciphername_test" => [
            "test/ciphername_test-bin-ciphername_test.o"
        ],
        "test/ciphername_test-bin-ciphername_test.o" => [
            "test/ciphername_test.c"
        ],
        "test/clienthellotest" => [
            "test/clienthellotest-bin-clienthellotest.o"
        ],
        "test/clienthellotest-bin-clienthellotest.o" => [
            "test/clienthellotest.c"
        ],
        "test/cmactest" => [
            "test/cmactest-bin-cmactest.o"
        ],
        "test/cmactest-bin-cmactest.o" => [
            "test/cmactest.c"
        ],
        "test/cmp_asn_test" => [
            "test/cmp_asn_test-bin-cmp_asn_test.o",
            "test/helpers/cmp_asn_test-bin-cmp_testlib.o"
        ],
        "test/cmp_asn_test-bin-cmp_asn_test.o" => [
            "test/cmp_asn_test.c"
        ],
        "test/cmp_client_test" => [
            "apps/lib/cmp_client_test-bin-cmp_mock_srv.o",
            "test/cmp_client_test-bin-cmp_client_test.o",
            "test/helpers/cmp_client_test-bin-cmp_testlib.o"
        ],
        "test/cmp_client_test-bin-cmp_client_test.o" => [
            "test/cmp_client_test.c"
        ],
        "test/cmp_ctx_test" => [
            "test/cmp_ctx_test-bin-cmp_ctx_test.o",
            "test/helpers/cmp_ctx_test-bin-cmp_testlib.o"
        ],
        "test/cmp_ctx_test-bin-cmp_ctx_test.o" => [
            "test/cmp_ctx_test.c"
        ],
        "test/cmp_hdr_test" => [
            "test/cmp_hdr_test-bin-cmp_hdr_test.o",
            "test/helpers/cmp_hdr_test-bin-cmp_testlib.o"
        ],
        "test/cmp_hdr_test-bin-cmp_hdr_test.o" => [
            "test/cmp_hdr_test.c"
        ],
        "test/cmp_msg_test" => [
            "test/cmp_msg_test-bin-cmp_msg_test.o",
            "test/helpers/cmp_msg_test-bin-cmp_testlib.o"
        ],
        "test/cmp_msg_test-bin-cmp_msg_test.o" => [
            "test/cmp_msg_test.c"
        ],
        "test/cmp_protect_test" => [
            "test/cmp_protect_test-bin-cmp_protect_test.o",
            "test/helpers/cmp_protect_test-bin-cmp_testlib.o"
        ],
        "test/cmp_protect_test-bin-cmp_protect_test.o" => [
            "test/cmp_protect_test.c"
        ],
        "test/cmp_server_test" => [
            "test/cmp_server_test-bin-cmp_server_test.o",
            "test/helpers/cmp_server_test-bin-cmp_testlib.o"
        ],
        "test/cmp_server_test-bin-cmp_server_test.o" => [
            "test/cmp_server_test.c"
        ],
        "test/cmp_status_test" => [
            "test/cmp_status_test-bin-cmp_status_test.o",
            "test/helpers/cmp_status_test-bin-cmp_testlib.o"
        ],
        "test/cmp_status_test-bin-cmp_status_test.o" => [
            "test/cmp_status_test.c"
        ],
        "test/cmp_vfy_test" => [
            "test/cmp_vfy_test-bin-cmp_vfy_test.o",
            "test/helpers/cmp_vfy_test-bin-cmp_testlib.o"
        ],
        "test/cmp_vfy_test-bin-cmp_vfy_test.o" => [
            "test/cmp_vfy_test.c"
        ],
        "test/cmsapitest" => [
            "test/cmsapitest-bin-cmsapitest.o"
        ],
        "test/cmsapitest-bin-cmsapitest.o" => [
            "test/cmsapitest.c"
        ],
        "test/conf_include_test" => [
            "test/conf_include_test-bin-conf_include_test.o"
        ],
        "test/conf_include_test-bin-conf_include_test.o" => [
            "test/conf_include_test.c"
        ],
        "test/confdump" => [
            "test/confdump-bin-confdump.o"
        ],
        "test/confdump-bin-confdump.o" => [
            "test/confdump.c"
        ],
        "test/constant_time_test" => [
            "test/constant_time_test-bin-constant_time_test.o"
        ],
        "test/constant_time_test-bin-constant_time_test.o" => [
            "test/constant_time_test.c"
        ],
        "test/context_internal_test" => [
            "test/context_internal_test-bin-context_internal_test.o"
        ],
        "test/context_internal_test-bin-context_internal_test.o" => [
            "test/context_internal_test.c"
        ],
        "test/crltest" => [
            "test/crltest-bin-crltest.o"
        ],
        "test/crltest-bin-crltest.o" => [
            "test/crltest.c"
        ],
        "test/ct_test" => [
            "test/ct_test-bin-ct_test.o"
        ],
        "test/ct_test-bin-ct_test.o" => [
            "test/ct_test.c"
        ],
        "test/ctype_internal_test" => [
            "test/ctype_internal_test-bin-ctype_internal_test.o"
        ],
        "test/ctype_internal_test-bin-ctype_internal_test.o" => [
            "test/ctype_internal_test.c"
        ],
        "test/curve448_internal_test" => [
            "test/curve448_internal_test-bin-curve448_internal_test.o"
        ],
        "test/curve448_internal_test-bin-curve448_internal_test.o" => [
            "test/curve448_internal_test.c"
        ],
        "test/d2i_test" => [
            "test/d2i_test-bin-d2i_test.o"
        ],
        "test/d2i_test-bin-d2i_test.o" => [
            "test/d2i_test.c"
        ],
        "test/danetest" => [
            "test/danetest-bin-danetest.o"
        ],
        "test/danetest-bin-danetest.o" => [
            "test/danetest.c"
        ],
        "test/defltfips_test" => [
            "test/defltfips_test-bin-defltfips_test.o"
        ],
        "test/defltfips_test-bin-defltfips_test.o" => [
            "test/defltfips_test.c"
        ],
        "test/destest" => [
            "test/destest-bin-destest.o"
        ],
        "test/destest-bin-destest.o" => [
            "test/destest.c"
        ],
        "test/dhtest" => [
            "test/dhtest-bin-dhtest.o"
        ],
        "test/dhtest-bin-dhtest.o" => [
            "test/dhtest.c"
        ],
        "test/drbgtest" => [
            "test/drbgtest-bin-drbgtest.o"
        ],
        "test/drbgtest-bin-drbgtest.o" => [
            "test/drbgtest.c"
        ],
        "test/dsa_no_digest_size_test" => [
            "test/dsa_no_digest_size_test-bin-dsa_no_digest_size_test.o"
        ],
        "test/dsa_no_digest_size_test-bin-dsa_no_digest_size_test.o" => [
            "test/dsa_no_digest_size_test.c"
        ],
        "test/dsatest" => [
            "test/dsatest-bin-dsatest.o"
        ],
        "test/dsatest-bin-dsatest.o" => [
            "test/dsatest.c"
        ],
        "test/dtls_mtu_test" => [
            "test/dtls_mtu_test-bin-dtls_mtu_test.o",
            "test/helpers/dtls_mtu_test-bin-ssltestlib.o"
        ],
        "test/dtls_mtu_test-bin-dtls_mtu_test.o" => [
            "test/dtls_mtu_test.c"
        ],
        "test/dtlstest" => [
            "test/dtlstest-bin-dtlstest.o",
            "test/helpers/dtlstest-bin-ssltestlib.o"
        ],
        "test/dtlstest-bin-dtlstest.o" => [
            "test/dtlstest.c"
        ],
        "test/dtlsv1listentest" => [
            "test/dtlsv1listentest-bin-dtlsv1listentest.o"
        ],
        "test/dtlsv1listentest-bin-dtlsv1listentest.o" => [
            "test/dtlsv1listentest.c"
        ],
        "test/ec_internal_test" => [
            "test/ec_internal_test-bin-ec_internal_test.o"
        ],
        "test/ec_internal_test-bin-ec_internal_test.o" => [
            "test/ec_internal_test.c"
        ],
        "test/ecdsatest" => [
            "test/ecdsatest-bin-ecdsatest.o"
        ],
        "test/ecdsatest-bin-ecdsatest.o" => [
            "test/ecdsatest.c"
        ],
        "test/ecstresstest" => [
            "test/ecstresstest-bin-ecstresstest.o"
        ],
        "test/ecstresstest-bin-ecstresstest.o" => [
            "test/ecstresstest.c"
        ],
        "test/ectest" => [
            "test/ectest-bin-ectest.o"
        ],
        "test/ectest-bin-ectest.o" => [
            "test/ectest.c"
        ],
        "test/endecode_test" => [
            "test/endecode_test-bin-endecode_test.o",
            "test/helpers/endecode_test-bin-predefined_dhparams.o"
        ],
        "test/endecode_test-bin-endecode_test.o" => [
            "test/endecode_test.c"
        ],
        "test/endecoder_legacy_test" => [
            "test/endecoder_legacy_test-bin-endecoder_legacy_test.o"
        ],
        "test/endecoder_legacy_test-bin-endecoder_legacy_test.o" => [
            "test/endecoder_legacy_test.c"
        ],
        "test/enginetest" => [
            "test/enginetest-bin-enginetest.o"
        ],
        "test/enginetest-bin-enginetest.o" => [
            "test/enginetest.c"
        ],
        "test/errtest" => [
            "test/errtest-bin-errtest.o"
        ],
        "test/errtest-bin-errtest.o" => [
            "test/errtest.c"
        ],
        "test/evp_byname_test" => [
            "test/evp_byname_test-bin-evp_byname_test.o"
        ],
        "test/evp_byname_test-bin-evp_byname_test.o" => [
            "test/evp_byname_test.c"
        ],
        "test/evp_extra_test" => [
            "providers/evp_extra_test-bin-legacyprov.o",
            "test/evp_extra_test-bin-evp_extra_test.o"
        ],
        "test/evp_extra_test-bin-evp_extra_test.o" => [
            "test/evp_extra_test.c"
        ],
        "test/evp_extra_test2" => [
            "test/evp_extra_test2-bin-evp_extra_test2.o"
        ],
        "test/evp_extra_test2-bin-evp_extra_test2.o" => [
            "test/evp_extra_test2.c"
        ],
        "test/evp_fetch_prov_test" => [
            "test/evp_fetch_prov_test-bin-evp_fetch_prov_test.o"
        ],
        "test/evp_fetch_prov_test-bin-evp_fetch_prov_test.o" => [
            "test/evp_fetch_prov_test.c"
        ],
        "test/evp_kdf_test" => [
            "test/evp_kdf_test-bin-evp_kdf_test.o"
        ],
        "test/evp_kdf_test-bin-evp_kdf_test.o" => [
            "test/evp_kdf_test.c"
        ],
        "test/evp_libctx_test" => [
            "test/evp_libctx_test-bin-evp_libctx_test.o"
        ],
        "test/evp_libctx_test-bin-evp_libctx_test.o" => [
            "test/evp_libctx_test.c"
        ],
        "test/evp_pkey_ctx_new_from_name" => [
            "test/evp_pkey_ctx_new_from_name-bin-evp_pkey_ctx_new_from_name.o"
        ],
        "test/evp_pkey_ctx_new_from_name-bin-evp_pkey_ctx_new_from_name.o" => [
            "test/evp_pkey_ctx_new_from_name.c"
        ],
        "test/evp_pkey_dparams_test" => [
            "test/evp_pkey_dparams_test-bin-evp_pkey_dparams_test.o"
        ],
        "test/evp_pkey_dparams_test-bin-evp_pkey_dparams_test.o" => [
            "test/evp_pkey_dparams_test.c"
        ],
        "test/evp_pkey_provided_test" => [
            "test/evp_pkey_provided_test-bin-evp_pkey_provided_test.o"
        ],
        "test/evp_pkey_provided_test-bin-evp_pkey_provided_test.o" => [
            "test/evp_pkey_provided_test.c"
        ],
        "test/evp_test" => [
            "test/evp_test-bin-evp_test.o"
        ],
        "test/evp_test-bin-evp_test.o" => [
            "test/evp_test.c"
        ],
        "test/exdatatest" => [
            "test/exdatatest-bin-exdatatest.o"
        ],
        "test/exdatatest-bin-exdatatest.o" => [
            "test/exdatatest.c"
        ],
        "test/exptest" => [
            "test/exptest-bin-exptest.o"
        ],
        "test/exptest-bin-exptest.o" => [
            "test/exptest.c"
        ],
        "test/ext_internal_test" => [
            "test/ext_internal_test-bin-ext_internal_test.o"
        ],
        "test/ext_internal_test-bin-ext_internal_test.o" => [
            "test/ext_internal_test.c"
        ],
        "test/fatalerrtest" => [
            "test/fatalerrtest-bin-fatalerrtest.o",
            "test/helpers/fatalerrtest-bin-ssltestlib.o"
        ],
        "test/fatalerrtest-bin-fatalerrtest.o" => [
            "test/fatalerrtest.c"
        ],
        "test/ffc_internal_test" => [
            "test/ffc_internal_test-bin-ffc_internal_test.o"
        ],
        "test/ffc_internal_test-bin-ffc_internal_test.o" => [
            "test/ffc_internal_test.c"
        ],
        "test/fips_version_test" => [
            "test/fips_version_test-bin-fips_version_test.o"
        ],
        "test/fips_version_test-bin-fips_version_test.o" => [
            "test/fips_version_test.c"
        ],
        "test/gmdifftest" => [
            "test/gmdifftest-bin-gmdifftest.o"
        ],
        "test/gmdifftest-bin-gmdifftest.o" => [
            "test/gmdifftest.c"
        ],
        "test/helpers/asynciotest-bin-ssltestlib.o" => [
            "test/helpers/ssltestlib.c"
        ],
        "test/helpers/cmp_asn_test-bin-cmp_testlib.o" => [
            "test/helpers/cmp_testlib.c"
        ],
        "test/helpers/cmp_client_test-bin-cmp_testlib.o" => [
            "test/helpers/cmp_testlib.c"
        ],
        "test/helpers/cmp_ctx_test-bin-cmp_testlib.o" => [
            "test/helpers/cmp_testlib.c"
        ],
        "test/helpers/cmp_hdr_test-bin-cmp_testlib.o" => [
            "test/helpers/cmp_testlib.c"
        ],
        "test/helpers/cmp_msg_test-bin-cmp_testlib.o" => [
            "test/helpers/cmp_testlib.c"
        ],
        "test/helpers/cmp_protect_test-bin-cmp_testlib.o" => [
            "test/helpers/cmp_testlib.c"
        ],
        "test/helpers/cmp_server_test-bin-cmp_testlib.o" => [
            "test/helpers/cmp_testlib.c"
        ],
        "test/helpers/cmp_status_test-bin-cmp_testlib.o" => [
            "test/helpers/cmp_testlib.c"
        ],
        "test/helpers/cmp_vfy_test-bin-cmp_testlib.o" => [
            "test/helpers/cmp_testlib.c"
        ],
        "test/helpers/dtls_mtu_test-bin-ssltestlib.o" => [
            "test/helpers/ssltestlib.c"
        ],
        "test/helpers/dtlstest-bin-ssltestlib.o" => [
            "test/helpers/ssltestlib.c"
        ],
        "test/helpers/endecode_test-bin-predefined_dhparams.o" => [
            "test/helpers/predefined_dhparams.c"
        ],
        "test/helpers/fatalerrtest-bin-ssltestlib.o" => [
            "test/helpers/ssltestlib.c"
        ],
        "test/helpers/pkcs12_format_test-bin-pkcs12.o" => [
            "test/helpers/pkcs12.c"
        ],
        "test/helpers/recordlentest-bin-ssltestlib.o" => [
            "test/helpers/ssltestlib.c"
        ],
        "test/helpers/servername_test-bin-ssltestlib.o" => [
            "test/helpers/ssltestlib.c"
        ],
        "test/helpers/ssl_old_test-bin-predefined_dhparams.o" => [
            "test/helpers/predefined_dhparams.c"
        ],
        "test/helpers/ssl_test-bin-handshake.o" => [
            "test/helpers/handshake.c"
        ],
        "test/helpers/ssl_test-bin-handshake_srp.o" => [
            "test/helpers/handshake_srp.c"
        ],
        "test/helpers/ssl_test-bin-ssl_test_ctx.o" => [
            "test/helpers/ssl_test_ctx.c"
        ],
        "test/helpers/ssl_test_ctx_test-bin-ssl_test_ctx.o" => [
            "test/helpers/ssl_test_ctx.c"
        ],
        "test/helpers/sslapitest-bin-ssltestlib.o" => [
            "test/helpers/ssltestlib.c"
        ],
        "test/helpers/sslbuffertest-bin-ssltestlib.o" => [
            "test/helpers/ssltestlib.c"
        ],
        "test/helpers/sslcorrupttest-bin-ssltestlib.o" => [
            "test/helpers/ssltestlib.c"
        ],
        "test/helpers/tls13ccstest-bin-ssltestlib.o" => [
            "test/helpers/ssltestlib.c"
        ],
        "test/hexstr_test" => [
            "test/hexstr_test-bin-hexstr_test.o"
        ],
        "test/hexstr_test-bin-hexstr_test.o" => [
            "test/hexstr_test.c"
        ],
        "test/hmactest" => [
            "test/hmactest-bin-hmactest.o"
        ],
        "test/hmactest-bin-hmactest.o" => [
            "test/hmactest.c"
        ],
        "test/http_test" => [
            "test/http_test-bin-http_test.o"
        ],
        "test/http_test-bin-http_test.o" => [
            "test/http_test.c"
        ],
        "test/ideatest" => [
            "test/ideatest-bin-ideatest.o"
        ],
        "test/ideatest-bin-ideatest.o" => [
            "test/ideatest.c"
        ],
        "test/igetest" => [
            "test/igetest-bin-igetest.o"
        ],
        "test/igetest-bin-igetest.o" => [
            "test/igetest.c"
        ],
        "test/keymgmt_internal_test" => [
            "test/keymgmt_internal_test-bin-keymgmt_internal_test.o"
        ],
        "test/keymgmt_internal_test-bin-keymgmt_internal_test.o" => [
            "test/keymgmt_internal_test.c"
        ],
        "test/lhash_test" => [
            "test/lhash_test-bin-lhash_test.o"
        ],
        "test/lhash_test-bin-lhash_test.o" => [
            "test/lhash_test.c"
        ],
        "test/libtestutil.a" => [
            "apps/lib/libtestutil-lib-opt.o",
            "test/testutil/libtestutil-lib-apps_shims.o",
            "test/testutil/libtestutil-lib-basic_output.o",
            "test/testutil/libtestutil-lib-cb.o",
            "test/testutil/libtestutil-lib-driver.o",
            "test/testutil/libtestutil-lib-fake_random.o",
            "test/testutil/libtestutil-lib-format_output.o",
            "test/testutil/libtestutil-lib-load.o",
            "test/testutil/libtestutil-lib-main.o",
            "test/testutil/libtestutil-lib-options.o",
            "test/testutil/libtestutil-lib-output.o",
            "test/testutil/libtestutil-lib-provider.o",
            "test/testutil/libtestutil-lib-random.o",
            "test/testutil/libtestutil-lib-stanza.o",
            "test/testutil/libtestutil-lib-test_cleanup.o",
            "test/testutil/libtestutil-lib-test_options.o",
            "test/testutil/libtestutil-lib-tests.o",
            "test/testutil/libtestutil-lib-testutil_init.o"
        ],
        "test/localetest" => [
            "test/localetest-bin-localetest.o"
        ],
        "test/localetest-bin-localetest.o" => [
            "test/localetest.c"
        ],
        "test/mdc2_internal_test" => [
            "test/mdc2_internal_test-bin-mdc2_internal_test.o"
        ],
        "test/mdc2_internal_test-bin-mdc2_internal_test.o" => [
            "test/mdc2_internal_test.c"
        ],
        "test/mdc2test" => [
            "test/mdc2test-bin-mdc2test.o"
        ],
        "test/mdc2test-bin-mdc2test.o" => [
            "test/mdc2test.c"
        ],
        "test/memleaktest" => [
            "test/memleaktest-bin-memleaktest.o"
        ],
        "test/memleaktest-bin-memleaktest.o" => [
            "test/memleaktest.c"
        ],
        "test/modes_internal_test" => [
            "test/modes_internal_test-bin-modes_internal_test.o"
        ],
        "test/modes_internal_test-bin-modes_internal_test.o" => [
            "test/modes_internal_test.c"
        ],
        "test/namemap_internal_test" => [
            "test/namemap_internal_test-bin-namemap_internal_test.o"
        ],
        "test/namemap_internal_test-bin-namemap_internal_test.o" => [
            "test/namemap_internal_test.c"
        ],
        "test/nodefltctxtest" => [
            "test/nodefltctxtest-bin-nodefltctxtest.o"
        ],
        "test/nodefltctxtest-bin-nodefltctxtest.o" => [
            "test/nodefltctxtest.c"
        ],
        "test/ocspapitest" => [
            "test/ocspapitest-bin-ocspapitest.o"
        ],
        "test/ocspapitest-bin-ocspapitest.o" => [
            "test/ocspapitest.c"
        ],
        "test/ossl_store_test" => [
            "test/ossl_store_test-bin-ossl_store_test.o"
        ],
        "test/ossl_store_test-bin-ossl_store_test.o" => [
            "test/ossl_store_test.c"
        ],
        "test/p_minimal" => [
            "test/p_minimal-dso-p_minimal.o",
            "test/p_minimal.ld"
        ],
        "test/p_minimal-dso-p_minimal.o" => [
            "test/p_minimal.c"
        ],
        "test/p_test" => [
            "test/p_test-dso-p_test.o",
            "test/p_test.ld"
        ],
        "test/p_test-dso-p_test.o" => [
            "test/p_test.c"
        ],
        "test/packettest" => [
            "test/packettest-bin-packettest.o"
        ],
        "test/packettest-bin-packettest.o" => [
            "test/packettest.c"
        ],
        "test/param_build_test" => [
            "test/param_build_test-bin-param_build_test.o"
        ],
        "test/param_build_test-bin-param_build_test.o" => [
            "test/param_build_test.c"
        ],
        "test/params_api_test" => [
            "test/params_api_test-bin-params_api_test.o"
        ],
        "test/params_api_test-bin-params_api_test.o" => [
            "test/params_api_test.c"
        ],
        "test/params_conversion_test" => [
            "test/params_conversion_test-bin-params_conversion_test.o"
        ],
        "test/params_conversion_test-bin-params_conversion_test.o" => [
            "test/params_conversion_test.c"
        ],
        "test/params_test" => [
            "test/params_test-bin-params_test.o"
        ],
        "test/params_test-bin-params_test.o" => [
            "test/params_test.c"
        ],
        "test/pbelutest" => [
            "test/pbelutest-bin-pbelutest.o"
        ],
        "test/pbelutest-bin-pbelutest.o" => [
            "test/pbelutest.c"
        ],
        "test/pbetest" => [
            "test/pbetest-bin-pbetest.o"
        ],
        "test/pbetest-bin-pbetest.o" => [
            "test/pbetest.c"
        ],
        "test/pem_read_depr_test" => [
            "test/pem_read_depr_test-bin-pem_read_depr_test.o"
        ],
        "test/pem_read_depr_test-bin-pem_read_depr_test.o" => [
            "test/pem_read_depr_test.c"
        ],
        "test/pemtest" => [
            "test/pemtest-bin-pemtest.o"
        ],
        "test/pemtest-bin-pemtest.o" => [
            "test/pemtest.c"
        ],
        "test/pkcs12_format_test" => [
            "test/helpers/pkcs12_format_test-bin-pkcs12.o",
            "test/pkcs12_format_test-bin-pkcs12_format_test.o"
        ],
        "test/pkcs12_format_test-bin-pkcs12_format_test.o" => [
            "test/pkcs12_format_test.c"
        ],
        "test/pkcs7_test" => [
            "test/pkcs7_test-bin-pkcs7_test.o"
        ],
        "test/pkcs7_test-bin-pkcs7_test.o" => [
            "test/pkcs7_test.c"
        ],
        "test/pkey_meth_kdf_test" => [
            "test/pkey_meth_kdf_test-bin-pkey_meth_kdf_test.o"
        ],
        "test/pkey_meth_kdf_test-bin-pkey_meth_kdf_test.o" => [
            "test/pkey_meth_kdf_test.c"
        ],
        "test/pkey_meth_test" => [
            "test/pkey_meth_test-bin-pkey_meth_test.o"
        ],
        "test/pkey_meth_test-bin-pkey_meth_test.o" => [
            "test/pkey_meth_test.c"
        ],
        "test/poly1305_internal_test" => [
            "test/poly1305_internal_test-bin-poly1305_internal_test.o"
        ],
        "test/poly1305_internal_test-bin-poly1305_internal_test.o" => [
            "test/poly1305_internal_test.c"
        ],
        "test/property_test" => [
            "test/property_test-bin-property_test.o"
        ],
        "test/property_test-bin-property_test.o" => [
            "test/property_test.c"
        ],
        "test/prov_config_test" => [
            "test/prov_config_test-bin-prov_config_test.o"
        ],
        "test/prov_config_test-bin-prov_config_test.o" => [
            "test/prov_config_test.c"
        ],
        "test/provfetchtest" => [
            "test/provfetchtest-bin-provfetchtest.o"
        ],
        "test/provfetchtest-bin-provfetchtest.o" => [
            "test/provfetchtest.c"
        ],
        "test/provider_fallback_test" => [
            "test/provider_fallback_test-bin-provider_fallback_test.o"
        ],
        "test/provider_fallback_test-bin-provider_fallback_test.o" => [
            "test/provider_fallback_test.c"
        ],
        "test/provider_internal_test" => [
            "test/provider_internal_test-bin-p_test.o",
            "test/provider_internal_test-bin-provider_internal_test.o"
        ],
        "test/provider_internal_test-bin-p_test.o" => [
            "test/p_test.c"
        ],
        "test/provider_internal_test-bin-provider_internal_test.o" => [
            "test/provider_internal_test.c"
        ],
        "test/provider_pkey_test" => [
            "test/provider_pkey_test-bin-fake_rsaprov.o",
            "test/provider_pkey_test-bin-provider_pkey_test.o"
        ],
        "test/provider_pkey_test-bin-fake_rsaprov.o" => [
            "test/fake_rsaprov.c"
        ],
        "test/provider_pkey_test-bin-provider_pkey_test.o" => [
            "test/provider_pkey_test.c"
        ],
        "test/provider_status_test" => [
            "test/provider_status_test-bin-provider_status_test.o"
        ],
        "test/provider_status_test-bin-provider_status_test.o" => [
            "test/provider_status_test.c"
        ],
        "test/provider_test" => [
            "test/provider_test-bin-p_test.o",
            "test/provider_test-bin-provider_test.o"
        ],
        "test/provider_test-bin-p_test.o" => [
            "test/p_test.c"
        ],
        "test/provider_test-bin-provider_test.o" => [
            "test/provider_test.c"
        ],
        "test/punycode_test" => [
            "test/punycode_test-bin-punycode_test.o"
        ],
        "test/punycode_test-bin-punycode_test.o" => [
            "test/punycode_test.c"
        ],
        "test/rand_status_test" => [
            "test/rand_status_test-bin-rand_status_test.o"
        ],
        "test/rand_status_test-bin-rand_status_test.o" => [
            "test/rand_status_test.c"
        ],
        "test/rand_test" => [
            "test/rand_test-bin-rand_test.o"
        ],
        "test/rand_test-bin-rand_test.o" => [
            "test/rand_test.c"
        ],
        "test/rc2test" => [
            "test/rc2test-bin-rc2test.o"
        ],
        "test/rc2test-bin-rc2test.o" => [
            "test/rc2test.c"
        ],
        "test/rc4test" => [
            "test/rc4test-bin-rc4test.o"
        ],
        "test/rc4test-bin-rc4test.o" => [
            "test/rc4test.c"
        ],
        "test/rc5test" => [
            "test/rc5test-bin-rc5test.o"
        ],
        "test/rc5test-bin-rc5test.o" => [
            "test/rc5test.c"
        ],
        "test/rdrand_sanitytest" => [
            "test/rdrand_sanitytest-bin-rdrand_sanitytest.o"
        ],
        "test/rdrand_sanitytest-bin-rdrand_sanitytest.o" => [
            "test/rdrand_sanitytest.c"
        ],
        "test/recordlentest" => [
            "test/helpers/recordlentest-bin-ssltestlib.o",
            "test/recordlentest-bin-recordlentest.o"
        ],
        "test/recordlentest-bin-recordlentest.o" => [
            "test/recordlentest.c"
        ],
        "test/rsa_complex" => [
            "test/rsa_complex-bin-rsa_complex.o"
        ],
        "test/rsa_complex-bin-rsa_complex.o" => [
            "test/rsa_complex.c"
        ],
        "test/rsa_mp_test" => [
            "test/rsa_mp_test-bin-rsa_mp_test.o"
        ],
        "test/rsa_mp_test-bin-rsa_mp_test.o" => [
            "test/rsa_mp_test.c"
        ],
        "test/rsa_sp800_56b_test" => [
            "test/rsa_sp800_56b_test-bin-rsa_sp800_56b_test.o"
        ],
        "test/rsa_sp800_56b_test-bin-rsa_sp800_56b_test.o" => [
            "test/rsa_sp800_56b_test.c"
        ],
        "test/rsa_test" => [
            "test/rsa_test-bin-rsa_test.o"
        ],
        "test/rsa_test-bin-rsa_test.o" => [
            "test/rsa_test.c"
        ],
        "test/sanitytest" => [
            "test/sanitytest-bin-sanitytest.o"
        ],
        "test/sanitytest-bin-sanitytest.o" => [
            "test/sanitytest.c"
        ],
        "test/secmemtest" => [
            "test/secmemtest-bin-secmemtest.o"
        ],
        "test/secmemtest-bin-secmemtest.o" => [
            "test/secmemtest.c"
        ],
        "test/servername_test" => [
            "test/helpers/servername_test-bin-ssltestlib.o",
            "test/servername_test-bin-servername_test.o"
        ],
        "test/servername_test-bin-servername_test.o" => [
            "test/servername_test.c"
        ],
        "test/sha_test" => [
            "test/sha_test-bin-sha_test.o"
        ],
        "test/sha_test-bin-sha_test.o" => [
            "test/sha_test.c"
        ],
        "test/siphash_internal_test" => [
            "test/siphash_internal_test-bin-siphash_internal_test.o"
        ],
        "test/siphash_internal_test-bin-siphash_internal_test.o" => [
            "test/siphash_internal_test.c"
        ],
        "test/sm2_internal_test" => [
            "test/sm2_internal_test-bin-sm2_internal_test.o"
        ],
        "test/sm2_internal_test-bin-sm2_internal_test.o" => [
            "test/sm2_internal_test.c"
        ],
        "test/sm3_internal_test" => [
            "test/sm3_internal_test-bin-sm3_internal_test.o"
        ],
        "test/sm3_internal_test-bin-sm3_internal_test.o" => [
            "test/sm3_internal_test.c"
        ],
        "test/sm4_internal_test" => [
            "test/sm4_internal_test-bin-sm4_internal_test.o"
        ],
        "test/sm4_internal_test-bin-sm4_internal_test.o" => [
            "test/sm4_internal_test.c"
        ],
        "test/sparse_array_test" => [
            "test/sparse_array_test-bin-sparse_array_test.o"
        ],
        "test/sparse_array_test-bin-sparse_array_test.o" => [
            "test/sparse_array_test.c"
        ],
        "test/srptest" => [
            "test/srptest-bin-srptest.o"
        ],
        "test/srptest-bin-srptest.o" => [
            "test/srptest.c"
        ],
        "test/ssl_cert_table_internal_test" => [
            "test/ssl_cert_table_internal_test-bin-ssl_cert_table_internal_test.o"
        ],
        "test/ssl_cert_table_internal_test-bin-ssl_cert_table_internal_test.o" => [
            "test/ssl_cert_table_internal_test.c"
        ],
        "test/ssl_ctx_test" => [
            "test/ssl_ctx_test-bin-ssl_ctx_test.o"
        ],
        "test/ssl_ctx_test-bin-ssl_ctx_test.o" => [
            "test/ssl_ctx_test.c"
        ],
        "test/ssl_old_test" => [
            "test/helpers/ssl_old_test-bin-predefined_dhparams.o",
            "test/ssl_old_test-bin-ssl_old_test.o"
        ],
        "test/ssl_old_test-bin-ssl_old_test.o" => [
            "test/ssl_old_test.c"
        ],
        "test/ssl_test" => [
            "test/helpers/ssl_test-bin-handshake.o",
            "test/helpers/ssl_test-bin-handshake_srp.o",
            "test/helpers/ssl_test-bin-ssl_test_ctx.o",
            "test/ssl_test-bin-ssl_test.o"
        ],
        "test/ssl_test-bin-ssl_test.o" => [
            "test/ssl_test.c"
        ],
        "test/ssl_test_ctx_test" => [
            "test/helpers/ssl_test_ctx_test-bin-ssl_test_ctx.o",
            "test/ssl_test_ctx_test-bin-ssl_test_ctx_test.o"
        ],
        "test/ssl_test_ctx_test-bin-ssl_test_ctx_test.o" => [
            "test/ssl_test_ctx_test.c"
        ],
        "test/sslapitest" => [
            "test/helpers/sslapitest-bin-ssltestlib.o",
            "test/sslapitest-bin-filterprov.o",
            "test/sslapitest-bin-sslapitest.o",
            "test/sslapitest-bin-tls-provider.o"
        ],
        "test/sslapitest-bin-filterprov.o" => [
            "test/filterprov.c"
        ],
        "test/sslapitest-bin-sslapitest.o" => [
            "test/sslapitest.c"
        ],
        "test/sslapitest-bin-tls-provider.o" => [
            "test/tls-provider.c"
        ],
        "test/sslbuffertest" => [
            "test/helpers/sslbuffertest-bin-ssltestlib.o",
            "test/sslbuffertest-bin-sslbuffertest.o"
        ],
        "test/sslbuffertest-bin-sslbuffertest.o" => [
            "test/sslbuffertest.c"
        ],
        "test/sslcorrupttest" => [
            "test/helpers/sslcorrupttest-bin-ssltestlib.o",
            "test/sslcorrupttest-bin-sslcorrupttest.o"
        ],
        "test/sslcorrupttest-bin-sslcorrupttest.o" => [
            "test/sslcorrupttest.c"
        ],
        "test/stack_test" => [
            "test/stack_test-bin-stack_test.o"
        ],
        "test/stack_test-bin-stack_test.o" => [
            "test/stack_test.c"
        ],
        "test/sysdefaulttest" => [
            "test/sysdefaulttest-bin-sysdefaulttest.o"
        ],
        "test/sysdefaulttest-bin-sysdefaulttest.o" => [
            "test/sysdefaulttest.c"
        ],
        "test/test_test" => [
            "test/test_test-bin-test_test.o"
        ],
        "test/test_test-bin-test_test.o" => [
            "test/test_test.c"
        ],
        "test/testutil/libtestutil-lib-apps_shims.o" => [
            "test/testutil/apps_shims.c"
        ],
        "test/testutil/libtestutil-lib-basic_output.o" => [
            "test/testutil/basic_output.c"
        ],
        "test/testutil/libtestutil-lib-cb.o" => [
            "test/testutil/cb.c"
        ],
        "test/testutil/libtestutil-lib-driver.o" => [
            "test/testutil/driver.c"
        ],
        "test/testutil/libtestutil-lib-fake_random.o" => [
            "test/testutil/fake_random.c"
        ],
        "test/testutil/libtestutil-lib-format_output.o" => [
            "test/testutil/format_output.c"
        ],
        "test/testutil/libtestutil-lib-load.o" => [
            "test/testutil/load.c"
        ],
        "test/testutil/libtestutil-lib-main.o" => [
            "test/testutil/main.c"
        ],
        "test/testutil/libtestutil-lib-options.o" => [
            "test/testutil/options.c"
        ],
        "test/testutil/libtestutil-lib-output.o" => [
            "test/testutil/output.c"
        ],
        "test/testutil/libtestutil-lib-provider.o" => [
            "test/testutil/provider.c"
        ],
        "test/testutil/libtestutil-lib-random.o" => [
            "test/testutil/random.c"
        ],
        "test/testutil/libtestutil-lib-stanza.o" => [
            "test/testutil/stanza.c"
        ],
        "test/testutil/libtestutil-lib-test_cleanup.o" => [
            "test/testutil/test_cleanup.c"
        ],
        "test/testutil/libtestutil-lib-test_options.o" => [
            "test/testutil/test_options.c"
        ],
        "test/testutil/libtestutil-lib-tests.o" => [
            "test/testutil/tests.c"
        ],
        "test/testutil/libtestutil-lib-testutil_init.o" => [
            "test/testutil/testutil_init.c"
        ],
        "test/threadstest" => [
            "test/threadstest-bin-threadstest.o"
        ],
        "test/threadstest-bin-threadstest.o" => [
            "test/threadstest.c"
        ],
        "test/threadstest_fips" => [
            "test/threadstest_fips-bin-threadstest_fips.o"
        ],
        "test/threadstest_fips-bin-threadstest_fips.o" => [
            "test/threadstest_fips.c"
        ],
        "test/time_offset_test" => [
            "test/time_offset_test-bin-time_offset_test.o"
        ],
        "test/time_offset_test-bin-time_offset_test.o" => [
            "test/time_offset_test.c"
        ],
        "test/tls13ccstest" => [
            "test/helpers/tls13ccstest-bin-ssltestlib.o",
            "test/tls13ccstest-bin-tls13ccstest.o"
        ],
        "test/tls13ccstest-bin-tls13ccstest.o" => [
            "test/tls13ccstest.c"
        ],
        "test/tls13encryptiontest" => [
            "test/tls13encryptiontest-bin-tls13encryptiontest.o"
        ],
        "test/tls13encryptiontest-bin-tls13encryptiontest.o" => [
            "test/tls13encryptiontest.c"
        ],
        "test/trace_api_test" => [
            "test/trace_api_test-bin-trace_api_test.o"
        ],
        "test/trace_api_test-bin-trace_api_test.o" => [
            "test/trace_api_test.c"
        ],
        "test/uitest" => [
            "apps/lib/uitest-bin-apps_ui.o",
            "test/uitest-bin-uitest.o"
        ],
        "test/uitest-bin-uitest.o" => [
            "test/uitest.c"
        ],
        "test/upcallstest" => [
            "test/upcallstest-bin-upcallstest.o"
        ],
        "test/upcallstest-bin-upcallstest.o" => [
            "test/upcallstest.c"
        ],
        "test/user_property_test" => [
            "test/user_property_test-bin-user_property_test.o"
        ],
        "test/user_property_test-bin-user_property_test.o" => [
            "test/user_property_test.c"
        ],
        "test/v3ext" => [
            "test/v3ext-bin-v3ext.o"
        ],
        "test/v3ext-bin-v3ext.o" => [
            "test/v3ext.c"
        ],
        "test/v3nametest" => [
            "test/v3nametest-bin-v3nametest.o"
        ],
        "test/v3nametest-bin-v3nametest.o" => [
            "test/v3nametest.c"
        ],
        "test/verify_extra_test" => [
            "test/verify_extra_test-bin-verify_extra_test.o"
        ],
        "test/verify_extra_test-bin-verify_extra_test.o" => [
            "test/verify_extra_test.c"
        ],
        "test/versions" => [
            "test/versions-bin-versions.o"
        ],
        "test/versions-bin-versions.o" => [
            "test/versions.c"
        ],
        "test/wpackettest" => [
            "test/wpackettest-bin-wpackettest.o"
        ],
        "test/wpackettest-bin-wpackettest.o" => [
            "test/wpackettest.c"
        ],
        "test/x509_check_cert_pkey_test" => [
            "test/x509_check_cert_pkey_test-bin-x509_check_cert_pkey_test.o"
        ],
        "test/x509_check_cert_pkey_test-bin-x509_check_cert_pkey_test.o" => [
            "test/x509_check_cert_pkey_test.c"
        ],
        "test/x509_dup_cert_test" => [
            "test/x509_dup_cert_test-bin-x509_dup_cert_test.o"
        ],
        "test/x509_dup_cert_test-bin-x509_dup_cert_test.o" => [
            "test/x509_dup_cert_test.c"
        ],
        "test/x509_internal_test" => [
            "test/x509_internal_test-bin-x509_internal_test.o"
        ],
        "test/x509_internal_test-bin-x509_internal_test.o" => [
            "test/x509_internal_test.c"
        ],
        "test/x509_time_test" => [
            "test/x509_time_test-bin-x509_time_test.o"
        ],
        "test/x509_time_test-bin-x509_time_test.o" => [
            "test/x509_time_test.c"
        ],
        "test/x509aux" => [
            "test/x509aux-bin-x509aux.o"
        ],
        "test/x509aux-bin-x509aux.o" => [
            "test/x509aux.c"
        ],
        "tools/c_rehash" => [
            "tools/c_rehash.in"
        ],
        "util/shlib_wrap.sh" => [
            "util/shlib_wrap.sh.in"
        ],
        "util/wrap.pl" => [
            "util/wrap.pl.in"
        ]
    },
    "targets" => [
        "build_modules_nodep"
    ]
);

# Unexported, only used by OpenSSL::Test::Utils::available_protocols()
our %available_protocols = (
    tls  => [
    "ssl3",
    "tls1",
    "tls1_1",
    "tls1_2",
    "tls1_3"
],
    dtls => [
    "dtls1",
    "dtls1_2"
],
);

# The following data is only used when this files is use as a script
my @makevars = (
    "AR",
    "ARFLAGS",
    "AS",
    "ASFLAGS",
    "CC",
    "CFLAGS",
    "CPP",
    "CPPDEFINES",
    "CPPFLAGS",
    "CPPINCLUDES",
    "CROSS_COMPILE",
    "CXX",
    "CXXFLAGS",
    "HASHBANGPERL",
    "LD",
    "LDFLAGS",
    "LDLIBS",
    "MT",
    "MTFLAGS",
    "PERL",
    "RANLIB",
    "RC",
    "RCFLAGS",
    "RM"
);
my %disabled_info = (
    "afalgeng" => {
        "macro" => "OPENSSL_NO_AFALGENG"
    },
    "asan" => {
        "macro" => "OPENSSL_NO_ASAN"
    },
    "comp" => {
        "macro" => "OPENSSL_NO_COMP",
        "skipped" => [
            "crypto/comp"
        ]
    },
    "crypto-mdebug" => {
        "macro" => "OPENSSL_NO_CRYPTO_MDEBUG"
    },
    "crypto-mdebug-backtrace" => {
        "macro" => "OPENSSL_NO_CRYPTO_MDEBUG_BACKTRACE"
    },
    "devcryptoeng" => {
        "macro" => "OPENSSL_NO_DEVCRYPTOENG"
    },
    "ec_nistp_64_gcc_128" => {
        "macro" => "OPENSSL_NO_EC_NISTP_64_GCC_128"
    },
    "egd" => {
        "macro" => "OPENSSL_NO_EGD"
    },
    "external-tests" => {
        "macro" => "OPENSSL_NO_EXTERNAL_TESTS"
    },
    "fuzz-afl" => {
        "macro" => "OPENSSL_NO_FUZZ_AFL"
    },
    "fuzz-libfuzzer" => {
        "macro" => "OPENSSL_NO_FUZZ_LIBFUZZER"
    },
    "ktls" => {
        "macro" => "OPENSSL_NO_KTLS"
    },
    "loadereng" => {
        "macro" => "OPENSSL_NO_LOADERENG"
    },
    "md2" => {
        "macro" => "OPENSSL_NO_MD2",
        "skipped" => [
            "crypto/md2"
        ]
    },
    "msan" => {
        "macro" => "OPENSSL_NO_MSAN"
    },
    "rc5" => {
        "macro" => "OPENSSL_NO_RC5",
        "skipped" => [
            "crypto/rc5"
        ]
    },
    "sctp" => {
        "macro" => "OPENSSL_NO_SCTP"
    },
    "ssl3" => {
        "macro" => "OPENSSL_NO_SSL3"
    },
    "ssl3-method" => {
        "macro" => "OPENSSL_NO_SSL3_METHOD"
    },
    "trace" => {
        "macro" => "OPENSSL_NO_TRACE"
    },
    "ubsan" => {
        "macro" => "OPENSSL_NO_UBSAN"
    },
    "unit-test" => {
        "macro" => "OPENSSL_NO_UNIT_TEST"
    },
    "uplink" => {
        "macro" => "OPENSSL_NO_UPLINK"
    },
    "weak-ssl-ciphers" => {
        "macro" => "OPENSSL_NO_WEAK_SSL_CIPHERS"
    }
);
my @user_crossable = qw( AR AS CC CXX CPP LD MT RANLIB RC );

# If run directly, we can give some answers, and even reconfigure
unless (caller) {
    use Getopt::Long;
    use File::Spec::Functions;
    use File::Basename;
    use File::Compare qw(compare_text);
    use File::Copy;
    use Pod::Usage;

    use lib '/home/runner/work/node/node/deps/openssl/openssl/util/perl';
    use OpenSSL::fallback '/home/runner/work/node/node/deps/openssl/openssl/external/perl/MODULES.txt';

    my $here = dirname($0);

    if (scalar @ARGV == 0) {
        # With no arguments, re-create the build file
        # We do that in two steps, where the first step emits perl
        # snipets.

        my $buildfile = $config{build_file};
        my $buildfile_template = "$buildfile.in";
        my @autowarntext = (
            'WARNING: do not edit!',
            "Generated by configdata.pm from "
            .join(", ", @{$config{build_file_templates}}),
            "via $buildfile_template"
        );
        my %gendata = (
            config => \%config,
            target => \%target,
            disabled => \%disabled,
            withargs => \%withargs,
            unified_info => \%unified_info,
            autowarntext => \@autowarntext,
            );

        use lib '.';
        use lib '/home/runner/work/node/node/deps/openssl/openssl/Configurations';
        use gentemplate;

        open my $buildfile_template_fh, ">$buildfile_template"
            or die "Trying to create $buildfile_template: $!";
        foreach (@{$config{build_file_templates}}) {
            copy($_, $buildfile_template_fh)
                or die "Trying to copy $_ into $buildfile_template: $!";
        }
        gentemplate(output => $buildfile_template_fh, %gendata);
        close $buildfile_template_fh;
        print 'Created ',$buildfile_template,"\n";

        use OpenSSL::Template;

        my $prepend = <<'_____';
use File::Spec::Functions;
use lib '/home/runner/work/node/node/deps/openssl/openssl/util/perl';
use lib '/home/runner/work/node/node/deps/openssl/openssl/Configurations';
use lib '.';
use platform;
_____

        my $tmpl;
        open BUILDFILE, ">$buildfile.new"
            or die "Trying to create $buildfile.new: $!";
        $tmpl = OpenSSL::Template->new(TYPE => 'FILE',
                                       SOURCE => $buildfile_template);
        $tmpl->fill_in(FILENAME => $_,
                       OUTPUT => \*BUILDFILE,
                       HASH => \%gendata,
                       PREPEND => $prepend,
                       # To ensure that global variables and functions
                       # defined in one template stick around for the
                       # next, making them combinable
                       PACKAGE => 'OpenSSL::safe')
            or die $Text::Template::ERROR;
        close BUILDFILE;
        rename("$buildfile.new", $buildfile)
            or die "Trying to rename $buildfile.new to $buildfile: $!";
        print 'Created ',$buildfile,"\n";

        my $configuration_h =
            catfile('include', 'openssl', 'configuration.h');
        my $configuration_h_in =
            catfile($config{sourcedir}, 'include', 'openssl', 'configuration.h.in');
        open CONFIGURATION_H, ">${configuration_h}.new"
            or die "Trying to create ${configuration_h}.new: $!";
        $tmpl = OpenSSL::Template->new(TYPE => 'FILE',
                                       SOURCE => $configuration_h_in);
        $tmpl->fill_in(FILENAME => $_,
                       OUTPUT => \*CONFIGURATION_H,
                       HASH => \%gendata,
                       PREPEND => $prepend,
                       # To ensure that global variables and functions
                       # defined in one template stick around for the
                       # next, making them combinable
                       PACKAGE => 'OpenSSL::safe')
            or die $Text::Template::ERROR;
        close CONFIGURATION_H;

        # When using stat() on Windows, we can get it to perform better by
        # avoid some data.  This doesn't affect the mtime field, so we're not
        # losing anything...
        ${^WIN32_SLOPPY_STAT} = 1;

        my $update_configuration_h = 0;
        if (-f $configuration_h) {
            my $configuration_h_mtime = (stat($configuration_h))[9];
            my $configuration_h_in_mtime = (stat($configuration_h_in))[9];

            # If configuration.h.in was updated after the last configuration.h,
            # or if configuration.h.new differs configuration.h, we update
            # configuration.h
            if ($configuration_h_mtime < $configuration_h_in_mtime
                || compare_text("${configuration_h}.new", $configuration_h) != 0) {
                $update_configuration_h = 1;
            } else {
                # If nothing has changed, let's just drop the new one and
                # pretend like nothing happened
                unlink "${configuration_h}.new"
            }
        } else {
            $update_configuration_h = 1;
        }

        if ($update_configuration_h) {
            rename("${configuration_h}.new", $configuration_h)
                or die "Trying to rename ${configuration_h}.new to $configuration_h: $!";
            print 'Created ',$configuration_h,"\n";
        }

        exit(0);
    }

    my $dump = undef;
    my $cmdline = undef;
    my $options = undef;
    my $target = undef;
    my $envvars = undef;
    my $makevars = undef;
    my $buildparams = undef;
    my $reconf = undef;
    my $verbose = undef;
    my $query = undef;
    my $help = undef;
    my $man = undef;
    GetOptions('dump|d'                 => \$dump,
               'command-line|c'         => \$cmdline,
               'options|o'              => \$options,
               'target|t'               => \$target,
               'environment|e'          => \$envvars,
               'make-variables|m'       => \$makevars,
               'build-parameters|b'     => \$buildparams,
               'reconfigure|reconf|r'   => \$reconf,
               'verbose|v'              => \$verbose,
               'query|q=s'              => \$query,
               'help'                   => \$help,
               'man'                    => \$man)
        or die "Errors in command line arguments\n";

    # We allow extra arguments with --query.  That allows constructs like
    # this:
    # ./configdata.pm --query 'get_sources(@ARGV)' file1 file2 file3
    if (!$query && scalar @ARGV > 0) {
        print STDERR <<"_____";
Unrecognised arguments.
For more information, do '$0 --help'
_____
        exit(2);
    }

    if ($help) {
        pod2usage(-exitval => 0,
                  -verbose => 1);
    }
    if ($man) {
        pod2usage(-exitval => 0,
                  -verbose => 2);
    }
    if ($dump || $cmdline) {
        print "\nCommand line (with current working directory = $here):\n\n";
        print '    ',join(' ',
                          $config{PERL},
                          catfile($config{sourcedir}, 'Configure'),
                          @{$config{perlargv}}), "\n";
        print "\nPerl information:\n\n";
        print '    ',$config{perl_cmd},"\n";
        print '    ',$config{perl_version},' for ',$config{perl_archname},"\n";
    }
    if ($dump || $options) {
        my $longest = 0;
        my $longest2 = 0;
        foreach my $what (@disablables) {
            $longest = length($what) if $longest < length($what);
            $longest2 = length($disabled{$what})
                if $disabled{$what} && $longest2 < length($disabled{$what});
        }
        print "\nEnabled features:\n\n";
        foreach my $what (@disablables) {
            print "    $what\n" unless $disabled{$what};
        }
        print "\nDisabled features:\n\n";
        foreach my $what (@disablables) {
            if ($disabled{$what}) {
                print "    $what", ' ' x ($longest - length($what) + 1),
                    "[$disabled{$what}]", ' ' x ($longest2 - length($disabled{$what}) + 1);
                print $disabled_info{$what}->{macro}
                    if $disabled_info{$what}->{macro};
                print ' (skip ',
                    join(', ', @{$disabled_info{$what}->{skipped}}),
                    ')'
                    if $disabled_info{$what}->{skipped};
                print "\n";
            }
        }
    }
    if ($dump || $target) {
        print "\nConfig target attributes:\n\n";
        foreach (sort keys %target) {
            next if $_ =~ m|^_| || $_ eq 'template';
            my $quotify = sub {
                map {
                    if (defined $_) {
                        (my $x = $_) =~ s|([\\\$\@"])|\\$1|g; "\"$x\""
                    } else {
                        "undef";
                    }
                } @_;
            };
            print '    ', $_, ' => ';
            if (ref($target{$_}) eq "ARRAY") {
                print '[ ', join(', ', $quotify->(@{$target{$_}})), " ],\n";
            } else {
                print $quotify->($target{$_}), ",\n"
            }
        }
    }
    if ($dump || $envvars) {
        print "\nRecorded environment:\n\n";
        foreach (sort keys %{$config{perlenv}}) {
            print '    ',$_,' = ',($config{perlenv}->{$_} || ''),"\n";
        }
    }
    if ($dump || $makevars) {
        print "\nMakevars:\n\n";
        foreach my $var (@makevars) {
            my $prefix = '';
            $prefix = $config{CROSS_COMPILE}
                if grep { $var eq $_ } @user_crossable;
            $prefix //= '';
            print '    ',$var,' ' x (16 - length $var),'= ',
                (ref $config{$var} eq 'ARRAY'
                 ? join(' ', @{$config{$var}})
                 : $prefix.$config{$var}),
                "\n"
                if defined $config{$var};
        }

        my @buildfile = ($config{builddir}, $config{build_file});
        unshift @buildfile, $here
            unless file_name_is_absolute($config{builddir});
        my $buildfile = canonpath(catdir(@buildfile));
        print <<"_____";

NOTE: These variables only represent the configuration view.  The build file
template may have processed these variables further, please have a look at the
build file for more exact data:
    $buildfile
_____
    }
    if ($dump || $buildparams) {
        my @buildfile = ($config{builddir}, $config{build_file});
        unshift @buildfile, $here
            unless file_name_is_absolute($config{builddir});
        print "\nbuild file:\n\n";
        print "    ", canonpath(catfile(@buildfile)),"\n";

        print "\nbuild file templates:\n\n";
        foreach (@{$config{build_file_templates}}) {
            my @tmpl = ($_);
            unshift @tmpl, $here
                unless file_name_is_absolute($config{sourcedir});
            print '    ',canonpath(catfile(@tmpl)),"\n";
        }
    }
    if ($reconf) {
        if ($verbose) {
            print 'Reconfiguring with: ', join(' ',@{$config{perlargv}}), "\n";
            foreach (sort keys %{$config{perlenv}}) {
                print '    ',$_,' = ',($config{perlenv}->{$_} || ""),"\n";
            }
        }

        chdir $here;
        exec $^X,catfile($config{sourcedir}, 'Configure'),'reconf';
    }
    if ($query) {
        use OpenSSL::Config::Query;

        my $confquery = OpenSSL::Config::Query->new(info => \%unified_info,
                                                    config => \%config);
        my $result = eval "\$confquery->$query";

        # We may need a result class with a printing function at some point.
        # Until then, we assume that we get a scalar, or a list or a hash table
        # with scalar values and simply print them in some orderly fashion.
        if (ref $result eq 'ARRAY') {
            print "$_\n" foreach @$result;
        } elsif (ref $result eq 'HASH') {
            print "$_ : \\\n  ", join(" \\\n  ", @{$result->{$_}}), "\n"
                foreach sort keys %$result;
        } elsif (ref $result eq 'SCALAR') {
            print "$$result\n";
        }
    }
}

1;

__END__

=head1 NAME

configdata.pm - configuration data for OpenSSL builds

=head1 SYNOPSIS

Interactive:

  perl configdata.pm [options]

As data bank module:

  use configdata;

=head1 DESCRIPTION

This module can be used in two modes, interactively and as a module containing
all the data recorded by OpenSSL's Configure script.

When used interactively, simply run it as any perl script.
If run with no arguments, it will rebuild the build file (Makefile or
corresponding).
With at least one option, it will instead get the information you ask for, or
re-run the configuration process.
See L</OPTIONS> below for more information.

When loaded as a module, you get a few databanks with useful information to
perform build related tasks.  The databanks are:

    %config             Configured things.
    %target             The OpenSSL config target with all inheritances
                        resolved.
    %disabled           The features that are disabled.
    @disablables        The list of features that can be disabled.
    %withargs           All data given through --with-THING options.
    %unified_info       All information that was computed from the build.info
                        files.

=head1 OPTIONS

=over 4

=item B<--help>

Print a brief help message and exit.

=item B<--man>

Print the manual page and exit.

=item B<--dump> | B<-d>

Print all relevant configuration data.  This is equivalent to B<--command-line>
B<--options> B<--target> B<--environment> B<--make-variables>
B<--build-parameters>.

=item B<--command-line> | B<-c>

Print the current configuration command line.

=item B<--options> | B<-o>

Print the features, both enabled and disabled, and display defined macro and
skipped directories where applicable.

=item B<--target> | B<-t>

Print the config attributes for this config target.

=item B<--environment> | B<-e>

Print the environment variables and their values at the time of configuration.

=item B<--make-variables> | B<-m>

Print the main make variables generated in the current configuration

=item B<--build-parameters> | B<-b>

Print the build parameters, i.e. build file and build file templates.

=item B<--reconfigure> | B<--reconf> | B<-r>

Re-run the configuration process.

=item B<--verbose> | B<-v>

Verbose output.

=back

=cut

EOF
                                                                                                                                                                                                                                                                                                                                                                                                                                              node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/                                      0000775 0000000 0000000 00000000000 14746647661 0023733 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/aes/                                  0000775 0000000 0000000 00000000000 14746647661 0024503 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/aes/aes-x86_64.s                      0000664 0000000 0000000 00000162110 14746647661 0026374 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	
.type	_x86_64_AES_encrypt,@function
.align	16
_x86_64_AES_encrypt:
.cfi_startproc	
	xorl	0(%r15),%eax
	xorl	4(%r15),%ebx
	xorl	8(%r15),%ecx
	xorl	12(%r15),%edx

	movl	240(%r15),%r13d
	subl	$1,%r13d
	jmp	.Lenc_loop
.align	16
.Lenc_loop:

	movzbl	%al,%esi
	movzbl	%bl,%edi
	movzbl	%cl,%ebp
	movl	0(%r14,%rsi,8),%r10d
	movl	0(%r14,%rdi,8),%r11d
	movl	0(%r14,%rbp,8),%r12d

	movzbl	%bh,%esi
	movzbl	%ch,%edi
	movzbl	%dl,%ebp
	xorl	3(%r14,%rsi,8),%r10d
	xorl	3(%r14,%rdi,8),%r11d
	movl	0(%r14,%rbp,8),%r8d

	movzbl	%dh,%esi
	shrl	$16,%ecx
	movzbl	%ah,%ebp
	xorl	3(%r14,%rsi,8),%r12d
	shrl	$16,%edx
	xorl	3(%r14,%rbp,8),%r8d

	shrl	$16,%ebx
	leaq	16(%r15),%r15
	shrl	$16,%eax

	movzbl	%cl,%esi
	movzbl	%dl,%edi
	movzbl	%al,%ebp
	xorl	2(%r14,%rsi,8),%r10d
	xorl	2(%r14,%rdi,8),%r11d
	xorl	2(%r14,%rbp,8),%r12d

	movzbl	%dh,%esi
	movzbl	%ah,%edi
	movzbl	%bl,%ebp
	xorl	1(%r14,%rsi,8),%r10d
	xorl	1(%r14,%rdi,8),%r11d
	xorl	2(%r14,%rbp,8),%r8d

	movl	12(%r15),%edx
	movzbl	%bh,%edi
	movzbl	%ch,%ebp
	movl	0(%r15),%eax
	xorl	1(%r14,%rdi,8),%r12d
	xorl	1(%r14,%rbp,8),%r8d

	movl	4(%r15),%ebx
	movl	8(%r15),%ecx
	xorl	%r10d,%eax
	xorl	%r11d,%ebx
	xorl	%r12d,%ecx
	xorl	%r8d,%edx
	subl	$1,%r13d
	jnz	.Lenc_loop
	movzbl	%al,%esi
	movzbl	%bl,%edi
	movzbl	%cl,%ebp
	movzbl	2(%r14,%rsi,8),%r10d
	movzbl	2(%r14,%rdi,8),%r11d
	movzbl	2(%r14,%rbp,8),%r12d

	movzbl	%dl,%esi
	movzbl	%bh,%edi
	movzbl	%ch,%ebp
	movzbl	2(%r14,%rsi,8),%r8d
	movl	0(%r14,%rdi,8),%edi
	movl	0(%r14,%rbp,8),%ebp

	andl	$0x0000ff00,%edi
	andl	$0x0000ff00,%ebp

	xorl	%edi,%r10d
	xorl	%ebp,%r11d
	shrl	$16,%ecx

	movzbl	%dh,%esi
	movzbl	%ah,%edi
	shrl	$16,%edx
	movl	0(%r14,%rsi,8),%esi
	movl	0(%r14,%rdi,8),%edi

	andl	$0x0000ff00,%esi
	andl	$0x0000ff00,%edi
	shrl	$16,%ebx
	xorl	%esi,%r12d
	xorl	%edi,%r8d
	shrl	$16,%eax

	movzbl	%cl,%esi
	movzbl	%dl,%edi
	movzbl	%al,%ebp
	movl	0(%r14,%rsi,8),%esi
	movl	0(%r14,%rdi,8),%edi
	movl	0(%r14,%rbp,8),%ebp

	andl	$0x00ff0000,%esi
	andl	$0x00ff0000,%edi
	andl	$0x00ff0000,%ebp

	xorl	%esi,%r10d
	xorl	%edi,%r11d
	xorl	%ebp,%r12d

	movzbl	%bl,%esi
	movzbl	%dh,%edi
	movzbl	%ah,%ebp
	movl	0(%r14,%rsi,8),%esi
	movl	2(%r14,%rdi,8),%edi
	movl	2(%r14,%rbp,8),%ebp

	andl	$0x00ff0000,%esi
	andl	$0xff000000,%edi
	andl	$0xff000000,%ebp

	xorl	%esi,%r8d
	xorl	%edi,%r10d
	xorl	%ebp,%r11d

	movzbl	%bh,%esi
	movzbl	%ch,%edi
	movl	16+12(%r15),%edx
	movl	2(%r14,%rsi,8),%esi
	movl	2(%r14,%rdi,8),%edi
	movl	16+0(%r15),%eax

	andl	$0xff000000,%esi
	andl	$0xff000000,%edi

	xorl	%esi,%r12d
	xorl	%edi,%r8d

	movl	16+4(%r15),%ebx
	movl	16+8(%r15),%ecx
	xorl	%r10d,%eax
	xorl	%r11d,%ebx
	xorl	%r12d,%ecx
	xorl	%r8d,%edx
.byte	0xf3,0xc3
.cfi_endproc	
.size	_x86_64_AES_encrypt,.-_x86_64_AES_encrypt
.type	_x86_64_AES_encrypt_compact,@function
.align	16
_x86_64_AES_encrypt_compact:
.cfi_startproc	
	leaq	128(%r14),%r8
	movl	0-128(%r8),%edi
	movl	32-128(%r8),%ebp
	movl	64-128(%r8),%r10d
	movl	96-128(%r8),%r11d
	movl	128-128(%r8),%edi
	movl	160-128(%r8),%ebp
	movl	192-128(%r8),%r10d
	movl	224-128(%r8),%r11d
	jmp	.Lenc_loop_compact
.align	16
.Lenc_loop_compact:
	xorl	0(%r15),%eax
	xorl	4(%r15),%ebx
	xorl	8(%r15),%ecx
	xorl	12(%r15),%edx
	leaq	16(%r15),%r15
	movzbl	%al,%r10d
	movzbl	%bl,%r11d
	movzbl	%cl,%r12d
	movzbl	%dl,%r8d
	movzbl	%bh,%esi
	movzbl	%ch,%edi
	shrl	$16,%ecx
	movzbl	%dh,%ebp
	movzbl	(%r14,%r10,1),%r10d
	movzbl	(%r14,%r11,1),%r11d
	movzbl	(%r14,%r12,1),%r12d
	movzbl	(%r14,%r8,1),%r8d

	movzbl	(%r14,%rsi,1),%r9d
	movzbl	%ah,%esi
	movzbl	(%r14,%rdi,1),%r13d
	movzbl	%cl,%edi
	movzbl	(%r14,%rbp,1),%ebp
	movzbl	(%r14,%rsi,1),%esi

	shll	$8,%r9d
	shrl	$16,%edx
	shll	$8,%r13d
	xorl	%r9d,%r10d
	shrl	$16,%eax
	movzbl	%dl,%r9d
	shrl	$16,%ebx
	xorl	%r13d,%r11d
	shll	$8,%ebp
	movzbl	%al,%r13d
	movzbl	(%r14,%rdi,1),%edi
	xorl	%ebp,%r12d

	shll	$8,%esi
	movzbl	%bl,%ebp
	shll	$16,%edi
	xorl	%esi,%r8d
	movzbl	(%r14,%r9,1),%r9d
	movzbl	%dh,%esi
	movzbl	(%r14,%r13,1),%r13d
	xorl	%edi,%r10d

	shrl	$8,%ecx
	movzbl	%ah,%edi
	shll	$16,%r9d
	shrl	$8,%ebx
	shll	$16,%r13d
	xorl	%r9d,%r11d
	movzbl	(%r14,%rbp,1),%ebp
	movzbl	(%r14,%rsi,1),%esi
	movzbl	(%r14,%rdi,1),%edi
	movzbl	(%r14,%rcx,1),%edx
	movzbl	(%r14,%rbx,1),%ecx

	shll	$16,%ebp
	xorl	%r13d,%r12d
	shll	$24,%esi
	xorl	%ebp,%r8d
	shll	$24,%edi
	xorl	%esi,%r10d
	shll	$24,%edx
	xorl	%edi,%r11d
	shll	$24,%ecx
	movl	%r10d,%eax
	movl	%r11d,%ebx
	xorl	%r12d,%ecx
	xorl	%r8d,%edx
	cmpq	16(%rsp),%r15
	je	.Lenc_compact_done
	movl	$0x80808080,%r10d
	movl	$0x80808080,%r11d
	andl	%eax,%r10d
	andl	%ebx,%r11d
	movl	%r10d,%esi
	movl	%r11d,%edi
	shrl	$7,%r10d
	leal	(%rax,%rax,1),%r8d
	shrl	$7,%r11d
	leal	(%rbx,%rbx,1),%r9d
	subl	%r10d,%esi
	subl	%r11d,%edi
	andl	$0xfefefefe,%r8d
	andl	$0xfefefefe,%r9d
	andl	$0x1b1b1b1b,%esi
	andl	$0x1b1b1b1b,%edi
	movl	%eax,%r10d
	movl	%ebx,%r11d
	xorl	%esi,%r8d
	xorl	%edi,%r9d

	xorl	%r8d,%eax
	xorl	%r9d,%ebx
	movl	$0x80808080,%r12d
	roll	$24,%eax
	movl	$0x80808080,%ebp
	roll	$24,%ebx
	andl	%ecx,%r12d
	andl	%edx,%ebp
	xorl	%r8d,%eax
	xorl	%r9d,%ebx
	movl	%r12d,%esi
	rorl	$16,%r10d
	movl	%ebp,%edi
	rorl	$16,%r11d
	leal	(%rcx,%rcx,1),%r8d
	shrl	$7,%r12d
	xorl	%r10d,%eax
	shrl	$7,%ebp
	xorl	%r11d,%ebx
	rorl	$8,%r10d
	leal	(%rdx,%rdx,1),%r9d
	rorl	$8,%r11d
	subl	%r12d,%esi
	subl	%ebp,%edi
	xorl	%r10d,%eax
	xorl	%r11d,%ebx

	andl	$0xfefefefe,%r8d
	andl	$0xfefefefe,%r9d
	andl	$0x1b1b1b1b,%esi
	andl	$0x1b1b1b1b,%edi
	movl	%ecx,%r12d
	movl	%edx,%ebp
	xorl	%esi,%r8d
	xorl	%edi,%r9d

	rorl	$16,%r12d
	xorl	%r8d,%ecx
	rorl	$16,%ebp
	xorl	%r9d,%edx
	roll	$24,%ecx
	movl	0(%r14),%esi
	roll	$24,%edx
	xorl	%r8d,%ecx
	movl	64(%r14),%edi
	xorl	%r9d,%edx
	movl	128(%r14),%r8d
	xorl	%r12d,%ecx
	rorl	$8,%r12d
	xorl	%ebp,%edx
	rorl	$8,%ebp
	xorl	%r12d,%ecx
	movl	192(%r14),%r9d
	xorl	%ebp,%edx
	jmp	.Lenc_loop_compact
.align	16
.Lenc_compact_done:
	xorl	0(%r15),%eax
	xorl	4(%r15),%ebx
	xorl	8(%r15),%ecx
	xorl	12(%r15),%edx
.byte	0xf3,0xc3
.cfi_endproc	
.size	_x86_64_AES_encrypt_compact,.-_x86_64_AES_encrypt_compact
.globl	AES_encrypt
.type	AES_encrypt,@function
.align	16
.globl	asm_AES_encrypt
.hidden	asm_AES_encrypt
asm_AES_encrypt:
AES_encrypt:
.cfi_startproc	
.byte	243,15,30,250
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56


	leaq	-63(%rdx),%rcx
	andq	$-64,%rsp
	subq	%rsp,%rcx
	negq	%rcx
	andq	$0x3c0,%rcx
	subq	%rcx,%rsp
	subq	$32,%rsp

	movq	%rsi,16(%rsp)
	movq	%rax,24(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x18,0x06,0x23,0x08
.Lenc_prologue:

	movq	%rdx,%r15
	movl	240(%r15),%r13d

	movl	0(%rdi),%eax
	movl	4(%rdi),%ebx
	movl	8(%rdi),%ecx
	movl	12(%rdi),%edx

	shll	$4,%r13d
	leaq	(%r15,%r13,1),%rbp
	movq	%r15,(%rsp)
	movq	%rbp,8(%rsp)


	leaq	.LAES_Te+2048(%rip),%r14
	leaq	768(%rsp),%rbp
	subq	%r14,%rbp
	andq	$0x300,%rbp
	leaq	(%r14,%rbp,1),%r14

	call	_x86_64_AES_encrypt_compact

	movq	16(%rsp),%r9
	movq	24(%rsp),%rsi
.cfi_def_cfa	%rsi,8
	movl	%eax,0(%r9)
	movl	%ebx,4(%r9)
	movl	%ecx,8(%r9)
	movl	%edx,12(%r9)

	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lenc_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	AES_encrypt,.-AES_encrypt
.type	_x86_64_AES_decrypt,@function
.align	16
_x86_64_AES_decrypt:
.cfi_startproc	
	xorl	0(%r15),%eax
	xorl	4(%r15),%ebx
	xorl	8(%r15),%ecx
	xorl	12(%r15),%edx

	movl	240(%r15),%r13d
	subl	$1,%r13d
	jmp	.Ldec_loop
.align	16
.Ldec_loop:

	movzbl	%al,%esi
	movzbl	%bl,%edi
	movzbl	%cl,%ebp
	movl	0(%r14,%rsi,8),%r10d
	movl	0(%r14,%rdi,8),%r11d
	movl	0(%r14,%rbp,8),%r12d

	movzbl	%dh,%esi
	movzbl	%ah,%edi
	movzbl	%dl,%ebp
	xorl	3(%r14,%rsi,8),%r10d
	xorl	3(%r14,%rdi,8),%r11d
	movl	0(%r14,%rbp,8),%r8d

	movzbl	%bh,%esi
	shrl	$16,%eax
	movzbl	%ch,%ebp
	xorl	3(%r14,%rsi,8),%r12d
	shrl	$16,%edx
	xorl	3(%r14,%rbp,8),%r8d

	shrl	$16,%ebx
	leaq	16(%r15),%r15
	shrl	$16,%ecx

	movzbl	%cl,%esi
	movzbl	%dl,%edi
	movzbl	%al,%ebp
	xorl	2(%r14,%rsi,8),%r10d
	xorl	2(%r14,%rdi,8),%r11d
	xorl	2(%r14,%rbp,8),%r12d

	movzbl	%bh,%esi
	movzbl	%ch,%edi
	movzbl	%bl,%ebp
	xorl	1(%r14,%rsi,8),%r10d
	xorl	1(%r14,%rdi,8),%r11d
	xorl	2(%r14,%rbp,8),%r8d

	movzbl	%dh,%esi
	movl	12(%r15),%edx
	movzbl	%ah,%ebp
	xorl	1(%r14,%rsi,8),%r12d
	movl	0(%r15),%eax
	xorl	1(%r14,%rbp,8),%r8d

	xorl	%r10d,%eax
	movl	4(%r15),%ebx
	movl	8(%r15),%ecx
	xorl	%r12d,%ecx
	xorl	%r11d,%ebx
	xorl	%r8d,%edx
	subl	$1,%r13d
	jnz	.Ldec_loop
	leaq	2048(%r14),%r14
	movzbl	%al,%esi
	movzbl	%bl,%edi
	movzbl	%cl,%ebp
	movzbl	(%r14,%rsi,1),%r10d
	movzbl	(%r14,%rdi,1),%r11d
	movzbl	(%r14,%rbp,1),%r12d

	movzbl	%dl,%esi
	movzbl	%dh,%edi
	movzbl	%ah,%ebp
	movzbl	(%r14,%rsi,1),%r8d
	movzbl	(%r14,%rdi,1),%edi
	movzbl	(%r14,%rbp,1),%ebp

	shll	$8,%edi
	shll	$8,%ebp

	xorl	%edi,%r10d
	xorl	%ebp,%r11d
	shrl	$16,%edx

	movzbl	%bh,%esi
	movzbl	%ch,%edi
	shrl	$16,%eax
	movzbl	(%r14,%rsi,1),%esi
	movzbl	(%r14,%rdi,1),%edi

	shll	$8,%esi
	shll	$8,%edi
	shrl	$16,%ebx
	xorl	%esi,%r12d
	xorl	%edi,%r8d
	shrl	$16,%ecx

	movzbl	%cl,%esi
	movzbl	%dl,%edi
	movzbl	%al,%ebp
	movzbl	(%r14,%rsi,1),%esi
	movzbl	(%r14,%rdi,1),%edi
	movzbl	(%r14,%rbp,1),%ebp

	shll	$16,%esi
	shll	$16,%edi
	shll	$16,%ebp

	xorl	%esi,%r10d
	xorl	%edi,%r11d
	xorl	%ebp,%r12d

	movzbl	%bl,%esi
	movzbl	%bh,%edi
	movzbl	%ch,%ebp
	movzbl	(%r14,%rsi,1),%esi
	movzbl	(%r14,%rdi,1),%edi
	movzbl	(%r14,%rbp,1),%ebp

	shll	$16,%esi
	shll	$24,%edi
	shll	$24,%ebp

	xorl	%esi,%r8d
	xorl	%edi,%r10d
	xorl	%ebp,%r11d

	movzbl	%dh,%esi
	movzbl	%ah,%edi
	movl	16+12(%r15),%edx
	movzbl	(%r14,%rsi,1),%esi
	movzbl	(%r14,%rdi,1),%edi
	movl	16+0(%r15),%eax

	shll	$24,%esi
	shll	$24,%edi

	xorl	%esi,%r12d
	xorl	%edi,%r8d

	movl	16+4(%r15),%ebx
	movl	16+8(%r15),%ecx
	leaq	-2048(%r14),%r14
	xorl	%r10d,%eax
	xorl	%r11d,%ebx
	xorl	%r12d,%ecx
	xorl	%r8d,%edx
.byte	0xf3,0xc3
.cfi_endproc	
.size	_x86_64_AES_decrypt,.-_x86_64_AES_decrypt
.type	_x86_64_AES_decrypt_compact,@function
.align	16
_x86_64_AES_decrypt_compact:
.cfi_startproc	
	leaq	128(%r14),%r8
	movl	0-128(%r8),%edi
	movl	32-128(%r8),%ebp
	movl	64-128(%r8),%r10d
	movl	96-128(%r8),%r11d
	movl	128-128(%r8),%edi
	movl	160-128(%r8),%ebp
	movl	192-128(%r8),%r10d
	movl	224-128(%r8),%r11d
	jmp	.Ldec_loop_compact

.align	16
.Ldec_loop_compact:
	xorl	0(%r15),%eax
	xorl	4(%r15),%ebx
	xorl	8(%r15),%ecx
	xorl	12(%r15),%edx
	leaq	16(%r15),%r15
	movzbl	%al,%r10d
	movzbl	%bl,%r11d
	movzbl	%cl,%r12d
	movzbl	%dl,%r8d
	movzbl	%dh,%esi
	movzbl	%ah,%edi
	shrl	$16,%edx
	movzbl	%bh,%ebp
	movzbl	(%r14,%r10,1),%r10d
	movzbl	(%r14,%r11,1),%r11d
	movzbl	(%r14,%r12,1),%r12d
	movzbl	(%r14,%r8,1),%r8d

	movzbl	(%r14,%rsi,1),%r9d
	movzbl	%ch,%esi
	movzbl	(%r14,%rdi,1),%r13d
	movzbl	(%r14,%rbp,1),%ebp
	movzbl	(%r14,%rsi,1),%esi

	shrl	$16,%ecx
	shll	$8,%r13d
	shll	$8,%r9d
	movzbl	%cl,%edi
	shrl	$16,%eax
	xorl	%r9d,%r10d
	shrl	$16,%ebx
	movzbl	%dl,%r9d

	shll	$8,%ebp
	xorl	%r13d,%r11d
	shll	$8,%esi
	movzbl	%al,%r13d
	movzbl	(%r14,%rdi,1),%edi
	xorl	%ebp,%r12d
	movzbl	%bl,%ebp

	shll	$16,%edi
	xorl	%esi,%r8d
	movzbl	(%r14,%r9,1),%r9d
	movzbl	%bh,%esi
	movzbl	(%r14,%rbp,1),%ebp
	xorl	%edi,%r10d
	movzbl	(%r14,%r13,1),%r13d
	movzbl	%ch,%edi

	shll	$16,%ebp
	shll	$16,%r9d
	shll	$16,%r13d
	xorl	%ebp,%r8d
	movzbl	%dh,%ebp
	xorl	%r9d,%r11d
	shrl	$8,%eax
	xorl	%r13d,%r12d

	movzbl	(%r14,%rsi,1),%esi
	movzbl	(%r14,%rdi,1),%ebx
	movzbl	(%r14,%rbp,1),%ecx
	movzbl	(%r14,%rax,1),%edx

	movl	%r10d,%eax
	shll	$24,%esi
	shll	$24,%ebx
	shll	$24,%ecx
	xorl	%esi,%eax
	shll	$24,%edx
	xorl	%r11d,%ebx
	xorl	%r12d,%ecx
	xorl	%r8d,%edx
	cmpq	16(%rsp),%r15
	je	.Ldec_compact_done

	movq	256+0(%r14),%rsi
	shlq	$32,%rbx
	shlq	$32,%rdx
	movq	256+8(%r14),%rdi
	orq	%rbx,%rax
	orq	%rdx,%rcx
	movq	256+16(%r14),%rbp
	movq	%rsi,%r9
	movq	%rsi,%r12
	andq	%rax,%r9
	andq	%rcx,%r12
	movq	%r9,%rbx
	movq	%r12,%rdx
	shrq	$7,%r9
	leaq	(%rax,%rax,1),%r8
	shrq	$7,%r12
	leaq	(%rcx,%rcx,1),%r11
	subq	%r9,%rbx
	subq	%r12,%rdx
	andq	%rdi,%r8
	andq	%rdi,%r11
	andq	%rbp,%rbx
	andq	%rbp,%rdx
	xorq	%rbx,%r8
	xorq	%rdx,%r11
	movq	%rsi,%r10
	movq	%rsi,%r13

	andq	%r8,%r10
	andq	%r11,%r13
	movq	%r10,%rbx
	movq	%r13,%rdx
	shrq	$7,%r10
	leaq	(%r8,%r8,1),%r9
	shrq	$7,%r13
	leaq	(%r11,%r11,1),%r12
	subq	%r10,%rbx
	subq	%r13,%rdx
	andq	%rdi,%r9
	andq	%rdi,%r12
	andq	%rbp,%rbx
	andq	%rbp,%rdx
	xorq	%rbx,%r9
	xorq	%rdx,%r12
	movq	%rsi,%r10
	movq	%rsi,%r13

	andq	%r9,%r10
	andq	%r12,%r13
	movq	%r10,%rbx
	movq	%r13,%rdx
	shrq	$7,%r10
	xorq	%rax,%r8
	shrq	$7,%r13
	xorq	%rcx,%r11
	subq	%r10,%rbx
	subq	%r13,%rdx
	leaq	(%r9,%r9,1),%r10
	leaq	(%r12,%r12,1),%r13
	xorq	%rax,%r9
	xorq	%rcx,%r12
	andq	%rdi,%r10
	andq	%rdi,%r13
	andq	%rbp,%rbx
	andq	%rbp,%rdx
	xorq	%rbx,%r10
	xorq	%rdx,%r13

	xorq	%r10,%rax
	xorq	%r13,%rcx
	xorq	%r10,%r8
	xorq	%r13,%r11
	movq	%rax,%rbx
	movq	%rcx,%rdx
	xorq	%r10,%r9
	shrq	$32,%rbx
	xorq	%r13,%r12
	shrq	$32,%rdx
	xorq	%r8,%r10
	roll	$8,%eax
	xorq	%r11,%r13
	roll	$8,%ecx
	xorq	%r9,%r10
	roll	$8,%ebx
	xorq	%r12,%r13

	roll	$8,%edx
	xorl	%r10d,%eax
	shrq	$32,%r10
	xorl	%r13d,%ecx
	shrq	$32,%r13
	xorl	%r10d,%ebx
	xorl	%r13d,%edx

	movq	%r8,%r10
	roll	$24,%r8d
	movq	%r11,%r13
	roll	$24,%r11d
	shrq	$32,%r10
	xorl	%r8d,%eax
	shrq	$32,%r13
	xorl	%r11d,%ecx
	roll	$24,%r10d
	movq	%r9,%r8
	roll	$24,%r13d
	movq	%r12,%r11
	shrq	$32,%r8
	xorl	%r10d,%ebx
	shrq	$32,%r11
	xorl	%r13d,%edx

	movq	0(%r14),%rsi
	roll	$16,%r9d
	movq	64(%r14),%rdi
	roll	$16,%r12d
	movq	128(%r14),%rbp
	roll	$16,%r8d
	movq	192(%r14),%r10
	xorl	%r9d,%eax
	roll	$16,%r11d
	xorl	%r12d,%ecx
	movq	256(%r14),%r13
	xorl	%r8d,%ebx
	xorl	%r11d,%edx
	jmp	.Ldec_loop_compact
.align	16
.Ldec_compact_done:
	xorl	0(%r15),%eax
	xorl	4(%r15),%ebx
	xorl	8(%r15),%ecx
	xorl	12(%r15),%edx
.byte	0xf3,0xc3
.cfi_endproc	
.size	_x86_64_AES_decrypt_compact,.-_x86_64_AES_decrypt_compact
.globl	AES_decrypt
.type	AES_decrypt,@function
.align	16
.globl	asm_AES_decrypt
.hidden	asm_AES_decrypt
asm_AES_decrypt:
AES_decrypt:
.cfi_startproc	
.byte	243,15,30,250
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56


	leaq	-63(%rdx),%rcx
	andq	$-64,%rsp
	subq	%rsp,%rcx
	negq	%rcx
	andq	$0x3c0,%rcx
	subq	%rcx,%rsp
	subq	$32,%rsp

	movq	%rsi,16(%rsp)
	movq	%rax,24(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x18,0x06,0x23,0x08
.Ldec_prologue:

	movq	%rdx,%r15
	movl	240(%r15),%r13d

	movl	0(%rdi),%eax
	movl	4(%rdi),%ebx
	movl	8(%rdi),%ecx
	movl	12(%rdi),%edx

	shll	$4,%r13d
	leaq	(%r15,%r13,1),%rbp
	movq	%r15,(%rsp)
	movq	%rbp,8(%rsp)


	leaq	.LAES_Td+2048(%rip),%r14
	leaq	768(%rsp),%rbp
	subq	%r14,%rbp
	andq	$0x300,%rbp
	leaq	(%r14,%rbp,1),%r14
	shrq	$3,%rbp
	addq	%rbp,%r14

	call	_x86_64_AES_decrypt_compact

	movq	16(%rsp),%r9
	movq	24(%rsp),%rsi
.cfi_def_cfa	%rsi,8
	movl	%eax,0(%r9)
	movl	%ebx,4(%r9)
	movl	%ecx,8(%r9)
	movl	%edx,12(%r9)

	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Ldec_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	AES_decrypt,.-AES_decrypt
.globl	AES_set_encrypt_key
.type	AES_set_encrypt_key,@function
.align	16
AES_set_encrypt_key:
.cfi_startproc	
.byte	243,15,30,250
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-56
	subq	$8,%rsp
.cfi_adjust_cfa_offset	8
.Lenc_key_prologue:

	call	_x86_64_AES_set_encrypt_key

	movq	40(%rsp),%rbp
.cfi_restore	%rbp
	movq	48(%rsp),%rbx
.cfi_restore	%rbx
	addq	$56,%rsp
.cfi_adjust_cfa_offset	-56
.Lenc_key_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	AES_set_encrypt_key,.-AES_set_encrypt_key

.type	_x86_64_AES_set_encrypt_key,@function
.align	16
_x86_64_AES_set_encrypt_key:
.cfi_startproc	
	movl	%esi,%ecx
	movq	%rdi,%rsi
	movq	%rdx,%rdi

	testq	$-1,%rsi
	jz	.Lbadpointer
	testq	$-1,%rdi
	jz	.Lbadpointer

	leaq	.LAES_Te(%rip),%rbp
	leaq	2048+128(%rbp),%rbp


	movl	0-128(%rbp),%eax
	movl	32-128(%rbp),%ebx
	movl	64-128(%rbp),%r8d
	movl	96-128(%rbp),%edx
	movl	128-128(%rbp),%eax
	movl	160-128(%rbp),%ebx
	movl	192-128(%rbp),%r8d
	movl	224-128(%rbp),%edx

	cmpl	$128,%ecx
	je	.L10rounds
	cmpl	$192,%ecx
	je	.L12rounds
	cmpl	$256,%ecx
	je	.L14rounds
	movq	$-2,%rax
	jmp	.Lexit

.L10rounds:
	movq	0(%rsi),%rax
	movq	8(%rsi),%rdx
	movq	%rax,0(%rdi)
	movq	%rdx,8(%rdi)

	shrq	$32,%rdx
	xorl	%ecx,%ecx
	jmp	.L10shortcut
.align	4
.L10loop:
	movl	0(%rdi),%eax
	movl	12(%rdi),%edx
.L10shortcut:
	movzbl	%dl,%esi
	movzbl	-128(%rbp,%rsi,1),%ebx
	movzbl	%dh,%esi
	shll	$24,%ebx
	xorl	%ebx,%eax

	movzbl	-128(%rbp,%rsi,1),%ebx
	shrl	$16,%edx
	movzbl	%dl,%esi
	xorl	%ebx,%eax

	movzbl	-128(%rbp,%rsi,1),%ebx
	movzbl	%dh,%esi
	shll	$8,%ebx
	xorl	%ebx,%eax

	movzbl	-128(%rbp,%rsi,1),%ebx
	shll	$16,%ebx
	xorl	%ebx,%eax

	xorl	1024-128(%rbp,%rcx,4),%eax
	movl	%eax,16(%rdi)
	xorl	4(%rdi),%eax
	movl	%eax,20(%rdi)
	xorl	8(%rdi),%eax
	movl	%eax,24(%rdi)
	xorl	12(%rdi),%eax
	movl	%eax,28(%rdi)
	addl	$1,%ecx
	leaq	16(%rdi),%rdi
	cmpl	$10,%ecx
	jl	.L10loop

	movl	$10,80(%rdi)
	xorq	%rax,%rax
	jmp	.Lexit

.L12rounds:
	movq	0(%rsi),%rax
	movq	8(%rsi),%rbx
	movq	16(%rsi),%rdx
	movq	%rax,0(%rdi)
	movq	%rbx,8(%rdi)
	movq	%rdx,16(%rdi)

	shrq	$32,%rdx
	xorl	%ecx,%ecx
	jmp	.L12shortcut
.align	4
.L12loop:
	movl	0(%rdi),%eax
	movl	20(%rdi),%edx
.L12shortcut:
	movzbl	%dl,%esi
	movzbl	-128(%rbp,%rsi,1),%ebx
	movzbl	%dh,%esi
	shll	$24,%ebx
	xorl	%ebx,%eax

	movzbl	-128(%rbp,%rsi,1),%ebx
	shrl	$16,%edx
	movzbl	%dl,%esi
	xorl	%ebx,%eax

	movzbl	-128(%rbp,%rsi,1),%ebx
	movzbl	%dh,%esi
	shll	$8,%ebx
	xorl	%ebx,%eax

	movzbl	-128(%rbp,%rsi,1),%ebx
	shll	$16,%ebx
	xorl	%ebx,%eax

	xorl	1024-128(%rbp,%rcx,4),%eax
	movl	%eax,24(%rdi)
	xorl	4(%rdi),%eax
	movl	%eax,28(%rdi)
	xorl	8(%rdi),%eax
	movl	%eax,32(%rdi)
	xorl	12(%rdi),%eax
	movl	%eax,36(%rdi)

	cmpl	$7,%ecx
	je	.L12break
	addl	$1,%ecx

	xorl	16(%rdi),%eax
	movl	%eax,40(%rdi)
	xorl	20(%rdi),%eax
	movl	%eax,44(%rdi)

	leaq	24(%rdi),%rdi
	jmp	.L12loop
.L12break:
	movl	$12,72(%rdi)
	xorq	%rax,%rax
	jmp	.Lexit

.L14rounds:
	movq	0(%rsi),%rax
	movq	8(%rsi),%rbx
	movq	16(%rsi),%rcx
	movq	24(%rsi),%rdx
	movq	%rax,0(%rdi)
	movq	%rbx,8(%rdi)
	movq	%rcx,16(%rdi)
	movq	%rdx,24(%rdi)

	shrq	$32,%rdx
	xorl	%ecx,%ecx
	jmp	.L14shortcut
.align	4
.L14loop:
	movl	0(%rdi),%eax
	movl	28(%rdi),%edx
.L14shortcut:
	movzbl	%dl,%esi
	movzbl	-128(%rbp,%rsi,1),%ebx
	movzbl	%dh,%esi
	shll	$24,%ebx
	xorl	%ebx,%eax

	movzbl	-128(%rbp,%rsi,1),%ebx
	shrl	$16,%edx
	movzbl	%dl,%esi
	xorl	%ebx,%eax

	movzbl	-128(%rbp,%rsi,1),%ebx
	movzbl	%dh,%esi
	shll	$8,%ebx
	xorl	%ebx,%eax

	movzbl	-128(%rbp,%rsi,1),%ebx
	shll	$16,%ebx
	xorl	%ebx,%eax

	xorl	1024-128(%rbp,%rcx,4),%eax
	movl	%eax,32(%rdi)
	xorl	4(%rdi),%eax
	movl	%eax,36(%rdi)
	xorl	8(%rdi),%eax
	movl	%eax,40(%rdi)
	xorl	12(%rdi),%eax
	movl	%eax,44(%rdi)

	cmpl	$6,%ecx
	je	.L14break
	addl	$1,%ecx

	movl	%eax,%edx
	movl	16(%rdi),%eax
	movzbl	%dl,%esi
	movzbl	-128(%rbp,%rsi,1),%ebx
	movzbl	%dh,%esi
	xorl	%ebx,%eax

	movzbl	-128(%rbp,%rsi,1),%ebx
	shrl	$16,%edx
	shll	$8,%ebx
	movzbl	%dl,%esi
	xorl	%ebx,%eax

	movzbl	-128(%rbp,%rsi,1),%ebx
	movzbl	%dh,%esi
	shll	$16,%ebx
	xorl	%ebx,%eax

	movzbl	-128(%rbp,%rsi,1),%ebx
	shll	$24,%ebx
	xorl	%ebx,%eax

	movl	%eax,48(%rdi)
	xorl	20(%rdi),%eax
	movl	%eax,52(%rdi)
	xorl	24(%rdi),%eax
	movl	%eax,56(%rdi)
	xorl	28(%rdi),%eax
	movl	%eax,60(%rdi)

	leaq	32(%rdi),%rdi
	jmp	.L14loop
.L14break:
	movl	$14,48(%rdi)
	xorq	%rax,%rax
	jmp	.Lexit

.Lbadpointer:
	movq	$-1,%rax
.Lexit:
.byte	0xf3,0xc3
.cfi_endproc	
.size	_x86_64_AES_set_encrypt_key,.-_x86_64_AES_set_encrypt_key
.globl	AES_set_decrypt_key
.type	AES_set_decrypt_key,@function
.align	16
AES_set_decrypt_key:
.cfi_startproc	
.byte	243,15,30,250
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-56
	pushq	%rdx
.cfi_adjust_cfa_offset	8
.Ldec_key_prologue:

	call	_x86_64_AES_set_encrypt_key
	movq	(%rsp),%r8
	cmpl	$0,%eax
	jne	.Labort

	movl	240(%r8),%r14d
	xorq	%rdi,%rdi
	leaq	(%rdi,%r14,4),%rcx
	movq	%r8,%rsi
	leaq	(%r8,%rcx,4),%rdi
.align	4
.Linvert:
	movq	0(%rsi),%rax
	movq	8(%rsi),%rbx
	movq	0(%rdi),%rcx
	movq	8(%rdi),%rdx
	movq	%rax,0(%rdi)
	movq	%rbx,8(%rdi)
	movq	%rcx,0(%rsi)
	movq	%rdx,8(%rsi)
	leaq	16(%rsi),%rsi
	leaq	-16(%rdi),%rdi
	cmpq	%rsi,%rdi
	jne	.Linvert

	leaq	.LAES_Te+2048+1024(%rip),%rax

	movq	40(%rax),%rsi
	movq	48(%rax),%rdi
	movq	56(%rax),%rbp

	movq	%r8,%r15
	subl	$1,%r14d
.align	4
.Lpermute:
	leaq	16(%r15),%r15
	movq	0(%r15),%rax
	movq	8(%r15),%rcx
	movq	%rsi,%r9
	movq	%rsi,%r12
	andq	%rax,%r9
	andq	%rcx,%r12
	movq	%r9,%rbx
	movq	%r12,%rdx
	shrq	$7,%r9
	leaq	(%rax,%rax,1),%r8
	shrq	$7,%r12
	leaq	(%rcx,%rcx,1),%r11
	subq	%r9,%rbx
	subq	%r12,%rdx
	andq	%rdi,%r8
	andq	%rdi,%r11
	andq	%rbp,%rbx
	andq	%rbp,%rdx
	xorq	%rbx,%r8
	xorq	%rdx,%r11
	movq	%rsi,%r10
	movq	%rsi,%r13

	andq	%r8,%r10
	andq	%r11,%r13
	movq	%r10,%rbx
	movq	%r13,%rdx
	shrq	$7,%r10
	leaq	(%r8,%r8,1),%r9
	shrq	$7,%r13
	leaq	(%r11,%r11,1),%r12
	subq	%r10,%rbx
	subq	%r13,%rdx
	andq	%rdi,%r9
	andq	%rdi,%r12
	andq	%rbp,%rbx
	andq	%rbp,%rdx
	xorq	%rbx,%r9
	xorq	%rdx,%r12
	movq	%rsi,%r10
	movq	%rsi,%r13

	andq	%r9,%r10
	andq	%r12,%r13
	movq	%r10,%rbx
	movq	%r13,%rdx
	shrq	$7,%r10
	xorq	%rax,%r8
	shrq	$7,%r13
	xorq	%rcx,%r11
	subq	%r10,%rbx
	subq	%r13,%rdx
	leaq	(%r9,%r9,1),%r10
	leaq	(%r12,%r12,1),%r13
	xorq	%rax,%r9
	xorq	%rcx,%r12
	andq	%rdi,%r10
	andq	%rdi,%r13
	andq	%rbp,%rbx
	andq	%rbp,%rdx
	xorq	%rbx,%r10
	xorq	%rdx,%r13

	xorq	%r10,%rax
	xorq	%r13,%rcx
	xorq	%r10,%r8
	xorq	%r13,%r11
	movq	%rax,%rbx
	movq	%rcx,%rdx
	xorq	%r10,%r9
	shrq	$32,%rbx
	xorq	%r13,%r12
	shrq	$32,%rdx
	xorq	%r8,%r10
	roll	$8,%eax
	xorq	%r11,%r13
	roll	$8,%ecx
	xorq	%r9,%r10
	roll	$8,%ebx
	xorq	%r12,%r13

	roll	$8,%edx
	xorl	%r10d,%eax
	shrq	$32,%r10
	xorl	%r13d,%ecx
	shrq	$32,%r13
	xorl	%r10d,%ebx
	xorl	%r13d,%edx

	movq	%r8,%r10
	roll	$24,%r8d
	movq	%r11,%r13
	roll	$24,%r11d
	shrq	$32,%r10
	xorl	%r8d,%eax
	shrq	$32,%r13
	xorl	%r11d,%ecx
	roll	$24,%r10d
	movq	%r9,%r8
	roll	$24,%r13d
	movq	%r12,%r11
	shrq	$32,%r8
	xorl	%r10d,%ebx
	shrq	$32,%r11
	xorl	%r13d,%edx


	roll	$16,%r9d

	roll	$16,%r12d

	roll	$16,%r8d

	xorl	%r9d,%eax
	roll	$16,%r11d
	xorl	%r12d,%ecx

	xorl	%r8d,%ebx
	xorl	%r11d,%edx
	movl	%eax,0(%r15)
	movl	%ebx,4(%r15)
	movl	%ecx,8(%r15)
	movl	%edx,12(%r15)
	subl	$1,%r14d
	jnz	.Lpermute

	xorq	%rax,%rax
.Labort:
	movq	8(%rsp),%r15
.cfi_restore	%r15
	movq	16(%rsp),%r14
.cfi_restore	%r14
	movq	24(%rsp),%r13
.cfi_restore	%r13
	movq	32(%rsp),%r12
.cfi_restore	%r12
	movq	40(%rsp),%rbp
.cfi_restore	%rbp
	movq	48(%rsp),%rbx
.cfi_restore	%rbx
	addq	$56,%rsp
.cfi_adjust_cfa_offset	-56
.Ldec_key_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	AES_set_decrypt_key,.-AES_set_decrypt_key
.globl	AES_cbc_encrypt
.type	AES_cbc_encrypt,@function
.align	16

.globl	asm_AES_cbc_encrypt
.hidden	asm_AES_cbc_encrypt
asm_AES_cbc_encrypt:
AES_cbc_encrypt:
.cfi_startproc	
.byte	243,15,30,250
	cmpq	$0,%rdx
	je	.Lcbc_epilogue
	pushfq


.cfi_adjust_cfa_offset	8
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-24
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-32
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-40
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-48
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-56
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-64
.Lcbc_prologue:

	cld
	movl	%r9d,%r9d

	leaq	.LAES_Te(%rip),%r14
	leaq	.LAES_Td(%rip),%r10
	cmpq	$0,%r9
	cmoveq	%r10,%r14

.cfi_remember_state	
	movl	OPENSSL_ia32cap_P(%rip),%r10d
	cmpq	$512,%rdx
	jb	.Lcbc_slow_prologue
	testq	$15,%rdx
	jnz	.Lcbc_slow_prologue
	btl	$28,%r10d
	jc	.Lcbc_slow_prologue


	leaq	-88-248(%rsp),%r15
	andq	$-64,%r15


	movq	%r14,%r10
	leaq	2304(%r14),%r11
	movq	%r15,%r12
	andq	$0xFFF,%r10
	andq	$0xFFF,%r11
	andq	$0xFFF,%r12

	cmpq	%r11,%r12
	jb	.Lcbc_te_break_out
	subq	%r11,%r12
	subq	%r12,%r15
	jmp	.Lcbc_te_ok
.Lcbc_te_break_out:
	subq	%r10,%r12
	andq	$0xFFF,%r12
	addq	$320,%r12
	subq	%r12,%r15
.align	4
.Lcbc_te_ok:

	xchgq	%rsp,%r15
.cfi_def_cfa_register	%r15

	movq	%r15,16(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x10,0x06,0x23,0x40
.Lcbc_fast_body:
	movq	%rdi,24(%rsp)
	movq	%rsi,32(%rsp)
	movq	%rdx,40(%rsp)
	movq	%rcx,48(%rsp)
	movq	%r8,56(%rsp)
	movl	$0,80+240(%rsp)
	movq	%r8,%rbp
	movq	%r9,%rbx
	movq	%rsi,%r9
	movq	%rdi,%r8
	movq	%rcx,%r15

	movl	240(%r15),%eax

	movq	%r15,%r10
	subq	%r14,%r10
	andq	$0xfff,%r10
	cmpq	$2304,%r10
	jb	.Lcbc_do_ecopy
	cmpq	$4096-248,%r10
	jb	.Lcbc_skip_ecopy
.align	4
.Lcbc_do_ecopy:
	movq	%r15,%rsi
	leaq	80(%rsp),%rdi
	leaq	80(%rsp),%r15
	movl	$30,%ecx
.long	0x90A548F3
	movl	%eax,(%rdi)
.Lcbc_skip_ecopy:
	movq	%r15,0(%rsp)

	movl	$18,%ecx
.align	4
.Lcbc_prefetch_te:
	movq	0(%r14),%r10
	movq	32(%r14),%r11
	movq	64(%r14),%r12
	movq	96(%r14),%r13
	leaq	128(%r14),%r14
	subl	$1,%ecx
	jnz	.Lcbc_prefetch_te
	leaq	-2304(%r14),%r14

	cmpq	$0,%rbx
	je	.LFAST_DECRYPT


	movl	0(%rbp),%eax
	movl	4(%rbp),%ebx
	movl	8(%rbp),%ecx
	movl	12(%rbp),%edx

.align	4
.Lcbc_fast_enc_loop:
	xorl	0(%r8),%eax
	xorl	4(%r8),%ebx
	xorl	8(%r8),%ecx
	xorl	12(%r8),%edx
	movq	0(%rsp),%r15
	movq	%r8,24(%rsp)

	call	_x86_64_AES_encrypt

	movq	24(%rsp),%r8
	movq	40(%rsp),%r10
	movl	%eax,0(%r9)
	movl	%ebx,4(%r9)
	movl	%ecx,8(%r9)
	movl	%edx,12(%r9)

	leaq	16(%r8),%r8
	leaq	16(%r9),%r9
	subq	$16,%r10
	testq	$-16,%r10
	movq	%r10,40(%rsp)
	jnz	.Lcbc_fast_enc_loop
	movq	56(%rsp),%rbp
	movl	%eax,0(%rbp)
	movl	%ebx,4(%rbp)
	movl	%ecx,8(%rbp)
	movl	%edx,12(%rbp)

	jmp	.Lcbc_fast_cleanup


.align	16
.LFAST_DECRYPT:
	cmpq	%r8,%r9
	je	.Lcbc_fast_dec_in_place

	movq	%rbp,64(%rsp)
.align	4
.Lcbc_fast_dec_loop:
	movl	0(%r8),%eax
	movl	4(%r8),%ebx
	movl	8(%r8),%ecx
	movl	12(%r8),%edx
	movq	0(%rsp),%r15
	movq	%r8,24(%rsp)

	call	_x86_64_AES_decrypt

	movq	64(%rsp),%rbp
	movq	24(%rsp),%r8
	movq	40(%rsp),%r10
	xorl	0(%rbp),%eax
	xorl	4(%rbp),%ebx
	xorl	8(%rbp),%ecx
	xorl	12(%rbp),%edx
	movq	%r8,%rbp

	subq	$16,%r10
	movq	%r10,40(%rsp)
	movq	%rbp,64(%rsp)

	movl	%eax,0(%r9)
	movl	%ebx,4(%r9)
	movl	%ecx,8(%r9)
	movl	%edx,12(%r9)

	leaq	16(%r8),%r8
	leaq	16(%r9),%r9
	jnz	.Lcbc_fast_dec_loop
	movq	56(%rsp),%r12
	movq	0(%rbp),%r10
	movq	8(%rbp),%r11
	movq	%r10,0(%r12)
	movq	%r11,8(%r12)
	jmp	.Lcbc_fast_cleanup

.align	16
.Lcbc_fast_dec_in_place:
	movq	0(%rbp),%r10
	movq	8(%rbp),%r11
	movq	%r10,0+64(%rsp)
	movq	%r11,8+64(%rsp)
.align	4
.Lcbc_fast_dec_in_place_loop:
	movl	0(%r8),%eax
	movl	4(%r8),%ebx
	movl	8(%r8),%ecx
	movl	12(%r8),%edx
	movq	0(%rsp),%r15
	movq	%r8,24(%rsp)

	call	_x86_64_AES_decrypt

	movq	24(%rsp),%r8
	movq	40(%rsp),%r10
	xorl	0+64(%rsp),%eax
	xorl	4+64(%rsp),%ebx
	xorl	8+64(%rsp),%ecx
	xorl	12+64(%rsp),%edx

	movq	0(%r8),%r11
	movq	8(%r8),%r12
	subq	$16,%r10
	jz	.Lcbc_fast_dec_in_place_done

	movq	%r11,0+64(%rsp)
	movq	%r12,8+64(%rsp)

	movl	%eax,0(%r9)
	movl	%ebx,4(%r9)
	movl	%ecx,8(%r9)
	movl	%edx,12(%r9)

	leaq	16(%r8),%r8
	leaq	16(%r9),%r9
	movq	%r10,40(%rsp)
	jmp	.Lcbc_fast_dec_in_place_loop
.Lcbc_fast_dec_in_place_done:
	movq	56(%rsp),%rdi
	movq	%r11,0(%rdi)
	movq	%r12,8(%rdi)

	movl	%eax,0(%r9)
	movl	%ebx,4(%r9)
	movl	%ecx,8(%r9)
	movl	%edx,12(%r9)

.align	4
.Lcbc_fast_cleanup:
	cmpl	$0,80+240(%rsp)
	leaq	80(%rsp),%rdi
	je	.Lcbc_exit
	movl	$30,%ecx
	xorq	%rax,%rax
.long	0x90AB48F3

	jmp	.Lcbc_exit


.align	16
.Lcbc_slow_prologue:
.cfi_restore_state	

	leaq	-88(%rsp),%rbp
	andq	$-64,%rbp

	leaq	-88-63(%rcx),%r10
	subq	%rbp,%r10
	negq	%r10
	andq	$0x3c0,%r10
	subq	%r10,%rbp

	xchgq	%rsp,%rbp
.cfi_def_cfa_register	%rbp

	movq	%rbp,16(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x10,0x06,0x23,0x40
.Lcbc_slow_body:




	movq	%r8,56(%rsp)
	movq	%r8,%rbp
	movq	%r9,%rbx
	movq	%rsi,%r9
	movq	%rdi,%r8
	movq	%rcx,%r15
	movq	%rdx,%r10

	movl	240(%r15),%eax
	movq	%r15,0(%rsp)
	shll	$4,%eax
	leaq	(%r15,%rax,1),%rax
	movq	%rax,8(%rsp)


	leaq	2048(%r14),%r14
	leaq	768-8(%rsp),%rax
	subq	%r14,%rax
	andq	$0x300,%rax
	leaq	(%r14,%rax,1),%r14

	cmpq	$0,%rbx
	je	.LSLOW_DECRYPT


	testq	$-16,%r10
	movl	0(%rbp),%eax
	movl	4(%rbp),%ebx
	movl	8(%rbp),%ecx
	movl	12(%rbp),%edx
	jz	.Lcbc_slow_enc_tail

.align	4
.Lcbc_slow_enc_loop:
	xorl	0(%r8),%eax
	xorl	4(%r8),%ebx
	xorl	8(%r8),%ecx
	xorl	12(%r8),%edx
	movq	0(%rsp),%r15
	movq	%r8,24(%rsp)
	movq	%r9,32(%rsp)
	movq	%r10,40(%rsp)

	call	_x86_64_AES_encrypt_compact

	movq	24(%rsp),%r8
	movq	32(%rsp),%r9
	movq	40(%rsp),%r10
	movl	%eax,0(%r9)
	movl	%ebx,4(%r9)
	movl	%ecx,8(%r9)
	movl	%edx,12(%r9)

	leaq	16(%r8),%r8
	leaq	16(%r9),%r9
	subq	$16,%r10
	testq	$-16,%r10
	jnz	.Lcbc_slow_enc_loop
	testq	$15,%r10
	jnz	.Lcbc_slow_enc_tail
	movq	56(%rsp),%rbp
	movl	%eax,0(%rbp)
	movl	%ebx,4(%rbp)
	movl	%ecx,8(%rbp)
	movl	%edx,12(%rbp)

	jmp	.Lcbc_exit

.align	4
.Lcbc_slow_enc_tail:
	movq	%rax,%r11
	movq	%rcx,%r12
	movq	%r10,%rcx
	movq	%r8,%rsi
	movq	%r9,%rdi
.long	0x9066A4F3
	movq	$16,%rcx
	subq	%r10,%rcx
	xorq	%rax,%rax
.long	0x9066AAF3
	movq	%r9,%r8
	movq	$16,%r10
	movq	%r11,%rax
	movq	%r12,%rcx
	jmp	.Lcbc_slow_enc_loop

.align	16
.LSLOW_DECRYPT:
	shrq	$3,%rax
	addq	%rax,%r14

	movq	0(%rbp),%r11
	movq	8(%rbp),%r12
	movq	%r11,0+64(%rsp)
	movq	%r12,8+64(%rsp)

.align	4
.Lcbc_slow_dec_loop:
	movl	0(%r8),%eax
	movl	4(%r8),%ebx
	movl	8(%r8),%ecx
	movl	12(%r8),%edx
	movq	0(%rsp),%r15
	movq	%r8,24(%rsp)
	movq	%r9,32(%rsp)
	movq	%r10,40(%rsp)

	call	_x86_64_AES_decrypt_compact

	movq	24(%rsp),%r8
	movq	32(%rsp),%r9
	movq	40(%rsp),%r10
	xorl	0+64(%rsp),%eax
	xorl	4+64(%rsp),%ebx
	xorl	8+64(%rsp),%ecx
	xorl	12+64(%rsp),%edx

	movq	0(%r8),%r11
	movq	8(%r8),%r12
	subq	$16,%r10
	jc	.Lcbc_slow_dec_partial
	jz	.Lcbc_slow_dec_done

	movq	%r11,0+64(%rsp)
	movq	%r12,8+64(%rsp)

	movl	%eax,0(%r9)
	movl	%ebx,4(%r9)
	movl	%ecx,8(%r9)
	movl	%edx,12(%r9)

	leaq	16(%r8),%r8
	leaq	16(%r9),%r9
	jmp	.Lcbc_slow_dec_loop
.Lcbc_slow_dec_done:
	movq	56(%rsp),%rdi
	movq	%r11,0(%rdi)
	movq	%r12,8(%rdi)

	movl	%eax,0(%r9)
	movl	%ebx,4(%r9)
	movl	%ecx,8(%r9)
	movl	%edx,12(%r9)

	jmp	.Lcbc_exit

.align	4
.Lcbc_slow_dec_partial:
	movq	56(%rsp),%rdi
	movq	%r11,0(%rdi)
	movq	%r12,8(%rdi)

	movl	%eax,0+64(%rsp)
	movl	%ebx,4+64(%rsp)
	movl	%ecx,8+64(%rsp)
	movl	%edx,12+64(%rsp)

	movq	%r9,%rdi
	leaq	64(%rsp),%rsi
	leaq	16(%r10),%rcx
.long	0x9066A4F3
	jmp	.Lcbc_exit

.align	16
.Lcbc_exit:
	movq	16(%rsp),%rsi
.cfi_def_cfa	%rsi,64
	movq	(%rsi),%r15
.cfi_restore	%r15
	movq	8(%rsi),%r14
.cfi_restore	%r14
	movq	16(%rsi),%r13
.cfi_restore	%r13
	movq	24(%rsi),%r12
.cfi_restore	%r12
	movq	32(%rsi),%rbp
.cfi_restore	%rbp
	movq	40(%rsi),%rbx
.cfi_restore	%rbx
	leaq	48(%rsi),%rsp
.cfi_def_cfa	%rsp,16
.Lcbc_popfq:
	popfq


.cfi_adjust_cfa_offset	-8
.Lcbc_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	AES_cbc_encrypt,.-AES_cbc_encrypt
.align	64
.LAES_Te:
.long	0xa56363c6,0xa56363c6
.long	0x847c7cf8,0x847c7cf8
.long	0x997777ee,0x997777ee
.long	0x8d7b7bf6,0x8d7b7bf6
.long	0x0df2f2ff,0x0df2f2ff
.long	0xbd6b6bd6,0xbd6b6bd6
.long	0xb16f6fde,0xb16f6fde
.long	0x54c5c591,0x54c5c591
.long	0x50303060,0x50303060
.long	0x03010102,0x03010102
.long	0xa96767ce,0xa96767ce
.long	0x7d2b2b56,0x7d2b2b56
.long	0x19fefee7,0x19fefee7
.long	0x62d7d7b5,0x62d7d7b5
.long	0xe6abab4d,0xe6abab4d
.long	0x9a7676ec,0x9a7676ec
.long	0x45caca8f,0x45caca8f
.long	0x9d82821f,0x9d82821f
.long	0x40c9c989,0x40c9c989
.long	0x877d7dfa,0x877d7dfa
.long	0x15fafaef,0x15fafaef
.long	0xeb5959b2,0xeb5959b2
.long	0xc947478e,0xc947478e
.long	0x0bf0f0fb,0x0bf0f0fb
.long	0xecadad41,0xecadad41
.long	0x67d4d4b3,0x67d4d4b3
.long	0xfda2a25f,0xfda2a25f
.long	0xeaafaf45,0xeaafaf45
.long	0xbf9c9c23,0xbf9c9c23
.long	0xf7a4a453,0xf7a4a453
.long	0x967272e4,0x967272e4
.long	0x5bc0c09b,0x5bc0c09b
.long	0xc2b7b775,0xc2b7b775
.long	0x1cfdfde1,0x1cfdfde1
.long	0xae93933d,0xae93933d
.long	0x6a26264c,0x6a26264c
.long	0x5a36366c,0x5a36366c
.long	0x413f3f7e,0x413f3f7e
.long	0x02f7f7f5,0x02f7f7f5
.long	0x4fcccc83,0x4fcccc83
.long	0x5c343468,0x5c343468
.long	0xf4a5a551,0xf4a5a551
.long	0x34e5e5d1,0x34e5e5d1
.long	0x08f1f1f9,0x08f1f1f9
.long	0x937171e2,0x937171e2
.long	0x73d8d8ab,0x73d8d8ab
.long	0x53313162,0x53313162
.long	0x3f15152a,0x3f15152a
.long	0x0c040408,0x0c040408
.long	0x52c7c795,0x52c7c795
.long	0x65232346,0x65232346
.long	0x5ec3c39d,0x5ec3c39d
.long	0x28181830,0x28181830
.long	0xa1969637,0xa1969637
.long	0x0f05050a,0x0f05050a
.long	0xb59a9a2f,0xb59a9a2f
.long	0x0907070e,0x0907070e
.long	0x36121224,0x36121224
.long	0x9b80801b,0x9b80801b
.long	0x3de2e2df,0x3de2e2df
.long	0x26ebebcd,0x26ebebcd
.long	0x6927274e,0x6927274e
.long	0xcdb2b27f,0xcdb2b27f
.long	0x9f7575ea,0x9f7575ea
.long	0x1b090912,0x1b090912
.long	0x9e83831d,0x9e83831d
.long	0x742c2c58,0x742c2c58
.long	0x2e1a1a34,0x2e1a1a34
.long	0x2d1b1b36,0x2d1b1b36
.long	0xb26e6edc,0xb26e6edc
.long	0xee5a5ab4,0xee5a5ab4
.long	0xfba0a05b,0xfba0a05b
.long	0xf65252a4,0xf65252a4
.long	0x4d3b3b76,0x4d3b3b76
.long	0x61d6d6b7,0x61d6d6b7
.long	0xceb3b37d,0xceb3b37d
.long	0x7b292952,0x7b292952
.long	0x3ee3e3dd,0x3ee3e3dd
.long	0x712f2f5e,0x712f2f5e
.long	0x97848413,0x97848413
.long	0xf55353a6,0xf55353a6
.long	0x68d1d1b9,0x68d1d1b9
.long	0x00000000,0x00000000
.long	0x2cededc1,0x2cededc1
.long	0x60202040,0x60202040
.long	0x1ffcfce3,0x1ffcfce3
.long	0xc8b1b179,0xc8b1b179
.long	0xed5b5bb6,0xed5b5bb6
.long	0xbe6a6ad4,0xbe6a6ad4
.long	0x46cbcb8d,0x46cbcb8d
.long	0xd9bebe67,0xd9bebe67
.long	0x4b393972,0x4b393972
.long	0xde4a4a94,0xde4a4a94
.long	0xd44c4c98,0xd44c4c98
.long	0xe85858b0,0xe85858b0
.long	0x4acfcf85,0x4acfcf85
.long	0x6bd0d0bb,0x6bd0d0bb
.long	0x2aefefc5,0x2aefefc5
.long	0xe5aaaa4f,0xe5aaaa4f
.long	0x16fbfbed,0x16fbfbed
.long	0xc5434386,0xc5434386
.long	0xd74d4d9a,0xd74d4d9a
.long	0x55333366,0x55333366
.long	0x94858511,0x94858511
.long	0xcf45458a,0xcf45458a
.long	0x10f9f9e9,0x10f9f9e9
.long	0x06020204,0x06020204
.long	0x817f7ffe,0x817f7ffe
.long	0xf05050a0,0xf05050a0
.long	0x443c3c78,0x443c3c78
.long	0xba9f9f25,0xba9f9f25
.long	0xe3a8a84b,0xe3a8a84b
.long	0xf35151a2,0xf35151a2
.long	0xfea3a35d,0xfea3a35d
.long	0xc0404080,0xc0404080
.long	0x8a8f8f05,0x8a8f8f05
.long	0xad92923f,0xad92923f
.long	0xbc9d9d21,0xbc9d9d21
.long	0x48383870,0x48383870
.long	0x04f5f5f1,0x04f5f5f1
.long	0xdfbcbc63,0xdfbcbc63
.long	0xc1b6b677,0xc1b6b677
.long	0x75dadaaf,0x75dadaaf
.long	0x63212142,0x63212142
.long	0x30101020,0x30101020
.long	0x1affffe5,0x1affffe5
.long	0x0ef3f3fd,0x0ef3f3fd
.long	0x6dd2d2bf,0x6dd2d2bf
.long	0x4ccdcd81,0x4ccdcd81
.long	0x140c0c18,0x140c0c18
.long	0x35131326,0x35131326
.long	0x2fececc3,0x2fececc3
.long	0xe15f5fbe,0xe15f5fbe
.long	0xa2979735,0xa2979735
.long	0xcc444488,0xcc444488
.long	0x3917172e,0x3917172e
.long	0x57c4c493,0x57c4c493
.long	0xf2a7a755,0xf2a7a755
.long	0x827e7efc,0x827e7efc
.long	0x473d3d7a,0x473d3d7a
.long	0xac6464c8,0xac6464c8
.long	0xe75d5dba,0xe75d5dba
.long	0x2b191932,0x2b191932
.long	0x957373e6,0x957373e6
.long	0xa06060c0,0xa06060c0
.long	0x98818119,0x98818119
.long	0xd14f4f9e,0xd14f4f9e
.long	0x7fdcdca3,0x7fdcdca3
.long	0x66222244,0x66222244
.long	0x7e2a2a54,0x7e2a2a54
.long	0xab90903b,0xab90903b
.long	0x8388880b,0x8388880b
.long	0xca46468c,0xca46468c
.long	0x29eeeec7,0x29eeeec7
.long	0xd3b8b86b,0xd3b8b86b
.long	0x3c141428,0x3c141428
.long	0x79dedea7,0x79dedea7
.long	0xe25e5ebc,0xe25e5ebc
.long	0x1d0b0b16,0x1d0b0b16
.long	0x76dbdbad,0x76dbdbad
.long	0x3be0e0db,0x3be0e0db
.long	0x56323264,0x56323264
.long	0x4e3a3a74,0x4e3a3a74
.long	0x1e0a0a14,0x1e0a0a14
.long	0xdb494992,0xdb494992
.long	0x0a06060c,0x0a06060c
.long	0x6c242448,0x6c242448
.long	0xe45c5cb8,0xe45c5cb8
.long	0x5dc2c29f,0x5dc2c29f
.long	0x6ed3d3bd,0x6ed3d3bd
.long	0xefacac43,0xefacac43
.long	0xa66262c4,0xa66262c4
.long	0xa8919139,0xa8919139
.long	0xa4959531,0xa4959531
.long	0x37e4e4d3,0x37e4e4d3
.long	0x8b7979f2,0x8b7979f2
.long	0x32e7e7d5,0x32e7e7d5
.long	0x43c8c88b,0x43c8c88b
.long	0x5937376e,0x5937376e
.long	0xb76d6dda,0xb76d6dda
.long	0x8c8d8d01,0x8c8d8d01
.long	0x64d5d5b1,0x64d5d5b1
.long	0xd24e4e9c,0xd24e4e9c
.long	0xe0a9a949,0xe0a9a949
.long	0xb46c6cd8,0xb46c6cd8
.long	0xfa5656ac,0xfa5656ac
.long	0x07f4f4f3,0x07f4f4f3
.long	0x25eaeacf,0x25eaeacf
.long	0xaf6565ca,0xaf6565ca
.long	0x8e7a7af4,0x8e7a7af4
.long	0xe9aeae47,0xe9aeae47
.long	0x18080810,0x18080810
.long	0xd5baba6f,0xd5baba6f
.long	0x887878f0,0x887878f0
.long	0x6f25254a,0x6f25254a
.long	0x722e2e5c,0x722e2e5c
.long	0x241c1c38,0x241c1c38
.long	0xf1a6a657,0xf1a6a657
.long	0xc7b4b473,0xc7b4b473
.long	0x51c6c697,0x51c6c697
.long	0x23e8e8cb,0x23e8e8cb
.long	0x7cdddda1,0x7cdddda1
.long	0x9c7474e8,0x9c7474e8
.long	0x211f1f3e,0x211f1f3e
.long	0xdd4b4b96,0xdd4b4b96
.long	0xdcbdbd61,0xdcbdbd61
.long	0x868b8b0d,0x868b8b0d
.long	0x858a8a0f,0x858a8a0f
.long	0x907070e0,0x907070e0
.long	0x423e3e7c,0x423e3e7c
.long	0xc4b5b571,0xc4b5b571
.long	0xaa6666cc,0xaa6666cc
.long	0xd8484890,0xd8484890
.long	0x05030306,0x05030306
.long	0x01f6f6f7,0x01f6f6f7
.long	0x120e0e1c,0x120e0e1c
.long	0xa36161c2,0xa36161c2
.long	0x5f35356a,0x5f35356a
.long	0xf95757ae,0xf95757ae
.long	0xd0b9b969,0xd0b9b969
.long	0x91868617,0x91868617
.long	0x58c1c199,0x58c1c199
.long	0x271d1d3a,0x271d1d3a
.long	0xb99e9e27,0xb99e9e27
.long	0x38e1e1d9,0x38e1e1d9
.long	0x13f8f8eb,0x13f8f8eb
.long	0xb398982b,0xb398982b
.long	0x33111122,0x33111122
.long	0xbb6969d2,0xbb6969d2
.long	0x70d9d9a9,0x70d9d9a9
.long	0x898e8e07,0x898e8e07
.long	0xa7949433,0xa7949433
.long	0xb69b9b2d,0xb69b9b2d
.long	0x221e1e3c,0x221e1e3c
.long	0x92878715,0x92878715
.long	0x20e9e9c9,0x20e9e9c9
.long	0x49cece87,0x49cece87
.long	0xff5555aa,0xff5555aa
.long	0x78282850,0x78282850
.long	0x7adfdfa5,0x7adfdfa5
.long	0x8f8c8c03,0x8f8c8c03
.long	0xf8a1a159,0xf8a1a159
.long	0x80898909,0x80898909
.long	0x170d0d1a,0x170d0d1a
.long	0xdabfbf65,0xdabfbf65
.long	0x31e6e6d7,0x31e6e6d7
.long	0xc6424284,0xc6424284
.long	0xb86868d0,0xb86868d0
.long	0xc3414182,0xc3414182
.long	0xb0999929,0xb0999929
.long	0x772d2d5a,0x772d2d5a
.long	0x110f0f1e,0x110f0f1e
.long	0xcbb0b07b,0xcbb0b07b
.long	0xfc5454a8,0xfc5454a8
.long	0xd6bbbb6d,0xd6bbbb6d
.long	0x3a16162c,0x3a16162c
.byte	0x63,0x7c,0x77,0x7b,0xf2,0x6b,0x6f,0xc5
.byte	0x30,0x01,0x67,0x2b,0xfe,0xd7,0xab,0x76
.byte	0xca,0x82,0xc9,0x7d,0xfa,0x59,0x47,0xf0
.byte	0xad,0xd4,0xa2,0xaf,0x9c,0xa4,0x72,0xc0
.byte	0xb7,0xfd,0x93,0x26,0x36,0x3f,0xf7,0xcc
.byte	0x34,0xa5,0xe5,0xf1,0x71,0xd8,0x31,0x15
.byte	0x04,0xc7,0x23,0xc3,0x18,0x96,0x05,0x9a
.byte	0x07,0x12,0x80,0xe2,0xeb,0x27,0xb2,0x75
.byte	0x09,0x83,0x2c,0x1a,0x1b,0x6e,0x5a,0xa0
.byte	0x52,0x3b,0xd6,0xb3,0x29,0xe3,0x2f,0x84
.byte	0x53,0xd1,0x00,0xed,0x20,0xfc,0xb1,0x5b
.byte	0x6a,0xcb,0xbe,0x39,0x4a,0x4c,0x58,0xcf
.byte	0xd0,0xef,0xaa,0xfb,0x43,0x4d,0x33,0x85
.byte	0x45,0xf9,0x02,0x7f,0x50,0x3c,0x9f,0xa8
.byte	0x51,0xa3,0x40,0x8f,0x92,0x9d,0x38,0xf5
.byte	0xbc,0xb6,0xda,0x21,0x10,0xff,0xf3,0xd2
.byte	0xcd,0x0c,0x13,0xec,0x5f,0x97,0x44,0x17
.byte	0xc4,0xa7,0x7e,0x3d,0x64,0x5d,0x19,0x73
.byte	0x60,0x81,0x4f,0xdc,0x22,0x2a,0x90,0x88
.byte	0x46,0xee,0xb8,0x14,0xde,0x5e,0x0b,0xdb
.byte	0xe0,0x32,0x3a,0x0a,0x49,0x06,0x24,0x5c
.byte	0xc2,0xd3,0xac,0x62,0x91,0x95,0xe4,0x79
.byte	0xe7,0xc8,0x37,0x6d,0x8d,0xd5,0x4e,0xa9
.byte	0x6c,0x56,0xf4,0xea,0x65,0x7a,0xae,0x08
.byte	0xba,0x78,0x25,0x2e,0x1c,0xa6,0xb4,0xc6
.byte	0xe8,0xdd,0x74,0x1f,0x4b,0xbd,0x8b,0x8a
.byte	0x70,0x3e,0xb5,0x66,0x48,0x03,0xf6,0x0e
.byte	0x61,0x35,0x57,0xb9,0x86,0xc1,0x1d,0x9e
.byte	0xe1,0xf8,0x98,0x11,0x69,0xd9,0x8e,0x94
.byte	0x9b,0x1e,0x87,0xe9,0xce,0x55,0x28,0xdf
.byte	0x8c,0xa1,0x89,0x0d,0xbf,0xe6,0x42,0x68
.byte	0x41,0x99,0x2d,0x0f,0xb0,0x54,0xbb,0x16
.byte	0x63,0x7c,0x77,0x7b,0xf2,0x6b,0x6f,0xc5
.byte	0x30,0x01,0x67,0x2b,0xfe,0xd7,0xab,0x76
.byte	0xca,0x82,0xc9,0x7d,0xfa,0x59,0x47,0xf0
.byte	0xad,0xd4,0xa2,0xaf,0x9c,0xa4,0x72,0xc0
.byte	0xb7,0xfd,0x93,0x26,0x36,0x3f,0xf7,0xcc
.byte	0x34,0xa5,0xe5,0xf1,0x71,0xd8,0x31,0x15
.byte	0x04,0xc7,0x23,0xc3,0x18,0x96,0x05,0x9a
.byte	0x07,0x12,0x80,0xe2,0xeb,0x27,0xb2,0x75
.byte	0x09,0x83,0x2c,0x1a,0x1b,0x6e,0x5a,0xa0
.byte	0x52,0x3b,0xd6,0xb3,0x29,0xe3,0x2f,0x84
.byte	0x53,0xd1,0x00,0xed,0x20,0xfc,0xb1,0x5b
.byte	0x6a,0xcb,0xbe,0x39,0x4a,0x4c,0x58,0xcf
.byte	0xd0,0xef,0xaa,0xfb,0x43,0x4d,0x33,0x85
.byte	0x45,0xf9,0x02,0x7f,0x50,0x3c,0x9f,0xa8
.byte	0x51,0xa3,0x40,0x8f,0x92,0x9d,0x38,0xf5
.byte	0xbc,0xb6,0xda,0x21,0x10,0xff,0xf3,0xd2
.byte	0xcd,0x0c,0x13,0xec,0x5f,0x97,0x44,0x17
.byte	0xc4,0xa7,0x7e,0x3d,0x64,0x5d,0x19,0x73
.byte	0x60,0x81,0x4f,0xdc,0x22,0x2a,0x90,0x88
.byte	0x46,0xee,0xb8,0x14,0xde,0x5e,0x0b,0xdb
.byte	0xe0,0x32,0x3a,0x0a,0x49,0x06,0x24,0x5c
.byte	0xc2,0xd3,0xac,0x62,0x91,0x95,0xe4,0x79
.byte	0xe7,0xc8,0x37,0x6d,0x8d,0xd5,0x4e,0xa9
.byte	0x6c,0x56,0xf4,0xea,0x65,0x7a,0xae,0x08
.byte	0xba,0x78,0x25,0x2e,0x1c,0xa6,0xb4,0xc6
.byte	0xe8,0xdd,0x74,0x1f,0x4b,0xbd,0x8b,0x8a
.byte	0x70,0x3e,0xb5,0x66,0x48,0x03,0xf6,0x0e
.byte	0x61,0x35,0x57,0xb9,0x86,0xc1,0x1d,0x9e
.byte	0xe1,0xf8,0x98,0x11,0x69,0xd9,0x8e,0x94
.byte	0x9b,0x1e,0x87,0xe9,0xce,0x55,0x28,0xdf
.byte	0x8c,0xa1,0x89,0x0d,0xbf,0xe6,0x42,0x68
.byte	0x41,0x99,0x2d,0x0f,0xb0,0x54,0xbb,0x16
.byte	0x63,0x7c,0x77,0x7b,0xf2,0x6b,0x6f,0xc5
.byte	0x30,0x01,0x67,0x2b,0xfe,0xd7,0xab,0x76
.byte	0xca,0x82,0xc9,0x7d,0xfa,0x59,0x47,0xf0
.byte	0xad,0xd4,0xa2,0xaf,0x9c,0xa4,0x72,0xc0
.byte	0xb7,0xfd,0x93,0x26,0x36,0x3f,0xf7,0xcc
.byte	0x34,0xa5,0xe5,0xf1,0x71,0xd8,0x31,0x15
.byte	0x04,0xc7,0x23,0xc3,0x18,0x96,0x05,0x9a
.byte	0x07,0x12,0x80,0xe2,0xeb,0x27,0xb2,0x75
.byte	0x09,0x83,0x2c,0x1a,0x1b,0x6e,0x5a,0xa0
.byte	0x52,0x3b,0xd6,0xb3,0x29,0xe3,0x2f,0x84
.byte	0x53,0xd1,0x00,0xed,0x20,0xfc,0xb1,0x5b
.byte	0x6a,0xcb,0xbe,0x39,0x4a,0x4c,0x58,0xcf
.byte	0xd0,0xef,0xaa,0xfb,0x43,0x4d,0x33,0x85
.byte	0x45,0xf9,0x02,0x7f,0x50,0x3c,0x9f,0xa8
.byte	0x51,0xa3,0x40,0x8f,0x92,0x9d,0x38,0xf5
.byte	0xbc,0xb6,0xda,0x21,0x10,0xff,0xf3,0xd2
.byte	0xcd,0x0c,0x13,0xec,0x5f,0x97,0x44,0x17
.byte	0xc4,0xa7,0x7e,0x3d,0x64,0x5d,0x19,0x73
.byte	0x60,0x81,0x4f,0xdc,0x22,0x2a,0x90,0x88
.byte	0x46,0xee,0xb8,0x14,0xde,0x5e,0x0b,0xdb
.byte	0xe0,0x32,0x3a,0x0a,0x49,0x06,0x24,0x5c
.byte	0xc2,0xd3,0xac,0x62,0x91,0x95,0xe4,0x79
.byte	0xe7,0xc8,0x37,0x6d,0x8d,0xd5,0x4e,0xa9
.byte	0x6c,0x56,0xf4,0xea,0x65,0x7a,0xae,0x08
.byte	0xba,0x78,0x25,0x2e,0x1c,0xa6,0xb4,0xc6
.byte	0xe8,0xdd,0x74,0x1f,0x4b,0xbd,0x8b,0x8a
.byte	0x70,0x3e,0xb5,0x66,0x48,0x03,0xf6,0x0e
.byte	0x61,0x35,0x57,0xb9,0x86,0xc1,0x1d,0x9e
.byte	0xe1,0xf8,0x98,0x11,0x69,0xd9,0x8e,0x94
.byte	0x9b,0x1e,0x87,0xe9,0xce,0x55,0x28,0xdf
.byte	0x8c,0xa1,0x89,0x0d,0xbf,0xe6,0x42,0x68
.byte	0x41,0x99,0x2d,0x0f,0xb0,0x54,0xbb,0x16
.byte	0x63,0x7c,0x77,0x7b,0xf2,0x6b,0x6f,0xc5
.byte	0x30,0x01,0x67,0x2b,0xfe,0xd7,0xab,0x76
.byte	0xca,0x82,0xc9,0x7d,0xfa,0x59,0x47,0xf0
.byte	0xad,0xd4,0xa2,0xaf,0x9c,0xa4,0x72,0xc0
.byte	0xb7,0xfd,0x93,0x26,0x36,0x3f,0xf7,0xcc
.byte	0x34,0xa5,0xe5,0xf1,0x71,0xd8,0x31,0x15
.byte	0x04,0xc7,0x23,0xc3,0x18,0x96,0x05,0x9a
.byte	0x07,0x12,0x80,0xe2,0xeb,0x27,0xb2,0x75
.byte	0x09,0x83,0x2c,0x1a,0x1b,0x6e,0x5a,0xa0
.byte	0x52,0x3b,0xd6,0xb3,0x29,0xe3,0x2f,0x84
.byte	0x53,0xd1,0x00,0xed,0x20,0xfc,0xb1,0x5b
.byte	0x6a,0xcb,0xbe,0x39,0x4a,0x4c,0x58,0xcf
.byte	0xd0,0xef,0xaa,0xfb,0x43,0x4d,0x33,0x85
.byte	0x45,0xf9,0x02,0x7f,0x50,0x3c,0x9f,0xa8
.byte	0x51,0xa3,0x40,0x8f,0x92,0x9d,0x38,0xf5
.byte	0xbc,0xb6,0xda,0x21,0x10,0xff,0xf3,0xd2
.byte	0xcd,0x0c,0x13,0xec,0x5f,0x97,0x44,0x17
.byte	0xc4,0xa7,0x7e,0x3d,0x64,0x5d,0x19,0x73
.byte	0x60,0x81,0x4f,0xdc,0x22,0x2a,0x90,0x88
.byte	0x46,0xee,0xb8,0x14,0xde,0x5e,0x0b,0xdb
.byte	0xe0,0x32,0x3a,0x0a,0x49,0x06,0x24,0x5c
.byte	0xc2,0xd3,0xac,0x62,0x91,0x95,0xe4,0x79
.byte	0xe7,0xc8,0x37,0x6d,0x8d,0xd5,0x4e,0xa9
.byte	0x6c,0x56,0xf4,0xea,0x65,0x7a,0xae,0x08
.byte	0xba,0x78,0x25,0x2e,0x1c,0xa6,0xb4,0xc6
.byte	0xe8,0xdd,0x74,0x1f,0x4b,0xbd,0x8b,0x8a
.byte	0x70,0x3e,0xb5,0x66,0x48,0x03,0xf6,0x0e
.byte	0x61,0x35,0x57,0xb9,0x86,0xc1,0x1d,0x9e
.byte	0xe1,0xf8,0x98,0x11,0x69,0xd9,0x8e,0x94
.byte	0x9b,0x1e,0x87,0xe9,0xce,0x55,0x28,0xdf
.byte	0x8c,0xa1,0x89,0x0d,0xbf,0xe6,0x42,0x68
.byte	0x41,0x99,0x2d,0x0f,0xb0,0x54,0xbb,0x16
.long	0x00000001, 0x00000002, 0x00000004, 0x00000008
.long	0x00000010, 0x00000020, 0x00000040, 0x00000080
.long	0x0000001b, 0x00000036, 0x80808080, 0x80808080
.long	0xfefefefe, 0xfefefefe, 0x1b1b1b1b, 0x1b1b1b1b
.align	64
.LAES_Td:
.long	0x50a7f451,0x50a7f451
.long	0x5365417e,0x5365417e
.long	0xc3a4171a,0xc3a4171a
.long	0x965e273a,0x965e273a
.long	0xcb6bab3b,0xcb6bab3b
.long	0xf1459d1f,0xf1459d1f
.long	0xab58faac,0xab58faac
.long	0x9303e34b,0x9303e34b
.long	0x55fa3020,0x55fa3020
.long	0xf66d76ad,0xf66d76ad
.long	0x9176cc88,0x9176cc88
.long	0x254c02f5,0x254c02f5
.long	0xfcd7e54f,0xfcd7e54f
.long	0xd7cb2ac5,0xd7cb2ac5
.long	0x80443526,0x80443526
.long	0x8fa362b5,0x8fa362b5
.long	0x495ab1de,0x495ab1de
.long	0x671bba25,0x671bba25
.long	0x980eea45,0x980eea45
.long	0xe1c0fe5d,0xe1c0fe5d
.long	0x02752fc3,0x02752fc3
.long	0x12f04c81,0x12f04c81
.long	0xa397468d,0xa397468d
.long	0xc6f9d36b,0xc6f9d36b
.long	0xe75f8f03,0xe75f8f03
.long	0x959c9215,0x959c9215
.long	0xeb7a6dbf,0xeb7a6dbf
.long	0xda595295,0xda595295
.long	0x2d83bed4,0x2d83bed4
.long	0xd3217458,0xd3217458
.long	0x2969e049,0x2969e049
.long	0x44c8c98e,0x44c8c98e
.long	0x6a89c275,0x6a89c275
.long	0x78798ef4,0x78798ef4
.long	0x6b3e5899,0x6b3e5899
.long	0xdd71b927,0xdd71b927
.long	0xb64fe1be,0xb64fe1be
.long	0x17ad88f0,0x17ad88f0
.long	0x66ac20c9,0x66ac20c9
.long	0xb43ace7d,0xb43ace7d
.long	0x184adf63,0x184adf63
.long	0x82311ae5,0x82311ae5
.long	0x60335197,0x60335197
.long	0x457f5362,0x457f5362
.long	0xe07764b1,0xe07764b1
.long	0x84ae6bbb,0x84ae6bbb
.long	0x1ca081fe,0x1ca081fe
.long	0x942b08f9,0x942b08f9
.long	0x58684870,0x58684870
.long	0x19fd458f,0x19fd458f
.long	0x876cde94,0x876cde94
.long	0xb7f87b52,0xb7f87b52
.long	0x23d373ab,0x23d373ab
.long	0xe2024b72,0xe2024b72
.long	0x578f1fe3,0x578f1fe3
.long	0x2aab5566,0x2aab5566
.long	0x0728ebb2,0x0728ebb2
.long	0x03c2b52f,0x03c2b52f
.long	0x9a7bc586,0x9a7bc586
.long	0xa50837d3,0xa50837d3
.long	0xf2872830,0xf2872830
.long	0xb2a5bf23,0xb2a5bf23
.long	0xba6a0302,0xba6a0302
.long	0x5c8216ed,0x5c8216ed
.long	0x2b1ccf8a,0x2b1ccf8a
.long	0x92b479a7,0x92b479a7
.long	0xf0f207f3,0xf0f207f3
.long	0xa1e2694e,0xa1e2694e
.long	0xcdf4da65,0xcdf4da65
.long	0xd5be0506,0xd5be0506
.long	0x1f6234d1,0x1f6234d1
.long	0x8afea6c4,0x8afea6c4
.long	0x9d532e34,0x9d532e34
.long	0xa055f3a2,0xa055f3a2
.long	0x32e18a05,0x32e18a05
.long	0x75ebf6a4,0x75ebf6a4
.long	0x39ec830b,0x39ec830b
.long	0xaaef6040,0xaaef6040
.long	0x069f715e,0x069f715e
.long	0x51106ebd,0x51106ebd
.long	0xf98a213e,0xf98a213e
.long	0x3d06dd96,0x3d06dd96
.long	0xae053edd,0xae053edd
.long	0x46bde64d,0x46bde64d
.long	0xb58d5491,0xb58d5491
.long	0x055dc471,0x055dc471
.long	0x6fd40604,0x6fd40604
.long	0xff155060,0xff155060
.long	0x24fb9819,0x24fb9819
.long	0x97e9bdd6,0x97e9bdd6
.long	0xcc434089,0xcc434089
.long	0x779ed967,0x779ed967
.long	0xbd42e8b0,0xbd42e8b0
.long	0x888b8907,0x888b8907
.long	0x385b19e7,0x385b19e7
.long	0xdbeec879,0xdbeec879
.long	0x470a7ca1,0x470a7ca1
.long	0xe90f427c,0xe90f427c
.long	0xc91e84f8,0xc91e84f8
.long	0x00000000,0x00000000
.long	0x83868009,0x83868009
.long	0x48ed2b32,0x48ed2b32
.long	0xac70111e,0xac70111e
.long	0x4e725a6c,0x4e725a6c
.long	0xfbff0efd,0xfbff0efd
.long	0x5638850f,0x5638850f
.long	0x1ed5ae3d,0x1ed5ae3d
.long	0x27392d36,0x27392d36
.long	0x64d90f0a,0x64d90f0a
.long	0x21a65c68,0x21a65c68
.long	0xd1545b9b,0xd1545b9b
.long	0x3a2e3624,0x3a2e3624
.long	0xb1670a0c,0xb1670a0c
.long	0x0fe75793,0x0fe75793
.long	0xd296eeb4,0xd296eeb4
.long	0x9e919b1b,0x9e919b1b
.long	0x4fc5c080,0x4fc5c080
.long	0xa220dc61,0xa220dc61
.long	0x694b775a,0x694b775a
.long	0x161a121c,0x161a121c
.long	0x0aba93e2,0x0aba93e2
.long	0xe52aa0c0,0xe52aa0c0
.long	0x43e0223c,0x43e0223c
.long	0x1d171b12,0x1d171b12
.long	0x0b0d090e,0x0b0d090e
.long	0xadc78bf2,0xadc78bf2
.long	0xb9a8b62d,0xb9a8b62d
.long	0xc8a91e14,0xc8a91e14
.long	0x8519f157,0x8519f157
.long	0x4c0775af,0x4c0775af
.long	0xbbdd99ee,0xbbdd99ee
.long	0xfd607fa3,0xfd607fa3
.long	0x9f2601f7,0x9f2601f7
.long	0xbcf5725c,0xbcf5725c
.long	0xc53b6644,0xc53b6644
.long	0x347efb5b,0x347efb5b
.long	0x7629438b,0x7629438b
.long	0xdcc623cb,0xdcc623cb
.long	0x68fcedb6,0x68fcedb6
.long	0x63f1e4b8,0x63f1e4b8
.long	0xcadc31d7,0xcadc31d7
.long	0x10856342,0x10856342
.long	0x40229713,0x40229713
.long	0x2011c684,0x2011c684
.long	0x7d244a85,0x7d244a85
.long	0xf83dbbd2,0xf83dbbd2
.long	0x1132f9ae,0x1132f9ae
.long	0x6da129c7,0x6da129c7
.long	0x4b2f9e1d,0x4b2f9e1d
.long	0xf330b2dc,0xf330b2dc
.long	0xec52860d,0xec52860d
.long	0xd0e3c177,0xd0e3c177
.long	0x6c16b32b,0x6c16b32b
.long	0x99b970a9,0x99b970a9
.long	0xfa489411,0xfa489411
.long	0x2264e947,0x2264e947
.long	0xc48cfca8,0xc48cfca8
.long	0x1a3ff0a0,0x1a3ff0a0
.long	0xd82c7d56,0xd82c7d56
.long	0xef903322,0xef903322
.long	0xc74e4987,0xc74e4987
.long	0xc1d138d9,0xc1d138d9
.long	0xfea2ca8c,0xfea2ca8c
.long	0x360bd498,0x360bd498
.long	0xcf81f5a6,0xcf81f5a6
.long	0x28de7aa5,0x28de7aa5
.long	0x268eb7da,0x268eb7da
.long	0xa4bfad3f,0xa4bfad3f
.long	0xe49d3a2c,0xe49d3a2c
.long	0x0d927850,0x0d927850
.long	0x9bcc5f6a,0x9bcc5f6a
.long	0x62467e54,0x62467e54
.long	0xc2138df6,0xc2138df6
.long	0xe8b8d890,0xe8b8d890
.long	0x5ef7392e,0x5ef7392e
.long	0xf5afc382,0xf5afc382
.long	0xbe805d9f,0xbe805d9f
.long	0x7c93d069,0x7c93d069
.long	0xa92dd56f,0xa92dd56f
.long	0xb31225cf,0xb31225cf
.long	0x3b99acc8,0x3b99acc8
.long	0xa77d1810,0xa77d1810
.long	0x6e639ce8,0x6e639ce8
.long	0x7bbb3bdb,0x7bbb3bdb
.long	0x097826cd,0x097826cd
.long	0xf418596e,0xf418596e
.long	0x01b79aec,0x01b79aec
.long	0xa89a4f83,0xa89a4f83
.long	0x656e95e6,0x656e95e6
.long	0x7ee6ffaa,0x7ee6ffaa
.long	0x08cfbc21,0x08cfbc21
.long	0xe6e815ef,0xe6e815ef
.long	0xd99be7ba,0xd99be7ba
.long	0xce366f4a,0xce366f4a
.long	0xd4099fea,0xd4099fea
.long	0xd67cb029,0xd67cb029
.long	0xafb2a431,0xafb2a431
.long	0x31233f2a,0x31233f2a
.long	0x3094a5c6,0x3094a5c6
.long	0xc066a235,0xc066a235
.long	0x37bc4e74,0x37bc4e74
.long	0xa6ca82fc,0xa6ca82fc
.long	0xb0d090e0,0xb0d090e0
.long	0x15d8a733,0x15d8a733
.long	0x4a9804f1,0x4a9804f1
.long	0xf7daec41,0xf7daec41
.long	0x0e50cd7f,0x0e50cd7f
.long	0x2ff69117,0x2ff69117
.long	0x8dd64d76,0x8dd64d76
.long	0x4db0ef43,0x4db0ef43
.long	0x544daacc,0x544daacc
.long	0xdf0496e4,0xdf0496e4
.long	0xe3b5d19e,0xe3b5d19e
.long	0x1b886a4c,0x1b886a4c
.long	0xb81f2cc1,0xb81f2cc1
.long	0x7f516546,0x7f516546
.long	0x04ea5e9d,0x04ea5e9d
.long	0x5d358c01,0x5d358c01
.long	0x737487fa,0x737487fa
.long	0x2e410bfb,0x2e410bfb
.long	0x5a1d67b3,0x5a1d67b3
.long	0x52d2db92,0x52d2db92
.long	0x335610e9,0x335610e9
.long	0x1347d66d,0x1347d66d
.long	0x8c61d79a,0x8c61d79a
.long	0x7a0ca137,0x7a0ca137
.long	0x8e14f859,0x8e14f859
.long	0x893c13eb,0x893c13eb
.long	0xee27a9ce,0xee27a9ce
.long	0x35c961b7,0x35c961b7
.long	0xede51ce1,0xede51ce1
.long	0x3cb1477a,0x3cb1477a
.long	0x59dfd29c,0x59dfd29c
.long	0x3f73f255,0x3f73f255
.long	0x79ce1418,0x79ce1418
.long	0xbf37c773,0xbf37c773
.long	0xeacdf753,0xeacdf753
.long	0x5baafd5f,0x5baafd5f
.long	0x146f3ddf,0x146f3ddf
.long	0x86db4478,0x86db4478
.long	0x81f3afca,0x81f3afca
.long	0x3ec468b9,0x3ec468b9
.long	0x2c342438,0x2c342438
.long	0x5f40a3c2,0x5f40a3c2
.long	0x72c31d16,0x72c31d16
.long	0x0c25e2bc,0x0c25e2bc
.long	0x8b493c28,0x8b493c28
.long	0x41950dff,0x41950dff
.long	0x7101a839,0x7101a839
.long	0xdeb30c08,0xdeb30c08
.long	0x9ce4b4d8,0x9ce4b4d8
.long	0x90c15664,0x90c15664
.long	0x6184cb7b,0x6184cb7b
.long	0x70b632d5,0x70b632d5
.long	0x745c6c48,0x745c6c48
.long	0x4257b8d0,0x4257b8d0
.byte	0x52,0x09,0x6a,0xd5,0x30,0x36,0xa5,0x38
.byte	0xbf,0x40,0xa3,0x9e,0x81,0xf3,0xd7,0xfb
.byte	0x7c,0xe3,0x39,0x82,0x9b,0x2f,0xff,0x87
.byte	0x34,0x8e,0x43,0x44,0xc4,0xde,0xe9,0xcb
.byte	0x54,0x7b,0x94,0x32,0xa6,0xc2,0x23,0x3d
.byte	0xee,0x4c,0x95,0x0b,0x42,0xfa,0xc3,0x4e
.byte	0x08,0x2e,0xa1,0x66,0x28,0xd9,0x24,0xb2
.byte	0x76,0x5b,0xa2,0x49,0x6d,0x8b,0xd1,0x25
.byte	0x72,0xf8,0xf6,0x64,0x86,0x68,0x98,0x16
.byte	0xd4,0xa4,0x5c,0xcc,0x5d,0x65,0xb6,0x92
.byte	0x6c,0x70,0x48,0x50,0xfd,0xed,0xb9,0xda
.byte	0x5e,0x15,0x46,0x57,0xa7,0x8d,0x9d,0x84
.byte	0x90,0xd8,0xab,0x00,0x8c,0xbc,0xd3,0x0a
.byte	0xf7,0xe4,0x58,0x05,0xb8,0xb3,0x45,0x06
.byte	0xd0,0x2c,0x1e,0x8f,0xca,0x3f,0x0f,0x02
.byte	0xc1,0xaf,0xbd,0x03,0x01,0x13,0x8a,0x6b
.byte	0x3a,0x91,0x11,0x41,0x4f,0x67,0xdc,0xea
.byte	0x97,0xf2,0xcf,0xce,0xf0,0xb4,0xe6,0x73
.byte	0x96,0xac,0x74,0x22,0xe7,0xad,0x35,0x85
.byte	0xe2,0xf9,0x37,0xe8,0x1c,0x75,0xdf,0x6e
.byte	0x47,0xf1,0x1a,0x71,0x1d,0x29,0xc5,0x89
.byte	0x6f,0xb7,0x62,0x0e,0xaa,0x18,0xbe,0x1b
.byte	0xfc,0x56,0x3e,0x4b,0xc6,0xd2,0x79,0x20
.byte	0x9a,0xdb,0xc0,0xfe,0x78,0xcd,0x5a,0xf4
.byte	0x1f,0xdd,0xa8,0x33,0x88,0x07,0xc7,0x31
.byte	0xb1,0x12,0x10,0x59,0x27,0x80,0xec,0x5f
.byte	0x60,0x51,0x7f,0xa9,0x19,0xb5,0x4a,0x0d
.byte	0x2d,0xe5,0x7a,0x9f,0x93,0xc9,0x9c,0xef
.byte	0xa0,0xe0,0x3b,0x4d,0xae,0x2a,0xf5,0xb0
.byte	0xc8,0xeb,0xbb,0x3c,0x83,0x53,0x99,0x61
.byte	0x17,0x2b,0x04,0x7e,0xba,0x77,0xd6,0x26
.byte	0xe1,0x69,0x14,0x63,0x55,0x21,0x0c,0x7d
.long	0x80808080, 0x80808080, 0xfefefefe, 0xfefefefe
.long	0x1b1b1b1b, 0x1b1b1b1b, 0, 0
.byte	0x52,0x09,0x6a,0xd5,0x30,0x36,0xa5,0x38
.byte	0xbf,0x40,0xa3,0x9e,0x81,0xf3,0xd7,0xfb
.byte	0x7c,0xe3,0x39,0x82,0x9b,0x2f,0xff,0x87
.byte	0x34,0x8e,0x43,0x44,0xc4,0xde,0xe9,0xcb
.byte	0x54,0x7b,0x94,0x32,0xa6,0xc2,0x23,0x3d
.byte	0xee,0x4c,0x95,0x0b,0x42,0xfa,0xc3,0x4e
.byte	0x08,0x2e,0xa1,0x66,0x28,0xd9,0x24,0xb2
.byte	0x76,0x5b,0xa2,0x49,0x6d,0x8b,0xd1,0x25
.byte	0x72,0xf8,0xf6,0x64,0x86,0x68,0x98,0x16
.byte	0xd4,0xa4,0x5c,0xcc,0x5d,0x65,0xb6,0x92
.byte	0x6c,0x70,0x48,0x50,0xfd,0xed,0xb9,0xda
.byte	0x5e,0x15,0x46,0x57,0xa7,0x8d,0x9d,0x84
.byte	0x90,0xd8,0xab,0x00,0x8c,0xbc,0xd3,0x0a
.byte	0xf7,0xe4,0x58,0x05,0xb8,0xb3,0x45,0x06
.byte	0xd0,0x2c,0x1e,0x8f,0xca,0x3f,0x0f,0x02
.byte	0xc1,0xaf,0xbd,0x03,0x01,0x13,0x8a,0x6b
.byte	0x3a,0x91,0x11,0x41,0x4f,0x67,0xdc,0xea
.byte	0x97,0xf2,0xcf,0xce,0xf0,0xb4,0xe6,0x73
.byte	0x96,0xac,0x74,0x22,0xe7,0xad,0x35,0x85
.byte	0xe2,0xf9,0x37,0xe8,0x1c,0x75,0xdf,0x6e
.byte	0x47,0xf1,0x1a,0x71,0x1d,0x29,0xc5,0x89
.byte	0x6f,0xb7,0x62,0x0e,0xaa,0x18,0xbe,0x1b
.byte	0xfc,0x56,0x3e,0x4b,0xc6,0xd2,0x79,0x20
.byte	0x9a,0xdb,0xc0,0xfe,0x78,0xcd,0x5a,0xf4
.byte	0x1f,0xdd,0xa8,0x33,0x88,0x07,0xc7,0x31
.byte	0xb1,0x12,0x10,0x59,0x27,0x80,0xec,0x5f
.byte	0x60,0x51,0x7f,0xa9,0x19,0xb5,0x4a,0x0d
.byte	0x2d,0xe5,0x7a,0x9f,0x93,0xc9,0x9c,0xef
.byte	0xa0,0xe0,0x3b,0x4d,0xae,0x2a,0xf5,0xb0
.byte	0xc8,0xeb,0xbb,0x3c,0x83,0x53,0x99,0x61
.byte	0x17,0x2b,0x04,0x7e,0xba,0x77,0xd6,0x26
.byte	0xe1,0x69,0x14,0x63,0x55,0x21,0x0c,0x7d
.long	0x80808080, 0x80808080, 0xfefefefe, 0xfefefefe
.long	0x1b1b1b1b, 0x1b1b1b1b, 0, 0
.byte	0x52,0x09,0x6a,0xd5,0x30,0x36,0xa5,0x38
.byte	0xbf,0x40,0xa3,0x9e,0x81,0xf3,0xd7,0xfb
.byte	0x7c,0xe3,0x39,0x82,0x9b,0x2f,0xff,0x87
.byte	0x34,0x8e,0x43,0x44,0xc4,0xde,0xe9,0xcb
.byte	0x54,0x7b,0x94,0x32,0xa6,0xc2,0x23,0x3d
.byte	0xee,0x4c,0x95,0x0b,0x42,0xfa,0xc3,0x4e
.byte	0x08,0x2e,0xa1,0x66,0x28,0xd9,0x24,0xb2
.byte	0x76,0x5b,0xa2,0x49,0x6d,0x8b,0xd1,0x25
.byte	0x72,0xf8,0xf6,0x64,0x86,0x68,0x98,0x16
.byte	0xd4,0xa4,0x5c,0xcc,0x5d,0x65,0xb6,0x92
.byte	0x6c,0x70,0x48,0x50,0xfd,0xed,0xb9,0xda
.byte	0x5e,0x15,0x46,0x57,0xa7,0x8d,0x9d,0x84
.byte	0x90,0xd8,0xab,0x00,0x8c,0xbc,0xd3,0x0a
.byte	0xf7,0xe4,0x58,0x05,0xb8,0xb3,0x45,0x06
.byte	0xd0,0x2c,0x1e,0x8f,0xca,0x3f,0x0f,0x02
.byte	0xc1,0xaf,0xbd,0x03,0x01,0x13,0x8a,0x6b
.byte	0x3a,0x91,0x11,0x41,0x4f,0x67,0xdc,0xea
.byte	0x97,0xf2,0xcf,0xce,0xf0,0xb4,0xe6,0x73
.byte	0x96,0xac,0x74,0x22,0xe7,0xad,0x35,0x85
.byte	0xe2,0xf9,0x37,0xe8,0x1c,0x75,0xdf,0x6e
.byte	0x47,0xf1,0x1a,0x71,0x1d,0x29,0xc5,0x89
.byte	0x6f,0xb7,0x62,0x0e,0xaa,0x18,0xbe,0x1b
.byte	0xfc,0x56,0x3e,0x4b,0xc6,0xd2,0x79,0x20
.byte	0x9a,0xdb,0xc0,0xfe,0x78,0xcd,0x5a,0xf4
.byte	0x1f,0xdd,0xa8,0x33,0x88,0x07,0xc7,0x31
.byte	0xb1,0x12,0x10,0x59,0x27,0x80,0xec,0x5f
.byte	0x60,0x51,0x7f,0xa9,0x19,0xb5,0x4a,0x0d
.byte	0x2d,0xe5,0x7a,0x9f,0x93,0xc9,0x9c,0xef
.byte	0xa0,0xe0,0x3b,0x4d,0xae,0x2a,0xf5,0xb0
.byte	0xc8,0xeb,0xbb,0x3c,0x83,0x53,0x99,0x61
.byte	0x17,0x2b,0x04,0x7e,0xba,0x77,0xd6,0x26
.byte	0xe1,0x69,0x14,0x63,0x55,0x21,0x0c,0x7d
.long	0x80808080, 0x80808080, 0xfefefefe, 0xfefefefe
.long	0x1b1b1b1b, 0x1b1b1b1b, 0, 0
.byte	0x52,0x09,0x6a,0xd5,0x30,0x36,0xa5,0x38
.byte	0xbf,0x40,0xa3,0x9e,0x81,0xf3,0xd7,0xfb
.byte	0x7c,0xe3,0x39,0x82,0x9b,0x2f,0xff,0x87
.byte	0x34,0x8e,0x43,0x44,0xc4,0xde,0xe9,0xcb
.byte	0x54,0x7b,0x94,0x32,0xa6,0xc2,0x23,0x3d
.byte	0xee,0x4c,0x95,0x0b,0x42,0xfa,0xc3,0x4e
.byte	0x08,0x2e,0xa1,0x66,0x28,0xd9,0x24,0xb2
.byte	0x76,0x5b,0xa2,0x49,0x6d,0x8b,0xd1,0x25
.byte	0x72,0xf8,0xf6,0x64,0x86,0x68,0x98,0x16
.byte	0xd4,0xa4,0x5c,0xcc,0x5d,0x65,0xb6,0x92
.byte	0x6c,0x70,0x48,0x50,0xfd,0xed,0xb9,0xda
.byte	0x5e,0x15,0x46,0x57,0xa7,0x8d,0x9d,0x84
.byte	0x90,0xd8,0xab,0x00,0x8c,0xbc,0xd3,0x0a
.byte	0xf7,0xe4,0x58,0x05,0xb8,0xb3,0x45,0x06
.byte	0xd0,0x2c,0x1e,0x8f,0xca,0x3f,0x0f,0x02
.byte	0xc1,0xaf,0xbd,0x03,0x01,0x13,0x8a,0x6b
.byte	0x3a,0x91,0x11,0x41,0x4f,0x67,0xdc,0xea
.byte	0x97,0xf2,0xcf,0xce,0xf0,0xb4,0xe6,0x73
.byte	0x96,0xac,0x74,0x22,0xe7,0xad,0x35,0x85
.byte	0xe2,0xf9,0x37,0xe8,0x1c,0x75,0xdf,0x6e
.byte	0x47,0xf1,0x1a,0x71,0x1d,0x29,0xc5,0x89
.byte	0x6f,0xb7,0x62,0x0e,0xaa,0x18,0xbe,0x1b
.byte	0xfc,0x56,0x3e,0x4b,0xc6,0xd2,0x79,0x20
.byte	0x9a,0xdb,0xc0,0xfe,0x78,0xcd,0x5a,0xf4
.byte	0x1f,0xdd,0xa8,0x33,0x88,0x07,0xc7,0x31
.byte	0xb1,0x12,0x10,0x59,0x27,0x80,0xec,0x5f
.byte	0x60,0x51,0x7f,0xa9,0x19,0xb5,0x4a,0x0d
.byte	0x2d,0xe5,0x7a,0x9f,0x93,0xc9,0x9c,0xef
.byte	0xa0,0xe0,0x3b,0x4d,0xae,0x2a,0xf5,0xb0
.byte	0xc8,0xeb,0xbb,0x3c,0x83,0x53,0x99,0x61
.byte	0x17,0x2b,0x04,0x7e,0xba,0x77,0xd6,0x26
.byte	0xe1,0x69,0x14,0x63,0x55,0x21,0x0c,0x7d
.long	0x80808080, 0x80808080, 0xfefefefe, 0xfefefefe
.long	0x1b1b1b1b, 0x1b1b1b1b, 0, 0
.byte	65,69,83,32,102,111,114,32,120,56,54,95,54,52,44,32,67,82,89,80,84,79,71,65,77,83,32,98,121,32,60,97,112,112,114,111,64,111,112,101,110,115,115,108,46,111,114,103,62,0
.align	64
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                                                                                                                                                                                                                                                                                                        node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/aes/aesni-mb-x86_64.s                 0000664 0000000 0000000 00000075537 14746647661 0027337 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	



.globl	aesni_multi_cbc_encrypt
.type	aesni_multi_cbc_encrypt,@function
.align	32
aesni_multi_cbc_encrypt:
.cfi_startproc	
	cmpl	$2,%edx
	jb	.Lenc_non_avx
	movl	OPENSSL_ia32cap_P+4(%rip),%ecx
	testl	$268435456,%ecx
	jnz	_avx_cbc_enc_shortcut
	jmp	.Lenc_non_avx
.align	16
.Lenc_non_avx:
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56






	subq	$48,%rsp
	andq	$-64,%rsp
	movq	%rax,16(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x10,0x06,0x23,0x08

.Lenc4x_body:
	movdqu	(%rsi),%xmm12
	leaq	120(%rsi),%rsi
	leaq	80(%rdi),%rdi

.Lenc4x_loop_grande:
	movl	%edx,24(%rsp)
	xorl	%edx,%edx

	movl	-64(%rdi),%ecx
	movq	-80(%rdi),%r8
	cmpl	%edx,%ecx
	movq	-72(%rdi),%r12
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	movdqu	-56(%rdi),%xmm2
	movl	%ecx,32(%rsp)
	cmovleq	%rsp,%r8

	movl	-24(%rdi),%ecx
	movq	-40(%rdi),%r9
	cmpl	%edx,%ecx
	movq	-32(%rdi),%r13
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	movdqu	-16(%rdi),%xmm3
	movl	%ecx,36(%rsp)
	cmovleq	%rsp,%r9

	movl	16(%rdi),%ecx
	movq	0(%rdi),%r10
	cmpl	%edx,%ecx
	movq	8(%rdi),%r14
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	movdqu	24(%rdi),%xmm4
	movl	%ecx,40(%rsp)
	cmovleq	%rsp,%r10

	movl	56(%rdi),%ecx
	movq	40(%rdi),%r11
	cmpl	%edx,%ecx
	movq	48(%rdi),%r15
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	movdqu	64(%rdi),%xmm5
	movl	%ecx,44(%rsp)
	cmovleq	%rsp,%r11
	testl	%edx,%edx
	jz	.Lenc4x_done

	movups	16-120(%rsi),%xmm1
	pxor	%xmm12,%xmm2
	movups	32-120(%rsi),%xmm0
	pxor	%xmm12,%xmm3
	movl	240-120(%rsi),%eax
	pxor	%xmm12,%xmm4
	movdqu	(%r8),%xmm6
	pxor	%xmm12,%xmm5
	movdqu	(%r9),%xmm7
	pxor	%xmm6,%xmm2
	movdqu	(%r10),%xmm8
	pxor	%xmm7,%xmm3
	movdqu	(%r11),%xmm9
	pxor	%xmm8,%xmm4
	pxor	%xmm9,%xmm5
	movdqa	32(%rsp),%xmm10
	xorq	%rbx,%rbx
	jmp	.Loop_enc4x

.align	32
.Loop_enc4x:
	addq	$16,%rbx
	leaq	16(%rsp),%rbp
	movl	$1,%ecx
	subq	%rbx,%rbp

.byte	102,15,56,220,209
	prefetcht0	31(%r8,%rbx,1)
	prefetcht0	31(%r9,%rbx,1)
.byte	102,15,56,220,217
	prefetcht0	31(%r10,%rbx,1)
	prefetcht0	31(%r10,%rbx,1)
.byte	102,15,56,220,225
.byte	102,15,56,220,233
	movups	48-120(%rsi),%xmm1
	cmpl	32(%rsp),%ecx
.byte	102,15,56,220,208
.byte	102,15,56,220,216
.byte	102,15,56,220,224
	cmovgeq	%rbp,%r8
	cmovgq	%rbp,%r12
.byte	102,15,56,220,232
	movups	-56(%rsi),%xmm0
	cmpl	36(%rsp),%ecx
.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
	cmovgeq	%rbp,%r9
	cmovgq	%rbp,%r13
.byte	102,15,56,220,233
	movups	-40(%rsi),%xmm1
	cmpl	40(%rsp),%ecx
.byte	102,15,56,220,208
.byte	102,15,56,220,216
.byte	102,15,56,220,224
	cmovgeq	%rbp,%r10
	cmovgq	%rbp,%r14
.byte	102,15,56,220,232
	movups	-24(%rsi),%xmm0
	cmpl	44(%rsp),%ecx
.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
	cmovgeq	%rbp,%r11
	cmovgq	%rbp,%r15
.byte	102,15,56,220,233
	movups	-8(%rsi),%xmm1
	movdqa	%xmm10,%xmm11
.byte	102,15,56,220,208
	prefetcht0	15(%r12,%rbx,1)
	prefetcht0	15(%r13,%rbx,1)
.byte	102,15,56,220,216
	prefetcht0	15(%r14,%rbx,1)
	prefetcht0	15(%r15,%rbx,1)
.byte	102,15,56,220,224
.byte	102,15,56,220,232
	movups	128-120(%rsi),%xmm0
	pxor	%xmm12,%xmm12

.byte	102,15,56,220,209
	pcmpgtd	%xmm12,%xmm11
	movdqu	-120(%rsi),%xmm12
.byte	102,15,56,220,217
	paddd	%xmm11,%xmm10
	movdqa	%xmm10,32(%rsp)
.byte	102,15,56,220,225
.byte	102,15,56,220,233
	movups	144-120(%rsi),%xmm1

	cmpl	$11,%eax

.byte	102,15,56,220,208
.byte	102,15,56,220,216
.byte	102,15,56,220,224
.byte	102,15,56,220,232
	movups	160-120(%rsi),%xmm0

	jb	.Lenc4x_tail

.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.byte	102,15,56,220,233
	movups	176-120(%rsi),%xmm1

.byte	102,15,56,220,208
.byte	102,15,56,220,216
.byte	102,15,56,220,224
.byte	102,15,56,220,232
	movups	192-120(%rsi),%xmm0

	je	.Lenc4x_tail

.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.byte	102,15,56,220,233
	movups	208-120(%rsi),%xmm1

.byte	102,15,56,220,208
.byte	102,15,56,220,216
.byte	102,15,56,220,224
.byte	102,15,56,220,232
	movups	224-120(%rsi),%xmm0
	jmp	.Lenc4x_tail

.align	32
.Lenc4x_tail:
.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.byte	102,15,56,220,233
	movdqu	(%r8,%rbx,1),%xmm6
	movdqu	16-120(%rsi),%xmm1

.byte	102,15,56,221,208
	movdqu	(%r9,%rbx,1),%xmm7
	pxor	%xmm12,%xmm6
.byte	102,15,56,221,216
	movdqu	(%r10,%rbx,1),%xmm8
	pxor	%xmm12,%xmm7
.byte	102,15,56,221,224
	movdqu	(%r11,%rbx,1),%xmm9
	pxor	%xmm12,%xmm8
.byte	102,15,56,221,232
	movdqu	32-120(%rsi),%xmm0
	pxor	%xmm12,%xmm9

	movups	%xmm2,-16(%r12,%rbx,1)
	pxor	%xmm6,%xmm2
	movups	%xmm3,-16(%r13,%rbx,1)
	pxor	%xmm7,%xmm3
	movups	%xmm4,-16(%r14,%rbx,1)
	pxor	%xmm8,%xmm4
	movups	%xmm5,-16(%r15,%rbx,1)
	pxor	%xmm9,%xmm5

	decl	%edx
	jnz	.Loop_enc4x

	movq	16(%rsp),%rax
.cfi_def_cfa	%rax,8
	movl	24(%rsp),%edx











	leaq	160(%rdi),%rdi
	decl	%edx
	jnz	.Lenc4x_loop_grande

.Lenc4x_done:
	movq	-48(%rax),%r15
.cfi_restore	%r15
	movq	-40(%rax),%r14
.cfi_restore	%r14
	movq	-32(%rax),%r13
.cfi_restore	%r13
	movq	-24(%rax),%r12
.cfi_restore	%r12
	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lenc4x_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_multi_cbc_encrypt,.-aesni_multi_cbc_encrypt

.globl	aesni_multi_cbc_decrypt
.type	aesni_multi_cbc_decrypt,@function
.align	32
aesni_multi_cbc_decrypt:
.cfi_startproc	
	cmpl	$2,%edx
	jb	.Ldec_non_avx
	movl	OPENSSL_ia32cap_P+4(%rip),%ecx
	testl	$268435456,%ecx
	jnz	_avx_cbc_dec_shortcut
	jmp	.Ldec_non_avx
.align	16
.Ldec_non_avx:
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56






	subq	$48,%rsp
	andq	$-64,%rsp
	movq	%rax,16(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x10,0x06,0x23,0x08

.Ldec4x_body:
	movdqu	(%rsi),%xmm12
	leaq	120(%rsi),%rsi
	leaq	80(%rdi),%rdi

.Ldec4x_loop_grande:
	movl	%edx,24(%rsp)
	xorl	%edx,%edx

	movl	-64(%rdi),%ecx
	movq	-80(%rdi),%r8
	cmpl	%edx,%ecx
	movq	-72(%rdi),%r12
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	movdqu	-56(%rdi),%xmm6
	movl	%ecx,32(%rsp)
	cmovleq	%rsp,%r8

	movl	-24(%rdi),%ecx
	movq	-40(%rdi),%r9
	cmpl	%edx,%ecx
	movq	-32(%rdi),%r13
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	movdqu	-16(%rdi),%xmm7
	movl	%ecx,36(%rsp)
	cmovleq	%rsp,%r9

	movl	16(%rdi),%ecx
	movq	0(%rdi),%r10
	cmpl	%edx,%ecx
	movq	8(%rdi),%r14
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	movdqu	24(%rdi),%xmm8
	movl	%ecx,40(%rsp)
	cmovleq	%rsp,%r10

	movl	56(%rdi),%ecx
	movq	40(%rdi),%r11
	cmpl	%edx,%ecx
	movq	48(%rdi),%r15
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	movdqu	64(%rdi),%xmm9
	movl	%ecx,44(%rsp)
	cmovleq	%rsp,%r11
	testl	%edx,%edx
	jz	.Ldec4x_done

	movups	16-120(%rsi),%xmm1
	movups	32-120(%rsi),%xmm0
	movl	240-120(%rsi),%eax
	movdqu	(%r8),%xmm2
	movdqu	(%r9),%xmm3
	pxor	%xmm12,%xmm2
	movdqu	(%r10),%xmm4
	pxor	%xmm12,%xmm3
	movdqu	(%r11),%xmm5
	pxor	%xmm12,%xmm4
	pxor	%xmm12,%xmm5
	movdqa	32(%rsp),%xmm10
	xorq	%rbx,%rbx
	jmp	.Loop_dec4x

.align	32
.Loop_dec4x:
	addq	$16,%rbx
	leaq	16(%rsp),%rbp
	movl	$1,%ecx
	subq	%rbx,%rbp

.byte	102,15,56,222,209
	prefetcht0	31(%r8,%rbx,1)
	prefetcht0	31(%r9,%rbx,1)
.byte	102,15,56,222,217
	prefetcht0	31(%r10,%rbx,1)
	prefetcht0	31(%r11,%rbx,1)
.byte	102,15,56,222,225
.byte	102,15,56,222,233
	movups	48-120(%rsi),%xmm1
	cmpl	32(%rsp),%ecx
.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
	cmovgeq	%rbp,%r8
	cmovgq	%rbp,%r12
.byte	102,15,56,222,232
	movups	-56(%rsi),%xmm0
	cmpl	36(%rsp),%ecx
.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
	cmovgeq	%rbp,%r9
	cmovgq	%rbp,%r13
.byte	102,15,56,222,233
	movups	-40(%rsi),%xmm1
	cmpl	40(%rsp),%ecx
.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
	cmovgeq	%rbp,%r10
	cmovgq	%rbp,%r14
.byte	102,15,56,222,232
	movups	-24(%rsi),%xmm0
	cmpl	44(%rsp),%ecx
.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
	cmovgeq	%rbp,%r11
	cmovgq	%rbp,%r15
.byte	102,15,56,222,233
	movups	-8(%rsi),%xmm1
	movdqa	%xmm10,%xmm11
.byte	102,15,56,222,208
	prefetcht0	15(%r12,%rbx,1)
	prefetcht0	15(%r13,%rbx,1)
.byte	102,15,56,222,216
	prefetcht0	15(%r14,%rbx,1)
	prefetcht0	15(%r15,%rbx,1)
.byte	102,15,56,222,224
.byte	102,15,56,222,232
	movups	128-120(%rsi),%xmm0
	pxor	%xmm12,%xmm12

.byte	102,15,56,222,209
	pcmpgtd	%xmm12,%xmm11
	movdqu	-120(%rsi),%xmm12
.byte	102,15,56,222,217
	paddd	%xmm11,%xmm10
	movdqa	%xmm10,32(%rsp)
.byte	102,15,56,222,225
.byte	102,15,56,222,233
	movups	144-120(%rsi),%xmm1

	cmpl	$11,%eax

.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
.byte	102,15,56,222,232
	movups	160-120(%rsi),%xmm0

	jb	.Ldec4x_tail

.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,222,233
	movups	176-120(%rsi),%xmm1

.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
.byte	102,15,56,222,232
	movups	192-120(%rsi),%xmm0

	je	.Ldec4x_tail

.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,222,233
	movups	208-120(%rsi),%xmm1

.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
.byte	102,15,56,222,232
	movups	224-120(%rsi),%xmm0
	jmp	.Ldec4x_tail

.align	32
.Ldec4x_tail:
.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
	pxor	%xmm0,%xmm6
	pxor	%xmm0,%xmm7
.byte	102,15,56,222,233
	movdqu	16-120(%rsi),%xmm1
	pxor	%xmm0,%xmm8
	pxor	%xmm0,%xmm9
	movdqu	32-120(%rsi),%xmm0

.byte	102,15,56,223,214
.byte	102,15,56,223,223
	movdqu	-16(%r8,%rbx,1),%xmm6
	movdqu	-16(%r9,%rbx,1),%xmm7
.byte	102,65,15,56,223,224
.byte	102,65,15,56,223,233
	movdqu	-16(%r10,%rbx,1),%xmm8
	movdqu	-16(%r11,%rbx,1),%xmm9

	movups	%xmm2,-16(%r12,%rbx,1)
	movdqu	(%r8,%rbx,1),%xmm2
	movups	%xmm3,-16(%r13,%rbx,1)
	movdqu	(%r9,%rbx,1),%xmm3
	pxor	%xmm12,%xmm2
	movups	%xmm4,-16(%r14,%rbx,1)
	movdqu	(%r10,%rbx,1),%xmm4
	pxor	%xmm12,%xmm3
	movups	%xmm5,-16(%r15,%rbx,1)
	movdqu	(%r11,%rbx,1),%xmm5
	pxor	%xmm12,%xmm4
	pxor	%xmm12,%xmm5

	decl	%edx
	jnz	.Loop_dec4x

	movq	16(%rsp),%rax
.cfi_def_cfa	%rax,8
	movl	24(%rsp),%edx

	leaq	160(%rdi),%rdi
	decl	%edx
	jnz	.Ldec4x_loop_grande

.Ldec4x_done:
	movq	-48(%rax),%r15
.cfi_restore	%r15
	movq	-40(%rax),%r14
.cfi_restore	%r14
	movq	-32(%rax),%r13
.cfi_restore	%r13
	movq	-24(%rax),%r12
.cfi_restore	%r12
	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Ldec4x_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_multi_cbc_decrypt,.-aesni_multi_cbc_decrypt
.type	aesni_multi_cbc_encrypt_avx,@function
.align	32
aesni_multi_cbc_encrypt_avx:
.cfi_startproc	
_avx_cbc_enc_shortcut:
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56








	subq	$192,%rsp
	andq	$-128,%rsp
	movq	%rax,16(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x10,0x06,0x23,0x08

.Lenc8x_body:
	vzeroupper
	vmovdqu	(%rsi),%xmm15
	leaq	120(%rsi),%rsi
	leaq	160(%rdi),%rdi
	shrl	$1,%edx

.Lenc8x_loop_grande:

	xorl	%edx,%edx

	movl	-144(%rdi),%ecx

	movq	-160(%rdi),%r8
	cmpl	%edx,%ecx

	movq	-152(%rdi),%rbx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	vmovdqu	-136(%rdi),%xmm2
	movl	%ecx,32(%rsp)
	cmovleq	%rsp,%r8
	subq	%r8,%rbx
	movq	%rbx,64(%rsp)

	movl	-104(%rdi),%ecx

	movq	-120(%rdi),%r9
	cmpl	%edx,%ecx

	movq	-112(%rdi),%rbp
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	vmovdqu	-96(%rdi),%xmm3
	movl	%ecx,36(%rsp)
	cmovleq	%rsp,%r9
	subq	%r9,%rbp
	movq	%rbp,72(%rsp)

	movl	-64(%rdi),%ecx

	movq	-80(%rdi),%r10
	cmpl	%edx,%ecx

	movq	-72(%rdi),%rbp
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	vmovdqu	-56(%rdi),%xmm4
	movl	%ecx,40(%rsp)
	cmovleq	%rsp,%r10
	subq	%r10,%rbp
	movq	%rbp,80(%rsp)

	movl	-24(%rdi),%ecx

	movq	-40(%rdi),%r11
	cmpl	%edx,%ecx

	movq	-32(%rdi),%rbp
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	vmovdqu	-16(%rdi),%xmm5
	movl	%ecx,44(%rsp)
	cmovleq	%rsp,%r11
	subq	%r11,%rbp
	movq	%rbp,88(%rsp)

	movl	16(%rdi),%ecx

	movq	0(%rdi),%r12
	cmpl	%edx,%ecx

	movq	8(%rdi),%rbp
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	vmovdqu	24(%rdi),%xmm6
	movl	%ecx,48(%rsp)
	cmovleq	%rsp,%r12
	subq	%r12,%rbp
	movq	%rbp,96(%rsp)

	movl	56(%rdi),%ecx

	movq	40(%rdi),%r13
	cmpl	%edx,%ecx

	movq	48(%rdi),%rbp
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	vmovdqu	64(%rdi),%xmm7
	movl	%ecx,52(%rsp)
	cmovleq	%rsp,%r13
	subq	%r13,%rbp
	movq	%rbp,104(%rsp)

	movl	96(%rdi),%ecx

	movq	80(%rdi),%r14
	cmpl	%edx,%ecx

	movq	88(%rdi),%rbp
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	vmovdqu	104(%rdi),%xmm8
	movl	%ecx,56(%rsp)
	cmovleq	%rsp,%r14
	subq	%r14,%rbp
	movq	%rbp,112(%rsp)

	movl	136(%rdi),%ecx

	movq	120(%rdi),%r15
	cmpl	%edx,%ecx

	movq	128(%rdi),%rbp
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	vmovdqu	144(%rdi),%xmm9
	movl	%ecx,60(%rsp)
	cmovleq	%rsp,%r15
	subq	%r15,%rbp
	movq	%rbp,120(%rsp)
	testl	%edx,%edx
	jz	.Lenc8x_done

	vmovups	16-120(%rsi),%xmm1
	vmovups	32-120(%rsi),%xmm0
	movl	240-120(%rsi),%eax

	vpxor	(%r8),%xmm15,%xmm10
	leaq	128(%rsp),%rbp
	vpxor	(%r9),%xmm15,%xmm11
	vpxor	(%r10),%xmm15,%xmm12
	vpxor	(%r11),%xmm15,%xmm13
	vpxor	%xmm10,%xmm2,%xmm2
	vpxor	(%r12),%xmm15,%xmm10
	vpxor	%xmm11,%xmm3,%xmm3
	vpxor	(%r13),%xmm15,%xmm11
	vpxor	%xmm12,%xmm4,%xmm4
	vpxor	(%r14),%xmm15,%xmm12
	vpxor	%xmm13,%xmm5,%xmm5
	vpxor	(%r15),%xmm15,%xmm13
	vpxor	%xmm10,%xmm6,%xmm6
	movl	$1,%ecx
	vpxor	%xmm11,%xmm7,%xmm7
	vpxor	%xmm12,%xmm8,%xmm8
	vpxor	%xmm13,%xmm9,%xmm9
	jmp	.Loop_enc8x

.align	32
.Loop_enc8x:
	vaesenc	%xmm1,%xmm2,%xmm2
	cmpl	32+0(%rsp),%ecx
	vaesenc	%xmm1,%xmm3,%xmm3
	prefetcht0	31(%r8)
	vaesenc	%xmm1,%xmm4,%xmm4
	vaesenc	%xmm1,%xmm5,%xmm5
	leaq	(%r8,%rbx,1),%rbx
	cmovgeq	%rsp,%r8
	vaesenc	%xmm1,%xmm6,%xmm6
	cmovgq	%rsp,%rbx
	vaesenc	%xmm1,%xmm7,%xmm7
	subq	%r8,%rbx
	vaesenc	%xmm1,%xmm8,%xmm8
	vpxor	16(%r8),%xmm15,%xmm10
	movq	%rbx,64+0(%rsp)
	vaesenc	%xmm1,%xmm9,%xmm9
	vmovups	-72(%rsi),%xmm1
	leaq	16(%r8,%rbx,1),%r8
	vmovdqu	%xmm10,0(%rbp)
	vaesenc	%xmm0,%xmm2,%xmm2
	cmpl	32+4(%rsp),%ecx
	movq	64+8(%rsp),%rbx
	vaesenc	%xmm0,%xmm3,%xmm3
	prefetcht0	31(%r9)
	vaesenc	%xmm0,%xmm4,%xmm4
	vaesenc	%xmm0,%xmm5,%xmm5
	leaq	(%r9,%rbx,1),%rbx
	cmovgeq	%rsp,%r9
	vaesenc	%xmm0,%xmm6,%xmm6
	cmovgq	%rsp,%rbx
	vaesenc	%xmm0,%xmm7,%xmm7
	subq	%r9,%rbx
	vaesenc	%xmm0,%xmm8,%xmm8
	vpxor	16(%r9),%xmm15,%xmm11
	movq	%rbx,64+8(%rsp)
	vaesenc	%xmm0,%xmm9,%xmm9
	vmovups	-56(%rsi),%xmm0
	leaq	16(%r9,%rbx,1),%r9
	vmovdqu	%xmm11,16(%rbp)
	vaesenc	%xmm1,%xmm2,%xmm2
	cmpl	32+8(%rsp),%ecx
	movq	64+16(%rsp),%rbx
	vaesenc	%xmm1,%xmm3,%xmm3
	prefetcht0	31(%r10)
	vaesenc	%xmm1,%xmm4,%xmm4
	prefetcht0	15(%r8)
	vaesenc	%xmm1,%xmm5,%xmm5
	leaq	(%r10,%rbx,1),%rbx
	cmovgeq	%rsp,%r10
	vaesenc	%xmm1,%xmm6,%xmm6
	cmovgq	%rsp,%rbx
	vaesenc	%xmm1,%xmm7,%xmm7
	subq	%r10,%rbx
	vaesenc	%xmm1,%xmm8,%xmm8
	vpxor	16(%r10),%xmm15,%xmm12
	movq	%rbx,64+16(%rsp)
	vaesenc	%xmm1,%xmm9,%xmm9
	vmovups	-40(%rsi),%xmm1
	leaq	16(%r10,%rbx,1),%r10
	vmovdqu	%xmm12,32(%rbp)
	vaesenc	%xmm0,%xmm2,%xmm2
	cmpl	32+12(%rsp),%ecx
	movq	64+24(%rsp),%rbx
	vaesenc	%xmm0,%xmm3,%xmm3
	prefetcht0	31(%r11)
	vaesenc	%xmm0,%xmm4,%xmm4
	prefetcht0	15(%r9)
	vaesenc	%xmm0,%xmm5,%xmm5
	leaq	(%r11,%rbx,1),%rbx
	cmovgeq	%rsp,%r11
	vaesenc	%xmm0,%xmm6,%xmm6
	cmovgq	%rsp,%rbx
	vaesenc	%xmm0,%xmm7,%xmm7
	subq	%r11,%rbx
	vaesenc	%xmm0,%xmm8,%xmm8
	vpxor	16(%r11),%xmm15,%xmm13
	movq	%rbx,64+24(%rsp)
	vaesenc	%xmm0,%xmm9,%xmm9
	vmovups	-24(%rsi),%xmm0
	leaq	16(%r11,%rbx,1),%r11
	vmovdqu	%xmm13,48(%rbp)
	vaesenc	%xmm1,%xmm2,%xmm2
	cmpl	32+16(%rsp),%ecx
	movq	64+32(%rsp),%rbx
	vaesenc	%xmm1,%xmm3,%xmm3
	prefetcht0	31(%r12)
	vaesenc	%xmm1,%xmm4,%xmm4
	prefetcht0	15(%r10)
	vaesenc	%xmm1,%xmm5,%xmm5
	leaq	(%r12,%rbx,1),%rbx
	cmovgeq	%rsp,%r12
	vaesenc	%xmm1,%xmm6,%xmm6
	cmovgq	%rsp,%rbx
	vaesenc	%xmm1,%xmm7,%xmm7
	subq	%r12,%rbx
	vaesenc	%xmm1,%xmm8,%xmm8
	vpxor	16(%r12),%xmm15,%xmm10
	movq	%rbx,64+32(%rsp)
	vaesenc	%xmm1,%xmm9,%xmm9
	vmovups	-8(%rsi),%xmm1
	leaq	16(%r12,%rbx,1),%r12
	vaesenc	%xmm0,%xmm2,%xmm2
	cmpl	32+20(%rsp),%ecx
	movq	64+40(%rsp),%rbx
	vaesenc	%xmm0,%xmm3,%xmm3
	prefetcht0	31(%r13)
	vaesenc	%xmm0,%xmm4,%xmm4
	prefetcht0	15(%r11)
	vaesenc	%xmm0,%xmm5,%xmm5
	leaq	(%rbx,%r13,1),%rbx
	cmovgeq	%rsp,%r13
	vaesenc	%xmm0,%xmm6,%xmm6
	cmovgq	%rsp,%rbx
	vaesenc	%xmm0,%xmm7,%xmm7
	subq	%r13,%rbx
	vaesenc	%xmm0,%xmm8,%xmm8
	vpxor	16(%r13),%xmm15,%xmm11
	movq	%rbx,64+40(%rsp)
	vaesenc	%xmm0,%xmm9,%xmm9
	vmovups	8(%rsi),%xmm0
	leaq	16(%r13,%rbx,1),%r13
	vaesenc	%xmm1,%xmm2,%xmm2
	cmpl	32+24(%rsp),%ecx
	movq	64+48(%rsp),%rbx
	vaesenc	%xmm1,%xmm3,%xmm3
	prefetcht0	31(%r14)
	vaesenc	%xmm1,%xmm4,%xmm4
	prefetcht0	15(%r12)
	vaesenc	%xmm1,%xmm5,%xmm5
	leaq	(%r14,%rbx,1),%rbx
	cmovgeq	%rsp,%r14
	vaesenc	%xmm1,%xmm6,%xmm6
	cmovgq	%rsp,%rbx
	vaesenc	%xmm1,%xmm7,%xmm7
	subq	%r14,%rbx
	vaesenc	%xmm1,%xmm8,%xmm8
	vpxor	16(%r14),%xmm15,%xmm12
	movq	%rbx,64+48(%rsp)
	vaesenc	%xmm1,%xmm9,%xmm9
	vmovups	24(%rsi),%xmm1
	leaq	16(%r14,%rbx,1),%r14
	vaesenc	%xmm0,%xmm2,%xmm2
	cmpl	32+28(%rsp),%ecx
	movq	64+56(%rsp),%rbx
	vaesenc	%xmm0,%xmm3,%xmm3
	prefetcht0	31(%r15)
	vaesenc	%xmm0,%xmm4,%xmm4
	prefetcht0	15(%r13)
	vaesenc	%xmm0,%xmm5,%xmm5
	leaq	(%r15,%rbx,1),%rbx
	cmovgeq	%rsp,%r15
	vaesenc	%xmm0,%xmm6,%xmm6
	cmovgq	%rsp,%rbx
	vaesenc	%xmm0,%xmm7,%xmm7
	subq	%r15,%rbx
	vaesenc	%xmm0,%xmm8,%xmm8
	vpxor	16(%r15),%xmm15,%xmm13
	movq	%rbx,64+56(%rsp)
	vaesenc	%xmm0,%xmm9,%xmm9
	vmovups	40(%rsi),%xmm0
	leaq	16(%r15,%rbx,1),%r15
	vmovdqu	32(%rsp),%xmm14
	prefetcht0	15(%r14)
	prefetcht0	15(%r15)
	cmpl	$11,%eax
	jb	.Lenc8x_tail

	vaesenc	%xmm1,%xmm2,%xmm2
	vaesenc	%xmm1,%xmm3,%xmm3
	vaesenc	%xmm1,%xmm4,%xmm4
	vaesenc	%xmm1,%xmm5,%xmm5
	vaesenc	%xmm1,%xmm6,%xmm6
	vaesenc	%xmm1,%xmm7,%xmm7
	vaesenc	%xmm1,%xmm8,%xmm8
	vaesenc	%xmm1,%xmm9,%xmm9
	vmovups	176-120(%rsi),%xmm1

	vaesenc	%xmm0,%xmm2,%xmm2
	vaesenc	%xmm0,%xmm3,%xmm3
	vaesenc	%xmm0,%xmm4,%xmm4
	vaesenc	%xmm0,%xmm5,%xmm5
	vaesenc	%xmm0,%xmm6,%xmm6
	vaesenc	%xmm0,%xmm7,%xmm7
	vaesenc	%xmm0,%xmm8,%xmm8
	vaesenc	%xmm0,%xmm9,%xmm9
	vmovups	192-120(%rsi),%xmm0
	je	.Lenc8x_tail

	vaesenc	%xmm1,%xmm2,%xmm2
	vaesenc	%xmm1,%xmm3,%xmm3
	vaesenc	%xmm1,%xmm4,%xmm4
	vaesenc	%xmm1,%xmm5,%xmm5
	vaesenc	%xmm1,%xmm6,%xmm6
	vaesenc	%xmm1,%xmm7,%xmm7
	vaesenc	%xmm1,%xmm8,%xmm8
	vaesenc	%xmm1,%xmm9,%xmm9
	vmovups	208-120(%rsi),%xmm1

	vaesenc	%xmm0,%xmm2,%xmm2
	vaesenc	%xmm0,%xmm3,%xmm3
	vaesenc	%xmm0,%xmm4,%xmm4
	vaesenc	%xmm0,%xmm5,%xmm5
	vaesenc	%xmm0,%xmm6,%xmm6
	vaesenc	%xmm0,%xmm7,%xmm7
	vaesenc	%xmm0,%xmm8,%xmm8
	vaesenc	%xmm0,%xmm9,%xmm9
	vmovups	224-120(%rsi),%xmm0

.Lenc8x_tail:
	vaesenc	%xmm1,%xmm2,%xmm2
	vpxor	%xmm15,%xmm15,%xmm15
	vaesenc	%xmm1,%xmm3,%xmm3
	vaesenc	%xmm1,%xmm4,%xmm4
	vpcmpgtd	%xmm15,%xmm14,%xmm15
	vaesenc	%xmm1,%xmm5,%xmm5
	vaesenc	%xmm1,%xmm6,%xmm6
	vpaddd	%xmm14,%xmm15,%xmm15
	vmovdqu	48(%rsp),%xmm14
	vaesenc	%xmm1,%xmm7,%xmm7
	movq	64(%rsp),%rbx
	vaesenc	%xmm1,%xmm8,%xmm8
	vaesenc	%xmm1,%xmm9,%xmm9
	vmovups	16-120(%rsi),%xmm1

	vaesenclast	%xmm0,%xmm2,%xmm2
	vmovdqa	%xmm15,32(%rsp)
	vpxor	%xmm15,%xmm15,%xmm15
	vaesenclast	%xmm0,%xmm3,%xmm3
	vaesenclast	%xmm0,%xmm4,%xmm4
	vpcmpgtd	%xmm15,%xmm14,%xmm15
	vaesenclast	%xmm0,%xmm5,%xmm5
	vaesenclast	%xmm0,%xmm6,%xmm6
	vpaddd	%xmm15,%xmm14,%xmm14
	vmovdqu	-120(%rsi),%xmm15
	vaesenclast	%xmm0,%xmm7,%xmm7
	vaesenclast	%xmm0,%xmm8,%xmm8
	vmovdqa	%xmm14,48(%rsp)
	vaesenclast	%xmm0,%xmm9,%xmm9
	vmovups	32-120(%rsi),%xmm0

	vmovups	%xmm2,-16(%r8)
	subq	%rbx,%r8
	vpxor	0(%rbp),%xmm2,%xmm2
	vmovups	%xmm3,-16(%r9)
	subq	72(%rsp),%r9
	vpxor	16(%rbp),%xmm3,%xmm3
	vmovups	%xmm4,-16(%r10)
	subq	80(%rsp),%r10
	vpxor	32(%rbp),%xmm4,%xmm4
	vmovups	%xmm5,-16(%r11)
	subq	88(%rsp),%r11
	vpxor	48(%rbp),%xmm5,%xmm5
	vmovups	%xmm6,-16(%r12)
	subq	96(%rsp),%r12
	vpxor	%xmm10,%xmm6,%xmm6
	vmovups	%xmm7,-16(%r13)
	subq	104(%rsp),%r13
	vpxor	%xmm11,%xmm7,%xmm7
	vmovups	%xmm8,-16(%r14)
	subq	112(%rsp),%r14
	vpxor	%xmm12,%xmm8,%xmm8
	vmovups	%xmm9,-16(%r15)
	subq	120(%rsp),%r15
	vpxor	%xmm13,%xmm9,%xmm9

	decl	%edx
	jnz	.Loop_enc8x

	movq	16(%rsp),%rax
.cfi_def_cfa	%rax,8





.Lenc8x_done:
	vzeroupper
	movq	-48(%rax),%r15
.cfi_restore	%r15
	movq	-40(%rax),%r14
.cfi_restore	%r14
	movq	-32(%rax),%r13
.cfi_restore	%r13
	movq	-24(%rax),%r12
.cfi_restore	%r12
	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lenc8x_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_multi_cbc_encrypt_avx,.-aesni_multi_cbc_encrypt_avx

.type	aesni_multi_cbc_decrypt_avx,@function
.align	32
aesni_multi_cbc_decrypt_avx:
.cfi_startproc	
_avx_cbc_dec_shortcut:
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56









	subq	$256,%rsp
	andq	$-256,%rsp
	subq	$192,%rsp
	movq	%rax,16(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x10,0x06,0x23,0x08

.Ldec8x_body:
	vzeroupper
	vmovdqu	(%rsi),%xmm15
	leaq	120(%rsi),%rsi
	leaq	160(%rdi),%rdi
	shrl	$1,%edx

.Ldec8x_loop_grande:

	xorl	%edx,%edx

	movl	-144(%rdi),%ecx

	movq	-160(%rdi),%r8
	cmpl	%edx,%ecx

	movq	-152(%rdi),%rbx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	vmovdqu	-136(%rdi),%xmm2
	movl	%ecx,32(%rsp)
	cmovleq	%rsp,%r8
	subq	%r8,%rbx
	movq	%rbx,64(%rsp)
	vmovdqu	%xmm2,192(%rsp)

	movl	-104(%rdi),%ecx

	movq	-120(%rdi),%r9
	cmpl	%edx,%ecx

	movq	-112(%rdi),%rbp
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	vmovdqu	-96(%rdi),%xmm3
	movl	%ecx,36(%rsp)
	cmovleq	%rsp,%r9
	subq	%r9,%rbp
	movq	%rbp,72(%rsp)
	vmovdqu	%xmm3,208(%rsp)

	movl	-64(%rdi),%ecx

	movq	-80(%rdi),%r10
	cmpl	%edx,%ecx

	movq	-72(%rdi),%rbp
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	vmovdqu	-56(%rdi),%xmm4
	movl	%ecx,40(%rsp)
	cmovleq	%rsp,%r10
	subq	%r10,%rbp
	movq	%rbp,80(%rsp)
	vmovdqu	%xmm4,224(%rsp)

	movl	-24(%rdi),%ecx

	movq	-40(%rdi),%r11
	cmpl	%edx,%ecx

	movq	-32(%rdi),%rbp
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	vmovdqu	-16(%rdi),%xmm5
	movl	%ecx,44(%rsp)
	cmovleq	%rsp,%r11
	subq	%r11,%rbp
	movq	%rbp,88(%rsp)
	vmovdqu	%xmm5,240(%rsp)

	movl	16(%rdi),%ecx

	movq	0(%rdi),%r12
	cmpl	%edx,%ecx

	movq	8(%rdi),%rbp
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	vmovdqu	24(%rdi),%xmm6
	movl	%ecx,48(%rsp)
	cmovleq	%rsp,%r12
	subq	%r12,%rbp
	movq	%rbp,96(%rsp)
	vmovdqu	%xmm6,256(%rsp)

	movl	56(%rdi),%ecx

	movq	40(%rdi),%r13
	cmpl	%edx,%ecx

	movq	48(%rdi),%rbp
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	vmovdqu	64(%rdi),%xmm7
	movl	%ecx,52(%rsp)
	cmovleq	%rsp,%r13
	subq	%r13,%rbp
	movq	%rbp,104(%rsp)
	vmovdqu	%xmm7,272(%rsp)

	movl	96(%rdi),%ecx

	movq	80(%rdi),%r14
	cmpl	%edx,%ecx

	movq	88(%rdi),%rbp
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	vmovdqu	104(%rdi),%xmm8
	movl	%ecx,56(%rsp)
	cmovleq	%rsp,%r14
	subq	%r14,%rbp
	movq	%rbp,112(%rsp)
	vmovdqu	%xmm8,288(%rsp)

	movl	136(%rdi),%ecx

	movq	120(%rdi),%r15
	cmpl	%edx,%ecx

	movq	128(%rdi),%rbp
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx

	vmovdqu	144(%rdi),%xmm9
	movl	%ecx,60(%rsp)
	cmovleq	%rsp,%r15
	subq	%r15,%rbp
	movq	%rbp,120(%rsp)
	vmovdqu	%xmm9,304(%rsp)
	testl	%edx,%edx
	jz	.Ldec8x_done

	vmovups	16-120(%rsi),%xmm1
	vmovups	32-120(%rsi),%xmm0
	movl	240-120(%rsi),%eax
	leaq	192+128(%rsp),%rbp

	vmovdqu	(%r8),%xmm2
	vmovdqu	(%r9),%xmm3
	vmovdqu	(%r10),%xmm4
	vmovdqu	(%r11),%xmm5
	vmovdqu	(%r12),%xmm6
	vmovdqu	(%r13),%xmm7
	vmovdqu	(%r14),%xmm8
	vmovdqu	(%r15),%xmm9
	vmovdqu	%xmm2,0(%rbp)
	vpxor	%xmm15,%xmm2,%xmm2
	vmovdqu	%xmm3,16(%rbp)
	vpxor	%xmm15,%xmm3,%xmm3
	vmovdqu	%xmm4,32(%rbp)
	vpxor	%xmm15,%xmm4,%xmm4
	vmovdqu	%xmm5,48(%rbp)
	vpxor	%xmm15,%xmm5,%xmm5
	vmovdqu	%xmm6,64(%rbp)
	vpxor	%xmm15,%xmm6,%xmm6
	vmovdqu	%xmm7,80(%rbp)
	vpxor	%xmm15,%xmm7,%xmm7
	vmovdqu	%xmm8,96(%rbp)
	vpxor	%xmm15,%xmm8,%xmm8
	vmovdqu	%xmm9,112(%rbp)
	vpxor	%xmm15,%xmm9,%xmm9
	xorq	$0x80,%rbp
	movl	$1,%ecx
	jmp	.Loop_dec8x

.align	32
.Loop_dec8x:
	vaesdec	%xmm1,%xmm2,%xmm2
	cmpl	32+0(%rsp),%ecx
	vaesdec	%xmm1,%xmm3,%xmm3
	prefetcht0	31(%r8)
	vaesdec	%xmm1,%xmm4,%xmm4
	vaesdec	%xmm1,%xmm5,%xmm5
	leaq	(%r8,%rbx,1),%rbx
	cmovgeq	%rsp,%r8
	vaesdec	%xmm1,%xmm6,%xmm6
	cmovgq	%rsp,%rbx
	vaesdec	%xmm1,%xmm7,%xmm7
	subq	%r8,%rbx
	vaesdec	%xmm1,%xmm8,%xmm8
	vmovdqu	16(%r8),%xmm10
	movq	%rbx,64+0(%rsp)
	vaesdec	%xmm1,%xmm9,%xmm9
	vmovups	-72(%rsi),%xmm1
	leaq	16(%r8,%rbx,1),%r8
	vmovdqu	%xmm10,128(%rsp)
	vaesdec	%xmm0,%xmm2,%xmm2
	cmpl	32+4(%rsp),%ecx
	movq	64+8(%rsp),%rbx
	vaesdec	%xmm0,%xmm3,%xmm3
	prefetcht0	31(%r9)
	vaesdec	%xmm0,%xmm4,%xmm4
	vaesdec	%xmm0,%xmm5,%xmm5
	leaq	(%r9,%rbx,1),%rbx
	cmovgeq	%rsp,%r9
	vaesdec	%xmm0,%xmm6,%xmm6
	cmovgq	%rsp,%rbx
	vaesdec	%xmm0,%xmm7,%xmm7
	subq	%r9,%rbx
	vaesdec	%xmm0,%xmm8,%xmm8
	vmovdqu	16(%r9),%xmm11
	movq	%rbx,64+8(%rsp)
	vaesdec	%xmm0,%xmm9,%xmm9
	vmovups	-56(%rsi),%xmm0
	leaq	16(%r9,%rbx,1),%r9
	vmovdqu	%xmm11,144(%rsp)
	vaesdec	%xmm1,%xmm2,%xmm2
	cmpl	32+8(%rsp),%ecx
	movq	64+16(%rsp),%rbx
	vaesdec	%xmm1,%xmm3,%xmm3
	prefetcht0	31(%r10)
	vaesdec	%xmm1,%xmm4,%xmm4
	prefetcht0	15(%r8)
	vaesdec	%xmm1,%xmm5,%xmm5
	leaq	(%r10,%rbx,1),%rbx
	cmovgeq	%rsp,%r10
	vaesdec	%xmm1,%xmm6,%xmm6
	cmovgq	%rsp,%rbx
	vaesdec	%xmm1,%xmm7,%xmm7
	subq	%r10,%rbx
	vaesdec	%xmm1,%xmm8,%xmm8
	vmovdqu	16(%r10),%xmm12
	movq	%rbx,64+16(%rsp)
	vaesdec	%xmm1,%xmm9,%xmm9
	vmovups	-40(%rsi),%xmm1
	leaq	16(%r10,%rbx,1),%r10
	vmovdqu	%xmm12,160(%rsp)
	vaesdec	%xmm0,%xmm2,%xmm2
	cmpl	32+12(%rsp),%ecx
	movq	64+24(%rsp),%rbx
	vaesdec	%xmm0,%xmm3,%xmm3
	prefetcht0	31(%r11)
	vaesdec	%xmm0,%xmm4,%xmm4
	prefetcht0	15(%r9)
	vaesdec	%xmm0,%xmm5,%xmm5
	leaq	(%r11,%rbx,1),%rbx
	cmovgeq	%rsp,%r11
	vaesdec	%xmm0,%xmm6,%xmm6
	cmovgq	%rsp,%rbx
	vaesdec	%xmm0,%xmm7,%xmm7
	subq	%r11,%rbx
	vaesdec	%xmm0,%xmm8,%xmm8
	vmovdqu	16(%r11),%xmm13
	movq	%rbx,64+24(%rsp)
	vaesdec	%xmm0,%xmm9,%xmm9
	vmovups	-24(%rsi),%xmm0
	leaq	16(%r11,%rbx,1),%r11
	vmovdqu	%xmm13,176(%rsp)
	vaesdec	%xmm1,%xmm2,%xmm2
	cmpl	32+16(%rsp),%ecx
	movq	64+32(%rsp),%rbx
	vaesdec	%xmm1,%xmm3,%xmm3
	prefetcht0	31(%r12)
	vaesdec	%xmm1,%xmm4,%xmm4
	prefetcht0	15(%r10)
	vaesdec	%xmm1,%xmm5,%xmm5
	leaq	(%r12,%rbx,1),%rbx
	cmovgeq	%rsp,%r12
	vaesdec	%xmm1,%xmm6,%xmm6
	cmovgq	%rsp,%rbx
	vaesdec	%xmm1,%xmm7,%xmm7
	subq	%r12,%rbx
	vaesdec	%xmm1,%xmm8,%xmm8
	vmovdqu	16(%r12),%xmm10
	movq	%rbx,64+32(%rsp)
	vaesdec	%xmm1,%xmm9,%xmm9
	vmovups	-8(%rsi),%xmm1
	leaq	16(%r12,%rbx,1),%r12
	vaesdec	%xmm0,%xmm2,%xmm2
	cmpl	32+20(%rsp),%ecx
	movq	64+40(%rsp),%rbx
	vaesdec	%xmm0,%xmm3,%xmm3
	prefetcht0	31(%r13)
	vaesdec	%xmm0,%xmm4,%xmm4
	prefetcht0	15(%r11)
	vaesdec	%xmm0,%xmm5,%xmm5
	leaq	(%rbx,%r13,1),%rbx
	cmovgeq	%rsp,%r13
	vaesdec	%xmm0,%xmm6,%xmm6
	cmovgq	%rsp,%rbx
	vaesdec	%xmm0,%xmm7,%xmm7
	subq	%r13,%rbx
	vaesdec	%xmm0,%xmm8,%xmm8
	vmovdqu	16(%r13),%xmm11
	movq	%rbx,64+40(%rsp)
	vaesdec	%xmm0,%xmm9,%xmm9
	vmovups	8(%rsi),%xmm0
	leaq	16(%r13,%rbx,1),%r13
	vaesdec	%xmm1,%xmm2,%xmm2
	cmpl	32+24(%rsp),%ecx
	movq	64+48(%rsp),%rbx
	vaesdec	%xmm1,%xmm3,%xmm3
	prefetcht0	31(%r14)
	vaesdec	%xmm1,%xmm4,%xmm4
	prefetcht0	15(%r12)
	vaesdec	%xmm1,%xmm5,%xmm5
	leaq	(%r14,%rbx,1),%rbx
	cmovgeq	%rsp,%r14
	vaesdec	%xmm1,%xmm6,%xmm6
	cmovgq	%rsp,%rbx
	vaesdec	%xmm1,%xmm7,%xmm7
	subq	%r14,%rbx
	vaesdec	%xmm1,%xmm8,%xmm8
	vmovdqu	16(%r14),%xmm12
	movq	%rbx,64+48(%rsp)
	vaesdec	%xmm1,%xmm9,%xmm9
	vmovups	24(%rsi),%xmm1
	leaq	16(%r14,%rbx,1),%r14
	vaesdec	%xmm0,%xmm2,%xmm2
	cmpl	32+28(%rsp),%ecx
	movq	64+56(%rsp),%rbx
	vaesdec	%xmm0,%xmm3,%xmm3
	prefetcht0	31(%r15)
	vaesdec	%xmm0,%xmm4,%xmm4
	prefetcht0	15(%r13)
	vaesdec	%xmm0,%xmm5,%xmm5
	leaq	(%r15,%rbx,1),%rbx
	cmovgeq	%rsp,%r15
	vaesdec	%xmm0,%xmm6,%xmm6
	cmovgq	%rsp,%rbx
	vaesdec	%xmm0,%xmm7,%xmm7
	subq	%r15,%rbx
	vaesdec	%xmm0,%xmm8,%xmm8
	vmovdqu	16(%r15),%xmm13
	movq	%rbx,64+56(%rsp)
	vaesdec	%xmm0,%xmm9,%xmm9
	vmovups	40(%rsi),%xmm0
	leaq	16(%r15,%rbx,1),%r15
	vmovdqu	32(%rsp),%xmm14
	prefetcht0	15(%r14)
	prefetcht0	15(%r15)
	cmpl	$11,%eax
	jb	.Ldec8x_tail

	vaesdec	%xmm1,%xmm2,%xmm2
	vaesdec	%xmm1,%xmm3,%xmm3
	vaesdec	%xmm1,%xmm4,%xmm4
	vaesdec	%xmm1,%xmm5,%xmm5
	vaesdec	%xmm1,%xmm6,%xmm6
	vaesdec	%xmm1,%xmm7,%xmm7
	vaesdec	%xmm1,%xmm8,%xmm8
	vaesdec	%xmm1,%xmm9,%xmm9
	vmovups	176-120(%rsi),%xmm1

	vaesdec	%xmm0,%xmm2,%xmm2
	vaesdec	%xmm0,%xmm3,%xmm3
	vaesdec	%xmm0,%xmm4,%xmm4
	vaesdec	%xmm0,%xmm5,%xmm5
	vaesdec	%xmm0,%xmm6,%xmm6
	vaesdec	%xmm0,%xmm7,%xmm7
	vaesdec	%xmm0,%xmm8,%xmm8
	vaesdec	%xmm0,%xmm9,%xmm9
	vmovups	192-120(%rsi),%xmm0
	je	.Ldec8x_tail

	vaesdec	%xmm1,%xmm2,%xmm2
	vaesdec	%xmm1,%xmm3,%xmm3
	vaesdec	%xmm1,%xmm4,%xmm4
	vaesdec	%xmm1,%xmm5,%xmm5
	vaesdec	%xmm1,%xmm6,%xmm6
	vaesdec	%xmm1,%xmm7,%xmm7
	vaesdec	%xmm1,%xmm8,%xmm8
	vaesdec	%xmm1,%xmm9,%xmm9
	vmovups	208-120(%rsi),%xmm1

	vaesdec	%xmm0,%xmm2,%xmm2
	vaesdec	%xmm0,%xmm3,%xmm3
	vaesdec	%xmm0,%xmm4,%xmm4
	vaesdec	%xmm0,%xmm5,%xmm5
	vaesdec	%xmm0,%xmm6,%xmm6
	vaesdec	%xmm0,%xmm7,%xmm7
	vaesdec	%xmm0,%xmm8,%xmm8
	vaesdec	%xmm0,%xmm9,%xmm9
	vmovups	224-120(%rsi),%xmm0

.Ldec8x_tail:
	vaesdec	%xmm1,%xmm2,%xmm2
	vpxor	%xmm15,%xmm15,%xmm15
	vaesdec	%xmm1,%xmm3,%xmm3
	vaesdec	%xmm1,%xmm4,%xmm4
	vpcmpgtd	%xmm15,%xmm14,%xmm15
	vaesdec	%xmm1,%xmm5,%xmm5
	vaesdec	%xmm1,%xmm6,%xmm6
	vpaddd	%xmm14,%xmm15,%xmm15
	vmovdqu	48(%rsp),%xmm14
	vaesdec	%xmm1,%xmm7,%xmm7
	movq	64(%rsp),%rbx
	vaesdec	%xmm1,%xmm8,%xmm8
	vaesdec	%xmm1,%xmm9,%xmm9
	vmovups	16-120(%rsi),%xmm1

	vaesdeclast	%xmm0,%xmm2,%xmm2
	vmovdqa	%xmm15,32(%rsp)
	vpxor	%xmm15,%xmm15,%xmm15
	vaesdeclast	%xmm0,%xmm3,%xmm3
	vpxor	0(%rbp),%xmm2,%xmm2
	vaesdeclast	%xmm0,%xmm4,%xmm4
	vpxor	16(%rbp),%xmm3,%xmm3
	vpcmpgtd	%xmm15,%xmm14,%xmm15
	vaesdeclast	%xmm0,%xmm5,%xmm5
	vpxor	32(%rbp),%xmm4,%xmm4
	vaesdeclast	%xmm0,%xmm6,%xmm6
	vpxor	48(%rbp),%xmm5,%xmm5
	vpaddd	%xmm15,%xmm14,%xmm14
	vmovdqu	-120(%rsi),%xmm15
	vaesdeclast	%xmm0,%xmm7,%xmm7
	vpxor	64(%rbp),%xmm6,%xmm6
	vaesdeclast	%xmm0,%xmm8,%xmm8
	vpxor	80(%rbp),%xmm7,%xmm7
	vmovdqa	%xmm14,48(%rsp)
	vaesdeclast	%xmm0,%xmm9,%xmm9
	vpxor	96(%rbp),%xmm8,%xmm8
	vmovups	32-120(%rsi),%xmm0

	vmovups	%xmm2,-16(%r8)
	subq	%rbx,%r8
	vmovdqu	128+0(%rsp),%xmm2
	vpxor	112(%rbp),%xmm9,%xmm9
	vmovups	%xmm3,-16(%r9)
	subq	72(%rsp),%r9
	vmovdqu	%xmm2,0(%rbp)
	vpxor	%xmm15,%xmm2,%xmm2
	vmovdqu	128+16(%rsp),%xmm3
	vmovups	%xmm4,-16(%r10)
	subq	80(%rsp),%r10
	vmovdqu	%xmm3,16(%rbp)
	vpxor	%xmm15,%xmm3,%xmm3
	vmovdqu	128+32(%rsp),%xmm4
	vmovups	%xmm5,-16(%r11)
	subq	88(%rsp),%r11
	vmovdqu	%xmm4,32(%rbp)
	vpxor	%xmm15,%xmm4,%xmm4
	vmovdqu	128+48(%rsp),%xmm5
	vmovups	%xmm6,-16(%r12)
	subq	96(%rsp),%r12
	vmovdqu	%xmm5,48(%rbp)
	vpxor	%xmm15,%xmm5,%xmm5
	vmovdqu	%xmm10,64(%rbp)
	vpxor	%xmm10,%xmm15,%xmm6
	vmovups	%xmm7,-16(%r13)
	subq	104(%rsp),%r13
	vmovdqu	%xmm11,80(%rbp)
	vpxor	%xmm11,%xmm15,%xmm7
	vmovups	%xmm8,-16(%r14)
	subq	112(%rsp),%r14
	vmovdqu	%xmm12,96(%rbp)
	vpxor	%xmm12,%xmm15,%xmm8
	vmovups	%xmm9,-16(%r15)
	subq	120(%rsp),%r15
	vmovdqu	%xmm13,112(%rbp)
	vpxor	%xmm13,%xmm15,%xmm9

	xorq	$128,%rbp
	decl	%edx
	jnz	.Loop_dec8x

	movq	16(%rsp),%rax
.cfi_def_cfa	%rax,8





.Ldec8x_done:
	vzeroupper
	movq	-48(%rax),%r15
.cfi_restore	%r15
	movq	-40(%rax),%r14
.cfi_restore	%r14
	movq	-32(%rax),%r13
.cfi_restore	%r13
	movq	-24(%rax),%r12
.cfi_restore	%r12
	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Ldec8x_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_multi_cbc_decrypt_avx,.-aesni_multi_cbc_decrypt_avx
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                 node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/aes/aesni-sha1-x86_64.s               0000664 0000000 0000000 00000162326 14746647661 0027566 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	


.globl	aesni_cbc_sha1_enc
.type	aesni_cbc_sha1_enc,@function
.align	32
aesni_cbc_sha1_enc:
.cfi_startproc	

	movl	OPENSSL_ia32cap_P+0(%rip),%r10d
	movq	OPENSSL_ia32cap_P+4(%rip),%r11
	btq	$61,%r11
	jc	aesni_cbc_sha1_enc_shaext
	andl	$268435456,%r11d
	andl	$1073741824,%r10d
	orl	%r11d,%r10d
	cmpl	$1342177280,%r10d
	je	aesni_cbc_sha1_enc_avx
	jmp	aesni_cbc_sha1_enc_ssse3
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_cbc_sha1_enc,.-aesni_cbc_sha1_enc
.type	aesni_cbc_sha1_enc_ssse3,@function
.align	32
aesni_cbc_sha1_enc_ssse3:
.cfi_startproc	
	movq	8(%rsp),%r10


	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-56
	leaq	-104(%rsp),%rsp
.cfi_adjust_cfa_offset	104


	movq	%rdi,%r12
	movq	%rsi,%r13
	movq	%rdx,%r14
	leaq	112(%rcx),%r15
	movdqu	(%r8),%xmm2
	movq	%r8,88(%rsp)
	shlq	$6,%r14
	subq	%r12,%r13
	movl	240-112(%r15),%r8d
	addq	%r10,%r14

	leaq	K_XX_XX(%rip),%r11
	movl	0(%r9),%eax
	movl	4(%r9),%ebx
	movl	8(%r9),%ecx
	movl	12(%r9),%edx
	movl	%ebx,%esi
	movl	16(%r9),%ebp
	movl	%ecx,%edi
	xorl	%edx,%edi
	andl	%edi,%esi

	movdqa	64(%r11),%xmm3
	movdqa	0(%r11),%xmm13
	movdqu	0(%r10),%xmm4
	movdqu	16(%r10),%xmm5
	movdqu	32(%r10),%xmm6
	movdqu	48(%r10),%xmm7
.byte	102,15,56,0,227
.byte	102,15,56,0,235
.byte	102,15,56,0,243
	addq	$64,%r10
	paddd	%xmm13,%xmm4
.byte	102,15,56,0,251
	paddd	%xmm13,%xmm5
	paddd	%xmm13,%xmm6
	movdqa	%xmm4,0(%rsp)
	psubd	%xmm13,%xmm4
	movdqa	%xmm5,16(%rsp)
	psubd	%xmm13,%xmm5
	movdqa	%xmm6,32(%rsp)
	psubd	%xmm13,%xmm6
	movups	-112(%r15),%xmm15
	movups	16-112(%r15),%xmm0
	jmp	.Loop_ssse3
.align	32
.Loop_ssse3:
	rorl	$2,%ebx
	movups	0(%r12),%xmm14
	xorps	%xmm15,%xmm14
	xorps	%xmm14,%xmm2
	movups	-80(%r15),%xmm1
.byte	102,15,56,220,208
	pshufd	$238,%xmm4,%xmm8
	xorl	%edx,%esi
	movdqa	%xmm7,%xmm12
	paddd	%xmm7,%xmm13
	movl	%eax,%edi
	addl	0(%rsp),%ebp
	punpcklqdq	%xmm5,%xmm8
	xorl	%ecx,%ebx
	roll	$5,%eax
	addl	%esi,%ebp
	psrldq	$4,%xmm12
	andl	%ebx,%edi
	xorl	%ecx,%ebx
	pxor	%xmm4,%xmm8
	addl	%eax,%ebp
	rorl	$7,%eax
	pxor	%xmm6,%xmm12
	xorl	%ecx,%edi
	movl	%ebp,%esi
	addl	4(%rsp),%edx
	pxor	%xmm12,%xmm8
	xorl	%ebx,%eax
	roll	$5,%ebp
	movdqa	%xmm13,48(%rsp)
	addl	%edi,%edx
	movups	-64(%r15),%xmm0
.byte	102,15,56,220,209
	andl	%eax,%esi
	movdqa	%xmm8,%xmm3
	xorl	%ebx,%eax
	addl	%ebp,%edx
	rorl	$7,%ebp
	movdqa	%xmm8,%xmm12
	xorl	%ebx,%esi
	pslldq	$12,%xmm3
	paddd	%xmm8,%xmm8
	movl	%edx,%edi
	addl	8(%rsp),%ecx
	psrld	$31,%xmm12
	xorl	%eax,%ebp
	roll	$5,%edx
	addl	%esi,%ecx
	movdqa	%xmm3,%xmm13
	andl	%ebp,%edi
	xorl	%eax,%ebp
	psrld	$30,%xmm3
	addl	%edx,%ecx
	rorl	$7,%edx
	por	%xmm12,%xmm8
	xorl	%eax,%edi
	movl	%ecx,%esi
	addl	12(%rsp),%ebx
	movups	-48(%r15),%xmm1
.byte	102,15,56,220,208
	pslld	$2,%xmm13
	pxor	%xmm3,%xmm8
	xorl	%ebp,%edx
	movdqa	0(%r11),%xmm3
	roll	$5,%ecx
	addl	%edi,%ebx
	andl	%edx,%esi
	pxor	%xmm13,%xmm8
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	rorl	$7,%ecx
	pshufd	$238,%xmm5,%xmm9
	xorl	%ebp,%esi
	movdqa	%xmm8,%xmm13
	paddd	%xmm8,%xmm3
	movl	%ebx,%edi
	addl	16(%rsp),%eax
	punpcklqdq	%xmm6,%xmm9
	xorl	%edx,%ecx
	roll	$5,%ebx
	addl	%esi,%eax
	psrldq	$4,%xmm13
	andl	%ecx,%edi
	xorl	%edx,%ecx
	pxor	%xmm5,%xmm9
	addl	%ebx,%eax
	rorl	$7,%ebx
	movups	-32(%r15),%xmm0
.byte	102,15,56,220,209
	pxor	%xmm7,%xmm13
	xorl	%edx,%edi
	movl	%eax,%esi
	addl	20(%rsp),%ebp
	pxor	%xmm13,%xmm9
	xorl	%ecx,%ebx
	roll	$5,%eax
	movdqa	%xmm3,0(%rsp)
	addl	%edi,%ebp
	andl	%ebx,%esi
	movdqa	%xmm9,%xmm12
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	rorl	$7,%eax
	movdqa	%xmm9,%xmm13
	xorl	%ecx,%esi
	pslldq	$12,%xmm12
	paddd	%xmm9,%xmm9
	movl	%ebp,%edi
	addl	24(%rsp),%edx
	psrld	$31,%xmm13
	xorl	%ebx,%eax
	roll	$5,%ebp
	addl	%esi,%edx
	movups	-16(%r15),%xmm1
.byte	102,15,56,220,208
	movdqa	%xmm12,%xmm3
	andl	%eax,%edi
	xorl	%ebx,%eax
	psrld	$30,%xmm12
	addl	%ebp,%edx
	rorl	$7,%ebp
	por	%xmm13,%xmm9
	xorl	%ebx,%edi
	movl	%edx,%esi
	addl	28(%rsp),%ecx
	pslld	$2,%xmm3
	pxor	%xmm12,%xmm9
	xorl	%eax,%ebp
	movdqa	16(%r11),%xmm12
	roll	$5,%edx
	addl	%edi,%ecx
	andl	%ebp,%esi
	pxor	%xmm3,%xmm9
	xorl	%eax,%ebp
	addl	%edx,%ecx
	rorl	$7,%edx
	pshufd	$238,%xmm6,%xmm10
	xorl	%eax,%esi
	movdqa	%xmm9,%xmm3
	paddd	%xmm9,%xmm12
	movl	%ecx,%edi
	addl	32(%rsp),%ebx
	movups	0(%r15),%xmm0
.byte	102,15,56,220,209
	punpcklqdq	%xmm7,%xmm10
	xorl	%ebp,%edx
	roll	$5,%ecx
	addl	%esi,%ebx
	psrldq	$4,%xmm3
	andl	%edx,%edi
	xorl	%ebp,%edx
	pxor	%xmm6,%xmm10
	addl	%ecx,%ebx
	rorl	$7,%ecx
	pxor	%xmm8,%xmm3
	xorl	%ebp,%edi
	movl	%ebx,%esi
	addl	36(%rsp),%eax
	pxor	%xmm3,%xmm10
	xorl	%edx,%ecx
	roll	$5,%ebx
	movdqa	%xmm12,16(%rsp)
	addl	%edi,%eax
	andl	%ecx,%esi
	movdqa	%xmm10,%xmm13
	xorl	%edx,%ecx
	addl	%ebx,%eax
	rorl	$7,%ebx
	movups	16(%r15),%xmm1
.byte	102,15,56,220,208
	movdqa	%xmm10,%xmm3
	xorl	%edx,%esi
	pslldq	$12,%xmm13
	paddd	%xmm10,%xmm10
	movl	%eax,%edi
	addl	40(%rsp),%ebp
	psrld	$31,%xmm3
	xorl	%ecx,%ebx
	roll	$5,%eax
	addl	%esi,%ebp
	movdqa	%xmm13,%xmm12
	andl	%ebx,%edi
	xorl	%ecx,%ebx
	psrld	$30,%xmm13
	addl	%eax,%ebp
	rorl	$7,%eax
	por	%xmm3,%xmm10
	xorl	%ecx,%edi
	movl	%ebp,%esi
	addl	44(%rsp),%edx
	pslld	$2,%xmm12
	pxor	%xmm13,%xmm10
	xorl	%ebx,%eax
	movdqa	16(%r11),%xmm13
	roll	$5,%ebp
	addl	%edi,%edx
	movups	32(%r15),%xmm0
.byte	102,15,56,220,209
	andl	%eax,%esi
	pxor	%xmm12,%xmm10
	xorl	%ebx,%eax
	addl	%ebp,%edx
	rorl	$7,%ebp
	pshufd	$238,%xmm7,%xmm11
	xorl	%ebx,%esi
	movdqa	%xmm10,%xmm12
	paddd	%xmm10,%xmm13
	movl	%edx,%edi
	addl	48(%rsp),%ecx
	punpcklqdq	%xmm8,%xmm11
	xorl	%eax,%ebp
	roll	$5,%edx
	addl	%esi,%ecx
	psrldq	$4,%xmm12
	andl	%ebp,%edi
	xorl	%eax,%ebp
	pxor	%xmm7,%xmm11
	addl	%edx,%ecx
	rorl	$7,%edx
	pxor	%xmm9,%xmm12
	xorl	%eax,%edi
	movl	%ecx,%esi
	addl	52(%rsp),%ebx
	movups	48(%r15),%xmm1
.byte	102,15,56,220,208
	pxor	%xmm12,%xmm11
	xorl	%ebp,%edx
	roll	$5,%ecx
	movdqa	%xmm13,32(%rsp)
	addl	%edi,%ebx
	andl	%edx,%esi
	movdqa	%xmm11,%xmm3
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	rorl	$7,%ecx
	movdqa	%xmm11,%xmm12
	xorl	%ebp,%esi
	pslldq	$12,%xmm3
	paddd	%xmm11,%xmm11
	movl	%ebx,%edi
	addl	56(%rsp),%eax
	psrld	$31,%xmm12
	xorl	%edx,%ecx
	roll	$5,%ebx
	addl	%esi,%eax
	movdqa	%xmm3,%xmm13
	andl	%ecx,%edi
	xorl	%edx,%ecx
	psrld	$30,%xmm3
	addl	%ebx,%eax
	rorl	$7,%ebx
	cmpl	$11,%r8d
	jb	.Laesenclast1
	movups	64(%r15),%xmm0
.byte	102,15,56,220,209
	movups	80(%r15),%xmm1
.byte	102,15,56,220,208
	je	.Laesenclast1
	movups	96(%r15),%xmm0
.byte	102,15,56,220,209
	movups	112(%r15),%xmm1
.byte	102,15,56,220,208
.Laesenclast1:
.byte	102,15,56,221,209
	movups	16-112(%r15),%xmm0
	por	%xmm12,%xmm11
	xorl	%edx,%edi
	movl	%eax,%esi
	addl	60(%rsp),%ebp
	pslld	$2,%xmm13
	pxor	%xmm3,%xmm11
	xorl	%ecx,%ebx
	movdqa	16(%r11),%xmm3
	roll	$5,%eax
	addl	%edi,%ebp
	andl	%ebx,%esi
	pxor	%xmm13,%xmm11
	pshufd	$238,%xmm10,%xmm13
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	rorl	$7,%eax
	pxor	%xmm8,%xmm4
	xorl	%ecx,%esi
	movl	%ebp,%edi
	addl	0(%rsp),%edx
	punpcklqdq	%xmm11,%xmm13
	xorl	%ebx,%eax
	roll	$5,%ebp
	pxor	%xmm5,%xmm4
	addl	%esi,%edx
	movups	16(%r12),%xmm14
	xorps	%xmm15,%xmm14
	movups	%xmm2,0(%r12,%r13,1)
	xorps	%xmm14,%xmm2
	movups	-80(%r15),%xmm1
.byte	102,15,56,220,208
	andl	%eax,%edi
	movdqa	%xmm3,%xmm12
	xorl	%ebx,%eax
	paddd	%xmm11,%xmm3
	addl	%ebp,%edx
	pxor	%xmm13,%xmm4
	rorl	$7,%ebp
	xorl	%ebx,%edi
	movl	%edx,%esi
	addl	4(%rsp),%ecx
	movdqa	%xmm4,%xmm13
	xorl	%eax,%ebp
	roll	$5,%edx
	movdqa	%xmm3,48(%rsp)
	addl	%edi,%ecx
	andl	%ebp,%esi
	xorl	%eax,%ebp
	pslld	$2,%xmm4
	addl	%edx,%ecx
	rorl	$7,%edx
	psrld	$30,%xmm13
	xorl	%eax,%esi
	movl	%ecx,%edi
	addl	8(%rsp),%ebx
	movups	-64(%r15),%xmm0
.byte	102,15,56,220,209
	por	%xmm13,%xmm4
	xorl	%ebp,%edx
	roll	$5,%ecx
	pshufd	$238,%xmm11,%xmm3
	addl	%esi,%ebx
	andl	%edx,%edi
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	addl	12(%rsp),%eax
	xorl	%ebp,%edi
	movl	%ebx,%esi
	roll	$5,%ebx
	addl	%edi,%eax
	xorl	%edx,%esi
	rorl	$7,%ecx
	addl	%ebx,%eax
	pxor	%xmm9,%xmm5
	addl	16(%rsp),%ebp
	movups	-48(%r15),%xmm1
.byte	102,15,56,220,208
	xorl	%ecx,%esi
	punpcklqdq	%xmm4,%xmm3
	movl	%eax,%edi
	roll	$5,%eax
	pxor	%xmm6,%xmm5
	addl	%esi,%ebp
	xorl	%ecx,%edi
	movdqa	%xmm12,%xmm13
	rorl	$7,%ebx
	paddd	%xmm4,%xmm12
	addl	%eax,%ebp
	pxor	%xmm3,%xmm5
	addl	20(%rsp),%edx
	xorl	%ebx,%edi
	movl	%ebp,%esi
	roll	$5,%ebp
	movdqa	%xmm5,%xmm3
	addl	%edi,%edx
	xorl	%ebx,%esi
	movdqa	%xmm12,0(%rsp)
	rorl	$7,%eax
	addl	%ebp,%edx
	addl	24(%rsp),%ecx
	pslld	$2,%xmm5
	xorl	%eax,%esi
	movl	%edx,%edi
	psrld	$30,%xmm3
	roll	$5,%edx
	addl	%esi,%ecx
	movups	-32(%r15),%xmm0
.byte	102,15,56,220,209
	xorl	%eax,%edi
	rorl	$7,%ebp
	por	%xmm3,%xmm5
	addl	%edx,%ecx
	addl	28(%rsp),%ebx
	pshufd	$238,%xmm4,%xmm12
	xorl	%ebp,%edi
	movl	%ecx,%esi
	roll	$5,%ecx
	addl	%edi,%ebx
	xorl	%ebp,%esi
	rorl	$7,%edx
	addl	%ecx,%ebx
	pxor	%xmm10,%xmm6
	addl	32(%rsp),%eax
	xorl	%edx,%esi
	punpcklqdq	%xmm5,%xmm12
	movl	%ebx,%edi
	roll	$5,%ebx
	pxor	%xmm7,%xmm6
	addl	%esi,%eax
	xorl	%edx,%edi
	movdqa	32(%r11),%xmm3
	rorl	$7,%ecx
	paddd	%xmm5,%xmm13
	addl	%ebx,%eax
	pxor	%xmm12,%xmm6
	addl	36(%rsp),%ebp
	movups	-16(%r15),%xmm1
.byte	102,15,56,220,208
	xorl	%ecx,%edi
	movl	%eax,%esi
	roll	$5,%eax
	movdqa	%xmm6,%xmm12
	addl	%edi,%ebp
	xorl	%ecx,%esi
	movdqa	%xmm13,16(%rsp)
	rorl	$7,%ebx
	addl	%eax,%ebp
	addl	40(%rsp),%edx
	pslld	$2,%xmm6
	xorl	%ebx,%esi
	movl	%ebp,%edi
	psrld	$30,%xmm12
	roll	$5,%ebp
	addl	%esi,%edx
	xorl	%ebx,%edi
	rorl	$7,%eax
	por	%xmm12,%xmm6
	addl	%ebp,%edx
	addl	44(%rsp),%ecx
	pshufd	$238,%xmm5,%xmm13
	xorl	%eax,%edi
	movl	%edx,%esi
	roll	$5,%edx
	addl	%edi,%ecx
	movups	0(%r15),%xmm0
.byte	102,15,56,220,209
	xorl	%eax,%esi
	rorl	$7,%ebp
	addl	%edx,%ecx
	pxor	%xmm11,%xmm7
	addl	48(%rsp),%ebx
	xorl	%ebp,%esi
	punpcklqdq	%xmm6,%xmm13
	movl	%ecx,%edi
	roll	$5,%ecx
	pxor	%xmm8,%xmm7
	addl	%esi,%ebx
	xorl	%ebp,%edi
	movdqa	%xmm3,%xmm12
	rorl	$7,%edx
	paddd	%xmm6,%xmm3
	addl	%ecx,%ebx
	pxor	%xmm13,%xmm7
	addl	52(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	roll	$5,%ebx
	movdqa	%xmm7,%xmm13
	addl	%edi,%eax
	xorl	%edx,%esi
	movdqa	%xmm3,32(%rsp)
	rorl	$7,%ecx
	addl	%ebx,%eax
	addl	56(%rsp),%ebp
	movups	16(%r15),%xmm1
.byte	102,15,56,220,208
	pslld	$2,%xmm7
	xorl	%ecx,%esi
	movl	%eax,%edi
	psrld	$30,%xmm13
	roll	$5,%eax
	addl	%esi,%ebp
	xorl	%ecx,%edi
	rorl	$7,%ebx
	por	%xmm13,%xmm7
	addl	%eax,%ebp
	addl	60(%rsp),%edx
	pshufd	$238,%xmm6,%xmm3
	xorl	%ebx,%edi
	movl	%ebp,%esi
	roll	$5,%ebp
	addl	%edi,%edx
	xorl	%ebx,%esi
	rorl	$7,%eax
	addl	%ebp,%edx
	pxor	%xmm4,%xmm8
	addl	0(%rsp),%ecx
	xorl	%eax,%esi
	punpcklqdq	%xmm7,%xmm3
	movl	%edx,%edi
	roll	$5,%edx
	pxor	%xmm9,%xmm8
	addl	%esi,%ecx
	movups	32(%r15),%xmm0
.byte	102,15,56,220,209
	xorl	%eax,%edi
	movdqa	%xmm12,%xmm13
	rorl	$7,%ebp
	paddd	%xmm7,%xmm12
	addl	%edx,%ecx
	pxor	%xmm3,%xmm8
	addl	4(%rsp),%ebx
	xorl	%ebp,%edi
	movl	%ecx,%esi
	roll	$5,%ecx
	movdqa	%xmm8,%xmm3
	addl	%edi,%ebx
	xorl	%ebp,%esi
	movdqa	%xmm12,48(%rsp)
	rorl	$7,%edx
	addl	%ecx,%ebx
	addl	8(%rsp),%eax
	pslld	$2,%xmm8
	xorl	%edx,%esi
	movl	%ebx,%edi
	psrld	$30,%xmm3
	roll	$5,%ebx
	addl	%esi,%eax
	xorl	%edx,%edi
	rorl	$7,%ecx
	por	%xmm3,%xmm8
	addl	%ebx,%eax
	addl	12(%rsp),%ebp
	movups	48(%r15),%xmm1
.byte	102,15,56,220,208
	pshufd	$238,%xmm7,%xmm12
	xorl	%ecx,%edi
	movl	%eax,%esi
	roll	$5,%eax
	addl	%edi,%ebp
	xorl	%ecx,%esi
	rorl	$7,%ebx
	addl	%eax,%ebp
	pxor	%xmm5,%xmm9
	addl	16(%rsp),%edx
	xorl	%ebx,%esi
	punpcklqdq	%xmm8,%xmm12
	movl	%ebp,%edi
	roll	$5,%ebp
	pxor	%xmm10,%xmm9
	addl	%esi,%edx
	xorl	%ebx,%edi
	movdqa	%xmm13,%xmm3
	rorl	$7,%eax
	paddd	%xmm8,%xmm13
	addl	%ebp,%edx
	pxor	%xmm12,%xmm9
	addl	20(%rsp),%ecx
	xorl	%eax,%edi
	movl	%edx,%esi
	roll	$5,%edx
	movdqa	%xmm9,%xmm12
	addl	%edi,%ecx
	cmpl	$11,%r8d
	jb	.Laesenclast2
	movups	64(%r15),%xmm0
.byte	102,15,56,220,209
	movups	80(%r15),%xmm1
.byte	102,15,56,220,208
	je	.Laesenclast2
	movups	96(%r15),%xmm0
.byte	102,15,56,220,209
	movups	112(%r15),%xmm1
.byte	102,15,56,220,208
.Laesenclast2:
.byte	102,15,56,221,209
	movups	16-112(%r15),%xmm0
	xorl	%eax,%esi
	movdqa	%xmm13,0(%rsp)
	rorl	$7,%ebp
	addl	%edx,%ecx
	addl	24(%rsp),%ebx
	pslld	$2,%xmm9
	xorl	%ebp,%esi
	movl	%ecx,%edi
	psrld	$30,%xmm12
	roll	$5,%ecx
	addl	%esi,%ebx
	xorl	%ebp,%edi
	rorl	$7,%edx
	por	%xmm12,%xmm9
	addl	%ecx,%ebx
	addl	28(%rsp),%eax
	pshufd	$238,%xmm8,%xmm13
	rorl	$7,%ecx
	movl	%ebx,%esi
	xorl	%edx,%edi
	roll	$5,%ebx
	addl	%edi,%eax
	xorl	%ecx,%esi
	xorl	%edx,%ecx
	addl	%ebx,%eax
	pxor	%xmm6,%xmm10
	addl	32(%rsp),%ebp
	movups	32(%r12),%xmm14
	xorps	%xmm15,%xmm14
	movups	%xmm2,16(%r13,%r12,1)
	xorps	%xmm14,%xmm2
	movups	-80(%r15),%xmm1
.byte	102,15,56,220,208
	andl	%ecx,%esi
	xorl	%edx,%ecx
	rorl	$7,%ebx
	punpcklqdq	%xmm9,%xmm13
	movl	%eax,%edi
	xorl	%ecx,%esi
	pxor	%xmm11,%xmm10
	roll	$5,%eax
	addl	%esi,%ebp
	movdqa	%xmm3,%xmm12
	xorl	%ebx,%edi
	paddd	%xmm9,%xmm3
	xorl	%ecx,%ebx
	pxor	%xmm13,%xmm10
	addl	%eax,%ebp
	addl	36(%rsp),%edx
	andl	%ebx,%edi
	xorl	%ecx,%ebx
	rorl	$7,%eax
	movdqa	%xmm10,%xmm13
	movl	%ebp,%esi
	xorl	%ebx,%edi
	movdqa	%xmm3,16(%rsp)
	roll	$5,%ebp
	addl	%edi,%edx
	movups	-64(%r15),%xmm0
.byte	102,15,56,220,209
	xorl	%eax,%esi
	pslld	$2,%xmm10
	xorl	%ebx,%eax
	addl	%ebp,%edx
	psrld	$30,%xmm13
	addl	40(%rsp),%ecx
	andl	%eax,%esi
	xorl	%ebx,%eax
	por	%xmm13,%xmm10
	rorl	$7,%ebp
	movl	%edx,%edi
	xorl	%eax,%esi
	roll	$5,%edx
	pshufd	$238,%xmm9,%xmm3
	addl	%esi,%ecx
	xorl	%ebp,%edi
	xorl	%eax,%ebp
	addl	%edx,%ecx
	addl	44(%rsp),%ebx
	andl	%ebp,%edi
	xorl	%eax,%ebp
	rorl	$7,%edx
	movups	-48(%r15),%xmm1
.byte	102,15,56,220,208
	movl	%ecx,%esi
	xorl	%ebp,%edi
	roll	$5,%ecx
	addl	%edi,%ebx
	xorl	%edx,%esi
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	pxor	%xmm7,%xmm11
	addl	48(%rsp),%eax
	andl	%edx,%esi
	xorl	%ebp,%edx
	rorl	$7,%ecx
	punpcklqdq	%xmm10,%xmm3
	movl	%ebx,%edi
	xorl	%edx,%esi
	pxor	%xmm4,%xmm11
	roll	$5,%ebx
	addl	%esi,%eax
	movdqa	48(%r11),%xmm13
	xorl	%ecx,%edi
	paddd	%xmm10,%xmm12
	xorl	%edx,%ecx
	pxor	%xmm3,%xmm11
	addl	%ebx,%eax
	addl	52(%rsp),%ebp
	movups	-32(%r15),%xmm0
.byte	102,15,56,220,209
	andl	%ecx,%edi
	xorl	%edx,%ecx
	rorl	$7,%ebx
	movdqa	%xmm11,%xmm3
	movl	%eax,%esi
	xorl	%ecx,%edi
	movdqa	%xmm12,32(%rsp)
	roll	$5,%eax
	addl	%edi,%ebp
	xorl	%ebx,%esi
	pslld	$2,%xmm11
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	psrld	$30,%xmm3
	addl	56(%rsp),%edx
	andl	%ebx,%esi
	xorl	%ecx,%ebx
	por	%xmm3,%xmm11
	rorl	$7,%eax
	movl	%ebp,%edi
	xorl	%ebx,%esi
	roll	$5,%ebp
	pshufd	$238,%xmm10,%xmm12
	addl	%esi,%edx
	movups	-16(%r15),%xmm1
.byte	102,15,56,220,208
	xorl	%eax,%edi
	xorl	%ebx,%eax
	addl	%ebp,%edx
	addl	60(%rsp),%ecx
	andl	%eax,%edi
	xorl	%ebx,%eax
	rorl	$7,%ebp
	movl	%edx,%esi
	xorl	%eax,%edi
	roll	$5,%edx
	addl	%edi,%ecx
	xorl	%ebp,%esi
	xorl	%eax,%ebp
	addl	%edx,%ecx
	pxor	%xmm8,%xmm4
	addl	0(%rsp),%ebx
	andl	%ebp,%esi
	xorl	%eax,%ebp
	rorl	$7,%edx
	movups	0(%r15),%xmm0
.byte	102,15,56,220,209
	punpcklqdq	%xmm11,%xmm12
	movl	%ecx,%edi
	xorl	%ebp,%esi
	pxor	%xmm5,%xmm4
	roll	$5,%ecx
	addl	%esi,%ebx
	movdqa	%xmm13,%xmm3
	xorl	%edx,%edi
	paddd	%xmm11,%xmm13
	xorl	%ebp,%edx
	pxor	%xmm12,%xmm4
	addl	%ecx,%ebx
	addl	4(%rsp),%eax
	andl	%edx,%edi
	xorl	%ebp,%edx
	rorl	$7,%ecx
	movdqa	%xmm4,%xmm12
	movl	%ebx,%esi
	xorl	%edx,%edi
	movdqa	%xmm13,48(%rsp)
	roll	$5,%ebx
	addl	%edi,%eax
	xorl	%ecx,%esi
	pslld	$2,%xmm4
	xorl	%edx,%ecx
	addl	%ebx,%eax
	psrld	$30,%xmm12
	addl	8(%rsp),%ebp
	movups	16(%r15),%xmm1
.byte	102,15,56,220,208
	andl	%ecx,%esi
	xorl	%edx,%ecx
	por	%xmm12,%xmm4
	rorl	$7,%ebx
	movl	%eax,%edi
	xorl	%ecx,%esi
	roll	$5,%eax
	pshufd	$238,%xmm11,%xmm13
	addl	%esi,%ebp
	xorl	%ebx,%edi
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	addl	12(%rsp),%edx
	andl	%ebx,%edi
	xorl	%ecx,%ebx
	rorl	$7,%eax
	movl	%ebp,%esi
	xorl	%ebx,%edi
	roll	$5,%ebp
	addl	%edi,%edx
	movups	32(%r15),%xmm0
.byte	102,15,56,220,209
	xorl	%eax,%esi
	xorl	%ebx,%eax
	addl	%ebp,%edx
	pxor	%xmm9,%xmm5
	addl	16(%rsp),%ecx
	andl	%eax,%esi
	xorl	%ebx,%eax
	rorl	$7,%ebp
	punpcklqdq	%xmm4,%xmm13
	movl	%edx,%edi
	xorl	%eax,%esi
	pxor	%xmm6,%xmm5
	roll	$5,%edx
	addl	%esi,%ecx
	movdqa	%xmm3,%xmm12
	xorl	%ebp,%edi
	paddd	%xmm4,%xmm3
	xorl	%eax,%ebp
	pxor	%xmm13,%xmm5
	addl	%edx,%ecx
	addl	20(%rsp),%ebx
	andl	%ebp,%edi
	xorl	%eax,%ebp
	rorl	$7,%edx
	movups	48(%r15),%xmm1
.byte	102,15,56,220,208
	movdqa	%xmm5,%xmm13
	movl	%ecx,%esi
	xorl	%ebp,%edi
	movdqa	%xmm3,0(%rsp)
	roll	$5,%ecx
	addl	%edi,%ebx
	xorl	%edx,%esi
	pslld	$2,%xmm5
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	psrld	$30,%xmm13
	addl	24(%rsp),%eax
	andl	%edx,%esi
	xorl	%ebp,%edx
	por	%xmm13,%xmm5
	rorl	$7,%ecx
	movl	%ebx,%edi
	xorl	%edx,%esi
	roll	$5,%ebx
	pshufd	$238,%xmm4,%xmm3
	addl	%esi,%eax
	xorl	%ecx,%edi
	xorl	%edx,%ecx
	addl	%ebx,%eax
	addl	28(%rsp),%ebp
	cmpl	$11,%r8d
	jb	.Laesenclast3
	movups	64(%r15),%xmm0
.byte	102,15,56,220,209
	movups	80(%r15),%xmm1
.byte	102,15,56,220,208
	je	.Laesenclast3
	movups	96(%r15),%xmm0
.byte	102,15,56,220,209
	movups	112(%r15),%xmm1
.byte	102,15,56,220,208
.Laesenclast3:
.byte	102,15,56,221,209
	movups	16-112(%r15),%xmm0
	andl	%ecx,%edi
	xorl	%edx,%ecx
	rorl	$7,%ebx
	movl	%eax,%esi
	xorl	%ecx,%edi
	roll	$5,%eax
	addl	%edi,%ebp
	xorl	%ebx,%esi
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	pxor	%xmm10,%xmm6
	addl	32(%rsp),%edx
	andl	%ebx,%esi
	xorl	%ecx,%ebx
	rorl	$7,%eax
	punpcklqdq	%xmm5,%xmm3
	movl	%ebp,%edi
	xorl	%ebx,%esi
	pxor	%xmm7,%xmm6
	roll	$5,%ebp
	addl	%esi,%edx
	movups	48(%r12),%xmm14
	xorps	%xmm15,%xmm14
	movups	%xmm2,32(%r13,%r12,1)
	xorps	%xmm14,%xmm2
	movups	-80(%r15),%xmm1
.byte	102,15,56,220,208
	movdqa	%xmm12,%xmm13
	xorl	%eax,%edi
	paddd	%xmm5,%xmm12
	xorl	%ebx,%eax
	pxor	%xmm3,%xmm6
	addl	%ebp,%edx
	addl	36(%rsp),%ecx
	andl	%eax,%edi
	xorl	%ebx,%eax
	rorl	$7,%ebp
	movdqa	%xmm6,%xmm3
	movl	%edx,%esi
	xorl	%eax,%edi
	movdqa	%xmm12,16(%rsp)
	roll	$5,%edx
	addl	%edi,%ecx
	xorl	%ebp,%esi
	pslld	$2,%xmm6
	xorl	%eax,%ebp
	addl	%edx,%ecx
	psrld	$30,%xmm3
	addl	40(%rsp),%ebx
	andl	%ebp,%esi
	xorl	%eax,%ebp
	por	%xmm3,%xmm6
	rorl	$7,%edx
	movups	-64(%r15),%xmm0
.byte	102,15,56,220,209
	movl	%ecx,%edi
	xorl	%ebp,%esi
	roll	$5,%ecx
	pshufd	$238,%xmm5,%xmm12
	addl	%esi,%ebx
	xorl	%edx,%edi
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	addl	44(%rsp),%eax
	andl	%edx,%edi
	xorl	%ebp,%edx
	rorl	$7,%ecx
	movl	%ebx,%esi
	xorl	%edx,%edi
	roll	$5,%ebx
	addl	%edi,%eax
	xorl	%edx,%esi
	addl	%ebx,%eax
	pxor	%xmm11,%xmm7
	addl	48(%rsp),%ebp
	movups	-48(%r15),%xmm1
.byte	102,15,56,220,208
	xorl	%ecx,%esi
	punpcklqdq	%xmm6,%xmm12
	movl	%eax,%edi
	roll	$5,%eax
	pxor	%xmm8,%xmm7
	addl	%esi,%ebp
	xorl	%ecx,%edi
	movdqa	%xmm13,%xmm3
	rorl	$7,%ebx
	paddd	%xmm6,%xmm13
	addl	%eax,%ebp
	pxor	%xmm12,%xmm7
	addl	52(%rsp),%edx
	xorl	%ebx,%edi
	movl	%ebp,%esi
	roll	$5,%ebp
	movdqa	%xmm7,%xmm12
	addl	%edi,%edx
	xorl	%ebx,%esi
	movdqa	%xmm13,32(%rsp)
	rorl	$7,%eax
	addl	%ebp,%edx
	addl	56(%rsp),%ecx
	pslld	$2,%xmm7
	xorl	%eax,%esi
	movl	%edx,%edi
	psrld	$30,%xmm12
	roll	$5,%edx
	addl	%esi,%ecx
	movups	-32(%r15),%xmm0
.byte	102,15,56,220,209
	xorl	%eax,%edi
	rorl	$7,%ebp
	por	%xmm12,%xmm7
	addl	%edx,%ecx
	addl	60(%rsp),%ebx
	xorl	%ebp,%edi
	movl	%ecx,%esi
	roll	$5,%ecx
	addl	%edi,%ebx
	xorl	%ebp,%esi
	rorl	$7,%edx
	addl	%ecx,%ebx
	addl	0(%rsp),%eax
	xorl	%edx,%esi
	movl	%ebx,%edi
	roll	$5,%ebx
	paddd	%xmm7,%xmm3
	addl	%esi,%eax
	xorl	%edx,%edi
	movdqa	%xmm3,48(%rsp)
	rorl	$7,%ecx
	addl	%ebx,%eax
	addl	4(%rsp),%ebp
	movups	-16(%r15),%xmm1
.byte	102,15,56,220,208
	xorl	%ecx,%edi
	movl	%eax,%esi
	roll	$5,%eax
	addl	%edi,%ebp
	xorl	%ecx,%esi
	rorl	$7,%ebx
	addl	%eax,%ebp
	addl	8(%rsp),%edx
	xorl	%ebx,%esi
	movl	%ebp,%edi
	roll	$5,%ebp
	addl	%esi,%edx
	xorl	%ebx,%edi
	rorl	$7,%eax
	addl	%ebp,%edx
	addl	12(%rsp),%ecx
	xorl	%eax,%edi
	movl	%edx,%esi
	roll	$5,%edx
	addl	%edi,%ecx
	movups	0(%r15),%xmm0
.byte	102,15,56,220,209
	xorl	%eax,%esi
	rorl	$7,%ebp
	addl	%edx,%ecx
	cmpq	%r14,%r10
	je	.Ldone_ssse3
	movdqa	64(%r11),%xmm3
	movdqa	0(%r11),%xmm13
	movdqu	0(%r10),%xmm4
	movdqu	16(%r10),%xmm5
	movdqu	32(%r10),%xmm6
	movdqu	48(%r10),%xmm7
.byte	102,15,56,0,227
	addq	$64,%r10
	addl	16(%rsp),%ebx
	xorl	%ebp,%esi
	movl	%ecx,%edi
.byte	102,15,56,0,235
	roll	$5,%ecx
	addl	%esi,%ebx
	xorl	%ebp,%edi
	rorl	$7,%edx
	paddd	%xmm13,%xmm4
	addl	%ecx,%ebx
	addl	20(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	movdqa	%xmm4,0(%rsp)
	roll	$5,%ebx
	addl	%edi,%eax
	xorl	%edx,%esi
	rorl	$7,%ecx
	psubd	%xmm13,%xmm4
	addl	%ebx,%eax
	addl	24(%rsp),%ebp
	movups	16(%r15),%xmm1
.byte	102,15,56,220,208
	xorl	%ecx,%esi
	movl	%eax,%edi
	roll	$5,%eax
	addl	%esi,%ebp
	xorl	%ecx,%edi
	rorl	$7,%ebx
	addl	%eax,%ebp
	addl	28(%rsp),%edx
	xorl	%ebx,%edi
	movl	%ebp,%esi
	roll	$5,%ebp
	addl	%edi,%edx
	xorl	%ebx,%esi
	rorl	$7,%eax
	addl	%ebp,%edx
	addl	32(%rsp),%ecx
	xorl	%eax,%esi
	movl	%edx,%edi
.byte	102,15,56,0,243
	roll	$5,%edx
	addl	%esi,%ecx
	movups	32(%r15),%xmm0
.byte	102,15,56,220,209
	xorl	%eax,%edi
	rorl	$7,%ebp
	paddd	%xmm13,%xmm5
	addl	%edx,%ecx
	addl	36(%rsp),%ebx
	xorl	%ebp,%edi
	movl	%ecx,%esi
	movdqa	%xmm5,16(%rsp)
	roll	$5,%ecx
	addl	%edi,%ebx
	xorl	%ebp,%esi
	rorl	$7,%edx
	psubd	%xmm13,%xmm5
	addl	%ecx,%ebx
	addl	40(%rsp),%eax
	xorl	%edx,%esi
	movl	%ebx,%edi
	roll	$5,%ebx
	addl	%esi,%eax
	xorl	%edx,%edi
	rorl	$7,%ecx
	addl	%ebx,%eax
	addl	44(%rsp),%ebp
	movups	48(%r15),%xmm1
.byte	102,15,56,220,208
	xorl	%ecx,%edi
	movl	%eax,%esi
	roll	$5,%eax
	addl	%edi,%ebp
	xorl	%ecx,%esi
	rorl	$7,%ebx
	addl	%eax,%ebp
	addl	48(%rsp),%edx
	xorl	%ebx,%esi
	movl	%ebp,%edi
.byte	102,15,56,0,251
	roll	$5,%ebp
	addl	%esi,%edx
	xorl	%ebx,%edi
	rorl	$7,%eax
	paddd	%xmm13,%xmm6
	addl	%ebp,%edx
	addl	52(%rsp),%ecx
	xorl	%eax,%edi
	movl	%edx,%esi
	movdqa	%xmm6,32(%rsp)
	roll	$5,%edx
	addl	%edi,%ecx
	cmpl	$11,%r8d
	jb	.Laesenclast4
	movups	64(%r15),%xmm0
.byte	102,15,56,220,209
	movups	80(%r15),%xmm1
.byte	102,15,56,220,208
	je	.Laesenclast4
	movups	96(%r15),%xmm0
.byte	102,15,56,220,209
	movups	112(%r15),%xmm1
.byte	102,15,56,220,208
.Laesenclast4:
.byte	102,15,56,221,209
	movups	16-112(%r15),%xmm0
	xorl	%eax,%esi
	rorl	$7,%ebp
	psubd	%xmm13,%xmm6
	addl	%edx,%ecx
	addl	56(%rsp),%ebx
	xorl	%ebp,%esi
	movl	%ecx,%edi
	roll	$5,%ecx
	addl	%esi,%ebx
	xorl	%ebp,%edi
	rorl	$7,%edx
	addl	%ecx,%ebx
	addl	60(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	roll	$5,%ebx
	addl	%edi,%eax
	rorl	$7,%ecx
	addl	%ebx,%eax
	movups	%xmm2,48(%r13,%r12,1)
	leaq	64(%r12),%r12

	addl	0(%r9),%eax
	addl	4(%r9),%esi
	addl	8(%r9),%ecx
	addl	12(%r9),%edx
	movl	%eax,0(%r9)
	addl	16(%r9),%ebp
	movl	%esi,4(%r9)
	movl	%esi,%ebx
	movl	%ecx,8(%r9)
	movl	%ecx,%edi
	movl	%edx,12(%r9)
	xorl	%edx,%edi
	movl	%ebp,16(%r9)
	andl	%edi,%esi
	jmp	.Loop_ssse3

.Ldone_ssse3:
	addl	16(%rsp),%ebx
	xorl	%ebp,%esi
	movl	%ecx,%edi
	roll	$5,%ecx
	addl	%esi,%ebx
	xorl	%ebp,%edi
	rorl	$7,%edx
	addl	%ecx,%ebx
	addl	20(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	roll	$5,%ebx
	addl	%edi,%eax
	xorl	%edx,%esi
	rorl	$7,%ecx
	addl	%ebx,%eax
	addl	24(%rsp),%ebp
	movups	16(%r15),%xmm1
.byte	102,15,56,220,208
	xorl	%ecx,%esi
	movl	%eax,%edi
	roll	$5,%eax
	addl	%esi,%ebp
	xorl	%ecx,%edi
	rorl	$7,%ebx
	addl	%eax,%ebp
	addl	28(%rsp),%edx
	xorl	%ebx,%edi
	movl	%ebp,%esi
	roll	$5,%ebp
	addl	%edi,%edx
	xorl	%ebx,%esi
	rorl	$7,%eax
	addl	%ebp,%edx
	addl	32(%rsp),%ecx
	xorl	%eax,%esi
	movl	%edx,%edi
	roll	$5,%edx
	addl	%esi,%ecx
	movups	32(%r15),%xmm0
.byte	102,15,56,220,209
	xorl	%eax,%edi
	rorl	$7,%ebp
	addl	%edx,%ecx
	addl	36(%rsp),%ebx
	xorl	%ebp,%edi
	movl	%ecx,%esi
	roll	$5,%ecx
	addl	%edi,%ebx
	xorl	%ebp,%esi
	rorl	$7,%edx
	addl	%ecx,%ebx
	addl	40(%rsp),%eax
	xorl	%edx,%esi
	movl	%ebx,%edi
	roll	$5,%ebx
	addl	%esi,%eax
	xorl	%edx,%edi
	rorl	$7,%ecx
	addl	%ebx,%eax
	addl	44(%rsp),%ebp
	movups	48(%r15),%xmm1
.byte	102,15,56,220,208
	xorl	%ecx,%edi
	movl	%eax,%esi
	roll	$5,%eax
	addl	%edi,%ebp
	xorl	%ecx,%esi
	rorl	$7,%ebx
	addl	%eax,%ebp
	addl	48(%rsp),%edx
	xorl	%ebx,%esi
	movl	%ebp,%edi
	roll	$5,%ebp
	addl	%esi,%edx
	xorl	%ebx,%edi
	rorl	$7,%eax
	addl	%ebp,%edx
	addl	52(%rsp),%ecx
	xorl	%eax,%edi
	movl	%edx,%esi
	roll	$5,%edx
	addl	%edi,%ecx
	cmpl	$11,%r8d
	jb	.Laesenclast5
	movups	64(%r15),%xmm0
.byte	102,15,56,220,209
	movups	80(%r15),%xmm1
.byte	102,15,56,220,208
	je	.Laesenclast5
	movups	96(%r15),%xmm0
.byte	102,15,56,220,209
	movups	112(%r15),%xmm1
.byte	102,15,56,220,208
.Laesenclast5:
.byte	102,15,56,221,209
	movups	16-112(%r15),%xmm0
	xorl	%eax,%esi
	rorl	$7,%ebp
	addl	%edx,%ecx
	addl	56(%rsp),%ebx
	xorl	%ebp,%esi
	movl	%ecx,%edi
	roll	$5,%ecx
	addl	%esi,%ebx
	xorl	%ebp,%edi
	rorl	$7,%edx
	addl	%ecx,%ebx
	addl	60(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	roll	$5,%ebx
	addl	%edi,%eax
	rorl	$7,%ecx
	addl	%ebx,%eax
	movups	%xmm2,48(%r13,%r12,1)
	movq	88(%rsp),%r8

	addl	0(%r9),%eax
	addl	4(%r9),%esi
	addl	8(%r9),%ecx
	movl	%eax,0(%r9)
	addl	12(%r9),%edx
	movl	%esi,4(%r9)
	addl	16(%r9),%ebp
	movl	%ecx,8(%r9)
	movl	%edx,12(%r9)
	movl	%ebp,16(%r9)
	movups	%xmm2,(%r8)
	leaq	104(%rsp),%rsi
.cfi_def_cfa	%rsi,56
	movq	0(%rsi),%r15
.cfi_restore	%r15
	movq	8(%rsi),%r14
.cfi_restore	%r14
	movq	16(%rsi),%r13
.cfi_restore	%r13
	movq	24(%rsi),%r12
.cfi_restore	%r12
	movq	32(%rsi),%rbp
.cfi_restore	%rbp
	movq	40(%rsi),%rbx
.cfi_restore	%rbx
	leaq	48(%rsi),%rsp
.cfi_def_cfa	%rsp,8
.Lepilogue_ssse3:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_cbc_sha1_enc_ssse3,.-aesni_cbc_sha1_enc_ssse3
.type	aesni_cbc_sha1_enc_avx,@function
.align	32
aesni_cbc_sha1_enc_avx:
.cfi_startproc	
	movq	8(%rsp),%r10


	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-56
	leaq	-104(%rsp),%rsp
.cfi_adjust_cfa_offset	104


	vzeroall
	movq	%rdi,%r12
	movq	%rsi,%r13
	movq	%rdx,%r14
	leaq	112(%rcx),%r15
	vmovdqu	(%r8),%xmm12
	movq	%r8,88(%rsp)
	shlq	$6,%r14
	subq	%r12,%r13
	movl	240-112(%r15),%r8d
	addq	%r10,%r14

	leaq	K_XX_XX(%rip),%r11
	movl	0(%r9),%eax
	movl	4(%r9),%ebx
	movl	8(%r9),%ecx
	movl	12(%r9),%edx
	movl	%ebx,%esi
	movl	16(%r9),%ebp
	movl	%ecx,%edi
	xorl	%edx,%edi
	andl	%edi,%esi

	vmovdqa	64(%r11),%xmm6
	vmovdqa	0(%r11),%xmm10
	vmovdqu	0(%r10),%xmm0
	vmovdqu	16(%r10),%xmm1
	vmovdqu	32(%r10),%xmm2
	vmovdqu	48(%r10),%xmm3
	vpshufb	%xmm6,%xmm0,%xmm0
	addq	$64,%r10
	vpshufb	%xmm6,%xmm1,%xmm1
	vpshufb	%xmm6,%xmm2,%xmm2
	vpshufb	%xmm6,%xmm3,%xmm3
	vpaddd	%xmm10,%xmm0,%xmm4
	vpaddd	%xmm10,%xmm1,%xmm5
	vpaddd	%xmm10,%xmm2,%xmm6
	vmovdqa	%xmm4,0(%rsp)
	vmovdqa	%xmm5,16(%rsp)
	vmovdqa	%xmm6,32(%rsp)
	vmovups	-112(%r15),%xmm15
	vmovups	16-112(%r15),%xmm14
	jmp	.Loop_avx
.align	32
.Loop_avx:
	shrdl	$2,%ebx,%ebx
	vmovdqu	0(%r12),%xmm13
	vpxor	%xmm15,%xmm13,%xmm13
	vpxor	%xmm13,%xmm12,%xmm12
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	-80(%r15),%xmm15
	xorl	%edx,%esi
	vpalignr	$8,%xmm0,%xmm1,%xmm4
	movl	%eax,%edi
	addl	0(%rsp),%ebp
	vpaddd	%xmm3,%xmm10,%xmm9
	xorl	%ecx,%ebx
	shldl	$5,%eax,%eax
	vpsrldq	$4,%xmm3,%xmm8
	addl	%esi,%ebp
	andl	%ebx,%edi
	vpxor	%xmm0,%xmm4,%xmm4
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	vpxor	%xmm2,%xmm8,%xmm8
	shrdl	$7,%eax,%eax
	xorl	%ecx,%edi
	movl	%ebp,%esi
	addl	4(%rsp),%edx
	vpxor	%xmm8,%xmm4,%xmm4
	xorl	%ebx,%eax
	shldl	$5,%ebp,%ebp
	vmovdqa	%xmm9,48(%rsp)
	addl	%edi,%edx
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	-64(%r15),%xmm14
	andl	%eax,%esi
	vpsrld	$31,%xmm4,%xmm8
	xorl	%ebx,%eax
	addl	%ebp,%edx
	shrdl	$7,%ebp,%ebp
	xorl	%ebx,%esi
	vpslldq	$12,%xmm4,%xmm9
	vpaddd	%xmm4,%xmm4,%xmm4
	movl	%edx,%edi
	addl	8(%rsp),%ecx
	xorl	%eax,%ebp
	shldl	$5,%edx,%edx
	vpor	%xmm8,%xmm4,%xmm4
	vpsrld	$30,%xmm9,%xmm8
	addl	%esi,%ecx
	andl	%ebp,%edi
	xorl	%eax,%ebp
	addl	%edx,%ecx
	vpslld	$2,%xmm9,%xmm9
	vpxor	%xmm8,%xmm4,%xmm4
	shrdl	$7,%edx,%edx
	xorl	%eax,%edi
	movl	%ecx,%esi
	addl	12(%rsp),%ebx
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	-48(%r15),%xmm15
	vpxor	%xmm9,%xmm4,%xmm4
	xorl	%ebp,%edx
	shldl	$5,%ecx,%ecx
	addl	%edi,%ebx
	andl	%edx,%esi
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	shrdl	$7,%ecx,%ecx
	xorl	%ebp,%esi
	vpalignr	$8,%xmm1,%xmm2,%xmm5
	movl	%ebx,%edi
	addl	16(%rsp),%eax
	vpaddd	%xmm4,%xmm10,%xmm9
	xorl	%edx,%ecx
	shldl	$5,%ebx,%ebx
	vpsrldq	$4,%xmm4,%xmm8
	addl	%esi,%eax
	andl	%ecx,%edi
	vpxor	%xmm1,%xmm5,%xmm5
	xorl	%edx,%ecx
	addl	%ebx,%eax
	vpxor	%xmm3,%xmm8,%xmm8
	shrdl	$7,%ebx,%ebx
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	-32(%r15),%xmm14
	xorl	%edx,%edi
	movl	%eax,%esi
	addl	20(%rsp),%ebp
	vpxor	%xmm8,%xmm5,%xmm5
	xorl	%ecx,%ebx
	shldl	$5,%eax,%eax
	vmovdqa	%xmm9,0(%rsp)
	addl	%edi,%ebp
	andl	%ebx,%esi
	vpsrld	$31,%xmm5,%xmm8
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	shrdl	$7,%eax,%eax
	xorl	%ecx,%esi
	vpslldq	$12,%xmm5,%xmm9
	vpaddd	%xmm5,%xmm5,%xmm5
	movl	%ebp,%edi
	addl	24(%rsp),%edx
	xorl	%ebx,%eax
	shldl	$5,%ebp,%ebp
	vpor	%xmm8,%xmm5,%xmm5
	vpsrld	$30,%xmm9,%xmm8
	addl	%esi,%edx
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	-16(%r15),%xmm15
	andl	%eax,%edi
	xorl	%ebx,%eax
	addl	%ebp,%edx
	vpslld	$2,%xmm9,%xmm9
	vpxor	%xmm8,%xmm5,%xmm5
	shrdl	$7,%ebp,%ebp
	xorl	%ebx,%edi
	movl	%edx,%esi
	addl	28(%rsp),%ecx
	vpxor	%xmm9,%xmm5,%xmm5
	xorl	%eax,%ebp
	shldl	$5,%edx,%edx
	vmovdqa	16(%r11),%xmm10
	addl	%edi,%ecx
	andl	%ebp,%esi
	xorl	%eax,%ebp
	addl	%edx,%ecx
	shrdl	$7,%edx,%edx
	xorl	%eax,%esi
	vpalignr	$8,%xmm2,%xmm3,%xmm6
	movl	%ecx,%edi
	addl	32(%rsp),%ebx
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	0(%r15),%xmm14
	vpaddd	%xmm5,%xmm10,%xmm9
	xorl	%ebp,%edx
	shldl	$5,%ecx,%ecx
	vpsrldq	$4,%xmm5,%xmm8
	addl	%esi,%ebx
	andl	%edx,%edi
	vpxor	%xmm2,%xmm6,%xmm6
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	vpxor	%xmm4,%xmm8,%xmm8
	shrdl	$7,%ecx,%ecx
	xorl	%ebp,%edi
	movl	%ebx,%esi
	addl	36(%rsp),%eax
	vpxor	%xmm8,%xmm6,%xmm6
	xorl	%edx,%ecx
	shldl	$5,%ebx,%ebx
	vmovdqa	%xmm9,16(%rsp)
	addl	%edi,%eax
	andl	%ecx,%esi
	vpsrld	$31,%xmm6,%xmm8
	xorl	%edx,%ecx
	addl	%ebx,%eax
	shrdl	$7,%ebx,%ebx
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	16(%r15),%xmm15
	xorl	%edx,%esi
	vpslldq	$12,%xmm6,%xmm9
	vpaddd	%xmm6,%xmm6,%xmm6
	movl	%eax,%edi
	addl	40(%rsp),%ebp
	xorl	%ecx,%ebx
	shldl	$5,%eax,%eax
	vpor	%xmm8,%xmm6,%xmm6
	vpsrld	$30,%xmm9,%xmm8
	addl	%esi,%ebp
	andl	%ebx,%edi
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	vpslld	$2,%xmm9,%xmm9
	vpxor	%xmm8,%xmm6,%xmm6
	shrdl	$7,%eax,%eax
	xorl	%ecx,%edi
	movl	%ebp,%esi
	addl	44(%rsp),%edx
	vpxor	%xmm9,%xmm6,%xmm6
	xorl	%ebx,%eax
	shldl	$5,%ebp,%ebp
	addl	%edi,%edx
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	32(%r15),%xmm14
	andl	%eax,%esi
	xorl	%ebx,%eax
	addl	%ebp,%edx
	shrdl	$7,%ebp,%ebp
	xorl	%ebx,%esi
	vpalignr	$8,%xmm3,%xmm4,%xmm7
	movl	%edx,%edi
	addl	48(%rsp),%ecx
	vpaddd	%xmm6,%xmm10,%xmm9
	xorl	%eax,%ebp
	shldl	$5,%edx,%edx
	vpsrldq	$4,%xmm6,%xmm8
	addl	%esi,%ecx
	andl	%ebp,%edi
	vpxor	%xmm3,%xmm7,%xmm7
	xorl	%eax,%ebp
	addl	%edx,%ecx
	vpxor	%xmm5,%xmm8,%xmm8
	shrdl	$7,%edx,%edx
	xorl	%eax,%edi
	movl	%ecx,%esi
	addl	52(%rsp),%ebx
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	48(%r15),%xmm15
	vpxor	%xmm8,%xmm7,%xmm7
	xorl	%ebp,%edx
	shldl	$5,%ecx,%ecx
	vmovdqa	%xmm9,32(%rsp)
	addl	%edi,%ebx
	andl	%edx,%esi
	vpsrld	$31,%xmm7,%xmm8
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	shrdl	$7,%ecx,%ecx
	xorl	%ebp,%esi
	vpslldq	$12,%xmm7,%xmm9
	vpaddd	%xmm7,%xmm7,%xmm7
	movl	%ebx,%edi
	addl	56(%rsp),%eax
	xorl	%edx,%ecx
	shldl	$5,%ebx,%ebx
	vpor	%xmm8,%xmm7,%xmm7
	vpsrld	$30,%xmm9,%xmm8
	addl	%esi,%eax
	andl	%ecx,%edi
	xorl	%edx,%ecx
	addl	%ebx,%eax
	vpslld	$2,%xmm9,%xmm9
	vpxor	%xmm8,%xmm7,%xmm7
	shrdl	$7,%ebx,%ebx
	cmpl	$11,%r8d
	jb	.Lvaesenclast6
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	64(%r15),%xmm14
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	80(%r15),%xmm15
	je	.Lvaesenclast6
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	96(%r15),%xmm14
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	112(%r15),%xmm15
.Lvaesenclast6:
	vaesenclast	%xmm15,%xmm12,%xmm12
	vmovups	-112(%r15),%xmm15
	vmovups	16-112(%r15),%xmm14
	xorl	%edx,%edi
	movl	%eax,%esi
	addl	60(%rsp),%ebp
	vpxor	%xmm9,%xmm7,%xmm7
	xorl	%ecx,%ebx
	shldl	$5,%eax,%eax
	addl	%edi,%ebp
	andl	%ebx,%esi
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	vpalignr	$8,%xmm6,%xmm7,%xmm8
	vpxor	%xmm4,%xmm0,%xmm0
	shrdl	$7,%eax,%eax
	xorl	%ecx,%esi
	movl	%ebp,%edi
	addl	0(%rsp),%edx
	vpxor	%xmm1,%xmm0,%xmm0
	xorl	%ebx,%eax
	shldl	$5,%ebp,%ebp
	vpaddd	%xmm7,%xmm10,%xmm9
	addl	%esi,%edx
	vmovdqu	16(%r12),%xmm13
	vpxor	%xmm15,%xmm13,%xmm13
	vmovups	%xmm12,0(%r12,%r13,1)
	vpxor	%xmm13,%xmm12,%xmm12
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	-80(%r15),%xmm15
	andl	%eax,%edi
	vpxor	%xmm8,%xmm0,%xmm0
	xorl	%ebx,%eax
	addl	%ebp,%edx
	shrdl	$7,%ebp,%ebp
	xorl	%ebx,%edi
	vpsrld	$30,%xmm0,%xmm8
	vmovdqa	%xmm9,48(%rsp)
	movl	%edx,%esi
	addl	4(%rsp),%ecx
	xorl	%eax,%ebp
	shldl	$5,%edx,%edx
	vpslld	$2,%xmm0,%xmm0
	addl	%edi,%ecx
	andl	%ebp,%esi
	xorl	%eax,%ebp
	addl	%edx,%ecx
	shrdl	$7,%edx,%edx
	xorl	%eax,%esi
	movl	%ecx,%edi
	addl	8(%rsp),%ebx
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	-64(%r15),%xmm14
	vpor	%xmm8,%xmm0,%xmm0
	xorl	%ebp,%edx
	shldl	$5,%ecx,%ecx
	addl	%esi,%ebx
	andl	%edx,%edi
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	addl	12(%rsp),%eax
	xorl	%ebp,%edi
	movl	%ebx,%esi
	shldl	$5,%ebx,%ebx
	addl	%edi,%eax
	xorl	%edx,%esi
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	vpalignr	$8,%xmm7,%xmm0,%xmm8
	vpxor	%xmm5,%xmm1,%xmm1
	addl	16(%rsp),%ebp
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	-48(%r15),%xmm15
	xorl	%ecx,%esi
	movl	%eax,%edi
	shldl	$5,%eax,%eax
	vpxor	%xmm2,%xmm1,%xmm1
	addl	%esi,%ebp
	xorl	%ecx,%edi
	vpaddd	%xmm0,%xmm10,%xmm9
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	vpxor	%xmm8,%xmm1,%xmm1
	addl	20(%rsp),%edx
	xorl	%ebx,%edi
	movl	%ebp,%esi
	shldl	$5,%ebp,%ebp
	vpsrld	$30,%xmm1,%xmm8
	vmovdqa	%xmm9,0(%rsp)
	addl	%edi,%edx
	xorl	%ebx,%esi
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	vpslld	$2,%xmm1,%xmm1
	addl	24(%rsp),%ecx
	xorl	%eax,%esi
	movl	%edx,%edi
	shldl	$5,%edx,%edx
	addl	%esi,%ecx
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	-32(%r15),%xmm14
	xorl	%eax,%edi
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	vpor	%xmm8,%xmm1,%xmm1
	addl	28(%rsp),%ebx
	xorl	%ebp,%edi
	movl	%ecx,%esi
	shldl	$5,%ecx,%ecx
	addl	%edi,%ebx
	xorl	%ebp,%esi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	vpalignr	$8,%xmm0,%xmm1,%xmm8
	vpxor	%xmm6,%xmm2,%xmm2
	addl	32(%rsp),%eax
	xorl	%edx,%esi
	movl	%ebx,%edi
	shldl	$5,%ebx,%ebx
	vpxor	%xmm3,%xmm2,%xmm2
	addl	%esi,%eax
	xorl	%edx,%edi
	vpaddd	%xmm1,%xmm10,%xmm9
	vmovdqa	32(%r11),%xmm10
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	vpxor	%xmm8,%xmm2,%xmm2
	addl	36(%rsp),%ebp
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	-16(%r15),%xmm15
	xorl	%ecx,%edi
	movl	%eax,%esi
	shldl	$5,%eax,%eax
	vpsrld	$30,%xmm2,%xmm8
	vmovdqa	%xmm9,16(%rsp)
	addl	%edi,%ebp
	xorl	%ecx,%esi
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	vpslld	$2,%xmm2,%xmm2
	addl	40(%rsp),%edx
	xorl	%ebx,%esi
	movl	%ebp,%edi
	shldl	$5,%ebp,%ebp
	addl	%esi,%edx
	xorl	%ebx,%edi
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	vpor	%xmm8,%xmm2,%xmm2
	addl	44(%rsp),%ecx
	xorl	%eax,%edi
	movl	%edx,%esi
	shldl	$5,%edx,%edx
	addl	%edi,%ecx
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	0(%r15),%xmm14
	xorl	%eax,%esi
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	vpalignr	$8,%xmm1,%xmm2,%xmm8
	vpxor	%xmm7,%xmm3,%xmm3
	addl	48(%rsp),%ebx
	xorl	%ebp,%esi
	movl	%ecx,%edi
	shldl	$5,%ecx,%ecx
	vpxor	%xmm4,%xmm3,%xmm3
	addl	%esi,%ebx
	xorl	%ebp,%edi
	vpaddd	%xmm2,%xmm10,%xmm9
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	vpxor	%xmm8,%xmm3,%xmm3
	addl	52(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	shldl	$5,%ebx,%ebx
	vpsrld	$30,%xmm3,%xmm8
	vmovdqa	%xmm9,32(%rsp)
	addl	%edi,%eax
	xorl	%edx,%esi
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	vpslld	$2,%xmm3,%xmm3
	addl	56(%rsp),%ebp
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	16(%r15),%xmm15
	xorl	%ecx,%esi
	movl	%eax,%edi
	shldl	$5,%eax,%eax
	addl	%esi,%ebp
	xorl	%ecx,%edi
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	vpor	%xmm8,%xmm3,%xmm3
	addl	60(%rsp),%edx
	xorl	%ebx,%edi
	movl	%ebp,%esi
	shldl	$5,%ebp,%ebp
	addl	%edi,%edx
	xorl	%ebx,%esi
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	vpalignr	$8,%xmm2,%xmm3,%xmm8
	vpxor	%xmm0,%xmm4,%xmm4
	addl	0(%rsp),%ecx
	xorl	%eax,%esi
	movl	%edx,%edi
	shldl	$5,%edx,%edx
	vpxor	%xmm5,%xmm4,%xmm4
	addl	%esi,%ecx
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	32(%r15),%xmm14
	xorl	%eax,%edi
	vpaddd	%xmm3,%xmm10,%xmm9
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	vpxor	%xmm8,%xmm4,%xmm4
	addl	4(%rsp),%ebx
	xorl	%ebp,%edi
	movl	%ecx,%esi
	shldl	$5,%ecx,%ecx
	vpsrld	$30,%xmm4,%xmm8
	vmovdqa	%xmm9,48(%rsp)
	addl	%edi,%ebx
	xorl	%ebp,%esi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	vpslld	$2,%xmm4,%xmm4
	addl	8(%rsp),%eax
	xorl	%edx,%esi
	movl	%ebx,%edi
	shldl	$5,%ebx,%ebx
	addl	%esi,%eax
	xorl	%edx,%edi
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	vpor	%xmm8,%xmm4,%xmm4
	addl	12(%rsp),%ebp
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	48(%r15),%xmm15
	xorl	%ecx,%edi
	movl	%eax,%esi
	shldl	$5,%eax,%eax
	addl	%edi,%ebp
	xorl	%ecx,%esi
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	vpalignr	$8,%xmm3,%xmm4,%xmm8
	vpxor	%xmm1,%xmm5,%xmm5
	addl	16(%rsp),%edx
	xorl	%ebx,%esi
	movl	%ebp,%edi
	shldl	$5,%ebp,%ebp
	vpxor	%xmm6,%xmm5,%xmm5
	addl	%esi,%edx
	xorl	%ebx,%edi
	vpaddd	%xmm4,%xmm10,%xmm9
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	vpxor	%xmm8,%xmm5,%xmm5
	addl	20(%rsp),%ecx
	xorl	%eax,%edi
	movl	%edx,%esi
	shldl	$5,%edx,%edx
	vpsrld	$30,%xmm5,%xmm8
	vmovdqa	%xmm9,0(%rsp)
	addl	%edi,%ecx
	cmpl	$11,%r8d
	jb	.Lvaesenclast7
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	64(%r15),%xmm14
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	80(%r15),%xmm15
	je	.Lvaesenclast7
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	96(%r15),%xmm14
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	112(%r15),%xmm15
.Lvaesenclast7:
	vaesenclast	%xmm15,%xmm12,%xmm12
	vmovups	-112(%r15),%xmm15
	vmovups	16-112(%r15),%xmm14
	xorl	%eax,%esi
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	vpslld	$2,%xmm5,%xmm5
	addl	24(%rsp),%ebx
	xorl	%ebp,%esi
	movl	%ecx,%edi
	shldl	$5,%ecx,%ecx
	addl	%esi,%ebx
	xorl	%ebp,%edi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	vpor	%xmm8,%xmm5,%xmm5
	addl	28(%rsp),%eax
	shrdl	$7,%ecx,%ecx
	movl	%ebx,%esi
	xorl	%edx,%edi
	shldl	$5,%ebx,%ebx
	addl	%edi,%eax
	xorl	%ecx,%esi
	xorl	%edx,%ecx
	addl	%ebx,%eax
	vpalignr	$8,%xmm4,%xmm5,%xmm8
	vpxor	%xmm2,%xmm6,%xmm6
	addl	32(%rsp),%ebp
	vmovdqu	32(%r12),%xmm13
	vpxor	%xmm15,%xmm13,%xmm13
	vmovups	%xmm12,16(%r13,%r12,1)
	vpxor	%xmm13,%xmm12,%xmm12
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	-80(%r15),%xmm15
	andl	%ecx,%esi
	xorl	%edx,%ecx
	shrdl	$7,%ebx,%ebx
	vpxor	%xmm7,%xmm6,%xmm6
	movl	%eax,%edi
	xorl	%ecx,%esi
	vpaddd	%xmm5,%xmm10,%xmm9
	shldl	$5,%eax,%eax
	addl	%esi,%ebp
	vpxor	%xmm8,%xmm6,%xmm6
	xorl	%ebx,%edi
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	addl	36(%rsp),%edx
	vpsrld	$30,%xmm6,%xmm8
	vmovdqa	%xmm9,16(%rsp)
	andl	%ebx,%edi
	xorl	%ecx,%ebx
	shrdl	$7,%eax,%eax
	movl	%ebp,%esi
	vpslld	$2,%xmm6,%xmm6
	xorl	%ebx,%edi
	shldl	$5,%ebp,%ebp
	addl	%edi,%edx
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	-64(%r15),%xmm14
	xorl	%eax,%esi
	xorl	%ebx,%eax
	addl	%ebp,%edx
	addl	40(%rsp),%ecx
	andl	%eax,%esi
	vpor	%xmm8,%xmm6,%xmm6
	xorl	%ebx,%eax
	shrdl	$7,%ebp,%ebp
	movl	%edx,%edi
	xorl	%eax,%esi
	shldl	$5,%edx,%edx
	addl	%esi,%ecx
	xorl	%ebp,%edi
	xorl	%eax,%ebp
	addl	%edx,%ecx
	addl	44(%rsp),%ebx
	andl	%ebp,%edi
	xorl	%eax,%ebp
	shrdl	$7,%edx,%edx
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	-48(%r15),%xmm15
	movl	%ecx,%esi
	xorl	%ebp,%edi
	shldl	$5,%ecx,%ecx
	addl	%edi,%ebx
	xorl	%edx,%esi
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	vpalignr	$8,%xmm5,%xmm6,%xmm8
	vpxor	%xmm3,%xmm7,%xmm7
	addl	48(%rsp),%eax
	andl	%edx,%esi
	xorl	%ebp,%edx
	shrdl	$7,%ecx,%ecx
	vpxor	%xmm0,%xmm7,%xmm7
	movl	%ebx,%edi
	xorl	%edx,%esi
	vpaddd	%xmm6,%xmm10,%xmm9
	vmovdqa	48(%r11),%xmm10
	shldl	$5,%ebx,%ebx
	addl	%esi,%eax
	vpxor	%xmm8,%xmm7,%xmm7
	xorl	%ecx,%edi
	xorl	%edx,%ecx
	addl	%ebx,%eax
	addl	52(%rsp),%ebp
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	-32(%r15),%xmm14
	vpsrld	$30,%xmm7,%xmm8
	vmovdqa	%xmm9,32(%rsp)
	andl	%ecx,%edi
	xorl	%edx,%ecx
	shrdl	$7,%ebx,%ebx
	movl	%eax,%esi
	vpslld	$2,%xmm7,%xmm7
	xorl	%ecx,%edi
	shldl	$5,%eax,%eax
	addl	%edi,%ebp
	xorl	%ebx,%esi
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	addl	56(%rsp),%edx
	andl	%ebx,%esi
	vpor	%xmm8,%xmm7,%xmm7
	xorl	%ecx,%ebx
	shrdl	$7,%eax,%eax
	movl	%ebp,%edi
	xorl	%ebx,%esi
	shldl	$5,%ebp,%ebp
	addl	%esi,%edx
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	-16(%r15),%xmm15
	xorl	%eax,%edi
	xorl	%ebx,%eax
	addl	%ebp,%edx
	addl	60(%rsp),%ecx
	andl	%eax,%edi
	xorl	%ebx,%eax
	shrdl	$7,%ebp,%ebp
	movl	%edx,%esi
	xorl	%eax,%edi
	shldl	$5,%edx,%edx
	addl	%edi,%ecx
	xorl	%ebp,%esi
	xorl	%eax,%ebp
	addl	%edx,%ecx
	vpalignr	$8,%xmm6,%xmm7,%xmm8
	vpxor	%xmm4,%xmm0,%xmm0
	addl	0(%rsp),%ebx
	andl	%ebp,%esi
	xorl	%eax,%ebp
	shrdl	$7,%edx,%edx
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	0(%r15),%xmm14
	vpxor	%xmm1,%xmm0,%xmm0
	movl	%ecx,%edi
	xorl	%ebp,%esi
	vpaddd	%xmm7,%xmm10,%xmm9
	shldl	$5,%ecx,%ecx
	addl	%esi,%ebx
	vpxor	%xmm8,%xmm0,%xmm0
	xorl	%edx,%edi
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	addl	4(%rsp),%eax
	vpsrld	$30,%xmm0,%xmm8
	vmovdqa	%xmm9,48(%rsp)
	andl	%edx,%edi
	xorl	%ebp,%edx
	shrdl	$7,%ecx,%ecx
	movl	%ebx,%esi
	vpslld	$2,%xmm0,%xmm0
	xorl	%edx,%edi
	shldl	$5,%ebx,%ebx
	addl	%edi,%eax
	xorl	%ecx,%esi
	xorl	%edx,%ecx
	addl	%ebx,%eax
	addl	8(%rsp),%ebp
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	16(%r15),%xmm15
	andl	%ecx,%esi
	vpor	%xmm8,%xmm0,%xmm0
	xorl	%edx,%ecx
	shrdl	$7,%ebx,%ebx
	movl	%eax,%edi
	xorl	%ecx,%esi
	shldl	$5,%eax,%eax
	addl	%esi,%ebp
	xorl	%ebx,%edi
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	addl	12(%rsp),%edx
	andl	%ebx,%edi
	xorl	%ecx,%ebx
	shrdl	$7,%eax,%eax
	movl	%ebp,%esi
	xorl	%ebx,%edi
	shldl	$5,%ebp,%ebp
	addl	%edi,%edx
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	32(%r15),%xmm14
	xorl	%eax,%esi
	xorl	%ebx,%eax
	addl	%ebp,%edx
	vpalignr	$8,%xmm7,%xmm0,%xmm8
	vpxor	%xmm5,%xmm1,%xmm1
	addl	16(%rsp),%ecx
	andl	%eax,%esi
	xorl	%ebx,%eax
	shrdl	$7,%ebp,%ebp
	vpxor	%xmm2,%xmm1,%xmm1
	movl	%edx,%edi
	xorl	%eax,%esi
	vpaddd	%xmm0,%xmm10,%xmm9
	shldl	$5,%edx,%edx
	addl	%esi,%ecx
	vpxor	%xmm8,%xmm1,%xmm1
	xorl	%ebp,%edi
	xorl	%eax,%ebp
	addl	%edx,%ecx
	addl	20(%rsp),%ebx
	vpsrld	$30,%xmm1,%xmm8
	vmovdqa	%xmm9,0(%rsp)
	andl	%ebp,%edi
	xorl	%eax,%ebp
	shrdl	$7,%edx,%edx
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	48(%r15),%xmm15
	movl	%ecx,%esi
	vpslld	$2,%xmm1,%xmm1
	xorl	%ebp,%edi
	shldl	$5,%ecx,%ecx
	addl	%edi,%ebx
	xorl	%edx,%esi
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	addl	24(%rsp),%eax
	andl	%edx,%esi
	vpor	%xmm8,%xmm1,%xmm1
	xorl	%ebp,%edx
	shrdl	$7,%ecx,%ecx
	movl	%ebx,%edi
	xorl	%edx,%esi
	shldl	$5,%ebx,%ebx
	addl	%esi,%eax
	xorl	%ecx,%edi
	xorl	%edx,%ecx
	addl	%ebx,%eax
	addl	28(%rsp),%ebp
	cmpl	$11,%r8d
	jb	.Lvaesenclast8
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	64(%r15),%xmm14
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	80(%r15),%xmm15
	je	.Lvaesenclast8
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	96(%r15),%xmm14
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	112(%r15),%xmm15
.Lvaesenclast8:
	vaesenclast	%xmm15,%xmm12,%xmm12
	vmovups	-112(%r15),%xmm15
	vmovups	16-112(%r15),%xmm14
	andl	%ecx,%edi
	xorl	%edx,%ecx
	shrdl	$7,%ebx,%ebx
	movl	%eax,%esi
	xorl	%ecx,%edi
	shldl	$5,%eax,%eax
	addl	%edi,%ebp
	xorl	%ebx,%esi
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	vpalignr	$8,%xmm0,%xmm1,%xmm8
	vpxor	%xmm6,%xmm2,%xmm2
	addl	32(%rsp),%edx
	andl	%ebx,%esi
	xorl	%ecx,%ebx
	shrdl	$7,%eax,%eax
	vpxor	%xmm3,%xmm2,%xmm2
	movl	%ebp,%edi
	xorl	%ebx,%esi
	vpaddd	%xmm1,%xmm10,%xmm9
	shldl	$5,%ebp,%ebp
	addl	%esi,%edx
	vmovdqu	48(%r12),%xmm13
	vpxor	%xmm15,%xmm13,%xmm13
	vmovups	%xmm12,32(%r13,%r12,1)
	vpxor	%xmm13,%xmm12,%xmm12
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	-80(%r15),%xmm15
	vpxor	%xmm8,%xmm2,%xmm2
	xorl	%eax,%edi
	xorl	%ebx,%eax
	addl	%ebp,%edx
	addl	36(%rsp),%ecx
	vpsrld	$30,%xmm2,%xmm8
	vmovdqa	%xmm9,16(%rsp)
	andl	%eax,%edi
	xorl	%ebx,%eax
	shrdl	$7,%ebp,%ebp
	movl	%edx,%esi
	vpslld	$2,%xmm2,%xmm2
	xorl	%eax,%edi
	shldl	$5,%edx,%edx
	addl	%edi,%ecx
	xorl	%ebp,%esi
	xorl	%eax,%ebp
	addl	%edx,%ecx
	addl	40(%rsp),%ebx
	andl	%ebp,%esi
	vpor	%xmm8,%xmm2,%xmm2
	xorl	%eax,%ebp
	shrdl	$7,%edx,%edx
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	-64(%r15),%xmm14
	movl	%ecx,%edi
	xorl	%ebp,%esi
	shldl	$5,%ecx,%ecx
	addl	%esi,%ebx
	xorl	%edx,%edi
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	addl	44(%rsp),%eax
	andl	%edx,%edi
	xorl	%ebp,%edx
	shrdl	$7,%ecx,%ecx
	movl	%ebx,%esi
	xorl	%edx,%edi
	shldl	$5,%ebx,%ebx
	addl	%edi,%eax
	xorl	%edx,%esi
	addl	%ebx,%eax
	vpalignr	$8,%xmm1,%xmm2,%xmm8
	vpxor	%xmm7,%xmm3,%xmm3
	addl	48(%rsp),%ebp
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	-48(%r15),%xmm15
	xorl	%ecx,%esi
	movl	%eax,%edi
	shldl	$5,%eax,%eax
	vpxor	%xmm4,%xmm3,%xmm3
	addl	%esi,%ebp
	xorl	%ecx,%edi
	vpaddd	%xmm2,%xmm10,%xmm9
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	vpxor	%xmm8,%xmm3,%xmm3
	addl	52(%rsp),%edx
	xorl	%ebx,%edi
	movl	%ebp,%esi
	shldl	$5,%ebp,%ebp
	vpsrld	$30,%xmm3,%xmm8
	vmovdqa	%xmm9,32(%rsp)
	addl	%edi,%edx
	xorl	%ebx,%esi
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	vpslld	$2,%xmm3,%xmm3
	addl	56(%rsp),%ecx
	xorl	%eax,%esi
	movl	%edx,%edi
	shldl	$5,%edx,%edx
	addl	%esi,%ecx
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	-32(%r15),%xmm14
	xorl	%eax,%edi
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	vpor	%xmm8,%xmm3,%xmm3
	addl	60(%rsp),%ebx
	xorl	%ebp,%edi
	movl	%ecx,%esi
	shldl	$5,%ecx,%ecx
	addl	%edi,%ebx
	xorl	%ebp,%esi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	addl	0(%rsp),%eax
	vpaddd	%xmm3,%xmm10,%xmm9
	xorl	%edx,%esi
	movl	%ebx,%edi
	shldl	$5,%ebx,%ebx
	addl	%esi,%eax
	vmovdqa	%xmm9,48(%rsp)
	xorl	%edx,%edi
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	addl	4(%rsp),%ebp
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	-16(%r15),%xmm15
	xorl	%ecx,%edi
	movl	%eax,%esi
	shldl	$5,%eax,%eax
	addl	%edi,%ebp
	xorl	%ecx,%esi
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	addl	8(%rsp),%edx
	xorl	%ebx,%esi
	movl	%ebp,%edi
	shldl	$5,%ebp,%ebp
	addl	%esi,%edx
	xorl	%ebx,%edi
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	addl	12(%rsp),%ecx
	xorl	%eax,%edi
	movl	%edx,%esi
	shldl	$5,%edx,%edx
	addl	%edi,%ecx
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	0(%r15),%xmm14
	xorl	%eax,%esi
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	cmpq	%r14,%r10
	je	.Ldone_avx
	vmovdqa	64(%r11),%xmm9
	vmovdqa	0(%r11),%xmm10
	vmovdqu	0(%r10),%xmm0
	vmovdqu	16(%r10),%xmm1
	vmovdqu	32(%r10),%xmm2
	vmovdqu	48(%r10),%xmm3
	vpshufb	%xmm9,%xmm0,%xmm0
	addq	$64,%r10
	addl	16(%rsp),%ebx
	xorl	%ebp,%esi
	vpshufb	%xmm9,%xmm1,%xmm1
	movl	%ecx,%edi
	shldl	$5,%ecx,%ecx
	vpaddd	%xmm10,%xmm0,%xmm8
	addl	%esi,%ebx
	xorl	%ebp,%edi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	vmovdqa	%xmm8,0(%rsp)
	addl	20(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	shldl	$5,%ebx,%ebx
	addl	%edi,%eax
	xorl	%edx,%esi
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	addl	24(%rsp),%ebp
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	16(%r15),%xmm15
	xorl	%ecx,%esi
	movl	%eax,%edi
	shldl	$5,%eax,%eax
	addl	%esi,%ebp
	xorl	%ecx,%edi
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	addl	28(%rsp),%edx
	xorl	%ebx,%edi
	movl	%ebp,%esi
	shldl	$5,%ebp,%ebp
	addl	%edi,%edx
	xorl	%ebx,%esi
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	addl	32(%rsp),%ecx
	xorl	%eax,%esi
	vpshufb	%xmm9,%xmm2,%xmm2
	movl	%edx,%edi
	shldl	$5,%edx,%edx
	vpaddd	%xmm10,%xmm1,%xmm8
	addl	%esi,%ecx
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	32(%r15),%xmm14
	xorl	%eax,%edi
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	vmovdqa	%xmm8,16(%rsp)
	addl	36(%rsp),%ebx
	xorl	%ebp,%edi
	movl	%ecx,%esi
	shldl	$5,%ecx,%ecx
	addl	%edi,%ebx
	xorl	%ebp,%esi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	addl	40(%rsp),%eax
	xorl	%edx,%esi
	movl	%ebx,%edi
	shldl	$5,%ebx,%ebx
	addl	%esi,%eax
	xorl	%edx,%edi
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	addl	44(%rsp),%ebp
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	48(%r15),%xmm15
	xorl	%ecx,%edi
	movl	%eax,%esi
	shldl	$5,%eax,%eax
	addl	%edi,%ebp
	xorl	%ecx,%esi
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	addl	48(%rsp),%edx
	xorl	%ebx,%esi
	vpshufb	%xmm9,%xmm3,%xmm3
	movl	%ebp,%edi
	shldl	$5,%ebp,%ebp
	vpaddd	%xmm10,%xmm2,%xmm8
	addl	%esi,%edx
	xorl	%ebx,%edi
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	vmovdqa	%xmm8,32(%rsp)
	addl	52(%rsp),%ecx
	xorl	%eax,%edi
	movl	%edx,%esi
	shldl	$5,%edx,%edx
	addl	%edi,%ecx
	cmpl	$11,%r8d
	jb	.Lvaesenclast9
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	64(%r15),%xmm14
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	80(%r15),%xmm15
	je	.Lvaesenclast9
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	96(%r15),%xmm14
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	112(%r15),%xmm15
.Lvaesenclast9:
	vaesenclast	%xmm15,%xmm12,%xmm12
	vmovups	-112(%r15),%xmm15
	vmovups	16-112(%r15),%xmm14
	xorl	%eax,%esi
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	addl	56(%rsp),%ebx
	xorl	%ebp,%esi
	movl	%ecx,%edi
	shldl	$5,%ecx,%ecx
	addl	%esi,%ebx
	xorl	%ebp,%edi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	addl	60(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	shldl	$5,%ebx,%ebx
	addl	%edi,%eax
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	vmovups	%xmm12,48(%r13,%r12,1)
	leaq	64(%r12),%r12

	addl	0(%r9),%eax
	addl	4(%r9),%esi
	addl	8(%r9),%ecx
	addl	12(%r9),%edx
	movl	%eax,0(%r9)
	addl	16(%r9),%ebp
	movl	%esi,4(%r9)
	movl	%esi,%ebx
	movl	%ecx,8(%r9)
	movl	%ecx,%edi
	movl	%edx,12(%r9)
	xorl	%edx,%edi
	movl	%ebp,16(%r9)
	andl	%edi,%esi
	jmp	.Loop_avx

.Ldone_avx:
	addl	16(%rsp),%ebx
	xorl	%ebp,%esi
	movl	%ecx,%edi
	shldl	$5,%ecx,%ecx
	addl	%esi,%ebx
	xorl	%ebp,%edi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	addl	20(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	shldl	$5,%ebx,%ebx
	addl	%edi,%eax
	xorl	%edx,%esi
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	addl	24(%rsp),%ebp
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	16(%r15),%xmm15
	xorl	%ecx,%esi
	movl	%eax,%edi
	shldl	$5,%eax,%eax
	addl	%esi,%ebp
	xorl	%ecx,%edi
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	addl	28(%rsp),%edx
	xorl	%ebx,%edi
	movl	%ebp,%esi
	shldl	$5,%ebp,%ebp
	addl	%edi,%edx
	xorl	%ebx,%esi
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	addl	32(%rsp),%ecx
	xorl	%eax,%esi
	movl	%edx,%edi
	shldl	$5,%edx,%edx
	addl	%esi,%ecx
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	32(%r15),%xmm14
	xorl	%eax,%edi
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	addl	36(%rsp),%ebx
	xorl	%ebp,%edi
	movl	%ecx,%esi
	shldl	$5,%ecx,%ecx
	addl	%edi,%ebx
	xorl	%ebp,%esi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	addl	40(%rsp),%eax
	xorl	%edx,%esi
	movl	%ebx,%edi
	shldl	$5,%ebx,%ebx
	addl	%esi,%eax
	xorl	%edx,%edi
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	addl	44(%rsp),%ebp
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	48(%r15),%xmm15
	xorl	%ecx,%edi
	movl	%eax,%esi
	shldl	$5,%eax,%eax
	addl	%edi,%ebp
	xorl	%ecx,%esi
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	addl	48(%rsp),%edx
	xorl	%ebx,%esi
	movl	%ebp,%edi
	shldl	$5,%ebp,%ebp
	addl	%esi,%edx
	xorl	%ebx,%edi
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	addl	52(%rsp),%ecx
	xorl	%eax,%edi
	movl	%edx,%esi
	shldl	$5,%edx,%edx
	addl	%edi,%ecx
	cmpl	$11,%r8d
	jb	.Lvaesenclast10
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	64(%r15),%xmm14
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	80(%r15),%xmm15
	je	.Lvaesenclast10
	vaesenc	%xmm15,%xmm12,%xmm12
	vmovups	96(%r15),%xmm14
	vaesenc	%xmm14,%xmm12,%xmm12
	vmovups	112(%r15),%xmm15
.Lvaesenclast10:
	vaesenclast	%xmm15,%xmm12,%xmm12
	vmovups	-112(%r15),%xmm15
	vmovups	16-112(%r15),%xmm14
	xorl	%eax,%esi
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	addl	56(%rsp),%ebx
	xorl	%ebp,%esi
	movl	%ecx,%edi
	shldl	$5,%ecx,%ecx
	addl	%esi,%ebx
	xorl	%ebp,%edi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	addl	60(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	shldl	$5,%ebx,%ebx
	addl	%edi,%eax
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	vmovups	%xmm12,48(%r13,%r12,1)
	movq	88(%rsp),%r8

	addl	0(%r9),%eax
	addl	4(%r9),%esi
	addl	8(%r9),%ecx
	movl	%eax,0(%r9)
	addl	12(%r9),%edx
	movl	%esi,4(%r9)
	addl	16(%r9),%ebp
	movl	%ecx,8(%r9)
	movl	%edx,12(%r9)
	movl	%ebp,16(%r9)
	vmovups	%xmm12,(%r8)
	vzeroall
	leaq	104(%rsp),%rsi
.cfi_def_cfa	%rsi,56
	movq	0(%rsi),%r15
.cfi_restore	%r15
	movq	8(%rsi),%r14
.cfi_restore	%r14
	movq	16(%rsi),%r13
.cfi_restore	%r13
	movq	24(%rsi),%r12
.cfi_restore	%r12
	movq	32(%rsi),%rbp
.cfi_restore	%rbp
	movq	40(%rsi),%rbx
.cfi_restore	%rbx
	leaq	48(%rsi),%rsp
.cfi_def_cfa	%rsp,8
.Lepilogue_avx:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_cbc_sha1_enc_avx,.-aesni_cbc_sha1_enc_avx
.align	64
K_XX_XX:
.long	0x5a827999,0x5a827999,0x5a827999,0x5a827999
.long	0x6ed9eba1,0x6ed9eba1,0x6ed9eba1,0x6ed9eba1
.long	0x8f1bbcdc,0x8f1bbcdc,0x8f1bbcdc,0x8f1bbcdc
.long	0xca62c1d6,0xca62c1d6,0xca62c1d6,0xca62c1d6
.long	0x00010203,0x04050607,0x08090a0b,0x0c0d0e0f
.byte	0xf,0xe,0xd,0xc,0xb,0xa,0x9,0x8,0x7,0x6,0x5,0x4,0x3,0x2,0x1,0x0

.byte	65,69,83,78,73,45,67,66,67,43,83,72,65,49,32,115,116,105,116,99,104,32,102,111,114,32,120,56,54,95,54,52,44,32,67,82,89,80,84,79,71,65,77,83,32,98,121,32,60,97,112,112,114,111,64,111,112,101,110,115,115,108,46,111,114,103,62,0
.align	64
.type	aesni_cbc_sha1_enc_shaext,@function
.align	32
aesni_cbc_sha1_enc_shaext:
.cfi_startproc	
	movq	8(%rsp),%r10
	movdqu	(%r9),%xmm8
	movd	16(%r9),%xmm9
	movdqa	K_XX_XX+80(%rip),%xmm7

	movl	240(%rcx),%r11d
	subq	%rdi,%rsi
	movups	(%rcx),%xmm15
	movups	(%r8),%xmm2
	movups	16(%rcx),%xmm0
	leaq	112(%rcx),%rcx

	pshufd	$27,%xmm8,%xmm8
	pshufd	$27,%xmm9,%xmm9
	jmp	.Loop_shaext

.align	16
.Loop_shaext:
	movups	0(%rdi),%xmm14
	xorps	%xmm15,%xmm14
	xorps	%xmm14,%xmm2
	movups	-80(%rcx),%xmm1
.byte	102,15,56,220,208
	movdqu	(%r10),%xmm3
	movdqa	%xmm9,%xmm12
.byte	102,15,56,0,223
	movdqu	16(%r10),%xmm4
	movdqa	%xmm8,%xmm11
	movups	-64(%rcx),%xmm0
.byte	102,15,56,220,209
.byte	102,15,56,0,231

	paddd	%xmm3,%xmm9
	movdqu	32(%r10),%xmm5
	leaq	64(%r10),%r10
	pxor	%xmm12,%xmm3
	movups	-48(%rcx),%xmm1
.byte	102,15,56,220,208
	pxor	%xmm12,%xmm3
	movdqa	%xmm8,%xmm10
.byte	102,15,56,0,239
.byte	69,15,58,204,193,0
.byte	68,15,56,200,212
	movups	-32(%rcx),%xmm0
.byte	102,15,56,220,209
.byte	15,56,201,220
	movdqu	-16(%r10),%xmm6
	movdqa	%xmm8,%xmm9
.byte	102,15,56,0,247
	movups	-16(%rcx),%xmm1
.byte	102,15,56,220,208
.byte	69,15,58,204,194,0
.byte	68,15,56,200,205
	pxor	%xmm5,%xmm3
.byte	15,56,201,229
	movups	0(%rcx),%xmm0
.byte	102,15,56,220,209
	movdqa	%xmm8,%xmm10
.byte	69,15,58,204,193,0
.byte	68,15,56,200,214
	movups	16(%rcx),%xmm1
.byte	102,15,56,220,208
.byte	15,56,202,222
	pxor	%xmm6,%xmm4
.byte	15,56,201,238
	movups	32(%rcx),%xmm0
.byte	102,15,56,220,209
	movdqa	%xmm8,%xmm9
.byte	69,15,58,204,194,0
.byte	68,15,56,200,203
	movups	48(%rcx),%xmm1
.byte	102,15,56,220,208
.byte	15,56,202,227
	pxor	%xmm3,%xmm5
.byte	15,56,201,243
	cmpl	$11,%r11d
	jb	.Laesenclast11
	movups	64(%rcx),%xmm0
.byte	102,15,56,220,209
	movups	80(%rcx),%xmm1
.byte	102,15,56,220,208
	je	.Laesenclast11
	movups	96(%rcx),%xmm0
.byte	102,15,56,220,209
	movups	112(%rcx),%xmm1
.byte	102,15,56,220,208
.Laesenclast11:
.byte	102,15,56,221,209
	movups	16-112(%rcx),%xmm0
	movdqa	%xmm8,%xmm10
.byte	69,15,58,204,193,0
.byte	68,15,56,200,212
	movups	16(%rdi),%xmm14
	xorps	%xmm15,%xmm14
	movups	%xmm2,0(%rsi,%rdi,1)
	xorps	%xmm14,%xmm2
	movups	-80(%rcx),%xmm1
.byte	102,15,56,220,208
.byte	15,56,202,236
	pxor	%xmm4,%xmm6
.byte	15,56,201,220
	movups	-64(%rcx),%xmm0
.byte	102,15,56,220,209
	movdqa	%xmm8,%xmm9
.byte	69,15,58,204,194,1
.byte	68,15,56,200,205
	movups	-48(%rcx),%xmm1
.byte	102,15,56,220,208
.byte	15,56,202,245
	pxor	%xmm5,%xmm3
.byte	15,56,201,229
	movups	-32(%rcx),%xmm0
.byte	102,15,56,220,209
	movdqa	%xmm8,%xmm10
.byte	69,15,58,204,193,1
.byte	68,15,56,200,214
	movups	-16(%rcx),%xmm1
.byte	102,15,56,220,208
.byte	15,56,202,222
	pxor	%xmm6,%xmm4
.byte	15,56,201,238
	movups	0(%rcx),%xmm0
.byte	102,15,56,220,209
	movdqa	%xmm8,%xmm9
.byte	69,15,58,204,194,1
.byte	68,15,56,200,203
	movups	16(%rcx),%xmm1
.byte	102,15,56,220,208
.byte	15,56,202,227
	pxor	%xmm3,%xmm5
.byte	15,56,201,243
	movups	32(%rcx),%xmm0
.byte	102,15,56,220,209
	movdqa	%xmm8,%xmm10
.byte	69,15,58,204,193,1
.byte	68,15,56,200,212
	movups	48(%rcx),%xmm1
.byte	102,15,56,220,208
.byte	15,56,202,236
	pxor	%xmm4,%xmm6
.byte	15,56,201,220
	cmpl	$11,%r11d
	jb	.Laesenclast12
	movups	64(%rcx),%xmm0
.byte	102,15,56,220,209
	movups	80(%rcx),%xmm1
.byte	102,15,56,220,208
	je	.Laesenclast12
	movups	96(%rcx),%xmm0
.byte	102,15,56,220,209
	movups	112(%rcx),%xmm1
.byte	102,15,56,220,208
.Laesenclast12:
.byte	102,15,56,221,209
	movups	16-112(%rcx),%xmm0
	movdqa	%xmm8,%xmm9
.byte	69,15,58,204,194,1
.byte	68,15,56,200,205
	movups	32(%rdi),%xmm14
	xorps	%xmm15,%xmm14
	movups	%xmm2,16(%rsi,%rdi,1)
	xorps	%xmm14,%xmm2
	movups	-80(%rcx),%xmm1
.byte	102,15,56,220,208
.byte	15,56,202,245
	pxor	%xmm5,%xmm3
.byte	15,56,201,229
	movups	-64(%rcx),%xmm0
.byte	102,15,56,220,209
	movdqa	%xmm8,%xmm10
.byte	69,15,58,204,193,2
.byte	68,15,56,200,214
	movups	-48(%rcx),%xmm1
.byte	102,15,56,220,208
.byte	15,56,202,222
	pxor	%xmm6,%xmm4
.byte	15,56,201,238
	movups	-32(%rcx),%xmm0
.byte	102,15,56,220,209
	movdqa	%xmm8,%xmm9
.byte	69,15,58,204,194,2
.byte	68,15,56,200,203
	movups	-16(%rcx),%xmm1
.byte	102,15,56,220,208
.byte	15,56,202,227
	pxor	%xmm3,%xmm5
.byte	15,56,201,243
	movups	0(%rcx),%xmm0
.byte	102,15,56,220,209
	movdqa	%xmm8,%xmm10
.byte	69,15,58,204,193,2
.byte	68,15,56,200,212
	movups	16(%rcx),%xmm1
.byte	102,15,56,220,208
.byte	15,56,202,236
	pxor	%xmm4,%xmm6
.byte	15,56,201,220
	movups	32(%rcx),%xmm0
.byte	102,15,56,220,209
	movdqa	%xmm8,%xmm9
.byte	69,15,58,204,194,2
.byte	68,15,56,200,205
	movups	48(%rcx),%xmm1
.byte	102,15,56,220,208
.byte	15,56,202,245
	pxor	%xmm5,%xmm3
.byte	15,56,201,229
	cmpl	$11,%r11d
	jb	.Laesenclast13
	movups	64(%rcx),%xmm0
.byte	102,15,56,220,209
	movups	80(%rcx),%xmm1
.byte	102,15,56,220,208
	je	.Laesenclast13
	movups	96(%rcx),%xmm0
.byte	102,15,56,220,209
	movups	112(%rcx),%xmm1
.byte	102,15,56,220,208
.Laesenclast13:
.byte	102,15,56,221,209
	movups	16-112(%rcx),%xmm0
	movdqa	%xmm8,%xmm10
.byte	69,15,58,204,193,2
.byte	68,15,56,200,214
	movups	48(%rdi),%xmm14
	xorps	%xmm15,%xmm14
	movups	%xmm2,32(%rsi,%rdi,1)
	xorps	%xmm14,%xmm2
	movups	-80(%rcx),%xmm1
.byte	102,15,56,220,208
.byte	15,56,202,222
	pxor	%xmm6,%xmm4
.byte	15,56,201,238
	movups	-64(%rcx),%xmm0
.byte	102,15,56,220,209
	movdqa	%xmm8,%xmm9
.byte	69,15,58,204,194,3
.byte	68,15,56,200,203
	movups	-48(%rcx),%xmm1
.byte	102,15,56,220,208
.byte	15,56,202,227
	pxor	%xmm3,%xmm5
.byte	15,56,201,243
	movups	-32(%rcx),%xmm0
.byte	102,15,56,220,209
	movdqa	%xmm8,%xmm10
.byte	69,15,58,204,193,3
.byte	68,15,56,200,212
.byte	15,56,202,236
	pxor	%xmm4,%xmm6
	movups	-16(%rcx),%xmm1
.byte	102,15,56,220,208
	movdqa	%xmm8,%xmm9
.byte	69,15,58,204,194,3
.byte	68,15,56,200,205
.byte	15,56,202,245
	movups	0(%rcx),%xmm0
.byte	102,15,56,220,209
	movdqa	%xmm12,%xmm5
	movdqa	%xmm8,%xmm10
.byte	69,15,58,204,193,3
.byte	68,15,56,200,214
	movups	16(%rcx),%xmm1
.byte	102,15,56,220,208
	movdqa	%xmm8,%xmm9
.byte	69,15,58,204,194,3
.byte	68,15,56,200,205
	movups	32(%rcx),%xmm0
.byte	102,15,56,220,209
	movups	48(%rcx),%xmm1
.byte	102,15,56,220,208
	cmpl	$11,%r11d
	jb	.Laesenclast14
	movups	64(%rcx),%xmm0
.byte	102,15,56,220,209
	movups	80(%rcx),%xmm1
.byte	102,15,56,220,208
	je	.Laesenclast14
	movups	96(%rcx),%xmm0
.byte	102,15,56,220,209
	movups	112(%rcx),%xmm1
.byte	102,15,56,220,208
.Laesenclast14:
.byte	102,15,56,221,209
	movups	16-112(%rcx),%xmm0
	decq	%rdx

	paddd	%xmm11,%xmm8
	movups	%xmm2,48(%rsi,%rdi,1)
	leaq	64(%rdi),%rdi
	jnz	.Loop_shaext

	pshufd	$27,%xmm8,%xmm8
	pshufd	$27,%xmm9,%xmm9
	movups	%xmm2,(%r8)
	movdqu	%xmm8,(%r9)
	movd	%xmm9,16(%r9)
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_cbc_sha1_enc_shaext,.-aesni_cbc_sha1_enc_shaext
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                                                                                                                                                          node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/aes/aesni-sha256-x86_64.s             0000664 0000000 0000000 00000262432 14746647661 0027741 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	


.globl	aesni_cbc_sha256_enc
.type	aesni_cbc_sha256_enc,@function
.align	16
aesni_cbc_sha256_enc:
.cfi_startproc	
	leaq	OPENSSL_ia32cap_P(%rip),%r11
	movl	$1,%eax
	cmpq	$0,%rdi
	je	.Lprobe
	movl	0(%r11),%eax
	movq	4(%r11),%r10
	btq	$61,%r10
	jc	aesni_cbc_sha256_enc_shaext
	movq	%r10,%r11
	shrq	$32,%r11

	testl	$2048,%r10d
	jnz	aesni_cbc_sha256_enc_xop
	andl	$296,%r11d
	cmpl	$296,%r11d
	je	aesni_cbc_sha256_enc_avx2
	andl	$268435456,%r10d
	jnz	aesni_cbc_sha256_enc_avx
	ud2
	xorl	%eax,%eax
	cmpq	$0,%rdi
	je	.Lprobe
	ud2
.Lprobe:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_cbc_sha256_enc,.-aesni_cbc_sha256_enc

.align	64
.type	K256,@object
K256:
.long	0x428a2f98,0x71374491,0xb5c0fbcf,0xe9b5dba5
.long	0x428a2f98,0x71374491,0xb5c0fbcf,0xe9b5dba5
.long	0x3956c25b,0x59f111f1,0x923f82a4,0xab1c5ed5
.long	0x3956c25b,0x59f111f1,0x923f82a4,0xab1c5ed5
.long	0xd807aa98,0x12835b01,0x243185be,0x550c7dc3
.long	0xd807aa98,0x12835b01,0x243185be,0x550c7dc3
.long	0x72be5d74,0x80deb1fe,0x9bdc06a7,0xc19bf174
.long	0x72be5d74,0x80deb1fe,0x9bdc06a7,0xc19bf174
.long	0xe49b69c1,0xefbe4786,0x0fc19dc6,0x240ca1cc
.long	0xe49b69c1,0xefbe4786,0x0fc19dc6,0x240ca1cc
.long	0x2de92c6f,0x4a7484aa,0x5cb0a9dc,0x76f988da
.long	0x2de92c6f,0x4a7484aa,0x5cb0a9dc,0x76f988da
.long	0x983e5152,0xa831c66d,0xb00327c8,0xbf597fc7
.long	0x983e5152,0xa831c66d,0xb00327c8,0xbf597fc7
.long	0xc6e00bf3,0xd5a79147,0x06ca6351,0x14292967
.long	0xc6e00bf3,0xd5a79147,0x06ca6351,0x14292967
.long	0x27b70a85,0x2e1b2138,0x4d2c6dfc,0x53380d13
.long	0x27b70a85,0x2e1b2138,0x4d2c6dfc,0x53380d13
.long	0x650a7354,0x766a0abb,0x81c2c92e,0x92722c85
.long	0x650a7354,0x766a0abb,0x81c2c92e,0x92722c85
.long	0xa2bfe8a1,0xa81a664b,0xc24b8b70,0xc76c51a3
.long	0xa2bfe8a1,0xa81a664b,0xc24b8b70,0xc76c51a3
.long	0xd192e819,0xd6990624,0xf40e3585,0x106aa070
.long	0xd192e819,0xd6990624,0xf40e3585,0x106aa070
.long	0x19a4c116,0x1e376c08,0x2748774c,0x34b0bcb5
.long	0x19a4c116,0x1e376c08,0x2748774c,0x34b0bcb5
.long	0x391c0cb3,0x4ed8aa4a,0x5b9cca4f,0x682e6ff3
.long	0x391c0cb3,0x4ed8aa4a,0x5b9cca4f,0x682e6ff3
.long	0x748f82ee,0x78a5636f,0x84c87814,0x8cc70208
.long	0x748f82ee,0x78a5636f,0x84c87814,0x8cc70208
.long	0x90befffa,0xa4506ceb,0xbef9a3f7,0xc67178f2
.long	0x90befffa,0xa4506ceb,0xbef9a3f7,0xc67178f2

.long	0x00010203,0x04050607,0x08090a0b,0x0c0d0e0f
.long	0x00010203,0x04050607,0x08090a0b,0x0c0d0e0f
.long	0,0,0,0,   0,0,0,0,   -1,-1,-1,-1
.long	0,0,0,0,   0,0,0,0
.byte	65,69,83,78,73,45,67,66,67,43,83,72,65,50,53,54,32,115,116,105,116,99,104,32,102,111,114,32,120,56,54,95,54,52,44,32,67,82,89,80,84,79,71,65,77,83,32,98,121,32,60,97,112,112,114,111,64,111,112,101,110,115,115,108,46,111,114,103,62,0
.align	64
.type	aesni_cbc_sha256_enc_xop,@function
.align	64
aesni_cbc_sha256_enc_xop:
.cfi_startproc	
.Lxop_shortcut:
	movq	8(%rsp),%r10
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
	subq	$128,%rsp
	andq	$-64,%rsp

	shlq	$6,%rdx
	subq	%rdi,%rsi
	subq	%rdi,%r10
	addq	%rdi,%rdx


	movq	%rsi,64+8(%rsp)
	movq	%rdx,64+16(%rsp)

	movq	%r8,64+32(%rsp)
	movq	%r9,64+40(%rsp)
	movq	%r10,64+48(%rsp)
	movq	%rax,120(%rsp)
.cfi_escape	0x0f,0x06,0x77,0xf8,0x00,0x06,0x23,0x08
.Lprologue_xop:
	vzeroall

	movq	%rdi,%r12
	leaq	128(%rcx),%rdi
	leaq	K256+544(%rip),%r13
	movl	240-128(%rdi),%r14d
	movq	%r9,%r15
	movq	%r10,%rsi
	vmovdqu	(%r8),%xmm8
	subq	$9,%r14

	movl	0(%r15),%eax
	movl	4(%r15),%ebx
	movl	8(%r15),%ecx
	movl	12(%r15),%edx
	movl	16(%r15),%r8d
	movl	20(%r15),%r9d
	movl	24(%r15),%r10d
	movl	28(%r15),%r11d

	vmovdqa	0(%r13,%r14,8),%xmm14
	vmovdqa	16(%r13,%r14,8),%xmm13
	vmovdqa	32(%r13,%r14,8),%xmm12
	vmovdqu	0-128(%rdi),%xmm10
	jmp	.Lloop_xop
.align	16
.Lloop_xop:
	vmovdqa	K256+512(%rip),%xmm7
	vmovdqu	0(%rsi,%r12,1),%xmm0
	vmovdqu	16(%rsi,%r12,1),%xmm1
	vmovdqu	32(%rsi,%r12,1),%xmm2
	vmovdqu	48(%rsi,%r12,1),%xmm3
	vpshufb	%xmm7,%xmm0,%xmm0
	leaq	K256(%rip),%rbp
	vpshufb	%xmm7,%xmm1,%xmm1
	vpshufb	%xmm7,%xmm2,%xmm2
	vpaddd	0(%rbp),%xmm0,%xmm4
	vpshufb	%xmm7,%xmm3,%xmm3
	vpaddd	32(%rbp),%xmm1,%xmm5
	vpaddd	64(%rbp),%xmm2,%xmm6
	vpaddd	96(%rbp),%xmm3,%xmm7
	vmovdqa	%xmm4,0(%rsp)
	movl	%eax,%r14d
	vmovdqa	%xmm5,16(%rsp)
	movl	%ebx,%esi
	vmovdqa	%xmm6,32(%rsp)
	xorl	%ecx,%esi
	vmovdqa	%xmm7,48(%rsp)
	movl	%r8d,%r13d
	jmp	.Lxop_00_47

.align	16
.Lxop_00_47:
	subq	$-32*4,%rbp
	vmovdqu	(%r12),%xmm9
	movq	%r12,64+0(%rsp)
	vpalignr	$4,%xmm0,%xmm1,%xmm4
	rorl	$14,%r13d
	movl	%r14d,%eax
	vpalignr	$4,%xmm2,%xmm3,%xmm7
	movl	%r9d,%r12d
	xorl	%r8d,%r13d
.byte	143,232,120,194,236,14
	rorl	$9,%r14d
	xorl	%r10d,%r12d
	vpsrld	$3,%xmm4,%xmm4
	rorl	$5,%r13d
	xorl	%eax,%r14d
	vpaddd	%xmm7,%xmm0,%xmm0
	andl	%r8d,%r12d
	vpxor	%xmm10,%xmm9,%xmm9
	vmovdqu	16-128(%rdi),%xmm10
	xorl	%r8d,%r13d
	addl	0(%rsp),%r11d
	movl	%eax,%r15d
.byte	143,232,120,194,245,11
	rorl	$11,%r14d
	xorl	%r10d,%r12d
	vpxor	%xmm5,%xmm4,%xmm4
	xorl	%ebx,%r15d
	rorl	$6,%r13d
	addl	%r12d,%r11d
	andl	%r15d,%esi
.byte	143,232,120,194,251,13
	xorl	%eax,%r14d
	addl	%r13d,%r11d
	vpxor	%xmm6,%xmm4,%xmm4
	xorl	%ebx,%esi
	addl	%r11d,%edx
	vpsrld	$10,%xmm3,%xmm6
	rorl	$2,%r14d
	addl	%esi,%r11d
	vpaddd	%xmm4,%xmm0,%xmm0
	movl	%edx,%r13d
	addl	%r11d,%r14d
.byte	143,232,120,194,239,2
	rorl	$14,%r13d
	movl	%r14d,%r11d
	vpxor	%xmm6,%xmm7,%xmm7
	movl	%r8d,%r12d
	xorl	%edx,%r13d
	rorl	$9,%r14d
	xorl	%r9d,%r12d
	vpxor	%xmm5,%xmm7,%xmm7
	rorl	$5,%r13d
	xorl	%r11d,%r14d
	andl	%edx,%r12d
	vpxor	%xmm8,%xmm9,%xmm9
	xorl	%edx,%r13d
	vpsrldq	$8,%xmm7,%xmm7
	addl	4(%rsp),%r10d
	movl	%r11d,%esi
	rorl	$11,%r14d
	xorl	%r9d,%r12d
	vpaddd	%xmm7,%xmm0,%xmm0
	xorl	%eax,%esi
	rorl	$6,%r13d
	addl	%r12d,%r10d
	andl	%esi,%r15d
.byte	143,232,120,194,248,13
	xorl	%r11d,%r14d
	addl	%r13d,%r10d
	vpsrld	$10,%xmm0,%xmm6
	xorl	%eax,%r15d
	addl	%r10d,%ecx
.byte	143,232,120,194,239,2
	rorl	$2,%r14d
	addl	%r15d,%r10d
	vpxor	%xmm6,%xmm7,%xmm7
	movl	%ecx,%r13d
	addl	%r10d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r10d
	vpxor	%xmm5,%xmm7,%xmm7
	movl	%edx,%r12d
	xorl	%ecx,%r13d
	rorl	$9,%r14d
	xorl	%r8d,%r12d
	vpslldq	$8,%xmm7,%xmm7
	rorl	$5,%r13d
	xorl	%r10d,%r14d
	andl	%ecx,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	32-128(%rdi),%xmm10
	xorl	%ecx,%r13d
	vpaddd	%xmm7,%xmm0,%xmm0
	addl	8(%rsp),%r9d
	movl	%r10d,%r15d
	rorl	$11,%r14d
	xorl	%r8d,%r12d
	vpaddd	0(%rbp),%xmm0,%xmm6
	xorl	%r11d,%r15d
	rorl	$6,%r13d
	addl	%r12d,%r9d
	andl	%r15d,%esi
	xorl	%r10d,%r14d
	addl	%r13d,%r9d
	xorl	%r11d,%esi
	addl	%r9d,%ebx
	rorl	$2,%r14d
	addl	%esi,%r9d
	movl	%ebx,%r13d
	addl	%r9d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r9d
	movl	%ecx,%r12d
	xorl	%ebx,%r13d
	rorl	$9,%r14d
	xorl	%edx,%r12d
	rorl	$5,%r13d
	xorl	%r9d,%r14d
	andl	%ebx,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	48-128(%rdi),%xmm10
	xorl	%ebx,%r13d
	addl	12(%rsp),%r8d
	movl	%r9d,%esi
	rorl	$11,%r14d
	xorl	%edx,%r12d
	xorl	%r10d,%esi
	rorl	$6,%r13d
	addl	%r12d,%r8d
	andl	%esi,%r15d
	xorl	%r9d,%r14d
	addl	%r13d,%r8d
	xorl	%r10d,%r15d
	addl	%r8d,%eax
	rorl	$2,%r14d
	addl	%r15d,%r8d
	movl	%eax,%r13d
	addl	%r8d,%r14d
	vmovdqa	%xmm6,0(%rsp)
	vpalignr	$4,%xmm1,%xmm2,%xmm4
	rorl	$14,%r13d
	movl	%r14d,%r8d
	vpalignr	$4,%xmm3,%xmm0,%xmm7
	movl	%ebx,%r12d
	xorl	%eax,%r13d
.byte	143,232,120,194,236,14
	rorl	$9,%r14d
	xorl	%ecx,%r12d
	vpsrld	$3,%xmm4,%xmm4
	rorl	$5,%r13d
	xorl	%r8d,%r14d
	vpaddd	%xmm7,%xmm1,%xmm1
	andl	%eax,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	64-128(%rdi),%xmm10
	xorl	%eax,%r13d
	addl	16(%rsp),%edx
	movl	%r8d,%r15d
.byte	143,232,120,194,245,11
	rorl	$11,%r14d
	xorl	%ecx,%r12d
	vpxor	%xmm5,%xmm4,%xmm4
	xorl	%r9d,%r15d
	rorl	$6,%r13d
	addl	%r12d,%edx
	andl	%r15d,%esi
.byte	143,232,120,194,248,13
	xorl	%r8d,%r14d
	addl	%r13d,%edx
	vpxor	%xmm6,%xmm4,%xmm4
	xorl	%r9d,%esi
	addl	%edx,%r11d
	vpsrld	$10,%xmm0,%xmm6
	rorl	$2,%r14d
	addl	%esi,%edx
	vpaddd	%xmm4,%xmm1,%xmm1
	movl	%r11d,%r13d
	addl	%edx,%r14d
.byte	143,232,120,194,239,2
	rorl	$14,%r13d
	movl	%r14d,%edx
	vpxor	%xmm6,%xmm7,%xmm7
	movl	%eax,%r12d
	xorl	%r11d,%r13d
	rorl	$9,%r14d
	xorl	%ebx,%r12d
	vpxor	%xmm5,%xmm7,%xmm7
	rorl	$5,%r13d
	xorl	%edx,%r14d
	andl	%r11d,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	80-128(%rdi),%xmm10
	xorl	%r11d,%r13d
	vpsrldq	$8,%xmm7,%xmm7
	addl	20(%rsp),%ecx
	movl	%edx,%esi
	rorl	$11,%r14d
	xorl	%ebx,%r12d
	vpaddd	%xmm7,%xmm1,%xmm1
	xorl	%r8d,%esi
	rorl	$6,%r13d
	addl	%r12d,%ecx
	andl	%esi,%r15d
.byte	143,232,120,194,249,13
	xorl	%edx,%r14d
	addl	%r13d,%ecx
	vpsrld	$10,%xmm1,%xmm6
	xorl	%r8d,%r15d
	addl	%ecx,%r10d
.byte	143,232,120,194,239,2
	rorl	$2,%r14d
	addl	%r15d,%ecx
	vpxor	%xmm6,%xmm7,%xmm7
	movl	%r10d,%r13d
	addl	%ecx,%r14d
	rorl	$14,%r13d
	movl	%r14d,%ecx
	vpxor	%xmm5,%xmm7,%xmm7
	movl	%r11d,%r12d
	xorl	%r10d,%r13d
	rorl	$9,%r14d
	xorl	%eax,%r12d
	vpslldq	$8,%xmm7,%xmm7
	rorl	$5,%r13d
	xorl	%ecx,%r14d
	andl	%r10d,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	96-128(%rdi),%xmm10
	xorl	%r10d,%r13d
	vpaddd	%xmm7,%xmm1,%xmm1
	addl	24(%rsp),%ebx
	movl	%ecx,%r15d
	rorl	$11,%r14d
	xorl	%eax,%r12d
	vpaddd	32(%rbp),%xmm1,%xmm6
	xorl	%edx,%r15d
	rorl	$6,%r13d
	addl	%r12d,%ebx
	andl	%r15d,%esi
	xorl	%ecx,%r14d
	addl	%r13d,%ebx
	xorl	%edx,%esi
	addl	%ebx,%r9d
	rorl	$2,%r14d
	addl	%esi,%ebx
	movl	%r9d,%r13d
	addl	%ebx,%r14d
	rorl	$14,%r13d
	movl	%r14d,%ebx
	movl	%r10d,%r12d
	xorl	%r9d,%r13d
	rorl	$9,%r14d
	xorl	%r11d,%r12d
	rorl	$5,%r13d
	xorl	%ebx,%r14d
	andl	%r9d,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	112-128(%rdi),%xmm10
	xorl	%r9d,%r13d
	addl	28(%rsp),%eax
	movl	%ebx,%esi
	rorl	$11,%r14d
	xorl	%r11d,%r12d
	xorl	%ecx,%esi
	rorl	$6,%r13d
	addl	%r12d,%eax
	andl	%esi,%r15d
	xorl	%ebx,%r14d
	addl	%r13d,%eax
	xorl	%ecx,%r15d
	addl	%eax,%r8d
	rorl	$2,%r14d
	addl	%r15d,%eax
	movl	%r8d,%r13d
	addl	%eax,%r14d
	vmovdqa	%xmm6,16(%rsp)
	vpalignr	$4,%xmm2,%xmm3,%xmm4
	rorl	$14,%r13d
	movl	%r14d,%eax
	vpalignr	$4,%xmm0,%xmm1,%xmm7
	movl	%r9d,%r12d
	xorl	%r8d,%r13d
.byte	143,232,120,194,236,14
	rorl	$9,%r14d
	xorl	%r10d,%r12d
	vpsrld	$3,%xmm4,%xmm4
	rorl	$5,%r13d
	xorl	%eax,%r14d
	vpaddd	%xmm7,%xmm2,%xmm2
	andl	%r8d,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	128-128(%rdi),%xmm10
	xorl	%r8d,%r13d
	addl	32(%rsp),%r11d
	movl	%eax,%r15d
.byte	143,232,120,194,245,11
	rorl	$11,%r14d
	xorl	%r10d,%r12d
	vpxor	%xmm5,%xmm4,%xmm4
	xorl	%ebx,%r15d
	rorl	$6,%r13d
	addl	%r12d,%r11d
	andl	%r15d,%esi
.byte	143,232,120,194,249,13
	xorl	%eax,%r14d
	addl	%r13d,%r11d
	vpxor	%xmm6,%xmm4,%xmm4
	xorl	%ebx,%esi
	addl	%r11d,%edx
	vpsrld	$10,%xmm1,%xmm6
	rorl	$2,%r14d
	addl	%esi,%r11d
	vpaddd	%xmm4,%xmm2,%xmm2
	movl	%edx,%r13d
	addl	%r11d,%r14d
.byte	143,232,120,194,239,2
	rorl	$14,%r13d
	movl	%r14d,%r11d
	vpxor	%xmm6,%xmm7,%xmm7
	movl	%r8d,%r12d
	xorl	%edx,%r13d
	rorl	$9,%r14d
	xorl	%r9d,%r12d
	vpxor	%xmm5,%xmm7,%xmm7
	rorl	$5,%r13d
	xorl	%r11d,%r14d
	andl	%edx,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	144-128(%rdi),%xmm10
	xorl	%edx,%r13d
	vpsrldq	$8,%xmm7,%xmm7
	addl	36(%rsp),%r10d
	movl	%r11d,%esi
	rorl	$11,%r14d
	xorl	%r9d,%r12d
	vpaddd	%xmm7,%xmm2,%xmm2
	xorl	%eax,%esi
	rorl	$6,%r13d
	addl	%r12d,%r10d
	andl	%esi,%r15d
.byte	143,232,120,194,250,13
	xorl	%r11d,%r14d
	addl	%r13d,%r10d
	vpsrld	$10,%xmm2,%xmm6
	xorl	%eax,%r15d
	addl	%r10d,%ecx
.byte	143,232,120,194,239,2
	rorl	$2,%r14d
	addl	%r15d,%r10d
	vpxor	%xmm6,%xmm7,%xmm7
	movl	%ecx,%r13d
	addl	%r10d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r10d
	vpxor	%xmm5,%xmm7,%xmm7
	movl	%edx,%r12d
	xorl	%ecx,%r13d
	rorl	$9,%r14d
	xorl	%r8d,%r12d
	vpslldq	$8,%xmm7,%xmm7
	rorl	$5,%r13d
	xorl	%r10d,%r14d
	andl	%ecx,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	160-128(%rdi),%xmm10
	xorl	%ecx,%r13d
	vpaddd	%xmm7,%xmm2,%xmm2
	addl	40(%rsp),%r9d
	movl	%r10d,%r15d
	rorl	$11,%r14d
	xorl	%r8d,%r12d
	vpaddd	64(%rbp),%xmm2,%xmm6
	xorl	%r11d,%r15d
	rorl	$6,%r13d
	addl	%r12d,%r9d
	andl	%r15d,%esi
	xorl	%r10d,%r14d
	addl	%r13d,%r9d
	xorl	%r11d,%esi
	addl	%r9d,%ebx
	rorl	$2,%r14d
	addl	%esi,%r9d
	movl	%ebx,%r13d
	addl	%r9d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r9d
	movl	%ecx,%r12d
	xorl	%ebx,%r13d
	rorl	$9,%r14d
	xorl	%edx,%r12d
	rorl	$5,%r13d
	xorl	%r9d,%r14d
	andl	%ebx,%r12d
	vaesenclast	%xmm10,%xmm9,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	176-128(%rdi),%xmm10
	xorl	%ebx,%r13d
	addl	44(%rsp),%r8d
	movl	%r9d,%esi
	rorl	$11,%r14d
	xorl	%edx,%r12d
	xorl	%r10d,%esi
	rorl	$6,%r13d
	addl	%r12d,%r8d
	andl	%esi,%r15d
	xorl	%r9d,%r14d
	addl	%r13d,%r8d
	xorl	%r10d,%r15d
	addl	%r8d,%eax
	rorl	$2,%r14d
	addl	%r15d,%r8d
	movl	%eax,%r13d
	addl	%r8d,%r14d
	vmovdqa	%xmm6,32(%rsp)
	vpalignr	$4,%xmm3,%xmm0,%xmm4
	rorl	$14,%r13d
	movl	%r14d,%r8d
	vpalignr	$4,%xmm1,%xmm2,%xmm7
	movl	%ebx,%r12d
	xorl	%eax,%r13d
.byte	143,232,120,194,236,14
	rorl	$9,%r14d
	xorl	%ecx,%r12d
	vpsrld	$3,%xmm4,%xmm4
	rorl	$5,%r13d
	xorl	%r8d,%r14d
	vpaddd	%xmm7,%xmm3,%xmm3
	andl	%eax,%r12d
	vpand	%xmm12,%xmm11,%xmm8
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	192-128(%rdi),%xmm10
	xorl	%eax,%r13d
	addl	48(%rsp),%edx
	movl	%r8d,%r15d
.byte	143,232,120,194,245,11
	rorl	$11,%r14d
	xorl	%ecx,%r12d
	vpxor	%xmm5,%xmm4,%xmm4
	xorl	%r9d,%r15d
	rorl	$6,%r13d
	addl	%r12d,%edx
	andl	%r15d,%esi
.byte	143,232,120,194,250,13
	xorl	%r8d,%r14d
	addl	%r13d,%edx
	vpxor	%xmm6,%xmm4,%xmm4
	xorl	%r9d,%esi
	addl	%edx,%r11d
	vpsrld	$10,%xmm2,%xmm6
	rorl	$2,%r14d
	addl	%esi,%edx
	vpaddd	%xmm4,%xmm3,%xmm3
	movl	%r11d,%r13d
	addl	%edx,%r14d
.byte	143,232,120,194,239,2
	rorl	$14,%r13d
	movl	%r14d,%edx
	vpxor	%xmm6,%xmm7,%xmm7
	movl	%eax,%r12d
	xorl	%r11d,%r13d
	rorl	$9,%r14d
	xorl	%ebx,%r12d
	vpxor	%xmm5,%xmm7,%xmm7
	rorl	$5,%r13d
	xorl	%edx,%r14d
	andl	%r11d,%r12d
	vaesenclast	%xmm10,%xmm9,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	208-128(%rdi),%xmm10
	xorl	%r11d,%r13d
	vpsrldq	$8,%xmm7,%xmm7
	addl	52(%rsp),%ecx
	movl	%edx,%esi
	rorl	$11,%r14d
	xorl	%ebx,%r12d
	vpaddd	%xmm7,%xmm3,%xmm3
	xorl	%r8d,%esi
	rorl	$6,%r13d
	addl	%r12d,%ecx
	andl	%esi,%r15d
.byte	143,232,120,194,251,13
	xorl	%edx,%r14d
	addl	%r13d,%ecx
	vpsrld	$10,%xmm3,%xmm6
	xorl	%r8d,%r15d
	addl	%ecx,%r10d
.byte	143,232,120,194,239,2
	rorl	$2,%r14d
	addl	%r15d,%ecx
	vpxor	%xmm6,%xmm7,%xmm7
	movl	%r10d,%r13d
	addl	%ecx,%r14d
	rorl	$14,%r13d
	movl	%r14d,%ecx
	vpxor	%xmm5,%xmm7,%xmm7
	movl	%r11d,%r12d
	xorl	%r10d,%r13d
	rorl	$9,%r14d
	xorl	%eax,%r12d
	vpslldq	$8,%xmm7,%xmm7
	rorl	$5,%r13d
	xorl	%ecx,%r14d
	andl	%r10d,%r12d
	vpand	%xmm13,%xmm11,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	224-128(%rdi),%xmm10
	xorl	%r10d,%r13d
	vpaddd	%xmm7,%xmm3,%xmm3
	addl	56(%rsp),%ebx
	movl	%ecx,%r15d
	rorl	$11,%r14d
	xorl	%eax,%r12d
	vpaddd	96(%rbp),%xmm3,%xmm6
	xorl	%edx,%r15d
	rorl	$6,%r13d
	addl	%r12d,%ebx
	andl	%r15d,%esi
	xorl	%ecx,%r14d
	addl	%r13d,%ebx
	xorl	%edx,%esi
	addl	%ebx,%r9d
	rorl	$2,%r14d
	addl	%esi,%ebx
	movl	%r9d,%r13d
	addl	%ebx,%r14d
	rorl	$14,%r13d
	movl	%r14d,%ebx
	movl	%r10d,%r12d
	xorl	%r9d,%r13d
	rorl	$9,%r14d
	xorl	%r11d,%r12d
	rorl	$5,%r13d
	xorl	%ebx,%r14d
	andl	%r9d,%r12d
	vpor	%xmm11,%xmm8,%xmm8
	vaesenclast	%xmm10,%xmm9,%xmm11
	vmovdqu	0-128(%rdi),%xmm10
	xorl	%r9d,%r13d
	addl	60(%rsp),%eax
	movl	%ebx,%esi
	rorl	$11,%r14d
	xorl	%r11d,%r12d
	xorl	%ecx,%esi
	rorl	$6,%r13d
	addl	%r12d,%eax
	andl	%esi,%r15d
	xorl	%ebx,%r14d
	addl	%r13d,%eax
	xorl	%ecx,%r15d
	addl	%eax,%r8d
	rorl	$2,%r14d
	addl	%r15d,%eax
	movl	%r8d,%r13d
	addl	%eax,%r14d
	vmovdqa	%xmm6,48(%rsp)
	movq	64+0(%rsp),%r12
	vpand	%xmm14,%xmm11,%xmm11
	movq	64+8(%rsp),%r15
	vpor	%xmm11,%xmm8,%xmm8
	vmovdqu	%xmm8,(%r15,%r12,1)
	leaq	16(%r12),%r12
	cmpb	$0,131(%rbp)
	jne	.Lxop_00_47
	vmovdqu	(%r12),%xmm9
	movq	%r12,64+0(%rsp)
	rorl	$14,%r13d
	movl	%r14d,%eax
	movl	%r9d,%r12d
	xorl	%r8d,%r13d
	rorl	$9,%r14d
	xorl	%r10d,%r12d
	rorl	$5,%r13d
	xorl	%eax,%r14d
	andl	%r8d,%r12d
	vpxor	%xmm10,%xmm9,%xmm9
	vmovdqu	16-128(%rdi),%xmm10
	xorl	%r8d,%r13d
	addl	0(%rsp),%r11d
	movl	%eax,%r15d
	rorl	$11,%r14d
	xorl	%r10d,%r12d
	xorl	%ebx,%r15d
	rorl	$6,%r13d
	addl	%r12d,%r11d
	andl	%r15d,%esi
	xorl	%eax,%r14d
	addl	%r13d,%r11d
	xorl	%ebx,%esi
	addl	%r11d,%edx
	rorl	$2,%r14d
	addl	%esi,%r11d
	movl	%edx,%r13d
	addl	%r11d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r11d
	movl	%r8d,%r12d
	xorl	%edx,%r13d
	rorl	$9,%r14d
	xorl	%r9d,%r12d
	rorl	$5,%r13d
	xorl	%r11d,%r14d
	andl	%edx,%r12d
	vpxor	%xmm8,%xmm9,%xmm9
	xorl	%edx,%r13d
	addl	4(%rsp),%r10d
	movl	%r11d,%esi
	rorl	$11,%r14d
	xorl	%r9d,%r12d
	xorl	%eax,%esi
	rorl	$6,%r13d
	addl	%r12d,%r10d
	andl	%esi,%r15d
	xorl	%r11d,%r14d
	addl	%r13d,%r10d
	xorl	%eax,%r15d
	addl	%r10d,%ecx
	rorl	$2,%r14d
	addl	%r15d,%r10d
	movl	%ecx,%r13d
	addl	%r10d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r10d
	movl	%edx,%r12d
	xorl	%ecx,%r13d
	rorl	$9,%r14d
	xorl	%r8d,%r12d
	rorl	$5,%r13d
	xorl	%r10d,%r14d
	andl	%ecx,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	32-128(%rdi),%xmm10
	xorl	%ecx,%r13d
	addl	8(%rsp),%r9d
	movl	%r10d,%r15d
	rorl	$11,%r14d
	xorl	%r8d,%r12d
	xorl	%r11d,%r15d
	rorl	$6,%r13d
	addl	%r12d,%r9d
	andl	%r15d,%esi
	xorl	%r10d,%r14d
	addl	%r13d,%r9d
	xorl	%r11d,%esi
	addl	%r9d,%ebx
	rorl	$2,%r14d
	addl	%esi,%r9d
	movl	%ebx,%r13d
	addl	%r9d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r9d
	movl	%ecx,%r12d
	xorl	%ebx,%r13d
	rorl	$9,%r14d
	xorl	%edx,%r12d
	rorl	$5,%r13d
	xorl	%r9d,%r14d
	andl	%ebx,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	48-128(%rdi),%xmm10
	xorl	%ebx,%r13d
	addl	12(%rsp),%r8d
	movl	%r9d,%esi
	rorl	$11,%r14d
	xorl	%edx,%r12d
	xorl	%r10d,%esi
	rorl	$6,%r13d
	addl	%r12d,%r8d
	andl	%esi,%r15d
	xorl	%r9d,%r14d
	addl	%r13d,%r8d
	xorl	%r10d,%r15d
	addl	%r8d,%eax
	rorl	$2,%r14d
	addl	%r15d,%r8d
	movl	%eax,%r13d
	addl	%r8d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r8d
	movl	%ebx,%r12d
	xorl	%eax,%r13d
	rorl	$9,%r14d
	xorl	%ecx,%r12d
	rorl	$5,%r13d
	xorl	%r8d,%r14d
	andl	%eax,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	64-128(%rdi),%xmm10
	xorl	%eax,%r13d
	addl	16(%rsp),%edx
	movl	%r8d,%r15d
	rorl	$11,%r14d
	xorl	%ecx,%r12d
	xorl	%r9d,%r15d
	rorl	$6,%r13d
	addl	%r12d,%edx
	andl	%r15d,%esi
	xorl	%r8d,%r14d
	addl	%r13d,%edx
	xorl	%r9d,%esi
	addl	%edx,%r11d
	rorl	$2,%r14d
	addl	%esi,%edx
	movl	%r11d,%r13d
	addl	%edx,%r14d
	rorl	$14,%r13d
	movl	%r14d,%edx
	movl	%eax,%r12d
	xorl	%r11d,%r13d
	rorl	$9,%r14d
	xorl	%ebx,%r12d
	rorl	$5,%r13d
	xorl	%edx,%r14d
	andl	%r11d,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	80-128(%rdi),%xmm10
	xorl	%r11d,%r13d
	addl	20(%rsp),%ecx
	movl	%edx,%esi
	rorl	$11,%r14d
	xorl	%ebx,%r12d
	xorl	%r8d,%esi
	rorl	$6,%r13d
	addl	%r12d,%ecx
	andl	%esi,%r15d
	xorl	%edx,%r14d
	addl	%r13d,%ecx
	xorl	%r8d,%r15d
	addl	%ecx,%r10d
	rorl	$2,%r14d
	addl	%r15d,%ecx
	movl	%r10d,%r13d
	addl	%ecx,%r14d
	rorl	$14,%r13d
	movl	%r14d,%ecx
	movl	%r11d,%r12d
	xorl	%r10d,%r13d
	rorl	$9,%r14d
	xorl	%eax,%r12d
	rorl	$5,%r13d
	xorl	%ecx,%r14d
	andl	%r10d,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	96-128(%rdi),%xmm10
	xorl	%r10d,%r13d
	addl	24(%rsp),%ebx
	movl	%ecx,%r15d
	rorl	$11,%r14d
	xorl	%eax,%r12d
	xorl	%edx,%r15d
	rorl	$6,%r13d
	addl	%r12d,%ebx
	andl	%r15d,%esi
	xorl	%ecx,%r14d
	addl	%r13d,%ebx
	xorl	%edx,%esi
	addl	%ebx,%r9d
	rorl	$2,%r14d
	addl	%esi,%ebx
	movl	%r9d,%r13d
	addl	%ebx,%r14d
	rorl	$14,%r13d
	movl	%r14d,%ebx
	movl	%r10d,%r12d
	xorl	%r9d,%r13d
	rorl	$9,%r14d
	xorl	%r11d,%r12d
	rorl	$5,%r13d
	xorl	%ebx,%r14d
	andl	%r9d,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	112-128(%rdi),%xmm10
	xorl	%r9d,%r13d
	addl	28(%rsp),%eax
	movl	%ebx,%esi
	rorl	$11,%r14d
	xorl	%r11d,%r12d
	xorl	%ecx,%esi
	rorl	$6,%r13d
	addl	%r12d,%eax
	andl	%esi,%r15d
	xorl	%ebx,%r14d
	addl	%r13d,%eax
	xorl	%ecx,%r15d
	addl	%eax,%r8d
	rorl	$2,%r14d
	addl	%r15d,%eax
	movl	%r8d,%r13d
	addl	%eax,%r14d
	rorl	$14,%r13d
	movl	%r14d,%eax
	movl	%r9d,%r12d
	xorl	%r8d,%r13d
	rorl	$9,%r14d
	xorl	%r10d,%r12d
	rorl	$5,%r13d
	xorl	%eax,%r14d
	andl	%r8d,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	128-128(%rdi),%xmm10
	xorl	%r8d,%r13d
	addl	32(%rsp),%r11d
	movl	%eax,%r15d
	rorl	$11,%r14d
	xorl	%r10d,%r12d
	xorl	%ebx,%r15d
	rorl	$6,%r13d
	addl	%r12d,%r11d
	andl	%r15d,%esi
	xorl	%eax,%r14d
	addl	%r13d,%r11d
	xorl	%ebx,%esi
	addl	%r11d,%edx
	rorl	$2,%r14d
	addl	%esi,%r11d
	movl	%edx,%r13d
	addl	%r11d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r11d
	movl	%r8d,%r12d
	xorl	%edx,%r13d
	rorl	$9,%r14d
	xorl	%r9d,%r12d
	rorl	$5,%r13d
	xorl	%r11d,%r14d
	andl	%edx,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	144-128(%rdi),%xmm10
	xorl	%edx,%r13d
	addl	36(%rsp),%r10d
	movl	%r11d,%esi
	rorl	$11,%r14d
	xorl	%r9d,%r12d
	xorl	%eax,%esi
	rorl	$6,%r13d
	addl	%r12d,%r10d
	andl	%esi,%r15d
	xorl	%r11d,%r14d
	addl	%r13d,%r10d
	xorl	%eax,%r15d
	addl	%r10d,%ecx
	rorl	$2,%r14d
	addl	%r15d,%r10d
	movl	%ecx,%r13d
	addl	%r10d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r10d
	movl	%edx,%r12d
	xorl	%ecx,%r13d
	rorl	$9,%r14d
	xorl	%r8d,%r12d
	rorl	$5,%r13d
	xorl	%r10d,%r14d
	andl	%ecx,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	160-128(%rdi),%xmm10
	xorl	%ecx,%r13d
	addl	40(%rsp),%r9d
	movl	%r10d,%r15d
	rorl	$11,%r14d
	xorl	%r8d,%r12d
	xorl	%r11d,%r15d
	rorl	$6,%r13d
	addl	%r12d,%r9d
	andl	%r15d,%esi
	xorl	%r10d,%r14d
	addl	%r13d,%r9d
	xorl	%r11d,%esi
	addl	%r9d,%ebx
	rorl	$2,%r14d
	addl	%esi,%r9d
	movl	%ebx,%r13d
	addl	%r9d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r9d
	movl	%ecx,%r12d
	xorl	%ebx,%r13d
	rorl	$9,%r14d
	xorl	%edx,%r12d
	rorl	$5,%r13d
	xorl	%r9d,%r14d
	andl	%ebx,%r12d
	vaesenclast	%xmm10,%xmm9,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	176-128(%rdi),%xmm10
	xorl	%ebx,%r13d
	addl	44(%rsp),%r8d
	movl	%r9d,%esi
	rorl	$11,%r14d
	xorl	%edx,%r12d
	xorl	%r10d,%esi
	rorl	$6,%r13d
	addl	%r12d,%r8d
	andl	%esi,%r15d
	xorl	%r9d,%r14d
	addl	%r13d,%r8d
	xorl	%r10d,%r15d
	addl	%r8d,%eax
	rorl	$2,%r14d
	addl	%r15d,%r8d
	movl	%eax,%r13d
	addl	%r8d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r8d
	movl	%ebx,%r12d
	xorl	%eax,%r13d
	rorl	$9,%r14d
	xorl	%ecx,%r12d
	rorl	$5,%r13d
	xorl	%r8d,%r14d
	andl	%eax,%r12d
	vpand	%xmm12,%xmm11,%xmm8
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	192-128(%rdi),%xmm10
	xorl	%eax,%r13d
	addl	48(%rsp),%edx
	movl	%r8d,%r15d
	rorl	$11,%r14d
	xorl	%ecx,%r12d
	xorl	%r9d,%r15d
	rorl	$6,%r13d
	addl	%r12d,%edx
	andl	%r15d,%esi
	xorl	%r8d,%r14d
	addl	%r13d,%edx
	xorl	%r9d,%esi
	addl	%edx,%r11d
	rorl	$2,%r14d
	addl	%esi,%edx
	movl	%r11d,%r13d
	addl	%edx,%r14d
	rorl	$14,%r13d
	movl	%r14d,%edx
	movl	%eax,%r12d
	xorl	%r11d,%r13d
	rorl	$9,%r14d
	xorl	%ebx,%r12d
	rorl	$5,%r13d
	xorl	%edx,%r14d
	andl	%r11d,%r12d
	vaesenclast	%xmm10,%xmm9,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	208-128(%rdi),%xmm10
	xorl	%r11d,%r13d
	addl	52(%rsp),%ecx
	movl	%edx,%esi
	rorl	$11,%r14d
	xorl	%ebx,%r12d
	xorl	%r8d,%esi
	rorl	$6,%r13d
	addl	%r12d,%ecx
	andl	%esi,%r15d
	xorl	%edx,%r14d
	addl	%r13d,%ecx
	xorl	%r8d,%r15d
	addl	%ecx,%r10d
	rorl	$2,%r14d
	addl	%r15d,%ecx
	movl	%r10d,%r13d
	addl	%ecx,%r14d
	rorl	$14,%r13d
	movl	%r14d,%ecx
	movl	%r11d,%r12d
	xorl	%r10d,%r13d
	rorl	$9,%r14d
	xorl	%eax,%r12d
	rorl	$5,%r13d
	xorl	%ecx,%r14d
	andl	%r10d,%r12d
	vpand	%xmm13,%xmm11,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	224-128(%rdi),%xmm10
	xorl	%r10d,%r13d
	addl	56(%rsp),%ebx
	movl	%ecx,%r15d
	rorl	$11,%r14d
	xorl	%eax,%r12d
	xorl	%edx,%r15d
	rorl	$6,%r13d
	addl	%r12d,%ebx
	andl	%r15d,%esi
	xorl	%ecx,%r14d
	addl	%r13d,%ebx
	xorl	%edx,%esi
	addl	%ebx,%r9d
	rorl	$2,%r14d
	addl	%esi,%ebx
	movl	%r9d,%r13d
	addl	%ebx,%r14d
	rorl	$14,%r13d
	movl	%r14d,%ebx
	movl	%r10d,%r12d
	xorl	%r9d,%r13d
	rorl	$9,%r14d
	xorl	%r11d,%r12d
	rorl	$5,%r13d
	xorl	%ebx,%r14d
	andl	%r9d,%r12d
	vpor	%xmm11,%xmm8,%xmm8
	vaesenclast	%xmm10,%xmm9,%xmm11
	vmovdqu	0-128(%rdi),%xmm10
	xorl	%r9d,%r13d
	addl	60(%rsp),%eax
	movl	%ebx,%esi
	rorl	$11,%r14d
	xorl	%r11d,%r12d
	xorl	%ecx,%esi
	rorl	$6,%r13d
	addl	%r12d,%eax
	andl	%esi,%r15d
	xorl	%ebx,%r14d
	addl	%r13d,%eax
	xorl	%ecx,%r15d
	addl	%eax,%r8d
	rorl	$2,%r14d
	addl	%r15d,%eax
	movl	%r8d,%r13d
	addl	%eax,%r14d
	movq	64+0(%rsp),%r12
	movq	64+8(%rsp),%r13
	movq	64+40(%rsp),%r15
	movq	64+48(%rsp),%rsi

	vpand	%xmm14,%xmm11,%xmm11
	movl	%r14d,%eax
	vpor	%xmm11,%xmm8,%xmm8
	vmovdqu	%xmm8,(%r12,%r13,1)
	leaq	16(%r12),%r12

	addl	0(%r15),%eax
	addl	4(%r15),%ebx
	addl	8(%r15),%ecx
	addl	12(%r15),%edx
	addl	16(%r15),%r8d
	addl	20(%r15),%r9d
	addl	24(%r15),%r10d
	addl	28(%r15),%r11d

	cmpq	64+16(%rsp),%r12

	movl	%eax,0(%r15)
	movl	%ebx,4(%r15)
	movl	%ecx,8(%r15)
	movl	%edx,12(%r15)
	movl	%r8d,16(%r15)
	movl	%r9d,20(%r15)
	movl	%r10d,24(%r15)
	movl	%r11d,28(%r15)

	jb	.Lloop_xop

	movq	64+32(%rsp),%r8
	movq	120(%rsp),%rsi
.cfi_def_cfa	%rsi,8
	vmovdqu	%xmm8,(%r8)
	vzeroall
	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue_xop:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_cbc_sha256_enc_xop,.-aesni_cbc_sha256_enc_xop
.type	aesni_cbc_sha256_enc_avx,@function
.align	64
aesni_cbc_sha256_enc_avx:
.cfi_startproc	
.Lavx_shortcut:
	movq	8(%rsp),%r10
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
	subq	$128,%rsp
	andq	$-64,%rsp

	shlq	$6,%rdx
	subq	%rdi,%rsi
	subq	%rdi,%r10
	addq	%rdi,%rdx


	movq	%rsi,64+8(%rsp)
	movq	%rdx,64+16(%rsp)

	movq	%r8,64+32(%rsp)
	movq	%r9,64+40(%rsp)
	movq	%r10,64+48(%rsp)
	movq	%rax,120(%rsp)
.cfi_escape	0x0f,0x06,0x77,0xf8,0x00,0x06,0x23,0x08
.Lprologue_avx:
	vzeroall

	movq	%rdi,%r12
	leaq	128(%rcx),%rdi
	leaq	K256+544(%rip),%r13
	movl	240-128(%rdi),%r14d
	movq	%r9,%r15
	movq	%r10,%rsi
	vmovdqu	(%r8),%xmm8
	subq	$9,%r14

	movl	0(%r15),%eax
	movl	4(%r15),%ebx
	movl	8(%r15),%ecx
	movl	12(%r15),%edx
	movl	16(%r15),%r8d
	movl	20(%r15),%r9d
	movl	24(%r15),%r10d
	movl	28(%r15),%r11d

	vmovdqa	0(%r13,%r14,8),%xmm14
	vmovdqa	16(%r13,%r14,8),%xmm13
	vmovdqa	32(%r13,%r14,8),%xmm12
	vmovdqu	0-128(%rdi),%xmm10
	jmp	.Lloop_avx
.align	16
.Lloop_avx:
	vmovdqa	K256+512(%rip),%xmm7
	vmovdqu	0(%rsi,%r12,1),%xmm0
	vmovdqu	16(%rsi,%r12,1),%xmm1
	vmovdqu	32(%rsi,%r12,1),%xmm2
	vmovdqu	48(%rsi,%r12,1),%xmm3
	vpshufb	%xmm7,%xmm0,%xmm0
	leaq	K256(%rip),%rbp
	vpshufb	%xmm7,%xmm1,%xmm1
	vpshufb	%xmm7,%xmm2,%xmm2
	vpaddd	0(%rbp),%xmm0,%xmm4
	vpshufb	%xmm7,%xmm3,%xmm3
	vpaddd	32(%rbp),%xmm1,%xmm5
	vpaddd	64(%rbp),%xmm2,%xmm6
	vpaddd	96(%rbp),%xmm3,%xmm7
	vmovdqa	%xmm4,0(%rsp)
	movl	%eax,%r14d
	vmovdqa	%xmm5,16(%rsp)
	movl	%ebx,%esi
	vmovdqa	%xmm6,32(%rsp)
	xorl	%ecx,%esi
	vmovdqa	%xmm7,48(%rsp)
	movl	%r8d,%r13d
	jmp	.Lavx_00_47

.align	16
.Lavx_00_47:
	subq	$-32*4,%rbp
	vmovdqu	(%r12),%xmm9
	movq	%r12,64+0(%rsp)
	vpalignr	$4,%xmm0,%xmm1,%xmm4
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%eax
	movl	%r9d,%r12d
	vpalignr	$4,%xmm2,%xmm3,%xmm7
	xorl	%r8d,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%r10d,%r12d
	vpsrld	$7,%xmm4,%xmm6
	shrdl	$5,%r13d,%r13d
	xorl	%eax,%r14d
	andl	%r8d,%r12d
	vpaddd	%xmm7,%xmm0,%xmm0
	vpxor	%xmm10,%xmm9,%xmm9
	vmovdqu	16-128(%rdi),%xmm10
	xorl	%r8d,%r13d
	addl	0(%rsp),%r11d
	movl	%eax,%r15d
	vpsrld	$3,%xmm4,%xmm7
	shrdl	$11,%r14d,%r14d
	xorl	%r10d,%r12d
	xorl	%ebx,%r15d
	vpslld	$14,%xmm4,%xmm5
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%r11d
	andl	%r15d,%esi
	vpxor	%xmm6,%xmm7,%xmm4
	xorl	%eax,%r14d
	addl	%r13d,%r11d
	xorl	%ebx,%esi
	vpshufd	$250,%xmm3,%xmm7
	addl	%r11d,%edx
	shrdl	$2,%r14d,%r14d
	addl	%esi,%r11d
	vpsrld	$11,%xmm6,%xmm6
	movl	%edx,%r13d
	addl	%r11d,%r14d
	shrdl	$14,%r13d,%r13d
	vpxor	%xmm5,%xmm4,%xmm4
	movl	%r14d,%r11d
	movl	%r8d,%r12d
	xorl	%edx,%r13d
	vpslld	$11,%xmm5,%xmm5
	shrdl	$9,%r14d,%r14d
	xorl	%r9d,%r12d
	shrdl	$5,%r13d,%r13d
	vpxor	%xmm6,%xmm4,%xmm4
	xorl	%r11d,%r14d
	andl	%edx,%r12d
	vpxor	%xmm8,%xmm9,%xmm9
	xorl	%edx,%r13d
	vpsrld	$10,%xmm7,%xmm6
	addl	4(%rsp),%r10d
	movl	%r11d,%esi
	shrdl	$11,%r14d,%r14d
	vpxor	%xmm5,%xmm4,%xmm4
	xorl	%r9d,%r12d
	xorl	%eax,%esi
	shrdl	$6,%r13d,%r13d
	vpsrlq	$17,%xmm7,%xmm7
	addl	%r12d,%r10d
	andl	%esi,%r15d
	xorl	%r11d,%r14d
	vpaddd	%xmm4,%xmm0,%xmm0
	addl	%r13d,%r10d
	xorl	%eax,%r15d
	addl	%r10d,%ecx
	vpxor	%xmm7,%xmm6,%xmm6
	shrdl	$2,%r14d,%r14d
	addl	%r15d,%r10d
	movl	%ecx,%r13d
	vpsrlq	$2,%xmm7,%xmm7
	addl	%r10d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r10d
	vpxor	%xmm7,%xmm6,%xmm6
	movl	%edx,%r12d
	xorl	%ecx,%r13d
	shrdl	$9,%r14d,%r14d
	vpshufd	$132,%xmm6,%xmm6
	xorl	%r8d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r10d,%r14d
	vpsrldq	$8,%xmm6,%xmm6
	andl	%ecx,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	32-128(%rdi),%xmm10
	xorl	%ecx,%r13d
	addl	8(%rsp),%r9d
	vpaddd	%xmm6,%xmm0,%xmm0
	movl	%r10d,%r15d
	shrdl	$11,%r14d,%r14d
	xorl	%r8d,%r12d
	vpshufd	$80,%xmm0,%xmm7
	xorl	%r11d,%r15d
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%r9d
	vpsrld	$10,%xmm7,%xmm6
	andl	%r15d,%esi
	xorl	%r10d,%r14d
	addl	%r13d,%r9d
	vpsrlq	$17,%xmm7,%xmm7
	xorl	%r11d,%esi
	addl	%r9d,%ebx
	shrdl	$2,%r14d,%r14d
	vpxor	%xmm7,%xmm6,%xmm6
	addl	%esi,%r9d
	movl	%ebx,%r13d
	addl	%r9d,%r14d
	vpsrlq	$2,%xmm7,%xmm7
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r9d
	movl	%ecx,%r12d
	vpxor	%xmm7,%xmm6,%xmm6
	xorl	%ebx,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%edx,%r12d
	vpshufd	$232,%xmm6,%xmm6
	shrdl	$5,%r13d,%r13d
	xorl	%r9d,%r14d
	andl	%ebx,%r12d
	vpslldq	$8,%xmm6,%xmm6
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	48-128(%rdi),%xmm10
	xorl	%ebx,%r13d
	addl	12(%rsp),%r8d
	movl	%r9d,%esi
	vpaddd	%xmm6,%xmm0,%xmm0
	shrdl	$11,%r14d,%r14d
	xorl	%edx,%r12d
	xorl	%r10d,%esi
	vpaddd	0(%rbp),%xmm0,%xmm6
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%r8d
	andl	%esi,%r15d
	xorl	%r9d,%r14d
	addl	%r13d,%r8d
	xorl	%r10d,%r15d
	addl	%r8d,%eax
	shrdl	$2,%r14d,%r14d
	addl	%r15d,%r8d
	movl	%eax,%r13d
	addl	%r8d,%r14d
	vmovdqa	%xmm6,0(%rsp)
	vpalignr	$4,%xmm1,%xmm2,%xmm4
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r8d
	movl	%ebx,%r12d
	vpalignr	$4,%xmm3,%xmm0,%xmm7
	xorl	%eax,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%ecx,%r12d
	vpsrld	$7,%xmm4,%xmm6
	shrdl	$5,%r13d,%r13d
	xorl	%r8d,%r14d
	andl	%eax,%r12d
	vpaddd	%xmm7,%xmm1,%xmm1
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	64-128(%rdi),%xmm10
	xorl	%eax,%r13d
	addl	16(%rsp),%edx
	movl	%r8d,%r15d
	vpsrld	$3,%xmm4,%xmm7
	shrdl	$11,%r14d,%r14d
	xorl	%ecx,%r12d
	xorl	%r9d,%r15d
	vpslld	$14,%xmm4,%xmm5
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%edx
	andl	%r15d,%esi
	vpxor	%xmm6,%xmm7,%xmm4
	xorl	%r8d,%r14d
	addl	%r13d,%edx
	xorl	%r9d,%esi
	vpshufd	$250,%xmm0,%xmm7
	addl	%edx,%r11d
	shrdl	$2,%r14d,%r14d
	addl	%esi,%edx
	vpsrld	$11,%xmm6,%xmm6
	movl	%r11d,%r13d
	addl	%edx,%r14d
	shrdl	$14,%r13d,%r13d
	vpxor	%xmm5,%xmm4,%xmm4
	movl	%r14d,%edx
	movl	%eax,%r12d
	xorl	%r11d,%r13d
	vpslld	$11,%xmm5,%xmm5
	shrdl	$9,%r14d,%r14d
	xorl	%ebx,%r12d
	shrdl	$5,%r13d,%r13d
	vpxor	%xmm6,%xmm4,%xmm4
	xorl	%edx,%r14d
	andl	%r11d,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	80-128(%rdi),%xmm10
	xorl	%r11d,%r13d
	vpsrld	$10,%xmm7,%xmm6
	addl	20(%rsp),%ecx
	movl	%edx,%esi
	shrdl	$11,%r14d,%r14d
	vpxor	%xmm5,%xmm4,%xmm4
	xorl	%ebx,%r12d
	xorl	%r8d,%esi
	shrdl	$6,%r13d,%r13d
	vpsrlq	$17,%xmm7,%xmm7
	addl	%r12d,%ecx
	andl	%esi,%r15d
	xorl	%edx,%r14d
	vpaddd	%xmm4,%xmm1,%xmm1
	addl	%r13d,%ecx
	xorl	%r8d,%r15d
	addl	%ecx,%r10d
	vpxor	%xmm7,%xmm6,%xmm6
	shrdl	$2,%r14d,%r14d
	addl	%r15d,%ecx
	movl	%r10d,%r13d
	vpsrlq	$2,%xmm7,%xmm7
	addl	%ecx,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%ecx
	vpxor	%xmm7,%xmm6,%xmm6
	movl	%r11d,%r12d
	xorl	%r10d,%r13d
	shrdl	$9,%r14d,%r14d
	vpshufd	$132,%xmm6,%xmm6
	xorl	%eax,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%ecx,%r14d
	vpsrldq	$8,%xmm6,%xmm6
	andl	%r10d,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	96-128(%rdi),%xmm10
	xorl	%r10d,%r13d
	addl	24(%rsp),%ebx
	vpaddd	%xmm6,%xmm1,%xmm1
	movl	%ecx,%r15d
	shrdl	$11,%r14d,%r14d
	xorl	%eax,%r12d
	vpshufd	$80,%xmm1,%xmm7
	xorl	%edx,%r15d
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%ebx
	vpsrld	$10,%xmm7,%xmm6
	andl	%r15d,%esi
	xorl	%ecx,%r14d
	addl	%r13d,%ebx
	vpsrlq	$17,%xmm7,%xmm7
	xorl	%edx,%esi
	addl	%ebx,%r9d
	shrdl	$2,%r14d,%r14d
	vpxor	%xmm7,%xmm6,%xmm6
	addl	%esi,%ebx
	movl	%r9d,%r13d
	addl	%ebx,%r14d
	vpsrlq	$2,%xmm7,%xmm7
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%ebx
	movl	%r10d,%r12d
	vpxor	%xmm7,%xmm6,%xmm6
	xorl	%r9d,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%r11d,%r12d
	vpshufd	$232,%xmm6,%xmm6
	shrdl	$5,%r13d,%r13d
	xorl	%ebx,%r14d
	andl	%r9d,%r12d
	vpslldq	$8,%xmm6,%xmm6
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	112-128(%rdi),%xmm10
	xorl	%r9d,%r13d
	addl	28(%rsp),%eax
	movl	%ebx,%esi
	vpaddd	%xmm6,%xmm1,%xmm1
	shrdl	$11,%r14d,%r14d
	xorl	%r11d,%r12d
	xorl	%ecx,%esi
	vpaddd	32(%rbp),%xmm1,%xmm6
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%eax
	andl	%esi,%r15d
	xorl	%ebx,%r14d
	addl	%r13d,%eax
	xorl	%ecx,%r15d
	addl	%eax,%r8d
	shrdl	$2,%r14d,%r14d
	addl	%r15d,%eax
	movl	%r8d,%r13d
	addl	%eax,%r14d
	vmovdqa	%xmm6,16(%rsp)
	vpalignr	$4,%xmm2,%xmm3,%xmm4
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%eax
	movl	%r9d,%r12d
	vpalignr	$4,%xmm0,%xmm1,%xmm7
	xorl	%r8d,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%r10d,%r12d
	vpsrld	$7,%xmm4,%xmm6
	shrdl	$5,%r13d,%r13d
	xorl	%eax,%r14d
	andl	%r8d,%r12d
	vpaddd	%xmm7,%xmm2,%xmm2
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	128-128(%rdi),%xmm10
	xorl	%r8d,%r13d
	addl	32(%rsp),%r11d
	movl	%eax,%r15d
	vpsrld	$3,%xmm4,%xmm7
	shrdl	$11,%r14d,%r14d
	xorl	%r10d,%r12d
	xorl	%ebx,%r15d
	vpslld	$14,%xmm4,%xmm5
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%r11d
	andl	%r15d,%esi
	vpxor	%xmm6,%xmm7,%xmm4
	xorl	%eax,%r14d
	addl	%r13d,%r11d
	xorl	%ebx,%esi
	vpshufd	$250,%xmm1,%xmm7
	addl	%r11d,%edx
	shrdl	$2,%r14d,%r14d
	addl	%esi,%r11d
	vpsrld	$11,%xmm6,%xmm6
	movl	%edx,%r13d
	addl	%r11d,%r14d
	shrdl	$14,%r13d,%r13d
	vpxor	%xmm5,%xmm4,%xmm4
	movl	%r14d,%r11d
	movl	%r8d,%r12d
	xorl	%edx,%r13d
	vpslld	$11,%xmm5,%xmm5
	shrdl	$9,%r14d,%r14d
	xorl	%r9d,%r12d
	shrdl	$5,%r13d,%r13d
	vpxor	%xmm6,%xmm4,%xmm4
	xorl	%r11d,%r14d
	andl	%edx,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	144-128(%rdi),%xmm10
	xorl	%edx,%r13d
	vpsrld	$10,%xmm7,%xmm6
	addl	36(%rsp),%r10d
	movl	%r11d,%esi
	shrdl	$11,%r14d,%r14d
	vpxor	%xmm5,%xmm4,%xmm4
	xorl	%r9d,%r12d
	xorl	%eax,%esi
	shrdl	$6,%r13d,%r13d
	vpsrlq	$17,%xmm7,%xmm7
	addl	%r12d,%r10d
	andl	%esi,%r15d
	xorl	%r11d,%r14d
	vpaddd	%xmm4,%xmm2,%xmm2
	addl	%r13d,%r10d
	xorl	%eax,%r15d
	addl	%r10d,%ecx
	vpxor	%xmm7,%xmm6,%xmm6
	shrdl	$2,%r14d,%r14d
	addl	%r15d,%r10d
	movl	%ecx,%r13d
	vpsrlq	$2,%xmm7,%xmm7
	addl	%r10d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r10d
	vpxor	%xmm7,%xmm6,%xmm6
	movl	%edx,%r12d
	xorl	%ecx,%r13d
	shrdl	$9,%r14d,%r14d
	vpshufd	$132,%xmm6,%xmm6
	xorl	%r8d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r10d,%r14d
	vpsrldq	$8,%xmm6,%xmm6
	andl	%ecx,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	160-128(%rdi),%xmm10
	xorl	%ecx,%r13d
	addl	40(%rsp),%r9d
	vpaddd	%xmm6,%xmm2,%xmm2
	movl	%r10d,%r15d
	shrdl	$11,%r14d,%r14d
	xorl	%r8d,%r12d
	vpshufd	$80,%xmm2,%xmm7
	xorl	%r11d,%r15d
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%r9d
	vpsrld	$10,%xmm7,%xmm6
	andl	%r15d,%esi
	xorl	%r10d,%r14d
	addl	%r13d,%r9d
	vpsrlq	$17,%xmm7,%xmm7
	xorl	%r11d,%esi
	addl	%r9d,%ebx
	shrdl	$2,%r14d,%r14d
	vpxor	%xmm7,%xmm6,%xmm6
	addl	%esi,%r9d
	movl	%ebx,%r13d
	addl	%r9d,%r14d
	vpsrlq	$2,%xmm7,%xmm7
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r9d
	movl	%ecx,%r12d
	vpxor	%xmm7,%xmm6,%xmm6
	xorl	%ebx,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%edx,%r12d
	vpshufd	$232,%xmm6,%xmm6
	shrdl	$5,%r13d,%r13d
	xorl	%r9d,%r14d
	andl	%ebx,%r12d
	vpslldq	$8,%xmm6,%xmm6
	vaesenclast	%xmm10,%xmm9,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	176-128(%rdi),%xmm10
	xorl	%ebx,%r13d
	addl	44(%rsp),%r8d
	movl	%r9d,%esi
	vpaddd	%xmm6,%xmm2,%xmm2
	shrdl	$11,%r14d,%r14d
	xorl	%edx,%r12d
	xorl	%r10d,%esi
	vpaddd	64(%rbp),%xmm2,%xmm6
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%r8d
	andl	%esi,%r15d
	xorl	%r9d,%r14d
	addl	%r13d,%r8d
	xorl	%r10d,%r15d
	addl	%r8d,%eax
	shrdl	$2,%r14d,%r14d
	addl	%r15d,%r8d
	movl	%eax,%r13d
	addl	%r8d,%r14d
	vmovdqa	%xmm6,32(%rsp)
	vpalignr	$4,%xmm3,%xmm0,%xmm4
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r8d
	movl	%ebx,%r12d
	vpalignr	$4,%xmm1,%xmm2,%xmm7
	xorl	%eax,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%ecx,%r12d
	vpsrld	$7,%xmm4,%xmm6
	shrdl	$5,%r13d,%r13d
	xorl	%r8d,%r14d
	andl	%eax,%r12d
	vpaddd	%xmm7,%xmm3,%xmm3
	vpand	%xmm12,%xmm11,%xmm8
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	192-128(%rdi),%xmm10
	xorl	%eax,%r13d
	addl	48(%rsp),%edx
	movl	%r8d,%r15d
	vpsrld	$3,%xmm4,%xmm7
	shrdl	$11,%r14d,%r14d
	xorl	%ecx,%r12d
	xorl	%r9d,%r15d
	vpslld	$14,%xmm4,%xmm5
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%edx
	andl	%r15d,%esi
	vpxor	%xmm6,%xmm7,%xmm4
	xorl	%r8d,%r14d
	addl	%r13d,%edx
	xorl	%r9d,%esi
	vpshufd	$250,%xmm2,%xmm7
	addl	%edx,%r11d
	shrdl	$2,%r14d,%r14d
	addl	%esi,%edx
	vpsrld	$11,%xmm6,%xmm6
	movl	%r11d,%r13d
	addl	%edx,%r14d
	shrdl	$14,%r13d,%r13d
	vpxor	%xmm5,%xmm4,%xmm4
	movl	%r14d,%edx
	movl	%eax,%r12d
	xorl	%r11d,%r13d
	vpslld	$11,%xmm5,%xmm5
	shrdl	$9,%r14d,%r14d
	xorl	%ebx,%r12d
	shrdl	$5,%r13d,%r13d
	vpxor	%xmm6,%xmm4,%xmm4
	xorl	%edx,%r14d
	andl	%r11d,%r12d
	vaesenclast	%xmm10,%xmm9,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	208-128(%rdi),%xmm10
	xorl	%r11d,%r13d
	vpsrld	$10,%xmm7,%xmm6
	addl	52(%rsp),%ecx
	movl	%edx,%esi
	shrdl	$11,%r14d,%r14d
	vpxor	%xmm5,%xmm4,%xmm4
	xorl	%ebx,%r12d
	xorl	%r8d,%esi
	shrdl	$6,%r13d,%r13d
	vpsrlq	$17,%xmm7,%xmm7
	addl	%r12d,%ecx
	andl	%esi,%r15d
	xorl	%edx,%r14d
	vpaddd	%xmm4,%xmm3,%xmm3
	addl	%r13d,%ecx
	xorl	%r8d,%r15d
	addl	%ecx,%r10d
	vpxor	%xmm7,%xmm6,%xmm6
	shrdl	$2,%r14d,%r14d
	addl	%r15d,%ecx
	movl	%r10d,%r13d
	vpsrlq	$2,%xmm7,%xmm7
	addl	%ecx,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%ecx
	vpxor	%xmm7,%xmm6,%xmm6
	movl	%r11d,%r12d
	xorl	%r10d,%r13d
	shrdl	$9,%r14d,%r14d
	vpshufd	$132,%xmm6,%xmm6
	xorl	%eax,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%ecx,%r14d
	vpsrldq	$8,%xmm6,%xmm6
	andl	%r10d,%r12d
	vpand	%xmm13,%xmm11,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	224-128(%rdi),%xmm10
	xorl	%r10d,%r13d
	addl	56(%rsp),%ebx
	vpaddd	%xmm6,%xmm3,%xmm3
	movl	%ecx,%r15d
	shrdl	$11,%r14d,%r14d
	xorl	%eax,%r12d
	vpshufd	$80,%xmm3,%xmm7
	xorl	%edx,%r15d
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%ebx
	vpsrld	$10,%xmm7,%xmm6
	andl	%r15d,%esi
	xorl	%ecx,%r14d
	addl	%r13d,%ebx
	vpsrlq	$17,%xmm7,%xmm7
	xorl	%edx,%esi
	addl	%ebx,%r9d
	shrdl	$2,%r14d,%r14d
	vpxor	%xmm7,%xmm6,%xmm6
	addl	%esi,%ebx
	movl	%r9d,%r13d
	addl	%ebx,%r14d
	vpsrlq	$2,%xmm7,%xmm7
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%ebx
	movl	%r10d,%r12d
	vpxor	%xmm7,%xmm6,%xmm6
	xorl	%r9d,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%r11d,%r12d
	vpshufd	$232,%xmm6,%xmm6
	shrdl	$5,%r13d,%r13d
	xorl	%ebx,%r14d
	andl	%r9d,%r12d
	vpslldq	$8,%xmm6,%xmm6
	vpor	%xmm11,%xmm8,%xmm8
	vaesenclast	%xmm10,%xmm9,%xmm11
	vmovdqu	0-128(%rdi),%xmm10
	xorl	%r9d,%r13d
	addl	60(%rsp),%eax
	movl	%ebx,%esi
	vpaddd	%xmm6,%xmm3,%xmm3
	shrdl	$11,%r14d,%r14d
	xorl	%r11d,%r12d
	xorl	%ecx,%esi
	vpaddd	96(%rbp),%xmm3,%xmm6
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%eax
	andl	%esi,%r15d
	xorl	%ebx,%r14d
	addl	%r13d,%eax
	xorl	%ecx,%r15d
	addl	%eax,%r8d
	shrdl	$2,%r14d,%r14d
	addl	%r15d,%eax
	movl	%r8d,%r13d
	addl	%eax,%r14d
	vmovdqa	%xmm6,48(%rsp)
	movq	64+0(%rsp),%r12
	vpand	%xmm14,%xmm11,%xmm11
	movq	64+8(%rsp),%r15
	vpor	%xmm11,%xmm8,%xmm8
	vmovdqu	%xmm8,(%r15,%r12,1)
	leaq	16(%r12),%r12
	cmpb	$0,131(%rbp)
	jne	.Lavx_00_47
	vmovdqu	(%r12),%xmm9
	movq	%r12,64+0(%rsp)
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%eax
	movl	%r9d,%r12d
	xorl	%r8d,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%r10d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%eax,%r14d
	andl	%r8d,%r12d
	vpxor	%xmm10,%xmm9,%xmm9
	vmovdqu	16-128(%rdi),%xmm10
	xorl	%r8d,%r13d
	addl	0(%rsp),%r11d
	movl	%eax,%r15d
	shrdl	$11,%r14d,%r14d
	xorl	%r10d,%r12d
	xorl	%ebx,%r15d
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%r11d
	andl	%r15d,%esi
	xorl	%eax,%r14d
	addl	%r13d,%r11d
	xorl	%ebx,%esi
	addl	%r11d,%edx
	shrdl	$2,%r14d,%r14d
	addl	%esi,%r11d
	movl	%edx,%r13d
	addl	%r11d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r11d
	movl	%r8d,%r12d
	xorl	%edx,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%r9d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r11d,%r14d
	andl	%edx,%r12d
	vpxor	%xmm8,%xmm9,%xmm9
	xorl	%edx,%r13d
	addl	4(%rsp),%r10d
	movl	%r11d,%esi
	shrdl	$11,%r14d,%r14d
	xorl	%r9d,%r12d
	xorl	%eax,%esi
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%r10d
	andl	%esi,%r15d
	xorl	%r11d,%r14d
	addl	%r13d,%r10d
	xorl	%eax,%r15d
	addl	%r10d,%ecx
	shrdl	$2,%r14d,%r14d
	addl	%r15d,%r10d
	movl	%ecx,%r13d
	addl	%r10d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r10d
	movl	%edx,%r12d
	xorl	%ecx,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%r8d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r10d,%r14d
	andl	%ecx,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	32-128(%rdi),%xmm10
	xorl	%ecx,%r13d
	addl	8(%rsp),%r9d
	movl	%r10d,%r15d
	shrdl	$11,%r14d,%r14d
	xorl	%r8d,%r12d
	xorl	%r11d,%r15d
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%r9d
	andl	%r15d,%esi
	xorl	%r10d,%r14d
	addl	%r13d,%r9d
	xorl	%r11d,%esi
	addl	%r9d,%ebx
	shrdl	$2,%r14d,%r14d
	addl	%esi,%r9d
	movl	%ebx,%r13d
	addl	%r9d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r9d
	movl	%ecx,%r12d
	xorl	%ebx,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%edx,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r9d,%r14d
	andl	%ebx,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	48-128(%rdi),%xmm10
	xorl	%ebx,%r13d
	addl	12(%rsp),%r8d
	movl	%r9d,%esi
	shrdl	$11,%r14d,%r14d
	xorl	%edx,%r12d
	xorl	%r10d,%esi
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%r8d
	andl	%esi,%r15d
	xorl	%r9d,%r14d
	addl	%r13d,%r8d
	xorl	%r10d,%r15d
	addl	%r8d,%eax
	shrdl	$2,%r14d,%r14d
	addl	%r15d,%r8d
	movl	%eax,%r13d
	addl	%r8d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r8d
	movl	%ebx,%r12d
	xorl	%eax,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%ecx,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r8d,%r14d
	andl	%eax,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	64-128(%rdi),%xmm10
	xorl	%eax,%r13d
	addl	16(%rsp),%edx
	movl	%r8d,%r15d
	shrdl	$11,%r14d,%r14d
	xorl	%ecx,%r12d
	xorl	%r9d,%r15d
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%edx
	andl	%r15d,%esi
	xorl	%r8d,%r14d
	addl	%r13d,%edx
	xorl	%r9d,%esi
	addl	%edx,%r11d
	shrdl	$2,%r14d,%r14d
	addl	%esi,%edx
	movl	%r11d,%r13d
	addl	%edx,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%edx
	movl	%eax,%r12d
	xorl	%r11d,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%ebx,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%edx,%r14d
	andl	%r11d,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	80-128(%rdi),%xmm10
	xorl	%r11d,%r13d
	addl	20(%rsp),%ecx
	movl	%edx,%esi
	shrdl	$11,%r14d,%r14d
	xorl	%ebx,%r12d
	xorl	%r8d,%esi
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%ecx
	andl	%esi,%r15d
	xorl	%edx,%r14d
	addl	%r13d,%ecx
	xorl	%r8d,%r15d
	addl	%ecx,%r10d
	shrdl	$2,%r14d,%r14d
	addl	%r15d,%ecx
	movl	%r10d,%r13d
	addl	%ecx,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%ecx
	movl	%r11d,%r12d
	xorl	%r10d,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%eax,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%ecx,%r14d
	andl	%r10d,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	96-128(%rdi),%xmm10
	xorl	%r10d,%r13d
	addl	24(%rsp),%ebx
	movl	%ecx,%r15d
	shrdl	$11,%r14d,%r14d
	xorl	%eax,%r12d
	xorl	%edx,%r15d
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%ebx
	andl	%r15d,%esi
	xorl	%ecx,%r14d
	addl	%r13d,%ebx
	xorl	%edx,%esi
	addl	%ebx,%r9d
	shrdl	$2,%r14d,%r14d
	addl	%esi,%ebx
	movl	%r9d,%r13d
	addl	%ebx,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%ebx
	movl	%r10d,%r12d
	xorl	%r9d,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%r11d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%ebx,%r14d
	andl	%r9d,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	112-128(%rdi),%xmm10
	xorl	%r9d,%r13d
	addl	28(%rsp),%eax
	movl	%ebx,%esi
	shrdl	$11,%r14d,%r14d
	xorl	%r11d,%r12d
	xorl	%ecx,%esi
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%eax
	andl	%esi,%r15d
	xorl	%ebx,%r14d
	addl	%r13d,%eax
	xorl	%ecx,%r15d
	addl	%eax,%r8d
	shrdl	$2,%r14d,%r14d
	addl	%r15d,%eax
	movl	%r8d,%r13d
	addl	%eax,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%eax
	movl	%r9d,%r12d
	xorl	%r8d,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%r10d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%eax,%r14d
	andl	%r8d,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	128-128(%rdi),%xmm10
	xorl	%r8d,%r13d
	addl	32(%rsp),%r11d
	movl	%eax,%r15d
	shrdl	$11,%r14d,%r14d
	xorl	%r10d,%r12d
	xorl	%ebx,%r15d
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%r11d
	andl	%r15d,%esi
	xorl	%eax,%r14d
	addl	%r13d,%r11d
	xorl	%ebx,%esi
	addl	%r11d,%edx
	shrdl	$2,%r14d,%r14d
	addl	%esi,%r11d
	movl	%edx,%r13d
	addl	%r11d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r11d
	movl	%r8d,%r12d
	xorl	%edx,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%r9d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r11d,%r14d
	andl	%edx,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	144-128(%rdi),%xmm10
	xorl	%edx,%r13d
	addl	36(%rsp),%r10d
	movl	%r11d,%esi
	shrdl	$11,%r14d,%r14d
	xorl	%r9d,%r12d
	xorl	%eax,%esi
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%r10d
	andl	%esi,%r15d
	xorl	%r11d,%r14d
	addl	%r13d,%r10d
	xorl	%eax,%r15d
	addl	%r10d,%ecx
	shrdl	$2,%r14d,%r14d
	addl	%r15d,%r10d
	movl	%ecx,%r13d
	addl	%r10d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r10d
	movl	%edx,%r12d
	xorl	%ecx,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%r8d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r10d,%r14d
	andl	%ecx,%r12d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	160-128(%rdi),%xmm10
	xorl	%ecx,%r13d
	addl	40(%rsp),%r9d
	movl	%r10d,%r15d
	shrdl	$11,%r14d,%r14d
	xorl	%r8d,%r12d
	xorl	%r11d,%r15d
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%r9d
	andl	%r15d,%esi
	xorl	%r10d,%r14d
	addl	%r13d,%r9d
	xorl	%r11d,%esi
	addl	%r9d,%ebx
	shrdl	$2,%r14d,%r14d
	addl	%esi,%r9d
	movl	%ebx,%r13d
	addl	%r9d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r9d
	movl	%ecx,%r12d
	xorl	%ebx,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%edx,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r9d,%r14d
	andl	%ebx,%r12d
	vaesenclast	%xmm10,%xmm9,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	176-128(%rdi),%xmm10
	xorl	%ebx,%r13d
	addl	44(%rsp),%r8d
	movl	%r9d,%esi
	shrdl	$11,%r14d,%r14d
	xorl	%edx,%r12d
	xorl	%r10d,%esi
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%r8d
	andl	%esi,%r15d
	xorl	%r9d,%r14d
	addl	%r13d,%r8d
	xorl	%r10d,%r15d
	addl	%r8d,%eax
	shrdl	$2,%r14d,%r14d
	addl	%r15d,%r8d
	movl	%eax,%r13d
	addl	%r8d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r8d
	movl	%ebx,%r12d
	xorl	%eax,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%ecx,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r8d,%r14d
	andl	%eax,%r12d
	vpand	%xmm12,%xmm11,%xmm8
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	192-128(%rdi),%xmm10
	xorl	%eax,%r13d
	addl	48(%rsp),%edx
	movl	%r8d,%r15d
	shrdl	$11,%r14d,%r14d
	xorl	%ecx,%r12d
	xorl	%r9d,%r15d
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%edx
	andl	%r15d,%esi
	xorl	%r8d,%r14d
	addl	%r13d,%edx
	xorl	%r9d,%esi
	addl	%edx,%r11d
	shrdl	$2,%r14d,%r14d
	addl	%esi,%edx
	movl	%r11d,%r13d
	addl	%edx,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%edx
	movl	%eax,%r12d
	xorl	%r11d,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%ebx,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%edx,%r14d
	andl	%r11d,%r12d
	vaesenclast	%xmm10,%xmm9,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	208-128(%rdi),%xmm10
	xorl	%r11d,%r13d
	addl	52(%rsp),%ecx
	movl	%edx,%esi
	shrdl	$11,%r14d,%r14d
	xorl	%ebx,%r12d
	xorl	%r8d,%esi
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%ecx
	andl	%esi,%r15d
	xorl	%edx,%r14d
	addl	%r13d,%ecx
	xorl	%r8d,%r15d
	addl	%ecx,%r10d
	shrdl	$2,%r14d,%r14d
	addl	%r15d,%ecx
	movl	%r10d,%r13d
	addl	%ecx,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%ecx
	movl	%r11d,%r12d
	xorl	%r10d,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%eax,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%ecx,%r14d
	andl	%r10d,%r12d
	vpand	%xmm13,%xmm11,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	224-128(%rdi),%xmm10
	xorl	%r10d,%r13d
	addl	56(%rsp),%ebx
	movl	%ecx,%r15d
	shrdl	$11,%r14d,%r14d
	xorl	%eax,%r12d
	xorl	%edx,%r15d
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%ebx
	andl	%r15d,%esi
	xorl	%ecx,%r14d
	addl	%r13d,%ebx
	xorl	%edx,%esi
	addl	%ebx,%r9d
	shrdl	$2,%r14d,%r14d
	addl	%esi,%ebx
	movl	%r9d,%r13d
	addl	%ebx,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%ebx
	movl	%r10d,%r12d
	xorl	%r9d,%r13d
	shrdl	$9,%r14d,%r14d
	xorl	%r11d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%ebx,%r14d
	andl	%r9d,%r12d
	vpor	%xmm11,%xmm8,%xmm8
	vaesenclast	%xmm10,%xmm9,%xmm11
	vmovdqu	0-128(%rdi),%xmm10
	xorl	%r9d,%r13d
	addl	60(%rsp),%eax
	movl	%ebx,%esi
	shrdl	$11,%r14d,%r14d
	xorl	%r11d,%r12d
	xorl	%ecx,%esi
	shrdl	$6,%r13d,%r13d
	addl	%r12d,%eax
	andl	%esi,%r15d
	xorl	%ebx,%r14d
	addl	%r13d,%eax
	xorl	%ecx,%r15d
	addl	%eax,%r8d
	shrdl	$2,%r14d,%r14d
	addl	%r15d,%eax
	movl	%r8d,%r13d
	addl	%eax,%r14d
	movq	64+0(%rsp),%r12
	movq	64+8(%rsp),%r13
	movq	64+40(%rsp),%r15
	movq	64+48(%rsp),%rsi

	vpand	%xmm14,%xmm11,%xmm11
	movl	%r14d,%eax
	vpor	%xmm11,%xmm8,%xmm8
	vmovdqu	%xmm8,(%r12,%r13,1)
	leaq	16(%r12),%r12

	addl	0(%r15),%eax
	addl	4(%r15),%ebx
	addl	8(%r15),%ecx
	addl	12(%r15),%edx
	addl	16(%r15),%r8d
	addl	20(%r15),%r9d
	addl	24(%r15),%r10d
	addl	28(%r15),%r11d

	cmpq	64+16(%rsp),%r12

	movl	%eax,0(%r15)
	movl	%ebx,4(%r15)
	movl	%ecx,8(%r15)
	movl	%edx,12(%r15)
	movl	%r8d,16(%r15)
	movl	%r9d,20(%r15)
	movl	%r10d,24(%r15)
	movl	%r11d,28(%r15)
	jb	.Lloop_avx

	movq	64+32(%rsp),%r8
	movq	120(%rsp),%rsi
.cfi_def_cfa	%rsi,8
	vmovdqu	%xmm8,(%r8)
	vzeroall
	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue_avx:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_cbc_sha256_enc_avx,.-aesni_cbc_sha256_enc_avx
.type	aesni_cbc_sha256_enc_avx2,@function
.align	64
aesni_cbc_sha256_enc_avx2:
.cfi_startproc	
.Lavx2_shortcut:
	movq	8(%rsp),%r10
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
	subq	$576,%rsp
	andq	$-1024,%rsp
	addq	$448,%rsp

	shlq	$6,%rdx
	subq	%rdi,%rsi
	subq	%rdi,%r10
	addq	%rdi,%rdx



	movq	%rdx,64+16(%rsp)

	movq	%r8,64+32(%rsp)
	movq	%r9,64+40(%rsp)
	movq	%r10,64+48(%rsp)
	movq	%rax,120(%rsp)
.cfi_escape	0x0f,0x06,0x77,0xf8,0x00,0x06,0x23,0x08
.Lprologue_avx2:
	vzeroall

	movq	%rdi,%r13
	vpinsrq	$1,%rsi,%xmm15,%xmm15
	leaq	128(%rcx),%rdi
	leaq	K256+544(%rip),%r12
	movl	240-128(%rdi),%r14d
	movq	%r9,%r15
	movq	%r10,%rsi
	vmovdqu	(%r8),%xmm8
	leaq	-9(%r14),%r14

	vmovdqa	0(%r12,%r14,8),%xmm14
	vmovdqa	16(%r12,%r14,8),%xmm13
	vmovdqa	32(%r12,%r14,8),%xmm12

	subq	$-64,%r13
	movl	0(%r15),%eax
	leaq	(%rsi,%r13,1),%r12
	movl	4(%r15),%ebx
	cmpq	%rdx,%r13
	movl	8(%r15),%ecx
	cmoveq	%rsp,%r12
	movl	12(%r15),%edx
	movl	16(%r15),%r8d
	movl	20(%r15),%r9d
	movl	24(%r15),%r10d
	movl	28(%r15),%r11d
	vmovdqu	0-128(%rdi),%xmm10
	jmp	.Loop_avx2
.align	16
.Loop_avx2:
	vmovdqa	K256+512(%rip),%ymm7
	vmovdqu	-64+0(%rsi,%r13,1),%xmm0
	vmovdqu	-64+16(%rsi,%r13,1),%xmm1
	vmovdqu	-64+32(%rsi,%r13,1),%xmm2
	vmovdqu	-64+48(%rsi,%r13,1),%xmm3

	vinserti128	$1,(%r12),%ymm0,%ymm0
	vinserti128	$1,16(%r12),%ymm1,%ymm1
	vpshufb	%ymm7,%ymm0,%ymm0
	vinserti128	$1,32(%r12),%ymm2,%ymm2
	vpshufb	%ymm7,%ymm1,%ymm1
	vinserti128	$1,48(%r12),%ymm3,%ymm3

	leaq	K256(%rip),%rbp
	vpshufb	%ymm7,%ymm2,%ymm2
	leaq	-64(%r13),%r13
	vpaddd	0(%rbp),%ymm0,%ymm4
	vpshufb	%ymm7,%ymm3,%ymm3
	vpaddd	32(%rbp),%ymm1,%ymm5
	vpaddd	64(%rbp),%ymm2,%ymm6
	vpaddd	96(%rbp),%ymm3,%ymm7
	vmovdqa	%ymm4,0(%rsp)
	xorl	%r14d,%r14d
	vmovdqa	%ymm5,32(%rsp)

	movq	120(%rsp),%rsi
.cfi_def_cfa	%rsi,8
	leaq	-64(%rsp),%rsp



	movq	%rsi,-8(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x78,0x06,0x23,0x08
	movl	%ebx,%esi
	vmovdqa	%ymm6,0(%rsp)
	xorl	%ecx,%esi
	vmovdqa	%ymm7,32(%rsp)
	movl	%r9d,%r12d
	subq	$-32*4,%rbp
	jmp	.Lavx2_00_47

.align	16
.Lavx2_00_47:
	vmovdqu	(%r13),%xmm9
	vpinsrq	$0,%r13,%xmm15,%xmm15
	leaq	-64(%rsp),%rsp
.cfi_escape	0x0f,0x05,0x77,0x38,0x06,0x23,0x08

	pushq	64-8(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x00,0x06,0x23,0x08
	leaq	8(%rsp),%rsp
.cfi_escape	0x0f,0x05,0x77,0x78,0x06,0x23,0x08
	vpalignr	$4,%ymm0,%ymm1,%ymm4
	addl	0+128(%rsp),%r11d
	andl	%r8d,%r12d
	rorxl	$25,%r8d,%r13d
	vpalignr	$4,%ymm2,%ymm3,%ymm7
	rorxl	$11,%r8d,%r15d
	leal	(%rax,%r14,1),%eax
	leal	(%r11,%r12,1),%r11d
	vpsrld	$7,%ymm4,%ymm6
	andnl	%r10d,%r8d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r8d,%r14d
	vpaddd	%ymm7,%ymm0,%ymm0
	leal	(%r11,%r12,1),%r11d
	xorl	%r14d,%r13d
	movl	%eax,%r15d
	vpsrld	$3,%ymm4,%ymm7
	rorxl	$22,%eax,%r12d
	leal	(%r11,%r13,1),%r11d
	xorl	%ebx,%r15d
	vpslld	$14,%ymm4,%ymm5
	rorxl	$13,%eax,%r14d
	rorxl	$2,%eax,%r13d
	leal	(%rdx,%r11,1),%edx
	vpxor	%ymm6,%ymm7,%ymm4
	andl	%r15d,%esi
	vpxor	%xmm10,%xmm9,%xmm9
	vmovdqu	16-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%ebx,%esi
	vpshufd	$250,%ymm3,%ymm7
	xorl	%r13d,%r14d
	leal	(%r11,%rsi,1),%r11d
	movl	%r8d,%r12d
	vpsrld	$11,%ymm6,%ymm6
	addl	4+128(%rsp),%r10d
	andl	%edx,%r12d
	rorxl	$25,%edx,%r13d
	vpxor	%ymm5,%ymm4,%ymm4
	rorxl	$11,%edx,%esi
	leal	(%r11,%r14,1),%r11d
	leal	(%r10,%r12,1),%r10d
	vpslld	$11,%ymm5,%ymm5
	andnl	%r9d,%edx,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%edx,%r14d
	vpxor	%ymm6,%ymm4,%ymm4
	leal	(%r10,%r12,1),%r10d
	xorl	%r14d,%r13d
	movl	%r11d,%esi
	vpsrld	$10,%ymm7,%ymm6
	rorxl	$22,%r11d,%r12d
	leal	(%r10,%r13,1),%r10d
	xorl	%eax,%esi
	vpxor	%ymm5,%ymm4,%ymm4
	rorxl	$13,%r11d,%r14d
	rorxl	$2,%r11d,%r13d
	leal	(%rcx,%r10,1),%ecx
	vpsrlq	$17,%ymm7,%ymm7
	andl	%esi,%r15d
	vpxor	%xmm8,%xmm9,%xmm9
	xorl	%r12d,%r14d
	xorl	%eax,%r15d
	vpaddd	%ymm4,%ymm0,%ymm0
	xorl	%r13d,%r14d
	leal	(%r10,%r15,1),%r10d
	movl	%edx,%r12d
	vpxor	%ymm7,%ymm6,%ymm6
	addl	8+128(%rsp),%r9d
	andl	%ecx,%r12d
	rorxl	$25,%ecx,%r13d
	vpsrlq	$2,%ymm7,%ymm7
	rorxl	$11,%ecx,%r15d
	leal	(%r10,%r14,1),%r10d
	leal	(%r9,%r12,1),%r9d
	vpxor	%ymm7,%ymm6,%ymm6
	andnl	%r8d,%ecx,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%ecx,%r14d
	vpshufd	$132,%ymm6,%ymm6
	leal	(%r9,%r12,1),%r9d
	xorl	%r14d,%r13d
	movl	%r10d,%r15d
	vpsrldq	$8,%ymm6,%ymm6
	rorxl	$22,%r10d,%r12d
	leal	(%r9,%r13,1),%r9d
	xorl	%r11d,%r15d
	vpaddd	%ymm6,%ymm0,%ymm0
	rorxl	$13,%r10d,%r14d
	rorxl	$2,%r10d,%r13d
	leal	(%rbx,%r9,1),%ebx
	vpshufd	$80,%ymm0,%ymm7
	andl	%r15d,%esi
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	32-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r11d,%esi
	vpsrld	$10,%ymm7,%ymm6
	xorl	%r13d,%r14d
	leal	(%r9,%rsi,1),%r9d
	movl	%ecx,%r12d
	vpsrlq	$17,%ymm7,%ymm7
	addl	12+128(%rsp),%r8d
	andl	%ebx,%r12d
	rorxl	$25,%ebx,%r13d
	vpxor	%ymm7,%ymm6,%ymm6
	rorxl	$11,%ebx,%esi
	leal	(%r9,%r14,1),%r9d
	leal	(%r8,%r12,1),%r8d
	vpsrlq	$2,%ymm7,%ymm7
	andnl	%edx,%ebx,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%ebx,%r14d
	vpxor	%ymm7,%ymm6,%ymm6
	leal	(%r8,%r12,1),%r8d
	xorl	%r14d,%r13d
	movl	%r9d,%esi
	vpshufd	$232,%ymm6,%ymm6
	rorxl	$22,%r9d,%r12d
	leal	(%r8,%r13,1),%r8d
	xorl	%r10d,%esi
	vpslldq	$8,%ymm6,%ymm6
	rorxl	$13,%r9d,%r14d
	rorxl	$2,%r9d,%r13d
	leal	(%rax,%r8,1),%eax
	vpaddd	%ymm6,%ymm0,%ymm0
	andl	%esi,%r15d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	48-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r10d,%r15d
	vpaddd	0(%rbp),%ymm0,%ymm6
	xorl	%r13d,%r14d
	leal	(%r8,%r15,1),%r8d
	movl	%ebx,%r12d
	vmovdqa	%ymm6,0(%rsp)
	vpalignr	$4,%ymm1,%ymm2,%ymm4
	addl	32+128(%rsp),%edx
	andl	%eax,%r12d
	rorxl	$25,%eax,%r13d
	vpalignr	$4,%ymm3,%ymm0,%ymm7
	rorxl	$11,%eax,%r15d
	leal	(%r8,%r14,1),%r8d
	leal	(%rdx,%r12,1),%edx
	vpsrld	$7,%ymm4,%ymm6
	andnl	%ecx,%eax,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%eax,%r14d
	vpaddd	%ymm7,%ymm1,%ymm1
	leal	(%rdx,%r12,1),%edx
	xorl	%r14d,%r13d
	movl	%r8d,%r15d
	vpsrld	$3,%ymm4,%ymm7
	rorxl	$22,%r8d,%r12d
	leal	(%rdx,%r13,1),%edx
	xorl	%r9d,%r15d
	vpslld	$14,%ymm4,%ymm5
	rorxl	$13,%r8d,%r14d
	rorxl	$2,%r8d,%r13d
	leal	(%r11,%rdx,1),%r11d
	vpxor	%ymm6,%ymm7,%ymm4
	andl	%r15d,%esi
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	64-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r9d,%esi
	vpshufd	$250,%ymm0,%ymm7
	xorl	%r13d,%r14d
	leal	(%rdx,%rsi,1),%edx
	movl	%eax,%r12d
	vpsrld	$11,%ymm6,%ymm6
	addl	36+128(%rsp),%ecx
	andl	%r11d,%r12d
	rorxl	$25,%r11d,%r13d
	vpxor	%ymm5,%ymm4,%ymm4
	rorxl	$11,%r11d,%esi
	leal	(%rdx,%r14,1),%edx
	leal	(%rcx,%r12,1),%ecx
	vpslld	$11,%ymm5,%ymm5
	andnl	%ebx,%r11d,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%r11d,%r14d
	vpxor	%ymm6,%ymm4,%ymm4
	leal	(%rcx,%r12,1),%ecx
	xorl	%r14d,%r13d
	movl	%edx,%esi
	vpsrld	$10,%ymm7,%ymm6
	rorxl	$22,%edx,%r12d
	leal	(%rcx,%r13,1),%ecx
	xorl	%r8d,%esi
	vpxor	%ymm5,%ymm4,%ymm4
	rorxl	$13,%edx,%r14d
	rorxl	$2,%edx,%r13d
	leal	(%r10,%rcx,1),%r10d
	vpsrlq	$17,%ymm7,%ymm7
	andl	%esi,%r15d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	80-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r8d,%r15d
	vpaddd	%ymm4,%ymm1,%ymm1
	xorl	%r13d,%r14d
	leal	(%rcx,%r15,1),%ecx
	movl	%r11d,%r12d
	vpxor	%ymm7,%ymm6,%ymm6
	addl	40+128(%rsp),%ebx
	andl	%r10d,%r12d
	rorxl	$25,%r10d,%r13d
	vpsrlq	$2,%ymm7,%ymm7
	rorxl	$11,%r10d,%r15d
	leal	(%rcx,%r14,1),%ecx
	leal	(%rbx,%r12,1),%ebx
	vpxor	%ymm7,%ymm6,%ymm6
	andnl	%eax,%r10d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r10d,%r14d
	vpshufd	$132,%ymm6,%ymm6
	leal	(%rbx,%r12,1),%ebx
	xorl	%r14d,%r13d
	movl	%ecx,%r15d
	vpsrldq	$8,%ymm6,%ymm6
	rorxl	$22,%ecx,%r12d
	leal	(%rbx,%r13,1),%ebx
	xorl	%edx,%r15d
	vpaddd	%ymm6,%ymm1,%ymm1
	rorxl	$13,%ecx,%r14d
	rorxl	$2,%ecx,%r13d
	leal	(%r9,%rbx,1),%r9d
	vpshufd	$80,%ymm1,%ymm7
	andl	%r15d,%esi
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	96-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%edx,%esi
	vpsrld	$10,%ymm7,%ymm6
	xorl	%r13d,%r14d
	leal	(%rbx,%rsi,1),%ebx
	movl	%r10d,%r12d
	vpsrlq	$17,%ymm7,%ymm7
	addl	44+128(%rsp),%eax
	andl	%r9d,%r12d
	rorxl	$25,%r9d,%r13d
	vpxor	%ymm7,%ymm6,%ymm6
	rorxl	$11,%r9d,%esi
	leal	(%rbx,%r14,1),%ebx
	leal	(%rax,%r12,1),%eax
	vpsrlq	$2,%ymm7,%ymm7
	andnl	%r11d,%r9d,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%r9d,%r14d
	vpxor	%ymm7,%ymm6,%ymm6
	leal	(%rax,%r12,1),%eax
	xorl	%r14d,%r13d
	movl	%ebx,%esi
	vpshufd	$232,%ymm6,%ymm6
	rorxl	$22,%ebx,%r12d
	leal	(%rax,%r13,1),%eax
	xorl	%ecx,%esi
	vpslldq	$8,%ymm6,%ymm6
	rorxl	$13,%ebx,%r14d
	rorxl	$2,%ebx,%r13d
	leal	(%r8,%rax,1),%r8d
	vpaddd	%ymm6,%ymm1,%ymm1
	andl	%esi,%r15d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	112-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%ecx,%r15d
	vpaddd	32(%rbp),%ymm1,%ymm6
	xorl	%r13d,%r14d
	leal	(%rax,%r15,1),%eax
	movl	%r9d,%r12d
	vmovdqa	%ymm6,32(%rsp)
	leaq	-64(%rsp),%rsp
.cfi_escape	0x0f,0x05,0x77,0x38,0x06,0x23,0x08

	pushq	64-8(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x00,0x06,0x23,0x08
	leaq	8(%rsp),%rsp
.cfi_escape	0x0f,0x05,0x77,0x78,0x06,0x23,0x08
	vpalignr	$4,%ymm2,%ymm3,%ymm4
	addl	0+128(%rsp),%r11d
	andl	%r8d,%r12d
	rorxl	$25,%r8d,%r13d
	vpalignr	$4,%ymm0,%ymm1,%ymm7
	rorxl	$11,%r8d,%r15d
	leal	(%rax,%r14,1),%eax
	leal	(%r11,%r12,1),%r11d
	vpsrld	$7,%ymm4,%ymm6
	andnl	%r10d,%r8d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r8d,%r14d
	vpaddd	%ymm7,%ymm2,%ymm2
	leal	(%r11,%r12,1),%r11d
	xorl	%r14d,%r13d
	movl	%eax,%r15d
	vpsrld	$3,%ymm4,%ymm7
	rorxl	$22,%eax,%r12d
	leal	(%r11,%r13,1),%r11d
	xorl	%ebx,%r15d
	vpslld	$14,%ymm4,%ymm5
	rorxl	$13,%eax,%r14d
	rorxl	$2,%eax,%r13d
	leal	(%rdx,%r11,1),%edx
	vpxor	%ymm6,%ymm7,%ymm4
	andl	%r15d,%esi
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	128-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%ebx,%esi
	vpshufd	$250,%ymm1,%ymm7
	xorl	%r13d,%r14d
	leal	(%r11,%rsi,1),%r11d
	movl	%r8d,%r12d
	vpsrld	$11,%ymm6,%ymm6
	addl	4+128(%rsp),%r10d
	andl	%edx,%r12d
	rorxl	$25,%edx,%r13d
	vpxor	%ymm5,%ymm4,%ymm4
	rorxl	$11,%edx,%esi
	leal	(%r11,%r14,1),%r11d
	leal	(%r10,%r12,1),%r10d
	vpslld	$11,%ymm5,%ymm5
	andnl	%r9d,%edx,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%edx,%r14d
	vpxor	%ymm6,%ymm4,%ymm4
	leal	(%r10,%r12,1),%r10d
	xorl	%r14d,%r13d
	movl	%r11d,%esi
	vpsrld	$10,%ymm7,%ymm6
	rorxl	$22,%r11d,%r12d
	leal	(%r10,%r13,1),%r10d
	xorl	%eax,%esi
	vpxor	%ymm5,%ymm4,%ymm4
	rorxl	$13,%r11d,%r14d
	rorxl	$2,%r11d,%r13d
	leal	(%rcx,%r10,1),%ecx
	vpsrlq	$17,%ymm7,%ymm7
	andl	%esi,%r15d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	144-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%eax,%r15d
	vpaddd	%ymm4,%ymm2,%ymm2
	xorl	%r13d,%r14d
	leal	(%r10,%r15,1),%r10d
	movl	%edx,%r12d
	vpxor	%ymm7,%ymm6,%ymm6
	addl	8+128(%rsp),%r9d
	andl	%ecx,%r12d
	rorxl	$25,%ecx,%r13d
	vpsrlq	$2,%ymm7,%ymm7
	rorxl	$11,%ecx,%r15d
	leal	(%r10,%r14,1),%r10d
	leal	(%r9,%r12,1),%r9d
	vpxor	%ymm7,%ymm6,%ymm6
	andnl	%r8d,%ecx,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%ecx,%r14d
	vpshufd	$132,%ymm6,%ymm6
	leal	(%r9,%r12,1),%r9d
	xorl	%r14d,%r13d
	movl	%r10d,%r15d
	vpsrldq	$8,%ymm6,%ymm6
	rorxl	$22,%r10d,%r12d
	leal	(%r9,%r13,1),%r9d
	xorl	%r11d,%r15d
	vpaddd	%ymm6,%ymm2,%ymm2
	rorxl	$13,%r10d,%r14d
	rorxl	$2,%r10d,%r13d
	leal	(%rbx,%r9,1),%ebx
	vpshufd	$80,%ymm2,%ymm7
	andl	%r15d,%esi
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	160-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r11d,%esi
	vpsrld	$10,%ymm7,%ymm6
	xorl	%r13d,%r14d
	leal	(%r9,%rsi,1),%r9d
	movl	%ecx,%r12d
	vpsrlq	$17,%ymm7,%ymm7
	addl	12+128(%rsp),%r8d
	andl	%ebx,%r12d
	rorxl	$25,%ebx,%r13d
	vpxor	%ymm7,%ymm6,%ymm6
	rorxl	$11,%ebx,%esi
	leal	(%r9,%r14,1),%r9d
	leal	(%r8,%r12,1),%r8d
	vpsrlq	$2,%ymm7,%ymm7
	andnl	%edx,%ebx,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%ebx,%r14d
	vpxor	%ymm7,%ymm6,%ymm6
	leal	(%r8,%r12,1),%r8d
	xorl	%r14d,%r13d
	movl	%r9d,%esi
	vpshufd	$232,%ymm6,%ymm6
	rorxl	$22,%r9d,%r12d
	leal	(%r8,%r13,1),%r8d
	xorl	%r10d,%esi
	vpslldq	$8,%ymm6,%ymm6
	rorxl	$13,%r9d,%r14d
	rorxl	$2,%r9d,%r13d
	leal	(%rax,%r8,1),%eax
	vpaddd	%ymm6,%ymm2,%ymm2
	andl	%esi,%r15d
	vaesenclast	%xmm10,%xmm9,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	176-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r10d,%r15d
	vpaddd	64(%rbp),%ymm2,%ymm6
	xorl	%r13d,%r14d
	leal	(%r8,%r15,1),%r8d
	movl	%ebx,%r12d
	vmovdqa	%ymm6,0(%rsp)
	vpalignr	$4,%ymm3,%ymm0,%ymm4
	addl	32+128(%rsp),%edx
	andl	%eax,%r12d
	rorxl	$25,%eax,%r13d
	vpalignr	$4,%ymm1,%ymm2,%ymm7
	rorxl	$11,%eax,%r15d
	leal	(%r8,%r14,1),%r8d
	leal	(%rdx,%r12,1),%edx
	vpsrld	$7,%ymm4,%ymm6
	andnl	%ecx,%eax,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%eax,%r14d
	vpaddd	%ymm7,%ymm3,%ymm3
	leal	(%rdx,%r12,1),%edx
	xorl	%r14d,%r13d
	movl	%r8d,%r15d
	vpsrld	$3,%ymm4,%ymm7
	rorxl	$22,%r8d,%r12d
	leal	(%rdx,%r13,1),%edx
	xorl	%r9d,%r15d
	vpslld	$14,%ymm4,%ymm5
	rorxl	$13,%r8d,%r14d
	rorxl	$2,%r8d,%r13d
	leal	(%r11,%rdx,1),%r11d
	vpxor	%ymm6,%ymm7,%ymm4
	andl	%r15d,%esi
	vpand	%xmm12,%xmm11,%xmm8
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	192-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r9d,%esi
	vpshufd	$250,%ymm2,%ymm7
	xorl	%r13d,%r14d
	leal	(%rdx,%rsi,1),%edx
	movl	%eax,%r12d
	vpsrld	$11,%ymm6,%ymm6
	addl	36+128(%rsp),%ecx
	andl	%r11d,%r12d
	rorxl	$25,%r11d,%r13d
	vpxor	%ymm5,%ymm4,%ymm4
	rorxl	$11,%r11d,%esi
	leal	(%rdx,%r14,1),%edx
	leal	(%rcx,%r12,1),%ecx
	vpslld	$11,%ymm5,%ymm5
	andnl	%ebx,%r11d,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%r11d,%r14d
	vpxor	%ymm6,%ymm4,%ymm4
	leal	(%rcx,%r12,1),%ecx
	xorl	%r14d,%r13d
	movl	%edx,%esi
	vpsrld	$10,%ymm7,%ymm6
	rorxl	$22,%edx,%r12d
	leal	(%rcx,%r13,1),%ecx
	xorl	%r8d,%esi
	vpxor	%ymm5,%ymm4,%ymm4
	rorxl	$13,%edx,%r14d
	rorxl	$2,%edx,%r13d
	leal	(%r10,%rcx,1),%r10d
	vpsrlq	$17,%ymm7,%ymm7
	andl	%esi,%r15d
	vaesenclast	%xmm10,%xmm9,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	208-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r8d,%r15d
	vpaddd	%ymm4,%ymm3,%ymm3
	xorl	%r13d,%r14d
	leal	(%rcx,%r15,1),%ecx
	movl	%r11d,%r12d
	vpxor	%ymm7,%ymm6,%ymm6
	addl	40+128(%rsp),%ebx
	andl	%r10d,%r12d
	rorxl	$25,%r10d,%r13d
	vpsrlq	$2,%ymm7,%ymm7
	rorxl	$11,%r10d,%r15d
	leal	(%rcx,%r14,1),%ecx
	leal	(%rbx,%r12,1),%ebx
	vpxor	%ymm7,%ymm6,%ymm6
	andnl	%eax,%r10d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r10d,%r14d
	vpshufd	$132,%ymm6,%ymm6
	leal	(%rbx,%r12,1),%ebx
	xorl	%r14d,%r13d
	movl	%ecx,%r15d
	vpsrldq	$8,%ymm6,%ymm6
	rorxl	$22,%ecx,%r12d
	leal	(%rbx,%r13,1),%ebx
	xorl	%edx,%r15d
	vpaddd	%ymm6,%ymm3,%ymm3
	rorxl	$13,%ecx,%r14d
	rorxl	$2,%ecx,%r13d
	leal	(%r9,%rbx,1),%r9d
	vpshufd	$80,%ymm3,%ymm7
	andl	%r15d,%esi
	vpand	%xmm13,%xmm11,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	224-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%edx,%esi
	vpsrld	$10,%ymm7,%ymm6
	xorl	%r13d,%r14d
	leal	(%rbx,%rsi,1),%ebx
	movl	%r10d,%r12d
	vpsrlq	$17,%ymm7,%ymm7
	addl	44+128(%rsp),%eax
	andl	%r9d,%r12d
	rorxl	$25,%r9d,%r13d
	vpxor	%ymm7,%ymm6,%ymm6
	rorxl	$11,%r9d,%esi
	leal	(%rbx,%r14,1),%ebx
	leal	(%rax,%r12,1),%eax
	vpsrlq	$2,%ymm7,%ymm7
	andnl	%r11d,%r9d,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%r9d,%r14d
	vpxor	%ymm7,%ymm6,%ymm6
	leal	(%rax,%r12,1),%eax
	xorl	%r14d,%r13d
	movl	%ebx,%esi
	vpshufd	$232,%ymm6,%ymm6
	rorxl	$22,%ebx,%r12d
	leal	(%rax,%r13,1),%eax
	xorl	%ecx,%esi
	vpslldq	$8,%ymm6,%ymm6
	rorxl	$13,%ebx,%r14d
	rorxl	$2,%ebx,%r13d
	leal	(%r8,%rax,1),%r8d
	vpaddd	%ymm6,%ymm3,%ymm3
	andl	%esi,%r15d
	vpor	%xmm11,%xmm8,%xmm8
	vaesenclast	%xmm10,%xmm9,%xmm11
	vmovdqu	0-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%ecx,%r15d
	vpaddd	96(%rbp),%ymm3,%ymm6
	xorl	%r13d,%r14d
	leal	(%rax,%r15,1),%eax
	movl	%r9d,%r12d
	vmovdqa	%ymm6,32(%rsp)
	vmovq	%xmm15,%r13
	vpextrq	$1,%xmm15,%r15
	vpand	%xmm14,%xmm11,%xmm11
	vpor	%xmm11,%xmm8,%xmm8
	vmovdqu	%xmm8,(%r15,%r13,1)
	leaq	16(%r13),%r13
	leaq	128(%rbp),%rbp
	cmpb	$0,3(%rbp)
	jne	.Lavx2_00_47
	vmovdqu	(%r13),%xmm9
	vpinsrq	$0,%r13,%xmm15,%xmm15
	addl	0+64(%rsp),%r11d
	andl	%r8d,%r12d
	rorxl	$25,%r8d,%r13d
	rorxl	$11,%r8d,%r15d
	leal	(%rax,%r14,1),%eax
	leal	(%r11,%r12,1),%r11d
	andnl	%r10d,%r8d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r8d,%r14d
	leal	(%r11,%r12,1),%r11d
	xorl	%r14d,%r13d
	movl	%eax,%r15d
	rorxl	$22,%eax,%r12d
	leal	(%r11,%r13,1),%r11d
	xorl	%ebx,%r15d
	rorxl	$13,%eax,%r14d
	rorxl	$2,%eax,%r13d
	leal	(%rdx,%r11,1),%edx
	andl	%r15d,%esi
	vpxor	%xmm10,%xmm9,%xmm9
	vmovdqu	16-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%ebx,%esi
	xorl	%r13d,%r14d
	leal	(%r11,%rsi,1),%r11d
	movl	%r8d,%r12d
	addl	4+64(%rsp),%r10d
	andl	%edx,%r12d
	rorxl	$25,%edx,%r13d
	rorxl	$11,%edx,%esi
	leal	(%r11,%r14,1),%r11d
	leal	(%r10,%r12,1),%r10d
	andnl	%r9d,%edx,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%edx,%r14d
	leal	(%r10,%r12,1),%r10d
	xorl	%r14d,%r13d
	movl	%r11d,%esi
	rorxl	$22,%r11d,%r12d
	leal	(%r10,%r13,1),%r10d
	xorl	%eax,%esi
	rorxl	$13,%r11d,%r14d
	rorxl	$2,%r11d,%r13d
	leal	(%rcx,%r10,1),%ecx
	andl	%esi,%r15d
	vpxor	%xmm8,%xmm9,%xmm9
	xorl	%r12d,%r14d
	xorl	%eax,%r15d
	xorl	%r13d,%r14d
	leal	(%r10,%r15,1),%r10d
	movl	%edx,%r12d
	addl	8+64(%rsp),%r9d
	andl	%ecx,%r12d
	rorxl	$25,%ecx,%r13d
	rorxl	$11,%ecx,%r15d
	leal	(%r10,%r14,1),%r10d
	leal	(%r9,%r12,1),%r9d
	andnl	%r8d,%ecx,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%ecx,%r14d
	leal	(%r9,%r12,1),%r9d
	xorl	%r14d,%r13d
	movl	%r10d,%r15d
	rorxl	$22,%r10d,%r12d
	leal	(%r9,%r13,1),%r9d
	xorl	%r11d,%r15d
	rorxl	$13,%r10d,%r14d
	rorxl	$2,%r10d,%r13d
	leal	(%rbx,%r9,1),%ebx
	andl	%r15d,%esi
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	32-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r11d,%esi
	xorl	%r13d,%r14d
	leal	(%r9,%rsi,1),%r9d
	movl	%ecx,%r12d
	addl	12+64(%rsp),%r8d
	andl	%ebx,%r12d
	rorxl	$25,%ebx,%r13d
	rorxl	$11,%ebx,%esi
	leal	(%r9,%r14,1),%r9d
	leal	(%r8,%r12,1),%r8d
	andnl	%edx,%ebx,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%ebx,%r14d
	leal	(%r8,%r12,1),%r8d
	xorl	%r14d,%r13d
	movl	%r9d,%esi
	rorxl	$22,%r9d,%r12d
	leal	(%r8,%r13,1),%r8d
	xorl	%r10d,%esi
	rorxl	$13,%r9d,%r14d
	rorxl	$2,%r9d,%r13d
	leal	(%rax,%r8,1),%eax
	andl	%esi,%r15d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	48-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r10d,%r15d
	xorl	%r13d,%r14d
	leal	(%r8,%r15,1),%r8d
	movl	%ebx,%r12d
	addl	32+64(%rsp),%edx
	andl	%eax,%r12d
	rorxl	$25,%eax,%r13d
	rorxl	$11,%eax,%r15d
	leal	(%r8,%r14,1),%r8d
	leal	(%rdx,%r12,1),%edx
	andnl	%ecx,%eax,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%eax,%r14d
	leal	(%rdx,%r12,1),%edx
	xorl	%r14d,%r13d
	movl	%r8d,%r15d
	rorxl	$22,%r8d,%r12d
	leal	(%rdx,%r13,1),%edx
	xorl	%r9d,%r15d
	rorxl	$13,%r8d,%r14d
	rorxl	$2,%r8d,%r13d
	leal	(%r11,%rdx,1),%r11d
	andl	%r15d,%esi
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	64-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r9d,%esi
	xorl	%r13d,%r14d
	leal	(%rdx,%rsi,1),%edx
	movl	%eax,%r12d
	addl	36+64(%rsp),%ecx
	andl	%r11d,%r12d
	rorxl	$25,%r11d,%r13d
	rorxl	$11,%r11d,%esi
	leal	(%rdx,%r14,1),%edx
	leal	(%rcx,%r12,1),%ecx
	andnl	%ebx,%r11d,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%r11d,%r14d
	leal	(%rcx,%r12,1),%ecx
	xorl	%r14d,%r13d
	movl	%edx,%esi
	rorxl	$22,%edx,%r12d
	leal	(%rcx,%r13,1),%ecx
	xorl	%r8d,%esi
	rorxl	$13,%edx,%r14d
	rorxl	$2,%edx,%r13d
	leal	(%r10,%rcx,1),%r10d
	andl	%esi,%r15d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	80-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r8d,%r15d
	xorl	%r13d,%r14d
	leal	(%rcx,%r15,1),%ecx
	movl	%r11d,%r12d
	addl	40+64(%rsp),%ebx
	andl	%r10d,%r12d
	rorxl	$25,%r10d,%r13d
	rorxl	$11,%r10d,%r15d
	leal	(%rcx,%r14,1),%ecx
	leal	(%rbx,%r12,1),%ebx
	andnl	%eax,%r10d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r10d,%r14d
	leal	(%rbx,%r12,1),%ebx
	xorl	%r14d,%r13d
	movl	%ecx,%r15d
	rorxl	$22,%ecx,%r12d
	leal	(%rbx,%r13,1),%ebx
	xorl	%edx,%r15d
	rorxl	$13,%ecx,%r14d
	rorxl	$2,%ecx,%r13d
	leal	(%r9,%rbx,1),%r9d
	andl	%r15d,%esi
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	96-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%edx,%esi
	xorl	%r13d,%r14d
	leal	(%rbx,%rsi,1),%ebx
	movl	%r10d,%r12d
	addl	44+64(%rsp),%eax
	andl	%r9d,%r12d
	rorxl	$25,%r9d,%r13d
	rorxl	$11,%r9d,%esi
	leal	(%rbx,%r14,1),%ebx
	leal	(%rax,%r12,1),%eax
	andnl	%r11d,%r9d,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%r9d,%r14d
	leal	(%rax,%r12,1),%eax
	xorl	%r14d,%r13d
	movl	%ebx,%esi
	rorxl	$22,%ebx,%r12d
	leal	(%rax,%r13,1),%eax
	xorl	%ecx,%esi
	rorxl	$13,%ebx,%r14d
	rorxl	$2,%ebx,%r13d
	leal	(%r8,%rax,1),%r8d
	andl	%esi,%r15d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	112-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%ecx,%r15d
	xorl	%r13d,%r14d
	leal	(%rax,%r15,1),%eax
	movl	%r9d,%r12d
	addl	0(%rsp),%r11d
	andl	%r8d,%r12d
	rorxl	$25,%r8d,%r13d
	rorxl	$11,%r8d,%r15d
	leal	(%rax,%r14,1),%eax
	leal	(%r11,%r12,1),%r11d
	andnl	%r10d,%r8d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r8d,%r14d
	leal	(%r11,%r12,1),%r11d
	xorl	%r14d,%r13d
	movl	%eax,%r15d
	rorxl	$22,%eax,%r12d
	leal	(%r11,%r13,1),%r11d
	xorl	%ebx,%r15d
	rorxl	$13,%eax,%r14d
	rorxl	$2,%eax,%r13d
	leal	(%rdx,%r11,1),%edx
	andl	%r15d,%esi
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	128-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%ebx,%esi
	xorl	%r13d,%r14d
	leal	(%r11,%rsi,1),%r11d
	movl	%r8d,%r12d
	addl	4(%rsp),%r10d
	andl	%edx,%r12d
	rorxl	$25,%edx,%r13d
	rorxl	$11,%edx,%esi
	leal	(%r11,%r14,1),%r11d
	leal	(%r10,%r12,1),%r10d
	andnl	%r9d,%edx,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%edx,%r14d
	leal	(%r10,%r12,1),%r10d
	xorl	%r14d,%r13d
	movl	%r11d,%esi
	rorxl	$22,%r11d,%r12d
	leal	(%r10,%r13,1),%r10d
	xorl	%eax,%esi
	rorxl	$13,%r11d,%r14d
	rorxl	$2,%r11d,%r13d
	leal	(%rcx,%r10,1),%ecx
	andl	%esi,%r15d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	144-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%eax,%r15d
	xorl	%r13d,%r14d
	leal	(%r10,%r15,1),%r10d
	movl	%edx,%r12d
	addl	8(%rsp),%r9d
	andl	%ecx,%r12d
	rorxl	$25,%ecx,%r13d
	rorxl	$11,%ecx,%r15d
	leal	(%r10,%r14,1),%r10d
	leal	(%r9,%r12,1),%r9d
	andnl	%r8d,%ecx,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%ecx,%r14d
	leal	(%r9,%r12,1),%r9d
	xorl	%r14d,%r13d
	movl	%r10d,%r15d
	rorxl	$22,%r10d,%r12d
	leal	(%r9,%r13,1),%r9d
	xorl	%r11d,%r15d
	rorxl	$13,%r10d,%r14d
	rorxl	$2,%r10d,%r13d
	leal	(%rbx,%r9,1),%ebx
	andl	%r15d,%esi
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	160-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r11d,%esi
	xorl	%r13d,%r14d
	leal	(%r9,%rsi,1),%r9d
	movl	%ecx,%r12d
	addl	12(%rsp),%r8d
	andl	%ebx,%r12d
	rorxl	$25,%ebx,%r13d
	rorxl	$11,%ebx,%esi
	leal	(%r9,%r14,1),%r9d
	leal	(%r8,%r12,1),%r8d
	andnl	%edx,%ebx,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%ebx,%r14d
	leal	(%r8,%r12,1),%r8d
	xorl	%r14d,%r13d
	movl	%r9d,%esi
	rorxl	$22,%r9d,%r12d
	leal	(%r8,%r13,1),%r8d
	xorl	%r10d,%esi
	rorxl	$13,%r9d,%r14d
	rorxl	$2,%r9d,%r13d
	leal	(%rax,%r8,1),%eax
	andl	%esi,%r15d
	vaesenclast	%xmm10,%xmm9,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	176-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r10d,%r15d
	xorl	%r13d,%r14d
	leal	(%r8,%r15,1),%r8d
	movl	%ebx,%r12d
	addl	32(%rsp),%edx
	andl	%eax,%r12d
	rorxl	$25,%eax,%r13d
	rorxl	$11,%eax,%r15d
	leal	(%r8,%r14,1),%r8d
	leal	(%rdx,%r12,1),%edx
	andnl	%ecx,%eax,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%eax,%r14d
	leal	(%rdx,%r12,1),%edx
	xorl	%r14d,%r13d
	movl	%r8d,%r15d
	rorxl	$22,%r8d,%r12d
	leal	(%rdx,%r13,1),%edx
	xorl	%r9d,%r15d
	rorxl	$13,%r8d,%r14d
	rorxl	$2,%r8d,%r13d
	leal	(%r11,%rdx,1),%r11d
	andl	%r15d,%esi
	vpand	%xmm12,%xmm11,%xmm8
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	192-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r9d,%esi
	xorl	%r13d,%r14d
	leal	(%rdx,%rsi,1),%edx
	movl	%eax,%r12d
	addl	36(%rsp),%ecx
	andl	%r11d,%r12d
	rorxl	$25,%r11d,%r13d
	rorxl	$11,%r11d,%esi
	leal	(%rdx,%r14,1),%edx
	leal	(%rcx,%r12,1),%ecx
	andnl	%ebx,%r11d,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%r11d,%r14d
	leal	(%rcx,%r12,1),%ecx
	xorl	%r14d,%r13d
	movl	%edx,%esi
	rorxl	$22,%edx,%r12d
	leal	(%rcx,%r13,1),%ecx
	xorl	%r8d,%esi
	rorxl	$13,%edx,%r14d
	rorxl	$2,%edx,%r13d
	leal	(%r10,%rcx,1),%r10d
	andl	%esi,%r15d
	vaesenclast	%xmm10,%xmm9,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	208-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r8d,%r15d
	xorl	%r13d,%r14d
	leal	(%rcx,%r15,1),%ecx
	movl	%r11d,%r12d
	addl	40(%rsp),%ebx
	andl	%r10d,%r12d
	rorxl	$25,%r10d,%r13d
	rorxl	$11,%r10d,%r15d
	leal	(%rcx,%r14,1),%ecx
	leal	(%rbx,%r12,1),%ebx
	andnl	%eax,%r10d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r10d,%r14d
	leal	(%rbx,%r12,1),%ebx
	xorl	%r14d,%r13d
	movl	%ecx,%r15d
	rorxl	$22,%ecx,%r12d
	leal	(%rbx,%r13,1),%ebx
	xorl	%edx,%r15d
	rorxl	$13,%ecx,%r14d
	rorxl	$2,%ecx,%r13d
	leal	(%r9,%rbx,1),%r9d
	andl	%r15d,%esi
	vpand	%xmm13,%xmm11,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	224-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%edx,%esi
	xorl	%r13d,%r14d
	leal	(%rbx,%rsi,1),%ebx
	movl	%r10d,%r12d
	addl	44(%rsp),%eax
	andl	%r9d,%r12d
	rorxl	$25,%r9d,%r13d
	rorxl	$11,%r9d,%esi
	leal	(%rbx,%r14,1),%ebx
	leal	(%rax,%r12,1),%eax
	andnl	%r11d,%r9d,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%r9d,%r14d
	leal	(%rax,%r12,1),%eax
	xorl	%r14d,%r13d
	movl	%ebx,%esi
	rorxl	$22,%ebx,%r12d
	leal	(%rax,%r13,1),%eax
	xorl	%ecx,%esi
	rorxl	$13,%ebx,%r14d
	rorxl	$2,%ebx,%r13d
	leal	(%r8,%rax,1),%r8d
	andl	%esi,%r15d
	vpor	%xmm11,%xmm8,%xmm8
	vaesenclast	%xmm10,%xmm9,%xmm11
	vmovdqu	0-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%ecx,%r15d
	xorl	%r13d,%r14d
	leal	(%rax,%r15,1),%eax
	movl	%r9d,%r12d
	vpextrq	$1,%xmm15,%r12
	vmovq	%xmm15,%r13
	movq	552(%rsp),%r15
	addl	%r14d,%eax
	leaq	448(%rsp),%rbp

	vpand	%xmm14,%xmm11,%xmm11
	vpor	%xmm11,%xmm8,%xmm8
	vmovdqu	%xmm8,(%r12,%r13,1)
	leaq	16(%r13),%r13

	addl	0(%r15),%eax
	addl	4(%r15),%ebx
	addl	8(%r15),%ecx
	addl	12(%r15),%edx
	addl	16(%r15),%r8d
	addl	20(%r15),%r9d
	addl	24(%r15),%r10d
	addl	28(%r15),%r11d

	movl	%eax,0(%r15)
	movl	%ebx,4(%r15)
	movl	%ecx,8(%r15)
	movl	%edx,12(%r15)
	movl	%r8d,16(%r15)
	movl	%r9d,20(%r15)
	movl	%r10d,24(%r15)
	movl	%r11d,28(%r15)

	cmpq	80(%rbp),%r13
	je	.Ldone_avx2

	xorl	%r14d,%r14d
	movl	%ebx,%esi
	movl	%r9d,%r12d
	xorl	%ecx,%esi
	jmp	.Lower_avx2
.align	16
.Lower_avx2:
	vmovdqu	(%r13),%xmm9
	vpinsrq	$0,%r13,%xmm15,%xmm15
	addl	0+16(%rbp),%r11d
	andl	%r8d,%r12d
	rorxl	$25,%r8d,%r13d
	rorxl	$11,%r8d,%r15d
	leal	(%rax,%r14,1),%eax
	leal	(%r11,%r12,1),%r11d
	andnl	%r10d,%r8d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r8d,%r14d
	leal	(%r11,%r12,1),%r11d
	xorl	%r14d,%r13d
	movl	%eax,%r15d
	rorxl	$22,%eax,%r12d
	leal	(%r11,%r13,1),%r11d
	xorl	%ebx,%r15d
	rorxl	$13,%eax,%r14d
	rorxl	$2,%eax,%r13d
	leal	(%rdx,%r11,1),%edx
	andl	%r15d,%esi
	vpxor	%xmm10,%xmm9,%xmm9
	vmovdqu	16-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%ebx,%esi
	xorl	%r13d,%r14d
	leal	(%r11,%rsi,1),%r11d
	movl	%r8d,%r12d
	addl	4+16(%rbp),%r10d
	andl	%edx,%r12d
	rorxl	$25,%edx,%r13d
	rorxl	$11,%edx,%esi
	leal	(%r11,%r14,1),%r11d
	leal	(%r10,%r12,1),%r10d
	andnl	%r9d,%edx,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%edx,%r14d
	leal	(%r10,%r12,1),%r10d
	xorl	%r14d,%r13d
	movl	%r11d,%esi
	rorxl	$22,%r11d,%r12d
	leal	(%r10,%r13,1),%r10d
	xorl	%eax,%esi
	rorxl	$13,%r11d,%r14d
	rorxl	$2,%r11d,%r13d
	leal	(%rcx,%r10,1),%ecx
	andl	%esi,%r15d
	vpxor	%xmm8,%xmm9,%xmm9
	xorl	%r12d,%r14d
	xorl	%eax,%r15d
	xorl	%r13d,%r14d
	leal	(%r10,%r15,1),%r10d
	movl	%edx,%r12d
	addl	8+16(%rbp),%r9d
	andl	%ecx,%r12d
	rorxl	$25,%ecx,%r13d
	rorxl	$11,%ecx,%r15d
	leal	(%r10,%r14,1),%r10d
	leal	(%r9,%r12,1),%r9d
	andnl	%r8d,%ecx,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%ecx,%r14d
	leal	(%r9,%r12,1),%r9d
	xorl	%r14d,%r13d
	movl	%r10d,%r15d
	rorxl	$22,%r10d,%r12d
	leal	(%r9,%r13,1),%r9d
	xorl	%r11d,%r15d
	rorxl	$13,%r10d,%r14d
	rorxl	$2,%r10d,%r13d
	leal	(%rbx,%r9,1),%ebx
	andl	%r15d,%esi
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	32-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r11d,%esi
	xorl	%r13d,%r14d
	leal	(%r9,%rsi,1),%r9d
	movl	%ecx,%r12d
	addl	12+16(%rbp),%r8d
	andl	%ebx,%r12d
	rorxl	$25,%ebx,%r13d
	rorxl	$11,%ebx,%esi
	leal	(%r9,%r14,1),%r9d
	leal	(%r8,%r12,1),%r8d
	andnl	%edx,%ebx,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%ebx,%r14d
	leal	(%r8,%r12,1),%r8d
	xorl	%r14d,%r13d
	movl	%r9d,%esi
	rorxl	$22,%r9d,%r12d
	leal	(%r8,%r13,1),%r8d
	xorl	%r10d,%esi
	rorxl	$13,%r9d,%r14d
	rorxl	$2,%r9d,%r13d
	leal	(%rax,%r8,1),%eax
	andl	%esi,%r15d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	48-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r10d,%r15d
	xorl	%r13d,%r14d
	leal	(%r8,%r15,1),%r8d
	movl	%ebx,%r12d
	addl	32+16(%rbp),%edx
	andl	%eax,%r12d
	rorxl	$25,%eax,%r13d
	rorxl	$11,%eax,%r15d
	leal	(%r8,%r14,1),%r8d
	leal	(%rdx,%r12,1),%edx
	andnl	%ecx,%eax,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%eax,%r14d
	leal	(%rdx,%r12,1),%edx
	xorl	%r14d,%r13d
	movl	%r8d,%r15d
	rorxl	$22,%r8d,%r12d
	leal	(%rdx,%r13,1),%edx
	xorl	%r9d,%r15d
	rorxl	$13,%r8d,%r14d
	rorxl	$2,%r8d,%r13d
	leal	(%r11,%rdx,1),%r11d
	andl	%r15d,%esi
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	64-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r9d,%esi
	xorl	%r13d,%r14d
	leal	(%rdx,%rsi,1),%edx
	movl	%eax,%r12d
	addl	36+16(%rbp),%ecx
	andl	%r11d,%r12d
	rorxl	$25,%r11d,%r13d
	rorxl	$11,%r11d,%esi
	leal	(%rdx,%r14,1),%edx
	leal	(%rcx,%r12,1),%ecx
	andnl	%ebx,%r11d,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%r11d,%r14d
	leal	(%rcx,%r12,1),%ecx
	xorl	%r14d,%r13d
	movl	%edx,%esi
	rorxl	$22,%edx,%r12d
	leal	(%rcx,%r13,1),%ecx
	xorl	%r8d,%esi
	rorxl	$13,%edx,%r14d
	rorxl	$2,%edx,%r13d
	leal	(%r10,%rcx,1),%r10d
	andl	%esi,%r15d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	80-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r8d,%r15d
	xorl	%r13d,%r14d
	leal	(%rcx,%r15,1),%ecx
	movl	%r11d,%r12d
	addl	40+16(%rbp),%ebx
	andl	%r10d,%r12d
	rorxl	$25,%r10d,%r13d
	rorxl	$11,%r10d,%r15d
	leal	(%rcx,%r14,1),%ecx
	leal	(%rbx,%r12,1),%ebx
	andnl	%eax,%r10d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r10d,%r14d
	leal	(%rbx,%r12,1),%ebx
	xorl	%r14d,%r13d
	movl	%ecx,%r15d
	rorxl	$22,%ecx,%r12d
	leal	(%rbx,%r13,1),%ebx
	xorl	%edx,%r15d
	rorxl	$13,%ecx,%r14d
	rorxl	$2,%ecx,%r13d
	leal	(%r9,%rbx,1),%r9d
	andl	%r15d,%esi
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	96-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%edx,%esi
	xorl	%r13d,%r14d
	leal	(%rbx,%rsi,1),%ebx
	movl	%r10d,%r12d
	addl	44+16(%rbp),%eax
	andl	%r9d,%r12d
	rorxl	$25,%r9d,%r13d
	rorxl	$11,%r9d,%esi
	leal	(%rbx,%r14,1),%ebx
	leal	(%rax,%r12,1),%eax
	andnl	%r11d,%r9d,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%r9d,%r14d
	leal	(%rax,%r12,1),%eax
	xorl	%r14d,%r13d
	movl	%ebx,%esi
	rorxl	$22,%ebx,%r12d
	leal	(%rax,%r13,1),%eax
	xorl	%ecx,%esi
	rorxl	$13,%ebx,%r14d
	rorxl	$2,%ebx,%r13d
	leal	(%r8,%rax,1),%r8d
	andl	%esi,%r15d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	112-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%ecx,%r15d
	xorl	%r13d,%r14d
	leal	(%rax,%r15,1),%eax
	movl	%r9d,%r12d
	leaq	-64(%rbp),%rbp
	addl	0+16(%rbp),%r11d
	andl	%r8d,%r12d
	rorxl	$25,%r8d,%r13d
	rorxl	$11,%r8d,%r15d
	leal	(%rax,%r14,1),%eax
	leal	(%r11,%r12,1),%r11d
	andnl	%r10d,%r8d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r8d,%r14d
	leal	(%r11,%r12,1),%r11d
	xorl	%r14d,%r13d
	movl	%eax,%r15d
	rorxl	$22,%eax,%r12d
	leal	(%r11,%r13,1),%r11d
	xorl	%ebx,%r15d
	rorxl	$13,%eax,%r14d
	rorxl	$2,%eax,%r13d
	leal	(%rdx,%r11,1),%edx
	andl	%r15d,%esi
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	128-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%ebx,%esi
	xorl	%r13d,%r14d
	leal	(%r11,%rsi,1),%r11d
	movl	%r8d,%r12d
	addl	4+16(%rbp),%r10d
	andl	%edx,%r12d
	rorxl	$25,%edx,%r13d
	rorxl	$11,%edx,%esi
	leal	(%r11,%r14,1),%r11d
	leal	(%r10,%r12,1),%r10d
	andnl	%r9d,%edx,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%edx,%r14d
	leal	(%r10,%r12,1),%r10d
	xorl	%r14d,%r13d
	movl	%r11d,%esi
	rorxl	$22,%r11d,%r12d
	leal	(%r10,%r13,1),%r10d
	xorl	%eax,%esi
	rorxl	$13,%r11d,%r14d
	rorxl	$2,%r11d,%r13d
	leal	(%rcx,%r10,1),%ecx
	andl	%esi,%r15d
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	144-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%eax,%r15d
	xorl	%r13d,%r14d
	leal	(%r10,%r15,1),%r10d
	movl	%edx,%r12d
	addl	8+16(%rbp),%r9d
	andl	%ecx,%r12d
	rorxl	$25,%ecx,%r13d
	rorxl	$11,%ecx,%r15d
	leal	(%r10,%r14,1),%r10d
	leal	(%r9,%r12,1),%r9d
	andnl	%r8d,%ecx,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%ecx,%r14d
	leal	(%r9,%r12,1),%r9d
	xorl	%r14d,%r13d
	movl	%r10d,%r15d
	rorxl	$22,%r10d,%r12d
	leal	(%r9,%r13,1),%r9d
	xorl	%r11d,%r15d
	rorxl	$13,%r10d,%r14d
	rorxl	$2,%r10d,%r13d
	leal	(%rbx,%r9,1),%ebx
	andl	%r15d,%esi
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	160-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r11d,%esi
	xorl	%r13d,%r14d
	leal	(%r9,%rsi,1),%r9d
	movl	%ecx,%r12d
	addl	12+16(%rbp),%r8d
	andl	%ebx,%r12d
	rorxl	$25,%ebx,%r13d
	rorxl	$11,%ebx,%esi
	leal	(%r9,%r14,1),%r9d
	leal	(%r8,%r12,1),%r8d
	andnl	%edx,%ebx,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%ebx,%r14d
	leal	(%r8,%r12,1),%r8d
	xorl	%r14d,%r13d
	movl	%r9d,%esi
	rorxl	$22,%r9d,%r12d
	leal	(%r8,%r13,1),%r8d
	xorl	%r10d,%esi
	rorxl	$13,%r9d,%r14d
	rorxl	$2,%r9d,%r13d
	leal	(%rax,%r8,1),%eax
	andl	%esi,%r15d
	vaesenclast	%xmm10,%xmm9,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	176-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r10d,%r15d
	xorl	%r13d,%r14d
	leal	(%r8,%r15,1),%r8d
	movl	%ebx,%r12d
	addl	32+16(%rbp),%edx
	andl	%eax,%r12d
	rorxl	$25,%eax,%r13d
	rorxl	$11,%eax,%r15d
	leal	(%r8,%r14,1),%r8d
	leal	(%rdx,%r12,1),%edx
	andnl	%ecx,%eax,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%eax,%r14d
	leal	(%rdx,%r12,1),%edx
	xorl	%r14d,%r13d
	movl	%r8d,%r15d
	rorxl	$22,%r8d,%r12d
	leal	(%rdx,%r13,1),%edx
	xorl	%r9d,%r15d
	rorxl	$13,%r8d,%r14d
	rorxl	$2,%r8d,%r13d
	leal	(%r11,%rdx,1),%r11d
	andl	%r15d,%esi
	vpand	%xmm12,%xmm11,%xmm8
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	192-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r9d,%esi
	xorl	%r13d,%r14d
	leal	(%rdx,%rsi,1),%edx
	movl	%eax,%r12d
	addl	36+16(%rbp),%ecx
	andl	%r11d,%r12d
	rorxl	$25,%r11d,%r13d
	rorxl	$11,%r11d,%esi
	leal	(%rdx,%r14,1),%edx
	leal	(%rcx,%r12,1),%ecx
	andnl	%ebx,%r11d,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%r11d,%r14d
	leal	(%rcx,%r12,1),%ecx
	xorl	%r14d,%r13d
	movl	%edx,%esi
	rorxl	$22,%edx,%r12d
	leal	(%rcx,%r13,1),%ecx
	xorl	%r8d,%esi
	rorxl	$13,%edx,%r14d
	rorxl	$2,%edx,%r13d
	leal	(%r10,%rcx,1),%r10d
	andl	%esi,%r15d
	vaesenclast	%xmm10,%xmm9,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	208-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%r8d,%r15d
	xorl	%r13d,%r14d
	leal	(%rcx,%r15,1),%ecx
	movl	%r11d,%r12d
	addl	40+16(%rbp),%ebx
	andl	%r10d,%r12d
	rorxl	$25,%r10d,%r13d
	rorxl	$11,%r10d,%r15d
	leal	(%rcx,%r14,1),%ecx
	leal	(%rbx,%r12,1),%ebx
	andnl	%eax,%r10d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r10d,%r14d
	leal	(%rbx,%r12,1),%ebx
	xorl	%r14d,%r13d
	movl	%ecx,%r15d
	rorxl	$22,%ecx,%r12d
	leal	(%rbx,%r13,1),%ebx
	xorl	%edx,%r15d
	rorxl	$13,%ecx,%r14d
	rorxl	$2,%ecx,%r13d
	leal	(%r9,%rbx,1),%r9d
	andl	%r15d,%esi
	vpand	%xmm13,%xmm11,%xmm11
	vaesenc	%xmm10,%xmm9,%xmm9
	vmovdqu	224-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%edx,%esi
	xorl	%r13d,%r14d
	leal	(%rbx,%rsi,1),%ebx
	movl	%r10d,%r12d
	addl	44+16(%rbp),%eax
	andl	%r9d,%r12d
	rorxl	$25,%r9d,%r13d
	rorxl	$11,%r9d,%esi
	leal	(%rbx,%r14,1),%ebx
	leal	(%rax,%r12,1),%eax
	andnl	%r11d,%r9d,%r12d
	xorl	%esi,%r13d
	rorxl	$6,%r9d,%r14d
	leal	(%rax,%r12,1),%eax
	xorl	%r14d,%r13d
	movl	%ebx,%esi
	rorxl	$22,%ebx,%r12d
	leal	(%rax,%r13,1),%eax
	xorl	%ecx,%esi
	rorxl	$13,%ebx,%r14d
	rorxl	$2,%ebx,%r13d
	leal	(%r8,%rax,1),%r8d
	andl	%esi,%r15d
	vpor	%xmm11,%xmm8,%xmm8
	vaesenclast	%xmm10,%xmm9,%xmm11
	vmovdqu	0-128(%rdi),%xmm10
	xorl	%r12d,%r14d
	xorl	%ecx,%r15d
	xorl	%r13d,%r14d
	leal	(%rax,%r15,1),%eax
	movl	%r9d,%r12d
	vmovq	%xmm15,%r13
	vpextrq	$1,%xmm15,%r15
	vpand	%xmm14,%xmm11,%xmm11
	vpor	%xmm11,%xmm8,%xmm8
	leaq	-64(%rbp),%rbp
	vmovdqu	%xmm8,(%r15,%r13,1)
	leaq	16(%r13),%r13
	cmpq	%rsp,%rbp
	jae	.Lower_avx2

	movq	552(%rsp),%r15
	leaq	64(%r13),%r13
	movq	560(%rsp),%rsi
	addl	%r14d,%eax
	leaq	448(%rsp),%rsp

	addl	0(%r15),%eax
	addl	4(%r15),%ebx
	addl	8(%r15),%ecx
	addl	12(%r15),%edx
	addl	16(%r15),%r8d
	addl	20(%r15),%r9d
	addl	24(%r15),%r10d
	leaq	(%rsi,%r13,1),%r12
	addl	28(%r15),%r11d

	cmpq	64+16(%rsp),%r13

	movl	%eax,0(%r15)
	cmoveq	%rsp,%r12
	movl	%ebx,4(%r15)
	movl	%ecx,8(%r15)
	movl	%edx,12(%r15)
	movl	%r8d,16(%r15)
	movl	%r9d,20(%r15)
	movl	%r10d,24(%r15)
	movl	%r11d,28(%r15)

	jbe	.Loop_avx2
	leaq	(%rsp),%rbp


.cfi_escape	0x0f,0x06,0x76,0xf8,0x00,0x06,0x23,0x08

.Ldone_avx2:
	movq	64+32(%rbp),%r8
	movq	64+56(%rbp),%rsi
.cfi_def_cfa	%rsi,8
	vmovdqu	%xmm8,(%r8)
	vzeroall
	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue_avx2:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_cbc_sha256_enc_avx2,.-aesni_cbc_sha256_enc_avx2
.type	aesni_cbc_sha256_enc_shaext,@function
.align	32
aesni_cbc_sha256_enc_shaext:
.cfi_startproc	
	movq	8(%rsp),%r10
	leaq	K256+128(%rip),%rax
	movdqu	(%r9),%xmm1
	movdqu	16(%r9),%xmm2
	movdqa	512-128(%rax),%xmm3

	movl	240(%rcx),%r11d
	subq	%rdi,%rsi
	movups	(%rcx),%xmm15
	movups	(%r8),%xmm6
	movups	16(%rcx),%xmm4
	leaq	112(%rcx),%rcx

	pshufd	$0x1b,%xmm1,%xmm0
	pshufd	$0xb1,%xmm1,%xmm1
	pshufd	$0x1b,%xmm2,%xmm2
	movdqa	%xmm3,%xmm7
.byte	102,15,58,15,202,8
	punpcklqdq	%xmm0,%xmm2

	jmp	.Loop_shaext

.align	16
.Loop_shaext:
	movdqu	(%r10),%xmm10
	movdqu	16(%r10),%xmm11
	movdqu	32(%r10),%xmm12
.byte	102,68,15,56,0,211
	movdqu	48(%r10),%xmm13

	movdqa	0-128(%rax),%xmm0
	paddd	%xmm10,%xmm0
.byte	102,68,15,56,0,219
	movdqa	%xmm2,%xmm9
	movdqa	%xmm1,%xmm8
	movups	0(%rdi),%xmm14
	xorps	%xmm15,%xmm14
	xorps	%xmm14,%xmm6
	movups	-80(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movups	-64(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
.byte	15,56,203,202

	movdqa	32-128(%rax),%xmm0
	paddd	%xmm11,%xmm0
.byte	102,68,15,56,0,227
	leaq	64(%r10),%r10
	movups	-48(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movups	-32(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
.byte	15,56,203,202

	movdqa	64-128(%rax),%xmm0
	paddd	%xmm12,%xmm0
.byte	102,68,15,56,0,235
.byte	69,15,56,204,211
	movups	-16(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm13,%xmm3
.byte	102,65,15,58,15,220,4
	paddd	%xmm3,%xmm10
	movups	0(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
.byte	15,56,203,202

	movdqa	96-128(%rax),%xmm0
	paddd	%xmm13,%xmm0
.byte	69,15,56,205,213
.byte	69,15,56,204,220
	movups	16(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movups	32(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
	movdqa	%xmm10,%xmm3
.byte	102,65,15,58,15,221,4
	paddd	%xmm3,%xmm11
.byte	15,56,203,202
	movdqa	128-128(%rax),%xmm0
	paddd	%xmm10,%xmm0
.byte	69,15,56,205,218
.byte	69,15,56,204,229
	movups	48(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm11,%xmm3
.byte	102,65,15,58,15,218,4
	paddd	%xmm3,%xmm12
	cmpl	$11,%r11d
	jb	.Laesenclast1
	movups	64(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
	movups	80(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
	je	.Laesenclast1
	movups	96(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
	movups	112(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
.Laesenclast1:
	aesenclast	%xmm5,%xmm6
	movups	16-112(%rcx),%xmm4
	nop
.byte	15,56,203,202
	movups	16(%rdi),%xmm14
	xorps	%xmm15,%xmm14
	movups	%xmm6,0(%rsi,%rdi,1)
	xorps	%xmm14,%xmm6
	movups	-80(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
	movdqa	160-128(%rax),%xmm0
	paddd	%xmm11,%xmm0
.byte	69,15,56,205,227
.byte	69,15,56,204,234
	movups	-64(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm12,%xmm3
.byte	102,65,15,58,15,219,4
	paddd	%xmm3,%xmm13
	movups	-48(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
.byte	15,56,203,202
	movdqa	192-128(%rax),%xmm0
	paddd	%xmm12,%xmm0
.byte	69,15,56,205,236
.byte	69,15,56,204,211
	movups	-32(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm13,%xmm3
.byte	102,65,15,58,15,220,4
	paddd	%xmm3,%xmm10
	movups	-16(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
.byte	15,56,203,202
	movdqa	224-128(%rax),%xmm0
	paddd	%xmm13,%xmm0
.byte	69,15,56,205,213
.byte	69,15,56,204,220
	movups	0(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm10,%xmm3
.byte	102,65,15,58,15,221,4
	paddd	%xmm3,%xmm11
	movups	16(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
.byte	15,56,203,202
	movdqa	256-128(%rax),%xmm0
	paddd	%xmm10,%xmm0
.byte	69,15,56,205,218
.byte	69,15,56,204,229
	movups	32(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm11,%xmm3
.byte	102,65,15,58,15,218,4
	paddd	%xmm3,%xmm12
	movups	48(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
	cmpl	$11,%r11d
	jb	.Laesenclast2
	movups	64(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
	movups	80(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
	je	.Laesenclast2
	movups	96(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
	movups	112(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
.Laesenclast2:
	aesenclast	%xmm5,%xmm6
	movups	16-112(%rcx),%xmm4
	nop
.byte	15,56,203,202
	movups	32(%rdi),%xmm14
	xorps	%xmm15,%xmm14
	movups	%xmm6,16(%rsi,%rdi,1)
	xorps	%xmm14,%xmm6
	movups	-80(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
	movdqa	288-128(%rax),%xmm0
	paddd	%xmm11,%xmm0
.byte	69,15,56,205,227
.byte	69,15,56,204,234
	movups	-64(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm12,%xmm3
.byte	102,65,15,58,15,219,4
	paddd	%xmm3,%xmm13
	movups	-48(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
.byte	15,56,203,202
	movdqa	320-128(%rax),%xmm0
	paddd	%xmm12,%xmm0
.byte	69,15,56,205,236
.byte	69,15,56,204,211
	movups	-32(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm13,%xmm3
.byte	102,65,15,58,15,220,4
	paddd	%xmm3,%xmm10
	movups	-16(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
.byte	15,56,203,202
	movdqa	352-128(%rax),%xmm0
	paddd	%xmm13,%xmm0
.byte	69,15,56,205,213
.byte	69,15,56,204,220
	movups	0(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm10,%xmm3
.byte	102,65,15,58,15,221,4
	paddd	%xmm3,%xmm11
	movups	16(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
.byte	15,56,203,202
	movdqa	384-128(%rax),%xmm0
	paddd	%xmm10,%xmm0
.byte	69,15,56,205,218
.byte	69,15,56,204,229
	movups	32(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm11,%xmm3
.byte	102,65,15,58,15,218,4
	paddd	%xmm3,%xmm12
	movups	48(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
.byte	15,56,203,202
	movdqa	416-128(%rax),%xmm0
	paddd	%xmm11,%xmm0
.byte	69,15,56,205,227
.byte	69,15,56,204,234
	cmpl	$11,%r11d
	jb	.Laesenclast3
	movups	64(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
	movups	80(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
	je	.Laesenclast3
	movups	96(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
	movups	112(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
.Laesenclast3:
	aesenclast	%xmm5,%xmm6
	movups	16-112(%rcx),%xmm4
	nop
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm12,%xmm3
.byte	102,65,15,58,15,219,4
	paddd	%xmm3,%xmm13
	movups	48(%rdi),%xmm14
	xorps	%xmm15,%xmm14
	movups	%xmm6,32(%rsi,%rdi,1)
	xorps	%xmm14,%xmm6
	movups	-80(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
	movups	-64(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
.byte	15,56,203,202

	movdqa	448-128(%rax),%xmm0
	paddd	%xmm12,%xmm0
.byte	69,15,56,205,236
	movdqa	%xmm7,%xmm3
	movups	-48(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movups	-32(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
.byte	15,56,203,202

	movdqa	480-128(%rax),%xmm0
	paddd	%xmm13,%xmm0
	movups	-16(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
	movups	0(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movups	16(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
.byte	15,56,203,202

	movups	32(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
	movups	48(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
	cmpl	$11,%r11d
	jb	.Laesenclast4
	movups	64(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
	movups	80(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
	je	.Laesenclast4
	movups	96(%rcx),%xmm4
	aesenc	%xmm5,%xmm6
	movups	112(%rcx),%xmm5
	aesenc	%xmm4,%xmm6
.Laesenclast4:
	aesenclast	%xmm5,%xmm6
	movups	16-112(%rcx),%xmm4
	nop

	paddd	%xmm9,%xmm2
	paddd	%xmm8,%xmm1

	decq	%rdx
	movups	%xmm6,48(%rsi,%rdi,1)
	leaq	64(%rdi),%rdi
	jnz	.Loop_shaext

	pshufd	$0xb1,%xmm2,%xmm2
	pshufd	$0x1b,%xmm1,%xmm3
	pshufd	$0xb1,%xmm1,%xmm1
	punpckhqdq	%xmm2,%xmm1
.byte	102,15,58,15,211,8

	movups	%xmm6,(%r8)
	movdqu	%xmm1,(%r9)
	movdqu	%xmm2,16(%r9)
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_cbc_sha256_enc_shaext,.-aesni_cbc_sha256_enc_shaext
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                                                                                      node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/aes/aesni-x86_64.s                    0000664 0000000 0000000 00000251111 14746647661 0026723 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	

.globl	aesni_encrypt
.type	aesni_encrypt,@function
.align	16
aesni_encrypt:
.cfi_startproc	
.byte	243,15,30,250
	movups	(%rdi),%xmm2
	movl	240(%rdx),%eax
	movups	(%rdx),%xmm0
	movups	16(%rdx),%xmm1
	leaq	32(%rdx),%rdx
	xorps	%xmm0,%xmm2
.Loop_enc1_1:
.byte	102,15,56,220,209
	decl	%eax
	movups	(%rdx),%xmm1
	leaq	16(%rdx),%rdx
	jnz	.Loop_enc1_1
.byte	102,15,56,221,209
	pxor	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	movups	%xmm2,(%rsi)
	pxor	%xmm2,%xmm2
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_encrypt,.-aesni_encrypt

.globl	aesni_decrypt
.type	aesni_decrypt,@function
.align	16
aesni_decrypt:
.cfi_startproc	
.byte	243,15,30,250
	movups	(%rdi),%xmm2
	movl	240(%rdx),%eax
	movups	(%rdx),%xmm0
	movups	16(%rdx),%xmm1
	leaq	32(%rdx),%rdx
	xorps	%xmm0,%xmm2
.Loop_dec1_2:
.byte	102,15,56,222,209
	decl	%eax
	movups	(%rdx),%xmm1
	leaq	16(%rdx),%rdx
	jnz	.Loop_dec1_2
.byte	102,15,56,223,209
	pxor	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	movups	%xmm2,(%rsi)
	pxor	%xmm2,%xmm2
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_decrypt, .-aesni_decrypt
.type	_aesni_encrypt2,@function
.align	16
_aesni_encrypt2:
.cfi_startproc	
	movups	(%rcx),%xmm0
	shll	$4,%eax
	movups	16(%rcx),%xmm1
	xorps	%xmm0,%xmm2
	xorps	%xmm0,%xmm3
	movups	32(%rcx),%xmm0
	leaq	32(%rcx,%rax,1),%rcx
	negq	%rax
	addq	$16,%rax

.Lenc_loop2:
.byte	102,15,56,220,209
.byte	102,15,56,220,217
	movups	(%rcx,%rax,1),%xmm1
	addq	$32,%rax
.byte	102,15,56,220,208
.byte	102,15,56,220,216
	movups	-16(%rcx,%rax,1),%xmm0
	jnz	.Lenc_loop2

.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,221,208
.byte	102,15,56,221,216
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_aesni_encrypt2,.-_aesni_encrypt2
.type	_aesni_decrypt2,@function
.align	16
_aesni_decrypt2:
.cfi_startproc	
	movups	(%rcx),%xmm0
	shll	$4,%eax
	movups	16(%rcx),%xmm1
	xorps	%xmm0,%xmm2
	xorps	%xmm0,%xmm3
	movups	32(%rcx),%xmm0
	leaq	32(%rcx,%rax,1),%rcx
	negq	%rax
	addq	$16,%rax

.Ldec_loop2:
.byte	102,15,56,222,209
.byte	102,15,56,222,217
	movups	(%rcx,%rax,1),%xmm1
	addq	$32,%rax
.byte	102,15,56,222,208
.byte	102,15,56,222,216
	movups	-16(%rcx,%rax,1),%xmm0
	jnz	.Ldec_loop2

.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,223,208
.byte	102,15,56,223,216
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_aesni_decrypt2,.-_aesni_decrypt2
.type	_aesni_encrypt3,@function
.align	16
_aesni_encrypt3:
.cfi_startproc	
	movups	(%rcx),%xmm0
	shll	$4,%eax
	movups	16(%rcx),%xmm1
	xorps	%xmm0,%xmm2
	xorps	%xmm0,%xmm3
	xorps	%xmm0,%xmm4
	movups	32(%rcx),%xmm0
	leaq	32(%rcx,%rax,1),%rcx
	negq	%rax
	addq	$16,%rax

.Lenc_loop3:
.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
	movups	(%rcx,%rax,1),%xmm1
	addq	$32,%rax
.byte	102,15,56,220,208
.byte	102,15,56,220,216
.byte	102,15,56,220,224
	movups	-16(%rcx,%rax,1),%xmm0
	jnz	.Lenc_loop3

.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.byte	102,15,56,221,208
.byte	102,15,56,221,216
.byte	102,15,56,221,224
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_aesni_encrypt3,.-_aesni_encrypt3
.type	_aesni_decrypt3,@function
.align	16
_aesni_decrypt3:
.cfi_startproc	
	movups	(%rcx),%xmm0
	shll	$4,%eax
	movups	16(%rcx),%xmm1
	xorps	%xmm0,%xmm2
	xorps	%xmm0,%xmm3
	xorps	%xmm0,%xmm4
	movups	32(%rcx),%xmm0
	leaq	32(%rcx,%rax,1),%rcx
	negq	%rax
	addq	$16,%rax

.Ldec_loop3:
.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
	movups	(%rcx,%rax,1),%xmm1
	addq	$32,%rax
.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
	movups	-16(%rcx,%rax,1),%xmm0
	jnz	.Ldec_loop3

.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,223,208
.byte	102,15,56,223,216
.byte	102,15,56,223,224
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_aesni_decrypt3,.-_aesni_decrypt3
.type	_aesni_encrypt4,@function
.align	16
_aesni_encrypt4:
.cfi_startproc	
	movups	(%rcx),%xmm0
	shll	$4,%eax
	movups	16(%rcx),%xmm1
	xorps	%xmm0,%xmm2
	xorps	%xmm0,%xmm3
	xorps	%xmm0,%xmm4
	xorps	%xmm0,%xmm5
	movups	32(%rcx),%xmm0
	leaq	32(%rcx,%rax,1),%rcx
	negq	%rax
.byte	0x0f,0x1f,0x00
	addq	$16,%rax

.Lenc_loop4:
.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.byte	102,15,56,220,233
	movups	(%rcx,%rax,1),%xmm1
	addq	$32,%rax
.byte	102,15,56,220,208
.byte	102,15,56,220,216
.byte	102,15,56,220,224
.byte	102,15,56,220,232
	movups	-16(%rcx,%rax,1),%xmm0
	jnz	.Lenc_loop4

.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.byte	102,15,56,220,233
.byte	102,15,56,221,208
.byte	102,15,56,221,216
.byte	102,15,56,221,224
.byte	102,15,56,221,232
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_aesni_encrypt4,.-_aesni_encrypt4
.type	_aesni_decrypt4,@function
.align	16
_aesni_decrypt4:
.cfi_startproc	
	movups	(%rcx),%xmm0
	shll	$4,%eax
	movups	16(%rcx),%xmm1
	xorps	%xmm0,%xmm2
	xorps	%xmm0,%xmm3
	xorps	%xmm0,%xmm4
	xorps	%xmm0,%xmm5
	movups	32(%rcx),%xmm0
	leaq	32(%rcx,%rax,1),%rcx
	negq	%rax
.byte	0x0f,0x1f,0x00
	addq	$16,%rax

.Ldec_loop4:
.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,222,233
	movups	(%rcx,%rax,1),%xmm1
	addq	$32,%rax
.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
.byte	102,15,56,222,232
	movups	-16(%rcx,%rax,1),%xmm0
	jnz	.Ldec_loop4

.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,222,233
.byte	102,15,56,223,208
.byte	102,15,56,223,216
.byte	102,15,56,223,224
.byte	102,15,56,223,232
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_aesni_decrypt4,.-_aesni_decrypt4
.type	_aesni_encrypt6,@function
.align	16
_aesni_encrypt6:
.cfi_startproc	
	movups	(%rcx),%xmm0
	shll	$4,%eax
	movups	16(%rcx),%xmm1
	xorps	%xmm0,%xmm2
	pxor	%xmm0,%xmm3
	pxor	%xmm0,%xmm4
.byte	102,15,56,220,209
	leaq	32(%rcx,%rax,1),%rcx
	negq	%rax
.byte	102,15,56,220,217
	pxor	%xmm0,%xmm5
	pxor	%xmm0,%xmm6
.byte	102,15,56,220,225
	pxor	%xmm0,%xmm7
	movups	(%rcx,%rax,1),%xmm0
	addq	$16,%rax
	jmp	.Lenc_loop6_enter
.align	16
.Lenc_loop6:
.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.Lenc_loop6_enter:
.byte	102,15,56,220,233
.byte	102,15,56,220,241
.byte	102,15,56,220,249
	movups	(%rcx,%rax,1),%xmm1
	addq	$32,%rax
.byte	102,15,56,220,208
.byte	102,15,56,220,216
.byte	102,15,56,220,224
.byte	102,15,56,220,232
.byte	102,15,56,220,240
.byte	102,15,56,220,248
	movups	-16(%rcx,%rax,1),%xmm0
	jnz	.Lenc_loop6

.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.byte	102,15,56,220,233
.byte	102,15,56,220,241
.byte	102,15,56,220,249
.byte	102,15,56,221,208
.byte	102,15,56,221,216
.byte	102,15,56,221,224
.byte	102,15,56,221,232
.byte	102,15,56,221,240
.byte	102,15,56,221,248
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_aesni_encrypt6,.-_aesni_encrypt6
.type	_aesni_decrypt6,@function
.align	16
_aesni_decrypt6:
.cfi_startproc	
	movups	(%rcx),%xmm0
	shll	$4,%eax
	movups	16(%rcx),%xmm1
	xorps	%xmm0,%xmm2
	pxor	%xmm0,%xmm3
	pxor	%xmm0,%xmm4
.byte	102,15,56,222,209
	leaq	32(%rcx,%rax,1),%rcx
	negq	%rax
.byte	102,15,56,222,217
	pxor	%xmm0,%xmm5
	pxor	%xmm0,%xmm6
.byte	102,15,56,222,225
	pxor	%xmm0,%xmm7
	movups	(%rcx,%rax,1),%xmm0
	addq	$16,%rax
	jmp	.Ldec_loop6_enter
.align	16
.Ldec_loop6:
.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.Ldec_loop6_enter:
.byte	102,15,56,222,233
.byte	102,15,56,222,241
.byte	102,15,56,222,249
	movups	(%rcx,%rax,1),%xmm1
	addq	$32,%rax
.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
.byte	102,15,56,222,232
.byte	102,15,56,222,240
.byte	102,15,56,222,248
	movups	-16(%rcx,%rax,1),%xmm0
	jnz	.Ldec_loop6

.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,222,233
.byte	102,15,56,222,241
.byte	102,15,56,222,249
.byte	102,15,56,223,208
.byte	102,15,56,223,216
.byte	102,15,56,223,224
.byte	102,15,56,223,232
.byte	102,15,56,223,240
.byte	102,15,56,223,248
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_aesni_decrypt6,.-_aesni_decrypt6
.type	_aesni_encrypt8,@function
.align	16
_aesni_encrypt8:
.cfi_startproc	
	movups	(%rcx),%xmm0
	shll	$4,%eax
	movups	16(%rcx),%xmm1
	xorps	%xmm0,%xmm2
	xorps	%xmm0,%xmm3
	pxor	%xmm0,%xmm4
	pxor	%xmm0,%xmm5
	pxor	%xmm0,%xmm6
	leaq	32(%rcx,%rax,1),%rcx
	negq	%rax
.byte	102,15,56,220,209
	pxor	%xmm0,%xmm7
	pxor	%xmm0,%xmm8
.byte	102,15,56,220,217
	pxor	%xmm0,%xmm9
	movups	(%rcx,%rax,1),%xmm0
	addq	$16,%rax
	jmp	.Lenc_loop8_inner
.align	16
.Lenc_loop8:
.byte	102,15,56,220,209
.byte	102,15,56,220,217
.Lenc_loop8_inner:
.byte	102,15,56,220,225
.byte	102,15,56,220,233
.byte	102,15,56,220,241
.byte	102,15,56,220,249
.byte	102,68,15,56,220,193
.byte	102,68,15,56,220,201
.Lenc_loop8_enter:
	movups	(%rcx,%rax,1),%xmm1
	addq	$32,%rax
.byte	102,15,56,220,208
.byte	102,15,56,220,216
.byte	102,15,56,220,224
.byte	102,15,56,220,232
.byte	102,15,56,220,240
.byte	102,15,56,220,248
.byte	102,68,15,56,220,192
.byte	102,68,15,56,220,200
	movups	-16(%rcx,%rax,1),%xmm0
	jnz	.Lenc_loop8

.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.byte	102,15,56,220,233
.byte	102,15,56,220,241
.byte	102,15,56,220,249
.byte	102,68,15,56,220,193
.byte	102,68,15,56,220,201
.byte	102,15,56,221,208
.byte	102,15,56,221,216
.byte	102,15,56,221,224
.byte	102,15,56,221,232
.byte	102,15,56,221,240
.byte	102,15,56,221,248
.byte	102,68,15,56,221,192
.byte	102,68,15,56,221,200
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_aesni_encrypt8,.-_aesni_encrypt8
.type	_aesni_decrypt8,@function
.align	16
_aesni_decrypt8:
.cfi_startproc	
	movups	(%rcx),%xmm0
	shll	$4,%eax
	movups	16(%rcx),%xmm1
	xorps	%xmm0,%xmm2
	xorps	%xmm0,%xmm3
	pxor	%xmm0,%xmm4
	pxor	%xmm0,%xmm5
	pxor	%xmm0,%xmm6
	leaq	32(%rcx,%rax,1),%rcx
	negq	%rax
.byte	102,15,56,222,209
	pxor	%xmm0,%xmm7
	pxor	%xmm0,%xmm8
.byte	102,15,56,222,217
	pxor	%xmm0,%xmm9
	movups	(%rcx,%rax,1),%xmm0
	addq	$16,%rax
	jmp	.Ldec_loop8_inner
.align	16
.Ldec_loop8:
.byte	102,15,56,222,209
.byte	102,15,56,222,217
.Ldec_loop8_inner:
.byte	102,15,56,222,225
.byte	102,15,56,222,233
.byte	102,15,56,222,241
.byte	102,15,56,222,249
.byte	102,68,15,56,222,193
.byte	102,68,15,56,222,201
.Ldec_loop8_enter:
	movups	(%rcx,%rax,1),%xmm1
	addq	$32,%rax
.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
.byte	102,15,56,222,232
.byte	102,15,56,222,240
.byte	102,15,56,222,248
.byte	102,68,15,56,222,192
.byte	102,68,15,56,222,200
	movups	-16(%rcx,%rax,1),%xmm0
	jnz	.Ldec_loop8

.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,222,233
.byte	102,15,56,222,241
.byte	102,15,56,222,249
.byte	102,68,15,56,222,193
.byte	102,68,15,56,222,201
.byte	102,15,56,223,208
.byte	102,15,56,223,216
.byte	102,15,56,223,224
.byte	102,15,56,223,232
.byte	102,15,56,223,240
.byte	102,15,56,223,248
.byte	102,68,15,56,223,192
.byte	102,68,15,56,223,200
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_aesni_decrypt8,.-_aesni_decrypt8
.globl	aesni_ecb_encrypt
.type	aesni_ecb_encrypt,@function
.align	16
aesni_ecb_encrypt:
.cfi_startproc	
.byte	243,15,30,250
	andq	$-16,%rdx
	jz	.Lecb_ret

	movl	240(%rcx),%eax
	movups	(%rcx),%xmm0
	movq	%rcx,%r11
	movl	%eax,%r10d
	testl	%r8d,%r8d
	jz	.Lecb_decrypt

	cmpq	$0x80,%rdx
	jb	.Lecb_enc_tail

	movdqu	(%rdi),%xmm2
	movdqu	16(%rdi),%xmm3
	movdqu	32(%rdi),%xmm4
	movdqu	48(%rdi),%xmm5
	movdqu	64(%rdi),%xmm6
	movdqu	80(%rdi),%xmm7
	movdqu	96(%rdi),%xmm8
	movdqu	112(%rdi),%xmm9
	leaq	128(%rdi),%rdi
	subq	$0x80,%rdx
	jmp	.Lecb_enc_loop8_enter
.align	16
.Lecb_enc_loop8:
	movups	%xmm2,(%rsi)
	movq	%r11,%rcx
	movdqu	(%rdi),%xmm2
	movl	%r10d,%eax
	movups	%xmm3,16(%rsi)
	movdqu	16(%rdi),%xmm3
	movups	%xmm4,32(%rsi)
	movdqu	32(%rdi),%xmm4
	movups	%xmm5,48(%rsi)
	movdqu	48(%rdi),%xmm5
	movups	%xmm6,64(%rsi)
	movdqu	64(%rdi),%xmm6
	movups	%xmm7,80(%rsi)
	movdqu	80(%rdi),%xmm7
	movups	%xmm8,96(%rsi)
	movdqu	96(%rdi),%xmm8
	movups	%xmm9,112(%rsi)
	leaq	128(%rsi),%rsi
	movdqu	112(%rdi),%xmm9
	leaq	128(%rdi),%rdi
.Lecb_enc_loop8_enter:

	call	_aesni_encrypt8

	subq	$0x80,%rdx
	jnc	.Lecb_enc_loop8

	movups	%xmm2,(%rsi)
	movq	%r11,%rcx
	movups	%xmm3,16(%rsi)
	movl	%r10d,%eax
	movups	%xmm4,32(%rsi)
	movups	%xmm5,48(%rsi)
	movups	%xmm6,64(%rsi)
	movups	%xmm7,80(%rsi)
	movups	%xmm8,96(%rsi)
	movups	%xmm9,112(%rsi)
	leaq	128(%rsi),%rsi
	addq	$0x80,%rdx
	jz	.Lecb_ret

.Lecb_enc_tail:
	movups	(%rdi),%xmm2
	cmpq	$0x20,%rdx
	jb	.Lecb_enc_one
	movups	16(%rdi),%xmm3
	je	.Lecb_enc_two
	movups	32(%rdi),%xmm4
	cmpq	$0x40,%rdx
	jb	.Lecb_enc_three
	movups	48(%rdi),%xmm5
	je	.Lecb_enc_four
	movups	64(%rdi),%xmm6
	cmpq	$0x60,%rdx
	jb	.Lecb_enc_five
	movups	80(%rdi),%xmm7
	je	.Lecb_enc_six
	movdqu	96(%rdi),%xmm8
	xorps	%xmm9,%xmm9
	call	_aesni_encrypt8
	movups	%xmm2,(%rsi)
	movups	%xmm3,16(%rsi)
	movups	%xmm4,32(%rsi)
	movups	%xmm5,48(%rsi)
	movups	%xmm6,64(%rsi)
	movups	%xmm7,80(%rsi)
	movups	%xmm8,96(%rsi)
	jmp	.Lecb_ret
.align	16
.Lecb_enc_one:
	movups	(%rcx),%xmm0
	movups	16(%rcx),%xmm1
	leaq	32(%rcx),%rcx
	xorps	%xmm0,%xmm2
.Loop_enc1_3:
.byte	102,15,56,220,209
	decl	%eax
	movups	(%rcx),%xmm1
	leaq	16(%rcx),%rcx
	jnz	.Loop_enc1_3
.byte	102,15,56,221,209
	movups	%xmm2,(%rsi)
	jmp	.Lecb_ret
.align	16
.Lecb_enc_two:
	call	_aesni_encrypt2
	movups	%xmm2,(%rsi)
	movups	%xmm3,16(%rsi)
	jmp	.Lecb_ret
.align	16
.Lecb_enc_three:
	call	_aesni_encrypt3
	movups	%xmm2,(%rsi)
	movups	%xmm3,16(%rsi)
	movups	%xmm4,32(%rsi)
	jmp	.Lecb_ret
.align	16
.Lecb_enc_four:
	call	_aesni_encrypt4
	movups	%xmm2,(%rsi)
	movups	%xmm3,16(%rsi)
	movups	%xmm4,32(%rsi)
	movups	%xmm5,48(%rsi)
	jmp	.Lecb_ret
.align	16
.Lecb_enc_five:
	xorps	%xmm7,%xmm7
	call	_aesni_encrypt6
	movups	%xmm2,(%rsi)
	movups	%xmm3,16(%rsi)
	movups	%xmm4,32(%rsi)
	movups	%xmm5,48(%rsi)
	movups	%xmm6,64(%rsi)
	jmp	.Lecb_ret
.align	16
.Lecb_enc_six:
	call	_aesni_encrypt6
	movups	%xmm2,(%rsi)
	movups	%xmm3,16(%rsi)
	movups	%xmm4,32(%rsi)
	movups	%xmm5,48(%rsi)
	movups	%xmm6,64(%rsi)
	movups	%xmm7,80(%rsi)
	jmp	.Lecb_ret

.align	16
.Lecb_decrypt:
	cmpq	$0x80,%rdx
	jb	.Lecb_dec_tail

	movdqu	(%rdi),%xmm2
	movdqu	16(%rdi),%xmm3
	movdqu	32(%rdi),%xmm4
	movdqu	48(%rdi),%xmm5
	movdqu	64(%rdi),%xmm6
	movdqu	80(%rdi),%xmm7
	movdqu	96(%rdi),%xmm8
	movdqu	112(%rdi),%xmm9
	leaq	128(%rdi),%rdi
	subq	$0x80,%rdx
	jmp	.Lecb_dec_loop8_enter
.align	16
.Lecb_dec_loop8:
	movups	%xmm2,(%rsi)
	movq	%r11,%rcx
	movdqu	(%rdi),%xmm2
	movl	%r10d,%eax
	movups	%xmm3,16(%rsi)
	movdqu	16(%rdi),%xmm3
	movups	%xmm4,32(%rsi)
	movdqu	32(%rdi),%xmm4
	movups	%xmm5,48(%rsi)
	movdqu	48(%rdi),%xmm5
	movups	%xmm6,64(%rsi)
	movdqu	64(%rdi),%xmm6
	movups	%xmm7,80(%rsi)
	movdqu	80(%rdi),%xmm7
	movups	%xmm8,96(%rsi)
	movdqu	96(%rdi),%xmm8
	movups	%xmm9,112(%rsi)
	leaq	128(%rsi),%rsi
	movdqu	112(%rdi),%xmm9
	leaq	128(%rdi),%rdi
.Lecb_dec_loop8_enter:

	call	_aesni_decrypt8

	movups	(%r11),%xmm0
	subq	$0x80,%rdx
	jnc	.Lecb_dec_loop8

	movups	%xmm2,(%rsi)
	pxor	%xmm2,%xmm2
	movq	%r11,%rcx
	movups	%xmm3,16(%rsi)
	pxor	%xmm3,%xmm3
	movl	%r10d,%eax
	movups	%xmm4,32(%rsi)
	pxor	%xmm4,%xmm4
	movups	%xmm5,48(%rsi)
	pxor	%xmm5,%xmm5
	movups	%xmm6,64(%rsi)
	pxor	%xmm6,%xmm6
	movups	%xmm7,80(%rsi)
	pxor	%xmm7,%xmm7
	movups	%xmm8,96(%rsi)
	pxor	%xmm8,%xmm8
	movups	%xmm9,112(%rsi)
	pxor	%xmm9,%xmm9
	leaq	128(%rsi),%rsi
	addq	$0x80,%rdx
	jz	.Lecb_ret

.Lecb_dec_tail:
	movups	(%rdi),%xmm2
	cmpq	$0x20,%rdx
	jb	.Lecb_dec_one
	movups	16(%rdi),%xmm3
	je	.Lecb_dec_two
	movups	32(%rdi),%xmm4
	cmpq	$0x40,%rdx
	jb	.Lecb_dec_three
	movups	48(%rdi),%xmm5
	je	.Lecb_dec_four
	movups	64(%rdi),%xmm6
	cmpq	$0x60,%rdx
	jb	.Lecb_dec_five
	movups	80(%rdi),%xmm7
	je	.Lecb_dec_six
	movups	96(%rdi),%xmm8
	movups	(%rcx),%xmm0
	xorps	%xmm9,%xmm9
	call	_aesni_decrypt8
	movups	%xmm2,(%rsi)
	pxor	%xmm2,%xmm2
	movups	%xmm3,16(%rsi)
	pxor	%xmm3,%xmm3
	movups	%xmm4,32(%rsi)
	pxor	%xmm4,%xmm4
	movups	%xmm5,48(%rsi)
	pxor	%xmm5,%xmm5
	movups	%xmm6,64(%rsi)
	pxor	%xmm6,%xmm6
	movups	%xmm7,80(%rsi)
	pxor	%xmm7,%xmm7
	movups	%xmm8,96(%rsi)
	pxor	%xmm8,%xmm8
	pxor	%xmm9,%xmm9
	jmp	.Lecb_ret
.align	16
.Lecb_dec_one:
	movups	(%rcx),%xmm0
	movups	16(%rcx),%xmm1
	leaq	32(%rcx),%rcx
	xorps	%xmm0,%xmm2
.Loop_dec1_4:
.byte	102,15,56,222,209
	decl	%eax
	movups	(%rcx),%xmm1
	leaq	16(%rcx),%rcx
	jnz	.Loop_dec1_4
.byte	102,15,56,223,209
	movups	%xmm2,(%rsi)
	pxor	%xmm2,%xmm2
	jmp	.Lecb_ret
.align	16
.Lecb_dec_two:
	call	_aesni_decrypt2
	movups	%xmm2,(%rsi)
	pxor	%xmm2,%xmm2
	movups	%xmm3,16(%rsi)
	pxor	%xmm3,%xmm3
	jmp	.Lecb_ret
.align	16
.Lecb_dec_three:
	call	_aesni_decrypt3
	movups	%xmm2,(%rsi)
	pxor	%xmm2,%xmm2
	movups	%xmm3,16(%rsi)
	pxor	%xmm3,%xmm3
	movups	%xmm4,32(%rsi)
	pxor	%xmm4,%xmm4
	jmp	.Lecb_ret
.align	16
.Lecb_dec_four:
	call	_aesni_decrypt4
	movups	%xmm2,(%rsi)
	pxor	%xmm2,%xmm2
	movups	%xmm3,16(%rsi)
	pxor	%xmm3,%xmm3
	movups	%xmm4,32(%rsi)
	pxor	%xmm4,%xmm4
	movups	%xmm5,48(%rsi)
	pxor	%xmm5,%xmm5
	jmp	.Lecb_ret
.align	16
.Lecb_dec_five:
	xorps	%xmm7,%xmm7
	call	_aesni_decrypt6
	movups	%xmm2,(%rsi)
	pxor	%xmm2,%xmm2
	movups	%xmm3,16(%rsi)
	pxor	%xmm3,%xmm3
	movups	%xmm4,32(%rsi)
	pxor	%xmm4,%xmm4
	movups	%xmm5,48(%rsi)
	pxor	%xmm5,%xmm5
	movups	%xmm6,64(%rsi)
	pxor	%xmm6,%xmm6
	pxor	%xmm7,%xmm7
	jmp	.Lecb_ret
.align	16
.Lecb_dec_six:
	call	_aesni_decrypt6
	movups	%xmm2,(%rsi)
	pxor	%xmm2,%xmm2
	movups	%xmm3,16(%rsi)
	pxor	%xmm3,%xmm3
	movups	%xmm4,32(%rsi)
	pxor	%xmm4,%xmm4
	movups	%xmm5,48(%rsi)
	pxor	%xmm5,%xmm5
	movups	%xmm6,64(%rsi)
	pxor	%xmm6,%xmm6
	movups	%xmm7,80(%rsi)
	pxor	%xmm7,%xmm7

.Lecb_ret:
	xorps	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_ecb_encrypt,.-aesni_ecb_encrypt
.globl	aesni_ccm64_encrypt_blocks
.type	aesni_ccm64_encrypt_blocks,@function
.align	16
aesni_ccm64_encrypt_blocks:
.cfi_startproc	
.byte	243,15,30,250
	movl	240(%rcx),%eax
	movdqu	(%r8),%xmm6
	movdqa	.Lincrement64(%rip),%xmm9
	movdqa	.Lbswap_mask(%rip),%xmm7

	shll	$4,%eax
	movl	$16,%r10d
	leaq	0(%rcx),%r11
	movdqu	(%r9),%xmm3
	movdqa	%xmm6,%xmm2
	leaq	32(%rcx,%rax,1),%rcx
.byte	102,15,56,0,247
	subq	%rax,%r10
	jmp	.Lccm64_enc_outer
.align	16
.Lccm64_enc_outer:
	movups	(%r11),%xmm0
	movq	%r10,%rax
	movups	(%rdi),%xmm8

	xorps	%xmm0,%xmm2
	movups	16(%r11),%xmm1
	xorps	%xmm8,%xmm0
	xorps	%xmm0,%xmm3
	movups	32(%r11),%xmm0

.Lccm64_enc2_loop:
.byte	102,15,56,220,209
.byte	102,15,56,220,217
	movups	(%rcx,%rax,1),%xmm1
	addq	$32,%rax
.byte	102,15,56,220,208
.byte	102,15,56,220,216
	movups	-16(%rcx,%rax,1),%xmm0
	jnz	.Lccm64_enc2_loop
.byte	102,15,56,220,209
.byte	102,15,56,220,217
	paddq	%xmm9,%xmm6
	decq	%rdx
.byte	102,15,56,221,208
.byte	102,15,56,221,216

	leaq	16(%rdi),%rdi
	xorps	%xmm2,%xmm8
	movdqa	%xmm6,%xmm2
	movups	%xmm8,(%rsi)
.byte	102,15,56,0,215
	leaq	16(%rsi),%rsi
	jnz	.Lccm64_enc_outer

	pxor	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	pxor	%xmm2,%xmm2
	movups	%xmm3,(%r9)
	pxor	%xmm3,%xmm3
	pxor	%xmm8,%xmm8
	pxor	%xmm6,%xmm6
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_ccm64_encrypt_blocks,.-aesni_ccm64_encrypt_blocks
.globl	aesni_ccm64_decrypt_blocks
.type	aesni_ccm64_decrypt_blocks,@function
.align	16
aesni_ccm64_decrypt_blocks:
.cfi_startproc	
.byte	243,15,30,250
	movl	240(%rcx),%eax
	movups	(%r8),%xmm6
	movdqu	(%r9),%xmm3
	movdqa	.Lincrement64(%rip),%xmm9
	movdqa	.Lbswap_mask(%rip),%xmm7

	movaps	%xmm6,%xmm2
	movl	%eax,%r10d
	movq	%rcx,%r11
.byte	102,15,56,0,247
	movups	(%rcx),%xmm0
	movups	16(%rcx),%xmm1
	leaq	32(%rcx),%rcx
	xorps	%xmm0,%xmm2
.Loop_enc1_5:
.byte	102,15,56,220,209
	decl	%eax
	movups	(%rcx),%xmm1
	leaq	16(%rcx),%rcx
	jnz	.Loop_enc1_5
.byte	102,15,56,221,209
	shll	$4,%r10d
	movl	$16,%eax
	movups	(%rdi),%xmm8
	paddq	%xmm9,%xmm6
	leaq	16(%rdi),%rdi
	subq	%r10,%rax
	leaq	32(%r11,%r10,1),%rcx
	movq	%rax,%r10
	jmp	.Lccm64_dec_outer
.align	16
.Lccm64_dec_outer:
	xorps	%xmm2,%xmm8
	movdqa	%xmm6,%xmm2
	movups	%xmm8,(%rsi)
	leaq	16(%rsi),%rsi
.byte	102,15,56,0,215

	subq	$1,%rdx
	jz	.Lccm64_dec_break

	movups	(%r11),%xmm0
	movq	%r10,%rax
	movups	16(%r11),%xmm1
	xorps	%xmm0,%xmm8
	xorps	%xmm0,%xmm2
	xorps	%xmm8,%xmm3
	movups	32(%r11),%xmm0
	jmp	.Lccm64_dec2_loop
.align	16
.Lccm64_dec2_loop:
.byte	102,15,56,220,209
.byte	102,15,56,220,217
	movups	(%rcx,%rax,1),%xmm1
	addq	$32,%rax
.byte	102,15,56,220,208
.byte	102,15,56,220,216
	movups	-16(%rcx,%rax,1),%xmm0
	jnz	.Lccm64_dec2_loop
	movups	(%rdi),%xmm8
	paddq	%xmm9,%xmm6
.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,221,208
.byte	102,15,56,221,216
	leaq	16(%rdi),%rdi
	jmp	.Lccm64_dec_outer

.align	16
.Lccm64_dec_break:

	movl	240(%r11),%eax
	movups	(%r11),%xmm0
	movups	16(%r11),%xmm1
	xorps	%xmm0,%xmm8
	leaq	32(%r11),%r11
	xorps	%xmm8,%xmm3
.Loop_enc1_6:
.byte	102,15,56,220,217
	decl	%eax
	movups	(%r11),%xmm1
	leaq	16(%r11),%r11
	jnz	.Loop_enc1_6
.byte	102,15,56,221,217
	pxor	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	pxor	%xmm2,%xmm2
	movups	%xmm3,(%r9)
	pxor	%xmm3,%xmm3
	pxor	%xmm8,%xmm8
	pxor	%xmm6,%xmm6
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_ccm64_decrypt_blocks,.-aesni_ccm64_decrypt_blocks
.globl	aesni_ctr32_encrypt_blocks
.type	aesni_ctr32_encrypt_blocks,@function
.align	16
aesni_ctr32_encrypt_blocks:
.cfi_startproc	
.byte	243,15,30,250
	cmpq	$1,%rdx
	jne	.Lctr32_bulk



	movups	(%r8),%xmm2
	movups	(%rdi),%xmm3
	movl	240(%rcx),%edx
	movups	(%rcx),%xmm0
	movups	16(%rcx),%xmm1
	leaq	32(%rcx),%rcx
	xorps	%xmm0,%xmm2
.Loop_enc1_7:
.byte	102,15,56,220,209
	decl	%edx
	movups	(%rcx),%xmm1
	leaq	16(%rcx),%rcx
	jnz	.Loop_enc1_7
.byte	102,15,56,221,209
	pxor	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	xorps	%xmm3,%xmm2
	pxor	%xmm3,%xmm3
	movups	%xmm2,(%rsi)
	xorps	%xmm2,%xmm2
	jmp	.Lctr32_epilogue

.align	16
.Lctr32_bulk:
	leaq	(%rsp),%r11
.cfi_def_cfa_register	%r11
	pushq	%rbp
.cfi_offset	%rbp,-16
	subq	$128,%rsp
	andq	$-16,%rsp




	movdqu	(%r8),%xmm2
	movdqu	(%rcx),%xmm0
	movl	12(%r8),%r8d
	pxor	%xmm0,%xmm2
	movl	12(%rcx),%ebp
	movdqa	%xmm2,0(%rsp)
	bswapl	%r8d
	movdqa	%xmm2,%xmm3
	movdqa	%xmm2,%xmm4
	movdqa	%xmm2,%xmm5
	movdqa	%xmm2,64(%rsp)
	movdqa	%xmm2,80(%rsp)
	movdqa	%xmm2,96(%rsp)
	movq	%rdx,%r10
	movdqa	%xmm2,112(%rsp)

	leaq	1(%r8),%rax
	leaq	2(%r8),%rdx
	bswapl	%eax
	bswapl	%edx
	xorl	%ebp,%eax
	xorl	%ebp,%edx
.byte	102,15,58,34,216,3
	leaq	3(%r8),%rax
	movdqa	%xmm3,16(%rsp)
.byte	102,15,58,34,226,3
	bswapl	%eax
	movq	%r10,%rdx
	leaq	4(%r8),%r10
	movdqa	%xmm4,32(%rsp)
	xorl	%ebp,%eax
	bswapl	%r10d
.byte	102,15,58,34,232,3
	xorl	%ebp,%r10d
	movdqa	%xmm5,48(%rsp)
	leaq	5(%r8),%r9
	movl	%r10d,64+12(%rsp)
	bswapl	%r9d
	leaq	6(%r8),%r10
	movl	240(%rcx),%eax
	xorl	%ebp,%r9d
	bswapl	%r10d
	movl	%r9d,80+12(%rsp)
	xorl	%ebp,%r10d
	leaq	7(%r8),%r9
	movl	%r10d,96+12(%rsp)
	bswapl	%r9d
	movl	OPENSSL_ia32cap_P+4(%rip),%r10d
	xorl	%ebp,%r9d
	andl	$71303168,%r10d
	movl	%r9d,112+12(%rsp)

	movups	16(%rcx),%xmm1

	movdqa	64(%rsp),%xmm6
	movdqa	80(%rsp),%xmm7

	cmpq	$8,%rdx
	jb	.Lctr32_tail

	subq	$6,%rdx
	cmpl	$4194304,%r10d
	je	.Lctr32_6x

	leaq	128(%rcx),%rcx
	subq	$2,%rdx
	jmp	.Lctr32_loop8

.align	16
.Lctr32_6x:
	shll	$4,%eax
	movl	$48,%r10d
	bswapl	%ebp
	leaq	32(%rcx,%rax,1),%rcx
	subq	%rax,%r10
	jmp	.Lctr32_loop6

.align	16
.Lctr32_loop6:
	addl	$6,%r8d
	movups	-48(%rcx,%r10,1),%xmm0
.byte	102,15,56,220,209
	movl	%r8d,%eax
	xorl	%ebp,%eax
.byte	102,15,56,220,217
.byte	0x0f,0x38,0xf1,0x44,0x24,12
	leal	1(%r8),%eax
.byte	102,15,56,220,225
	xorl	%ebp,%eax
.byte	0x0f,0x38,0xf1,0x44,0x24,28
.byte	102,15,56,220,233
	leal	2(%r8),%eax
	xorl	%ebp,%eax
.byte	102,15,56,220,241
.byte	0x0f,0x38,0xf1,0x44,0x24,44
	leal	3(%r8),%eax
.byte	102,15,56,220,249
	movups	-32(%rcx,%r10,1),%xmm1
	xorl	%ebp,%eax

.byte	102,15,56,220,208
.byte	0x0f,0x38,0xf1,0x44,0x24,60
	leal	4(%r8),%eax
.byte	102,15,56,220,216
	xorl	%ebp,%eax
.byte	0x0f,0x38,0xf1,0x44,0x24,76
.byte	102,15,56,220,224
	leal	5(%r8),%eax
	xorl	%ebp,%eax
.byte	102,15,56,220,232
.byte	0x0f,0x38,0xf1,0x44,0x24,92
	movq	%r10,%rax
.byte	102,15,56,220,240
.byte	102,15,56,220,248
	movups	-16(%rcx,%r10,1),%xmm0

	call	.Lenc_loop6

	movdqu	(%rdi),%xmm8
	movdqu	16(%rdi),%xmm9
	movdqu	32(%rdi),%xmm10
	movdqu	48(%rdi),%xmm11
	movdqu	64(%rdi),%xmm12
	movdqu	80(%rdi),%xmm13
	leaq	96(%rdi),%rdi
	movups	-64(%rcx,%r10,1),%xmm1
	pxor	%xmm2,%xmm8
	movaps	0(%rsp),%xmm2
	pxor	%xmm3,%xmm9
	movaps	16(%rsp),%xmm3
	pxor	%xmm4,%xmm10
	movaps	32(%rsp),%xmm4
	pxor	%xmm5,%xmm11
	movaps	48(%rsp),%xmm5
	pxor	%xmm6,%xmm12
	movaps	64(%rsp),%xmm6
	pxor	%xmm7,%xmm13
	movaps	80(%rsp),%xmm7
	movdqu	%xmm8,(%rsi)
	movdqu	%xmm9,16(%rsi)
	movdqu	%xmm10,32(%rsi)
	movdqu	%xmm11,48(%rsi)
	movdqu	%xmm12,64(%rsi)
	movdqu	%xmm13,80(%rsi)
	leaq	96(%rsi),%rsi

	subq	$6,%rdx
	jnc	.Lctr32_loop6

	addq	$6,%rdx
	jz	.Lctr32_done

	leal	-48(%r10),%eax
	leaq	-80(%rcx,%r10,1),%rcx
	negl	%eax
	shrl	$4,%eax
	jmp	.Lctr32_tail

.align	32
.Lctr32_loop8:
	addl	$8,%r8d
	movdqa	96(%rsp),%xmm8
.byte	102,15,56,220,209
	movl	%r8d,%r9d
	movdqa	112(%rsp),%xmm9
.byte	102,15,56,220,217
	bswapl	%r9d
	movups	32-128(%rcx),%xmm0
.byte	102,15,56,220,225
	xorl	%ebp,%r9d
	nop
.byte	102,15,56,220,233
	movl	%r9d,0+12(%rsp)
	leaq	1(%r8),%r9
.byte	102,15,56,220,241
.byte	102,15,56,220,249
.byte	102,68,15,56,220,193
.byte	102,68,15,56,220,201
	movups	48-128(%rcx),%xmm1
	bswapl	%r9d
.byte	102,15,56,220,208
.byte	102,15,56,220,216
	xorl	%ebp,%r9d
.byte	0x66,0x90
.byte	102,15,56,220,224
.byte	102,15,56,220,232
	movl	%r9d,16+12(%rsp)
	leaq	2(%r8),%r9
.byte	102,15,56,220,240
.byte	102,15,56,220,248
.byte	102,68,15,56,220,192
.byte	102,68,15,56,220,200
	movups	64-128(%rcx),%xmm0
	bswapl	%r9d
.byte	102,15,56,220,209
.byte	102,15,56,220,217
	xorl	%ebp,%r9d
.byte	0x66,0x90
.byte	102,15,56,220,225
.byte	102,15,56,220,233
	movl	%r9d,32+12(%rsp)
	leaq	3(%r8),%r9
.byte	102,15,56,220,241
.byte	102,15,56,220,249
.byte	102,68,15,56,220,193
.byte	102,68,15,56,220,201
	movups	80-128(%rcx),%xmm1
	bswapl	%r9d
.byte	102,15,56,220,208
.byte	102,15,56,220,216
	xorl	%ebp,%r9d
.byte	0x66,0x90
.byte	102,15,56,220,224
.byte	102,15,56,220,232
	movl	%r9d,48+12(%rsp)
	leaq	4(%r8),%r9
.byte	102,15,56,220,240
.byte	102,15,56,220,248
.byte	102,68,15,56,220,192
.byte	102,68,15,56,220,200
	movups	96-128(%rcx),%xmm0
	bswapl	%r9d
.byte	102,15,56,220,209
.byte	102,15,56,220,217
	xorl	%ebp,%r9d
.byte	0x66,0x90
.byte	102,15,56,220,225
.byte	102,15,56,220,233
	movl	%r9d,64+12(%rsp)
	leaq	5(%r8),%r9
.byte	102,15,56,220,241
.byte	102,15,56,220,249
.byte	102,68,15,56,220,193
.byte	102,68,15,56,220,201
	movups	112-128(%rcx),%xmm1
	bswapl	%r9d
.byte	102,15,56,220,208
.byte	102,15,56,220,216
	xorl	%ebp,%r9d
.byte	0x66,0x90
.byte	102,15,56,220,224
.byte	102,15,56,220,232
	movl	%r9d,80+12(%rsp)
	leaq	6(%r8),%r9
.byte	102,15,56,220,240
.byte	102,15,56,220,248
.byte	102,68,15,56,220,192
.byte	102,68,15,56,220,200
	movups	128-128(%rcx),%xmm0
	bswapl	%r9d
.byte	102,15,56,220,209
.byte	102,15,56,220,217
	xorl	%ebp,%r9d
.byte	0x66,0x90
.byte	102,15,56,220,225
.byte	102,15,56,220,233
	movl	%r9d,96+12(%rsp)
	leaq	7(%r8),%r9
.byte	102,15,56,220,241
.byte	102,15,56,220,249
.byte	102,68,15,56,220,193
.byte	102,68,15,56,220,201
	movups	144-128(%rcx),%xmm1
	bswapl	%r9d
.byte	102,15,56,220,208
.byte	102,15,56,220,216
.byte	102,15,56,220,224
	xorl	%ebp,%r9d
	movdqu	0(%rdi),%xmm10
.byte	102,15,56,220,232
	movl	%r9d,112+12(%rsp)
	cmpl	$11,%eax
.byte	102,15,56,220,240
.byte	102,15,56,220,248
.byte	102,68,15,56,220,192
.byte	102,68,15,56,220,200
	movups	160-128(%rcx),%xmm0

	jb	.Lctr32_enc_done

.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.byte	102,15,56,220,233
.byte	102,15,56,220,241
.byte	102,15,56,220,249
.byte	102,68,15,56,220,193
.byte	102,68,15,56,220,201
	movups	176-128(%rcx),%xmm1

.byte	102,15,56,220,208
.byte	102,15,56,220,216
.byte	102,15,56,220,224
.byte	102,15,56,220,232
.byte	102,15,56,220,240
.byte	102,15,56,220,248
.byte	102,68,15,56,220,192
.byte	102,68,15,56,220,200
	movups	192-128(%rcx),%xmm0
	je	.Lctr32_enc_done

.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.byte	102,15,56,220,233
.byte	102,15,56,220,241
.byte	102,15,56,220,249
.byte	102,68,15,56,220,193
.byte	102,68,15,56,220,201
	movups	208-128(%rcx),%xmm1

.byte	102,15,56,220,208
.byte	102,15,56,220,216
.byte	102,15,56,220,224
.byte	102,15,56,220,232
.byte	102,15,56,220,240
.byte	102,15,56,220,248
.byte	102,68,15,56,220,192
.byte	102,68,15,56,220,200
	movups	224-128(%rcx),%xmm0
	jmp	.Lctr32_enc_done

.align	16
.Lctr32_enc_done:
	movdqu	16(%rdi),%xmm11
	pxor	%xmm0,%xmm10
	movdqu	32(%rdi),%xmm12
	pxor	%xmm0,%xmm11
	movdqu	48(%rdi),%xmm13
	pxor	%xmm0,%xmm12
	movdqu	64(%rdi),%xmm14
	pxor	%xmm0,%xmm13
	movdqu	80(%rdi),%xmm15
	pxor	%xmm0,%xmm14
	pxor	%xmm0,%xmm15
.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.byte	102,15,56,220,233
.byte	102,15,56,220,241
.byte	102,15,56,220,249
.byte	102,68,15,56,220,193
.byte	102,68,15,56,220,201
	movdqu	96(%rdi),%xmm1
	leaq	128(%rdi),%rdi

.byte	102,65,15,56,221,210
	pxor	%xmm0,%xmm1
	movdqu	112-128(%rdi),%xmm10
.byte	102,65,15,56,221,219
	pxor	%xmm0,%xmm10
	movdqa	0(%rsp),%xmm11
.byte	102,65,15,56,221,228
.byte	102,65,15,56,221,237
	movdqa	16(%rsp),%xmm12
	movdqa	32(%rsp),%xmm13
.byte	102,65,15,56,221,246
.byte	102,65,15,56,221,255
	movdqa	48(%rsp),%xmm14
	movdqa	64(%rsp),%xmm15
.byte	102,68,15,56,221,193
	movdqa	80(%rsp),%xmm0
	movups	16-128(%rcx),%xmm1
.byte	102,69,15,56,221,202

	movups	%xmm2,(%rsi)
	movdqa	%xmm11,%xmm2
	movups	%xmm3,16(%rsi)
	movdqa	%xmm12,%xmm3
	movups	%xmm4,32(%rsi)
	movdqa	%xmm13,%xmm4
	movups	%xmm5,48(%rsi)
	movdqa	%xmm14,%xmm5
	movups	%xmm6,64(%rsi)
	movdqa	%xmm15,%xmm6
	movups	%xmm7,80(%rsi)
	movdqa	%xmm0,%xmm7
	movups	%xmm8,96(%rsi)
	movups	%xmm9,112(%rsi)
	leaq	128(%rsi),%rsi

	subq	$8,%rdx
	jnc	.Lctr32_loop8

	addq	$8,%rdx
	jz	.Lctr32_done
	leaq	-128(%rcx),%rcx

.Lctr32_tail:


	leaq	16(%rcx),%rcx
	cmpq	$4,%rdx
	jb	.Lctr32_loop3
	je	.Lctr32_loop4


	shll	$4,%eax
	movdqa	96(%rsp),%xmm8
	pxor	%xmm9,%xmm9

	movups	16(%rcx),%xmm0
.byte	102,15,56,220,209
.byte	102,15,56,220,217
	leaq	32-16(%rcx,%rax,1),%rcx
	negq	%rax
.byte	102,15,56,220,225
	addq	$16,%rax
	movups	(%rdi),%xmm10
.byte	102,15,56,220,233
.byte	102,15,56,220,241
	movups	16(%rdi),%xmm11
	movups	32(%rdi),%xmm12
.byte	102,15,56,220,249
.byte	102,68,15,56,220,193

	call	.Lenc_loop8_enter

	movdqu	48(%rdi),%xmm13
	pxor	%xmm10,%xmm2
	movdqu	64(%rdi),%xmm10
	pxor	%xmm11,%xmm3
	movdqu	%xmm2,(%rsi)
	pxor	%xmm12,%xmm4
	movdqu	%xmm3,16(%rsi)
	pxor	%xmm13,%xmm5
	movdqu	%xmm4,32(%rsi)
	pxor	%xmm10,%xmm6
	movdqu	%xmm5,48(%rsi)
	movdqu	%xmm6,64(%rsi)
	cmpq	$6,%rdx
	jb	.Lctr32_done

	movups	80(%rdi),%xmm11
	xorps	%xmm11,%xmm7
	movups	%xmm7,80(%rsi)
	je	.Lctr32_done

	movups	96(%rdi),%xmm12
	xorps	%xmm12,%xmm8
	movups	%xmm8,96(%rsi)
	jmp	.Lctr32_done

.align	32
.Lctr32_loop4:
.byte	102,15,56,220,209
	leaq	16(%rcx),%rcx
	decl	%eax
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.byte	102,15,56,220,233
	movups	(%rcx),%xmm1
	jnz	.Lctr32_loop4
.byte	102,15,56,221,209
.byte	102,15,56,221,217
	movups	(%rdi),%xmm10
	movups	16(%rdi),%xmm11
.byte	102,15,56,221,225
.byte	102,15,56,221,233
	movups	32(%rdi),%xmm12
	movups	48(%rdi),%xmm13

	xorps	%xmm10,%xmm2
	movups	%xmm2,(%rsi)
	xorps	%xmm11,%xmm3
	movups	%xmm3,16(%rsi)
	pxor	%xmm12,%xmm4
	movdqu	%xmm4,32(%rsi)
	pxor	%xmm13,%xmm5
	movdqu	%xmm5,48(%rsi)
	jmp	.Lctr32_done

.align	32
.Lctr32_loop3:
.byte	102,15,56,220,209
	leaq	16(%rcx),%rcx
	decl	%eax
.byte	102,15,56,220,217
.byte	102,15,56,220,225
	movups	(%rcx),%xmm1
	jnz	.Lctr32_loop3
.byte	102,15,56,221,209
.byte	102,15,56,221,217
.byte	102,15,56,221,225

	movups	(%rdi),%xmm10
	xorps	%xmm10,%xmm2
	movups	%xmm2,(%rsi)
	cmpq	$2,%rdx
	jb	.Lctr32_done

	movups	16(%rdi),%xmm11
	xorps	%xmm11,%xmm3
	movups	%xmm3,16(%rsi)
	je	.Lctr32_done

	movups	32(%rdi),%xmm12
	xorps	%xmm12,%xmm4
	movups	%xmm4,32(%rsi)

.Lctr32_done:
	xorps	%xmm0,%xmm0
	xorl	%ebp,%ebp
	pxor	%xmm1,%xmm1
	pxor	%xmm2,%xmm2
	pxor	%xmm3,%xmm3
	pxor	%xmm4,%xmm4
	pxor	%xmm5,%xmm5
	pxor	%xmm6,%xmm6
	pxor	%xmm7,%xmm7
	movaps	%xmm0,0(%rsp)
	pxor	%xmm8,%xmm8
	movaps	%xmm0,16(%rsp)
	pxor	%xmm9,%xmm9
	movaps	%xmm0,32(%rsp)
	pxor	%xmm10,%xmm10
	movaps	%xmm0,48(%rsp)
	pxor	%xmm11,%xmm11
	movaps	%xmm0,64(%rsp)
	pxor	%xmm12,%xmm12
	movaps	%xmm0,80(%rsp)
	pxor	%xmm13,%xmm13
	movaps	%xmm0,96(%rsp)
	pxor	%xmm14,%xmm14
	movaps	%xmm0,112(%rsp)
	pxor	%xmm15,%xmm15
	movq	-8(%r11),%rbp
.cfi_restore	%rbp
	leaq	(%r11),%rsp
.cfi_def_cfa_register	%rsp
.Lctr32_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_ctr32_encrypt_blocks,.-aesni_ctr32_encrypt_blocks
.globl	aesni_xts_encrypt
.type	aesni_xts_encrypt,@function
.align	16
aesni_xts_encrypt:
.cfi_startproc	
.byte	243,15,30,250
	leaq	(%rsp),%r11
.cfi_def_cfa_register	%r11
	pushq	%rbp
.cfi_offset	%rbp,-16
	subq	$112,%rsp
	andq	$-16,%rsp
	movups	(%r9),%xmm2
	movl	240(%r8),%eax
	movl	240(%rcx),%r10d
	movups	(%r8),%xmm0
	movups	16(%r8),%xmm1
	leaq	32(%r8),%r8
	xorps	%xmm0,%xmm2
.Loop_enc1_8:
.byte	102,15,56,220,209
	decl	%eax
	movups	(%r8),%xmm1
	leaq	16(%r8),%r8
	jnz	.Loop_enc1_8
.byte	102,15,56,221,209
	movups	(%rcx),%xmm0
	movq	%rcx,%rbp
	movl	%r10d,%eax
	shll	$4,%r10d
	movq	%rdx,%r9
	andq	$-16,%rdx

	movups	16(%rcx,%r10,1),%xmm1

	movdqa	.Lxts_magic(%rip),%xmm8
	movdqa	%xmm2,%xmm15
	pshufd	$0x5f,%xmm2,%xmm9
	pxor	%xmm0,%xmm1
	movdqa	%xmm9,%xmm14
	paddd	%xmm9,%xmm9
	movdqa	%xmm15,%xmm10
	psrad	$31,%xmm14
	paddq	%xmm15,%xmm15
	pand	%xmm8,%xmm14
	pxor	%xmm0,%xmm10
	pxor	%xmm14,%xmm15
	movdqa	%xmm9,%xmm14
	paddd	%xmm9,%xmm9
	movdqa	%xmm15,%xmm11
	psrad	$31,%xmm14
	paddq	%xmm15,%xmm15
	pand	%xmm8,%xmm14
	pxor	%xmm0,%xmm11
	pxor	%xmm14,%xmm15
	movdqa	%xmm9,%xmm14
	paddd	%xmm9,%xmm9
	movdqa	%xmm15,%xmm12
	psrad	$31,%xmm14
	paddq	%xmm15,%xmm15
	pand	%xmm8,%xmm14
	pxor	%xmm0,%xmm12
	pxor	%xmm14,%xmm15
	movdqa	%xmm9,%xmm14
	paddd	%xmm9,%xmm9
	movdqa	%xmm15,%xmm13
	psrad	$31,%xmm14
	paddq	%xmm15,%xmm15
	pand	%xmm8,%xmm14
	pxor	%xmm0,%xmm13
	pxor	%xmm14,%xmm15
	movdqa	%xmm15,%xmm14
	psrad	$31,%xmm9
	paddq	%xmm15,%xmm15
	pand	%xmm8,%xmm9
	pxor	%xmm0,%xmm14
	pxor	%xmm9,%xmm15
	movaps	%xmm1,96(%rsp)

	subq	$96,%rdx
	jc	.Lxts_enc_short

	movl	$16+96,%eax
	leaq	32(%rbp,%r10,1),%rcx
	subq	%r10,%rax
	movups	16(%rbp),%xmm1
	movq	%rax,%r10
	leaq	.Lxts_magic(%rip),%r8
	jmp	.Lxts_enc_grandloop

.align	32
.Lxts_enc_grandloop:
	movdqu	0(%rdi),%xmm2
	movdqa	%xmm0,%xmm8
	movdqu	16(%rdi),%xmm3
	pxor	%xmm10,%xmm2
	movdqu	32(%rdi),%xmm4
	pxor	%xmm11,%xmm3
.byte	102,15,56,220,209
	movdqu	48(%rdi),%xmm5
	pxor	%xmm12,%xmm4
.byte	102,15,56,220,217
	movdqu	64(%rdi),%xmm6
	pxor	%xmm13,%xmm5
.byte	102,15,56,220,225
	movdqu	80(%rdi),%xmm7
	pxor	%xmm15,%xmm8
	movdqa	96(%rsp),%xmm9
	pxor	%xmm14,%xmm6
.byte	102,15,56,220,233
	movups	32(%rbp),%xmm0
	leaq	96(%rdi),%rdi
	pxor	%xmm8,%xmm7

	pxor	%xmm9,%xmm10
.byte	102,15,56,220,241
	pxor	%xmm9,%xmm11
	movdqa	%xmm10,0(%rsp)
.byte	102,15,56,220,249
	movups	48(%rbp),%xmm1
	pxor	%xmm9,%xmm12

.byte	102,15,56,220,208
	pxor	%xmm9,%xmm13
	movdqa	%xmm11,16(%rsp)
.byte	102,15,56,220,216
	pxor	%xmm9,%xmm14
	movdqa	%xmm12,32(%rsp)
.byte	102,15,56,220,224
.byte	102,15,56,220,232
	pxor	%xmm9,%xmm8
	movdqa	%xmm14,64(%rsp)
.byte	102,15,56,220,240
.byte	102,15,56,220,248
	movups	64(%rbp),%xmm0
	movdqa	%xmm8,80(%rsp)
	pshufd	$0x5f,%xmm15,%xmm9
	jmp	.Lxts_enc_loop6
.align	32
.Lxts_enc_loop6:
.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.byte	102,15,56,220,233
.byte	102,15,56,220,241
.byte	102,15,56,220,249
	movups	-64(%rcx,%rax,1),%xmm1
	addq	$32,%rax

.byte	102,15,56,220,208
.byte	102,15,56,220,216
.byte	102,15,56,220,224
.byte	102,15,56,220,232
.byte	102,15,56,220,240
.byte	102,15,56,220,248
	movups	-80(%rcx,%rax,1),%xmm0
	jnz	.Lxts_enc_loop6

	movdqa	(%r8),%xmm8
	movdqa	%xmm9,%xmm14
	paddd	%xmm9,%xmm9
.byte	102,15,56,220,209
	paddq	%xmm15,%xmm15
	psrad	$31,%xmm14
.byte	102,15,56,220,217
	pand	%xmm8,%xmm14
	movups	(%rbp),%xmm10
.byte	102,15,56,220,225
.byte	102,15,56,220,233
.byte	102,15,56,220,241
	pxor	%xmm14,%xmm15
	movaps	%xmm10,%xmm11
.byte	102,15,56,220,249
	movups	-64(%rcx),%xmm1

	movdqa	%xmm9,%xmm14
.byte	102,15,56,220,208
	paddd	%xmm9,%xmm9
	pxor	%xmm15,%xmm10
.byte	102,15,56,220,216
	psrad	$31,%xmm14
	paddq	%xmm15,%xmm15
.byte	102,15,56,220,224
.byte	102,15,56,220,232
	pand	%xmm8,%xmm14
	movaps	%xmm11,%xmm12
.byte	102,15,56,220,240
	pxor	%xmm14,%xmm15
	movdqa	%xmm9,%xmm14
.byte	102,15,56,220,248
	movups	-48(%rcx),%xmm0

	paddd	%xmm9,%xmm9
.byte	102,15,56,220,209
	pxor	%xmm15,%xmm11
	psrad	$31,%xmm14
.byte	102,15,56,220,217
	paddq	%xmm15,%xmm15
	pand	%xmm8,%xmm14
.byte	102,15,56,220,225
.byte	102,15,56,220,233
	movdqa	%xmm13,48(%rsp)
	pxor	%xmm14,%xmm15
.byte	102,15,56,220,241
	movaps	%xmm12,%xmm13
	movdqa	%xmm9,%xmm14
.byte	102,15,56,220,249
	movups	-32(%rcx),%xmm1

	paddd	%xmm9,%xmm9
.byte	102,15,56,220,208
	pxor	%xmm15,%xmm12
	psrad	$31,%xmm14
.byte	102,15,56,220,216
	paddq	%xmm15,%xmm15
	pand	%xmm8,%xmm14
.byte	102,15,56,220,224
.byte	102,15,56,220,232
.byte	102,15,56,220,240
	pxor	%xmm14,%xmm15
	movaps	%xmm13,%xmm14
.byte	102,15,56,220,248

	movdqa	%xmm9,%xmm0
	paddd	%xmm9,%xmm9
.byte	102,15,56,220,209
	pxor	%xmm15,%xmm13
	psrad	$31,%xmm0
.byte	102,15,56,220,217
	paddq	%xmm15,%xmm15
	pand	%xmm8,%xmm0
.byte	102,15,56,220,225
.byte	102,15,56,220,233
	pxor	%xmm0,%xmm15
	movups	(%rbp),%xmm0
.byte	102,15,56,220,241
.byte	102,15,56,220,249
	movups	16(%rbp),%xmm1

	pxor	%xmm15,%xmm14
.byte	102,15,56,221,84,36,0
	psrad	$31,%xmm9
	paddq	%xmm15,%xmm15
.byte	102,15,56,221,92,36,16
.byte	102,15,56,221,100,36,32
	pand	%xmm8,%xmm9
	movq	%r10,%rax
.byte	102,15,56,221,108,36,48
.byte	102,15,56,221,116,36,64
.byte	102,15,56,221,124,36,80
	pxor	%xmm9,%xmm15

	leaq	96(%rsi),%rsi
	movups	%xmm2,-96(%rsi)
	movups	%xmm3,-80(%rsi)
	movups	%xmm4,-64(%rsi)
	movups	%xmm5,-48(%rsi)
	movups	%xmm6,-32(%rsi)
	movups	%xmm7,-16(%rsi)
	subq	$96,%rdx
	jnc	.Lxts_enc_grandloop

	movl	$16+96,%eax
	subl	%r10d,%eax
	movq	%rbp,%rcx
	shrl	$4,%eax

.Lxts_enc_short:

	movl	%eax,%r10d
	pxor	%xmm0,%xmm10
	addq	$96,%rdx
	jz	.Lxts_enc_done

	pxor	%xmm0,%xmm11
	cmpq	$0x20,%rdx
	jb	.Lxts_enc_one
	pxor	%xmm0,%xmm12
	je	.Lxts_enc_two

	pxor	%xmm0,%xmm13
	cmpq	$0x40,%rdx
	jb	.Lxts_enc_three
	pxor	%xmm0,%xmm14
	je	.Lxts_enc_four

	movdqu	(%rdi),%xmm2
	movdqu	16(%rdi),%xmm3
	movdqu	32(%rdi),%xmm4
	pxor	%xmm10,%xmm2
	movdqu	48(%rdi),%xmm5
	pxor	%xmm11,%xmm3
	movdqu	64(%rdi),%xmm6
	leaq	80(%rdi),%rdi
	pxor	%xmm12,%xmm4
	pxor	%xmm13,%xmm5
	pxor	%xmm14,%xmm6
	pxor	%xmm7,%xmm7

	call	_aesni_encrypt6

	xorps	%xmm10,%xmm2
	movdqa	%xmm15,%xmm10
	xorps	%xmm11,%xmm3
	xorps	%xmm12,%xmm4
	movdqu	%xmm2,(%rsi)
	xorps	%xmm13,%xmm5
	movdqu	%xmm3,16(%rsi)
	xorps	%xmm14,%xmm6
	movdqu	%xmm4,32(%rsi)
	movdqu	%xmm5,48(%rsi)
	movdqu	%xmm6,64(%rsi)
	leaq	80(%rsi),%rsi
	jmp	.Lxts_enc_done

.align	16
.Lxts_enc_one:
	movups	(%rdi),%xmm2
	leaq	16(%rdi),%rdi
	xorps	%xmm10,%xmm2
	movups	(%rcx),%xmm0
	movups	16(%rcx),%xmm1
	leaq	32(%rcx),%rcx
	xorps	%xmm0,%xmm2
.Loop_enc1_9:
.byte	102,15,56,220,209
	decl	%eax
	movups	(%rcx),%xmm1
	leaq	16(%rcx),%rcx
	jnz	.Loop_enc1_9
.byte	102,15,56,221,209
	xorps	%xmm10,%xmm2
	movdqa	%xmm11,%xmm10
	movups	%xmm2,(%rsi)
	leaq	16(%rsi),%rsi
	jmp	.Lxts_enc_done

.align	16
.Lxts_enc_two:
	movups	(%rdi),%xmm2
	movups	16(%rdi),%xmm3
	leaq	32(%rdi),%rdi
	xorps	%xmm10,%xmm2
	xorps	%xmm11,%xmm3

	call	_aesni_encrypt2

	xorps	%xmm10,%xmm2
	movdqa	%xmm12,%xmm10
	xorps	%xmm11,%xmm3
	movups	%xmm2,(%rsi)
	movups	%xmm3,16(%rsi)
	leaq	32(%rsi),%rsi
	jmp	.Lxts_enc_done

.align	16
.Lxts_enc_three:
	movups	(%rdi),%xmm2
	movups	16(%rdi),%xmm3
	movups	32(%rdi),%xmm4
	leaq	48(%rdi),%rdi
	xorps	%xmm10,%xmm2
	xorps	%xmm11,%xmm3
	xorps	%xmm12,%xmm4

	call	_aesni_encrypt3

	xorps	%xmm10,%xmm2
	movdqa	%xmm13,%xmm10
	xorps	%xmm11,%xmm3
	xorps	%xmm12,%xmm4
	movups	%xmm2,(%rsi)
	movups	%xmm3,16(%rsi)
	movups	%xmm4,32(%rsi)
	leaq	48(%rsi),%rsi
	jmp	.Lxts_enc_done

.align	16
.Lxts_enc_four:
	movups	(%rdi),%xmm2
	movups	16(%rdi),%xmm3
	movups	32(%rdi),%xmm4
	xorps	%xmm10,%xmm2
	movups	48(%rdi),%xmm5
	leaq	64(%rdi),%rdi
	xorps	%xmm11,%xmm3
	xorps	%xmm12,%xmm4
	xorps	%xmm13,%xmm5

	call	_aesni_encrypt4

	pxor	%xmm10,%xmm2
	movdqa	%xmm14,%xmm10
	pxor	%xmm11,%xmm3
	pxor	%xmm12,%xmm4
	movdqu	%xmm2,(%rsi)
	pxor	%xmm13,%xmm5
	movdqu	%xmm3,16(%rsi)
	movdqu	%xmm4,32(%rsi)
	movdqu	%xmm5,48(%rsi)
	leaq	64(%rsi),%rsi
	jmp	.Lxts_enc_done

.align	16
.Lxts_enc_done:
	andq	$15,%r9
	jz	.Lxts_enc_ret
	movq	%r9,%rdx

.Lxts_enc_steal:
	movzbl	(%rdi),%eax
	movzbl	-16(%rsi),%ecx
	leaq	1(%rdi),%rdi
	movb	%al,-16(%rsi)
	movb	%cl,0(%rsi)
	leaq	1(%rsi),%rsi
	subq	$1,%rdx
	jnz	.Lxts_enc_steal

	subq	%r9,%rsi
	movq	%rbp,%rcx
	movl	%r10d,%eax

	movups	-16(%rsi),%xmm2
	xorps	%xmm10,%xmm2
	movups	(%rcx),%xmm0
	movups	16(%rcx),%xmm1
	leaq	32(%rcx),%rcx
	xorps	%xmm0,%xmm2
.Loop_enc1_10:
.byte	102,15,56,220,209
	decl	%eax
	movups	(%rcx),%xmm1
	leaq	16(%rcx),%rcx
	jnz	.Loop_enc1_10
.byte	102,15,56,221,209
	xorps	%xmm10,%xmm2
	movups	%xmm2,-16(%rsi)

.Lxts_enc_ret:
	xorps	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	pxor	%xmm2,%xmm2
	pxor	%xmm3,%xmm3
	pxor	%xmm4,%xmm4
	pxor	%xmm5,%xmm5
	pxor	%xmm6,%xmm6
	pxor	%xmm7,%xmm7
	movaps	%xmm0,0(%rsp)
	pxor	%xmm8,%xmm8
	movaps	%xmm0,16(%rsp)
	pxor	%xmm9,%xmm9
	movaps	%xmm0,32(%rsp)
	pxor	%xmm10,%xmm10
	movaps	%xmm0,48(%rsp)
	pxor	%xmm11,%xmm11
	movaps	%xmm0,64(%rsp)
	pxor	%xmm12,%xmm12
	movaps	%xmm0,80(%rsp)
	pxor	%xmm13,%xmm13
	movaps	%xmm0,96(%rsp)
	pxor	%xmm14,%xmm14
	pxor	%xmm15,%xmm15
	movq	-8(%r11),%rbp
.cfi_restore	%rbp
	leaq	(%r11),%rsp
.cfi_def_cfa_register	%rsp
.Lxts_enc_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_xts_encrypt,.-aesni_xts_encrypt
.globl	aesni_xts_decrypt
.type	aesni_xts_decrypt,@function
.align	16
aesni_xts_decrypt:
.cfi_startproc	
.byte	243,15,30,250
	leaq	(%rsp),%r11
.cfi_def_cfa_register	%r11
	pushq	%rbp
.cfi_offset	%rbp,-16
	subq	$112,%rsp
	andq	$-16,%rsp
	movups	(%r9),%xmm2
	movl	240(%r8),%eax
	movl	240(%rcx),%r10d
	movups	(%r8),%xmm0
	movups	16(%r8),%xmm1
	leaq	32(%r8),%r8
	xorps	%xmm0,%xmm2
.Loop_enc1_11:
.byte	102,15,56,220,209
	decl	%eax
	movups	(%r8),%xmm1
	leaq	16(%r8),%r8
	jnz	.Loop_enc1_11
.byte	102,15,56,221,209
	xorl	%eax,%eax
	testq	$15,%rdx
	setnz	%al
	shlq	$4,%rax
	subq	%rax,%rdx

	movups	(%rcx),%xmm0
	movq	%rcx,%rbp
	movl	%r10d,%eax
	shll	$4,%r10d
	movq	%rdx,%r9
	andq	$-16,%rdx

	movups	16(%rcx,%r10,1),%xmm1

	movdqa	.Lxts_magic(%rip),%xmm8
	movdqa	%xmm2,%xmm15
	pshufd	$0x5f,%xmm2,%xmm9
	pxor	%xmm0,%xmm1
	movdqa	%xmm9,%xmm14
	paddd	%xmm9,%xmm9
	movdqa	%xmm15,%xmm10
	psrad	$31,%xmm14
	paddq	%xmm15,%xmm15
	pand	%xmm8,%xmm14
	pxor	%xmm0,%xmm10
	pxor	%xmm14,%xmm15
	movdqa	%xmm9,%xmm14
	paddd	%xmm9,%xmm9
	movdqa	%xmm15,%xmm11
	psrad	$31,%xmm14
	paddq	%xmm15,%xmm15
	pand	%xmm8,%xmm14
	pxor	%xmm0,%xmm11
	pxor	%xmm14,%xmm15
	movdqa	%xmm9,%xmm14
	paddd	%xmm9,%xmm9
	movdqa	%xmm15,%xmm12
	psrad	$31,%xmm14
	paddq	%xmm15,%xmm15
	pand	%xmm8,%xmm14
	pxor	%xmm0,%xmm12
	pxor	%xmm14,%xmm15
	movdqa	%xmm9,%xmm14
	paddd	%xmm9,%xmm9
	movdqa	%xmm15,%xmm13
	psrad	$31,%xmm14
	paddq	%xmm15,%xmm15
	pand	%xmm8,%xmm14
	pxor	%xmm0,%xmm13
	pxor	%xmm14,%xmm15
	movdqa	%xmm15,%xmm14
	psrad	$31,%xmm9
	paddq	%xmm15,%xmm15
	pand	%xmm8,%xmm9
	pxor	%xmm0,%xmm14
	pxor	%xmm9,%xmm15
	movaps	%xmm1,96(%rsp)

	subq	$96,%rdx
	jc	.Lxts_dec_short

	movl	$16+96,%eax
	leaq	32(%rbp,%r10,1),%rcx
	subq	%r10,%rax
	movups	16(%rbp),%xmm1
	movq	%rax,%r10
	leaq	.Lxts_magic(%rip),%r8
	jmp	.Lxts_dec_grandloop

.align	32
.Lxts_dec_grandloop:
	movdqu	0(%rdi),%xmm2
	movdqa	%xmm0,%xmm8
	movdqu	16(%rdi),%xmm3
	pxor	%xmm10,%xmm2
	movdqu	32(%rdi),%xmm4
	pxor	%xmm11,%xmm3
.byte	102,15,56,222,209
	movdqu	48(%rdi),%xmm5
	pxor	%xmm12,%xmm4
.byte	102,15,56,222,217
	movdqu	64(%rdi),%xmm6
	pxor	%xmm13,%xmm5
.byte	102,15,56,222,225
	movdqu	80(%rdi),%xmm7
	pxor	%xmm15,%xmm8
	movdqa	96(%rsp),%xmm9
	pxor	%xmm14,%xmm6
.byte	102,15,56,222,233
	movups	32(%rbp),%xmm0
	leaq	96(%rdi),%rdi
	pxor	%xmm8,%xmm7

	pxor	%xmm9,%xmm10
.byte	102,15,56,222,241
	pxor	%xmm9,%xmm11
	movdqa	%xmm10,0(%rsp)
.byte	102,15,56,222,249
	movups	48(%rbp),%xmm1
	pxor	%xmm9,%xmm12

.byte	102,15,56,222,208
	pxor	%xmm9,%xmm13
	movdqa	%xmm11,16(%rsp)
.byte	102,15,56,222,216
	pxor	%xmm9,%xmm14
	movdqa	%xmm12,32(%rsp)
.byte	102,15,56,222,224
.byte	102,15,56,222,232
	pxor	%xmm9,%xmm8
	movdqa	%xmm14,64(%rsp)
.byte	102,15,56,222,240
.byte	102,15,56,222,248
	movups	64(%rbp),%xmm0
	movdqa	%xmm8,80(%rsp)
	pshufd	$0x5f,%xmm15,%xmm9
	jmp	.Lxts_dec_loop6
.align	32
.Lxts_dec_loop6:
.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,222,233
.byte	102,15,56,222,241
.byte	102,15,56,222,249
	movups	-64(%rcx,%rax,1),%xmm1
	addq	$32,%rax

.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
.byte	102,15,56,222,232
.byte	102,15,56,222,240
.byte	102,15,56,222,248
	movups	-80(%rcx,%rax,1),%xmm0
	jnz	.Lxts_dec_loop6

	movdqa	(%r8),%xmm8
	movdqa	%xmm9,%xmm14
	paddd	%xmm9,%xmm9
.byte	102,15,56,222,209
	paddq	%xmm15,%xmm15
	psrad	$31,%xmm14
.byte	102,15,56,222,217
	pand	%xmm8,%xmm14
	movups	(%rbp),%xmm10
.byte	102,15,56,222,225
.byte	102,15,56,222,233
.byte	102,15,56,222,241
	pxor	%xmm14,%xmm15
	movaps	%xmm10,%xmm11
.byte	102,15,56,222,249
	movups	-64(%rcx),%xmm1

	movdqa	%xmm9,%xmm14
.byte	102,15,56,222,208
	paddd	%xmm9,%xmm9
	pxor	%xmm15,%xmm10
.byte	102,15,56,222,216
	psrad	$31,%xmm14
	paddq	%xmm15,%xmm15
.byte	102,15,56,222,224
.byte	102,15,56,222,232
	pand	%xmm8,%xmm14
	movaps	%xmm11,%xmm12
.byte	102,15,56,222,240
	pxor	%xmm14,%xmm15
	movdqa	%xmm9,%xmm14
.byte	102,15,56,222,248
	movups	-48(%rcx),%xmm0

	paddd	%xmm9,%xmm9
.byte	102,15,56,222,209
	pxor	%xmm15,%xmm11
	psrad	$31,%xmm14
.byte	102,15,56,222,217
	paddq	%xmm15,%xmm15
	pand	%xmm8,%xmm14
.byte	102,15,56,222,225
.byte	102,15,56,222,233
	movdqa	%xmm13,48(%rsp)
	pxor	%xmm14,%xmm15
.byte	102,15,56,222,241
	movaps	%xmm12,%xmm13
	movdqa	%xmm9,%xmm14
.byte	102,15,56,222,249
	movups	-32(%rcx),%xmm1

	paddd	%xmm9,%xmm9
.byte	102,15,56,222,208
	pxor	%xmm15,%xmm12
	psrad	$31,%xmm14
.byte	102,15,56,222,216
	paddq	%xmm15,%xmm15
	pand	%xmm8,%xmm14
.byte	102,15,56,222,224
.byte	102,15,56,222,232
.byte	102,15,56,222,240
	pxor	%xmm14,%xmm15
	movaps	%xmm13,%xmm14
.byte	102,15,56,222,248

	movdqa	%xmm9,%xmm0
	paddd	%xmm9,%xmm9
.byte	102,15,56,222,209
	pxor	%xmm15,%xmm13
	psrad	$31,%xmm0
.byte	102,15,56,222,217
	paddq	%xmm15,%xmm15
	pand	%xmm8,%xmm0
.byte	102,15,56,222,225
.byte	102,15,56,222,233
	pxor	%xmm0,%xmm15
	movups	(%rbp),%xmm0
.byte	102,15,56,222,241
.byte	102,15,56,222,249
	movups	16(%rbp),%xmm1

	pxor	%xmm15,%xmm14
.byte	102,15,56,223,84,36,0
	psrad	$31,%xmm9
	paddq	%xmm15,%xmm15
.byte	102,15,56,223,92,36,16
.byte	102,15,56,223,100,36,32
	pand	%xmm8,%xmm9
	movq	%r10,%rax
.byte	102,15,56,223,108,36,48
.byte	102,15,56,223,116,36,64
.byte	102,15,56,223,124,36,80
	pxor	%xmm9,%xmm15

	leaq	96(%rsi),%rsi
	movups	%xmm2,-96(%rsi)
	movups	%xmm3,-80(%rsi)
	movups	%xmm4,-64(%rsi)
	movups	%xmm5,-48(%rsi)
	movups	%xmm6,-32(%rsi)
	movups	%xmm7,-16(%rsi)
	subq	$96,%rdx
	jnc	.Lxts_dec_grandloop

	movl	$16+96,%eax
	subl	%r10d,%eax
	movq	%rbp,%rcx
	shrl	$4,%eax

.Lxts_dec_short:

	movl	%eax,%r10d
	pxor	%xmm0,%xmm10
	pxor	%xmm0,%xmm11
	addq	$96,%rdx
	jz	.Lxts_dec_done

	pxor	%xmm0,%xmm12
	cmpq	$0x20,%rdx
	jb	.Lxts_dec_one
	pxor	%xmm0,%xmm13
	je	.Lxts_dec_two

	pxor	%xmm0,%xmm14
	cmpq	$0x40,%rdx
	jb	.Lxts_dec_three
	je	.Lxts_dec_four

	movdqu	(%rdi),%xmm2
	movdqu	16(%rdi),%xmm3
	movdqu	32(%rdi),%xmm4
	pxor	%xmm10,%xmm2
	movdqu	48(%rdi),%xmm5
	pxor	%xmm11,%xmm3
	movdqu	64(%rdi),%xmm6
	leaq	80(%rdi),%rdi
	pxor	%xmm12,%xmm4
	pxor	%xmm13,%xmm5
	pxor	%xmm14,%xmm6

	call	_aesni_decrypt6

	xorps	%xmm10,%xmm2
	xorps	%xmm11,%xmm3
	xorps	%xmm12,%xmm4
	movdqu	%xmm2,(%rsi)
	xorps	%xmm13,%xmm5
	movdqu	%xmm3,16(%rsi)
	xorps	%xmm14,%xmm6
	movdqu	%xmm4,32(%rsi)
	pxor	%xmm14,%xmm14
	movdqu	%xmm5,48(%rsi)
	pcmpgtd	%xmm15,%xmm14
	movdqu	%xmm6,64(%rsi)
	leaq	80(%rsi),%rsi
	pshufd	$0x13,%xmm14,%xmm11
	andq	$15,%r9
	jz	.Lxts_dec_ret

	movdqa	%xmm15,%xmm10
	paddq	%xmm15,%xmm15
	pand	%xmm8,%xmm11
	pxor	%xmm15,%xmm11
	jmp	.Lxts_dec_done2

.align	16
.Lxts_dec_one:
	movups	(%rdi),%xmm2
	leaq	16(%rdi),%rdi
	xorps	%xmm10,%xmm2
	movups	(%rcx),%xmm0
	movups	16(%rcx),%xmm1
	leaq	32(%rcx),%rcx
	xorps	%xmm0,%xmm2
.Loop_dec1_12:
.byte	102,15,56,222,209
	decl	%eax
	movups	(%rcx),%xmm1
	leaq	16(%rcx),%rcx
	jnz	.Loop_dec1_12
.byte	102,15,56,223,209
	xorps	%xmm10,%xmm2
	movdqa	%xmm11,%xmm10
	movups	%xmm2,(%rsi)
	movdqa	%xmm12,%xmm11
	leaq	16(%rsi),%rsi
	jmp	.Lxts_dec_done

.align	16
.Lxts_dec_two:
	movups	(%rdi),%xmm2
	movups	16(%rdi),%xmm3
	leaq	32(%rdi),%rdi
	xorps	%xmm10,%xmm2
	xorps	%xmm11,%xmm3

	call	_aesni_decrypt2

	xorps	%xmm10,%xmm2
	movdqa	%xmm12,%xmm10
	xorps	%xmm11,%xmm3
	movdqa	%xmm13,%xmm11
	movups	%xmm2,(%rsi)
	movups	%xmm3,16(%rsi)
	leaq	32(%rsi),%rsi
	jmp	.Lxts_dec_done

.align	16
.Lxts_dec_three:
	movups	(%rdi),%xmm2
	movups	16(%rdi),%xmm3
	movups	32(%rdi),%xmm4
	leaq	48(%rdi),%rdi
	xorps	%xmm10,%xmm2
	xorps	%xmm11,%xmm3
	xorps	%xmm12,%xmm4

	call	_aesni_decrypt3

	xorps	%xmm10,%xmm2
	movdqa	%xmm13,%xmm10
	xorps	%xmm11,%xmm3
	movdqa	%xmm14,%xmm11
	xorps	%xmm12,%xmm4
	movups	%xmm2,(%rsi)
	movups	%xmm3,16(%rsi)
	movups	%xmm4,32(%rsi)
	leaq	48(%rsi),%rsi
	jmp	.Lxts_dec_done

.align	16
.Lxts_dec_four:
	movups	(%rdi),%xmm2
	movups	16(%rdi),%xmm3
	movups	32(%rdi),%xmm4
	xorps	%xmm10,%xmm2
	movups	48(%rdi),%xmm5
	leaq	64(%rdi),%rdi
	xorps	%xmm11,%xmm3
	xorps	%xmm12,%xmm4
	xorps	%xmm13,%xmm5

	call	_aesni_decrypt4

	pxor	%xmm10,%xmm2
	movdqa	%xmm14,%xmm10
	pxor	%xmm11,%xmm3
	movdqa	%xmm15,%xmm11
	pxor	%xmm12,%xmm4
	movdqu	%xmm2,(%rsi)
	pxor	%xmm13,%xmm5
	movdqu	%xmm3,16(%rsi)
	movdqu	%xmm4,32(%rsi)
	movdqu	%xmm5,48(%rsi)
	leaq	64(%rsi),%rsi
	jmp	.Lxts_dec_done

.align	16
.Lxts_dec_done:
	andq	$15,%r9
	jz	.Lxts_dec_ret
.Lxts_dec_done2:
	movq	%r9,%rdx
	movq	%rbp,%rcx
	movl	%r10d,%eax

	movups	(%rdi),%xmm2
	xorps	%xmm11,%xmm2
	movups	(%rcx),%xmm0
	movups	16(%rcx),%xmm1
	leaq	32(%rcx),%rcx
	xorps	%xmm0,%xmm2
.Loop_dec1_13:
.byte	102,15,56,222,209
	decl	%eax
	movups	(%rcx),%xmm1
	leaq	16(%rcx),%rcx
	jnz	.Loop_dec1_13
.byte	102,15,56,223,209
	xorps	%xmm11,%xmm2
	movups	%xmm2,(%rsi)

.Lxts_dec_steal:
	movzbl	16(%rdi),%eax
	movzbl	(%rsi),%ecx
	leaq	1(%rdi),%rdi
	movb	%al,(%rsi)
	movb	%cl,16(%rsi)
	leaq	1(%rsi),%rsi
	subq	$1,%rdx
	jnz	.Lxts_dec_steal

	subq	%r9,%rsi
	movq	%rbp,%rcx
	movl	%r10d,%eax

	movups	(%rsi),%xmm2
	xorps	%xmm10,%xmm2
	movups	(%rcx),%xmm0
	movups	16(%rcx),%xmm1
	leaq	32(%rcx),%rcx
	xorps	%xmm0,%xmm2
.Loop_dec1_14:
.byte	102,15,56,222,209
	decl	%eax
	movups	(%rcx),%xmm1
	leaq	16(%rcx),%rcx
	jnz	.Loop_dec1_14
.byte	102,15,56,223,209
	xorps	%xmm10,%xmm2
	movups	%xmm2,(%rsi)

.Lxts_dec_ret:
	xorps	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	pxor	%xmm2,%xmm2
	pxor	%xmm3,%xmm3
	pxor	%xmm4,%xmm4
	pxor	%xmm5,%xmm5
	pxor	%xmm6,%xmm6
	pxor	%xmm7,%xmm7
	movaps	%xmm0,0(%rsp)
	pxor	%xmm8,%xmm8
	movaps	%xmm0,16(%rsp)
	pxor	%xmm9,%xmm9
	movaps	%xmm0,32(%rsp)
	pxor	%xmm10,%xmm10
	movaps	%xmm0,48(%rsp)
	pxor	%xmm11,%xmm11
	movaps	%xmm0,64(%rsp)
	pxor	%xmm12,%xmm12
	movaps	%xmm0,80(%rsp)
	pxor	%xmm13,%xmm13
	movaps	%xmm0,96(%rsp)
	pxor	%xmm14,%xmm14
	pxor	%xmm15,%xmm15
	movq	-8(%r11),%rbp
.cfi_restore	%rbp
	leaq	(%r11),%rsp
.cfi_def_cfa_register	%rsp
.Lxts_dec_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_xts_decrypt,.-aesni_xts_decrypt
.globl	aesni_ocb_encrypt
.type	aesni_ocb_encrypt,@function
.align	32
aesni_ocb_encrypt:
.cfi_startproc	
.byte	243,15,30,250
	leaq	(%rsp),%rax
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-48
	movq	8(%rax),%rbx
	movq	8+8(%rax),%rbp

	movl	240(%rcx),%r10d
	movq	%rcx,%r11
	shll	$4,%r10d
	movups	(%rcx),%xmm9
	movups	16(%rcx,%r10,1),%xmm1

	movdqu	(%r9),%xmm15
	pxor	%xmm1,%xmm9
	pxor	%xmm1,%xmm15

	movl	$16+32,%eax
	leaq	32(%r11,%r10,1),%rcx
	movups	16(%r11),%xmm1
	subq	%r10,%rax
	movq	%rax,%r10

	movdqu	(%rbx),%xmm10
	movdqu	(%rbp),%xmm8

	testq	$1,%r8
	jnz	.Locb_enc_odd

	bsfq	%r8,%r12
	addq	$1,%r8
	shlq	$4,%r12
	movdqu	(%rbx,%r12,1),%xmm7
	movdqu	(%rdi),%xmm2
	leaq	16(%rdi),%rdi

	call	__ocb_encrypt1

	movdqa	%xmm7,%xmm15
	movups	%xmm2,(%rsi)
	leaq	16(%rsi),%rsi
	subq	$1,%rdx
	jz	.Locb_enc_done

.Locb_enc_odd:
	leaq	1(%r8),%r12
	leaq	3(%r8),%r13
	leaq	5(%r8),%r14
	leaq	6(%r8),%r8
	bsfq	%r12,%r12
	bsfq	%r13,%r13
	bsfq	%r14,%r14
	shlq	$4,%r12
	shlq	$4,%r13
	shlq	$4,%r14

	subq	$6,%rdx
	jc	.Locb_enc_short
	jmp	.Locb_enc_grandloop

.align	32
.Locb_enc_grandloop:
	movdqu	0(%rdi),%xmm2
	movdqu	16(%rdi),%xmm3
	movdqu	32(%rdi),%xmm4
	movdqu	48(%rdi),%xmm5
	movdqu	64(%rdi),%xmm6
	movdqu	80(%rdi),%xmm7
	leaq	96(%rdi),%rdi

	call	__ocb_encrypt6

	movups	%xmm2,0(%rsi)
	movups	%xmm3,16(%rsi)
	movups	%xmm4,32(%rsi)
	movups	%xmm5,48(%rsi)
	movups	%xmm6,64(%rsi)
	movups	%xmm7,80(%rsi)
	leaq	96(%rsi),%rsi
	subq	$6,%rdx
	jnc	.Locb_enc_grandloop

.Locb_enc_short:
	addq	$6,%rdx
	jz	.Locb_enc_done

	movdqu	0(%rdi),%xmm2
	cmpq	$2,%rdx
	jb	.Locb_enc_one
	movdqu	16(%rdi),%xmm3
	je	.Locb_enc_two

	movdqu	32(%rdi),%xmm4
	cmpq	$4,%rdx
	jb	.Locb_enc_three
	movdqu	48(%rdi),%xmm5
	je	.Locb_enc_four

	movdqu	64(%rdi),%xmm6
	pxor	%xmm7,%xmm7

	call	__ocb_encrypt6

	movdqa	%xmm14,%xmm15
	movups	%xmm2,0(%rsi)
	movups	%xmm3,16(%rsi)
	movups	%xmm4,32(%rsi)
	movups	%xmm5,48(%rsi)
	movups	%xmm6,64(%rsi)

	jmp	.Locb_enc_done

.align	16
.Locb_enc_one:
	movdqa	%xmm10,%xmm7

	call	__ocb_encrypt1

	movdqa	%xmm7,%xmm15
	movups	%xmm2,0(%rsi)
	jmp	.Locb_enc_done

.align	16
.Locb_enc_two:
	pxor	%xmm4,%xmm4
	pxor	%xmm5,%xmm5

	call	__ocb_encrypt4

	movdqa	%xmm11,%xmm15
	movups	%xmm2,0(%rsi)
	movups	%xmm3,16(%rsi)

	jmp	.Locb_enc_done

.align	16
.Locb_enc_three:
	pxor	%xmm5,%xmm5

	call	__ocb_encrypt4

	movdqa	%xmm12,%xmm15
	movups	%xmm2,0(%rsi)
	movups	%xmm3,16(%rsi)
	movups	%xmm4,32(%rsi)

	jmp	.Locb_enc_done

.align	16
.Locb_enc_four:
	call	__ocb_encrypt4

	movdqa	%xmm13,%xmm15
	movups	%xmm2,0(%rsi)
	movups	%xmm3,16(%rsi)
	movups	%xmm4,32(%rsi)
	movups	%xmm5,48(%rsi)

.Locb_enc_done:
	pxor	%xmm0,%xmm15
	movdqu	%xmm8,(%rbp)
	movdqu	%xmm15,(%r9)

	xorps	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	pxor	%xmm2,%xmm2
	pxor	%xmm3,%xmm3
	pxor	%xmm4,%xmm4
	pxor	%xmm5,%xmm5
	pxor	%xmm6,%xmm6
	pxor	%xmm7,%xmm7
	pxor	%xmm8,%xmm8
	pxor	%xmm9,%xmm9
	pxor	%xmm10,%xmm10
	pxor	%xmm11,%xmm11
	pxor	%xmm12,%xmm12
	pxor	%xmm13,%xmm13
	pxor	%xmm14,%xmm14
	pxor	%xmm15,%xmm15
	leaq	40(%rsp),%rax
.cfi_def_cfa	%rax,8
	movq	-40(%rax),%r14
.cfi_restore	%r14
	movq	-32(%rax),%r13
.cfi_restore	%r13
	movq	-24(%rax),%r12
.cfi_restore	%r12
	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Locb_enc_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_ocb_encrypt,.-aesni_ocb_encrypt

.type	__ocb_encrypt6,@function
.align	32
__ocb_encrypt6:
.cfi_startproc	
	pxor	%xmm9,%xmm15
	movdqu	(%rbx,%r12,1),%xmm11
	movdqa	%xmm10,%xmm12
	movdqu	(%rbx,%r13,1),%xmm13
	movdqa	%xmm10,%xmm14
	pxor	%xmm15,%xmm10
	movdqu	(%rbx,%r14,1),%xmm15
	pxor	%xmm10,%xmm11
	pxor	%xmm2,%xmm8
	pxor	%xmm10,%xmm2
	pxor	%xmm11,%xmm12
	pxor	%xmm3,%xmm8
	pxor	%xmm11,%xmm3
	pxor	%xmm12,%xmm13
	pxor	%xmm4,%xmm8
	pxor	%xmm12,%xmm4
	pxor	%xmm13,%xmm14
	pxor	%xmm5,%xmm8
	pxor	%xmm13,%xmm5
	pxor	%xmm14,%xmm15
	pxor	%xmm6,%xmm8
	pxor	%xmm14,%xmm6
	pxor	%xmm7,%xmm8
	pxor	%xmm15,%xmm7
	movups	32(%r11),%xmm0

	leaq	1(%r8),%r12
	leaq	3(%r8),%r13
	leaq	5(%r8),%r14
	addq	$6,%r8
	pxor	%xmm9,%xmm10
	bsfq	%r12,%r12
	bsfq	%r13,%r13
	bsfq	%r14,%r14

.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.byte	102,15,56,220,233
	pxor	%xmm9,%xmm11
	pxor	%xmm9,%xmm12
.byte	102,15,56,220,241
	pxor	%xmm9,%xmm13
	pxor	%xmm9,%xmm14
.byte	102,15,56,220,249
	movups	48(%r11),%xmm1
	pxor	%xmm9,%xmm15

.byte	102,15,56,220,208
.byte	102,15,56,220,216
.byte	102,15,56,220,224
.byte	102,15,56,220,232
.byte	102,15,56,220,240
.byte	102,15,56,220,248
	movups	64(%r11),%xmm0
	shlq	$4,%r12
	shlq	$4,%r13
	jmp	.Locb_enc_loop6

.align	32
.Locb_enc_loop6:
.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.byte	102,15,56,220,233
.byte	102,15,56,220,241
.byte	102,15,56,220,249
	movups	(%rcx,%rax,1),%xmm1
	addq	$32,%rax

.byte	102,15,56,220,208
.byte	102,15,56,220,216
.byte	102,15,56,220,224
.byte	102,15,56,220,232
.byte	102,15,56,220,240
.byte	102,15,56,220,248
	movups	-16(%rcx,%rax,1),%xmm0
	jnz	.Locb_enc_loop6

.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.byte	102,15,56,220,233
.byte	102,15,56,220,241
.byte	102,15,56,220,249
	movups	16(%r11),%xmm1
	shlq	$4,%r14

.byte	102,65,15,56,221,210
	movdqu	(%rbx),%xmm10
	movq	%r10,%rax
.byte	102,65,15,56,221,219
.byte	102,65,15,56,221,228
.byte	102,65,15,56,221,237
.byte	102,65,15,56,221,246
.byte	102,65,15,56,221,255
	.byte	0xf3,0xc3
.cfi_endproc	
.size	__ocb_encrypt6,.-__ocb_encrypt6

.type	__ocb_encrypt4,@function
.align	32
__ocb_encrypt4:
.cfi_startproc	
	pxor	%xmm9,%xmm15
	movdqu	(%rbx,%r12,1),%xmm11
	movdqa	%xmm10,%xmm12
	movdqu	(%rbx,%r13,1),%xmm13
	pxor	%xmm15,%xmm10
	pxor	%xmm10,%xmm11
	pxor	%xmm2,%xmm8
	pxor	%xmm10,%xmm2
	pxor	%xmm11,%xmm12
	pxor	%xmm3,%xmm8
	pxor	%xmm11,%xmm3
	pxor	%xmm12,%xmm13
	pxor	%xmm4,%xmm8
	pxor	%xmm12,%xmm4
	pxor	%xmm5,%xmm8
	pxor	%xmm13,%xmm5
	movups	32(%r11),%xmm0

	pxor	%xmm9,%xmm10
	pxor	%xmm9,%xmm11
	pxor	%xmm9,%xmm12
	pxor	%xmm9,%xmm13

.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.byte	102,15,56,220,233
	movups	48(%r11),%xmm1

.byte	102,15,56,220,208
.byte	102,15,56,220,216
.byte	102,15,56,220,224
.byte	102,15,56,220,232
	movups	64(%r11),%xmm0
	jmp	.Locb_enc_loop4

.align	32
.Locb_enc_loop4:
.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.byte	102,15,56,220,233
	movups	(%rcx,%rax,1),%xmm1
	addq	$32,%rax

.byte	102,15,56,220,208
.byte	102,15,56,220,216
.byte	102,15,56,220,224
.byte	102,15,56,220,232
	movups	-16(%rcx,%rax,1),%xmm0
	jnz	.Locb_enc_loop4

.byte	102,15,56,220,209
.byte	102,15,56,220,217
.byte	102,15,56,220,225
.byte	102,15,56,220,233
	movups	16(%r11),%xmm1
	movq	%r10,%rax

.byte	102,65,15,56,221,210
.byte	102,65,15,56,221,219
.byte	102,65,15,56,221,228
.byte	102,65,15,56,221,237
	.byte	0xf3,0xc3
.cfi_endproc	
.size	__ocb_encrypt4,.-__ocb_encrypt4

.type	__ocb_encrypt1,@function
.align	32
__ocb_encrypt1:
.cfi_startproc	
	pxor	%xmm15,%xmm7
	pxor	%xmm9,%xmm7
	pxor	%xmm2,%xmm8
	pxor	%xmm7,%xmm2
	movups	32(%r11),%xmm0

.byte	102,15,56,220,209
	movups	48(%r11),%xmm1
	pxor	%xmm9,%xmm7

.byte	102,15,56,220,208
	movups	64(%r11),%xmm0
	jmp	.Locb_enc_loop1

.align	32
.Locb_enc_loop1:
.byte	102,15,56,220,209
	movups	(%rcx,%rax,1),%xmm1
	addq	$32,%rax

.byte	102,15,56,220,208
	movups	-16(%rcx,%rax,1),%xmm0
	jnz	.Locb_enc_loop1

.byte	102,15,56,220,209
	movups	16(%r11),%xmm1
	movq	%r10,%rax

.byte	102,15,56,221,215
	.byte	0xf3,0xc3
.cfi_endproc	
.size	__ocb_encrypt1,.-__ocb_encrypt1

.globl	aesni_ocb_decrypt
.type	aesni_ocb_decrypt,@function
.align	32
aesni_ocb_decrypt:
.cfi_startproc	
.byte	243,15,30,250
	leaq	(%rsp),%rax
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-48
	movq	8(%rax),%rbx
	movq	8+8(%rax),%rbp

	movl	240(%rcx),%r10d
	movq	%rcx,%r11
	shll	$4,%r10d
	movups	(%rcx),%xmm9
	movups	16(%rcx,%r10,1),%xmm1

	movdqu	(%r9),%xmm15
	pxor	%xmm1,%xmm9
	pxor	%xmm1,%xmm15

	movl	$16+32,%eax
	leaq	32(%r11,%r10,1),%rcx
	movups	16(%r11),%xmm1
	subq	%r10,%rax
	movq	%rax,%r10

	movdqu	(%rbx),%xmm10
	movdqu	(%rbp),%xmm8

	testq	$1,%r8
	jnz	.Locb_dec_odd

	bsfq	%r8,%r12
	addq	$1,%r8
	shlq	$4,%r12
	movdqu	(%rbx,%r12,1),%xmm7
	movdqu	(%rdi),%xmm2
	leaq	16(%rdi),%rdi

	call	__ocb_decrypt1

	movdqa	%xmm7,%xmm15
	movups	%xmm2,(%rsi)
	xorps	%xmm2,%xmm8
	leaq	16(%rsi),%rsi
	subq	$1,%rdx
	jz	.Locb_dec_done

.Locb_dec_odd:
	leaq	1(%r8),%r12
	leaq	3(%r8),%r13
	leaq	5(%r8),%r14
	leaq	6(%r8),%r8
	bsfq	%r12,%r12
	bsfq	%r13,%r13
	bsfq	%r14,%r14
	shlq	$4,%r12
	shlq	$4,%r13
	shlq	$4,%r14

	subq	$6,%rdx
	jc	.Locb_dec_short
	jmp	.Locb_dec_grandloop

.align	32
.Locb_dec_grandloop:
	movdqu	0(%rdi),%xmm2
	movdqu	16(%rdi),%xmm3
	movdqu	32(%rdi),%xmm4
	movdqu	48(%rdi),%xmm5
	movdqu	64(%rdi),%xmm6
	movdqu	80(%rdi),%xmm7
	leaq	96(%rdi),%rdi

	call	__ocb_decrypt6

	movups	%xmm2,0(%rsi)
	pxor	%xmm2,%xmm8
	movups	%xmm3,16(%rsi)
	pxor	%xmm3,%xmm8
	movups	%xmm4,32(%rsi)
	pxor	%xmm4,%xmm8
	movups	%xmm5,48(%rsi)
	pxor	%xmm5,%xmm8
	movups	%xmm6,64(%rsi)
	pxor	%xmm6,%xmm8
	movups	%xmm7,80(%rsi)
	pxor	%xmm7,%xmm8
	leaq	96(%rsi),%rsi
	subq	$6,%rdx
	jnc	.Locb_dec_grandloop

.Locb_dec_short:
	addq	$6,%rdx
	jz	.Locb_dec_done

	movdqu	0(%rdi),%xmm2
	cmpq	$2,%rdx
	jb	.Locb_dec_one
	movdqu	16(%rdi),%xmm3
	je	.Locb_dec_two

	movdqu	32(%rdi),%xmm4
	cmpq	$4,%rdx
	jb	.Locb_dec_three
	movdqu	48(%rdi),%xmm5
	je	.Locb_dec_four

	movdqu	64(%rdi),%xmm6
	pxor	%xmm7,%xmm7

	call	__ocb_decrypt6

	movdqa	%xmm14,%xmm15
	movups	%xmm2,0(%rsi)
	pxor	%xmm2,%xmm8
	movups	%xmm3,16(%rsi)
	pxor	%xmm3,%xmm8
	movups	%xmm4,32(%rsi)
	pxor	%xmm4,%xmm8
	movups	%xmm5,48(%rsi)
	pxor	%xmm5,%xmm8
	movups	%xmm6,64(%rsi)
	pxor	%xmm6,%xmm8

	jmp	.Locb_dec_done

.align	16
.Locb_dec_one:
	movdqa	%xmm10,%xmm7

	call	__ocb_decrypt1

	movdqa	%xmm7,%xmm15
	movups	%xmm2,0(%rsi)
	xorps	%xmm2,%xmm8
	jmp	.Locb_dec_done

.align	16
.Locb_dec_two:
	pxor	%xmm4,%xmm4
	pxor	%xmm5,%xmm5

	call	__ocb_decrypt4

	movdqa	%xmm11,%xmm15
	movups	%xmm2,0(%rsi)
	xorps	%xmm2,%xmm8
	movups	%xmm3,16(%rsi)
	xorps	%xmm3,%xmm8

	jmp	.Locb_dec_done

.align	16
.Locb_dec_three:
	pxor	%xmm5,%xmm5

	call	__ocb_decrypt4

	movdqa	%xmm12,%xmm15
	movups	%xmm2,0(%rsi)
	xorps	%xmm2,%xmm8
	movups	%xmm3,16(%rsi)
	xorps	%xmm3,%xmm8
	movups	%xmm4,32(%rsi)
	xorps	%xmm4,%xmm8

	jmp	.Locb_dec_done

.align	16
.Locb_dec_four:
	call	__ocb_decrypt4

	movdqa	%xmm13,%xmm15
	movups	%xmm2,0(%rsi)
	pxor	%xmm2,%xmm8
	movups	%xmm3,16(%rsi)
	pxor	%xmm3,%xmm8
	movups	%xmm4,32(%rsi)
	pxor	%xmm4,%xmm8
	movups	%xmm5,48(%rsi)
	pxor	%xmm5,%xmm8

.Locb_dec_done:
	pxor	%xmm0,%xmm15
	movdqu	%xmm8,(%rbp)
	movdqu	%xmm15,(%r9)

	xorps	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	pxor	%xmm2,%xmm2
	pxor	%xmm3,%xmm3
	pxor	%xmm4,%xmm4
	pxor	%xmm5,%xmm5
	pxor	%xmm6,%xmm6
	pxor	%xmm7,%xmm7
	pxor	%xmm8,%xmm8
	pxor	%xmm9,%xmm9
	pxor	%xmm10,%xmm10
	pxor	%xmm11,%xmm11
	pxor	%xmm12,%xmm12
	pxor	%xmm13,%xmm13
	pxor	%xmm14,%xmm14
	pxor	%xmm15,%xmm15
	leaq	40(%rsp),%rax
.cfi_def_cfa	%rax,8
	movq	-40(%rax),%r14
.cfi_restore	%r14
	movq	-32(%rax),%r13
.cfi_restore	%r13
	movq	-24(%rax),%r12
.cfi_restore	%r12
	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Locb_dec_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_ocb_decrypt,.-aesni_ocb_decrypt

.type	__ocb_decrypt6,@function
.align	32
__ocb_decrypt6:
.cfi_startproc	
	pxor	%xmm9,%xmm15
	movdqu	(%rbx,%r12,1),%xmm11
	movdqa	%xmm10,%xmm12
	movdqu	(%rbx,%r13,1),%xmm13
	movdqa	%xmm10,%xmm14
	pxor	%xmm15,%xmm10
	movdqu	(%rbx,%r14,1),%xmm15
	pxor	%xmm10,%xmm11
	pxor	%xmm10,%xmm2
	pxor	%xmm11,%xmm12
	pxor	%xmm11,%xmm3
	pxor	%xmm12,%xmm13
	pxor	%xmm12,%xmm4
	pxor	%xmm13,%xmm14
	pxor	%xmm13,%xmm5
	pxor	%xmm14,%xmm15
	pxor	%xmm14,%xmm6
	pxor	%xmm15,%xmm7
	movups	32(%r11),%xmm0

	leaq	1(%r8),%r12
	leaq	3(%r8),%r13
	leaq	5(%r8),%r14
	addq	$6,%r8
	pxor	%xmm9,%xmm10
	bsfq	%r12,%r12
	bsfq	%r13,%r13
	bsfq	%r14,%r14

.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,222,233
	pxor	%xmm9,%xmm11
	pxor	%xmm9,%xmm12
.byte	102,15,56,222,241
	pxor	%xmm9,%xmm13
	pxor	%xmm9,%xmm14
.byte	102,15,56,222,249
	movups	48(%r11),%xmm1
	pxor	%xmm9,%xmm15

.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
.byte	102,15,56,222,232
.byte	102,15,56,222,240
.byte	102,15,56,222,248
	movups	64(%r11),%xmm0
	shlq	$4,%r12
	shlq	$4,%r13
	jmp	.Locb_dec_loop6

.align	32
.Locb_dec_loop6:
.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,222,233
.byte	102,15,56,222,241
.byte	102,15,56,222,249
	movups	(%rcx,%rax,1),%xmm1
	addq	$32,%rax

.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
.byte	102,15,56,222,232
.byte	102,15,56,222,240
.byte	102,15,56,222,248
	movups	-16(%rcx,%rax,1),%xmm0
	jnz	.Locb_dec_loop6

.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,222,233
.byte	102,15,56,222,241
.byte	102,15,56,222,249
	movups	16(%r11),%xmm1
	shlq	$4,%r14

.byte	102,65,15,56,223,210
	movdqu	(%rbx),%xmm10
	movq	%r10,%rax
.byte	102,65,15,56,223,219
.byte	102,65,15,56,223,228
.byte	102,65,15,56,223,237
.byte	102,65,15,56,223,246
.byte	102,65,15,56,223,255
	.byte	0xf3,0xc3
.cfi_endproc	
.size	__ocb_decrypt6,.-__ocb_decrypt6

.type	__ocb_decrypt4,@function
.align	32
__ocb_decrypt4:
.cfi_startproc	
	pxor	%xmm9,%xmm15
	movdqu	(%rbx,%r12,1),%xmm11
	movdqa	%xmm10,%xmm12
	movdqu	(%rbx,%r13,1),%xmm13
	pxor	%xmm15,%xmm10
	pxor	%xmm10,%xmm11
	pxor	%xmm10,%xmm2
	pxor	%xmm11,%xmm12
	pxor	%xmm11,%xmm3
	pxor	%xmm12,%xmm13
	pxor	%xmm12,%xmm4
	pxor	%xmm13,%xmm5
	movups	32(%r11),%xmm0

	pxor	%xmm9,%xmm10
	pxor	%xmm9,%xmm11
	pxor	%xmm9,%xmm12
	pxor	%xmm9,%xmm13

.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,222,233
	movups	48(%r11),%xmm1

.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
.byte	102,15,56,222,232
	movups	64(%r11),%xmm0
	jmp	.Locb_dec_loop4

.align	32
.Locb_dec_loop4:
.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,222,233
	movups	(%rcx,%rax,1),%xmm1
	addq	$32,%rax

.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
.byte	102,15,56,222,232
	movups	-16(%rcx,%rax,1),%xmm0
	jnz	.Locb_dec_loop4

.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,222,233
	movups	16(%r11),%xmm1
	movq	%r10,%rax

.byte	102,65,15,56,223,210
.byte	102,65,15,56,223,219
.byte	102,65,15,56,223,228
.byte	102,65,15,56,223,237
	.byte	0xf3,0xc3
.cfi_endproc	
.size	__ocb_decrypt4,.-__ocb_decrypt4

.type	__ocb_decrypt1,@function
.align	32
__ocb_decrypt1:
.cfi_startproc	
	pxor	%xmm15,%xmm7
	pxor	%xmm9,%xmm7
	pxor	%xmm7,%xmm2
	movups	32(%r11),%xmm0

.byte	102,15,56,222,209
	movups	48(%r11),%xmm1
	pxor	%xmm9,%xmm7

.byte	102,15,56,222,208
	movups	64(%r11),%xmm0
	jmp	.Locb_dec_loop1

.align	32
.Locb_dec_loop1:
.byte	102,15,56,222,209
	movups	(%rcx,%rax,1),%xmm1
	addq	$32,%rax

.byte	102,15,56,222,208
	movups	-16(%rcx,%rax,1),%xmm0
	jnz	.Locb_dec_loop1

.byte	102,15,56,222,209
	movups	16(%r11),%xmm1
	movq	%r10,%rax

.byte	102,15,56,223,215
	.byte	0xf3,0xc3
.cfi_endproc	
.size	__ocb_decrypt1,.-__ocb_decrypt1
.globl	aesni_cbc_encrypt
.type	aesni_cbc_encrypt,@function
.align	16
aesni_cbc_encrypt:
.cfi_startproc	
.byte	243,15,30,250
	testq	%rdx,%rdx
	jz	.Lcbc_ret

	movl	240(%rcx),%r10d
	movq	%rcx,%r11
	testl	%r9d,%r9d
	jz	.Lcbc_decrypt

	movups	(%r8),%xmm2
	movl	%r10d,%eax
	cmpq	$16,%rdx
	jb	.Lcbc_enc_tail
	subq	$16,%rdx
	jmp	.Lcbc_enc_loop
.align	16
.Lcbc_enc_loop:
	movups	(%rdi),%xmm3
	leaq	16(%rdi),%rdi

	movups	(%rcx),%xmm0
	movups	16(%rcx),%xmm1
	xorps	%xmm0,%xmm3
	leaq	32(%rcx),%rcx
	xorps	%xmm3,%xmm2
.Loop_enc1_15:
.byte	102,15,56,220,209
	decl	%eax
	movups	(%rcx),%xmm1
	leaq	16(%rcx),%rcx
	jnz	.Loop_enc1_15
.byte	102,15,56,221,209
	movl	%r10d,%eax
	movq	%r11,%rcx
	movups	%xmm2,0(%rsi)
	leaq	16(%rsi),%rsi
	subq	$16,%rdx
	jnc	.Lcbc_enc_loop
	addq	$16,%rdx
	jnz	.Lcbc_enc_tail
	pxor	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	movups	%xmm2,(%r8)
	pxor	%xmm2,%xmm2
	pxor	%xmm3,%xmm3
	jmp	.Lcbc_ret

.Lcbc_enc_tail:
	movq	%rdx,%rcx
	xchgq	%rdi,%rsi
.long	0x9066A4F3
	movl	$16,%ecx
	subq	%rdx,%rcx
	xorl	%eax,%eax
.long	0x9066AAF3
	leaq	-16(%rdi),%rdi
	movl	%r10d,%eax
	movq	%rdi,%rsi
	movq	%r11,%rcx
	xorq	%rdx,%rdx
	jmp	.Lcbc_enc_loop

.align	16
.Lcbc_decrypt:
	cmpq	$16,%rdx
	jne	.Lcbc_decrypt_bulk



	movdqu	(%rdi),%xmm2
	movdqu	(%r8),%xmm3
	movdqa	%xmm2,%xmm4
	movups	(%rcx),%xmm0
	movups	16(%rcx),%xmm1
	leaq	32(%rcx),%rcx
	xorps	%xmm0,%xmm2
.Loop_dec1_16:
.byte	102,15,56,222,209
	decl	%r10d
	movups	(%rcx),%xmm1
	leaq	16(%rcx),%rcx
	jnz	.Loop_dec1_16
.byte	102,15,56,223,209
	pxor	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	movdqu	%xmm4,(%r8)
	xorps	%xmm3,%xmm2
	pxor	%xmm3,%xmm3
	movups	%xmm2,(%rsi)
	pxor	%xmm2,%xmm2
	jmp	.Lcbc_ret
.align	16
.Lcbc_decrypt_bulk:
	leaq	(%rsp),%r11
.cfi_def_cfa_register	%r11
	pushq	%rbp
.cfi_offset	%rbp,-16
	subq	$16,%rsp
	andq	$-16,%rsp
	movq	%rcx,%rbp
	movups	(%r8),%xmm10
	movl	%r10d,%eax
	cmpq	$0x50,%rdx
	jbe	.Lcbc_dec_tail

	movups	(%rcx),%xmm0
	movdqu	0(%rdi),%xmm2
	movdqu	16(%rdi),%xmm3
	movdqa	%xmm2,%xmm11
	movdqu	32(%rdi),%xmm4
	movdqa	%xmm3,%xmm12
	movdqu	48(%rdi),%xmm5
	movdqa	%xmm4,%xmm13
	movdqu	64(%rdi),%xmm6
	movdqa	%xmm5,%xmm14
	movdqu	80(%rdi),%xmm7
	movdqa	%xmm6,%xmm15
	movl	OPENSSL_ia32cap_P+4(%rip),%r9d
	cmpq	$0x70,%rdx
	jbe	.Lcbc_dec_six_or_seven

	andl	$71303168,%r9d
	subq	$0x50,%rdx
	cmpl	$4194304,%r9d
	je	.Lcbc_dec_loop6_enter
	subq	$0x20,%rdx
	leaq	112(%rcx),%rcx
	jmp	.Lcbc_dec_loop8_enter
.align	16
.Lcbc_dec_loop8:
	movups	%xmm9,(%rsi)
	leaq	16(%rsi),%rsi
.Lcbc_dec_loop8_enter:
	movdqu	96(%rdi),%xmm8
	pxor	%xmm0,%xmm2
	movdqu	112(%rdi),%xmm9
	pxor	%xmm0,%xmm3
	movups	16-112(%rcx),%xmm1
	pxor	%xmm0,%xmm4
	movq	$-1,%rbp
	cmpq	$0x70,%rdx
	pxor	%xmm0,%xmm5
	pxor	%xmm0,%xmm6
	pxor	%xmm0,%xmm7
	pxor	%xmm0,%xmm8

.byte	102,15,56,222,209
	pxor	%xmm0,%xmm9
	movups	32-112(%rcx),%xmm0
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,222,233
.byte	102,15,56,222,241
.byte	102,15,56,222,249
.byte	102,68,15,56,222,193
	adcq	$0,%rbp
	andq	$128,%rbp
.byte	102,68,15,56,222,201
	addq	%rdi,%rbp
	movups	48-112(%rcx),%xmm1
.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
.byte	102,15,56,222,232
.byte	102,15,56,222,240
.byte	102,15,56,222,248
.byte	102,68,15,56,222,192
.byte	102,68,15,56,222,200
	movups	64-112(%rcx),%xmm0
	nop
.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,222,233
.byte	102,15,56,222,241
.byte	102,15,56,222,249
.byte	102,68,15,56,222,193
.byte	102,68,15,56,222,201
	movups	80-112(%rcx),%xmm1
	nop
.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
.byte	102,15,56,222,232
.byte	102,15,56,222,240
.byte	102,15,56,222,248
.byte	102,68,15,56,222,192
.byte	102,68,15,56,222,200
	movups	96-112(%rcx),%xmm0
	nop
.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,222,233
.byte	102,15,56,222,241
.byte	102,15,56,222,249
.byte	102,68,15,56,222,193
.byte	102,68,15,56,222,201
	movups	112-112(%rcx),%xmm1
	nop
.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
.byte	102,15,56,222,232
.byte	102,15,56,222,240
.byte	102,15,56,222,248
.byte	102,68,15,56,222,192
.byte	102,68,15,56,222,200
	movups	128-112(%rcx),%xmm0
	nop
.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,222,233
.byte	102,15,56,222,241
.byte	102,15,56,222,249
.byte	102,68,15,56,222,193
.byte	102,68,15,56,222,201
	movups	144-112(%rcx),%xmm1
	cmpl	$11,%eax
.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
.byte	102,15,56,222,232
.byte	102,15,56,222,240
.byte	102,15,56,222,248
.byte	102,68,15,56,222,192
.byte	102,68,15,56,222,200
	movups	160-112(%rcx),%xmm0
	jb	.Lcbc_dec_done
.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,222,233
.byte	102,15,56,222,241
.byte	102,15,56,222,249
.byte	102,68,15,56,222,193
.byte	102,68,15,56,222,201
	movups	176-112(%rcx),%xmm1
	nop
.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
.byte	102,15,56,222,232
.byte	102,15,56,222,240
.byte	102,15,56,222,248
.byte	102,68,15,56,222,192
.byte	102,68,15,56,222,200
	movups	192-112(%rcx),%xmm0
	je	.Lcbc_dec_done
.byte	102,15,56,222,209
.byte	102,15,56,222,217
.byte	102,15,56,222,225
.byte	102,15,56,222,233
.byte	102,15,56,222,241
.byte	102,15,56,222,249
.byte	102,68,15,56,222,193
.byte	102,68,15,56,222,201
	movups	208-112(%rcx),%xmm1
	nop
.byte	102,15,56,222,208
.byte	102,15,56,222,216
.byte	102,15,56,222,224
.byte	102,15,56,222,232
.byte	102,15,56,222,240
.byte	102,15,56,222,248
.byte	102,68,15,56,222,192
.byte	102,68,15,56,222,200
	movups	224-112(%rcx),%xmm0
	jmp	.Lcbc_dec_done
.align	16
.Lcbc_dec_done:
.byte	102,15,56,222,209
.byte	102,15,56,222,217
	pxor	%xmm0,%xmm10
	pxor	%xmm0,%xmm11
.byte	102,15,56,222,225
.byte	102,15,56,222,233
	pxor	%xmm0,%xmm12
	pxor	%xmm0,%xmm13
.byte	102,15,56,222,241
.byte	102,15,56,222,249
	pxor	%xmm0,%xmm14
	pxor	%xmm0,%xmm15
.byte	102,68,15,56,222,193
.byte	102,68,15,56,222,201
	movdqu	80(%rdi),%xmm1

.byte	102,65,15,56,223,210
	movdqu	96(%rdi),%xmm10
	pxor	%xmm0,%xmm1
.byte	102,65,15,56,223,219
	pxor	%xmm0,%xmm10
	movdqu	112(%rdi),%xmm0
.byte	102,65,15,56,223,228
	leaq	128(%rdi),%rdi
	movdqu	0(%rbp),%xmm11
.byte	102,65,15,56,223,237
.byte	102,65,15,56,223,246
	movdqu	16(%rbp),%xmm12
	movdqu	32(%rbp),%xmm13
.byte	102,65,15,56,223,255
.byte	102,68,15,56,223,193
	movdqu	48(%rbp),%xmm14
	movdqu	64(%rbp),%xmm15
.byte	102,69,15,56,223,202
	movdqa	%xmm0,%xmm10
	movdqu	80(%rbp),%xmm1
	movups	-112(%rcx),%xmm0

	movups	%xmm2,(%rsi)
	movdqa	%xmm11,%xmm2
	movups	%xmm3,16(%rsi)
	movdqa	%xmm12,%xmm3
	movups	%xmm4,32(%rsi)
	movdqa	%xmm13,%xmm4
	movups	%xmm5,48(%rsi)
	movdqa	%xmm14,%xmm5
	movups	%xmm6,64(%rsi)
	movdqa	%xmm15,%xmm6
	movups	%xmm7,80(%rsi)
	movdqa	%xmm1,%xmm7
	movups	%xmm8,96(%rsi)
	leaq	112(%rsi),%rsi

	subq	$0x80,%rdx
	ja	.Lcbc_dec_loop8

	movaps	%xmm9,%xmm2
	leaq	-112(%rcx),%rcx
	addq	$0x70,%rdx
	jle	.Lcbc_dec_clear_tail_collected
	movups	%xmm9,(%rsi)
	leaq	16(%rsi),%rsi
	cmpq	$0x50,%rdx
	jbe	.Lcbc_dec_tail

	movaps	%xmm11,%xmm2
.Lcbc_dec_six_or_seven:
	cmpq	$0x60,%rdx
	ja	.Lcbc_dec_seven

	movaps	%xmm7,%xmm8
	call	_aesni_decrypt6
	pxor	%xmm10,%xmm2
	movaps	%xmm8,%xmm10
	pxor	%xmm11,%xmm3
	movdqu	%xmm2,(%rsi)
	pxor	%xmm12,%xmm4
	movdqu	%xmm3,16(%rsi)
	pxor	%xmm3,%xmm3
	pxor	%xmm13,%xmm5
	movdqu	%xmm4,32(%rsi)
	pxor	%xmm4,%xmm4
	pxor	%xmm14,%xmm6
	movdqu	%xmm5,48(%rsi)
	pxor	%xmm5,%xmm5
	pxor	%xmm15,%xmm7
	movdqu	%xmm6,64(%rsi)
	pxor	%xmm6,%xmm6
	leaq	80(%rsi),%rsi
	movdqa	%xmm7,%xmm2
	pxor	%xmm7,%xmm7
	jmp	.Lcbc_dec_tail_collected

.align	16
.Lcbc_dec_seven:
	movups	96(%rdi),%xmm8
	xorps	%xmm9,%xmm9
	call	_aesni_decrypt8
	movups	80(%rdi),%xmm9
	pxor	%xmm10,%xmm2
	movups	96(%rdi),%xmm10
	pxor	%xmm11,%xmm3
	movdqu	%xmm2,(%rsi)
	pxor	%xmm12,%xmm4
	movdqu	%xmm3,16(%rsi)
	pxor	%xmm3,%xmm3
	pxor	%xmm13,%xmm5
	movdqu	%xmm4,32(%rsi)
	pxor	%xmm4,%xmm4
	pxor	%xmm14,%xmm6
	movdqu	%xmm5,48(%rsi)
	pxor	%xmm5,%xmm5
	pxor	%xmm15,%xmm7
	movdqu	%xmm6,64(%rsi)
	pxor	%xmm6,%xmm6
	pxor	%xmm9,%xmm8
	movdqu	%xmm7,80(%rsi)
	pxor	%xmm7,%xmm7
	leaq	96(%rsi),%rsi
	movdqa	%xmm8,%xmm2
	pxor	%xmm8,%xmm8
	pxor	%xmm9,%xmm9
	jmp	.Lcbc_dec_tail_collected

.align	16
.Lcbc_dec_loop6:
	movups	%xmm7,(%rsi)
	leaq	16(%rsi),%rsi
	movdqu	0(%rdi),%xmm2
	movdqu	16(%rdi),%xmm3
	movdqa	%xmm2,%xmm11
	movdqu	32(%rdi),%xmm4
	movdqa	%xmm3,%xmm12
	movdqu	48(%rdi),%xmm5
	movdqa	%xmm4,%xmm13
	movdqu	64(%rdi),%xmm6
	movdqa	%xmm5,%xmm14
	movdqu	80(%rdi),%xmm7
	movdqa	%xmm6,%xmm15
.Lcbc_dec_loop6_enter:
	leaq	96(%rdi),%rdi
	movdqa	%xmm7,%xmm8

	call	_aesni_decrypt6

	pxor	%xmm10,%xmm2
	movdqa	%xmm8,%xmm10
	pxor	%xmm11,%xmm3
	movdqu	%xmm2,(%rsi)
	pxor	%xmm12,%xmm4
	movdqu	%xmm3,16(%rsi)
	pxor	%xmm13,%xmm5
	movdqu	%xmm4,32(%rsi)
	pxor	%xmm14,%xmm6
	movq	%rbp,%rcx
	movdqu	%xmm5,48(%rsi)
	pxor	%xmm15,%xmm7
	movl	%r10d,%eax
	movdqu	%xmm6,64(%rsi)
	leaq	80(%rsi),%rsi
	subq	$0x60,%rdx
	ja	.Lcbc_dec_loop6

	movdqa	%xmm7,%xmm2
	addq	$0x50,%rdx
	jle	.Lcbc_dec_clear_tail_collected
	movups	%xmm7,(%rsi)
	leaq	16(%rsi),%rsi

.Lcbc_dec_tail:
	movups	(%rdi),%xmm2
	subq	$0x10,%rdx
	jbe	.Lcbc_dec_one

	movups	16(%rdi),%xmm3
	movaps	%xmm2,%xmm11
	subq	$0x10,%rdx
	jbe	.Lcbc_dec_two

	movups	32(%rdi),%xmm4
	movaps	%xmm3,%xmm12
	subq	$0x10,%rdx
	jbe	.Lcbc_dec_three

	movups	48(%rdi),%xmm5
	movaps	%xmm4,%xmm13
	subq	$0x10,%rdx
	jbe	.Lcbc_dec_four

	movups	64(%rdi),%xmm6
	movaps	%xmm5,%xmm14
	movaps	%xmm6,%xmm15
	xorps	%xmm7,%xmm7
	call	_aesni_decrypt6
	pxor	%xmm10,%xmm2
	movaps	%xmm15,%xmm10
	pxor	%xmm11,%xmm3
	movdqu	%xmm2,(%rsi)
	pxor	%xmm12,%xmm4
	movdqu	%xmm3,16(%rsi)
	pxor	%xmm3,%xmm3
	pxor	%xmm13,%xmm5
	movdqu	%xmm4,32(%rsi)
	pxor	%xmm4,%xmm4
	pxor	%xmm14,%xmm6
	movdqu	%xmm5,48(%rsi)
	pxor	%xmm5,%xmm5
	leaq	64(%rsi),%rsi
	movdqa	%xmm6,%xmm2
	pxor	%xmm6,%xmm6
	pxor	%xmm7,%xmm7
	subq	$0x10,%rdx
	jmp	.Lcbc_dec_tail_collected

.align	16
.Lcbc_dec_one:
	movaps	%xmm2,%xmm11
	movups	(%rcx),%xmm0
	movups	16(%rcx),%xmm1
	leaq	32(%rcx),%rcx
	xorps	%xmm0,%xmm2
.Loop_dec1_17:
.byte	102,15,56,222,209
	decl	%eax
	movups	(%rcx),%xmm1
	leaq	16(%rcx),%rcx
	jnz	.Loop_dec1_17
.byte	102,15,56,223,209
	xorps	%xmm10,%xmm2
	movaps	%xmm11,%xmm10
	jmp	.Lcbc_dec_tail_collected
.align	16
.Lcbc_dec_two:
	movaps	%xmm3,%xmm12
	call	_aesni_decrypt2
	pxor	%xmm10,%xmm2
	movaps	%xmm12,%xmm10
	pxor	%xmm11,%xmm3
	movdqu	%xmm2,(%rsi)
	movdqa	%xmm3,%xmm2
	pxor	%xmm3,%xmm3
	leaq	16(%rsi),%rsi
	jmp	.Lcbc_dec_tail_collected
.align	16
.Lcbc_dec_three:
	movaps	%xmm4,%xmm13
	call	_aesni_decrypt3
	pxor	%xmm10,%xmm2
	movaps	%xmm13,%xmm10
	pxor	%xmm11,%xmm3
	movdqu	%xmm2,(%rsi)
	pxor	%xmm12,%xmm4
	movdqu	%xmm3,16(%rsi)
	pxor	%xmm3,%xmm3
	movdqa	%xmm4,%xmm2
	pxor	%xmm4,%xmm4
	leaq	32(%rsi),%rsi
	jmp	.Lcbc_dec_tail_collected
.align	16
.Lcbc_dec_four:
	movaps	%xmm5,%xmm14
	call	_aesni_decrypt4
	pxor	%xmm10,%xmm2
	movaps	%xmm14,%xmm10
	pxor	%xmm11,%xmm3
	movdqu	%xmm2,(%rsi)
	pxor	%xmm12,%xmm4
	movdqu	%xmm3,16(%rsi)
	pxor	%xmm3,%xmm3
	pxor	%xmm13,%xmm5
	movdqu	%xmm4,32(%rsi)
	pxor	%xmm4,%xmm4
	movdqa	%xmm5,%xmm2
	pxor	%xmm5,%xmm5
	leaq	48(%rsi),%rsi
	jmp	.Lcbc_dec_tail_collected

.align	16
.Lcbc_dec_clear_tail_collected:
	pxor	%xmm3,%xmm3
	pxor	%xmm4,%xmm4
	pxor	%xmm5,%xmm5
	pxor	%xmm6,%xmm6
	pxor	%xmm7,%xmm7
	pxor	%xmm8,%xmm8
	pxor	%xmm9,%xmm9
.Lcbc_dec_tail_collected:
	movups	%xmm10,(%r8)
	andq	$15,%rdx
	jnz	.Lcbc_dec_tail_partial
	movups	%xmm2,(%rsi)
	pxor	%xmm2,%xmm2
	jmp	.Lcbc_dec_ret
.align	16
.Lcbc_dec_tail_partial:
	movaps	%xmm2,(%rsp)
	pxor	%xmm2,%xmm2
	movq	$16,%rcx
	movq	%rsi,%rdi
	subq	%rdx,%rcx
	leaq	(%rsp),%rsi
.long	0x9066A4F3
	movdqa	%xmm2,(%rsp)

.Lcbc_dec_ret:
	xorps	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	movq	-8(%r11),%rbp
.cfi_restore	%rbp
	leaq	(%r11),%rsp
.cfi_def_cfa_register	%rsp
.Lcbc_ret:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_cbc_encrypt,.-aesni_cbc_encrypt
.globl	aesni_set_decrypt_key
.type	aesni_set_decrypt_key,@function
.align	16
aesni_set_decrypt_key:
.cfi_startproc	
.byte	0x48,0x83,0xEC,0x08
.cfi_adjust_cfa_offset	8
	call	__aesni_set_encrypt_key
	shll	$4,%esi
	testl	%eax,%eax
	jnz	.Ldec_key_ret
	leaq	16(%rdx,%rsi,1),%rdi

	movups	(%rdx),%xmm0
	movups	(%rdi),%xmm1
	movups	%xmm0,(%rdi)
	movups	%xmm1,(%rdx)
	leaq	16(%rdx),%rdx
	leaq	-16(%rdi),%rdi

.Ldec_key_inverse:
	movups	(%rdx),%xmm0
	movups	(%rdi),%xmm1
.byte	102,15,56,219,192
.byte	102,15,56,219,201
	leaq	16(%rdx),%rdx
	leaq	-16(%rdi),%rdi
	movups	%xmm0,16(%rdi)
	movups	%xmm1,-16(%rdx)
	cmpq	%rdx,%rdi
	ja	.Ldec_key_inverse

	movups	(%rdx),%xmm0
.byte	102,15,56,219,192
	pxor	%xmm1,%xmm1
	movups	%xmm0,(%rdi)
	pxor	%xmm0,%xmm0
.Ldec_key_ret:
	addq	$8,%rsp
.cfi_adjust_cfa_offset	-8
	.byte	0xf3,0xc3
.cfi_endproc	
.LSEH_end_set_decrypt_key:
.size	aesni_set_decrypt_key,.-aesni_set_decrypt_key
.globl	aesni_set_encrypt_key
.type	aesni_set_encrypt_key,@function
.align	16
aesni_set_encrypt_key:
__aesni_set_encrypt_key:
.cfi_startproc	
.byte	0x48,0x83,0xEC,0x08
.cfi_adjust_cfa_offset	8
	movq	$-1,%rax
	testq	%rdi,%rdi
	jz	.Lenc_key_ret
	testq	%rdx,%rdx
	jz	.Lenc_key_ret

	movl	$268437504,%r10d
	movups	(%rdi),%xmm0
	xorps	%xmm4,%xmm4
	andl	OPENSSL_ia32cap_P+4(%rip),%r10d
	leaq	16(%rdx),%rax
	cmpl	$256,%esi
	je	.L14rounds
	cmpl	$192,%esi
	je	.L12rounds
	cmpl	$128,%esi
	jne	.Lbad_keybits

.L10rounds:
	movl	$9,%esi
	cmpl	$268435456,%r10d
	je	.L10rounds_alt

	movups	%xmm0,(%rdx)
.byte	102,15,58,223,200,1
	call	.Lkey_expansion_128_cold
.byte	102,15,58,223,200,2
	call	.Lkey_expansion_128
.byte	102,15,58,223,200,4
	call	.Lkey_expansion_128
.byte	102,15,58,223,200,8
	call	.Lkey_expansion_128
.byte	102,15,58,223,200,16
	call	.Lkey_expansion_128
.byte	102,15,58,223,200,32
	call	.Lkey_expansion_128
.byte	102,15,58,223,200,64
	call	.Lkey_expansion_128
.byte	102,15,58,223,200,128
	call	.Lkey_expansion_128
.byte	102,15,58,223,200,27
	call	.Lkey_expansion_128
.byte	102,15,58,223,200,54
	call	.Lkey_expansion_128
	movups	%xmm0,(%rax)
	movl	%esi,80(%rax)
	xorl	%eax,%eax
	jmp	.Lenc_key_ret

.align	16
.L10rounds_alt:
	movdqa	.Lkey_rotate(%rip),%xmm5
	movl	$8,%r10d
	movdqa	.Lkey_rcon1(%rip),%xmm4
	movdqa	%xmm0,%xmm2
	movdqu	%xmm0,(%rdx)
	jmp	.Loop_key128

.align	16
.Loop_key128:
.byte	102,15,56,0,197
.byte	102,15,56,221,196
	pslld	$1,%xmm4
	leaq	16(%rax),%rax

	movdqa	%xmm2,%xmm3
	pslldq	$4,%xmm2
	pxor	%xmm2,%xmm3
	pslldq	$4,%xmm2
	pxor	%xmm2,%xmm3
	pslldq	$4,%xmm2
	pxor	%xmm3,%xmm2

	pxor	%xmm2,%xmm0
	movdqu	%xmm0,-16(%rax)
	movdqa	%xmm0,%xmm2

	decl	%r10d
	jnz	.Loop_key128

	movdqa	.Lkey_rcon1b(%rip),%xmm4

.byte	102,15,56,0,197
.byte	102,15,56,221,196
	pslld	$1,%xmm4

	movdqa	%xmm2,%xmm3
	pslldq	$4,%xmm2
	pxor	%xmm2,%xmm3
	pslldq	$4,%xmm2
	pxor	%xmm2,%xmm3
	pslldq	$4,%xmm2
	pxor	%xmm3,%xmm2

	pxor	%xmm2,%xmm0
	movdqu	%xmm0,(%rax)

	movdqa	%xmm0,%xmm2
.byte	102,15,56,0,197
.byte	102,15,56,221,196

	movdqa	%xmm2,%xmm3
	pslldq	$4,%xmm2
	pxor	%xmm2,%xmm3
	pslldq	$4,%xmm2
	pxor	%xmm2,%xmm3
	pslldq	$4,%xmm2
	pxor	%xmm3,%xmm2

	pxor	%xmm2,%xmm0
	movdqu	%xmm0,16(%rax)

	movl	%esi,96(%rax)
	xorl	%eax,%eax
	jmp	.Lenc_key_ret

.align	16
.L12rounds:
	movq	16(%rdi),%xmm2
	movl	$11,%esi
	cmpl	$268435456,%r10d
	je	.L12rounds_alt

	movups	%xmm0,(%rdx)
.byte	102,15,58,223,202,1
	call	.Lkey_expansion_192a_cold
.byte	102,15,58,223,202,2
	call	.Lkey_expansion_192b
.byte	102,15,58,223,202,4
	call	.Lkey_expansion_192a
.byte	102,15,58,223,202,8
	call	.Lkey_expansion_192b
.byte	102,15,58,223,202,16
	call	.Lkey_expansion_192a
.byte	102,15,58,223,202,32
	call	.Lkey_expansion_192b
.byte	102,15,58,223,202,64
	call	.Lkey_expansion_192a
.byte	102,15,58,223,202,128
	call	.Lkey_expansion_192b
	movups	%xmm0,(%rax)
	movl	%esi,48(%rax)
	xorq	%rax,%rax
	jmp	.Lenc_key_ret

.align	16
.L12rounds_alt:
	movdqa	.Lkey_rotate192(%rip),%xmm5
	movdqa	.Lkey_rcon1(%rip),%xmm4
	movl	$8,%r10d
	movdqu	%xmm0,(%rdx)
	jmp	.Loop_key192

.align	16
.Loop_key192:
	movq	%xmm2,0(%rax)
	movdqa	%xmm2,%xmm1
.byte	102,15,56,0,213
.byte	102,15,56,221,212
	pslld	$1,%xmm4
	leaq	24(%rax),%rax

	movdqa	%xmm0,%xmm3
	pslldq	$4,%xmm0
	pxor	%xmm0,%xmm3
	pslldq	$4,%xmm0
	pxor	%xmm0,%xmm3
	pslldq	$4,%xmm0
	pxor	%xmm3,%xmm0

	pshufd	$0xff,%xmm0,%xmm3
	pxor	%xmm1,%xmm3
	pslldq	$4,%xmm1
	pxor	%xmm1,%xmm3

	pxor	%xmm2,%xmm0
	pxor	%xmm3,%xmm2
	movdqu	%xmm0,-16(%rax)

	decl	%r10d
	jnz	.Loop_key192

	movl	%esi,32(%rax)
	xorl	%eax,%eax
	jmp	.Lenc_key_ret

.align	16
.L14rounds:
	movups	16(%rdi),%xmm2
	movl	$13,%esi
	leaq	16(%rax),%rax
	cmpl	$268435456,%r10d
	je	.L14rounds_alt

	movups	%xmm0,(%rdx)
	movups	%xmm2,16(%rdx)
.byte	102,15,58,223,202,1
	call	.Lkey_expansion_256a_cold
.byte	102,15,58,223,200,1
	call	.Lkey_expansion_256b
.byte	102,15,58,223,202,2
	call	.Lkey_expansion_256a
.byte	102,15,58,223,200,2
	call	.Lkey_expansion_256b
.byte	102,15,58,223,202,4
	call	.Lkey_expansion_256a
.byte	102,15,58,223,200,4
	call	.Lkey_expansion_256b
.byte	102,15,58,223,202,8
	call	.Lkey_expansion_256a
.byte	102,15,58,223,200,8
	call	.Lkey_expansion_256b
.byte	102,15,58,223,202,16
	call	.Lkey_expansion_256a
.byte	102,15,58,223,200,16
	call	.Lkey_expansion_256b
.byte	102,15,58,223,202,32
	call	.Lkey_expansion_256a
.byte	102,15,58,223,200,32
	call	.Lkey_expansion_256b
.byte	102,15,58,223,202,64
	call	.Lkey_expansion_256a
	movups	%xmm0,(%rax)
	movl	%esi,16(%rax)
	xorq	%rax,%rax
	jmp	.Lenc_key_ret

.align	16
.L14rounds_alt:
	movdqa	.Lkey_rotate(%rip),%xmm5
	movdqa	.Lkey_rcon1(%rip),%xmm4
	movl	$7,%r10d
	movdqu	%xmm0,0(%rdx)
	movdqa	%xmm2,%xmm1
	movdqu	%xmm2,16(%rdx)
	jmp	.Loop_key256

.align	16
.Loop_key256:
.byte	102,15,56,0,213
.byte	102,15,56,221,212

	movdqa	%xmm0,%xmm3
	pslldq	$4,%xmm0
	pxor	%xmm0,%xmm3
	pslldq	$4,%xmm0
	pxor	%xmm0,%xmm3
	pslldq	$4,%xmm0
	pxor	%xmm3,%xmm0
	pslld	$1,%xmm4

	pxor	%xmm2,%xmm0
	movdqu	%xmm0,(%rax)

	decl	%r10d
	jz	.Ldone_key256

	pshufd	$0xff,%xmm0,%xmm2
	pxor	%xmm3,%xmm3
.byte	102,15,56,221,211

	movdqa	%xmm1,%xmm3
	pslldq	$4,%xmm1
	pxor	%xmm1,%xmm3
	pslldq	$4,%xmm1
	pxor	%xmm1,%xmm3
	pslldq	$4,%xmm1
	pxor	%xmm3,%xmm1

	pxor	%xmm1,%xmm2
	movdqu	%xmm2,16(%rax)
	leaq	32(%rax),%rax
	movdqa	%xmm2,%xmm1

	jmp	.Loop_key256

.Ldone_key256:
	movl	%esi,16(%rax)
	xorl	%eax,%eax
	jmp	.Lenc_key_ret

.align	16
.Lbad_keybits:
	movq	$-2,%rax
.Lenc_key_ret:
	pxor	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	pxor	%xmm2,%xmm2
	pxor	%xmm3,%xmm3
	pxor	%xmm4,%xmm4
	pxor	%xmm5,%xmm5
	addq	$8,%rsp
.cfi_adjust_cfa_offset	-8
	.byte	0xf3,0xc3
.LSEH_end_set_encrypt_key:

.align	16
.Lkey_expansion_128:
	movups	%xmm0,(%rax)
	leaq	16(%rax),%rax
.Lkey_expansion_128_cold:
	shufps	$16,%xmm0,%xmm4
	xorps	%xmm4,%xmm0
	shufps	$140,%xmm0,%xmm4
	xorps	%xmm4,%xmm0
	shufps	$255,%xmm1,%xmm1
	xorps	%xmm1,%xmm0
	.byte	0xf3,0xc3

.align	16
.Lkey_expansion_192a:
	movups	%xmm0,(%rax)
	leaq	16(%rax),%rax
.Lkey_expansion_192a_cold:
	movaps	%xmm2,%xmm5
.Lkey_expansion_192b_warm:
	shufps	$16,%xmm0,%xmm4
	movdqa	%xmm2,%xmm3
	xorps	%xmm4,%xmm0
	shufps	$140,%xmm0,%xmm4
	pslldq	$4,%xmm3
	xorps	%xmm4,%xmm0
	pshufd	$85,%xmm1,%xmm1
	pxor	%xmm3,%xmm2
	pxor	%xmm1,%xmm0
	pshufd	$255,%xmm0,%xmm3
	pxor	%xmm3,%xmm2
	.byte	0xf3,0xc3

.align	16
.Lkey_expansion_192b:
	movaps	%xmm0,%xmm3
	shufps	$68,%xmm0,%xmm5
	movups	%xmm5,(%rax)
	shufps	$78,%xmm2,%xmm3
	movups	%xmm3,16(%rax)
	leaq	32(%rax),%rax
	jmp	.Lkey_expansion_192b_warm

.align	16
.Lkey_expansion_256a:
	movups	%xmm2,(%rax)
	leaq	16(%rax),%rax
.Lkey_expansion_256a_cold:
	shufps	$16,%xmm0,%xmm4
	xorps	%xmm4,%xmm0
	shufps	$140,%xmm0,%xmm4
	xorps	%xmm4,%xmm0
	shufps	$255,%xmm1,%xmm1
	xorps	%xmm1,%xmm0
	.byte	0xf3,0xc3

.align	16
.Lkey_expansion_256b:
	movups	%xmm0,(%rax)
	leaq	16(%rax),%rax

	shufps	$16,%xmm2,%xmm4
	xorps	%xmm4,%xmm2
	shufps	$140,%xmm2,%xmm4
	xorps	%xmm4,%xmm2
	shufps	$170,%xmm1,%xmm1
	xorps	%xmm1,%xmm2
	.byte	0xf3,0xc3
.cfi_endproc	
.size	aesni_set_encrypt_key,.-aesni_set_encrypt_key
.size	__aesni_set_encrypt_key,.-__aesni_set_encrypt_key
.align	64
.Lbswap_mask:
.byte	15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0
.Lincrement32:
.long	6,6,6,0
.Lincrement64:
.long	1,0,0,0
.Lxts_magic:
.long	0x87,0,1,0
.Lincrement1:
.byte	0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
.Lkey_rotate:
.long	0x0c0f0e0d,0x0c0f0e0d,0x0c0f0e0d,0x0c0f0e0d
.Lkey_rotate192:
.long	0x04070605,0x04070605,0x04070605,0x04070605
.Lkey_rcon1:
.long	1,1,1,1
.Lkey_rcon1b:
.long	0x1b,0x1b,0x1b,0x1b

.byte	65,69,83,32,102,111,114,32,73,110,116,101,108,32,65,69,83,45,78,73,44,32,67,82,89,80,84,79,71,65,77,83,32,98,121,32,60,97,112,112,114,111,64,111,112,101,110,115,115,108,46,111,114,103,62,0
.align	64
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                                                                                                                                                                                                                                                                                                       node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/aes/bsaes-x86_64.s                    0000664 0000000 0000000 00000140152 14746647661 0026723 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	




.type	_bsaes_encrypt8,@function
.align	64
_bsaes_encrypt8:
.cfi_startproc	
	leaq	.LBS0(%rip),%r11

	movdqa	(%rax),%xmm8
	leaq	16(%rax),%rax
	movdqa	80(%r11),%xmm7
	pxor	%xmm8,%xmm15
	pxor	%xmm8,%xmm0
	pxor	%xmm8,%xmm1
	pxor	%xmm8,%xmm2
.byte	102,68,15,56,0,255
.byte	102,15,56,0,199
	pxor	%xmm8,%xmm3
	pxor	%xmm8,%xmm4
.byte	102,15,56,0,207
.byte	102,15,56,0,215
	pxor	%xmm8,%xmm5
	pxor	%xmm8,%xmm6
.byte	102,15,56,0,223
.byte	102,15,56,0,231
.byte	102,15,56,0,239
.byte	102,15,56,0,247
_bsaes_encrypt8_bitslice:
	movdqa	0(%r11),%xmm7
	movdqa	16(%r11),%xmm8
	movdqa	%xmm5,%xmm9
	psrlq	$1,%xmm5
	movdqa	%xmm3,%xmm10
	psrlq	$1,%xmm3
	pxor	%xmm6,%xmm5
	pxor	%xmm4,%xmm3
	pand	%xmm7,%xmm5
	pand	%xmm7,%xmm3
	pxor	%xmm5,%xmm6
	psllq	$1,%xmm5
	pxor	%xmm3,%xmm4
	psllq	$1,%xmm3
	pxor	%xmm9,%xmm5
	pxor	%xmm10,%xmm3
	movdqa	%xmm1,%xmm9
	psrlq	$1,%xmm1
	movdqa	%xmm15,%xmm10
	psrlq	$1,%xmm15
	pxor	%xmm2,%xmm1
	pxor	%xmm0,%xmm15
	pand	%xmm7,%xmm1
	pand	%xmm7,%xmm15
	pxor	%xmm1,%xmm2
	psllq	$1,%xmm1
	pxor	%xmm15,%xmm0
	psllq	$1,%xmm15
	pxor	%xmm9,%xmm1
	pxor	%xmm10,%xmm15
	movdqa	32(%r11),%xmm7
	movdqa	%xmm4,%xmm9
	psrlq	$2,%xmm4
	movdqa	%xmm3,%xmm10
	psrlq	$2,%xmm3
	pxor	%xmm6,%xmm4
	pxor	%xmm5,%xmm3
	pand	%xmm8,%xmm4
	pand	%xmm8,%xmm3
	pxor	%xmm4,%xmm6
	psllq	$2,%xmm4
	pxor	%xmm3,%xmm5
	psllq	$2,%xmm3
	pxor	%xmm9,%xmm4
	pxor	%xmm10,%xmm3
	movdqa	%xmm0,%xmm9
	psrlq	$2,%xmm0
	movdqa	%xmm15,%xmm10
	psrlq	$2,%xmm15
	pxor	%xmm2,%xmm0
	pxor	%xmm1,%xmm15
	pand	%xmm8,%xmm0
	pand	%xmm8,%xmm15
	pxor	%xmm0,%xmm2
	psllq	$2,%xmm0
	pxor	%xmm15,%xmm1
	psllq	$2,%xmm15
	pxor	%xmm9,%xmm0
	pxor	%xmm10,%xmm15
	movdqa	%xmm2,%xmm9
	psrlq	$4,%xmm2
	movdqa	%xmm1,%xmm10
	psrlq	$4,%xmm1
	pxor	%xmm6,%xmm2
	pxor	%xmm5,%xmm1
	pand	%xmm7,%xmm2
	pand	%xmm7,%xmm1
	pxor	%xmm2,%xmm6
	psllq	$4,%xmm2
	pxor	%xmm1,%xmm5
	psllq	$4,%xmm1
	pxor	%xmm9,%xmm2
	pxor	%xmm10,%xmm1
	movdqa	%xmm0,%xmm9
	psrlq	$4,%xmm0
	movdqa	%xmm15,%xmm10
	psrlq	$4,%xmm15
	pxor	%xmm4,%xmm0
	pxor	%xmm3,%xmm15
	pand	%xmm7,%xmm0
	pand	%xmm7,%xmm15
	pxor	%xmm0,%xmm4
	psllq	$4,%xmm0
	pxor	%xmm15,%xmm3
	psllq	$4,%xmm15
	pxor	%xmm9,%xmm0
	pxor	%xmm10,%xmm15
	decl	%r10d
	jmp	.Lenc_sbox
.align	16
.Lenc_loop:
	pxor	0(%rax),%xmm15
	pxor	16(%rax),%xmm0
	pxor	32(%rax),%xmm1
	pxor	48(%rax),%xmm2
.byte	102,68,15,56,0,255
.byte	102,15,56,0,199
	pxor	64(%rax),%xmm3
	pxor	80(%rax),%xmm4
.byte	102,15,56,0,207
.byte	102,15,56,0,215
	pxor	96(%rax),%xmm5
	pxor	112(%rax),%xmm6
.byte	102,15,56,0,223
.byte	102,15,56,0,231
.byte	102,15,56,0,239
.byte	102,15,56,0,247
	leaq	128(%rax),%rax
.Lenc_sbox:
	pxor	%xmm5,%xmm4
	pxor	%xmm0,%xmm1
	pxor	%xmm15,%xmm2
	pxor	%xmm1,%xmm5
	pxor	%xmm15,%xmm4

	pxor	%xmm2,%xmm5
	pxor	%xmm6,%xmm2
	pxor	%xmm4,%xmm6
	pxor	%xmm3,%xmm2
	pxor	%xmm4,%xmm3
	pxor	%xmm0,%xmm2

	pxor	%xmm6,%xmm1
	pxor	%xmm4,%xmm0
	movdqa	%xmm6,%xmm10
	movdqa	%xmm0,%xmm9
	movdqa	%xmm4,%xmm8
	movdqa	%xmm1,%xmm12
	movdqa	%xmm5,%xmm11

	pxor	%xmm3,%xmm10
	pxor	%xmm1,%xmm9
	pxor	%xmm2,%xmm8
	movdqa	%xmm10,%xmm13
	pxor	%xmm3,%xmm12
	movdqa	%xmm9,%xmm7
	pxor	%xmm15,%xmm11
	movdqa	%xmm10,%xmm14

	por	%xmm8,%xmm9
	por	%xmm11,%xmm10
	pxor	%xmm7,%xmm14
	pand	%xmm11,%xmm13
	pxor	%xmm8,%xmm11
	pand	%xmm8,%xmm7
	pand	%xmm11,%xmm14
	movdqa	%xmm2,%xmm11
	pxor	%xmm15,%xmm11
	pand	%xmm11,%xmm12
	pxor	%xmm12,%xmm10
	pxor	%xmm12,%xmm9
	movdqa	%xmm6,%xmm12
	movdqa	%xmm4,%xmm11
	pxor	%xmm0,%xmm12
	pxor	%xmm5,%xmm11
	movdqa	%xmm12,%xmm8
	pand	%xmm11,%xmm12
	por	%xmm11,%xmm8
	pxor	%xmm12,%xmm7
	pxor	%xmm14,%xmm10
	pxor	%xmm13,%xmm9
	pxor	%xmm14,%xmm8
	movdqa	%xmm1,%xmm11
	pxor	%xmm13,%xmm7
	movdqa	%xmm3,%xmm12
	pxor	%xmm13,%xmm8
	movdqa	%xmm0,%xmm13
	pand	%xmm2,%xmm11
	movdqa	%xmm6,%xmm14
	pand	%xmm15,%xmm12
	pand	%xmm4,%xmm13
	por	%xmm5,%xmm14
	pxor	%xmm11,%xmm10
	pxor	%xmm12,%xmm9
	pxor	%xmm13,%xmm8
	pxor	%xmm14,%xmm7





	movdqa	%xmm10,%xmm11
	pand	%xmm8,%xmm10
	pxor	%xmm9,%xmm11

	movdqa	%xmm7,%xmm13
	movdqa	%xmm11,%xmm14
	pxor	%xmm10,%xmm13
	pand	%xmm13,%xmm14

	movdqa	%xmm8,%xmm12
	pxor	%xmm9,%xmm14
	pxor	%xmm7,%xmm12

	pxor	%xmm9,%xmm10

	pand	%xmm10,%xmm12

	movdqa	%xmm13,%xmm9
	pxor	%xmm7,%xmm12

	pxor	%xmm12,%xmm9
	pxor	%xmm12,%xmm8

	pand	%xmm7,%xmm9

	pxor	%xmm9,%xmm13
	pxor	%xmm9,%xmm8

	pand	%xmm14,%xmm13

	pxor	%xmm11,%xmm13
	movdqa	%xmm5,%xmm11
	movdqa	%xmm4,%xmm7
	movdqa	%xmm14,%xmm9
	pxor	%xmm13,%xmm9
	pand	%xmm5,%xmm9
	pxor	%xmm4,%xmm5
	pand	%xmm14,%xmm4
	pand	%xmm13,%xmm5
	pxor	%xmm4,%xmm5
	pxor	%xmm9,%xmm4
	pxor	%xmm15,%xmm11
	pxor	%xmm2,%xmm7
	pxor	%xmm12,%xmm14
	pxor	%xmm8,%xmm13
	movdqa	%xmm14,%xmm10
	movdqa	%xmm12,%xmm9
	pxor	%xmm13,%xmm10
	pxor	%xmm8,%xmm9
	pand	%xmm11,%xmm10
	pand	%xmm15,%xmm9
	pxor	%xmm7,%xmm11
	pxor	%xmm2,%xmm15
	pand	%xmm14,%xmm7
	pand	%xmm12,%xmm2
	pand	%xmm13,%xmm11
	pand	%xmm8,%xmm15
	pxor	%xmm11,%xmm7
	pxor	%xmm2,%xmm15
	pxor	%xmm10,%xmm11
	pxor	%xmm9,%xmm2
	pxor	%xmm11,%xmm5
	pxor	%xmm11,%xmm15
	pxor	%xmm7,%xmm4
	pxor	%xmm7,%xmm2

	movdqa	%xmm6,%xmm11
	movdqa	%xmm0,%xmm7
	pxor	%xmm3,%xmm11
	pxor	%xmm1,%xmm7
	movdqa	%xmm14,%xmm10
	movdqa	%xmm12,%xmm9
	pxor	%xmm13,%xmm10
	pxor	%xmm8,%xmm9
	pand	%xmm11,%xmm10
	pand	%xmm3,%xmm9
	pxor	%xmm7,%xmm11
	pxor	%xmm1,%xmm3
	pand	%xmm14,%xmm7
	pand	%xmm12,%xmm1
	pand	%xmm13,%xmm11
	pand	%xmm8,%xmm3
	pxor	%xmm11,%xmm7
	pxor	%xmm1,%xmm3
	pxor	%xmm10,%xmm11
	pxor	%xmm9,%xmm1
	pxor	%xmm12,%xmm14
	pxor	%xmm8,%xmm13
	movdqa	%xmm14,%xmm10
	pxor	%xmm13,%xmm10
	pand	%xmm6,%xmm10
	pxor	%xmm0,%xmm6
	pand	%xmm14,%xmm0
	pand	%xmm13,%xmm6
	pxor	%xmm0,%xmm6
	pxor	%xmm10,%xmm0
	pxor	%xmm11,%xmm6
	pxor	%xmm11,%xmm3
	pxor	%xmm7,%xmm0
	pxor	%xmm7,%xmm1
	pxor	%xmm15,%xmm6
	pxor	%xmm5,%xmm0
	pxor	%xmm6,%xmm3
	pxor	%xmm15,%xmm5
	pxor	%xmm0,%xmm15

	pxor	%xmm4,%xmm0
	pxor	%xmm1,%xmm4
	pxor	%xmm2,%xmm1
	pxor	%xmm4,%xmm2
	pxor	%xmm4,%xmm3

	pxor	%xmm2,%xmm5
	decl	%r10d
	jl	.Lenc_done
	pshufd	$0x93,%xmm15,%xmm7
	pshufd	$0x93,%xmm0,%xmm8
	pxor	%xmm7,%xmm15
	pshufd	$0x93,%xmm3,%xmm9
	pxor	%xmm8,%xmm0
	pshufd	$0x93,%xmm5,%xmm10
	pxor	%xmm9,%xmm3
	pshufd	$0x93,%xmm2,%xmm11
	pxor	%xmm10,%xmm5
	pshufd	$0x93,%xmm6,%xmm12
	pxor	%xmm11,%xmm2
	pshufd	$0x93,%xmm1,%xmm13
	pxor	%xmm12,%xmm6
	pshufd	$0x93,%xmm4,%xmm14
	pxor	%xmm13,%xmm1
	pxor	%xmm14,%xmm4

	pxor	%xmm15,%xmm8
	pxor	%xmm4,%xmm7
	pxor	%xmm4,%xmm8
	pshufd	$0x4E,%xmm15,%xmm15
	pxor	%xmm0,%xmm9
	pshufd	$0x4E,%xmm0,%xmm0
	pxor	%xmm2,%xmm12
	pxor	%xmm7,%xmm15
	pxor	%xmm6,%xmm13
	pxor	%xmm8,%xmm0
	pxor	%xmm5,%xmm11
	pshufd	$0x4E,%xmm2,%xmm7
	pxor	%xmm1,%xmm14
	pshufd	$0x4E,%xmm6,%xmm8
	pxor	%xmm3,%xmm10
	pshufd	$0x4E,%xmm5,%xmm2
	pxor	%xmm4,%xmm10
	pshufd	$0x4E,%xmm4,%xmm6
	pxor	%xmm4,%xmm11
	pshufd	$0x4E,%xmm1,%xmm5
	pxor	%xmm11,%xmm7
	pshufd	$0x4E,%xmm3,%xmm1
	pxor	%xmm12,%xmm8
	pxor	%xmm10,%xmm2
	pxor	%xmm14,%xmm6
	pxor	%xmm13,%xmm5
	movdqa	%xmm7,%xmm3
	pxor	%xmm9,%xmm1
	movdqa	%xmm8,%xmm4
	movdqa	48(%r11),%xmm7
	jnz	.Lenc_loop
	movdqa	64(%r11),%xmm7
	jmp	.Lenc_loop
.align	16
.Lenc_done:
	movdqa	0(%r11),%xmm7
	movdqa	16(%r11),%xmm8
	movdqa	%xmm1,%xmm9
	psrlq	$1,%xmm1
	movdqa	%xmm2,%xmm10
	psrlq	$1,%xmm2
	pxor	%xmm4,%xmm1
	pxor	%xmm6,%xmm2
	pand	%xmm7,%xmm1
	pand	%xmm7,%xmm2
	pxor	%xmm1,%xmm4
	psllq	$1,%xmm1
	pxor	%xmm2,%xmm6
	psllq	$1,%xmm2
	pxor	%xmm9,%xmm1
	pxor	%xmm10,%xmm2
	movdqa	%xmm3,%xmm9
	psrlq	$1,%xmm3
	movdqa	%xmm15,%xmm10
	psrlq	$1,%xmm15
	pxor	%xmm5,%xmm3
	pxor	%xmm0,%xmm15
	pand	%xmm7,%xmm3
	pand	%xmm7,%xmm15
	pxor	%xmm3,%xmm5
	psllq	$1,%xmm3
	pxor	%xmm15,%xmm0
	psllq	$1,%xmm15
	pxor	%xmm9,%xmm3
	pxor	%xmm10,%xmm15
	movdqa	32(%r11),%xmm7
	movdqa	%xmm6,%xmm9
	psrlq	$2,%xmm6
	movdqa	%xmm2,%xmm10
	psrlq	$2,%xmm2
	pxor	%xmm4,%xmm6
	pxor	%xmm1,%xmm2
	pand	%xmm8,%xmm6
	pand	%xmm8,%xmm2
	pxor	%xmm6,%xmm4
	psllq	$2,%xmm6
	pxor	%xmm2,%xmm1
	psllq	$2,%xmm2
	pxor	%xmm9,%xmm6
	pxor	%xmm10,%xmm2
	movdqa	%xmm0,%xmm9
	psrlq	$2,%xmm0
	movdqa	%xmm15,%xmm10
	psrlq	$2,%xmm15
	pxor	%xmm5,%xmm0
	pxor	%xmm3,%xmm15
	pand	%xmm8,%xmm0
	pand	%xmm8,%xmm15
	pxor	%xmm0,%xmm5
	psllq	$2,%xmm0
	pxor	%xmm15,%xmm3
	psllq	$2,%xmm15
	pxor	%xmm9,%xmm0
	pxor	%xmm10,%xmm15
	movdqa	%xmm5,%xmm9
	psrlq	$4,%xmm5
	movdqa	%xmm3,%xmm10
	psrlq	$4,%xmm3
	pxor	%xmm4,%xmm5
	pxor	%xmm1,%xmm3
	pand	%xmm7,%xmm5
	pand	%xmm7,%xmm3
	pxor	%xmm5,%xmm4
	psllq	$4,%xmm5
	pxor	%xmm3,%xmm1
	psllq	$4,%xmm3
	pxor	%xmm9,%xmm5
	pxor	%xmm10,%xmm3
	movdqa	%xmm0,%xmm9
	psrlq	$4,%xmm0
	movdqa	%xmm15,%xmm10
	psrlq	$4,%xmm15
	pxor	%xmm6,%xmm0
	pxor	%xmm2,%xmm15
	pand	%xmm7,%xmm0
	pand	%xmm7,%xmm15
	pxor	%xmm0,%xmm6
	psllq	$4,%xmm0
	pxor	%xmm15,%xmm2
	psllq	$4,%xmm15
	pxor	%xmm9,%xmm0
	pxor	%xmm10,%xmm15
	movdqa	(%rax),%xmm7
	pxor	%xmm7,%xmm3
	pxor	%xmm7,%xmm5
	pxor	%xmm7,%xmm2
	pxor	%xmm7,%xmm6
	pxor	%xmm7,%xmm1
	pxor	%xmm7,%xmm4
	pxor	%xmm7,%xmm15
	pxor	%xmm7,%xmm0
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_bsaes_encrypt8,.-_bsaes_encrypt8

.type	_bsaes_decrypt8,@function
.align	64
_bsaes_decrypt8:
.cfi_startproc	
	leaq	.LBS0(%rip),%r11

	movdqa	(%rax),%xmm8
	leaq	16(%rax),%rax
	movdqa	-48(%r11),%xmm7
	pxor	%xmm8,%xmm15
	pxor	%xmm8,%xmm0
	pxor	%xmm8,%xmm1
	pxor	%xmm8,%xmm2
.byte	102,68,15,56,0,255
.byte	102,15,56,0,199
	pxor	%xmm8,%xmm3
	pxor	%xmm8,%xmm4
.byte	102,15,56,0,207
.byte	102,15,56,0,215
	pxor	%xmm8,%xmm5
	pxor	%xmm8,%xmm6
.byte	102,15,56,0,223
.byte	102,15,56,0,231
.byte	102,15,56,0,239
.byte	102,15,56,0,247
	movdqa	0(%r11),%xmm7
	movdqa	16(%r11),%xmm8
	movdqa	%xmm5,%xmm9
	psrlq	$1,%xmm5
	movdqa	%xmm3,%xmm10
	psrlq	$1,%xmm3
	pxor	%xmm6,%xmm5
	pxor	%xmm4,%xmm3
	pand	%xmm7,%xmm5
	pand	%xmm7,%xmm3
	pxor	%xmm5,%xmm6
	psllq	$1,%xmm5
	pxor	%xmm3,%xmm4
	psllq	$1,%xmm3
	pxor	%xmm9,%xmm5
	pxor	%xmm10,%xmm3
	movdqa	%xmm1,%xmm9
	psrlq	$1,%xmm1
	movdqa	%xmm15,%xmm10
	psrlq	$1,%xmm15
	pxor	%xmm2,%xmm1
	pxor	%xmm0,%xmm15
	pand	%xmm7,%xmm1
	pand	%xmm7,%xmm15
	pxor	%xmm1,%xmm2
	psllq	$1,%xmm1
	pxor	%xmm15,%xmm0
	psllq	$1,%xmm15
	pxor	%xmm9,%xmm1
	pxor	%xmm10,%xmm15
	movdqa	32(%r11),%xmm7
	movdqa	%xmm4,%xmm9
	psrlq	$2,%xmm4
	movdqa	%xmm3,%xmm10
	psrlq	$2,%xmm3
	pxor	%xmm6,%xmm4
	pxor	%xmm5,%xmm3
	pand	%xmm8,%xmm4
	pand	%xmm8,%xmm3
	pxor	%xmm4,%xmm6
	psllq	$2,%xmm4
	pxor	%xmm3,%xmm5
	psllq	$2,%xmm3
	pxor	%xmm9,%xmm4
	pxor	%xmm10,%xmm3
	movdqa	%xmm0,%xmm9
	psrlq	$2,%xmm0
	movdqa	%xmm15,%xmm10
	psrlq	$2,%xmm15
	pxor	%xmm2,%xmm0
	pxor	%xmm1,%xmm15
	pand	%xmm8,%xmm0
	pand	%xmm8,%xmm15
	pxor	%xmm0,%xmm2
	psllq	$2,%xmm0
	pxor	%xmm15,%xmm1
	psllq	$2,%xmm15
	pxor	%xmm9,%xmm0
	pxor	%xmm10,%xmm15
	movdqa	%xmm2,%xmm9
	psrlq	$4,%xmm2
	movdqa	%xmm1,%xmm10
	psrlq	$4,%xmm1
	pxor	%xmm6,%xmm2
	pxor	%xmm5,%xmm1
	pand	%xmm7,%xmm2
	pand	%xmm7,%xmm1
	pxor	%xmm2,%xmm6
	psllq	$4,%xmm2
	pxor	%xmm1,%xmm5
	psllq	$4,%xmm1
	pxor	%xmm9,%xmm2
	pxor	%xmm10,%xmm1
	movdqa	%xmm0,%xmm9
	psrlq	$4,%xmm0
	movdqa	%xmm15,%xmm10
	psrlq	$4,%xmm15
	pxor	%xmm4,%xmm0
	pxor	%xmm3,%xmm15
	pand	%xmm7,%xmm0
	pand	%xmm7,%xmm15
	pxor	%xmm0,%xmm4
	psllq	$4,%xmm0
	pxor	%xmm15,%xmm3
	psllq	$4,%xmm15
	pxor	%xmm9,%xmm0
	pxor	%xmm10,%xmm15
	decl	%r10d
	jmp	.Ldec_sbox
.align	16
.Ldec_loop:
	pxor	0(%rax),%xmm15
	pxor	16(%rax),%xmm0
	pxor	32(%rax),%xmm1
	pxor	48(%rax),%xmm2
.byte	102,68,15,56,0,255
.byte	102,15,56,0,199
	pxor	64(%rax),%xmm3
	pxor	80(%rax),%xmm4
.byte	102,15,56,0,207
.byte	102,15,56,0,215
	pxor	96(%rax),%xmm5
	pxor	112(%rax),%xmm6
.byte	102,15,56,0,223
.byte	102,15,56,0,231
.byte	102,15,56,0,239
.byte	102,15,56,0,247
	leaq	128(%rax),%rax
.Ldec_sbox:
	pxor	%xmm3,%xmm2

	pxor	%xmm6,%xmm3
	pxor	%xmm6,%xmm1
	pxor	%xmm3,%xmm5
	pxor	%xmm5,%xmm6
	pxor	%xmm6,%xmm0

	pxor	%xmm0,%xmm15
	pxor	%xmm4,%xmm1
	pxor	%xmm15,%xmm2
	pxor	%xmm15,%xmm4
	pxor	%xmm2,%xmm0
	movdqa	%xmm2,%xmm10
	movdqa	%xmm6,%xmm9
	movdqa	%xmm0,%xmm8
	movdqa	%xmm3,%xmm12
	movdqa	%xmm4,%xmm11

	pxor	%xmm15,%xmm10
	pxor	%xmm3,%xmm9
	pxor	%xmm5,%xmm8
	movdqa	%xmm10,%xmm13
	pxor	%xmm15,%xmm12
	movdqa	%xmm9,%xmm7
	pxor	%xmm1,%xmm11
	movdqa	%xmm10,%xmm14

	por	%xmm8,%xmm9
	por	%xmm11,%xmm10
	pxor	%xmm7,%xmm14
	pand	%xmm11,%xmm13
	pxor	%xmm8,%xmm11
	pand	%xmm8,%xmm7
	pand	%xmm11,%xmm14
	movdqa	%xmm5,%xmm11
	pxor	%xmm1,%xmm11
	pand	%xmm11,%xmm12
	pxor	%xmm12,%xmm10
	pxor	%xmm12,%xmm9
	movdqa	%xmm2,%xmm12
	movdqa	%xmm0,%xmm11
	pxor	%xmm6,%xmm12
	pxor	%xmm4,%xmm11
	movdqa	%xmm12,%xmm8
	pand	%xmm11,%xmm12
	por	%xmm11,%xmm8
	pxor	%xmm12,%xmm7
	pxor	%xmm14,%xmm10
	pxor	%xmm13,%xmm9
	pxor	%xmm14,%xmm8
	movdqa	%xmm3,%xmm11
	pxor	%xmm13,%xmm7
	movdqa	%xmm15,%xmm12
	pxor	%xmm13,%xmm8
	movdqa	%xmm6,%xmm13
	pand	%xmm5,%xmm11
	movdqa	%xmm2,%xmm14
	pand	%xmm1,%xmm12
	pand	%xmm0,%xmm13
	por	%xmm4,%xmm14
	pxor	%xmm11,%xmm10
	pxor	%xmm12,%xmm9
	pxor	%xmm13,%xmm8
	pxor	%xmm14,%xmm7





	movdqa	%xmm10,%xmm11
	pand	%xmm8,%xmm10
	pxor	%xmm9,%xmm11

	movdqa	%xmm7,%xmm13
	movdqa	%xmm11,%xmm14
	pxor	%xmm10,%xmm13
	pand	%xmm13,%xmm14

	movdqa	%xmm8,%xmm12
	pxor	%xmm9,%xmm14
	pxor	%xmm7,%xmm12

	pxor	%xmm9,%xmm10

	pand	%xmm10,%xmm12

	movdqa	%xmm13,%xmm9
	pxor	%xmm7,%xmm12

	pxor	%xmm12,%xmm9
	pxor	%xmm12,%xmm8

	pand	%xmm7,%xmm9

	pxor	%xmm9,%xmm13
	pxor	%xmm9,%xmm8

	pand	%xmm14,%xmm13

	pxor	%xmm11,%xmm13
	movdqa	%xmm4,%xmm11
	movdqa	%xmm0,%xmm7
	movdqa	%xmm14,%xmm9
	pxor	%xmm13,%xmm9
	pand	%xmm4,%xmm9
	pxor	%xmm0,%xmm4
	pand	%xmm14,%xmm0
	pand	%xmm13,%xmm4
	pxor	%xmm0,%xmm4
	pxor	%xmm9,%xmm0
	pxor	%xmm1,%xmm11
	pxor	%xmm5,%xmm7
	pxor	%xmm12,%xmm14
	pxor	%xmm8,%xmm13
	movdqa	%xmm14,%xmm10
	movdqa	%xmm12,%xmm9
	pxor	%xmm13,%xmm10
	pxor	%xmm8,%xmm9
	pand	%xmm11,%xmm10
	pand	%xmm1,%xmm9
	pxor	%xmm7,%xmm11
	pxor	%xmm5,%xmm1
	pand	%xmm14,%xmm7
	pand	%xmm12,%xmm5
	pand	%xmm13,%xmm11
	pand	%xmm8,%xmm1
	pxor	%xmm11,%xmm7
	pxor	%xmm5,%xmm1
	pxor	%xmm10,%xmm11
	pxor	%xmm9,%xmm5
	pxor	%xmm11,%xmm4
	pxor	%xmm11,%xmm1
	pxor	%xmm7,%xmm0
	pxor	%xmm7,%xmm5

	movdqa	%xmm2,%xmm11
	movdqa	%xmm6,%xmm7
	pxor	%xmm15,%xmm11
	pxor	%xmm3,%xmm7
	movdqa	%xmm14,%xmm10
	movdqa	%xmm12,%xmm9
	pxor	%xmm13,%xmm10
	pxor	%xmm8,%xmm9
	pand	%xmm11,%xmm10
	pand	%xmm15,%xmm9
	pxor	%xmm7,%xmm11
	pxor	%xmm3,%xmm15
	pand	%xmm14,%xmm7
	pand	%xmm12,%xmm3
	pand	%xmm13,%xmm11
	pand	%xmm8,%xmm15
	pxor	%xmm11,%xmm7
	pxor	%xmm3,%xmm15
	pxor	%xmm10,%xmm11
	pxor	%xmm9,%xmm3
	pxor	%xmm12,%xmm14
	pxor	%xmm8,%xmm13
	movdqa	%xmm14,%xmm10
	pxor	%xmm13,%xmm10
	pand	%xmm2,%xmm10
	pxor	%xmm6,%xmm2
	pand	%xmm14,%xmm6
	pand	%xmm13,%xmm2
	pxor	%xmm6,%xmm2
	pxor	%xmm10,%xmm6
	pxor	%xmm11,%xmm2
	pxor	%xmm11,%xmm15
	pxor	%xmm7,%xmm6
	pxor	%xmm7,%xmm3
	pxor	%xmm6,%xmm0
	pxor	%xmm4,%xmm5

	pxor	%xmm0,%xmm3
	pxor	%xmm6,%xmm1
	pxor	%xmm6,%xmm4
	pxor	%xmm1,%xmm3
	pxor	%xmm15,%xmm6
	pxor	%xmm4,%xmm3
	pxor	%xmm5,%xmm2
	pxor	%xmm0,%xmm5
	pxor	%xmm3,%xmm2

	pxor	%xmm15,%xmm3
	pxor	%xmm2,%xmm6
	decl	%r10d
	jl	.Ldec_done

	pshufd	$0x4E,%xmm15,%xmm7
	pshufd	$0x4E,%xmm2,%xmm13
	pxor	%xmm15,%xmm7
	pshufd	$0x4E,%xmm4,%xmm14
	pxor	%xmm2,%xmm13
	pshufd	$0x4E,%xmm0,%xmm8
	pxor	%xmm4,%xmm14
	pshufd	$0x4E,%xmm5,%xmm9
	pxor	%xmm0,%xmm8
	pshufd	$0x4E,%xmm3,%xmm10
	pxor	%xmm5,%xmm9
	pxor	%xmm13,%xmm15
	pxor	%xmm13,%xmm0
	pshufd	$0x4E,%xmm1,%xmm11
	pxor	%xmm3,%xmm10
	pxor	%xmm7,%xmm5
	pxor	%xmm8,%xmm3
	pshufd	$0x4E,%xmm6,%xmm12
	pxor	%xmm1,%xmm11
	pxor	%xmm14,%xmm0
	pxor	%xmm9,%xmm1
	pxor	%xmm6,%xmm12

	pxor	%xmm14,%xmm5
	pxor	%xmm13,%xmm3
	pxor	%xmm13,%xmm1
	pxor	%xmm10,%xmm6
	pxor	%xmm11,%xmm2
	pxor	%xmm14,%xmm1
	pxor	%xmm14,%xmm6
	pxor	%xmm12,%xmm4
	pshufd	$0x93,%xmm15,%xmm7
	pshufd	$0x93,%xmm0,%xmm8
	pxor	%xmm7,%xmm15
	pshufd	$0x93,%xmm5,%xmm9
	pxor	%xmm8,%xmm0
	pshufd	$0x93,%xmm3,%xmm10
	pxor	%xmm9,%xmm5
	pshufd	$0x93,%xmm1,%xmm11
	pxor	%xmm10,%xmm3
	pshufd	$0x93,%xmm6,%xmm12
	pxor	%xmm11,%xmm1
	pshufd	$0x93,%xmm2,%xmm13
	pxor	%xmm12,%xmm6
	pshufd	$0x93,%xmm4,%xmm14
	pxor	%xmm13,%xmm2
	pxor	%xmm14,%xmm4

	pxor	%xmm15,%xmm8
	pxor	%xmm4,%xmm7
	pxor	%xmm4,%xmm8
	pshufd	$0x4E,%xmm15,%xmm15
	pxor	%xmm0,%xmm9
	pshufd	$0x4E,%xmm0,%xmm0
	pxor	%xmm1,%xmm12
	pxor	%xmm7,%xmm15
	pxor	%xmm6,%xmm13
	pxor	%xmm8,%xmm0
	pxor	%xmm3,%xmm11
	pshufd	$0x4E,%xmm1,%xmm7
	pxor	%xmm2,%xmm14
	pshufd	$0x4E,%xmm6,%xmm8
	pxor	%xmm5,%xmm10
	pshufd	$0x4E,%xmm3,%xmm1
	pxor	%xmm4,%xmm10
	pshufd	$0x4E,%xmm4,%xmm6
	pxor	%xmm4,%xmm11
	pshufd	$0x4E,%xmm2,%xmm3
	pxor	%xmm11,%xmm7
	pshufd	$0x4E,%xmm5,%xmm2
	pxor	%xmm12,%xmm8
	pxor	%xmm1,%xmm10
	pxor	%xmm14,%xmm6
	pxor	%xmm3,%xmm13
	movdqa	%xmm7,%xmm3
	pxor	%xmm9,%xmm2
	movdqa	%xmm13,%xmm5
	movdqa	%xmm8,%xmm4
	movdqa	%xmm2,%xmm1
	movdqa	%xmm10,%xmm2
	movdqa	-16(%r11),%xmm7
	jnz	.Ldec_loop
	movdqa	-32(%r11),%xmm7
	jmp	.Ldec_loop
.align	16
.Ldec_done:
	movdqa	0(%r11),%xmm7
	movdqa	16(%r11),%xmm8
	movdqa	%xmm2,%xmm9
	psrlq	$1,%xmm2
	movdqa	%xmm1,%xmm10
	psrlq	$1,%xmm1
	pxor	%xmm4,%xmm2
	pxor	%xmm6,%xmm1
	pand	%xmm7,%xmm2
	pand	%xmm7,%xmm1
	pxor	%xmm2,%xmm4
	psllq	$1,%xmm2
	pxor	%xmm1,%xmm6
	psllq	$1,%xmm1
	pxor	%xmm9,%xmm2
	pxor	%xmm10,%xmm1
	movdqa	%xmm5,%xmm9
	psrlq	$1,%xmm5
	movdqa	%xmm15,%xmm10
	psrlq	$1,%xmm15
	pxor	%xmm3,%xmm5
	pxor	%xmm0,%xmm15
	pand	%xmm7,%xmm5
	pand	%xmm7,%xmm15
	pxor	%xmm5,%xmm3
	psllq	$1,%xmm5
	pxor	%xmm15,%xmm0
	psllq	$1,%xmm15
	pxor	%xmm9,%xmm5
	pxor	%xmm10,%xmm15
	movdqa	32(%r11),%xmm7
	movdqa	%xmm6,%xmm9
	psrlq	$2,%xmm6
	movdqa	%xmm1,%xmm10
	psrlq	$2,%xmm1
	pxor	%xmm4,%xmm6
	pxor	%xmm2,%xmm1
	pand	%xmm8,%xmm6
	pand	%xmm8,%xmm1
	pxor	%xmm6,%xmm4
	psllq	$2,%xmm6
	pxor	%xmm1,%xmm2
	psllq	$2,%xmm1
	pxor	%xmm9,%xmm6
	pxor	%xmm10,%xmm1
	movdqa	%xmm0,%xmm9
	psrlq	$2,%xmm0
	movdqa	%xmm15,%xmm10
	psrlq	$2,%xmm15
	pxor	%xmm3,%xmm0
	pxor	%xmm5,%xmm15
	pand	%xmm8,%xmm0
	pand	%xmm8,%xmm15
	pxor	%xmm0,%xmm3
	psllq	$2,%xmm0
	pxor	%xmm15,%xmm5
	psllq	$2,%xmm15
	pxor	%xmm9,%xmm0
	pxor	%xmm10,%xmm15
	movdqa	%xmm3,%xmm9
	psrlq	$4,%xmm3
	movdqa	%xmm5,%xmm10
	psrlq	$4,%xmm5
	pxor	%xmm4,%xmm3
	pxor	%xmm2,%xmm5
	pand	%xmm7,%xmm3
	pand	%xmm7,%xmm5
	pxor	%xmm3,%xmm4
	psllq	$4,%xmm3
	pxor	%xmm5,%xmm2
	psllq	$4,%xmm5
	pxor	%xmm9,%xmm3
	pxor	%xmm10,%xmm5
	movdqa	%xmm0,%xmm9
	psrlq	$4,%xmm0
	movdqa	%xmm15,%xmm10
	psrlq	$4,%xmm15
	pxor	%xmm6,%xmm0
	pxor	%xmm1,%xmm15
	pand	%xmm7,%xmm0
	pand	%xmm7,%xmm15
	pxor	%xmm0,%xmm6
	psllq	$4,%xmm0
	pxor	%xmm15,%xmm1
	psllq	$4,%xmm15
	pxor	%xmm9,%xmm0
	pxor	%xmm10,%xmm15
	movdqa	(%rax),%xmm7
	pxor	%xmm7,%xmm5
	pxor	%xmm7,%xmm3
	pxor	%xmm7,%xmm1
	pxor	%xmm7,%xmm6
	pxor	%xmm7,%xmm2
	pxor	%xmm7,%xmm4
	pxor	%xmm7,%xmm15
	pxor	%xmm7,%xmm0
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_bsaes_decrypt8,.-_bsaes_decrypt8
.type	_bsaes_key_convert,@function
.align	16
_bsaes_key_convert:
.cfi_startproc	
	leaq	.Lmasks(%rip),%r11
	movdqu	(%rcx),%xmm7
	leaq	16(%rcx),%rcx
	movdqa	0(%r11),%xmm0
	movdqa	16(%r11),%xmm1
	movdqa	32(%r11),%xmm2
	movdqa	48(%r11),%xmm3
	movdqa	64(%r11),%xmm4
	pcmpeqd	%xmm5,%xmm5

	movdqu	(%rcx),%xmm6
	movdqa	%xmm7,(%rax)
	leaq	16(%rax),%rax
	decl	%r10d
	jmp	.Lkey_loop
.align	16
.Lkey_loop:
.byte	102,15,56,0,244

	movdqa	%xmm0,%xmm8
	movdqa	%xmm1,%xmm9

	pand	%xmm6,%xmm8
	pand	%xmm6,%xmm9
	movdqa	%xmm2,%xmm10
	pcmpeqb	%xmm0,%xmm8
	psllq	$4,%xmm0
	movdqa	%xmm3,%xmm11
	pcmpeqb	%xmm1,%xmm9
	psllq	$4,%xmm1

	pand	%xmm6,%xmm10
	pand	%xmm6,%xmm11
	movdqa	%xmm0,%xmm12
	pcmpeqb	%xmm2,%xmm10
	psllq	$4,%xmm2
	movdqa	%xmm1,%xmm13
	pcmpeqb	%xmm3,%xmm11
	psllq	$4,%xmm3

	movdqa	%xmm2,%xmm14
	movdqa	%xmm3,%xmm15
	pxor	%xmm5,%xmm8
	pxor	%xmm5,%xmm9

	pand	%xmm6,%xmm12
	pand	%xmm6,%xmm13
	movdqa	%xmm8,0(%rax)
	pcmpeqb	%xmm0,%xmm12
	psrlq	$4,%xmm0
	movdqa	%xmm9,16(%rax)
	pcmpeqb	%xmm1,%xmm13
	psrlq	$4,%xmm1
	leaq	16(%rcx),%rcx

	pand	%xmm6,%xmm14
	pand	%xmm6,%xmm15
	movdqa	%xmm10,32(%rax)
	pcmpeqb	%xmm2,%xmm14
	psrlq	$4,%xmm2
	movdqa	%xmm11,48(%rax)
	pcmpeqb	%xmm3,%xmm15
	psrlq	$4,%xmm3
	movdqu	(%rcx),%xmm6

	pxor	%xmm5,%xmm13
	pxor	%xmm5,%xmm14
	movdqa	%xmm12,64(%rax)
	movdqa	%xmm13,80(%rax)
	movdqa	%xmm14,96(%rax)
	movdqa	%xmm15,112(%rax)
	leaq	128(%rax),%rax
	decl	%r10d
	jnz	.Lkey_loop

	movdqa	80(%r11),%xmm7

	.byte	0xf3,0xc3
.cfi_endproc	
.size	_bsaes_key_convert,.-_bsaes_key_convert

.globl	ossl_bsaes_cbc_encrypt
.type	ossl_bsaes_cbc_encrypt,@function
.align	16
ossl_bsaes_cbc_encrypt:
.cfi_startproc	
.byte	243,15,30,250
	cmpl	$0,%r9d
	jne	asm_AES_cbc_encrypt
	cmpq	$128,%rdx
	jb	asm_AES_cbc_encrypt

	movq	%rsp,%rax
.Lcbc_dec_prologue:
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-16
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-24
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-56
	leaq	-72(%rsp),%rsp
.cfi_adjust_cfa_offset	0x48
	movq	%rsp,%rbp
.cfi_def_cfa_register	%rbp
	movl	240(%rcx),%eax
	movq	%rdi,%r12
	movq	%rsi,%r13
	movq	%rdx,%r14
	movq	%rcx,%r15
	movq	%r8,%rbx
	shrq	$4,%r14

	movl	%eax,%edx
	shlq	$7,%rax
	subq	$96,%rax
	subq	%rax,%rsp

	movq	%rsp,%rax
	movq	%r15,%rcx
	movl	%edx,%r10d
	call	_bsaes_key_convert
	pxor	(%rsp),%xmm7
	movdqa	%xmm6,(%rax)
	movdqa	%xmm7,(%rsp)

	movdqu	(%rbx),%xmm14
	subq	$8,%r14
.Lcbc_dec_loop:
	movdqu	0(%r12),%xmm15
	movdqu	16(%r12),%xmm0
	movdqu	32(%r12),%xmm1
	movdqu	48(%r12),%xmm2
	movdqu	64(%r12),%xmm3
	movdqu	80(%r12),%xmm4
	movq	%rsp,%rax
	movdqu	96(%r12),%xmm5
	movl	%edx,%r10d
	movdqu	112(%r12),%xmm6
	movdqa	%xmm14,32(%rbp)

	call	_bsaes_decrypt8

	pxor	32(%rbp),%xmm15
	movdqu	0(%r12),%xmm7
	movdqu	16(%r12),%xmm8
	pxor	%xmm7,%xmm0
	movdqu	32(%r12),%xmm9
	pxor	%xmm8,%xmm5
	movdqu	48(%r12),%xmm10
	pxor	%xmm9,%xmm3
	movdqu	64(%r12),%xmm11
	pxor	%xmm10,%xmm1
	movdqu	80(%r12),%xmm12
	pxor	%xmm11,%xmm6
	movdqu	96(%r12),%xmm13
	pxor	%xmm12,%xmm2
	movdqu	112(%r12),%xmm14
	pxor	%xmm13,%xmm4
	movdqu	%xmm15,0(%r13)
	leaq	128(%r12),%r12
	movdqu	%xmm0,16(%r13)
	movdqu	%xmm5,32(%r13)
	movdqu	%xmm3,48(%r13)
	movdqu	%xmm1,64(%r13)
	movdqu	%xmm6,80(%r13)
	movdqu	%xmm2,96(%r13)
	movdqu	%xmm4,112(%r13)
	leaq	128(%r13),%r13
	subq	$8,%r14
	jnc	.Lcbc_dec_loop

	addq	$8,%r14
	jz	.Lcbc_dec_done

	movdqu	0(%r12),%xmm15
	movq	%rsp,%rax
	movl	%edx,%r10d
	cmpq	$2,%r14
	jb	.Lcbc_dec_one
	movdqu	16(%r12),%xmm0
	je	.Lcbc_dec_two
	movdqu	32(%r12),%xmm1
	cmpq	$4,%r14
	jb	.Lcbc_dec_three
	movdqu	48(%r12),%xmm2
	je	.Lcbc_dec_four
	movdqu	64(%r12),%xmm3
	cmpq	$6,%r14
	jb	.Lcbc_dec_five
	movdqu	80(%r12),%xmm4
	je	.Lcbc_dec_six
	movdqu	96(%r12),%xmm5
	movdqa	%xmm14,32(%rbp)
	call	_bsaes_decrypt8
	pxor	32(%rbp),%xmm15
	movdqu	0(%r12),%xmm7
	movdqu	16(%r12),%xmm8
	pxor	%xmm7,%xmm0
	movdqu	32(%r12),%xmm9
	pxor	%xmm8,%xmm5
	movdqu	48(%r12),%xmm10
	pxor	%xmm9,%xmm3
	movdqu	64(%r12),%xmm11
	pxor	%xmm10,%xmm1
	movdqu	80(%r12),%xmm12
	pxor	%xmm11,%xmm6
	movdqu	96(%r12),%xmm14
	pxor	%xmm12,%xmm2
	movdqu	%xmm15,0(%r13)
	movdqu	%xmm0,16(%r13)
	movdqu	%xmm5,32(%r13)
	movdqu	%xmm3,48(%r13)
	movdqu	%xmm1,64(%r13)
	movdqu	%xmm6,80(%r13)
	movdqu	%xmm2,96(%r13)
	jmp	.Lcbc_dec_done
.align	16
.Lcbc_dec_six:
	movdqa	%xmm14,32(%rbp)
	call	_bsaes_decrypt8
	pxor	32(%rbp),%xmm15
	movdqu	0(%r12),%xmm7
	movdqu	16(%r12),%xmm8
	pxor	%xmm7,%xmm0
	movdqu	32(%r12),%xmm9
	pxor	%xmm8,%xmm5
	movdqu	48(%r12),%xmm10
	pxor	%xmm9,%xmm3
	movdqu	64(%r12),%xmm11
	pxor	%xmm10,%xmm1
	movdqu	80(%r12),%xmm14
	pxor	%xmm11,%xmm6
	movdqu	%xmm15,0(%r13)
	movdqu	%xmm0,16(%r13)
	movdqu	%xmm5,32(%r13)
	movdqu	%xmm3,48(%r13)
	movdqu	%xmm1,64(%r13)
	movdqu	%xmm6,80(%r13)
	jmp	.Lcbc_dec_done
.align	16
.Lcbc_dec_five:
	movdqa	%xmm14,32(%rbp)
	call	_bsaes_decrypt8
	pxor	32(%rbp),%xmm15
	movdqu	0(%r12),%xmm7
	movdqu	16(%r12),%xmm8
	pxor	%xmm7,%xmm0
	movdqu	32(%r12),%xmm9
	pxor	%xmm8,%xmm5
	movdqu	48(%r12),%xmm10
	pxor	%xmm9,%xmm3
	movdqu	64(%r12),%xmm14
	pxor	%xmm10,%xmm1
	movdqu	%xmm15,0(%r13)
	movdqu	%xmm0,16(%r13)
	movdqu	%xmm5,32(%r13)
	movdqu	%xmm3,48(%r13)
	movdqu	%xmm1,64(%r13)
	jmp	.Lcbc_dec_done
.align	16
.Lcbc_dec_four:
	movdqa	%xmm14,32(%rbp)
	call	_bsaes_decrypt8
	pxor	32(%rbp),%xmm15
	movdqu	0(%r12),%xmm7
	movdqu	16(%r12),%xmm8
	pxor	%xmm7,%xmm0
	movdqu	32(%r12),%xmm9
	pxor	%xmm8,%xmm5
	movdqu	48(%r12),%xmm14
	pxor	%xmm9,%xmm3
	movdqu	%xmm15,0(%r13)
	movdqu	%xmm0,16(%r13)
	movdqu	%xmm5,32(%r13)
	movdqu	%xmm3,48(%r13)
	jmp	.Lcbc_dec_done
.align	16
.Lcbc_dec_three:
	movdqa	%xmm14,32(%rbp)
	call	_bsaes_decrypt8
	pxor	32(%rbp),%xmm15
	movdqu	0(%r12),%xmm7
	movdqu	16(%r12),%xmm8
	pxor	%xmm7,%xmm0
	movdqu	32(%r12),%xmm14
	pxor	%xmm8,%xmm5
	movdqu	%xmm15,0(%r13)
	movdqu	%xmm0,16(%r13)
	movdqu	%xmm5,32(%r13)
	jmp	.Lcbc_dec_done
.align	16
.Lcbc_dec_two:
	movdqa	%xmm14,32(%rbp)
	call	_bsaes_decrypt8
	pxor	32(%rbp),%xmm15
	movdqu	0(%r12),%xmm7
	movdqu	16(%r12),%xmm14
	pxor	%xmm7,%xmm0
	movdqu	%xmm15,0(%r13)
	movdqu	%xmm0,16(%r13)
	jmp	.Lcbc_dec_done
.align	16
.Lcbc_dec_one:
	leaq	(%r12),%rdi
	leaq	32(%rbp),%rsi
	leaq	(%r15),%rdx
	call	asm_AES_decrypt
	pxor	32(%rbp),%xmm14
	movdqu	%xmm14,(%r13)
	movdqa	%xmm15,%xmm14

.Lcbc_dec_done:
	movdqu	%xmm14,(%rbx)
	leaq	(%rsp),%rax
	pxor	%xmm0,%xmm0
.Lcbc_dec_bzero:
	movdqa	%xmm0,0(%rax)
	movdqa	%xmm0,16(%rax)
	leaq	32(%rax),%rax
	cmpq	%rax,%rbp
	ja	.Lcbc_dec_bzero

	leaq	120(%rbp),%rax
.cfi_def_cfa	%rax,8
	movq	-48(%rax),%r15
.cfi_restore	%r15
	movq	-40(%rax),%r14
.cfi_restore	%r14
	movq	-32(%rax),%r13
.cfi_restore	%r13
	movq	-24(%rax),%r12
.cfi_restore	%r12
	movq	-16(%rax),%rbx
.cfi_restore	%rbx
	movq	-8(%rax),%rbp
.cfi_restore	%rbp
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lcbc_dec_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	ossl_bsaes_cbc_encrypt,.-ossl_bsaes_cbc_encrypt

.globl	ossl_bsaes_ctr32_encrypt_blocks
.type	ossl_bsaes_ctr32_encrypt_blocks,@function
.align	16
ossl_bsaes_ctr32_encrypt_blocks:
.cfi_startproc	
.byte	243,15,30,250
	movq	%rsp,%rax
.Lctr_enc_prologue:
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-16
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-24
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-56
	leaq	-72(%rsp),%rsp
.cfi_adjust_cfa_offset	0x48
	movq	%rsp,%rbp
.cfi_def_cfa_register	%rbp
	movdqu	(%r8),%xmm0
	movl	240(%rcx),%eax
	movq	%rdi,%r12
	movq	%rsi,%r13
	movq	%rdx,%r14
	movq	%rcx,%r15
	movdqa	%xmm0,32(%rbp)
	cmpq	$8,%rdx
	jb	.Lctr_enc_short

	movl	%eax,%ebx
	shlq	$7,%rax
	subq	$96,%rax
	subq	%rax,%rsp

	movq	%rsp,%rax
	movq	%r15,%rcx
	movl	%ebx,%r10d
	call	_bsaes_key_convert
	pxor	%xmm6,%xmm7
	movdqa	%xmm7,(%rax)

	movdqa	(%rsp),%xmm8
	leaq	.LADD1(%rip),%r11
	movdqa	32(%rbp),%xmm15
	movdqa	-32(%r11),%xmm7
.byte	102,68,15,56,0,199
.byte	102,68,15,56,0,255
	movdqa	%xmm8,(%rsp)
	jmp	.Lctr_enc_loop
.align	16
.Lctr_enc_loop:
	movdqa	%xmm15,32(%rbp)
	movdqa	%xmm15,%xmm0
	movdqa	%xmm15,%xmm1
	paddd	0(%r11),%xmm0
	movdqa	%xmm15,%xmm2
	paddd	16(%r11),%xmm1
	movdqa	%xmm15,%xmm3
	paddd	32(%r11),%xmm2
	movdqa	%xmm15,%xmm4
	paddd	48(%r11),%xmm3
	movdqa	%xmm15,%xmm5
	paddd	64(%r11),%xmm4
	movdqa	%xmm15,%xmm6
	paddd	80(%r11),%xmm5
	paddd	96(%r11),%xmm6



	movdqa	(%rsp),%xmm8
	leaq	16(%rsp),%rax
	movdqa	-16(%r11),%xmm7
	pxor	%xmm8,%xmm15
	pxor	%xmm8,%xmm0
	pxor	%xmm8,%xmm1
	pxor	%xmm8,%xmm2
.byte	102,68,15,56,0,255
.byte	102,15,56,0,199
	pxor	%xmm8,%xmm3
	pxor	%xmm8,%xmm4
.byte	102,15,56,0,207
.byte	102,15,56,0,215
	pxor	%xmm8,%xmm5
	pxor	%xmm8,%xmm6
.byte	102,15,56,0,223
.byte	102,15,56,0,231
.byte	102,15,56,0,239
.byte	102,15,56,0,247
	leaq	.LBS0(%rip),%r11
	movl	%ebx,%r10d

	call	_bsaes_encrypt8_bitslice

	subq	$8,%r14
	jc	.Lctr_enc_loop_done

	movdqu	0(%r12),%xmm7
	movdqu	16(%r12),%xmm8
	movdqu	32(%r12),%xmm9
	movdqu	48(%r12),%xmm10
	movdqu	64(%r12),%xmm11
	movdqu	80(%r12),%xmm12
	movdqu	96(%r12),%xmm13
	movdqu	112(%r12),%xmm14
	leaq	128(%r12),%r12
	pxor	%xmm15,%xmm7
	movdqa	32(%rbp),%xmm15
	pxor	%xmm8,%xmm0
	movdqu	%xmm7,0(%r13)
	pxor	%xmm9,%xmm3
	movdqu	%xmm0,16(%r13)
	pxor	%xmm10,%xmm5
	movdqu	%xmm3,32(%r13)
	pxor	%xmm11,%xmm2
	movdqu	%xmm5,48(%r13)
	pxor	%xmm12,%xmm6
	movdqu	%xmm2,64(%r13)
	pxor	%xmm13,%xmm1
	movdqu	%xmm6,80(%r13)
	pxor	%xmm14,%xmm4
	movdqu	%xmm1,96(%r13)
	leaq	.LADD1(%rip),%r11
	movdqu	%xmm4,112(%r13)
	leaq	128(%r13),%r13
	paddd	112(%r11),%xmm15
	jnz	.Lctr_enc_loop

	jmp	.Lctr_enc_done
.align	16
.Lctr_enc_loop_done:
	addq	$8,%r14
	movdqu	0(%r12),%xmm7
	pxor	%xmm7,%xmm15
	movdqu	%xmm15,0(%r13)
	cmpq	$2,%r14
	jb	.Lctr_enc_done
	movdqu	16(%r12),%xmm8
	pxor	%xmm8,%xmm0
	movdqu	%xmm0,16(%r13)
	je	.Lctr_enc_done
	movdqu	32(%r12),%xmm9
	pxor	%xmm9,%xmm3
	movdqu	%xmm3,32(%r13)
	cmpq	$4,%r14
	jb	.Lctr_enc_done
	movdqu	48(%r12),%xmm10
	pxor	%xmm10,%xmm5
	movdqu	%xmm5,48(%r13)
	je	.Lctr_enc_done
	movdqu	64(%r12),%xmm11
	pxor	%xmm11,%xmm2
	movdqu	%xmm2,64(%r13)
	cmpq	$6,%r14
	jb	.Lctr_enc_done
	movdqu	80(%r12),%xmm12
	pxor	%xmm12,%xmm6
	movdqu	%xmm6,80(%r13)
	je	.Lctr_enc_done
	movdqu	96(%r12),%xmm13
	pxor	%xmm13,%xmm1
	movdqu	%xmm1,96(%r13)
	jmp	.Lctr_enc_done

.align	16
.Lctr_enc_short:
	leaq	32(%rbp),%rdi
	leaq	48(%rbp),%rsi
	leaq	(%r15),%rdx
	call	asm_AES_encrypt
	movdqu	(%r12),%xmm0
	leaq	16(%r12),%r12
	movl	44(%rbp),%eax
	bswapl	%eax
	pxor	48(%rbp),%xmm0
	incl	%eax
	movdqu	%xmm0,(%r13)
	bswapl	%eax
	leaq	16(%r13),%r13
	movl	%eax,44(%rsp)
	decq	%r14
	jnz	.Lctr_enc_short

.Lctr_enc_done:
	leaq	(%rsp),%rax
	pxor	%xmm0,%xmm0
.Lctr_enc_bzero:
	movdqa	%xmm0,0(%rax)
	movdqa	%xmm0,16(%rax)
	leaq	32(%rax),%rax
	cmpq	%rax,%rbp
	ja	.Lctr_enc_bzero

	leaq	120(%rbp),%rax
.cfi_def_cfa	%rax,8
	movq	-48(%rax),%r15
.cfi_restore	%r15
	movq	-40(%rax),%r14
.cfi_restore	%r14
	movq	-32(%rax),%r13
.cfi_restore	%r13
	movq	-24(%rax),%r12
.cfi_restore	%r12
	movq	-16(%rax),%rbx
.cfi_restore	%rbx
	movq	-8(%rax),%rbp
.cfi_restore	%rbp
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lctr_enc_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	ossl_bsaes_ctr32_encrypt_blocks,.-ossl_bsaes_ctr32_encrypt_blocks
.globl	ossl_bsaes_xts_encrypt
.type	ossl_bsaes_xts_encrypt,@function
.align	16
ossl_bsaes_xts_encrypt:
.cfi_startproc	
	movq	%rsp,%rax
.Lxts_enc_prologue:
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-16
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-24
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-56
	leaq	-72(%rsp),%rsp
.cfi_adjust_cfa_offset	0x48
	movq	%rsp,%rbp
.cfi_def_cfa_register	%rbp
	movq	%rdi,%r12
	movq	%rsi,%r13
	movq	%rdx,%r14
	movq	%rcx,%r15

	leaq	(%r9),%rdi
	leaq	32(%rbp),%rsi
	leaq	(%r8),%rdx
	call	asm_AES_encrypt

	movl	240(%r15),%eax
	movq	%r14,%rbx

	movl	%eax,%edx
	shlq	$7,%rax
	subq	$96,%rax
	subq	%rax,%rsp

	movq	%rsp,%rax
	movq	%r15,%rcx
	movl	%edx,%r10d
	call	_bsaes_key_convert
	pxor	%xmm6,%xmm7
	movdqa	%xmm7,(%rax)

	andq	$-16,%r14
	subq	$0x80,%rsp
	movdqa	32(%rbp),%xmm6

	pxor	%xmm14,%xmm14
	movdqa	.Lxts_magic(%rip),%xmm12
	pcmpgtd	%xmm6,%xmm14

	subq	$0x80,%r14
	jc	.Lxts_enc_short
	jmp	.Lxts_enc_loop

.align	16
.Lxts_enc_loop:
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm15
	movdqa	%xmm6,0(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm0
	movdqa	%xmm6,16(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	0(%r12),%xmm7
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm1
	movdqa	%xmm6,32(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	16(%r12),%xmm8
	pxor	%xmm7,%xmm15
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm2
	movdqa	%xmm6,48(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	32(%r12),%xmm9
	pxor	%xmm8,%xmm0
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm3
	movdqa	%xmm6,64(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	48(%r12),%xmm10
	pxor	%xmm9,%xmm1
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm4
	movdqa	%xmm6,80(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	64(%r12),%xmm11
	pxor	%xmm10,%xmm2
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm5
	movdqa	%xmm6,96(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	80(%r12),%xmm12
	pxor	%xmm11,%xmm3
	movdqu	96(%r12),%xmm13
	pxor	%xmm12,%xmm4
	movdqu	112(%r12),%xmm14
	leaq	128(%r12),%r12
	movdqa	%xmm6,112(%rsp)
	pxor	%xmm13,%xmm5
	leaq	128(%rsp),%rax
	pxor	%xmm14,%xmm6
	movl	%edx,%r10d

	call	_bsaes_encrypt8

	pxor	0(%rsp),%xmm15
	pxor	16(%rsp),%xmm0
	movdqu	%xmm15,0(%r13)
	pxor	32(%rsp),%xmm3
	movdqu	%xmm0,16(%r13)
	pxor	48(%rsp),%xmm5
	movdqu	%xmm3,32(%r13)
	pxor	64(%rsp),%xmm2
	movdqu	%xmm5,48(%r13)
	pxor	80(%rsp),%xmm6
	movdqu	%xmm2,64(%r13)
	pxor	96(%rsp),%xmm1
	movdqu	%xmm6,80(%r13)
	pxor	112(%rsp),%xmm4
	movdqu	%xmm1,96(%r13)
	movdqu	%xmm4,112(%r13)
	leaq	128(%r13),%r13

	movdqa	112(%rsp),%xmm6
	pxor	%xmm14,%xmm14
	movdqa	.Lxts_magic(%rip),%xmm12
	pcmpgtd	%xmm6,%xmm14
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6

	subq	$0x80,%r14
	jnc	.Lxts_enc_loop

.Lxts_enc_short:
	addq	$0x80,%r14
	jz	.Lxts_enc_done
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm15
	movdqa	%xmm6,0(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm0
	movdqa	%xmm6,16(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	0(%r12),%xmm7
	cmpq	$16,%r14
	je	.Lxts_enc_1
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm1
	movdqa	%xmm6,32(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	16(%r12),%xmm8
	cmpq	$32,%r14
	je	.Lxts_enc_2
	pxor	%xmm7,%xmm15
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm2
	movdqa	%xmm6,48(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	32(%r12),%xmm9
	cmpq	$48,%r14
	je	.Lxts_enc_3
	pxor	%xmm8,%xmm0
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm3
	movdqa	%xmm6,64(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	48(%r12),%xmm10
	cmpq	$64,%r14
	je	.Lxts_enc_4
	pxor	%xmm9,%xmm1
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm4
	movdqa	%xmm6,80(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	64(%r12),%xmm11
	cmpq	$80,%r14
	je	.Lxts_enc_5
	pxor	%xmm10,%xmm2
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm5
	movdqa	%xmm6,96(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	80(%r12),%xmm12
	cmpq	$96,%r14
	je	.Lxts_enc_6
	pxor	%xmm11,%xmm3
	movdqu	96(%r12),%xmm13
	pxor	%xmm12,%xmm4
	movdqa	%xmm6,112(%rsp)
	leaq	112(%r12),%r12
	pxor	%xmm13,%xmm5
	leaq	128(%rsp),%rax
	movl	%edx,%r10d

	call	_bsaes_encrypt8

	pxor	0(%rsp),%xmm15
	pxor	16(%rsp),%xmm0
	movdqu	%xmm15,0(%r13)
	pxor	32(%rsp),%xmm3
	movdqu	%xmm0,16(%r13)
	pxor	48(%rsp),%xmm5
	movdqu	%xmm3,32(%r13)
	pxor	64(%rsp),%xmm2
	movdqu	%xmm5,48(%r13)
	pxor	80(%rsp),%xmm6
	movdqu	%xmm2,64(%r13)
	pxor	96(%rsp),%xmm1
	movdqu	%xmm6,80(%r13)
	movdqu	%xmm1,96(%r13)
	leaq	112(%r13),%r13

	movdqa	112(%rsp),%xmm6
	jmp	.Lxts_enc_done
.align	16
.Lxts_enc_6:
	pxor	%xmm11,%xmm3
	leaq	96(%r12),%r12
	pxor	%xmm12,%xmm4
	leaq	128(%rsp),%rax
	movl	%edx,%r10d

	call	_bsaes_encrypt8

	pxor	0(%rsp),%xmm15
	pxor	16(%rsp),%xmm0
	movdqu	%xmm15,0(%r13)
	pxor	32(%rsp),%xmm3
	movdqu	%xmm0,16(%r13)
	pxor	48(%rsp),%xmm5
	movdqu	%xmm3,32(%r13)
	pxor	64(%rsp),%xmm2
	movdqu	%xmm5,48(%r13)
	pxor	80(%rsp),%xmm6
	movdqu	%xmm2,64(%r13)
	movdqu	%xmm6,80(%r13)
	leaq	96(%r13),%r13

	movdqa	96(%rsp),%xmm6
	jmp	.Lxts_enc_done
.align	16
.Lxts_enc_5:
	pxor	%xmm10,%xmm2
	leaq	80(%r12),%r12
	pxor	%xmm11,%xmm3
	leaq	128(%rsp),%rax
	movl	%edx,%r10d

	call	_bsaes_encrypt8

	pxor	0(%rsp),%xmm15
	pxor	16(%rsp),%xmm0
	movdqu	%xmm15,0(%r13)
	pxor	32(%rsp),%xmm3
	movdqu	%xmm0,16(%r13)
	pxor	48(%rsp),%xmm5
	movdqu	%xmm3,32(%r13)
	pxor	64(%rsp),%xmm2
	movdqu	%xmm5,48(%r13)
	movdqu	%xmm2,64(%r13)
	leaq	80(%r13),%r13

	movdqa	80(%rsp),%xmm6
	jmp	.Lxts_enc_done
.align	16
.Lxts_enc_4:
	pxor	%xmm9,%xmm1
	leaq	64(%r12),%r12
	pxor	%xmm10,%xmm2
	leaq	128(%rsp),%rax
	movl	%edx,%r10d

	call	_bsaes_encrypt8

	pxor	0(%rsp),%xmm15
	pxor	16(%rsp),%xmm0
	movdqu	%xmm15,0(%r13)
	pxor	32(%rsp),%xmm3
	movdqu	%xmm0,16(%r13)
	pxor	48(%rsp),%xmm5
	movdqu	%xmm3,32(%r13)
	movdqu	%xmm5,48(%r13)
	leaq	64(%r13),%r13

	movdqa	64(%rsp),%xmm6
	jmp	.Lxts_enc_done
.align	16
.Lxts_enc_3:
	pxor	%xmm8,%xmm0
	leaq	48(%r12),%r12
	pxor	%xmm9,%xmm1
	leaq	128(%rsp),%rax
	movl	%edx,%r10d

	call	_bsaes_encrypt8

	pxor	0(%rsp),%xmm15
	pxor	16(%rsp),%xmm0
	movdqu	%xmm15,0(%r13)
	pxor	32(%rsp),%xmm3
	movdqu	%xmm0,16(%r13)
	movdqu	%xmm3,32(%r13)
	leaq	48(%r13),%r13

	movdqa	48(%rsp),%xmm6
	jmp	.Lxts_enc_done
.align	16
.Lxts_enc_2:
	pxor	%xmm7,%xmm15
	leaq	32(%r12),%r12
	pxor	%xmm8,%xmm0
	leaq	128(%rsp),%rax
	movl	%edx,%r10d

	call	_bsaes_encrypt8

	pxor	0(%rsp),%xmm15
	pxor	16(%rsp),%xmm0
	movdqu	%xmm15,0(%r13)
	movdqu	%xmm0,16(%r13)
	leaq	32(%r13),%r13

	movdqa	32(%rsp),%xmm6
	jmp	.Lxts_enc_done
.align	16
.Lxts_enc_1:
	pxor	%xmm15,%xmm7
	leaq	16(%r12),%r12
	movdqa	%xmm7,32(%rbp)
	leaq	32(%rbp),%rdi
	leaq	32(%rbp),%rsi
	leaq	(%r15),%rdx
	call	asm_AES_encrypt
	pxor	32(%rbp),%xmm15





	movdqu	%xmm15,0(%r13)
	leaq	16(%r13),%r13

	movdqa	16(%rsp),%xmm6

.Lxts_enc_done:
	andl	$15,%ebx
	jz	.Lxts_enc_ret
	movq	%r13,%rdx

.Lxts_enc_steal:
	movzbl	(%r12),%eax
	movzbl	-16(%rdx),%ecx
	leaq	1(%r12),%r12
	movb	%al,-16(%rdx)
	movb	%cl,0(%rdx)
	leaq	1(%rdx),%rdx
	subl	$1,%ebx
	jnz	.Lxts_enc_steal

	movdqu	-16(%r13),%xmm15
	leaq	32(%rbp),%rdi
	pxor	%xmm6,%xmm15
	leaq	32(%rbp),%rsi
	movdqa	%xmm15,32(%rbp)
	leaq	(%r15),%rdx
	call	asm_AES_encrypt
	pxor	32(%rbp),%xmm6
	movdqu	%xmm6,-16(%r13)

.Lxts_enc_ret:
	leaq	(%rsp),%rax
	pxor	%xmm0,%xmm0
.Lxts_enc_bzero:
	movdqa	%xmm0,0(%rax)
	movdqa	%xmm0,16(%rax)
	leaq	32(%rax),%rax
	cmpq	%rax,%rbp
	ja	.Lxts_enc_bzero

	leaq	120(%rbp),%rax
.cfi_def_cfa	%rax,8
	movq	-48(%rax),%r15
.cfi_restore	%r15
	movq	-40(%rax),%r14
.cfi_restore	%r14
	movq	-32(%rax),%r13
.cfi_restore	%r13
	movq	-24(%rax),%r12
.cfi_restore	%r12
	movq	-16(%rax),%rbx
.cfi_restore	%rbx
	movq	-8(%rax),%rbp
.cfi_restore	%rbp
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lxts_enc_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	ossl_bsaes_xts_encrypt,.-ossl_bsaes_xts_encrypt

.globl	ossl_bsaes_xts_decrypt
.type	ossl_bsaes_xts_decrypt,@function
.align	16
ossl_bsaes_xts_decrypt:
.cfi_startproc	
	movq	%rsp,%rax
.Lxts_dec_prologue:
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-16
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-24
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-56
	leaq	-72(%rsp),%rsp
.cfi_adjust_cfa_offset	0x48
	movq	%rsp,%rbp
	movq	%rdi,%r12
	movq	%rsi,%r13
	movq	%rdx,%r14
	movq	%rcx,%r15

	leaq	(%r9),%rdi
	leaq	32(%rbp),%rsi
	leaq	(%r8),%rdx
	call	asm_AES_encrypt

	movl	240(%r15),%eax
	movq	%r14,%rbx

	movl	%eax,%edx
	shlq	$7,%rax
	subq	$96,%rax
	subq	%rax,%rsp

	movq	%rsp,%rax
	movq	%r15,%rcx
	movl	%edx,%r10d
	call	_bsaes_key_convert
	pxor	(%rsp),%xmm7
	movdqa	%xmm6,(%rax)
	movdqa	%xmm7,(%rsp)

	xorl	%eax,%eax
	andq	$-16,%r14
	testl	$15,%ebx
	setnz	%al
	shlq	$4,%rax
	subq	%rax,%r14

	subq	$0x80,%rsp
	movdqa	32(%rbp),%xmm6

	pxor	%xmm14,%xmm14
	movdqa	.Lxts_magic(%rip),%xmm12
	pcmpgtd	%xmm6,%xmm14

	subq	$0x80,%r14
	jc	.Lxts_dec_short
	jmp	.Lxts_dec_loop

.align	16
.Lxts_dec_loop:
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm15
	movdqa	%xmm6,0(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm0
	movdqa	%xmm6,16(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	0(%r12),%xmm7
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm1
	movdqa	%xmm6,32(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	16(%r12),%xmm8
	pxor	%xmm7,%xmm15
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm2
	movdqa	%xmm6,48(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	32(%r12),%xmm9
	pxor	%xmm8,%xmm0
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm3
	movdqa	%xmm6,64(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	48(%r12),%xmm10
	pxor	%xmm9,%xmm1
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm4
	movdqa	%xmm6,80(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	64(%r12),%xmm11
	pxor	%xmm10,%xmm2
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm5
	movdqa	%xmm6,96(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	80(%r12),%xmm12
	pxor	%xmm11,%xmm3
	movdqu	96(%r12),%xmm13
	pxor	%xmm12,%xmm4
	movdqu	112(%r12),%xmm14
	leaq	128(%r12),%r12
	movdqa	%xmm6,112(%rsp)
	pxor	%xmm13,%xmm5
	leaq	128(%rsp),%rax
	pxor	%xmm14,%xmm6
	movl	%edx,%r10d

	call	_bsaes_decrypt8

	pxor	0(%rsp),%xmm15
	pxor	16(%rsp),%xmm0
	movdqu	%xmm15,0(%r13)
	pxor	32(%rsp),%xmm5
	movdqu	%xmm0,16(%r13)
	pxor	48(%rsp),%xmm3
	movdqu	%xmm5,32(%r13)
	pxor	64(%rsp),%xmm1
	movdqu	%xmm3,48(%r13)
	pxor	80(%rsp),%xmm6
	movdqu	%xmm1,64(%r13)
	pxor	96(%rsp),%xmm2
	movdqu	%xmm6,80(%r13)
	pxor	112(%rsp),%xmm4
	movdqu	%xmm2,96(%r13)
	movdqu	%xmm4,112(%r13)
	leaq	128(%r13),%r13

	movdqa	112(%rsp),%xmm6
	pxor	%xmm14,%xmm14
	movdqa	.Lxts_magic(%rip),%xmm12
	pcmpgtd	%xmm6,%xmm14
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6

	subq	$0x80,%r14
	jnc	.Lxts_dec_loop

.Lxts_dec_short:
	addq	$0x80,%r14
	jz	.Lxts_dec_done
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm15
	movdqa	%xmm6,0(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm0
	movdqa	%xmm6,16(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	0(%r12),%xmm7
	cmpq	$16,%r14
	je	.Lxts_dec_1
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm1
	movdqa	%xmm6,32(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	16(%r12),%xmm8
	cmpq	$32,%r14
	je	.Lxts_dec_2
	pxor	%xmm7,%xmm15
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm2
	movdqa	%xmm6,48(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	32(%r12),%xmm9
	cmpq	$48,%r14
	je	.Lxts_dec_3
	pxor	%xmm8,%xmm0
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm3
	movdqa	%xmm6,64(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	48(%r12),%xmm10
	cmpq	$64,%r14
	je	.Lxts_dec_4
	pxor	%xmm9,%xmm1
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm4
	movdqa	%xmm6,80(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	64(%r12),%xmm11
	cmpq	$80,%r14
	je	.Lxts_dec_5
	pxor	%xmm10,%xmm2
	pshufd	$0x13,%xmm14,%xmm13
	pxor	%xmm14,%xmm14
	movdqa	%xmm6,%xmm5
	movdqa	%xmm6,96(%rsp)
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	pcmpgtd	%xmm6,%xmm14
	pxor	%xmm13,%xmm6
	movdqu	80(%r12),%xmm12
	cmpq	$96,%r14
	je	.Lxts_dec_6
	pxor	%xmm11,%xmm3
	movdqu	96(%r12),%xmm13
	pxor	%xmm12,%xmm4
	movdqa	%xmm6,112(%rsp)
	leaq	112(%r12),%r12
	pxor	%xmm13,%xmm5
	leaq	128(%rsp),%rax
	movl	%edx,%r10d

	call	_bsaes_decrypt8

	pxor	0(%rsp),%xmm15
	pxor	16(%rsp),%xmm0
	movdqu	%xmm15,0(%r13)
	pxor	32(%rsp),%xmm5
	movdqu	%xmm0,16(%r13)
	pxor	48(%rsp),%xmm3
	movdqu	%xmm5,32(%r13)
	pxor	64(%rsp),%xmm1
	movdqu	%xmm3,48(%r13)
	pxor	80(%rsp),%xmm6
	movdqu	%xmm1,64(%r13)
	pxor	96(%rsp),%xmm2
	movdqu	%xmm6,80(%r13)
	movdqu	%xmm2,96(%r13)
	leaq	112(%r13),%r13

	movdqa	112(%rsp),%xmm6
	jmp	.Lxts_dec_done
.align	16
.Lxts_dec_6:
	pxor	%xmm11,%xmm3
	leaq	96(%r12),%r12
	pxor	%xmm12,%xmm4
	leaq	128(%rsp),%rax
	movl	%edx,%r10d

	call	_bsaes_decrypt8

	pxor	0(%rsp),%xmm15
	pxor	16(%rsp),%xmm0
	movdqu	%xmm15,0(%r13)
	pxor	32(%rsp),%xmm5
	movdqu	%xmm0,16(%r13)
	pxor	48(%rsp),%xmm3
	movdqu	%xmm5,32(%r13)
	pxor	64(%rsp),%xmm1
	movdqu	%xmm3,48(%r13)
	pxor	80(%rsp),%xmm6
	movdqu	%xmm1,64(%r13)
	movdqu	%xmm6,80(%r13)
	leaq	96(%r13),%r13

	movdqa	96(%rsp),%xmm6
	jmp	.Lxts_dec_done
.align	16
.Lxts_dec_5:
	pxor	%xmm10,%xmm2
	leaq	80(%r12),%r12
	pxor	%xmm11,%xmm3
	leaq	128(%rsp),%rax
	movl	%edx,%r10d

	call	_bsaes_decrypt8

	pxor	0(%rsp),%xmm15
	pxor	16(%rsp),%xmm0
	movdqu	%xmm15,0(%r13)
	pxor	32(%rsp),%xmm5
	movdqu	%xmm0,16(%r13)
	pxor	48(%rsp),%xmm3
	movdqu	%xmm5,32(%r13)
	pxor	64(%rsp),%xmm1
	movdqu	%xmm3,48(%r13)
	movdqu	%xmm1,64(%r13)
	leaq	80(%r13),%r13

	movdqa	80(%rsp),%xmm6
	jmp	.Lxts_dec_done
.align	16
.Lxts_dec_4:
	pxor	%xmm9,%xmm1
	leaq	64(%r12),%r12
	pxor	%xmm10,%xmm2
	leaq	128(%rsp),%rax
	movl	%edx,%r10d

	call	_bsaes_decrypt8

	pxor	0(%rsp),%xmm15
	pxor	16(%rsp),%xmm0
	movdqu	%xmm15,0(%r13)
	pxor	32(%rsp),%xmm5
	movdqu	%xmm0,16(%r13)
	pxor	48(%rsp),%xmm3
	movdqu	%xmm5,32(%r13)
	movdqu	%xmm3,48(%r13)
	leaq	64(%r13),%r13

	movdqa	64(%rsp),%xmm6
	jmp	.Lxts_dec_done
.align	16
.Lxts_dec_3:
	pxor	%xmm8,%xmm0
	leaq	48(%r12),%r12
	pxor	%xmm9,%xmm1
	leaq	128(%rsp),%rax
	movl	%edx,%r10d

	call	_bsaes_decrypt8

	pxor	0(%rsp),%xmm15
	pxor	16(%rsp),%xmm0
	movdqu	%xmm15,0(%r13)
	pxor	32(%rsp),%xmm5
	movdqu	%xmm0,16(%r13)
	movdqu	%xmm5,32(%r13)
	leaq	48(%r13),%r13

	movdqa	48(%rsp),%xmm6
	jmp	.Lxts_dec_done
.align	16
.Lxts_dec_2:
	pxor	%xmm7,%xmm15
	leaq	32(%r12),%r12
	pxor	%xmm8,%xmm0
	leaq	128(%rsp),%rax
	movl	%edx,%r10d

	call	_bsaes_decrypt8

	pxor	0(%rsp),%xmm15
	pxor	16(%rsp),%xmm0
	movdqu	%xmm15,0(%r13)
	movdqu	%xmm0,16(%r13)
	leaq	32(%r13),%r13

	movdqa	32(%rsp),%xmm6
	jmp	.Lxts_dec_done
.align	16
.Lxts_dec_1:
	pxor	%xmm15,%xmm7
	leaq	16(%r12),%r12
	movdqa	%xmm7,32(%rbp)
	leaq	32(%rbp),%rdi
	leaq	32(%rbp),%rsi
	leaq	(%r15),%rdx
	call	asm_AES_decrypt
	pxor	32(%rbp),%xmm15





	movdqu	%xmm15,0(%r13)
	leaq	16(%r13),%r13

	movdqa	16(%rsp),%xmm6

.Lxts_dec_done:
	andl	$15,%ebx
	jz	.Lxts_dec_ret

	pxor	%xmm14,%xmm14
	movdqa	.Lxts_magic(%rip),%xmm12
	pcmpgtd	%xmm6,%xmm14
	pshufd	$0x13,%xmm14,%xmm13
	movdqa	%xmm6,%xmm5
	paddq	%xmm6,%xmm6
	pand	%xmm12,%xmm13
	movdqu	(%r12),%xmm15
	pxor	%xmm13,%xmm6

	leaq	32(%rbp),%rdi
	pxor	%xmm6,%xmm15
	leaq	32(%rbp),%rsi
	movdqa	%xmm15,32(%rbp)
	leaq	(%r15),%rdx
	call	asm_AES_decrypt
	pxor	32(%rbp),%xmm6
	movq	%r13,%rdx
	movdqu	%xmm6,(%r13)

.Lxts_dec_steal:
	movzbl	16(%r12),%eax
	movzbl	(%rdx),%ecx
	leaq	1(%r12),%r12
	movb	%al,(%rdx)
	movb	%cl,16(%rdx)
	leaq	1(%rdx),%rdx
	subl	$1,%ebx
	jnz	.Lxts_dec_steal

	movdqu	(%r13),%xmm15
	leaq	32(%rbp),%rdi
	pxor	%xmm5,%xmm15
	leaq	32(%rbp),%rsi
	movdqa	%xmm15,32(%rbp)
	leaq	(%r15),%rdx
	call	asm_AES_decrypt
	pxor	32(%rbp),%xmm5
	movdqu	%xmm5,(%r13)

.Lxts_dec_ret:
	leaq	(%rsp),%rax
	pxor	%xmm0,%xmm0
.Lxts_dec_bzero:
	movdqa	%xmm0,0(%rax)
	movdqa	%xmm0,16(%rax)
	leaq	32(%rax),%rax
	cmpq	%rax,%rbp
	ja	.Lxts_dec_bzero

	leaq	120(%rbp),%rax
.cfi_def_cfa	%rax,8
	movq	-48(%rax),%r15
.cfi_restore	%r15
	movq	-40(%rax),%r14
.cfi_restore	%r14
	movq	-32(%rax),%r13
.cfi_restore	%r13
	movq	-24(%rax),%r12
.cfi_restore	%r12
	movq	-16(%rax),%rbx
.cfi_restore	%rbx
	movq	-8(%rax),%rbp
.cfi_restore	%rbp
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lxts_dec_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	ossl_bsaes_xts_decrypt,.-ossl_bsaes_xts_decrypt
.type	_bsaes_const,@object
.align	64
_bsaes_const:
.LM0ISR:
.quad	0x0a0e0206070b0f03, 0x0004080c0d010509
.LISRM0:
.quad	0x01040b0e0205080f, 0x0306090c00070a0d
.LISR:
.quad	0x0504070602010003, 0x0f0e0d0c080b0a09
.LBS0:
.quad	0x5555555555555555, 0x5555555555555555
.LBS1:
.quad	0x3333333333333333, 0x3333333333333333
.LBS2:
.quad	0x0f0f0f0f0f0f0f0f, 0x0f0f0f0f0f0f0f0f
.LSR:
.quad	0x0504070600030201, 0x0f0e0d0c0a09080b
.LSRM0:
.quad	0x0304090e00050a0f, 0x01060b0c0207080d
.LM0SR:
.quad	0x0a0e02060f03070b, 0x0004080c05090d01
.LSWPUP:
.quad	0x0706050403020100, 0x0c0d0e0f0b0a0908
.LSWPUPM0SR:
.quad	0x0a0d02060c03070b, 0x0004080f05090e01
.LADD1:
.quad	0x0000000000000000, 0x0000000100000000
.LADD2:
.quad	0x0000000000000000, 0x0000000200000000
.LADD3:
.quad	0x0000000000000000, 0x0000000300000000
.LADD4:
.quad	0x0000000000000000, 0x0000000400000000
.LADD5:
.quad	0x0000000000000000, 0x0000000500000000
.LADD6:
.quad	0x0000000000000000, 0x0000000600000000
.LADD7:
.quad	0x0000000000000000, 0x0000000700000000
.LADD8:
.quad	0x0000000000000000, 0x0000000800000000
.Lxts_magic:
.long	0x87,0,1,0
.Lmasks:
.quad	0x0101010101010101, 0x0101010101010101
.quad	0x0202020202020202, 0x0202020202020202
.quad	0x0404040404040404, 0x0404040404040404
.quad	0x0808080808080808, 0x0808080808080808
.LM0:
.quad	0x02060a0e03070b0f, 0x0004080c0105090d
.L63:
.quad	0x6363636363636363, 0x6363636363636363
.byte	66,105,116,45,115,108,105,99,101,100,32,65,69,83,32,102,111,114,32,120,56,54,95,54,52,47,83,83,83,69,51,44,32,69,109,105,108,105,97,32,75,195,164,115,112,101,114,44,32,80,101,116,101,114,32,83,99,104,119,97,98,101,44,32,65,110,100,121,32,80,111,108,121,97,107,111,118,0
.align	64
.size	_bsaes_const,.-_bsaes_const
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                                                                                                                                                                                                                                                                      node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/aes/vpaes-x86_64.s                    0000664 0000000 0000000 00000034157 14746647661 0026753 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	
















.type	_vpaes_encrypt_core,@function
.align	16
_vpaes_encrypt_core:
.cfi_startproc	
	movq	%rdx,%r9
	movq	$16,%r11
	movl	240(%rdx),%eax
	movdqa	%xmm9,%xmm1
	movdqa	.Lk_ipt(%rip),%xmm2
	pandn	%xmm0,%xmm1
	movdqu	(%r9),%xmm5
	psrld	$4,%xmm1
	pand	%xmm9,%xmm0
.byte	102,15,56,0,208
	movdqa	.Lk_ipt+16(%rip),%xmm0
.byte	102,15,56,0,193
	pxor	%xmm5,%xmm2
	addq	$16,%r9
	pxor	%xmm2,%xmm0
	leaq	.Lk_mc_backward(%rip),%r10
	jmp	.Lenc_entry

.align	16
.Lenc_loop:

	movdqa	%xmm13,%xmm4
	movdqa	%xmm12,%xmm0
.byte	102,15,56,0,226
.byte	102,15,56,0,195
	pxor	%xmm5,%xmm4
	movdqa	%xmm15,%xmm5
	pxor	%xmm4,%xmm0
	movdqa	-64(%r11,%r10,1),%xmm1
.byte	102,15,56,0,234
	movdqa	(%r11,%r10,1),%xmm4
	movdqa	%xmm14,%xmm2
.byte	102,15,56,0,211
	movdqa	%xmm0,%xmm3
	pxor	%xmm5,%xmm2
.byte	102,15,56,0,193
	addq	$16,%r9
	pxor	%xmm2,%xmm0
.byte	102,15,56,0,220
	addq	$16,%r11
	pxor	%xmm0,%xmm3
.byte	102,15,56,0,193
	andq	$0x30,%r11
	subq	$1,%rax
	pxor	%xmm3,%xmm0

.Lenc_entry:

	movdqa	%xmm9,%xmm1
	movdqa	%xmm11,%xmm5
	pandn	%xmm0,%xmm1
	psrld	$4,%xmm1
	pand	%xmm9,%xmm0
.byte	102,15,56,0,232
	movdqa	%xmm10,%xmm3
	pxor	%xmm1,%xmm0
.byte	102,15,56,0,217
	movdqa	%xmm10,%xmm4
	pxor	%xmm5,%xmm3
.byte	102,15,56,0,224
	movdqa	%xmm10,%xmm2
	pxor	%xmm5,%xmm4
.byte	102,15,56,0,211
	movdqa	%xmm10,%xmm3
	pxor	%xmm0,%xmm2
.byte	102,15,56,0,220
	movdqu	(%r9),%xmm5
	pxor	%xmm1,%xmm3
	jnz	.Lenc_loop


	movdqa	-96(%r10),%xmm4
	movdqa	-80(%r10),%xmm0
.byte	102,15,56,0,226
	pxor	%xmm5,%xmm4
.byte	102,15,56,0,195
	movdqa	64(%r11,%r10,1),%xmm1
	pxor	%xmm4,%xmm0
.byte	102,15,56,0,193
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_vpaes_encrypt_core,.-_vpaes_encrypt_core






.type	_vpaes_decrypt_core,@function
.align	16
_vpaes_decrypt_core:
.cfi_startproc	
	movq	%rdx,%r9
	movl	240(%rdx),%eax
	movdqa	%xmm9,%xmm1
	movdqa	.Lk_dipt(%rip),%xmm2
	pandn	%xmm0,%xmm1
	movq	%rax,%r11
	psrld	$4,%xmm1
	movdqu	(%r9),%xmm5
	shlq	$4,%r11
	pand	%xmm9,%xmm0
.byte	102,15,56,0,208
	movdqa	.Lk_dipt+16(%rip),%xmm0
	xorq	$0x30,%r11
	leaq	.Lk_dsbd(%rip),%r10
.byte	102,15,56,0,193
	andq	$0x30,%r11
	pxor	%xmm5,%xmm2
	movdqa	.Lk_mc_forward+48(%rip),%xmm5
	pxor	%xmm2,%xmm0
	addq	$16,%r9
	addq	%r10,%r11
	jmp	.Ldec_entry

.align	16
.Ldec_loop:



	movdqa	-32(%r10),%xmm4
	movdqa	-16(%r10),%xmm1
.byte	102,15,56,0,226
.byte	102,15,56,0,203
	pxor	%xmm4,%xmm0
	movdqa	0(%r10),%xmm4
	pxor	%xmm1,%xmm0
	movdqa	16(%r10),%xmm1

.byte	102,15,56,0,226
.byte	102,15,56,0,197
.byte	102,15,56,0,203
	pxor	%xmm4,%xmm0
	movdqa	32(%r10),%xmm4
	pxor	%xmm1,%xmm0
	movdqa	48(%r10),%xmm1

.byte	102,15,56,0,226
.byte	102,15,56,0,197
.byte	102,15,56,0,203
	pxor	%xmm4,%xmm0
	movdqa	64(%r10),%xmm4
	pxor	%xmm1,%xmm0
	movdqa	80(%r10),%xmm1

.byte	102,15,56,0,226
.byte	102,15,56,0,197
.byte	102,15,56,0,203
	pxor	%xmm4,%xmm0
	addq	$16,%r9
.byte	102,15,58,15,237,12
	pxor	%xmm1,%xmm0
	subq	$1,%rax

.Ldec_entry:

	movdqa	%xmm9,%xmm1
	pandn	%xmm0,%xmm1
	movdqa	%xmm11,%xmm2
	psrld	$4,%xmm1
	pand	%xmm9,%xmm0
.byte	102,15,56,0,208
	movdqa	%xmm10,%xmm3
	pxor	%xmm1,%xmm0
.byte	102,15,56,0,217
	movdqa	%xmm10,%xmm4
	pxor	%xmm2,%xmm3
.byte	102,15,56,0,224
	pxor	%xmm2,%xmm4
	movdqa	%xmm10,%xmm2
.byte	102,15,56,0,211
	movdqa	%xmm10,%xmm3
	pxor	%xmm0,%xmm2
.byte	102,15,56,0,220
	movdqu	(%r9),%xmm0
	pxor	%xmm1,%xmm3
	jnz	.Ldec_loop


	movdqa	96(%r10),%xmm4
.byte	102,15,56,0,226
	pxor	%xmm0,%xmm4
	movdqa	112(%r10),%xmm0
	movdqa	-352(%r11),%xmm2
.byte	102,15,56,0,195
	pxor	%xmm4,%xmm0
.byte	102,15,56,0,194
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_vpaes_decrypt_core,.-_vpaes_decrypt_core






.type	_vpaes_schedule_core,@function
.align	16
_vpaes_schedule_core:
.cfi_startproc	





	call	_vpaes_preheat
	movdqa	.Lk_rcon(%rip),%xmm8
	movdqu	(%rdi),%xmm0


	movdqa	%xmm0,%xmm3
	leaq	.Lk_ipt(%rip),%r11
	call	_vpaes_schedule_transform
	movdqa	%xmm0,%xmm7

	leaq	.Lk_sr(%rip),%r10
	testq	%rcx,%rcx
	jnz	.Lschedule_am_decrypting


	movdqu	%xmm0,(%rdx)
	jmp	.Lschedule_go

.Lschedule_am_decrypting:

	movdqa	(%r8,%r10,1),%xmm1
.byte	102,15,56,0,217
	movdqu	%xmm3,(%rdx)
	xorq	$0x30,%r8

.Lschedule_go:
	cmpl	$192,%esi
	ja	.Lschedule_256
	je	.Lschedule_192










.Lschedule_128:
	movl	$10,%esi

.Loop_schedule_128:
	call	_vpaes_schedule_round
	decq	%rsi
	jz	.Lschedule_mangle_last
	call	_vpaes_schedule_mangle
	jmp	.Loop_schedule_128
















.align	16
.Lschedule_192:
	movdqu	8(%rdi),%xmm0
	call	_vpaes_schedule_transform
	movdqa	%xmm0,%xmm6
	pxor	%xmm4,%xmm4
	movhlps	%xmm4,%xmm6
	movl	$4,%esi

.Loop_schedule_192:
	call	_vpaes_schedule_round
.byte	102,15,58,15,198,8
	call	_vpaes_schedule_mangle
	call	_vpaes_schedule_192_smear
	call	_vpaes_schedule_mangle
	call	_vpaes_schedule_round
	decq	%rsi
	jz	.Lschedule_mangle_last
	call	_vpaes_schedule_mangle
	call	_vpaes_schedule_192_smear
	jmp	.Loop_schedule_192











.align	16
.Lschedule_256:
	movdqu	16(%rdi),%xmm0
	call	_vpaes_schedule_transform
	movl	$7,%esi

.Loop_schedule_256:
	call	_vpaes_schedule_mangle
	movdqa	%xmm0,%xmm6


	call	_vpaes_schedule_round
	decq	%rsi
	jz	.Lschedule_mangle_last
	call	_vpaes_schedule_mangle


	pshufd	$0xFF,%xmm0,%xmm0
	movdqa	%xmm7,%xmm5
	movdqa	%xmm6,%xmm7
	call	_vpaes_schedule_low_round
	movdqa	%xmm5,%xmm7

	jmp	.Loop_schedule_256












.align	16
.Lschedule_mangle_last:

	leaq	.Lk_deskew(%rip),%r11
	testq	%rcx,%rcx
	jnz	.Lschedule_mangle_last_dec


	movdqa	(%r8,%r10,1),%xmm1
.byte	102,15,56,0,193
	leaq	.Lk_opt(%rip),%r11
	addq	$32,%rdx

.Lschedule_mangle_last_dec:
	addq	$-16,%rdx
	pxor	.Lk_s63(%rip),%xmm0
	call	_vpaes_schedule_transform
	movdqu	%xmm0,(%rdx)


	pxor	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	pxor	%xmm2,%xmm2
	pxor	%xmm3,%xmm3
	pxor	%xmm4,%xmm4
	pxor	%xmm5,%xmm5
	pxor	%xmm6,%xmm6
	pxor	%xmm7,%xmm7
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_vpaes_schedule_core,.-_vpaes_schedule_core















.type	_vpaes_schedule_192_smear,@function
.align	16
_vpaes_schedule_192_smear:
.cfi_startproc	
	pshufd	$0x80,%xmm6,%xmm1
	pshufd	$0xFE,%xmm7,%xmm0
	pxor	%xmm1,%xmm6
	pxor	%xmm1,%xmm1
	pxor	%xmm0,%xmm6
	movdqa	%xmm6,%xmm0
	movhlps	%xmm1,%xmm6
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_vpaes_schedule_192_smear,.-_vpaes_schedule_192_smear



















.type	_vpaes_schedule_round,@function
.align	16
_vpaes_schedule_round:
.cfi_startproc	

	pxor	%xmm1,%xmm1
.byte	102,65,15,58,15,200,15
.byte	102,69,15,58,15,192,15
	pxor	%xmm1,%xmm7


	pshufd	$0xFF,%xmm0,%xmm0
.byte	102,15,58,15,192,1




_vpaes_schedule_low_round:

	movdqa	%xmm7,%xmm1
	pslldq	$4,%xmm7
	pxor	%xmm1,%xmm7
	movdqa	%xmm7,%xmm1
	pslldq	$8,%xmm7
	pxor	%xmm1,%xmm7
	pxor	.Lk_s63(%rip),%xmm7


	movdqa	%xmm9,%xmm1
	pandn	%xmm0,%xmm1
	psrld	$4,%xmm1
	pand	%xmm9,%xmm0
	movdqa	%xmm11,%xmm2
.byte	102,15,56,0,208
	pxor	%xmm1,%xmm0
	movdqa	%xmm10,%xmm3
.byte	102,15,56,0,217
	pxor	%xmm2,%xmm3
	movdqa	%xmm10,%xmm4
.byte	102,15,56,0,224
	pxor	%xmm2,%xmm4
	movdqa	%xmm10,%xmm2
.byte	102,15,56,0,211
	pxor	%xmm0,%xmm2
	movdqa	%xmm10,%xmm3
.byte	102,15,56,0,220
	pxor	%xmm1,%xmm3
	movdqa	%xmm13,%xmm4
.byte	102,15,56,0,226
	movdqa	%xmm12,%xmm0
.byte	102,15,56,0,195
	pxor	%xmm4,%xmm0


	pxor	%xmm7,%xmm0
	movdqa	%xmm0,%xmm7
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_vpaes_schedule_round,.-_vpaes_schedule_round










.type	_vpaes_schedule_transform,@function
.align	16
_vpaes_schedule_transform:
.cfi_startproc	
	movdqa	%xmm9,%xmm1
	pandn	%xmm0,%xmm1
	psrld	$4,%xmm1
	pand	%xmm9,%xmm0
	movdqa	(%r11),%xmm2
.byte	102,15,56,0,208
	movdqa	16(%r11),%xmm0
.byte	102,15,56,0,193
	pxor	%xmm2,%xmm0
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_vpaes_schedule_transform,.-_vpaes_schedule_transform
























.type	_vpaes_schedule_mangle,@function
.align	16
_vpaes_schedule_mangle:
.cfi_startproc	
	movdqa	%xmm0,%xmm4
	movdqa	.Lk_mc_forward(%rip),%xmm5
	testq	%rcx,%rcx
	jnz	.Lschedule_mangle_dec


	addq	$16,%rdx
	pxor	.Lk_s63(%rip),%xmm4
.byte	102,15,56,0,229
	movdqa	%xmm4,%xmm3
.byte	102,15,56,0,229
	pxor	%xmm4,%xmm3
.byte	102,15,56,0,229
	pxor	%xmm4,%xmm3

	jmp	.Lschedule_mangle_both
.align	16
.Lschedule_mangle_dec:

	leaq	.Lk_dksd(%rip),%r11
	movdqa	%xmm9,%xmm1
	pandn	%xmm4,%xmm1
	psrld	$4,%xmm1
	pand	%xmm9,%xmm4

	movdqa	0(%r11),%xmm2
.byte	102,15,56,0,212
	movdqa	16(%r11),%xmm3
.byte	102,15,56,0,217
	pxor	%xmm2,%xmm3
.byte	102,15,56,0,221

	movdqa	32(%r11),%xmm2
.byte	102,15,56,0,212
	pxor	%xmm3,%xmm2
	movdqa	48(%r11),%xmm3
.byte	102,15,56,0,217
	pxor	%xmm2,%xmm3
.byte	102,15,56,0,221

	movdqa	64(%r11),%xmm2
.byte	102,15,56,0,212
	pxor	%xmm3,%xmm2
	movdqa	80(%r11),%xmm3
.byte	102,15,56,0,217
	pxor	%xmm2,%xmm3
.byte	102,15,56,0,221

	movdqa	96(%r11),%xmm2
.byte	102,15,56,0,212
	pxor	%xmm3,%xmm2
	movdqa	112(%r11),%xmm3
.byte	102,15,56,0,217
	pxor	%xmm2,%xmm3

	addq	$-16,%rdx

.Lschedule_mangle_both:
	movdqa	(%r8,%r10,1),%xmm1
.byte	102,15,56,0,217
	addq	$-16,%r8
	andq	$0x30,%r8
	movdqu	%xmm3,(%rdx)
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_vpaes_schedule_mangle,.-_vpaes_schedule_mangle




.globl	vpaes_set_encrypt_key
.type	vpaes_set_encrypt_key,@function
.align	16
vpaes_set_encrypt_key:
.cfi_startproc	
.byte	243,15,30,250
	movl	%esi,%eax
	shrl	$5,%eax
	addl	$5,%eax
	movl	%eax,240(%rdx)

	movl	$0,%ecx
	movl	$0x30,%r8d
	call	_vpaes_schedule_core
	xorl	%eax,%eax
	.byte	0xf3,0xc3
.cfi_endproc	
.size	vpaes_set_encrypt_key,.-vpaes_set_encrypt_key

.globl	vpaes_set_decrypt_key
.type	vpaes_set_decrypt_key,@function
.align	16
vpaes_set_decrypt_key:
.cfi_startproc	
.byte	243,15,30,250
	movl	%esi,%eax
	shrl	$5,%eax
	addl	$5,%eax
	movl	%eax,240(%rdx)
	shll	$4,%eax
	leaq	16(%rdx,%rax,1),%rdx

	movl	$1,%ecx
	movl	%esi,%r8d
	shrl	$1,%r8d
	andl	$32,%r8d
	xorl	$32,%r8d
	call	_vpaes_schedule_core
	xorl	%eax,%eax
	.byte	0xf3,0xc3
.cfi_endproc	
.size	vpaes_set_decrypt_key,.-vpaes_set_decrypt_key

.globl	vpaes_encrypt
.type	vpaes_encrypt,@function
.align	16
vpaes_encrypt:
.cfi_startproc	
.byte	243,15,30,250
	movdqu	(%rdi),%xmm0
	call	_vpaes_preheat
	call	_vpaes_encrypt_core
	movdqu	%xmm0,(%rsi)
	.byte	0xf3,0xc3
.cfi_endproc	
.size	vpaes_encrypt,.-vpaes_encrypt

.globl	vpaes_decrypt
.type	vpaes_decrypt,@function
.align	16
vpaes_decrypt:
.cfi_startproc	
.byte	243,15,30,250
	movdqu	(%rdi),%xmm0
	call	_vpaes_preheat
	call	_vpaes_decrypt_core
	movdqu	%xmm0,(%rsi)
	.byte	0xf3,0xc3
.cfi_endproc	
.size	vpaes_decrypt,.-vpaes_decrypt
.globl	vpaes_cbc_encrypt
.type	vpaes_cbc_encrypt,@function
.align	16
vpaes_cbc_encrypt:
.cfi_startproc	
.byte	243,15,30,250
	xchgq	%rcx,%rdx
	subq	$16,%rcx
	jc	.Lcbc_abort
	movdqu	(%r8),%xmm6
	subq	%rdi,%rsi
	call	_vpaes_preheat
	cmpl	$0,%r9d
	je	.Lcbc_dec_loop
	jmp	.Lcbc_enc_loop
.align	16
.Lcbc_enc_loop:
	movdqu	(%rdi),%xmm0
	pxor	%xmm6,%xmm0
	call	_vpaes_encrypt_core
	movdqa	%xmm0,%xmm6
	movdqu	%xmm0,(%rsi,%rdi,1)
	leaq	16(%rdi),%rdi
	subq	$16,%rcx
	jnc	.Lcbc_enc_loop
	jmp	.Lcbc_done
.align	16
.Lcbc_dec_loop:
	movdqu	(%rdi),%xmm0
	movdqa	%xmm0,%xmm7
	call	_vpaes_decrypt_core
	pxor	%xmm6,%xmm0
	movdqa	%xmm7,%xmm6
	movdqu	%xmm0,(%rsi,%rdi,1)
	leaq	16(%rdi),%rdi
	subq	$16,%rcx
	jnc	.Lcbc_dec_loop
.Lcbc_done:
	movdqu	%xmm6,(%r8)
.Lcbc_abort:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	vpaes_cbc_encrypt,.-vpaes_cbc_encrypt






.type	_vpaes_preheat,@function
.align	16
_vpaes_preheat:
.cfi_startproc	
	leaq	.Lk_s0F(%rip),%r10
	movdqa	-32(%r10),%xmm10
	movdqa	-16(%r10),%xmm11
	movdqa	0(%r10),%xmm9
	movdqa	48(%r10),%xmm13
	movdqa	64(%r10),%xmm12
	movdqa	80(%r10),%xmm15
	movdqa	96(%r10),%xmm14
	.byte	0xf3,0xc3
.cfi_endproc	
.size	_vpaes_preheat,.-_vpaes_preheat





.type	_vpaes_consts,@object
.align	64
_vpaes_consts:
.Lk_inv:
.quad	0x0E05060F0D080180, 0x040703090A0B0C02
.quad	0x01040A060F0B0780, 0x030D0E0C02050809

.Lk_s0F:
.quad	0x0F0F0F0F0F0F0F0F, 0x0F0F0F0F0F0F0F0F

.Lk_ipt:
.quad	0xC2B2E8985A2A7000, 0xCABAE09052227808
.quad	0x4C01307D317C4D00, 0xCD80B1FCB0FDCC81

.Lk_sb1:
.quad	0xB19BE18FCB503E00, 0xA5DF7A6E142AF544
.quad	0x3618D415FAE22300, 0x3BF7CCC10D2ED9EF
.Lk_sb2:
.quad	0xE27A93C60B712400, 0x5EB7E955BC982FCD
.quad	0x69EB88400AE12900, 0xC2A163C8AB82234A
.Lk_sbo:
.quad	0xD0D26D176FBDC700, 0x15AABF7AC502A878
.quad	0xCFE474A55FBB6A00, 0x8E1E90D1412B35FA

.Lk_mc_forward:
.quad	0x0407060500030201, 0x0C0F0E0D080B0A09
.quad	0x080B0A0904070605, 0x000302010C0F0E0D
.quad	0x0C0F0E0D080B0A09, 0x0407060500030201
.quad	0x000302010C0F0E0D, 0x080B0A0904070605

.Lk_mc_backward:
.quad	0x0605040702010003, 0x0E0D0C0F0A09080B
.quad	0x020100030E0D0C0F, 0x0A09080B06050407
.quad	0x0E0D0C0F0A09080B, 0x0605040702010003
.quad	0x0A09080B06050407, 0x020100030E0D0C0F

.Lk_sr:
.quad	0x0706050403020100, 0x0F0E0D0C0B0A0908
.quad	0x030E09040F0A0500, 0x0B06010C07020D08
.quad	0x0F060D040B020900, 0x070E050C030A0108
.quad	0x0B0E0104070A0D00, 0x0306090C0F020508

.Lk_rcon:
.quad	0x1F8391B9AF9DEEB6, 0x702A98084D7C7D81

.Lk_s63:
.quad	0x5B5B5B5B5B5B5B5B, 0x5B5B5B5B5B5B5B5B

.Lk_opt:
.quad	0xFF9F4929D6B66000, 0xF7974121DEBE6808
.quad	0x01EDBD5150BCEC00, 0xE10D5DB1B05C0CE0

.Lk_deskew:
.quad	0x07E4A34047A4E300, 0x1DFEB95A5DBEF91A
.quad	0x5F36B5DC83EA6900, 0x2841C2ABF49D1E77





.Lk_dksd:
.quad	0xFEB91A5DA3E44700, 0x0740E3A45A1DBEF9
.quad	0x41C277F4B5368300, 0x5FDC69EAAB289D1E
.Lk_dksb:
.quad	0x9A4FCA1F8550D500, 0x03D653861CC94C99
.quad	0x115BEDA7B6FC4A00, 0xD993256F7E3482C8
.Lk_dkse:
.quad	0xD5031CCA1FC9D600, 0x53859A4C994F5086
.quad	0xA23196054FDC7BE8, 0xCD5EF96A20B31487
.Lk_dks9:
.quad	0xB6116FC87ED9A700, 0x4AED933482255BFC
.quad	0x4576516227143300, 0x8BB89FACE9DAFDCE





.Lk_dipt:
.quad	0x0F505B040B545F00, 0x154A411E114E451A
.quad	0x86E383E660056500, 0x12771772F491F194

.Lk_dsb9:
.quad	0x851C03539A86D600, 0xCAD51F504F994CC9
.quad	0xC03B1789ECD74900, 0x725E2C9EB2FBA565
.Lk_dsbd:
.quad	0x7D57CCDFE6B1A200, 0xF56E9B13882A4439
.quad	0x3CE2FAF724C6CB00, 0x2931180D15DEEFD3
.Lk_dsbb:
.quad	0xD022649296B44200, 0x602646F6B0F2D404
.quad	0xC19498A6CD596700, 0xF3FF0C3E3255AA6B
.Lk_dsbe:
.quad	0x46F2929626D4D000, 0x2242600464B4F6B0
.quad	0x0C55A6CDFFAAC100, 0x9467F36B98593E32
.Lk_dsbo:
.quad	0x1387EA537EF94000, 0xC7AA6DB9D4943E2D
.quad	0x12D7560F93441D00, 0xCA4B8159D8C58E9C
.byte	86,101,99,116,111,114,32,80,101,114,109,117,116,97,116,105,111,110,32,65,69,83,32,102,111,114,32,120,56,54,95,54,52,47,83,83,83,69,51,44,32,77,105,107,101,32,72,97,109,98,117,114,103,32,40,83,116,97,110,102,111,114,100,32,85,110,105,118,101,114,115,105,116,121,41,0
.align	64
.size	_vpaes_consts,.-_vpaes_consts
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                                                                                                                                                                                                                                                                 node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/bn/                                   0000775 0000000 0000000 00000000000 14746647661 0024332 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/bn/rsaz-avx2.s                        0000664 0000000 0000000 00000115207 14746647661 0026361 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	

.globl	rsaz_1024_sqr_avx2
.type	rsaz_1024_sqr_avx2,@function
.align	64
rsaz_1024_sqr_avx2:
.cfi_startproc	
	leaq	(%rsp),%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
	vzeroupper
	movq	%rax,%rbp
.cfi_def_cfa_register	%rbp
	movq	%rdx,%r13
	subq	$832,%rsp
	movq	%r13,%r15
	subq	$-128,%rdi
	subq	$-128,%rsi
	subq	$-128,%r13

	andq	$4095,%r15
	addq	$320,%r15
	shrq	$12,%r15
	vpxor	%ymm9,%ymm9,%ymm9
	jz	.Lsqr_1024_no_n_copy





	subq	$320,%rsp
	vmovdqu	0-128(%r13),%ymm0
	andq	$-2048,%rsp
	vmovdqu	32-128(%r13),%ymm1
	vmovdqu	64-128(%r13),%ymm2
	vmovdqu	96-128(%r13),%ymm3
	vmovdqu	128-128(%r13),%ymm4
	vmovdqu	160-128(%r13),%ymm5
	vmovdqu	192-128(%r13),%ymm6
	vmovdqu	224-128(%r13),%ymm7
	vmovdqu	256-128(%r13),%ymm8
	leaq	832+128(%rsp),%r13
	vmovdqu	%ymm0,0-128(%r13)
	vmovdqu	%ymm1,32-128(%r13)
	vmovdqu	%ymm2,64-128(%r13)
	vmovdqu	%ymm3,96-128(%r13)
	vmovdqu	%ymm4,128-128(%r13)
	vmovdqu	%ymm5,160-128(%r13)
	vmovdqu	%ymm6,192-128(%r13)
	vmovdqu	%ymm7,224-128(%r13)
	vmovdqu	%ymm8,256-128(%r13)
	vmovdqu	%ymm9,288-128(%r13)

.Lsqr_1024_no_n_copy:
	andq	$-1024,%rsp

	vmovdqu	32-128(%rsi),%ymm1
	vmovdqu	64-128(%rsi),%ymm2
	vmovdqu	96-128(%rsi),%ymm3
	vmovdqu	128-128(%rsi),%ymm4
	vmovdqu	160-128(%rsi),%ymm5
	vmovdqu	192-128(%rsi),%ymm6
	vmovdqu	224-128(%rsi),%ymm7
	vmovdqu	256-128(%rsi),%ymm8

	leaq	192(%rsp),%rbx
	vmovdqu	.Land_mask(%rip),%ymm15
	jmp	.LOOP_GRANDE_SQR_1024

.align	32
.LOOP_GRANDE_SQR_1024:
	leaq	576+128(%rsp),%r9
	leaq	448(%rsp),%r12




	vpaddq	%ymm1,%ymm1,%ymm1
	vpbroadcastq	0-128(%rsi),%ymm10
	vpaddq	%ymm2,%ymm2,%ymm2
	vmovdqa	%ymm1,0-128(%r9)
	vpaddq	%ymm3,%ymm3,%ymm3
	vmovdqa	%ymm2,32-128(%r9)
	vpaddq	%ymm4,%ymm4,%ymm4
	vmovdqa	%ymm3,64-128(%r9)
	vpaddq	%ymm5,%ymm5,%ymm5
	vmovdqa	%ymm4,96-128(%r9)
	vpaddq	%ymm6,%ymm6,%ymm6
	vmovdqa	%ymm5,128-128(%r9)
	vpaddq	%ymm7,%ymm7,%ymm7
	vmovdqa	%ymm6,160-128(%r9)
	vpaddq	%ymm8,%ymm8,%ymm8
	vmovdqa	%ymm7,192-128(%r9)
	vpxor	%ymm9,%ymm9,%ymm9
	vmovdqa	%ymm8,224-128(%r9)

	vpmuludq	0-128(%rsi),%ymm10,%ymm0
	vpbroadcastq	32-128(%rsi),%ymm11
	vmovdqu	%ymm9,288-192(%rbx)
	vpmuludq	%ymm10,%ymm1,%ymm1
	vmovdqu	%ymm9,320-448(%r12)
	vpmuludq	%ymm10,%ymm2,%ymm2
	vmovdqu	%ymm9,352-448(%r12)
	vpmuludq	%ymm10,%ymm3,%ymm3
	vmovdqu	%ymm9,384-448(%r12)
	vpmuludq	%ymm10,%ymm4,%ymm4
	vmovdqu	%ymm9,416-448(%r12)
	vpmuludq	%ymm10,%ymm5,%ymm5
	vmovdqu	%ymm9,448-448(%r12)
	vpmuludq	%ymm10,%ymm6,%ymm6
	vmovdqu	%ymm9,480-448(%r12)
	vpmuludq	%ymm10,%ymm7,%ymm7
	vmovdqu	%ymm9,512-448(%r12)
	vpmuludq	%ymm10,%ymm8,%ymm8
	vpbroadcastq	64-128(%rsi),%ymm10
	vmovdqu	%ymm9,544-448(%r12)

	movq	%rsi,%r15
	movl	$4,%r14d
	jmp	.Lsqr_entry_1024
.align	32
.LOOP_SQR_1024:
	vpbroadcastq	32-128(%r15),%ymm11
	vpmuludq	0-128(%rsi),%ymm10,%ymm0
	vpaddq	0-192(%rbx),%ymm0,%ymm0
	vpmuludq	0-128(%r9),%ymm10,%ymm1
	vpaddq	32-192(%rbx),%ymm1,%ymm1
	vpmuludq	32-128(%r9),%ymm10,%ymm2
	vpaddq	64-192(%rbx),%ymm2,%ymm2
	vpmuludq	64-128(%r9),%ymm10,%ymm3
	vpaddq	96-192(%rbx),%ymm3,%ymm3
	vpmuludq	96-128(%r9),%ymm10,%ymm4
	vpaddq	128-192(%rbx),%ymm4,%ymm4
	vpmuludq	128-128(%r9),%ymm10,%ymm5
	vpaddq	160-192(%rbx),%ymm5,%ymm5
	vpmuludq	160-128(%r9),%ymm10,%ymm6
	vpaddq	192-192(%rbx),%ymm6,%ymm6
	vpmuludq	192-128(%r9),%ymm10,%ymm7
	vpaddq	224-192(%rbx),%ymm7,%ymm7
	vpmuludq	224-128(%r9),%ymm10,%ymm8
	vpbroadcastq	64-128(%r15),%ymm10
	vpaddq	256-192(%rbx),%ymm8,%ymm8
.Lsqr_entry_1024:
	vmovdqu	%ymm0,0-192(%rbx)
	vmovdqu	%ymm1,32-192(%rbx)

	vpmuludq	32-128(%rsi),%ymm11,%ymm12
	vpaddq	%ymm12,%ymm2,%ymm2
	vpmuludq	32-128(%r9),%ymm11,%ymm14
	vpaddq	%ymm14,%ymm3,%ymm3
	vpmuludq	64-128(%r9),%ymm11,%ymm13
	vpaddq	%ymm13,%ymm4,%ymm4
	vpmuludq	96-128(%r9),%ymm11,%ymm12
	vpaddq	%ymm12,%ymm5,%ymm5
	vpmuludq	128-128(%r9),%ymm11,%ymm14
	vpaddq	%ymm14,%ymm6,%ymm6
	vpmuludq	160-128(%r9),%ymm11,%ymm13
	vpaddq	%ymm13,%ymm7,%ymm7
	vpmuludq	192-128(%r9),%ymm11,%ymm12
	vpaddq	%ymm12,%ymm8,%ymm8
	vpmuludq	224-128(%r9),%ymm11,%ymm0
	vpbroadcastq	96-128(%r15),%ymm11
	vpaddq	288-192(%rbx),%ymm0,%ymm0

	vmovdqu	%ymm2,64-192(%rbx)
	vmovdqu	%ymm3,96-192(%rbx)

	vpmuludq	64-128(%rsi),%ymm10,%ymm13
	vpaddq	%ymm13,%ymm4,%ymm4
	vpmuludq	64-128(%r9),%ymm10,%ymm12
	vpaddq	%ymm12,%ymm5,%ymm5
	vpmuludq	96-128(%r9),%ymm10,%ymm14
	vpaddq	%ymm14,%ymm6,%ymm6
	vpmuludq	128-128(%r9),%ymm10,%ymm13
	vpaddq	%ymm13,%ymm7,%ymm7
	vpmuludq	160-128(%r9),%ymm10,%ymm12
	vpaddq	%ymm12,%ymm8,%ymm8
	vpmuludq	192-128(%r9),%ymm10,%ymm14
	vpaddq	%ymm14,%ymm0,%ymm0
	vpmuludq	224-128(%r9),%ymm10,%ymm1
	vpbroadcastq	128-128(%r15),%ymm10
	vpaddq	320-448(%r12),%ymm1,%ymm1

	vmovdqu	%ymm4,128-192(%rbx)
	vmovdqu	%ymm5,160-192(%rbx)

	vpmuludq	96-128(%rsi),%ymm11,%ymm12
	vpaddq	%ymm12,%ymm6,%ymm6
	vpmuludq	96-128(%r9),%ymm11,%ymm14
	vpaddq	%ymm14,%ymm7,%ymm7
	vpmuludq	128-128(%r9),%ymm11,%ymm13
	vpaddq	%ymm13,%ymm8,%ymm8
	vpmuludq	160-128(%r9),%ymm11,%ymm12
	vpaddq	%ymm12,%ymm0,%ymm0
	vpmuludq	192-128(%r9),%ymm11,%ymm14
	vpaddq	%ymm14,%ymm1,%ymm1
	vpmuludq	224-128(%r9),%ymm11,%ymm2
	vpbroadcastq	160-128(%r15),%ymm11
	vpaddq	352-448(%r12),%ymm2,%ymm2

	vmovdqu	%ymm6,192-192(%rbx)
	vmovdqu	%ymm7,224-192(%rbx)

	vpmuludq	128-128(%rsi),%ymm10,%ymm12
	vpaddq	%ymm12,%ymm8,%ymm8
	vpmuludq	128-128(%r9),%ymm10,%ymm14
	vpaddq	%ymm14,%ymm0,%ymm0
	vpmuludq	160-128(%r9),%ymm10,%ymm13
	vpaddq	%ymm13,%ymm1,%ymm1
	vpmuludq	192-128(%r9),%ymm10,%ymm12
	vpaddq	%ymm12,%ymm2,%ymm2
	vpmuludq	224-128(%r9),%ymm10,%ymm3
	vpbroadcastq	192-128(%r15),%ymm10
	vpaddq	384-448(%r12),%ymm3,%ymm3

	vmovdqu	%ymm8,256-192(%rbx)
	vmovdqu	%ymm0,288-192(%rbx)
	leaq	8(%rbx),%rbx

	vpmuludq	160-128(%rsi),%ymm11,%ymm13
	vpaddq	%ymm13,%ymm1,%ymm1
	vpmuludq	160-128(%r9),%ymm11,%ymm12
	vpaddq	%ymm12,%ymm2,%ymm2
	vpmuludq	192-128(%r9),%ymm11,%ymm14
	vpaddq	%ymm14,%ymm3,%ymm3
	vpmuludq	224-128(%r9),%ymm11,%ymm4
	vpbroadcastq	224-128(%r15),%ymm11
	vpaddq	416-448(%r12),%ymm4,%ymm4

	vmovdqu	%ymm1,320-448(%r12)
	vmovdqu	%ymm2,352-448(%r12)

	vpmuludq	192-128(%rsi),%ymm10,%ymm12
	vpaddq	%ymm12,%ymm3,%ymm3
	vpmuludq	192-128(%r9),%ymm10,%ymm14
	vpbroadcastq	256-128(%r15),%ymm0
	vpaddq	%ymm14,%ymm4,%ymm4
	vpmuludq	224-128(%r9),%ymm10,%ymm5
	vpbroadcastq	0+8-128(%r15),%ymm10
	vpaddq	448-448(%r12),%ymm5,%ymm5

	vmovdqu	%ymm3,384-448(%r12)
	vmovdqu	%ymm4,416-448(%r12)
	leaq	8(%r15),%r15

	vpmuludq	224-128(%rsi),%ymm11,%ymm12
	vpaddq	%ymm12,%ymm5,%ymm5
	vpmuludq	224-128(%r9),%ymm11,%ymm6
	vpaddq	480-448(%r12),%ymm6,%ymm6

	vpmuludq	256-128(%rsi),%ymm0,%ymm7
	vmovdqu	%ymm5,448-448(%r12)
	vpaddq	512-448(%r12),%ymm7,%ymm7
	vmovdqu	%ymm6,480-448(%r12)
	vmovdqu	%ymm7,512-448(%r12)
	leaq	8(%r12),%r12

	decl	%r14d
	jnz	.LOOP_SQR_1024

	vmovdqu	256(%rsp),%ymm8
	vmovdqu	288(%rsp),%ymm1
	vmovdqu	320(%rsp),%ymm2
	leaq	192(%rsp),%rbx

	vpsrlq	$29,%ymm8,%ymm14
	vpand	%ymm15,%ymm8,%ymm8
	vpsrlq	$29,%ymm1,%ymm11
	vpand	%ymm15,%ymm1,%ymm1

	vpermq	$0x93,%ymm14,%ymm14
	vpxor	%ymm9,%ymm9,%ymm9
	vpermq	$0x93,%ymm11,%ymm11

	vpblendd	$3,%ymm9,%ymm14,%ymm10
	vpblendd	$3,%ymm14,%ymm11,%ymm14
	vpaddq	%ymm10,%ymm8,%ymm8
	vpblendd	$3,%ymm11,%ymm9,%ymm11
	vpaddq	%ymm14,%ymm1,%ymm1
	vpaddq	%ymm11,%ymm2,%ymm2
	vmovdqu	%ymm1,288-192(%rbx)
	vmovdqu	%ymm2,320-192(%rbx)

	movq	(%rsp),%rax
	movq	8(%rsp),%r10
	movq	16(%rsp),%r11
	movq	24(%rsp),%r12
	vmovdqu	32(%rsp),%ymm1
	vmovdqu	64-192(%rbx),%ymm2
	vmovdqu	96-192(%rbx),%ymm3
	vmovdqu	128-192(%rbx),%ymm4
	vmovdqu	160-192(%rbx),%ymm5
	vmovdqu	192-192(%rbx),%ymm6
	vmovdqu	224-192(%rbx),%ymm7

	movq	%rax,%r9
	imull	%ecx,%eax
	andl	$0x1fffffff,%eax
	vmovd	%eax,%xmm12

	movq	%rax,%rdx
	imulq	-128(%r13),%rax
	vpbroadcastq	%xmm12,%ymm12
	addq	%rax,%r9
	movq	%rdx,%rax
	imulq	8-128(%r13),%rax
	shrq	$29,%r9
	addq	%rax,%r10
	movq	%rdx,%rax
	imulq	16-128(%r13),%rax
	addq	%r9,%r10
	addq	%rax,%r11
	imulq	24-128(%r13),%rdx
	addq	%rdx,%r12

	movq	%r10,%rax
	imull	%ecx,%eax
	andl	$0x1fffffff,%eax

	movl	$9,%r14d
	jmp	.LOOP_REDUCE_1024

.align	32
.LOOP_REDUCE_1024:
	vmovd	%eax,%xmm13
	vpbroadcastq	%xmm13,%ymm13

	vpmuludq	32-128(%r13),%ymm12,%ymm10
	movq	%rax,%rdx
	imulq	-128(%r13),%rax
	vpaddq	%ymm10,%ymm1,%ymm1
	addq	%rax,%r10
	vpmuludq	64-128(%r13),%ymm12,%ymm14
	movq	%rdx,%rax
	imulq	8-128(%r13),%rax
	vpaddq	%ymm14,%ymm2,%ymm2
	vpmuludq	96-128(%r13),%ymm12,%ymm11
.byte	0x67
	addq	%rax,%r11
.byte	0x67
	movq	%rdx,%rax
	imulq	16-128(%r13),%rax
	shrq	$29,%r10
	vpaddq	%ymm11,%ymm3,%ymm3
	vpmuludq	128-128(%r13),%ymm12,%ymm10
	addq	%rax,%r12
	addq	%r10,%r11
	vpaddq	%ymm10,%ymm4,%ymm4
	vpmuludq	160-128(%r13),%ymm12,%ymm14
	movq	%r11,%rax
	imull	%ecx,%eax
	vpaddq	%ymm14,%ymm5,%ymm5
	vpmuludq	192-128(%r13),%ymm12,%ymm11
	andl	$0x1fffffff,%eax
	vpaddq	%ymm11,%ymm6,%ymm6
	vpmuludq	224-128(%r13),%ymm12,%ymm10
	vpaddq	%ymm10,%ymm7,%ymm7
	vpmuludq	256-128(%r13),%ymm12,%ymm14
	vmovd	%eax,%xmm12

	vpaddq	%ymm14,%ymm8,%ymm8

	vpbroadcastq	%xmm12,%ymm12

	vpmuludq	32-8-128(%r13),%ymm13,%ymm11
	vmovdqu	96-8-128(%r13),%ymm14
	movq	%rax,%rdx
	imulq	-128(%r13),%rax
	vpaddq	%ymm11,%ymm1,%ymm1
	vpmuludq	64-8-128(%r13),%ymm13,%ymm10
	vmovdqu	128-8-128(%r13),%ymm11
	addq	%rax,%r11
	movq	%rdx,%rax
	imulq	8-128(%r13),%rax
	vpaddq	%ymm10,%ymm2,%ymm2
	addq	%r12,%rax
	shrq	$29,%r11
	vpmuludq	%ymm13,%ymm14,%ymm14
	vmovdqu	160-8-128(%r13),%ymm10
	addq	%r11,%rax
	vpaddq	%ymm14,%ymm3,%ymm3
	vpmuludq	%ymm13,%ymm11,%ymm11
	vmovdqu	192-8-128(%r13),%ymm14
.byte	0x67
	movq	%rax,%r12
	imull	%ecx,%eax
	vpaddq	%ymm11,%ymm4,%ymm4
	vpmuludq	%ymm13,%ymm10,%ymm10
.byte	0xc4,0x41,0x7e,0x6f,0x9d,0x58,0x00,0x00,0x00
	andl	$0x1fffffff,%eax
	vpaddq	%ymm10,%ymm5,%ymm5
	vpmuludq	%ymm13,%ymm14,%ymm14
	vmovdqu	256-8-128(%r13),%ymm10
	vpaddq	%ymm14,%ymm6,%ymm6
	vpmuludq	%ymm13,%ymm11,%ymm11
	vmovdqu	288-8-128(%r13),%ymm9
	vmovd	%eax,%xmm0
	imulq	-128(%r13),%rax
	vpaddq	%ymm11,%ymm7,%ymm7
	vpmuludq	%ymm13,%ymm10,%ymm10
	vmovdqu	32-16-128(%r13),%ymm14
	vpbroadcastq	%xmm0,%ymm0
	vpaddq	%ymm10,%ymm8,%ymm8
	vpmuludq	%ymm13,%ymm9,%ymm9
	vmovdqu	64-16-128(%r13),%ymm11
	addq	%rax,%r12

	vmovdqu	32-24-128(%r13),%ymm13
	vpmuludq	%ymm12,%ymm14,%ymm14
	vmovdqu	96-16-128(%r13),%ymm10
	vpaddq	%ymm14,%ymm1,%ymm1
	vpmuludq	%ymm0,%ymm13,%ymm13
	vpmuludq	%ymm12,%ymm11,%ymm11
.byte	0xc4,0x41,0x7e,0x6f,0xb5,0xf0,0xff,0xff,0xff
	vpaddq	%ymm1,%ymm13,%ymm13
	vpaddq	%ymm11,%ymm2,%ymm2
	vpmuludq	%ymm12,%ymm10,%ymm10
	vmovdqu	160-16-128(%r13),%ymm11
.byte	0x67
	vmovq	%xmm13,%rax
	vmovdqu	%ymm13,(%rsp)
	vpaddq	%ymm10,%ymm3,%ymm3
	vpmuludq	%ymm12,%ymm14,%ymm14
	vmovdqu	192-16-128(%r13),%ymm10
	vpaddq	%ymm14,%ymm4,%ymm4
	vpmuludq	%ymm12,%ymm11,%ymm11
	vmovdqu	224-16-128(%r13),%ymm14
	vpaddq	%ymm11,%ymm5,%ymm5
	vpmuludq	%ymm12,%ymm10,%ymm10
	vmovdqu	256-16-128(%r13),%ymm11
	vpaddq	%ymm10,%ymm6,%ymm6
	vpmuludq	%ymm12,%ymm14,%ymm14
	shrq	$29,%r12
	vmovdqu	288-16-128(%r13),%ymm10
	addq	%r12,%rax
	vpaddq	%ymm14,%ymm7,%ymm7
	vpmuludq	%ymm12,%ymm11,%ymm11

	movq	%rax,%r9
	imull	%ecx,%eax
	vpaddq	%ymm11,%ymm8,%ymm8
	vpmuludq	%ymm12,%ymm10,%ymm10
	andl	$0x1fffffff,%eax
	vmovd	%eax,%xmm12
	vmovdqu	96-24-128(%r13),%ymm11
.byte	0x67
	vpaddq	%ymm10,%ymm9,%ymm9
	vpbroadcastq	%xmm12,%ymm12

	vpmuludq	64-24-128(%r13),%ymm0,%ymm14
	vmovdqu	128-24-128(%r13),%ymm10
	movq	%rax,%rdx
	imulq	-128(%r13),%rax
	movq	8(%rsp),%r10
	vpaddq	%ymm14,%ymm2,%ymm1
	vpmuludq	%ymm0,%ymm11,%ymm11
	vmovdqu	160-24-128(%r13),%ymm14
	addq	%rax,%r9
	movq	%rdx,%rax
	imulq	8-128(%r13),%rax
.byte	0x67
	shrq	$29,%r9
	movq	16(%rsp),%r11
	vpaddq	%ymm11,%ymm3,%ymm2
	vpmuludq	%ymm0,%ymm10,%ymm10
	vmovdqu	192-24-128(%r13),%ymm11
	addq	%rax,%r10
	movq	%rdx,%rax
	imulq	16-128(%r13),%rax
	vpaddq	%ymm10,%ymm4,%ymm3
	vpmuludq	%ymm0,%ymm14,%ymm14
	vmovdqu	224-24-128(%r13),%ymm10
	imulq	24-128(%r13),%rdx
	addq	%rax,%r11
	leaq	(%r9,%r10,1),%rax
	vpaddq	%ymm14,%ymm5,%ymm4
	vpmuludq	%ymm0,%ymm11,%ymm11
	vmovdqu	256-24-128(%r13),%ymm14
	movq	%rax,%r10
	imull	%ecx,%eax
	vpmuludq	%ymm0,%ymm10,%ymm10
	vpaddq	%ymm11,%ymm6,%ymm5
	vmovdqu	288-24-128(%r13),%ymm11
	andl	$0x1fffffff,%eax
	vpaddq	%ymm10,%ymm7,%ymm6
	vpmuludq	%ymm0,%ymm14,%ymm14
	addq	24(%rsp),%rdx
	vpaddq	%ymm14,%ymm8,%ymm7
	vpmuludq	%ymm0,%ymm11,%ymm11
	vpaddq	%ymm11,%ymm9,%ymm8
	vmovq	%r12,%xmm9
	movq	%rdx,%r12

	decl	%r14d
	jnz	.LOOP_REDUCE_1024
	leaq	448(%rsp),%r12
	vpaddq	%ymm9,%ymm13,%ymm0
	vpxor	%ymm9,%ymm9,%ymm9

	vpaddq	288-192(%rbx),%ymm0,%ymm0
	vpaddq	320-448(%r12),%ymm1,%ymm1
	vpaddq	352-448(%r12),%ymm2,%ymm2
	vpaddq	384-448(%r12),%ymm3,%ymm3
	vpaddq	416-448(%r12),%ymm4,%ymm4
	vpaddq	448-448(%r12),%ymm5,%ymm5
	vpaddq	480-448(%r12),%ymm6,%ymm6
	vpaddq	512-448(%r12),%ymm7,%ymm7
	vpaddq	544-448(%r12),%ymm8,%ymm8

	vpsrlq	$29,%ymm0,%ymm14
	vpand	%ymm15,%ymm0,%ymm0
	vpsrlq	$29,%ymm1,%ymm11
	vpand	%ymm15,%ymm1,%ymm1
	vpsrlq	$29,%ymm2,%ymm12
	vpermq	$0x93,%ymm14,%ymm14
	vpand	%ymm15,%ymm2,%ymm2
	vpsrlq	$29,%ymm3,%ymm13
	vpermq	$0x93,%ymm11,%ymm11
	vpand	%ymm15,%ymm3,%ymm3
	vpermq	$0x93,%ymm12,%ymm12

	vpblendd	$3,%ymm9,%ymm14,%ymm10
	vpermq	$0x93,%ymm13,%ymm13
	vpblendd	$3,%ymm14,%ymm11,%ymm14
	vpaddq	%ymm10,%ymm0,%ymm0
	vpblendd	$3,%ymm11,%ymm12,%ymm11
	vpaddq	%ymm14,%ymm1,%ymm1
	vpblendd	$3,%ymm12,%ymm13,%ymm12
	vpaddq	%ymm11,%ymm2,%ymm2
	vpblendd	$3,%ymm13,%ymm9,%ymm13
	vpaddq	%ymm12,%ymm3,%ymm3
	vpaddq	%ymm13,%ymm4,%ymm4

	vpsrlq	$29,%ymm0,%ymm14
	vpand	%ymm15,%ymm0,%ymm0
	vpsrlq	$29,%ymm1,%ymm11
	vpand	%ymm15,%ymm1,%ymm1
	vpsrlq	$29,%ymm2,%ymm12
	vpermq	$0x93,%ymm14,%ymm14
	vpand	%ymm15,%ymm2,%ymm2
	vpsrlq	$29,%ymm3,%ymm13
	vpermq	$0x93,%ymm11,%ymm11
	vpand	%ymm15,%ymm3,%ymm3
	vpermq	$0x93,%ymm12,%ymm12

	vpblendd	$3,%ymm9,%ymm14,%ymm10
	vpermq	$0x93,%ymm13,%ymm13
	vpblendd	$3,%ymm14,%ymm11,%ymm14
	vpaddq	%ymm10,%ymm0,%ymm0
	vpblendd	$3,%ymm11,%ymm12,%ymm11
	vpaddq	%ymm14,%ymm1,%ymm1
	vmovdqu	%ymm0,0-128(%rdi)
	vpblendd	$3,%ymm12,%ymm13,%ymm12
	vpaddq	%ymm11,%ymm2,%ymm2
	vmovdqu	%ymm1,32-128(%rdi)
	vpblendd	$3,%ymm13,%ymm9,%ymm13
	vpaddq	%ymm12,%ymm3,%ymm3
	vmovdqu	%ymm2,64-128(%rdi)
	vpaddq	%ymm13,%ymm4,%ymm4
	vmovdqu	%ymm3,96-128(%rdi)
	vpsrlq	$29,%ymm4,%ymm14
	vpand	%ymm15,%ymm4,%ymm4
	vpsrlq	$29,%ymm5,%ymm11
	vpand	%ymm15,%ymm5,%ymm5
	vpsrlq	$29,%ymm6,%ymm12
	vpermq	$0x93,%ymm14,%ymm14
	vpand	%ymm15,%ymm6,%ymm6
	vpsrlq	$29,%ymm7,%ymm13
	vpermq	$0x93,%ymm11,%ymm11
	vpand	%ymm15,%ymm7,%ymm7
	vpsrlq	$29,%ymm8,%ymm0
	vpermq	$0x93,%ymm12,%ymm12
	vpand	%ymm15,%ymm8,%ymm8
	vpermq	$0x93,%ymm13,%ymm13

	vpblendd	$3,%ymm9,%ymm14,%ymm10
	vpermq	$0x93,%ymm0,%ymm0
	vpblendd	$3,%ymm14,%ymm11,%ymm14
	vpaddq	%ymm10,%ymm4,%ymm4
	vpblendd	$3,%ymm11,%ymm12,%ymm11
	vpaddq	%ymm14,%ymm5,%ymm5
	vpblendd	$3,%ymm12,%ymm13,%ymm12
	vpaddq	%ymm11,%ymm6,%ymm6
	vpblendd	$3,%ymm13,%ymm0,%ymm13
	vpaddq	%ymm12,%ymm7,%ymm7
	vpaddq	%ymm13,%ymm8,%ymm8

	vpsrlq	$29,%ymm4,%ymm14
	vpand	%ymm15,%ymm4,%ymm4
	vpsrlq	$29,%ymm5,%ymm11
	vpand	%ymm15,%ymm5,%ymm5
	vpsrlq	$29,%ymm6,%ymm12
	vpermq	$0x93,%ymm14,%ymm14
	vpand	%ymm15,%ymm6,%ymm6
	vpsrlq	$29,%ymm7,%ymm13
	vpermq	$0x93,%ymm11,%ymm11
	vpand	%ymm15,%ymm7,%ymm7
	vpsrlq	$29,%ymm8,%ymm0
	vpermq	$0x93,%ymm12,%ymm12
	vpand	%ymm15,%ymm8,%ymm8
	vpermq	$0x93,%ymm13,%ymm13

	vpblendd	$3,%ymm9,%ymm14,%ymm10
	vpermq	$0x93,%ymm0,%ymm0
	vpblendd	$3,%ymm14,%ymm11,%ymm14
	vpaddq	%ymm10,%ymm4,%ymm4
	vpblendd	$3,%ymm11,%ymm12,%ymm11
	vpaddq	%ymm14,%ymm5,%ymm5
	vmovdqu	%ymm4,128-128(%rdi)
	vpblendd	$3,%ymm12,%ymm13,%ymm12
	vpaddq	%ymm11,%ymm6,%ymm6
	vmovdqu	%ymm5,160-128(%rdi)
	vpblendd	$3,%ymm13,%ymm0,%ymm13
	vpaddq	%ymm12,%ymm7,%ymm7
	vmovdqu	%ymm6,192-128(%rdi)
	vpaddq	%ymm13,%ymm8,%ymm8
	vmovdqu	%ymm7,224-128(%rdi)
	vmovdqu	%ymm8,256-128(%rdi)

	movq	%rdi,%rsi
	decl	%r8d
	jne	.LOOP_GRANDE_SQR_1024

	vzeroall
	movq	%rbp,%rax
.cfi_def_cfa_register	%rax
	movq	-48(%rax),%r15
.cfi_restore	%r15
	movq	-40(%rax),%r14
.cfi_restore	%r14
	movq	-32(%rax),%r13
.cfi_restore	%r13
	movq	-24(%rax),%r12
.cfi_restore	%r12
	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lsqr_1024_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	rsaz_1024_sqr_avx2,.-rsaz_1024_sqr_avx2
.globl	rsaz_1024_mul_avx2
.type	rsaz_1024_mul_avx2,@function
.align	64
rsaz_1024_mul_avx2:
.cfi_startproc	
	leaq	(%rsp),%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
	movq	%rax,%rbp
.cfi_def_cfa_register	%rbp
	vzeroall
	movq	%rdx,%r13
	subq	$64,%rsp






.byte	0x67,0x67
	movq	%rsi,%r15
	andq	$4095,%r15
	addq	$320,%r15
	shrq	$12,%r15
	movq	%rsi,%r15
	cmovnzq	%r13,%rsi
	cmovnzq	%r15,%r13

	movq	%rcx,%r15
	subq	$-128,%rsi
	subq	$-128,%rcx
	subq	$-128,%rdi

	andq	$4095,%r15
	addq	$320,%r15
.byte	0x67,0x67
	shrq	$12,%r15
	jz	.Lmul_1024_no_n_copy





	subq	$320,%rsp
	vmovdqu	0-128(%rcx),%ymm0
	andq	$-512,%rsp
	vmovdqu	32-128(%rcx),%ymm1
	vmovdqu	64-128(%rcx),%ymm2
	vmovdqu	96-128(%rcx),%ymm3
	vmovdqu	128-128(%rcx),%ymm4
	vmovdqu	160-128(%rcx),%ymm5
	vmovdqu	192-128(%rcx),%ymm6
	vmovdqu	224-128(%rcx),%ymm7
	vmovdqu	256-128(%rcx),%ymm8
	leaq	64+128(%rsp),%rcx
	vmovdqu	%ymm0,0-128(%rcx)
	vpxor	%ymm0,%ymm0,%ymm0
	vmovdqu	%ymm1,32-128(%rcx)
	vpxor	%ymm1,%ymm1,%ymm1
	vmovdqu	%ymm2,64-128(%rcx)
	vpxor	%ymm2,%ymm2,%ymm2
	vmovdqu	%ymm3,96-128(%rcx)
	vpxor	%ymm3,%ymm3,%ymm3
	vmovdqu	%ymm4,128-128(%rcx)
	vpxor	%ymm4,%ymm4,%ymm4
	vmovdqu	%ymm5,160-128(%rcx)
	vpxor	%ymm5,%ymm5,%ymm5
	vmovdqu	%ymm6,192-128(%rcx)
	vpxor	%ymm6,%ymm6,%ymm6
	vmovdqu	%ymm7,224-128(%rcx)
	vpxor	%ymm7,%ymm7,%ymm7
	vmovdqu	%ymm8,256-128(%rcx)
	vmovdqa	%ymm0,%ymm8
	vmovdqu	%ymm9,288-128(%rcx)
.Lmul_1024_no_n_copy:
	andq	$-64,%rsp

	movq	(%r13),%rbx
	vpbroadcastq	(%r13),%ymm10
	vmovdqu	%ymm0,(%rsp)
	xorq	%r9,%r9
.byte	0x67
	xorq	%r10,%r10
	xorq	%r11,%r11
	xorq	%r12,%r12

	vmovdqu	.Land_mask(%rip),%ymm15
	movl	$9,%r14d
	vmovdqu	%ymm9,288-128(%rdi)
	jmp	.Loop_mul_1024

.align	32
.Loop_mul_1024:
	vpsrlq	$29,%ymm3,%ymm9
	movq	%rbx,%rax
	imulq	-128(%rsi),%rax
	addq	%r9,%rax
	movq	%rbx,%r10
	imulq	8-128(%rsi),%r10
	addq	8(%rsp),%r10

	movq	%rax,%r9
	imull	%r8d,%eax
	andl	$0x1fffffff,%eax

	movq	%rbx,%r11
	imulq	16-128(%rsi),%r11
	addq	16(%rsp),%r11

	movq	%rbx,%r12
	imulq	24-128(%rsi),%r12
	addq	24(%rsp),%r12
	vpmuludq	32-128(%rsi),%ymm10,%ymm0
	vmovd	%eax,%xmm11
	vpaddq	%ymm0,%ymm1,%ymm1
	vpmuludq	64-128(%rsi),%ymm10,%ymm12
	vpbroadcastq	%xmm11,%ymm11
	vpaddq	%ymm12,%ymm2,%ymm2
	vpmuludq	96-128(%rsi),%ymm10,%ymm13
	vpand	%ymm15,%ymm3,%ymm3
	vpaddq	%ymm13,%ymm3,%ymm3
	vpmuludq	128-128(%rsi),%ymm10,%ymm0
	vpaddq	%ymm0,%ymm4,%ymm4
	vpmuludq	160-128(%rsi),%ymm10,%ymm12
	vpaddq	%ymm12,%ymm5,%ymm5
	vpmuludq	192-128(%rsi),%ymm10,%ymm13
	vpaddq	%ymm13,%ymm6,%ymm6
	vpmuludq	224-128(%rsi),%ymm10,%ymm0
	vpermq	$0x93,%ymm9,%ymm9
	vpaddq	%ymm0,%ymm7,%ymm7
	vpmuludq	256-128(%rsi),%ymm10,%ymm12
	vpbroadcastq	8(%r13),%ymm10
	vpaddq	%ymm12,%ymm8,%ymm8

	movq	%rax,%rdx
	imulq	-128(%rcx),%rax
	addq	%rax,%r9
	movq	%rdx,%rax
	imulq	8-128(%rcx),%rax
	addq	%rax,%r10
	movq	%rdx,%rax
	imulq	16-128(%rcx),%rax
	addq	%rax,%r11
	shrq	$29,%r9
	imulq	24-128(%rcx),%rdx
	addq	%rdx,%r12
	addq	%r9,%r10

	vpmuludq	32-128(%rcx),%ymm11,%ymm13
	vmovq	%xmm10,%rbx
	vpaddq	%ymm13,%ymm1,%ymm1
	vpmuludq	64-128(%rcx),%ymm11,%ymm0
	vpaddq	%ymm0,%ymm2,%ymm2
	vpmuludq	96-128(%rcx),%ymm11,%ymm12
	vpaddq	%ymm12,%ymm3,%ymm3
	vpmuludq	128-128(%rcx),%ymm11,%ymm13
	vpaddq	%ymm13,%ymm4,%ymm4
	vpmuludq	160-128(%rcx),%ymm11,%ymm0
	vpaddq	%ymm0,%ymm5,%ymm5
	vpmuludq	192-128(%rcx),%ymm11,%ymm12
	vpaddq	%ymm12,%ymm6,%ymm6
	vpmuludq	224-128(%rcx),%ymm11,%ymm13
	vpblendd	$3,%ymm14,%ymm9,%ymm12
	vpaddq	%ymm13,%ymm7,%ymm7
	vpmuludq	256-128(%rcx),%ymm11,%ymm0
	vpaddq	%ymm12,%ymm3,%ymm3
	vpaddq	%ymm0,%ymm8,%ymm8

	movq	%rbx,%rax
	imulq	-128(%rsi),%rax
	addq	%rax,%r10
	vmovdqu	-8+32-128(%rsi),%ymm12
	movq	%rbx,%rax
	imulq	8-128(%rsi),%rax
	addq	%rax,%r11
	vmovdqu	-8+64-128(%rsi),%ymm13

	movq	%r10,%rax
	vpblendd	$0xfc,%ymm14,%ymm9,%ymm9
	imull	%r8d,%eax
	vpaddq	%ymm9,%ymm4,%ymm4
	andl	$0x1fffffff,%eax

	imulq	16-128(%rsi),%rbx
	addq	%rbx,%r12
	vpmuludq	%ymm10,%ymm12,%ymm12
	vmovd	%eax,%xmm11
	vmovdqu	-8+96-128(%rsi),%ymm0
	vpaddq	%ymm12,%ymm1,%ymm1
	vpmuludq	%ymm10,%ymm13,%ymm13
	vpbroadcastq	%xmm11,%ymm11
	vmovdqu	-8+128-128(%rsi),%ymm12
	vpaddq	%ymm13,%ymm2,%ymm2
	vpmuludq	%ymm10,%ymm0,%ymm0
	vmovdqu	-8+160-128(%rsi),%ymm13
	vpaddq	%ymm0,%ymm3,%ymm3
	vpmuludq	%ymm10,%ymm12,%ymm12
	vmovdqu	-8+192-128(%rsi),%ymm0
	vpaddq	%ymm12,%ymm4,%ymm4
	vpmuludq	%ymm10,%ymm13,%ymm13
	vmovdqu	-8+224-128(%rsi),%ymm12
	vpaddq	%ymm13,%ymm5,%ymm5
	vpmuludq	%ymm10,%ymm0,%ymm0
	vmovdqu	-8+256-128(%rsi),%ymm13
	vpaddq	%ymm0,%ymm6,%ymm6
	vpmuludq	%ymm10,%ymm12,%ymm12
	vmovdqu	-8+288-128(%rsi),%ymm9
	vpaddq	%ymm12,%ymm7,%ymm7
	vpmuludq	%ymm10,%ymm13,%ymm13
	vpaddq	%ymm13,%ymm8,%ymm8
	vpmuludq	%ymm10,%ymm9,%ymm9
	vpbroadcastq	16(%r13),%ymm10

	movq	%rax,%rdx
	imulq	-128(%rcx),%rax
	addq	%rax,%r10
	vmovdqu	-8+32-128(%rcx),%ymm0
	movq	%rdx,%rax
	imulq	8-128(%rcx),%rax
	addq	%rax,%r11
	vmovdqu	-8+64-128(%rcx),%ymm12
	shrq	$29,%r10
	imulq	16-128(%rcx),%rdx
	addq	%rdx,%r12
	addq	%r10,%r11

	vpmuludq	%ymm11,%ymm0,%ymm0
	vmovq	%xmm10,%rbx
	vmovdqu	-8+96-128(%rcx),%ymm13
	vpaddq	%ymm0,%ymm1,%ymm1
	vpmuludq	%ymm11,%ymm12,%ymm12
	vmovdqu	-8+128-128(%rcx),%ymm0
	vpaddq	%ymm12,%ymm2,%ymm2
	vpmuludq	%ymm11,%ymm13,%ymm13
	vmovdqu	-8+160-128(%rcx),%ymm12
	vpaddq	%ymm13,%ymm3,%ymm3
	vpmuludq	%ymm11,%ymm0,%ymm0
	vmovdqu	-8+192-128(%rcx),%ymm13
	vpaddq	%ymm0,%ymm4,%ymm4
	vpmuludq	%ymm11,%ymm12,%ymm12
	vmovdqu	-8+224-128(%rcx),%ymm0
	vpaddq	%ymm12,%ymm5,%ymm5
	vpmuludq	%ymm11,%ymm13,%ymm13
	vmovdqu	-8+256-128(%rcx),%ymm12
	vpaddq	%ymm13,%ymm6,%ymm6
	vpmuludq	%ymm11,%ymm0,%ymm0
	vmovdqu	-8+288-128(%rcx),%ymm13
	vpaddq	%ymm0,%ymm7,%ymm7
	vpmuludq	%ymm11,%ymm12,%ymm12
	vpaddq	%ymm12,%ymm8,%ymm8
	vpmuludq	%ymm11,%ymm13,%ymm13
	vpaddq	%ymm13,%ymm9,%ymm9

	vmovdqu	-16+32-128(%rsi),%ymm0
	movq	%rbx,%rax
	imulq	-128(%rsi),%rax
	addq	%r11,%rax

	vmovdqu	-16+64-128(%rsi),%ymm12
	movq	%rax,%r11
	imull	%r8d,%eax
	andl	$0x1fffffff,%eax

	imulq	8-128(%rsi),%rbx
	addq	%rbx,%r12
	vpmuludq	%ymm10,%ymm0,%ymm0
	vmovd	%eax,%xmm11
	vmovdqu	-16+96-128(%rsi),%ymm13
	vpaddq	%ymm0,%ymm1,%ymm1
	vpmuludq	%ymm10,%ymm12,%ymm12
	vpbroadcastq	%xmm11,%ymm11
	vmovdqu	-16+128-128(%rsi),%ymm0
	vpaddq	%ymm12,%ymm2,%ymm2
	vpmuludq	%ymm10,%ymm13,%ymm13
	vmovdqu	-16+160-128(%rsi),%ymm12
	vpaddq	%ymm13,%ymm3,%ymm3
	vpmuludq	%ymm10,%ymm0,%ymm0
	vmovdqu	-16+192-128(%rsi),%ymm13
	vpaddq	%ymm0,%ymm4,%ymm4
	vpmuludq	%ymm10,%ymm12,%ymm12
	vmovdqu	-16+224-128(%rsi),%ymm0
	vpaddq	%ymm12,%ymm5,%ymm5
	vpmuludq	%ymm10,%ymm13,%ymm13
	vmovdqu	-16+256-128(%rsi),%ymm12
	vpaddq	%ymm13,%ymm6,%ymm6
	vpmuludq	%ymm10,%ymm0,%ymm0
	vmovdqu	-16+288-128(%rsi),%ymm13
	vpaddq	%ymm0,%ymm7,%ymm7
	vpmuludq	%ymm10,%ymm12,%ymm12
	vpaddq	%ymm12,%ymm8,%ymm8
	vpmuludq	%ymm10,%ymm13,%ymm13
	vpbroadcastq	24(%r13),%ymm10
	vpaddq	%ymm13,%ymm9,%ymm9

	vmovdqu	-16+32-128(%rcx),%ymm0
	movq	%rax,%rdx
	imulq	-128(%rcx),%rax
	addq	%rax,%r11
	vmovdqu	-16+64-128(%rcx),%ymm12
	imulq	8-128(%rcx),%rdx
	addq	%rdx,%r12
	shrq	$29,%r11

	vpmuludq	%ymm11,%ymm0,%ymm0
	vmovq	%xmm10,%rbx
	vmovdqu	-16+96-128(%rcx),%ymm13
	vpaddq	%ymm0,%ymm1,%ymm1
	vpmuludq	%ymm11,%ymm12,%ymm12
	vmovdqu	-16+128-128(%rcx),%ymm0
	vpaddq	%ymm12,%ymm2,%ymm2
	vpmuludq	%ymm11,%ymm13,%ymm13
	vmovdqu	-16+160-128(%rcx),%ymm12
	vpaddq	%ymm13,%ymm3,%ymm3
	vpmuludq	%ymm11,%ymm0,%ymm0
	vmovdqu	-16+192-128(%rcx),%ymm13
	vpaddq	%ymm0,%ymm4,%ymm4
	vpmuludq	%ymm11,%ymm12,%ymm12
	vmovdqu	-16+224-128(%rcx),%ymm0
	vpaddq	%ymm12,%ymm5,%ymm5
	vpmuludq	%ymm11,%ymm13,%ymm13
	vmovdqu	-16+256-128(%rcx),%ymm12
	vpaddq	%ymm13,%ymm6,%ymm6
	vpmuludq	%ymm11,%ymm0,%ymm0
	vmovdqu	-16+288-128(%rcx),%ymm13
	vpaddq	%ymm0,%ymm7,%ymm7
	vpmuludq	%ymm11,%ymm12,%ymm12
	vmovdqu	-24+32-128(%rsi),%ymm0
	vpaddq	%ymm12,%ymm8,%ymm8
	vpmuludq	%ymm11,%ymm13,%ymm13
	vmovdqu	-24+64-128(%rsi),%ymm12
	vpaddq	%ymm13,%ymm9,%ymm9

	addq	%r11,%r12
	imulq	-128(%rsi),%rbx
	addq	%rbx,%r12

	movq	%r12,%rax
	imull	%r8d,%eax
	andl	$0x1fffffff,%eax

	vpmuludq	%ymm10,%ymm0,%ymm0
	vmovd	%eax,%xmm11
	vmovdqu	-24+96-128(%rsi),%ymm13
	vpaddq	%ymm0,%ymm1,%ymm1
	vpmuludq	%ymm10,%ymm12,%ymm12
	vpbroadcastq	%xmm11,%ymm11
	vmovdqu	-24+128-128(%rsi),%ymm0
	vpaddq	%ymm12,%ymm2,%ymm2
	vpmuludq	%ymm10,%ymm13,%ymm13
	vmovdqu	-24+160-128(%rsi),%ymm12
	vpaddq	%ymm13,%ymm3,%ymm3
	vpmuludq	%ymm10,%ymm0,%ymm0
	vmovdqu	-24+192-128(%rsi),%ymm13
	vpaddq	%ymm0,%ymm4,%ymm4
	vpmuludq	%ymm10,%ymm12,%ymm12
	vmovdqu	-24+224-128(%rsi),%ymm0
	vpaddq	%ymm12,%ymm5,%ymm5
	vpmuludq	%ymm10,%ymm13,%ymm13
	vmovdqu	-24+256-128(%rsi),%ymm12
	vpaddq	%ymm13,%ymm6,%ymm6
	vpmuludq	%ymm10,%ymm0,%ymm0
	vmovdqu	-24+288-128(%rsi),%ymm13
	vpaddq	%ymm0,%ymm7,%ymm7
	vpmuludq	%ymm10,%ymm12,%ymm12
	vpaddq	%ymm12,%ymm8,%ymm8
	vpmuludq	%ymm10,%ymm13,%ymm13
	vpbroadcastq	32(%r13),%ymm10
	vpaddq	%ymm13,%ymm9,%ymm9
	addq	$32,%r13

	vmovdqu	-24+32-128(%rcx),%ymm0
	imulq	-128(%rcx),%rax
	addq	%rax,%r12
	shrq	$29,%r12

	vmovdqu	-24+64-128(%rcx),%ymm12
	vpmuludq	%ymm11,%ymm0,%ymm0
	vmovq	%xmm10,%rbx
	vmovdqu	-24+96-128(%rcx),%ymm13
	vpaddq	%ymm0,%ymm1,%ymm0
	vpmuludq	%ymm11,%ymm12,%ymm12
	vmovdqu	%ymm0,(%rsp)
	vpaddq	%ymm12,%ymm2,%ymm1
	vmovdqu	-24+128-128(%rcx),%ymm0
	vpmuludq	%ymm11,%ymm13,%ymm13
	vmovdqu	-24+160-128(%rcx),%ymm12
	vpaddq	%ymm13,%ymm3,%ymm2
	vpmuludq	%ymm11,%ymm0,%ymm0
	vmovdqu	-24+192-128(%rcx),%ymm13
	vpaddq	%ymm0,%ymm4,%ymm3
	vpmuludq	%ymm11,%ymm12,%ymm12
	vmovdqu	-24+224-128(%rcx),%ymm0
	vpaddq	%ymm12,%ymm5,%ymm4
	vpmuludq	%ymm11,%ymm13,%ymm13
	vmovdqu	-24+256-128(%rcx),%ymm12
	vpaddq	%ymm13,%ymm6,%ymm5
	vpmuludq	%ymm11,%ymm0,%ymm0
	vmovdqu	-24+288-128(%rcx),%ymm13
	movq	%r12,%r9
	vpaddq	%ymm0,%ymm7,%ymm6
	vpmuludq	%ymm11,%ymm12,%ymm12
	addq	(%rsp),%r9
	vpaddq	%ymm12,%ymm8,%ymm7
	vpmuludq	%ymm11,%ymm13,%ymm13
	vmovq	%r12,%xmm12
	vpaddq	%ymm13,%ymm9,%ymm8

	decl	%r14d
	jnz	.Loop_mul_1024
	vpaddq	(%rsp),%ymm12,%ymm0

	vpsrlq	$29,%ymm0,%ymm12
	vpand	%ymm15,%ymm0,%ymm0
	vpsrlq	$29,%ymm1,%ymm13
	vpand	%ymm15,%ymm1,%ymm1
	vpsrlq	$29,%ymm2,%ymm10
	vpermq	$0x93,%ymm12,%ymm12
	vpand	%ymm15,%ymm2,%ymm2
	vpsrlq	$29,%ymm3,%ymm11
	vpermq	$0x93,%ymm13,%ymm13
	vpand	%ymm15,%ymm3,%ymm3

	vpblendd	$3,%ymm14,%ymm12,%ymm9
	vpermq	$0x93,%ymm10,%ymm10
	vpblendd	$3,%ymm12,%ymm13,%ymm12
	vpermq	$0x93,%ymm11,%ymm11
	vpaddq	%ymm9,%ymm0,%ymm0
	vpblendd	$3,%ymm13,%ymm10,%ymm13
	vpaddq	%ymm12,%ymm1,%ymm1
	vpblendd	$3,%ymm10,%ymm11,%ymm10
	vpaddq	%ymm13,%ymm2,%ymm2
	vpblendd	$3,%ymm11,%ymm14,%ymm11
	vpaddq	%ymm10,%ymm3,%ymm3
	vpaddq	%ymm11,%ymm4,%ymm4

	vpsrlq	$29,%ymm0,%ymm12
	vpand	%ymm15,%ymm0,%ymm0
	vpsrlq	$29,%ymm1,%ymm13
	vpand	%ymm15,%ymm1,%ymm1
	vpsrlq	$29,%ymm2,%ymm10
	vpermq	$0x93,%ymm12,%ymm12
	vpand	%ymm15,%ymm2,%ymm2
	vpsrlq	$29,%ymm3,%ymm11
	vpermq	$0x93,%ymm13,%ymm13
	vpand	%ymm15,%ymm3,%ymm3
	vpermq	$0x93,%ymm10,%ymm10

	vpblendd	$3,%ymm14,%ymm12,%ymm9
	vpermq	$0x93,%ymm11,%ymm11
	vpblendd	$3,%ymm12,%ymm13,%ymm12
	vpaddq	%ymm9,%ymm0,%ymm0
	vpblendd	$3,%ymm13,%ymm10,%ymm13
	vpaddq	%ymm12,%ymm1,%ymm1
	vpblendd	$3,%ymm10,%ymm11,%ymm10
	vpaddq	%ymm13,%ymm2,%ymm2
	vpblendd	$3,%ymm11,%ymm14,%ymm11
	vpaddq	%ymm10,%ymm3,%ymm3
	vpaddq	%ymm11,%ymm4,%ymm4

	vmovdqu	%ymm0,0-128(%rdi)
	vmovdqu	%ymm1,32-128(%rdi)
	vmovdqu	%ymm2,64-128(%rdi)
	vmovdqu	%ymm3,96-128(%rdi)
	vpsrlq	$29,%ymm4,%ymm12
	vpand	%ymm15,%ymm4,%ymm4
	vpsrlq	$29,%ymm5,%ymm13
	vpand	%ymm15,%ymm5,%ymm5
	vpsrlq	$29,%ymm6,%ymm10
	vpermq	$0x93,%ymm12,%ymm12
	vpand	%ymm15,%ymm6,%ymm6
	vpsrlq	$29,%ymm7,%ymm11
	vpermq	$0x93,%ymm13,%ymm13
	vpand	%ymm15,%ymm7,%ymm7
	vpsrlq	$29,%ymm8,%ymm0
	vpermq	$0x93,%ymm10,%ymm10
	vpand	%ymm15,%ymm8,%ymm8
	vpermq	$0x93,%ymm11,%ymm11

	vpblendd	$3,%ymm14,%ymm12,%ymm9
	vpermq	$0x93,%ymm0,%ymm0
	vpblendd	$3,%ymm12,%ymm13,%ymm12
	vpaddq	%ymm9,%ymm4,%ymm4
	vpblendd	$3,%ymm13,%ymm10,%ymm13
	vpaddq	%ymm12,%ymm5,%ymm5
	vpblendd	$3,%ymm10,%ymm11,%ymm10
	vpaddq	%ymm13,%ymm6,%ymm6
	vpblendd	$3,%ymm11,%ymm0,%ymm11
	vpaddq	%ymm10,%ymm7,%ymm7
	vpaddq	%ymm11,%ymm8,%ymm8

	vpsrlq	$29,%ymm4,%ymm12
	vpand	%ymm15,%ymm4,%ymm4
	vpsrlq	$29,%ymm5,%ymm13
	vpand	%ymm15,%ymm5,%ymm5
	vpsrlq	$29,%ymm6,%ymm10
	vpermq	$0x93,%ymm12,%ymm12
	vpand	%ymm15,%ymm6,%ymm6
	vpsrlq	$29,%ymm7,%ymm11
	vpermq	$0x93,%ymm13,%ymm13
	vpand	%ymm15,%ymm7,%ymm7
	vpsrlq	$29,%ymm8,%ymm0
	vpermq	$0x93,%ymm10,%ymm10
	vpand	%ymm15,%ymm8,%ymm8
	vpermq	$0x93,%ymm11,%ymm11

	vpblendd	$3,%ymm14,%ymm12,%ymm9
	vpermq	$0x93,%ymm0,%ymm0
	vpblendd	$3,%ymm12,%ymm13,%ymm12
	vpaddq	%ymm9,%ymm4,%ymm4
	vpblendd	$3,%ymm13,%ymm10,%ymm13
	vpaddq	%ymm12,%ymm5,%ymm5
	vpblendd	$3,%ymm10,%ymm11,%ymm10
	vpaddq	%ymm13,%ymm6,%ymm6
	vpblendd	$3,%ymm11,%ymm0,%ymm11
	vpaddq	%ymm10,%ymm7,%ymm7
	vpaddq	%ymm11,%ymm8,%ymm8

	vmovdqu	%ymm4,128-128(%rdi)
	vmovdqu	%ymm5,160-128(%rdi)
	vmovdqu	%ymm6,192-128(%rdi)
	vmovdqu	%ymm7,224-128(%rdi)
	vmovdqu	%ymm8,256-128(%rdi)
	vzeroupper

	movq	%rbp,%rax
.cfi_def_cfa_register	%rax
	movq	-48(%rax),%r15
.cfi_restore	%r15
	movq	-40(%rax),%r14
.cfi_restore	%r14
	movq	-32(%rax),%r13
.cfi_restore	%r13
	movq	-24(%rax),%r12
.cfi_restore	%r12
	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lmul_1024_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	rsaz_1024_mul_avx2,.-rsaz_1024_mul_avx2
.globl	rsaz_1024_red2norm_avx2
.type	rsaz_1024_red2norm_avx2,@function
.align	32
rsaz_1024_red2norm_avx2:
.cfi_startproc	
	subq	$-128,%rsi
	xorq	%rax,%rax
	movq	-128(%rsi),%r8
	movq	-120(%rsi),%r9
	movq	-112(%rsi),%r10
	shlq	$0,%r8
	shlq	$29,%r9
	movq	%r10,%r11
	shlq	$58,%r10
	shrq	$6,%r11
	addq	%r8,%rax
	addq	%r9,%rax
	addq	%r10,%rax
	adcq	$0,%r11
	movq	%rax,0(%rdi)
	movq	%r11,%rax
	movq	-104(%rsi),%r8
	movq	-96(%rsi),%r9
	shlq	$23,%r8
	movq	%r9,%r10
	shlq	$52,%r9
	shrq	$12,%r10
	addq	%r8,%rax
	addq	%r9,%rax
	adcq	$0,%r10
	movq	%rax,8(%rdi)
	movq	%r10,%rax
	movq	-88(%rsi),%r11
	movq	-80(%rsi),%r8
	shlq	$17,%r11
	movq	%r8,%r9
	shlq	$46,%r8
	shrq	$18,%r9
	addq	%r11,%rax
	addq	%r8,%rax
	adcq	$0,%r9
	movq	%rax,16(%rdi)
	movq	%r9,%rax
	movq	-72(%rsi),%r10
	movq	-64(%rsi),%r11
	shlq	$11,%r10
	movq	%r11,%r8
	shlq	$40,%r11
	shrq	$24,%r8
	addq	%r10,%rax
	addq	%r11,%rax
	adcq	$0,%r8
	movq	%rax,24(%rdi)
	movq	%r8,%rax
	movq	-56(%rsi),%r9
	movq	-48(%rsi),%r10
	movq	-40(%rsi),%r11
	shlq	$5,%r9
	shlq	$34,%r10
	movq	%r11,%r8
	shlq	$63,%r11
	shrq	$1,%r8
	addq	%r9,%rax
	addq	%r10,%rax
	addq	%r11,%rax
	adcq	$0,%r8
	movq	%rax,32(%rdi)
	movq	%r8,%rax
	movq	-32(%rsi),%r9
	movq	-24(%rsi),%r10
	shlq	$28,%r9
	movq	%r10,%r11
	shlq	$57,%r10
	shrq	$7,%r11
	addq	%r9,%rax
	addq	%r10,%rax
	adcq	$0,%r11
	movq	%rax,40(%rdi)
	movq	%r11,%rax
	movq	-16(%rsi),%r8
	movq	-8(%rsi),%r9
	shlq	$22,%r8
	movq	%r9,%r10
	shlq	$51,%r9
	shrq	$13,%r10
	addq	%r8,%rax
	addq	%r9,%rax
	adcq	$0,%r10
	movq	%rax,48(%rdi)
	movq	%r10,%rax
	movq	0(%rsi),%r11
	movq	8(%rsi),%r8
	shlq	$16,%r11
	movq	%r8,%r9
	shlq	$45,%r8
	shrq	$19,%r9
	addq	%r11,%rax
	addq	%r8,%rax
	adcq	$0,%r9
	movq	%rax,56(%rdi)
	movq	%r9,%rax
	movq	16(%rsi),%r10
	movq	24(%rsi),%r11
	shlq	$10,%r10
	movq	%r11,%r8
	shlq	$39,%r11
	shrq	$25,%r8
	addq	%r10,%rax
	addq	%r11,%rax
	adcq	$0,%r8
	movq	%rax,64(%rdi)
	movq	%r8,%rax
	movq	32(%rsi),%r9
	movq	40(%rsi),%r10
	movq	48(%rsi),%r11
	shlq	$4,%r9
	shlq	$33,%r10
	movq	%r11,%r8
	shlq	$62,%r11
	shrq	$2,%r8
	addq	%r9,%rax
	addq	%r10,%rax
	addq	%r11,%rax
	adcq	$0,%r8
	movq	%rax,72(%rdi)
	movq	%r8,%rax
	movq	56(%rsi),%r9
	movq	64(%rsi),%r10
	shlq	$27,%r9
	movq	%r10,%r11
	shlq	$56,%r10
	shrq	$8,%r11
	addq	%r9,%rax
	addq	%r10,%rax
	adcq	$0,%r11
	movq	%rax,80(%rdi)
	movq	%r11,%rax
	movq	72(%rsi),%r8
	movq	80(%rsi),%r9
	shlq	$21,%r8
	movq	%r9,%r10
	shlq	$50,%r9
	shrq	$14,%r10
	addq	%r8,%rax
	addq	%r9,%rax
	adcq	$0,%r10
	movq	%rax,88(%rdi)
	movq	%r10,%rax
	movq	88(%rsi),%r11
	movq	96(%rsi),%r8
	shlq	$15,%r11
	movq	%r8,%r9
	shlq	$44,%r8
	shrq	$20,%r9
	addq	%r11,%rax
	addq	%r8,%rax
	adcq	$0,%r9
	movq	%rax,96(%rdi)
	movq	%r9,%rax
	movq	104(%rsi),%r10
	movq	112(%rsi),%r11
	shlq	$9,%r10
	movq	%r11,%r8
	shlq	$38,%r11
	shrq	$26,%r8
	addq	%r10,%rax
	addq	%r11,%rax
	adcq	$0,%r8
	movq	%rax,104(%rdi)
	movq	%r8,%rax
	movq	120(%rsi),%r9
	movq	128(%rsi),%r10
	movq	136(%rsi),%r11
	shlq	$3,%r9
	shlq	$32,%r10
	movq	%r11,%r8
	shlq	$61,%r11
	shrq	$3,%r8
	addq	%r9,%rax
	addq	%r10,%rax
	addq	%r11,%rax
	adcq	$0,%r8
	movq	%rax,112(%rdi)
	movq	%r8,%rax
	movq	144(%rsi),%r9
	movq	152(%rsi),%r10
	shlq	$26,%r9
	movq	%r10,%r11
	shlq	$55,%r10
	shrq	$9,%r11
	addq	%r9,%rax
	addq	%r10,%rax
	adcq	$0,%r11
	movq	%rax,120(%rdi)
	movq	%r11,%rax
	.byte	0xf3,0xc3
.cfi_endproc	
.size	rsaz_1024_red2norm_avx2,.-rsaz_1024_red2norm_avx2

.globl	rsaz_1024_norm2red_avx2
.type	rsaz_1024_norm2red_avx2,@function
.align	32
rsaz_1024_norm2red_avx2:
.cfi_startproc	
	subq	$-128,%rdi
	movq	(%rsi),%r8
	movl	$0x1fffffff,%eax
	movq	8(%rsi),%r9
	movq	%r8,%r11
	shrq	$0,%r11
	andq	%rax,%r11
	movq	%r11,-128(%rdi)
	movq	%r8,%r10
	shrq	$29,%r10
	andq	%rax,%r10
	movq	%r10,-120(%rdi)
	shrdq	$58,%r9,%r8
	andq	%rax,%r8
	movq	%r8,-112(%rdi)
	movq	16(%rsi),%r10
	movq	%r9,%r8
	shrq	$23,%r8
	andq	%rax,%r8
	movq	%r8,-104(%rdi)
	shrdq	$52,%r10,%r9
	andq	%rax,%r9
	movq	%r9,-96(%rdi)
	movq	24(%rsi),%r11
	movq	%r10,%r9
	shrq	$17,%r9
	andq	%rax,%r9
	movq	%r9,-88(%rdi)
	shrdq	$46,%r11,%r10
	andq	%rax,%r10
	movq	%r10,-80(%rdi)
	movq	32(%rsi),%r8
	movq	%r11,%r10
	shrq	$11,%r10
	andq	%rax,%r10
	movq	%r10,-72(%rdi)
	shrdq	$40,%r8,%r11
	andq	%rax,%r11
	movq	%r11,-64(%rdi)
	movq	40(%rsi),%r9
	movq	%r8,%r11
	shrq	$5,%r11
	andq	%rax,%r11
	movq	%r11,-56(%rdi)
	movq	%r8,%r10
	shrq	$34,%r10
	andq	%rax,%r10
	movq	%r10,-48(%rdi)
	shrdq	$63,%r9,%r8
	andq	%rax,%r8
	movq	%r8,-40(%rdi)
	movq	48(%rsi),%r10
	movq	%r9,%r8
	shrq	$28,%r8
	andq	%rax,%r8
	movq	%r8,-32(%rdi)
	shrdq	$57,%r10,%r9
	andq	%rax,%r9
	movq	%r9,-24(%rdi)
	movq	56(%rsi),%r11
	movq	%r10,%r9
	shrq	$22,%r9
	andq	%rax,%r9
	movq	%r9,-16(%rdi)
	shrdq	$51,%r11,%r10
	andq	%rax,%r10
	movq	%r10,-8(%rdi)
	movq	64(%rsi),%r8
	movq	%r11,%r10
	shrq	$16,%r10
	andq	%rax,%r10
	movq	%r10,0(%rdi)
	shrdq	$45,%r8,%r11
	andq	%rax,%r11
	movq	%r11,8(%rdi)
	movq	72(%rsi),%r9
	movq	%r8,%r11
	shrq	$10,%r11
	andq	%rax,%r11
	movq	%r11,16(%rdi)
	shrdq	$39,%r9,%r8
	andq	%rax,%r8
	movq	%r8,24(%rdi)
	movq	80(%rsi),%r10
	movq	%r9,%r8
	shrq	$4,%r8
	andq	%rax,%r8
	movq	%r8,32(%rdi)
	movq	%r9,%r11
	shrq	$33,%r11
	andq	%rax,%r11
	movq	%r11,40(%rdi)
	shrdq	$62,%r10,%r9
	andq	%rax,%r9
	movq	%r9,48(%rdi)
	movq	88(%rsi),%r11
	movq	%r10,%r9
	shrq	$27,%r9
	andq	%rax,%r9
	movq	%r9,56(%rdi)
	shrdq	$56,%r11,%r10
	andq	%rax,%r10
	movq	%r10,64(%rdi)
	movq	96(%rsi),%r8
	movq	%r11,%r10
	shrq	$21,%r10
	andq	%rax,%r10
	movq	%r10,72(%rdi)
	shrdq	$50,%r8,%r11
	andq	%rax,%r11
	movq	%r11,80(%rdi)
	movq	104(%rsi),%r9
	movq	%r8,%r11
	shrq	$15,%r11
	andq	%rax,%r11
	movq	%r11,88(%rdi)
	shrdq	$44,%r9,%r8
	andq	%rax,%r8
	movq	%r8,96(%rdi)
	movq	112(%rsi),%r10
	movq	%r9,%r8
	shrq	$9,%r8
	andq	%rax,%r8
	movq	%r8,104(%rdi)
	shrdq	$38,%r10,%r9
	andq	%rax,%r9
	movq	%r9,112(%rdi)
	movq	120(%rsi),%r11
	movq	%r10,%r9
	shrq	$3,%r9
	andq	%rax,%r9
	movq	%r9,120(%rdi)
	movq	%r10,%r8
	shrq	$32,%r8
	andq	%rax,%r8
	movq	%r8,128(%rdi)
	shrdq	$61,%r11,%r10
	andq	%rax,%r10
	movq	%r10,136(%rdi)
	xorq	%r8,%r8
	movq	%r11,%r10
	shrq	$26,%r10
	andq	%rax,%r10
	movq	%r10,144(%rdi)
	shrdq	$55,%r8,%r11
	andq	%rax,%r11
	movq	%r11,152(%rdi)
	movq	%r8,160(%rdi)
	movq	%r8,168(%rdi)
	movq	%r8,176(%rdi)
	movq	%r8,184(%rdi)
	.byte	0xf3,0xc3
.cfi_endproc	
.size	rsaz_1024_norm2red_avx2,.-rsaz_1024_norm2red_avx2
.globl	rsaz_1024_scatter5_avx2
.type	rsaz_1024_scatter5_avx2,@function
.align	32
rsaz_1024_scatter5_avx2:
.cfi_startproc	
	vzeroupper
	vmovdqu	.Lscatter_permd(%rip),%ymm5
	shll	$4,%edx
	leaq	(%rdi,%rdx,1),%rdi
	movl	$9,%eax
	jmp	.Loop_scatter_1024

.align	32
.Loop_scatter_1024:
	vmovdqu	(%rsi),%ymm0
	leaq	32(%rsi),%rsi
	vpermd	%ymm0,%ymm5,%ymm0
	vmovdqu	%xmm0,(%rdi)
	leaq	512(%rdi),%rdi
	decl	%eax
	jnz	.Loop_scatter_1024

	vzeroupper
	.byte	0xf3,0xc3
.cfi_endproc	
.size	rsaz_1024_scatter5_avx2,.-rsaz_1024_scatter5_avx2

.globl	rsaz_1024_gather5_avx2
.type	rsaz_1024_gather5_avx2,@function
.align	32
rsaz_1024_gather5_avx2:
.cfi_startproc	
	vzeroupper
	movq	%rsp,%r11
.cfi_def_cfa_register	%r11
	leaq	-256(%rsp),%rsp
	andq	$-32,%rsp
	leaq	.Linc(%rip),%r10
	leaq	-128(%rsp),%rax

	vmovd	%edx,%xmm4
	vmovdqa	(%r10),%ymm0
	vmovdqa	32(%r10),%ymm1
	vmovdqa	64(%r10),%ymm5
	vpbroadcastd	%xmm4,%ymm4

	vpaddd	%ymm5,%ymm0,%ymm2
	vpcmpeqd	%ymm4,%ymm0,%ymm0
	vpaddd	%ymm5,%ymm1,%ymm3
	vpcmpeqd	%ymm4,%ymm1,%ymm1
	vmovdqa	%ymm0,0+128(%rax)
	vpaddd	%ymm5,%ymm2,%ymm0
	vpcmpeqd	%ymm4,%ymm2,%ymm2
	vmovdqa	%ymm1,32+128(%rax)
	vpaddd	%ymm5,%ymm3,%ymm1
	vpcmpeqd	%ymm4,%ymm3,%ymm3
	vmovdqa	%ymm2,64+128(%rax)
	vpaddd	%ymm5,%ymm0,%ymm2
	vpcmpeqd	%ymm4,%ymm0,%ymm0
	vmovdqa	%ymm3,96+128(%rax)
	vpaddd	%ymm5,%ymm1,%ymm3
	vpcmpeqd	%ymm4,%ymm1,%ymm1
	vmovdqa	%ymm0,128+128(%rax)
	vpaddd	%ymm5,%ymm2,%ymm8
	vpcmpeqd	%ymm4,%ymm2,%ymm2
	vmovdqa	%ymm1,160+128(%rax)
	vpaddd	%ymm5,%ymm3,%ymm9
	vpcmpeqd	%ymm4,%ymm3,%ymm3
	vmovdqa	%ymm2,192+128(%rax)
	vpaddd	%ymm5,%ymm8,%ymm10
	vpcmpeqd	%ymm4,%ymm8,%ymm8
	vmovdqa	%ymm3,224+128(%rax)
	vpaddd	%ymm5,%ymm9,%ymm11
	vpcmpeqd	%ymm4,%ymm9,%ymm9
	vpaddd	%ymm5,%ymm10,%ymm12
	vpcmpeqd	%ymm4,%ymm10,%ymm10
	vpaddd	%ymm5,%ymm11,%ymm13
	vpcmpeqd	%ymm4,%ymm11,%ymm11
	vpaddd	%ymm5,%ymm12,%ymm14
	vpcmpeqd	%ymm4,%ymm12,%ymm12
	vpaddd	%ymm5,%ymm13,%ymm15
	vpcmpeqd	%ymm4,%ymm13,%ymm13
	vpcmpeqd	%ymm4,%ymm14,%ymm14
	vpcmpeqd	%ymm4,%ymm15,%ymm15

	vmovdqa	-32(%r10),%ymm7
	leaq	128(%rsi),%rsi
	movl	$9,%edx

.Loop_gather_1024:
	vmovdqa	0-128(%rsi),%ymm0
	vmovdqa	32-128(%rsi),%ymm1
	vmovdqa	64-128(%rsi),%ymm2
	vmovdqa	96-128(%rsi),%ymm3
	vpand	0+128(%rax),%ymm0,%ymm0
	vpand	32+128(%rax),%ymm1,%ymm1
	vpand	64+128(%rax),%ymm2,%ymm2
	vpor	%ymm0,%ymm1,%ymm4
	vpand	96+128(%rax),%ymm3,%ymm3
	vmovdqa	128-128(%rsi),%ymm0
	vmovdqa	160-128(%rsi),%ymm1
	vpor	%ymm2,%ymm3,%ymm5
	vmovdqa	192-128(%rsi),%ymm2
	vmovdqa	224-128(%rsi),%ymm3
	vpand	128+128(%rax),%ymm0,%ymm0
	vpand	160+128(%rax),%ymm1,%ymm1
	vpand	192+128(%rax),%ymm2,%ymm2
	vpor	%ymm0,%ymm4,%ymm4
	vpand	224+128(%rax),%ymm3,%ymm3
	vpand	256-128(%rsi),%ymm8,%ymm0
	vpor	%ymm1,%ymm5,%ymm5
	vpand	288-128(%rsi),%ymm9,%ymm1
	vpor	%ymm2,%ymm4,%ymm4
	vpand	320-128(%rsi),%ymm10,%ymm2
	vpor	%ymm3,%ymm5,%ymm5
	vpand	352-128(%rsi),%ymm11,%ymm3
	vpor	%ymm0,%ymm4,%ymm4
	vpand	384-128(%rsi),%ymm12,%ymm0
	vpor	%ymm1,%ymm5,%ymm5
	vpand	416-128(%rsi),%ymm13,%ymm1
	vpor	%ymm2,%ymm4,%ymm4
	vpand	448-128(%rsi),%ymm14,%ymm2
	vpor	%ymm3,%ymm5,%ymm5
	vpand	480-128(%rsi),%ymm15,%ymm3
	leaq	512(%rsi),%rsi
	vpor	%ymm0,%ymm4,%ymm4
	vpor	%ymm1,%ymm5,%ymm5
	vpor	%ymm2,%ymm4,%ymm4
	vpor	%ymm3,%ymm5,%ymm5

	vpor	%ymm5,%ymm4,%ymm4
	vextracti128	$1,%ymm4,%xmm5
	vpor	%xmm4,%xmm5,%xmm5
	vpermd	%ymm5,%ymm7,%ymm5
	vmovdqu	%ymm5,(%rdi)
	leaq	32(%rdi),%rdi
	decl	%edx
	jnz	.Loop_gather_1024

	vpxor	%ymm0,%ymm0,%ymm0
	vmovdqu	%ymm0,(%rdi)
	vzeroupper
	leaq	(%r11),%rsp
.cfi_def_cfa_register	%rsp
	.byte	0xf3,0xc3
.cfi_endproc	
.LSEH_end_rsaz_1024_gather5:
.size	rsaz_1024_gather5_avx2,.-rsaz_1024_gather5_avx2

.globl	rsaz_avx2_eligible
.type	rsaz_avx2_eligible,@function
.align	32
rsaz_avx2_eligible:
	movl	OPENSSL_ia32cap_P+8(%rip),%eax
	movl	$524544,%ecx
	movl	$0,%edx
	andl	%eax,%ecx
	cmpl	$524544,%ecx
	cmovel	%edx,%eax
	andl	$32,%eax
	shrl	$5,%eax
	.byte	0xf3,0xc3
.size	rsaz_avx2_eligible,.-rsaz_avx2_eligible

.align	64
.Land_mask:
.quad	0x1fffffff,0x1fffffff,0x1fffffff,0x1fffffff
.Lscatter_permd:
.long	0,2,4,6,7,7,7,7
.Lgather_permd:
.long	0,7,1,7,2,7,3,7
.Linc:
.long	0,0,0,0, 1,1,1,1
.long	2,2,2,2, 3,3,3,3
.long	4,4,4,4, 4,4,4,4
.align	64
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                                                                                                                                                                                                                                         node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/bn/rsaz-avx512.s                      0000664 0000000 0000000 00000042501 14746647661 0026523 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        
.globl	ossl_rsaz_avx512ifma_eligible
.type	ossl_rsaz_avx512ifma_eligible,@function
.align	32
ossl_rsaz_avx512ifma_eligible:
	movl	OPENSSL_ia32cap_P+8(%rip),%ecx
	xorl	%eax,%eax
	andl	$2149777408,%ecx
	cmpl	$2149777408,%ecx
	cmovel	%ecx,%eax
	.byte	0xf3,0xc3
.size	ossl_rsaz_avx512ifma_eligible, .-ossl_rsaz_avx512ifma_eligible
.text	

.globl	ossl_rsaz_amm52x20_x1_256
.type	ossl_rsaz_amm52x20_x1_256,@function
.align	32
ossl_rsaz_amm52x20_x1_256:
.cfi_startproc	
.byte	243,15,30,250
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-56
.Lrsaz_amm52x20_x1_256_body:


	vpxord	%ymm0,%ymm0,%ymm0
	vmovdqa64	%ymm0,%ymm1
	vmovdqa64	%ymm0,%ymm16
	vmovdqa64	%ymm0,%ymm17
	vmovdqa64	%ymm0,%ymm18
	vmovdqa64	%ymm0,%ymm19

	xorl	%r9d,%r9d

	movq	%rdx,%r11
	movq	$0xfffffffffffff,%rax


	movl	$5,%ebx

.align	32
.Lloop5:
	movq	0(%r11),%r13

	vpbroadcastq	%r13,%ymm3
	movq	0(%rsi),%rdx
	mulxq	%r13,%r13,%r12
	addq	%r13,%r9
	movq	%r12,%r10
	adcq	$0,%r10

	movq	%r8,%r13
	imulq	%r9,%r13
	andq	%rax,%r13

	vpbroadcastq	%r13,%ymm4
	movq	0(%rcx),%rdx
	mulxq	%r13,%r13,%r12
	addq	%r13,%r9
	adcq	%r12,%r10

	shrq	$52,%r9
	salq	$12,%r10
	orq	%r10,%r9

	vpmadd52luq	0(%rsi),%ymm3,%ymm1
	vpmadd52luq	32(%rsi),%ymm3,%ymm16
	vpmadd52luq	64(%rsi),%ymm3,%ymm17
	vpmadd52luq	96(%rsi),%ymm3,%ymm18
	vpmadd52luq	128(%rsi),%ymm3,%ymm19

	vpmadd52luq	0(%rcx),%ymm4,%ymm1
	vpmadd52luq	32(%rcx),%ymm4,%ymm16
	vpmadd52luq	64(%rcx),%ymm4,%ymm17
	vpmadd52luq	96(%rcx),%ymm4,%ymm18
	vpmadd52luq	128(%rcx),%ymm4,%ymm19


	valignq	$1,%ymm1,%ymm16,%ymm1
	valignq	$1,%ymm16,%ymm17,%ymm16
	valignq	$1,%ymm17,%ymm18,%ymm17
	valignq	$1,%ymm18,%ymm19,%ymm18
	valignq	$1,%ymm19,%ymm0,%ymm19

	vmovq	%xmm1,%r13
	addq	%r13,%r9

	vpmadd52huq	0(%rsi),%ymm3,%ymm1
	vpmadd52huq	32(%rsi),%ymm3,%ymm16
	vpmadd52huq	64(%rsi),%ymm3,%ymm17
	vpmadd52huq	96(%rsi),%ymm3,%ymm18
	vpmadd52huq	128(%rsi),%ymm3,%ymm19

	vpmadd52huq	0(%rcx),%ymm4,%ymm1
	vpmadd52huq	32(%rcx),%ymm4,%ymm16
	vpmadd52huq	64(%rcx),%ymm4,%ymm17
	vpmadd52huq	96(%rcx),%ymm4,%ymm18
	vpmadd52huq	128(%rcx),%ymm4,%ymm19
	movq	8(%r11),%r13

	vpbroadcastq	%r13,%ymm3
	movq	0(%rsi),%rdx
	mulxq	%r13,%r13,%r12
	addq	%r13,%r9
	movq	%r12,%r10
	adcq	$0,%r10

	movq	%r8,%r13
	imulq	%r9,%r13
	andq	%rax,%r13

	vpbroadcastq	%r13,%ymm4
	movq	0(%rcx),%rdx
	mulxq	%r13,%r13,%r12
	addq	%r13,%r9
	adcq	%r12,%r10

	shrq	$52,%r9
	salq	$12,%r10
	orq	%r10,%r9

	vpmadd52luq	0(%rsi),%ymm3,%ymm1
	vpmadd52luq	32(%rsi),%ymm3,%ymm16
	vpmadd52luq	64(%rsi),%ymm3,%ymm17
	vpmadd52luq	96(%rsi),%ymm3,%ymm18
	vpmadd52luq	128(%rsi),%ymm3,%ymm19

	vpmadd52luq	0(%rcx),%ymm4,%ymm1
	vpmadd52luq	32(%rcx),%ymm4,%ymm16
	vpmadd52luq	64(%rcx),%ymm4,%ymm17
	vpmadd52luq	96(%rcx),%ymm4,%ymm18
	vpmadd52luq	128(%rcx),%ymm4,%ymm19


	valignq	$1,%ymm1,%ymm16,%ymm1
	valignq	$1,%ymm16,%ymm17,%ymm16
	valignq	$1,%ymm17,%ymm18,%ymm17
	valignq	$1,%ymm18,%ymm19,%ymm18
	valignq	$1,%ymm19,%ymm0,%ymm19

	vmovq	%xmm1,%r13
	addq	%r13,%r9

	vpmadd52huq	0(%rsi),%ymm3,%ymm1
	vpmadd52huq	32(%rsi),%ymm3,%ymm16
	vpmadd52huq	64(%rsi),%ymm3,%ymm17
	vpmadd52huq	96(%rsi),%ymm3,%ymm18
	vpmadd52huq	128(%rsi),%ymm3,%ymm19

	vpmadd52huq	0(%rcx),%ymm4,%ymm1
	vpmadd52huq	32(%rcx),%ymm4,%ymm16
	vpmadd52huq	64(%rcx),%ymm4,%ymm17
	vpmadd52huq	96(%rcx),%ymm4,%ymm18
	vpmadd52huq	128(%rcx),%ymm4,%ymm19
	movq	16(%r11),%r13

	vpbroadcastq	%r13,%ymm3
	movq	0(%rsi),%rdx
	mulxq	%r13,%r13,%r12
	addq	%r13,%r9
	movq	%r12,%r10
	adcq	$0,%r10

	movq	%r8,%r13
	imulq	%r9,%r13
	andq	%rax,%r13

	vpbroadcastq	%r13,%ymm4
	movq	0(%rcx),%rdx
	mulxq	%r13,%r13,%r12
	addq	%r13,%r9
	adcq	%r12,%r10

	shrq	$52,%r9
	salq	$12,%r10
	orq	%r10,%r9

	vpmadd52luq	0(%rsi),%ymm3,%ymm1
	vpmadd52luq	32(%rsi),%ymm3,%ymm16
	vpmadd52luq	64(%rsi),%ymm3,%ymm17
	vpmadd52luq	96(%rsi),%ymm3,%ymm18
	vpmadd52luq	128(%rsi),%ymm3,%ymm19

	vpmadd52luq	0(%rcx),%ymm4,%ymm1
	vpmadd52luq	32(%rcx),%ymm4,%ymm16
	vpmadd52luq	64(%rcx),%ymm4,%ymm17
	vpmadd52luq	96(%rcx),%ymm4,%ymm18
	vpmadd52luq	128(%rcx),%ymm4,%ymm19


	valignq	$1,%ymm1,%ymm16,%ymm1
	valignq	$1,%ymm16,%ymm17,%ymm16
	valignq	$1,%ymm17,%ymm18,%ymm17
	valignq	$1,%ymm18,%ymm19,%ymm18
	valignq	$1,%ymm19,%ymm0,%ymm19

	vmovq	%xmm1,%r13
	addq	%r13,%r9

	vpmadd52huq	0(%rsi),%ymm3,%ymm1
	vpmadd52huq	32(%rsi),%ymm3,%ymm16
	vpmadd52huq	64(%rsi),%ymm3,%ymm17
	vpmadd52huq	96(%rsi),%ymm3,%ymm18
	vpmadd52huq	128(%rsi),%ymm3,%ymm19

	vpmadd52huq	0(%rcx),%ymm4,%ymm1
	vpmadd52huq	32(%rcx),%ymm4,%ymm16
	vpmadd52huq	64(%rcx),%ymm4,%ymm17
	vpmadd52huq	96(%rcx),%ymm4,%ymm18
	vpmadd52huq	128(%rcx),%ymm4,%ymm19
	movq	24(%r11),%r13

	vpbroadcastq	%r13,%ymm3
	movq	0(%rsi),%rdx
	mulxq	%r13,%r13,%r12
	addq	%r13,%r9
	movq	%r12,%r10
	adcq	$0,%r10

	movq	%r8,%r13
	imulq	%r9,%r13
	andq	%rax,%r13

	vpbroadcastq	%r13,%ymm4
	movq	0(%rcx),%rdx
	mulxq	%r13,%r13,%r12
	addq	%r13,%r9
	adcq	%r12,%r10

	shrq	$52,%r9
	salq	$12,%r10
	orq	%r10,%r9

	vpmadd52luq	0(%rsi),%ymm3,%ymm1
	vpmadd52luq	32(%rsi),%ymm3,%ymm16
	vpmadd52luq	64(%rsi),%ymm3,%ymm17
	vpmadd52luq	96(%rsi),%ymm3,%ymm18
	vpmadd52luq	128(%rsi),%ymm3,%ymm19

	vpmadd52luq	0(%rcx),%ymm4,%ymm1
	vpmadd52luq	32(%rcx),%ymm4,%ymm16
	vpmadd52luq	64(%rcx),%ymm4,%ymm17
	vpmadd52luq	96(%rcx),%ymm4,%ymm18
	vpmadd52luq	128(%rcx),%ymm4,%ymm19


	valignq	$1,%ymm1,%ymm16,%ymm1
	valignq	$1,%ymm16,%ymm17,%ymm16
	valignq	$1,%ymm17,%ymm18,%ymm17
	valignq	$1,%ymm18,%ymm19,%ymm18
	valignq	$1,%ymm19,%ymm0,%ymm19

	vmovq	%xmm1,%r13
	addq	%r13,%r9

	vpmadd52huq	0(%rsi),%ymm3,%ymm1
	vpmadd52huq	32(%rsi),%ymm3,%ymm16
	vpmadd52huq	64(%rsi),%ymm3,%ymm17
	vpmadd52huq	96(%rsi),%ymm3,%ymm18
	vpmadd52huq	128(%rsi),%ymm3,%ymm19

	vpmadd52huq	0(%rcx),%ymm4,%ymm1
	vpmadd52huq	32(%rcx),%ymm4,%ymm16
	vpmadd52huq	64(%rcx),%ymm4,%ymm17
	vpmadd52huq	96(%rcx),%ymm4,%ymm18
	vpmadd52huq	128(%rcx),%ymm4,%ymm19
	leaq	32(%r11),%r11
	decl	%ebx
	jne	.Lloop5

	vmovdqa64	.Lmask52x4(%rip),%ymm4

	vpbroadcastq	%r9,%ymm3
	vpblendd	$3,%ymm3,%ymm1,%ymm1



	vpsrlq	$52,%ymm1,%ymm24
	vpsrlq	$52,%ymm16,%ymm25
	vpsrlq	$52,%ymm17,%ymm26
	vpsrlq	$52,%ymm18,%ymm27
	vpsrlq	$52,%ymm19,%ymm28


	valignq	$3,%ymm27,%ymm28,%ymm28
	valignq	$3,%ymm26,%ymm27,%ymm27
	valignq	$3,%ymm25,%ymm26,%ymm26
	valignq	$3,%ymm24,%ymm25,%ymm25
	valignq	$3,%ymm0,%ymm24,%ymm24


	vpandq	%ymm4,%ymm1,%ymm1
	vpandq	%ymm4,%ymm16,%ymm16
	vpandq	%ymm4,%ymm17,%ymm17
	vpandq	%ymm4,%ymm18,%ymm18
	vpandq	%ymm4,%ymm19,%ymm19


	vpaddq	%ymm24,%ymm1,%ymm1
	vpaddq	%ymm25,%ymm16,%ymm16
	vpaddq	%ymm26,%ymm17,%ymm17
	vpaddq	%ymm27,%ymm18,%ymm18
	vpaddq	%ymm28,%ymm19,%ymm19



	vpcmpuq	$1,%ymm1,%ymm4,%k1
	vpcmpuq	$1,%ymm16,%ymm4,%k2
	vpcmpuq	$1,%ymm17,%ymm4,%k3
	vpcmpuq	$1,%ymm18,%ymm4,%k4
	vpcmpuq	$1,%ymm19,%ymm4,%k5
	kmovb	%k1,%r14d
	kmovb	%k2,%r13d
	kmovb	%k3,%r12d
	kmovb	%k4,%r11d
	kmovb	%k5,%r10d


	vpcmpuq	$0,%ymm1,%ymm4,%k1
	vpcmpuq	$0,%ymm16,%ymm4,%k2
	vpcmpuq	$0,%ymm17,%ymm4,%k3
	vpcmpuq	$0,%ymm18,%ymm4,%k4
	vpcmpuq	$0,%ymm19,%ymm4,%k5
	kmovb	%k1,%r9d
	kmovb	%k2,%r8d
	kmovb	%k3,%ebx
	kmovb	%k4,%ecx
	kmovb	%k5,%edx



	shlb	$4,%r13b
	orb	%r13b,%r14b
	shlb	$4,%r11b
	orb	%r11b,%r12b

	addb	%r14b,%r14b
	adcb	%r12b,%r12b
	adcb	%r10b,%r10b

	shlb	$4,%r8b
	orb	%r8b,%r9b
	shlb	$4,%cl
	orb	%cl,%bl

	addb	%r9b,%r14b
	adcb	%bl,%r12b
	adcb	%dl,%r10b

	xorb	%r9b,%r14b
	xorb	%bl,%r12b
	xorb	%dl,%r10b

	kmovb	%r14d,%k1
	shrb	$4,%r14b
	kmovb	%r14d,%k2
	kmovb	%r12d,%k3
	shrb	$4,%r12b
	kmovb	%r12d,%k4
	kmovb	%r10d,%k5


	vpsubq	%ymm4,%ymm1,%ymm1{%k1}
	vpsubq	%ymm4,%ymm16,%ymm16{%k2}
	vpsubq	%ymm4,%ymm17,%ymm17{%k3}
	vpsubq	%ymm4,%ymm18,%ymm18{%k4}
	vpsubq	%ymm4,%ymm19,%ymm19{%k5}

	vpandq	%ymm4,%ymm1,%ymm1
	vpandq	%ymm4,%ymm16,%ymm16
	vpandq	%ymm4,%ymm17,%ymm17
	vpandq	%ymm4,%ymm18,%ymm18
	vpandq	%ymm4,%ymm19,%ymm19

	vmovdqu64	%ymm1,(%rdi)
	vmovdqu64	%ymm16,32(%rdi)
	vmovdqu64	%ymm17,64(%rdi)
	vmovdqu64	%ymm18,96(%rdi)
	vmovdqu64	%ymm19,128(%rdi)

	vzeroupper
	movq	0(%rsp),%r15
.cfi_restore	%r15
	movq	8(%rsp),%r14
.cfi_restore	%r14
	movq	16(%rsp),%r13
.cfi_restore	%r13
	movq	24(%rsp),%r12
.cfi_restore	%r12
	movq	32(%rsp),%rbp
.cfi_restore	%rbp
	movq	40(%rsp),%rbx
.cfi_restore	%rbx
	leaq	48(%rsp),%rsp
.cfi_adjust_cfa_offset	-48
.Lrsaz_amm52x20_x1_256_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	ossl_rsaz_amm52x20_x1_256, .-ossl_rsaz_amm52x20_x1_256
.data	
.align	32
.Lmask52x4:
.quad	0xfffffffffffff
.quad	0xfffffffffffff
.quad	0xfffffffffffff
.quad	0xfffffffffffff
.text	

.globl	ossl_rsaz_amm52x20_x2_256
.type	ossl_rsaz_amm52x20_x2_256,@function
.align	32
ossl_rsaz_amm52x20_x2_256:
.cfi_startproc	
.byte	243,15,30,250
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-56
.Lrsaz_amm52x20_x2_256_body:


	vpxord	%ymm0,%ymm0,%ymm0
	vmovdqa64	%ymm0,%ymm1
	vmovdqa64	%ymm0,%ymm16
	vmovdqa64	%ymm0,%ymm17
	vmovdqa64	%ymm0,%ymm18
	vmovdqa64	%ymm0,%ymm19
	vmovdqa64	%ymm0,%ymm2
	vmovdqa64	%ymm0,%ymm20
	vmovdqa64	%ymm0,%ymm21
	vmovdqa64	%ymm0,%ymm22
	vmovdqa64	%ymm0,%ymm23

	xorl	%r9d,%r9d
	xorl	%r15d,%r15d

	movq	%rdx,%r11
	movq	$0xfffffffffffff,%rax

	movl	$20,%ebx

.align	32
.Lloop20:
	movq	0(%r11),%r13

	vpbroadcastq	%r13,%ymm3
	movq	0(%rsi),%rdx
	mulxq	%r13,%r13,%r12
	addq	%r13,%r9
	movq	%r12,%r10
	adcq	$0,%r10

	movq	(%r8),%r13
	imulq	%r9,%r13
	andq	%rax,%r13

	vpbroadcastq	%r13,%ymm4
	movq	0(%rcx),%rdx
	mulxq	%r13,%r13,%r12
	addq	%r13,%r9
	adcq	%r12,%r10

	shrq	$52,%r9
	salq	$12,%r10
	orq	%r10,%r9

	vpmadd52luq	0(%rsi),%ymm3,%ymm1
	vpmadd52luq	32(%rsi),%ymm3,%ymm16
	vpmadd52luq	64(%rsi),%ymm3,%ymm17
	vpmadd52luq	96(%rsi),%ymm3,%ymm18
	vpmadd52luq	128(%rsi),%ymm3,%ymm19

	vpmadd52luq	0(%rcx),%ymm4,%ymm1
	vpmadd52luq	32(%rcx),%ymm4,%ymm16
	vpmadd52luq	64(%rcx),%ymm4,%ymm17
	vpmadd52luq	96(%rcx),%ymm4,%ymm18
	vpmadd52luq	128(%rcx),%ymm4,%ymm19


	valignq	$1,%ymm1,%ymm16,%ymm1
	valignq	$1,%ymm16,%ymm17,%ymm16
	valignq	$1,%ymm17,%ymm18,%ymm17
	valignq	$1,%ymm18,%ymm19,%ymm18
	valignq	$1,%ymm19,%ymm0,%ymm19

	vmovq	%xmm1,%r13
	addq	%r13,%r9

	vpmadd52huq	0(%rsi),%ymm3,%ymm1
	vpmadd52huq	32(%rsi),%ymm3,%ymm16
	vpmadd52huq	64(%rsi),%ymm3,%ymm17
	vpmadd52huq	96(%rsi),%ymm3,%ymm18
	vpmadd52huq	128(%rsi),%ymm3,%ymm19

	vpmadd52huq	0(%rcx),%ymm4,%ymm1
	vpmadd52huq	32(%rcx),%ymm4,%ymm16
	vpmadd52huq	64(%rcx),%ymm4,%ymm17
	vpmadd52huq	96(%rcx),%ymm4,%ymm18
	vpmadd52huq	128(%rcx),%ymm4,%ymm19
	movq	160(%r11),%r13

	vpbroadcastq	%r13,%ymm3
	movq	160(%rsi),%rdx
	mulxq	%r13,%r13,%r12
	addq	%r13,%r15
	movq	%r12,%r10
	adcq	$0,%r10

	movq	8(%r8),%r13
	imulq	%r15,%r13
	andq	%rax,%r13

	vpbroadcastq	%r13,%ymm4
	movq	160(%rcx),%rdx
	mulxq	%r13,%r13,%r12
	addq	%r13,%r15
	adcq	%r12,%r10

	shrq	$52,%r15
	salq	$12,%r10
	orq	%r10,%r15

	vpmadd52luq	160(%rsi),%ymm3,%ymm2
	vpmadd52luq	192(%rsi),%ymm3,%ymm20
	vpmadd52luq	224(%rsi),%ymm3,%ymm21
	vpmadd52luq	256(%rsi),%ymm3,%ymm22
	vpmadd52luq	288(%rsi),%ymm3,%ymm23

	vpmadd52luq	160(%rcx),%ymm4,%ymm2
	vpmadd52luq	192(%rcx),%ymm4,%ymm20
	vpmadd52luq	224(%rcx),%ymm4,%ymm21
	vpmadd52luq	256(%rcx),%ymm4,%ymm22
	vpmadd52luq	288(%rcx),%ymm4,%ymm23


	valignq	$1,%ymm2,%ymm20,%ymm2
	valignq	$1,%ymm20,%ymm21,%ymm20
	valignq	$1,%ymm21,%ymm22,%ymm21
	valignq	$1,%ymm22,%ymm23,%ymm22
	valignq	$1,%ymm23,%ymm0,%ymm23

	vmovq	%xmm2,%r13
	addq	%r13,%r15

	vpmadd52huq	160(%rsi),%ymm3,%ymm2
	vpmadd52huq	192(%rsi),%ymm3,%ymm20
	vpmadd52huq	224(%rsi),%ymm3,%ymm21
	vpmadd52huq	256(%rsi),%ymm3,%ymm22
	vpmadd52huq	288(%rsi),%ymm3,%ymm23

	vpmadd52huq	160(%rcx),%ymm4,%ymm2
	vpmadd52huq	192(%rcx),%ymm4,%ymm20
	vpmadd52huq	224(%rcx),%ymm4,%ymm21
	vpmadd52huq	256(%rcx),%ymm4,%ymm22
	vpmadd52huq	288(%rcx),%ymm4,%ymm23
	leaq	8(%r11),%r11
	decl	%ebx
	jne	.Lloop20

	vmovdqa64	.Lmask52x4(%rip),%ymm4

	vpbroadcastq	%r9,%ymm3
	vpblendd	$3,%ymm3,%ymm1,%ymm1



	vpsrlq	$52,%ymm1,%ymm24
	vpsrlq	$52,%ymm16,%ymm25
	vpsrlq	$52,%ymm17,%ymm26
	vpsrlq	$52,%ymm18,%ymm27
	vpsrlq	$52,%ymm19,%ymm28


	valignq	$3,%ymm27,%ymm28,%ymm28
	valignq	$3,%ymm26,%ymm27,%ymm27
	valignq	$3,%ymm25,%ymm26,%ymm26
	valignq	$3,%ymm24,%ymm25,%ymm25
	valignq	$3,%ymm0,%ymm24,%ymm24


	vpandq	%ymm4,%ymm1,%ymm1
	vpandq	%ymm4,%ymm16,%ymm16
	vpandq	%ymm4,%ymm17,%ymm17
	vpandq	%ymm4,%ymm18,%ymm18
	vpandq	%ymm4,%ymm19,%ymm19


	vpaddq	%ymm24,%ymm1,%ymm1
	vpaddq	%ymm25,%ymm16,%ymm16
	vpaddq	%ymm26,%ymm17,%ymm17
	vpaddq	%ymm27,%ymm18,%ymm18
	vpaddq	%ymm28,%ymm19,%ymm19



	vpcmpuq	$1,%ymm1,%ymm4,%k1
	vpcmpuq	$1,%ymm16,%ymm4,%k2
	vpcmpuq	$1,%ymm17,%ymm4,%k3
	vpcmpuq	$1,%ymm18,%ymm4,%k4
	vpcmpuq	$1,%ymm19,%ymm4,%k5
	kmovb	%k1,%r14d
	kmovb	%k2,%r13d
	kmovb	%k3,%r12d
	kmovb	%k4,%r11d
	kmovb	%k5,%r10d


	vpcmpuq	$0,%ymm1,%ymm4,%k1
	vpcmpuq	$0,%ymm16,%ymm4,%k2
	vpcmpuq	$0,%ymm17,%ymm4,%k3
	vpcmpuq	$0,%ymm18,%ymm4,%k4
	vpcmpuq	$0,%ymm19,%ymm4,%k5
	kmovb	%k1,%r9d
	kmovb	%k2,%r8d
	kmovb	%k3,%ebx
	kmovb	%k4,%ecx
	kmovb	%k5,%edx



	shlb	$4,%r13b
	orb	%r13b,%r14b
	shlb	$4,%r11b
	orb	%r11b,%r12b

	addb	%r14b,%r14b
	adcb	%r12b,%r12b
	adcb	%r10b,%r10b

	shlb	$4,%r8b
	orb	%r8b,%r9b
	shlb	$4,%cl
	orb	%cl,%bl

	addb	%r9b,%r14b
	adcb	%bl,%r12b
	adcb	%dl,%r10b

	xorb	%r9b,%r14b
	xorb	%bl,%r12b
	xorb	%dl,%r10b

	kmovb	%r14d,%k1
	shrb	$4,%r14b
	kmovb	%r14d,%k2
	kmovb	%r12d,%k3
	shrb	$4,%r12b
	kmovb	%r12d,%k4
	kmovb	%r10d,%k5


	vpsubq	%ymm4,%ymm1,%ymm1{%k1}
	vpsubq	%ymm4,%ymm16,%ymm16{%k2}
	vpsubq	%ymm4,%ymm17,%ymm17{%k3}
	vpsubq	%ymm4,%ymm18,%ymm18{%k4}
	vpsubq	%ymm4,%ymm19,%ymm19{%k5}

	vpandq	%ymm4,%ymm1,%ymm1
	vpandq	%ymm4,%ymm16,%ymm16
	vpandq	%ymm4,%ymm17,%ymm17
	vpandq	%ymm4,%ymm18,%ymm18
	vpandq	%ymm4,%ymm19,%ymm19

	vpbroadcastq	%r15,%ymm3
	vpblendd	$3,%ymm3,%ymm2,%ymm2



	vpsrlq	$52,%ymm2,%ymm24
	vpsrlq	$52,%ymm20,%ymm25
	vpsrlq	$52,%ymm21,%ymm26
	vpsrlq	$52,%ymm22,%ymm27
	vpsrlq	$52,%ymm23,%ymm28


	valignq	$3,%ymm27,%ymm28,%ymm28
	valignq	$3,%ymm26,%ymm27,%ymm27
	valignq	$3,%ymm25,%ymm26,%ymm26
	valignq	$3,%ymm24,%ymm25,%ymm25
	valignq	$3,%ymm0,%ymm24,%ymm24


	vpandq	%ymm4,%ymm2,%ymm2
	vpandq	%ymm4,%ymm20,%ymm20
	vpandq	%ymm4,%ymm21,%ymm21
	vpandq	%ymm4,%ymm22,%ymm22
	vpandq	%ymm4,%ymm23,%ymm23


	vpaddq	%ymm24,%ymm2,%ymm2
	vpaddq	%ymm25,%ymm20,%ymm20
	vpaddq	%ymm26,%ymm21,%ymm21
	vpaddq	%ymm27,%ymm22,%ymm22
	vpaddq	%ymm28,%ymm23,%ymm23



	vpcmpuq	$1,%ymm2,%ymm4,%k1
	vpcmpuq	$1,%ymm20,%ymm4,%k2
	vpcmpuq	$1,%ymm21,%ymm4,%k3
	vpcmpuq	$1,%ymm22,%ymm4,%k4
	vpcmpuq	$1,%ymm23,%ymm4,%k5
	kmovb	%k1,%r14d
	kmovb	%k2,%r13d
	kmovb	%k3,%r12d
	kmovb	%k4,%r11d
	kmovb	%k5,%r10d


	vpcmpuq	$0,%ymm2,%ymm4,%k1
	vpcmpuq	$0,%ymm20,%ymm4,%k2
	vpcmpuq	$0,%ymm21,%ymm4,%k3
	vpcmpuq	$0,%ymm22,%ymm4,%k4
	vpcmpuq	$0,%ymm23,%ymm4,%k5
	kmovb	%k1,%r9d
	kmovb	%k2,%r8d
	kmovb	%k3,%ebx
	kmovb	%k4,%ecx
	kmovb	%k5,%edx



	shlb	$4,%r13b
	orb	%r13b,%r14b
	shlb	$4,%r11b
	orb	%r11b,%r12b

	addb	%r14b,%r14b
	adcb	%r12b,%r12b
	adcb	%r10b,%r10b

	shlb	$4,%r8b
	orb	%r8b,%r9b
	shlb	$4,%cl
	orb	%cl,%bl

	addb	%r9b,%r14b
	adcb	%bl,%r12b
	adcb	%dl,%r10b

	xorb	%r9b,%r14b
	xorb	%bl,%r12b
	xorb	%dl,%r10b

	kmovb	%r14d,%k1
	shrb	$4,%r14b
	kmovb	%r14d,%k2
	kmovb	%r12d,%k3
	shrb	$4,%r12b
	kmovb	%r12d,%k4
	kmovb	%r10d,%k5


	vpsubq	%ymm4,%ymm2,%ymm2{%k1}
	vpsubq	%ymm4,%ymm20,%ymm20{%k2}
	vpsubq	%ymm4,%ymm21,%ymm21{%k3}
	vpsubq	%ymm4,%ymm22,%ymm22{%k4}
	vpsubq	%ymm4,%ymm23,%ymm23{%k5}

	vpandq	%ymm4,%ymm2,%ymm2
	vpandq	%ymm4,%ymm20,%ymm20
	vpandq	%ymm4,%ymm21,%ymm21
	vpandq	%ymm4,%ymm22,%ymm22
	vpandq	%ymm4,%ymm23,%ymm23

	vmovdqu64	%ymm1,(%rdi)
	vmovdqu64	%ymm16,32(%rdi)
	vmovdqu64	%ymm17,64(%rdi)
	vmovdqu64	%ymm18,96(%rdi)
	vmovdqu64	%ymm19,128(%rdi)

	vmovdqu64	%ymm2,160(%rdi)
	vmovdqu64	%ymm20,192(%rdi)
	vmovdqu64	%ymm21,224(%rdi)
	vmovdqu64	%ymm22,256(%rdi)
	vmovdqu64	%ymm23,288(%rdi)

	vzeroupper
	movq	0(%rsp),%r15
.cfi_restore	%r15
	movq	8(%rsp),%r14
.cfi_restore	%r14
	movq	16(%rsp),%r13
.cfi_restore	%r13
	movq	24(%rsp),%r12
.cfi_restore	%r12
	movq	32(%rsp),%rbp
.cfi_restore	%rbp
	movq	40(%rsp),%rbx
.cfi_restore	%rbx
	leaq	48(%rsp),%rsp
.cfi_adjust_cfa_offset	-48
.Lrsaz_amm52x20_x2_256_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	ossl_rsaz_amm52x20_x2_256, .-ossl_rsaz_amm52x20_x2_256
.text	

.align	32
.globl	ossl_extract_multiplier_2x20_win5
.type	ossl_extract_multiplier_2x20_win5,@function
ossl_extract_multiplier_2x20_win5:
.cfi_startproc	
.byte	243,15,30,250
	leaq	(%rcx,%rcx,4),%rax
	salq	$5,%rax
	addq	%rax,%rsi

	vmovdqa64	.Lones(%rip),%ymm23
	vpbroadcastq	%rdx,%ymm22
	leaq	10240(%rsi),%rax

	vpxor	%xmm4,%xmm4,%xmm4
	vmovdqa64	%ymm4,%ymm3
	vmovdqa64	%ymm4,%ymm2
	vmovdqa64	%ymm4,%ymm1
	vmovdqa64	%ymm4,%ymm0
	vmovdqa64	%ymm4,%ymm21

.align	32
.Lloop:
	vpcmpq	$0,%ymm21,%ymm22,%k1
	addq	$320,%rsi
	vpaddq	%ymm23,%ymm21,%ymm21
	vmovdqu64	-320(%rsi),%ymm16
	vmovdqu64	-288(%rsi),%ymm17
	vmovdqu64	-256(%rsi),%ymm18
	vmovdqu64	-224(%rsi),%ymm19
	vmovdqu64	-192(%rsi),%ymm20
	vpblendmq	%ymm16,%ymm0,%ymm0{%k1}
	vpblendmq	%ymm17,%ymm1,%ymm1{%k1}
	vpblendmq	%ymm18,%ymm2,%ymm2{%k1}
	vpblendmq	%ymm19,%ymm3,%ymm3{%k1}
	vpblendmq	%ymm20,%ymm4,%ymm4{%k1}
	cmpq	%rsi,%rax
	jne	.Lloop

	vmovdqu64	%ymm0,(%rdi)
	vmovdqu64	%ymm1,32(%rdi)
	vmovdqu64	%ymm2,64(%rdi)
	vmovdqu64	%ymm3,96(%rdi)
	vmovdqu64	%ymm4,128(%rdi)

	.byte	0xf3,0xc3
.cfi_endproc	
.size	ossl_extract_multiplier_2x20_win5, .-ossl_extract_multiplier_2x20_win5
.data	
.align	32
.Lones:
.quad	1,1,1,1
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                                               node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/bn/rsaz-x86_64.s                      0000664 0000000 0000000 00000077320 14746647661 0026442 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	



.globl	rsaz_512_sqr
.type	rsaz_512_sqr,@function
.align	32
rsaz_512_sqr:
.cfi_startproc	
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-56

	subq	$128+24,%rsp
.cfi_adjust_cfa_offset	128+24
.Lsqr_body:
.byte	102,72,15,110,202
	movq	(%rsi),%rdx
	movq	8(%rsi),%rax
	movq	%rcx,128(%rsp)
	movl	$0x80100,%r11d
	andl	OPENSSL_ia32cap_P+8(%rip),%r11d
	cmpl	$0x80100,%r11d
	je	.Loop_sqrx
	jmp	.Loop_sqr

.align	32
.Loop_sqr:
	movl	%r8d,128+8(%rsp)

	movq	%rdx,%rbx
	movq	%rax,%rbp
	mulq	%rdx
	movq	%rax,%r8
	movq	16(%rsi),%rax
	movq	%rdx,%r9

	mulq	%rbx
	addq	%rax,%r9
	movq	24(%rsi),%rax
	movq	%rdx,%r10
	adcq	$0,%r10

	mulq	%rbx
	addq	%rax,%r10
	movq	32(%rsi),%rax
	movq	%rdx,%r11
	adcq	$0,%r11

	mulq	%rbx
	addq	%rax,%r11
	movq	40(%rsi),%rax
	movq	%rdx,%r12
	adcq	$0,%r12

	mulq	%rbx
	addq	%rax,%r12
	movq	48(%rsi),%rax
	movq	%rdx,%r13
	adcq	$0,%r13

	mulq	%rbx
	addq	%rax,%r13
	movq	56(%rsi),%rax
	movq	%rdx,%r14
	adcq	$0,%r14

	mulq	%rbx
	addq	%rax,%r14
	movq	%rbx,%rax
	adcq	$0,%rdx

	xorq	%rcx,%rcx
	addq	%r8,%r8
	movq	%rdx,%r15
	adcq	$0,%rcx

	mulq	%rax
	addq	%r8,%rdx
	adcq	$0,%rcx

	movq	%rax,(%rsp)
	movq	%rdx,8(%rsp)


	movq	16(%rsi),%rax
	mulq	%rbp
	addq	%rax,%r10
	movq	24(%rsi),%rax
	movq	%rdx,%rbx
	adcq	$0,%rbx

	mulq	%rbp
	addq	%rax,%r11
	movq	32(%rsi),%rax
	adcq	$0,%rdx
	addq	%rbx,%r11
	movq	%rdx,%rbx
	adcq	$0,%rbx

	mulq	%rbp
	addq	%rax,%r12
	movq	40(%rsi),%rax
	adcq	$0,%rdx
	addq	%rbx,%r12
	movq	%rdx,%rbx
	adcq	$0,%rbx

	mulq	%rbp
	addq	%rax,%r13
	movq	48(%rsi),%rax
	adcq	$0,%rdx
	addq	%rbx,%r13
	movq	%rdx,%rbx
	adcq	$0,%rbx

	mulq	%rbp
	addq	%rax,%r14
	movq	56(%rsi),%rax
	adcq	$0,%rdx
	addq	%rbx,%r14
	movq	%rdx,%rbx
	adcq	$0,%rbx

	mulq	%rbp
	addq	%rax,%r15
	movq	%rbp,%rax
	adcq	$0,%rdx
	addq	%rbx,%r15
	adcq	$0,%rdx

	xorq	%rbx,%rbx
	addq	%r9,%r9
	movq	%rdx,%r8
	adcq	%r10,%r10
	adcq	$0,%rbx

	mulq	%rax

	addq	%rcx,%rax
	movq	16(%rsi),%rbp
	addq	%rax,%r9
	movq	24(%rsi),%rax
	adcq	%rdx,%r10
	adcq	$0,%rbx

	movq	%r9,16(%rsp)
	movq	%r10,24(%rsp)


	mulq	%rbp
	addq	%rax,%r12
	movq	32(%rsi),%rax
	movq	%rdx,%rcx
	adcq	$0,%rcx

	mulq	%rbp
	addq	%rax,%r13
	movq	40(%rsi),%rax
	adcq	$0,%rdx
	addq	%rcx,%r13
	movq	%rdx,%rcx
	adcq	$0,%rcx

	mulq	%rbp
	addq	%rax,%r14
	movq	48(%rsi),%rax
	adcq	$0,%rdx
	addq	%rcx,%r14
	movq	%rdx,%rcx
	adcq	$0,%rcx

	mulq	%rbp
	addq	%rax,%r15
	movq	56(%rsi),%rax
	adcq	$0,%rdx
	addq	%rcx,%r15
	movq	%rdx,%rcx
	adcq	$0,%rcx

	mulq	%rbp
	addq	%rax,%r8
	movq	%rbp,%rax
	adcq	$0,%rdx
	addq	%rcx,%r8
	adcq	$0,%rdx

	xorq	%rcx,%rcx
	addq	%r11,%r11
	movq	%rdx,%r9
	adcq	%r12,%r12
	adcq	$0,%rcx

	mulq	%rax

	addq	%rbx,%rax
	movq	24(%rsi),%r10
	addq	%rax,%r11
	movq	32(%rsi),%rax
	adcq	%rdx,%r12
	adcq	$0,%rcx

	movq	%r11,32(%rsp)
	movq	%r12,40(%rsp)


	movq	%rax,%r11
	mulq	%r10
	addq	%rax,%r14
	movq	40(%rsi),%rax
	movq	%rdx,%rbx
	adcq	$0,%rbx

	movq	%rax,%r12
	mulq	%r10
	addq	%rax,%r15
	movq	48(%rsi),%rax
	adcq	$0,%rdx
	addq	%rbx,%r15
	movq	%rdx,%rbx
	adcq	$0,%rbx

	movq	%rax,%rbp
	mulq	%r10
	addq	%rax,%r8
	movq	56(%rsi),%rax
	adcq	$0,%rdx
	addq	%rbx,%r8
	movq	%rdx,%rbx
	adcq	$0,%rbx

	mulq	%r10
	addq	%rax,%r9
	movq	%r10,%rax
	adcq	$0,%rdx
	addq	%rbx,%r9
	adcq	$0,%rdx

	xorq	%rbx,%rbx
	addq	%r13,%r13
	movq	%rdx,%r10
	adcq	%r14,%r14
	adcq	$0,%rbx

	mulq	%rax

	addq	%rcx,%rax
	addq	%rax,%r13
	movq	%r12,%rax
	adcq	%rdx,%r14
	adcq	$0,%rbx

	movq	%r13,48(%rsp)
	movq	%r14,56(%rsp)


	mulq	%r11
	addq	%rax,%r8
	movq	%rbp,%rax
	movq	%rdx,%rcx
	adcq	$0,%rcx

	mulq	%r11
	addq	%rax,%r9
	movq	56(%rsi),%rax
	adcq	$0,%rdx
	addq	%rcx,%r9
	movq	%rdx,%rcx
	adcq	$0,%rcx

	movq	%rax,%r14
	mulq	%r11
	addq	%rax,%r10
	movq	%r11,%rax
	adcq	$0,%rdx
	addq	%rcx,%r10
	adcq	$0,%rdx

	xorq	%rcx,%rcx
	addq	%r15,%r15
	movq	%rdx,%r11
	adcq	%r8,%r8
	adcq	$0,%rcx

	mulq	%rax

	addq	%rbx,%rax
	addq	%rax,%r15
	movq	%rbp,%rax
	adcq	%rdx,%r8
	adcq	$0,%rcx

	movq	%r15,64(%rsp)
	movq	%r8,72(%rsp)


	mulq	%r12
	addq	%rax,%r10
	movq	%r14,%rax
	movq	%rdx,%rbx
	adcq	$0,%rbx

	mulq	%r12
	addq	%rax,%r11
	movq	%r12,%rax
	adcq	$0,%rdx
	addq	%rbx,%r11
	adcq	$0,%rdx

	xorq	%rbx,%rbx
	addq	%r9,%r9
	movq	%rdx,%r12
	adcq	%r10,%r10
	adcq	$0,%rbx

	mulq	%rax

	addq	%rcx,%rax
	addq	%rax,%r9
	movq	%r14,%rax
	adcq	%rdx,%r10
	adcq	$0,%rbx

	movq	%r9,80(%rsp)
	movq	%r10,88(%rsp)


	mulq	%rbp
	addq	%rax,%r12
	movq	%rbp,%rax
	adcq	$0,%rdx

	xorq	%rcx,%rcx
	addq	%r11,%r11
	movq	%rdx,%r13
	adcq	%r12,%r12
	adcq	$0,%rcx

	mulq	%rax

	addq	%rbx,%rax
	addq	%rax,%r11
	movq	%r14,%rax
	adcq	%rdx,%r12
	adcq	$0,%rcx

	movq	%r11,96(%rsp)
	movq	%r12,104(%rsp)


	xorq	%rbx,%rbx
	addq	%r13,%r13
	adcq	$0,%rbx

	mulq	%rax

	addq	%rcx,%rax
	addq	%r13,%rax
	adcq	%rbx,%rdx

	movq	(%rsp),%r8
	movq	8(%rsp),%r9
	movq	16(%rsp),%r10
	movq	24(%rsp),%r11
	movq	32(%rsp),%r12
	movq	40(%rsp),%r13
	movq	48(%rsp),%r14
	movq	56(%rsp),%r15
.byte	102,72,15,126,205

	movq	%rax,112(%rsp)
	movq	%rdx,120(%rsp)

	call	__rsaz_512_reduce

	addq	64(%rsp),%r8
	adcq	72(%rsp),%r9
	adcq	80(%rsp),%r10
	adcq	88(%rsp),%r11
	adcq	96(%rsp),%r12
	adcq	104(%rsp),%r13
	adcq	112(%rsp),%r14
	adcq	120(%rsp),%r15
	sbbq	%rcx,%rcx

	call	__rsaz_512_subtract

	movq	%r8,%rdx
	movq	%r9,%rax
	movl	128+8(%rsp),%r8d
	movq	%rdi,%rsi

	decl	%r8d
	jnz	.Loop_sqr
	jmp	.Lsqr_tail

.align	32
.Loop_sqrx:
	movl	%r8d,128+8(%rsp)
.byte	102,72,15,110,199

	mulxq	%rax,%r8,%r9
	movq	%rax,%rbx

	mulxq	16(%rsi),%rcx,%r10
	xorq	%rbp,%rbp

	mulxq	24(%rsi),%rax,%r11
	adcxq	%rcx,%r9

.byte	0xc4,0x62,0xf3,0xf6,0xa6,0x20,0x00,0x00,0x00
	adcxq	%rax,%r10

.byte	0xc4,0x62,0xfb,0xf6,0xae,0x28,0x00,0x00,0x00
	adcxq	%rcx,%r11

	mulxq	48(%rsi),%rcx,%r14
	adcxq	%rax,%r12
	adcxq	%rcx,%r13

	mulxq	56(%rsi),%rax,%r15
	adcxq	%rax,%r14
	adcxq	%rbp,%r15

	mulxq	%rdx,%rax,%rdi
	movq	%rbx,%rdx
	xorq	%rcx,%rcx
	adoxq	%r8,%r8
	adcxq	%rdi,%r8
	adoxq	%rbp,%rcx
	adcxq	%rbp,%rcx

	movq	%rax,(%rsp)
	movq	%r8,8(%rsp)


.byte	0xc4,0xe2,0xfb,0xf6,0x9e,0x10,0x00,0x00,0x00
	adoxq	%rax,%r10
	adcxq	%rbx,%r11

	mulxq	24(%rsi),%rdi,%r8
	adoxq	%rdi,%r11
.byte	0x66
	adcxq	%r8,%r12

	mulxq	32(%rsi),%rax,%rbx
	adoxq	%rax,%r12
	adcxq	%rbx,%r13

	mulxq	40(%rsi),%rdi,%r8
	adoxq	%rdi,%r13
	adcxq	%r8,%r14

.byte	0xc4,0xe2,0xfb,0xf6,0x9e,0x30,0x00,0x00,0x00
	adoxq	%rax,%r14
	adcxq	%rbx,%r15

.byte	0xc4,0x62,0xc3,0xf6,0x86,0x38,0x00,0x00,0x00
	adoxq	%rdi,%r15
	adcxq	%rbp,%r8
	mulxq	%rdx,%rax,%rdi
	adoxq	%rbp,%r8
.byte	0x48,0x8b,0x96,0x10,0x00,0x00,0x00

	xorq	%rbx,%rbx
	adoxq	%r9,%r9

	adcxq	%rcx,%rax
	adoxq	%r10,%r10
	adcxq	%rax,%r9
	adoxq	%rbp,%rbx
	adcxq	%rdi,%r10
	adcxq	%rbp,%rbx

	movq	%r9,16(%rsp)
.byte	0x4c,0x89,0x94,0x24,0x18,0x00,0x00,0x00


	mulxq	24(%rsi),%rdi,%r9
	adoxq	%rdi,%r12
	adcxq	%r9,%r13

	mulxq	32(%rsi),%rax,%rcx
	adoxq	%rax,%r13
	adcxq	%rcx,%r14

.byte	0xc4,0x62,0xc3,0xf6,0x8e,0x28,0x00,0x00,0x00
	adoxq	%rdi,%r14
	adcxq	%r9,%r15

.byte	0xc4,0xe2,0xfb,0xf6,0x8e,0x30,0x00,0x00,0x00
	adoxq	%rax,%r15
	adcxq	%rcx,%r8

	mulxq	56(%rsi),%rdi,%r9
	adoxq	%rdi,%r8
	adcxq	%rbp,%r9
	mulxq	%rdx,%rax,%rdi
	adoxq	%rbp,%r9
	movq	24(%rsi),%rdx

	xorq	%rcx,%rcx
	adoxq	%r11,%r11

	adcxq	%rbx,%rax
	adoxq	%r12,%r12
	adcxq	%rax,%r11
	adoxq	%rbp,%rcx
	adcxq	%rdi,%r12
	adcxq	%rbp,%rcx

	movq	%r11,32(%rsp)
	movq	%r12,40(%rsp)


	mulxq	32(%rsi),%rax,%rbx
	adoxq	%rax,%r14
	adcxq	%rbx,%r15

	mulxq	40(%rsi),%rdi,%r10
	adoxq	%rdi,%r15
	adcxq	%r10,%r8

	mulxq	48(%rsi),%rax,%rbx
	adoxq	%rax,%r8
	adcxq	%rbx,%r9

	mulxq	56(%rsi),%rdi,%r10
	adoxq	%rdi,%r9
	adcxq	%rbp,%r10
	mulxq	%rdx,%rax,%rdi
	adoxq	%rbp,%r10
	movq	32(%rsi),%rdx

	xorq	%rbx,%rbx
	adoxq	%r13,%r13

	adcxq	%rcx,%rax
	adoxq	%r14,%r14
	adcxq	%rax,%r13
	adoxq	%rbp,%rbx
	adcxq	%rdi,%r14
	adcxq	%rbp,%rbx

	movq	%r13,48(%rsp)
	movq	%r14,56(%rsp)


	mulxq	40(%rsi),%rdi,%r11
	adoxq	%rdi,%r8
	adcxq	%r11,%r9

	mulxq	48(%rsi),%rax,%rcx
	adoxq	%rax,%r9
	adcxq	%rcx,%r10

	mulxq	56(%rsi),%rdi,%r11
	adoxq	%rdi,%r10
	adcxq	%rbp,%r11
	mulxq	%rdx,%rax,%rdi
	movq	40(%rsi),%rdx
	adoxq	%rbp,%r11

	xorq	%rcx,%rcx
	adoxq	%r15,%r15

	adcxq	%rbx,%rax
	adoxq	%r8,%r8
	adcxq	%rax,%r15
	adoxq	%rbp,%rcx
	adcxq	%rdi,%r8
	adcxq	%rbp,%rcx

	movq	%r15,64(%rsp)
	movq	%r8,72(%rsp)


.byte	0xc4,0xe2,0xfb,0xf6,0x9e,0x30,0x00,0x00,0x00
	adoxq	%rax,%r10
	adcxq	%rbx,%r11

.byte	0xc4,0x62,0xc3,0xf6,0xa6,0x38,0x00,0x00,0x00
	adoxq	%rdi,%r11
	adcxq	%rbp,%r12
	mulxq	%rdx,%rax,%rdi
	adoxq	%rbp,%r12
	movq	48(%rsi),%rdx

	xorq	%rbx,%rbx
	adoxq	%r9,%r9

	adcxq	%rcx,%rax
	adoxq	%r10,%r10
	adcxq	%rax,%r9
	adcxq	%rdi,%r10
	adoxq	%rbp,%rbx
	adcxq	%rbp,%rbx

	movq	%r9,80(%rsp)
	movq	%r10,88(%rsp)


.byte	0xc4,0x62,0xfb,0xf6,0xae,0x38,0x00,0x00,0x00
	adoxq	%rax,%r12
	adoxq	%rbp,%r13

	mulxq	%rdx,%rax,%rdi
	xorq	%rcx,%rcx
	movq	56(%rsi),%rdx
	adoxq	%r11,%r11

	adcxq	%rbx,%rax
	adoxq	%r12,%r12
	adcxq	%rax,%r11
	adoxq	%rbp,%rcx
	adcxq	%rdi,%r12
	adcxq	%rbp,%rcx

.byte	0x4c,0x89,0x9c,0x24,0x60,0x00,0x00,0x00
.byte	0x4c,0x89,0xa4,0x24,0x68,0x00,0x00,0x00


	mulxq	%rdx,%rax,%rdx
	xorq	%rbx,%rbx
	adoxq	%r13,%r13

	adcxq	%rcx,%rax
	adoxq	%rbp,%rbx
	adcxq	%r13,%rax
	adcxq	%rdx,%rbx

.byte	102,72,15,126,199
.byte	102,72,15,126,205

	movq	128(%rsp),%rdx
	movq	(%rsp),%r8
	movq	8(%rsp),%r9
	movq	16(%rsp),%r10
	movq	24(%rsp),%r11
	movq	32(%rsp),%r12
	movq	40(%rsp),%r13
	movq	48(%rsp),%r14
	movq	56(%rsp),%r15

	movq	%rax,112(%rsp)
	movq	%rbx,120(%rsp)

	call	__rsaz_512_reducex

	addq	64(%rsp),%r8
	adcq	72(%rsp),%r9
	adcq	80(%rsp),%r10
	adcq	88(%rsp),%r11
	adcq	96(%rsp),%r12
	adcq	104(%rsp),%r13
	adcq	112(%rsp),%r14
	adcq	120(%rsp),%r15
	sbbq	%rcx,%rcx

	call	__rsaz_512_subtract

	movq	%r8,%rdx
	movq	%r9,%rax
	movl	128+8(%rsp),%r8d
	movq	%rdi,%rsi

	decl	%r8d
	jnz	.Loop_sqrx

.Lsqr_tail:

	leaq	128+24+48(%rsp),%rax
.cfi_def_cfa	%rax,8
	movq	-48(%rax),%r15
.cfi_restore	%r15
	movq	-40(%rax),%r14
.cfi_restore	%r14
	movq	-32(%rax),%r13
.cfi_restore	%r13
	movq	-24(%rax),%r12
.cfi_restore	%r12
	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lsqr_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	rsaz_512_sqr,.-rsaz_512_sqr
.globl	rsaz_512_mul
.type	rsaz_512_mul,@function
.align	32
rsaz_512_mul:
.cfi_startproc	
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-56

	subq	$128+24,%rsp
.cfi_adjust_cfa_offset	128+24
.Lmul_body:
.byte	102,72,15,110,199
.byte	102,72,15,110,201
	movq	%r8,128(%rsp)
	movl	$0x80100,%r11d
	andl	OPENSSL_ia32cap_P+8(%rip),%r11d
	cmpl	$0x80100,%r11d
	je	.Lmulx
	movq	(%rdx),%rbx
	movq	%rdx,%rbp
	call	__rsaz_512_mul

.byte	102,72,15,126,199
.byte	102,72,15,126,205

	movq	(%rsp),%r8
	movq	8(%rsp),%r9
	movq	16(%rsp),%r10
	movq	24(%rsp),%r11
	movq	32(%rsp),%r12
	movq	40(%rsp),%r13
	movq	48(%rsp),%r14
	movq	56(%rsp),%r15

	call	__rsaz_512_reduce
	jmp	.Lmul_tail

.align	32
.Lmulx:
	movq	%rdx,%rbp
	movq	(%rdx),%rdx
	call	__rsaz_512_mulx

.byte	102,72,15,126,199
.byte	102,72,15,126,205

	movq	128(%rsp),%rdx
	movq	(%rsp),%r8
	movq	8(%rsp),%r9
	movq	16(%rsp),%r10
	movq	24(%rsp),%r11
	movq	32(%rsp),%r12
	movq	40(%rsp),%r13
	movq	48(%rsp),%r14
	movq	56(%rsp),%r15

	call	__rsaz_512_reducex
.Lmul_tail:
	addq	64(%rsp),%r8
	adcq	72(%rsp),%r9
	adcq	80(%rsp),%r10
	adcq	88(%rsp),%r11
	adcq	96(%rsp),%r12
	adcq	104(%rsp),%r13
	adcq	112(%rsp),%r14
	adcq	120(%rsp),%r15
	sbbq	%rcx,%rcx

	call	__rsaz_512_subtract

	leaq	128+24+48(%rsp),%rax
.cfi_def_cfa	%rax,8
	movq	-48(%rax),%r15
.cfi_restore	%r15
	movq	-40(%rax),%r14
.cfi_restore	%r14
	movq	-32(%rax),%r13
.cfi_restore	%r13
	movq	-24(%rax),%r12
.cfi_restore	%r12
	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lmul_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	rsaz_512_mul,.-rsaz_512_mul
.globl	rsaz_512_mul_gather4
.type	rsaz_512_mul_gather4,@function
.align	32
rsaz_512_mul_gather4:
.cfi_startproc	
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-56

	subq	$152,%rsp
.cfi_adjust_cfa_offset	152
.Lmul_gather4_body:
	movd	%r9d,%xmm8
	movdqa	.Linc+16(%rip),%xmm1
	movdqa	.Linc(%rip),%xmm0

	pshufd	$0,%xmm8,%xmm8
	movdqa	%xmm1,%xmm7
	movdqa	%xmm1,%xmm2
	paddd	%xmm0,%xmm1
	pcmpeqd	%xmm8,%xmm0
	movdqa	%xmm7,%xmm3
	paddd	%xmm1,%xmm2
	pcmpeqd	%xmm8,%xmm1
	movdqa	%xmm7,%xmm4
	paddd	%xmm2,%xmm3
	pcmpeqd	%xmm8,%xmm2
	movdqa	%xmm7,%xmm5
	paddd	%xmm3,%xmm4
	pcmpeqd	%xmm8,%xmm3
	movdqa	%xmm7,%xmm6
	paddd	%xmm4,%xmm5
	pcmpeqd	%xmm8,%xmm4
	paddd	%xmm5,%xmm6
	pcmpeqd	%xmm8,%xmm5
	paddd	%xmm6,%xmm7
	pcmpeqd	%xmm8,%xmm6
	pcmpeqd	%xmm8,%xmm7

	movdqa	0(%rdx),%xmm8
	movdqa	16(%rdx),%xmm9
	movdqa	32(%rdx),%xmm10
	movdqa	48(%rdx),%xmm11
	pand	%xmm0,%xmm8
	movdqa	64(%rdx),%xmm12
	pand	%xmm1,%xmm9
	movdqa	80(%rdx),%xmm13
	pand	%xmm2,%xmm10
	movdqa	96(%rdx),%xmm14
	pand	%xmm3,%xmm11
	movdqa	112(%rdx),%xmm15
	leaq	128(%rdx),%rbp
	pand	%xmm4,%xmm12
	pand	%xmm5,%xmm13
	pand	%xmm6,%xmm14
	pand	%xmm7,%xmm15
	por	%xmm10,%xmm8
	por	%xmm11,%xmm9
	por	%xmm12,%xmm8
	por	%xmm13,%xmm9
	por	%xmm14,%xmm8
	por	%xmm15,%xmm9

	por	%xmm9,%xmm8
	pshufd	$0x4e,%xmm8,%xmm9
	por	%xmm9,%xmm8
	movl	$0x80100,%r11d
	andl	OPENSSL_ia32cap_P+8(%rip),%r11d
	cmpl	$0x80100,%r11d
	je	.Lmulx_gather
.byte	102,76,15,126,195

	movq	%r8,128(%rsp)
	movq	%rdi,128+8(%rsp)
	movq	%rcx,128+16(%rsp)

	movq	(%rsi),%rax
	movq	8(%rsi),%rcx
	mulq	%rbx
	movq	%rax,(%rsp)
	movq	%rcx,%rax
	movq	%rdx,%r8

	mulq	%rbx
	addq	%rax,%r8
	movq	16(%rsi),%rax
	movq	%rdx,%r9
	adcq	$0,%r9

	mulq	%rbx
	addq	%rax,%r9
	movq	24(%rsi),%rax
	movq	%rdx,%r10
	adcq	$0,%r10

	mulq	%rbx
	addq	%rax,%r10
	movq	32(%rsi),%rax
	movq	%rdx,%r11
	adcq	$0,%r11

	mulq	%rbx
	addq	%rax,%r11
	movq	40(%rsi),%rax
	movq	%rdx,%r12
	adcq	$0,%r12

	mulq	%rbx
	addq	%rax,%r12
	movq	48(%rsi),%rax
	movq	%rdx,%r13
	adcq	$0,%r13

	mulq	%rbx
	addq	%rax,%r13
	movq	56(%rsi),%rax
	movq	%rdx,%r14
	adcq	$0,%r14

	mulq	%rbx
	addq	%rax,%r14
	movq	(%rsi),%rax
	movq	%rdx,%r15
	adcq	$0,%r15

	leaq	8(%rsp),%rdi
	movl	$7,%ecx
	jmp	.Loop_mul_gather

.align	32
.Loop_mul_gather:
	movdqa	0(%rbp),%xmm8
	movdqa	16(%rbp),%xmm9
	movdqa	32(%rbp),%xmm10
	movdqa	48(%rbp),%xmm11
	pand	%xmm0,%xmm8
	movdqa	64(%rbp),%xmm12
	pand	%xmm1,%xmm9
	movdqa	80(%rbp),%xmm13
	pand	%xmm2,%xmm10
	movdqa	96(%rbp),%xmm14
	pand	%xmm3,%xmm11
	movdqa	112(%rbp),%xmm15
	leaq	128(%rbp),%rbp
	pand	%xmm4,%xmm12
	pand	%xmm5,%xmm13
	pand	%xmm6,%xmm14
	pand	%xmm7,%xmm15
	por	%xmm10,%xmm8
	por	%xmm11,%xmm9
	por	%xmm12,%xmm8
	por	%xmm13,%xmm9
	por	%xmm14,%xmm8
	por	%xmm15,%xmm9

	por	%xmm9,%xmm8
	pshufd	$0x4e,%xmm8,%xmm9
	por	%xmm9,%xmm8
.byte	102,76,15,126,195

	mulq	%rbx
	addq	%rax,%r8
	movq	8(%rsi),%rax
	movq	%r8,(%rdi)
	movq	%rdx,%r8
	adcq	$0,%r8

	mulq	%rbx
	addq	%rax,%r9
	movq	16(%rsi),%rax
	adcq	$0,%rdx
	addq	%r9,%r8
	movq	%rdx,%r9
	adcq	$0,%r9

	mulq	%rbx
	addq	%rax,%r10
	movq	24(%rsi),%rax
	adcq	$0,%rdx
	addq	%r10,%r9
	movq	%rdx,%r10
	adcq	$0,%r10

	mulq	%rbx
	addq	%rax,%r11
	movq	32(%rsi),%rax
	adcq	$0,%rdx
	addq	%r11,%r10
	movq	%rdx,%r11
	adcq	$0,%r11

	mulq	%rbx
	addq	%rax,%r12
	movq	40(%rsi),%rax
	adcq	$0,%rdx
	addq	%r12,%r11
	movq	%rdx,%r12
	adcq	$0,%r12

	mulq	%rbx
	addq	%rax,%r13
	movq	48(%rsi),%rax
	adcq	$0,%rdx
	addq	%r13,%r12
	movq	%rdx,%r13
	adcq	$0,%r13

	mulq	%rbx
	addq	%rax,%r14
	movq	56(%rsi),%rax
	adcq	$0,%rdx
	addq	%r14,%r13
	movq	%rdx,%r14
	adcq	$0,%r14

	mulq	%rbx
	addq	%rax,%r15
	movq	(%rsi),%rax
	adcq	$0,%rdx
	addq	%r15,%r14
	movq	%rdx,%r15
	adcq	$0,%r15

	leaq	8(%rdi),%rdi

	decl	%ecx
	jnz	.Loop_mul_gather

	movq	%r8,(%rdi)
	movq	%r9,8(%rdi)
	movq	%r10,16(%rdi)
	movq	%r11,24(%rdi)
	movq	%r12,32(%rdi)
	movq	%r13,40(%rdi)
	movq	%r14,48(%rdi)
	movq	%r15,56(%rdi)

	movq	128+8(%rsp),%rdi
	movq	128+16(%rsp),%rbp

	movq	(%rsp),%r8
	movq	8(%rsp),%r9
	movq	16(%rsp),%r10
	movq	24(%rsp),%r11
	movq	32(%rsp),%r12
	movq	40(%rsp),%r13
	movq	48(%rsp),%r14
	movq	56(%rsp),%r15

	call	__rsaz_512_reduce
	jmp	.Lmul_gather_tail

.align	32
.Lmulx_gather:
.byte	102,76,15,126,194

	movq	%r8,128(%rsp)
	movq	%rdi,128+8(%rsp)
	movq	%rcx,128+16(%rsp)

	mulxq	(%rsi),%rbx,%r8
	movq	%rbx,(%rsp)
	xorl	%edi,%edi

	mulxq	8(%rsi),%rax,%r9

	mulxq	16(%rsi),%rbx,%r10
	adcxq	%rax,%r8

	mulxq	24(%rsi),%rax,%r11
	adcxq	%rbx,%r9

	mulxq	32(%rsi),%rbx,%r12
	adcxq	%rax,%r10

	mulxq	40(%rsi),%rax,%r13
	adcxq	%rbx,%r11

	mulxq	48(%rsi),%rbx,%r14
	adcxq	%rax,%r12

	mulxq	56(%rsi),%rax,%r15
	adcxq	%rbx,%r13
	adcxq	%rax,%r14
.byte	0x67
	movq	%r8,%rbx
	adcxq	%rdi,%r15

	movq	$-7,%rcx
	jmp	.Loop_mulx_gather

.align	32
.Loop_mulx_gather:
	movdqa	0(%rbp),%xmm8
	movdqa	16(%rbp),%xmm9
	movdqa	32(%rbp),%xmm10
	movdqa	48(%rbp),%xmm11
	pand	%xmm0,%xmm8
	movdqa	64(%rbp),%xmm12
	pand	%xmm1,%xmm9
	movdqa	80(%rbp),%xmm13
	pand	%xmm2,%xmm10
	movdqa	96(%rbp),%xmm14
	pand	%xmm3,%xmm11
	movdqa	112(%rbp),%xmm15
	leaq	128(%rbp),%rbp
	pand	%xmm4,%xmm12
	pand	%xmm5,%xmm13
	pand	%xmm6,%xmm14
	pand	%xmm7,%xmm15
	por	%xmm10,%xmm8
	por	%xmm11,%xmm9
	por	%xmm12,%xmm8
	por	%xmm13,%xmm9
	por	%xmm14,%xmm8
	por	%xmm15,%xmm9

	por	%xmm9,%xmm8
	pshufd	$0x4e,%xmm8,%xmm9
	por	%xmm9,%xmm8
.byte	102,76,15,126,194

.byte	0xc4,0x62,0xfb,0xf6,0x86,0x00,0x00,0x00,0x00
	adcxq	%rax,%rbx
	adoxq	%r9,%r8

	mulxq	8(%rsi),%rax,%r9
	adcxq	%rax,%r8
	adoxq	%r10,%r9

	mulxq	16(%rsi),%rax,%r10
	adcxq	%rax,%r9
	adoxq	%r11,%r10

.byte	0xc4,0x62,0xfb,0xf6,0x9e,0x18,0x00,0x00,0x00
	adcxq	%rax,%r10
	adoxq	%r12,%r11

	mulxq	32(%rsi),%rax,%r12
	adcxq	%rax,%r11
	adoxq	%r13,%r12

	mulxq	40(%rsi),%rax,%r13
	adcxq	%rax,%r12
	adoxq	%r14,%r13

.byte	0xc4,0x62,0xfb,0xf6,0xb6,0x30,0x00,0x00,0x00
	adcxq	%rax,%r13
.byte	0x67
	adoxq	%r15,%r14

	mulxq	56(%rsi),%rax,%r15
	movq	%rbx,64(%rsp,%rcx,8)
	adcxq	%rax,%r14
	adoxq	%rdi,%r15
	movq	%r8,%rbx
	adcxq	%rdi,%r15

	incq	%rcx
	jnz	.Loop_mulx_gather

	movq	%r8,64(%rsp)
	movq	%r9,64+8(%rsp)
	movq	%r10,64+16(%rsp)
	movq	%r11,64+24(%rsp)
	movq	%r12,64+32(%rsp)
	movq	%r13,64+40(%rsp)
	movq	%r14,64+48(%rsp)
	movq	%r15,64+56(%rsp)

	movq	128(%rsp),%rdx
	movq	128+8(%rsp),%rdi
	movq	128+16(%rsp),%rbp

	movq	(%rsp),%r8
	movq	8(%rsp),%r9
	movq	16(%rsp),%r10
	movq	24(%rsp),%r11
	movq	32(%rsp),%r12
	movq	40(%rsp),%r13
	movq	48(%rsp),%r14
	movq	56(%rsp),%r15

	call	__rsaz_512_reducex

.Lmul_gather_tail:
	addq	64(%rsp),%r8
	adcq	72(%rsp),%r9
	adcq	80(%rsp),%r10
	adcq	88(%rsp),%r11
	adcq	96(%rsp),%r12
	adcq	104(%rsp),%r13
	adcq	112(%rsp),%r14
	adcq	120(%rsp),%r15
	sbbq	%rcx,%rcx

	call	__rsaz_512_subtract

	leaq	128+24+48(%rsp),%rax
.cfi_def_cfa	%rax,8
	movq	-48(%rax),%r15
.cfi_restore	%r15
	movq	-40(%rax),%r14
.cfi_restore	%r14
	movq	-32(%rax),%r13
.cfi_restore	%r13
	movq	-24(%rax),%r12
.cfi_restore	%r12
	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lmul_gather4_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	rsaz_512_mul_gather4,.-rsaz_512_mul_gather4
.globl	rsaz_512_mul_scatter4
.type	rsaz_512_mul_scatter4,@function
.align	32
rsaz_512_mul_scatter4:
.cfi_startproc	
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-56

	movl	%r9d,%r9d
	subq	$128+24,%rsp
.cfi_adjust_cfa_offset	128+24
.Lmul_scatter4_body:
	leaq	(%r8,%r9,8),%r8
.byte	102,72,15,110,199
.byte	102,72,15,110,202
.byte	102,73,15,110,208
	movq	%rcx,128(%rsp)

	movq	%rdi,%rbp
	movl	$0x80100,%r11d
	andl	OPENSSL_ia32cap_P+8(%rip),%r11d
	cmpl	$0x80100,%r11d
	je	.Lmulx_scatter
	movq	(%rdi),%rbx
	call	__rsaz_512_mul

.byte	102,72,15,126,199
.byte	102,72,15,126,205

	movq	(%rsp),%r8
	movq	8(%rsp),%r9
	movq	16(%rsp),%r10
	movq	24(%rsp),%r11
	movq	32(%rsp),%r12
	movq	40(%rsp),%r13
	movq	48(%rsp),%r14
	movq	56(%rsp),%r15

	call	__rsaz_512_reduce
	jmp	.Lmul_scatter_tail

.align	32
.Lmulx_scatter:
	movq	(%rdi),%rdx
	call	__rsaz_512_mulx

.byte	102,72,15,126,199
.byte	102,72,15,126,205

	movq	128(%rsp),%rdx
	movq	(%rsp),%r8
	movq	8(%rsp),%r9
	movq	16(%rsp),%r10
	movq	24(%rsp),%r11
	movq	32(%rsp),%r12
	movq	40(%rsp),%r13
	movq	48(%rsp),%r14
	movq	56(%rsp),%r15

	call	__rsaz_512_reducex

.Lmul_scatter_tail:
	addq	64(%rsp),%r8
	adcq	72(%rsp),%r9
	adcq	80(%rsp),%r10
	adcq	88(%rsp),%r11
	adcq	96(%rsp),%r12
	adcq	104(%rsp),%r13
	adcq	112(%rsp),%r14
	adcq	120(%rsp),%r15
.byte	102,72,15,126,214
	sbbq	%rcx,%rcx

	call	__rsaz_512_subtract

	movq	%r8,0(%rsi)
	movq	%r9,128(%rsi)
	movq	%r10,256(%rsi)
	movq	%r11,384(%rsi)
	movq	%r12,512(%rsi)
	movq	%r13,640(%rsi)
	movq	%r14,768(%rsi)
	movq	%r15,896(%rsi)

	leaq	128+24+48(%rsp),%rax
.cfi_def_cfa	%rax,8
	movq	-48(%rax),%r15
.cfi_restore	%r15
	movq	-40(%rax),%r14
.cfi_restore	%r14
	movq	-32(%rax),%r13
.cfi_restore	%r13
	movq	-24(%rax),%r12
.cfi_restore	%r12
	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lmul_scatter4_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	rsaz_512_mul_scatter4,.-rsaz_512_mul_scatter4
.globl	rsaz_512_mul_by_one
.type	rsaz_512_mul_by_one,@function
.align	32
rsaz_512_mul_by_one:
.cfi_startproc	
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-56

	subq	$128+24,%rsp
.cfi_adjust_cfa_offset	128+24
.Lmul_by_one_body:
	movl	OPENSSL_ia32cap_P+8(%rip),%eax
	movq	%rdx,%rbp
	movq	%rcx,128(%rsp)

	movq	(%rsi),%r8
	pxor	%xmm0,%xmm0
	movq	8(%rsi),%r9
	movq	16(%rsi),%r10
	movq	24(%rsi),%r11
	movq	32(%rsi),%r12
	movq	40(%rsi),%r13
	movq	48(%rsi),%r14
	movq	56(%rsi),%r15

	movdqa	%xmm0,(%rsp)
	movdqa	%xmm0,16(%rsp)
	movdqa	%xmm0,32(%rsp)
	movdqa	%xmm0,48(%rsp)
	movdqa	%xmm0,64(%rsp)
	movdqa	%xmm0,80(%rsp)
	movdqa	%xmm0,96(%rsp)
	andl	$0x80100,%eax
	cmpl	$0x80100,%eax
	je	.Lby_one_callx
	call	__rsaz_512_reduce
	jmp	.Lby_one_tail
.align	32
.Lby_one_callx:
	movq	128(%rsp),%rdx
	call	__rsaz_512_reducex
.Lby_one_tail:
	movq	%r8,(%rdi)
	movq	%r9,8(%rdi)
	movq	%r10,16(%rdi)
	movq	%r11,24(%rdi)
	movq	%r12,32(%rdi)
	movq	%r13,40(%rdi)
	movq	%r14,48(%rdi)
	movq	%r15,56(%rdi)

	leaq	128+24+48(%rsp),%rax
.cfi_def_cfa	%rax,8
	movq	-48(%rax),%r15
.cfi_restore	%r15
	movq	-40(%rax),%r14
.cfi_restore	%r14
	movq	-32(%rax),%r13
.cfi_restore	%r13
	movq	-24(%rax),%r12
.cfi_restore	%r12
	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lmul_by_one_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	rsaz_512_mul_by_one,.-rsaz_512_mul_by_one
.type	__rsaz_512_reduce,@function
.align	32
__rsaz_512_reduce:
.cfi_startproc	
	movq	%r8,%rbx
	imulq	128+8(%rsp),%rbx
	movq	0(%rbp),%rax
	movl	$8,%ecx
	jmp	.Lreduction_loop

.align	32
.Lreduction_loop:
	mulq	%rbx
	movq	8(%rbp),%rax
	negq	%r8
	movq	%rdx,%r8
	adcq	$0,%r8

	mulq	%rbx
	addq	%rax,%r9
	movq	16(%rbp),%rax
	adcq	$0,%rdx
	addq	%r9,%r8
	movq	%rdx,%r9
	adcq	$0,%r9

	mulq	%rbx
	addq	%rax,%r10
	movq	24(%rbp),%rax
	adcq	$0,%rdx
	addq	%r10,%r9
	movq	%rdx,%r10
	adcq	$0,%r10

	mulq	%rbx
	addq	%rax,%r11
	movq	32(%rbp),%rax
	adcq	$0,%rdx
	addq	%r11,%r10
	movq	128+8(%rsp),%rsi


	adcq	$0,%rdx
	movq	%rdx,%r11

	mulq	%rbx
	addq	%rax,%r12
	movq	40(%rbp),%rax
	adcq	$0,%rdx
	imulq	%r8,%rsi
	addq	%r12,%r11
	movq	%rdx,%r12
	adcq	$0,%r12

	mulq	%rbx
	addq	%rax,%r13
	movq	48(%rbp),%rax
	adcq	$0,%rdx
	addq	%r13,%r12
	movq	%rdx,%r13
	adcq	$0,%r13

	mulq	%rbx
	addq	%rax,%r14
	movq	56(%rbp),%rax
	adcq	$0,%rdx
	addq	%r14,%r13
	movq	%rdx,%r14
	adcq	$0,%r14

	mulq	%rbx
	movq	%rsi,%rbx
	addq	%rax,%r15
	movq	0(%rbp),%rax
	adcq	$0,%rdx
	addq	%r15,%r14
	movq	%rdx,%r15
	adcq	$0,%r15

	decl	%ecx
	jne	.Lreduction_loop

	.byte	0xf3,0xc3
.cfi_endproc	
.size	__rsaz_512_reduce,.-__rsaz_512_reduce
.type	__rsaz_512_reducex,@function
.align	32
__rsaz_512_reducex:
.cfi_startproc	

	imulq	%r8,%rdx
	xorq	%rsi,%rsi
	movl	$8,%ecx
	jmp	.Lreduction_loopx

.align	32
.Lreduction_loopx:
	movq	%r8,%rbx
	mulxq	0(%rbp),%rax,%r8
	adcxq	%rbx,%rax
	adoxq	%r9,%r8

	mulxq	8(%rbp),%rax,%r9
	adcxq	%rax,%r8
	adoxq	%r10,%r9

	mulxq	16(%rbp),%rbx,%r10
	adcxq	%rbx,%r9
	adoxq	%r11,%r10

	mulxq	24(%rbp),%rbx,%r11
	adcxq	%rbx,%r10
	adoxq	%r12,%r11

.byte	0xc4,0x62,0xe3,0xf6,0xa5,0x20,0x00,0x00,0x00
	movq	%rdx,%rax
	movq	%r8,%rdx
	adcxq	%rbx,%r11
	adoxq	%r13,%r12

	mulxq	128+8(%rsp),%rbx,%rdx
	movq	%rax,%rdx

	mulxq	40(%rbp),%rax,%r13
	adcxq	%rax,%r12
	adoxq	%r14,%r13

.byte	0xc4,0x62,0xfb,0xf6,0xb5,0x30,0x00,0x00,0x00
	adcxq	%rax,%r13
	adoxq	%r15,%r14

	mulxq	56(%rbp),%rax,%r15
	movq	%rbx,%rdx
	adcxq	%rax,%r14
	adoxq	%rsi,%r15
	adcxq	%rsi,%r15

	decl	%ecx
	jne	.Lreduction_loopx

	.byte	0xf3,0xc3
.cfi_endproc	
.size	__rsaz_512_reducex,.-__rsaz_512_reducex
.type	__rsaz_512_subtract,@function
.align	32
__rsaz_512_subtract:
.cfi_startproc	
	movq	%r8,(%rdi)
	movq	%r9,8(%rdi)
	movq	%r10,16(%rdi)
	movq	%r11,24(%rdi)
	movq	%r12,32(%rdi)
	movq	%r13,40(%rdi)
	movq	%r14,48(%rdi)
	movq	%r15,56(%rdi)

	movq	0(%rbp),%r8
	movq	8(%rbp),%r9
	negq	%r8
	notq	%r9
	andq	%rcx,%r8
	movq	16(%rbp),%r10
	andq	%rcx,%r9
	notq	%r10
	movq	24(%rbp),%r11
	andq	%rcx,%r10
	notq	%r11
	movq	32(%rbp),%r12
	andq	%rcx,%r11
	notq	%r12
	movq	40(%rbp),%r13
	andq	%rcx,%r12
	notq	%r13
	movq	48(%rbp),%r14
	andq	%rcx,%r13
	notq	%r14
	movq	56(%rbp),%r15
	andq	%rcx,%r14
	notq	%r15
	andq	%rcx,%r15

	addq	(%rdi),%r8
	adcq	8(%rdi),%r9
	adcq	16(%rdi),%r10
	adcq	24(%rdi),%r11
	adcq	32(%rdi),%r12
	adcq	40(%rdi),%r13
	adcq	48(%rdi),%r14
	adcq	56(%rdi),%r15

	movq	%r8,(%rdi)
	movq	%r9,8(%rdi)
	movq	%r10,16(%rdi)
	movq	%r11,24(%rdi)
	movq	%r12,32(%rdi)
	movq	%r13,40(%rdi)
	movq	%r14,48(%rdi)
	movq	%r15,56(%rdi)

	.byte	0xf3,0xc3
.cfi_endproc	
.size	__rsaz_512_subtract,.-__rsaz_512_subtract
.type	__rsaz_512_mul,@function
.align	32
__rsaz_512_mul:
.cfi_startproc	
	leaq	8(%rsp),%rdi

	movq	(%rsi),%rax
	mulq	%rbx
	movq	%rax,(%rdi)
	movq	8(%rsi),%rax
	movq	%rdx,%r8

	mulq	%rbx
	addq	%rax,%r8
	movq	16(%rsi),%rax
	movq	%rdx,%r9
	adcq	$0,%r9

	mulq	%rbx
	addq	%rax,%r9
	movq	24(%rsi),%rax
	movq	%rdx,%r10
	adcq	$0,%r10

	mulq	%rbx
	addq	%rax,%r10
	movq	32(%rsi),%rax
	movq	%rdx,%r11
	adcq	$0,%r11

	mulq	%rbx
	addq	%rax,%r11
	movq	40(%rsi),%rax
	movq	%rdx,%r12
	adcq	$0,%r12

	mulq	%rbx
	addq	%rax,%r12
	movq	48(%rsi),%rax
	movq	%rdx,%r13
	adcq	$0,%r13

	mulq	%rbx
	addq	%rax,%r13
	movq	56(%rsi),%rax
	movq	%rdx,%r14
	adcq	$0,%r14

	mulq	%rbx
	addq	%rax,%r14
	movq	(%rsi),%rax
	movq	%rdx,%r15
	adcq	$0,%r15

	leaq	8(%rbp),%rbp
	leaq	8(%rdi),%rdi

	movl	$7,%ecx
	jmp	.Loop_mul

.align	32
.Loop_mul:
	movq	(%rbp),%rbx
	mulq	%rbx
	addq	%rax,%r8
	movq	8(%rsi),%rax
	movq	%r8,(%rdi)
	movq	%rdx,%r8
	adcq	$0,%r8

	mulq	%rbx
	addq	%rax,%r9
	movq	16(%rsi),%rax
	adcq	$0,%rdx
	addq	%r9,%r8
	movq	%rdx,%r9
	adcq	$0,%r9

	mulq	%rbx
	addq	%rax,%r10
	movq	24(%rsi),%rax
	adcq	$0,%rdx
	addq	%r10,%r9
	movq	%rdx,%r10
	adcq	$0,%r10

	mulq	%rbx
	addq	%rax,%r11
	movq	32(%rsi),%rax
	adcq	$0,%rdx
	addq	%r11,%r10
	movq	%rdx,%r11
	adcq	$0,%r11

	mulq	%rbx
	addq	%rax,%r12
	movq	40(%rsi),%rax
	adcq	$0,%rdx
	addq	%r12,%r11
	movq	%rdx,%r12
	adcq	$0,%r12

	mulq	%rbx
	addq	%rax,%r13
	movq	48(%rsi),%rax
	adcq	$0,%rdx
	addq	%r13,%r12
	movq	%rdx,%r13
	adcq	$0,%r13

	mulq	%rbx
	addq	%rax,%r14
	movq	56(%rsi),%rax
	adcq	$0,%rdx
	addq	%r14,%r13
	movq	%rdx,%r14
	leaq	8(%rbp),%rbp
	adcq	$0,%r14

	mulq	%rbx
	addq	%rax,%r15
	movq	(%rsi),%rax
	adcq	$0,%rdx
	addq	%r15,%r14
	movq	%rdx,%r15
	adcq	$0,%r15

	leaq	8(%rdi),%rdi

	decl	%ecx
	jnz	.Loop_mul

	movq	%r8,(%rdi)
	movq	%r9,8(%rdi)
	movq	%r10,16(%rdi)
	movq	%r11,24(%rdi)
	movq	%r12,32(%rdi)
	movq	%r13,40(%rdi)
	movq	%r14,48(%rdi)
	movq	%r15,56(%rdi)

	.byte	0xf3,0xc3
.cfi_endproc	
.size	__rsaz_512_mul,.-__rsaz_512_mul
.type	__rsaz_512_mulx,@function
.align	32
__rsaz_512_mulx:
.cfi_startproc	
	mulxq	(%rsi),%rbx,%r8
	movq	$-6,%rcx

	mulxq	8(%rsi),%rax,%r9
	movq	%rbx,8(%rsp)

	mulxq	16(%rsi),%rbx,%r10
	adcq	%rax,%r8

	mulxq	24(%rsi),%rax,%r11
	adcq	%rbx,%r9

	mulxq	32(%rsi),%rbx,%r12
	adcq	%rax,%r10

	mulxq	40(%rsi),%rax,%r13
	adcq	%rbx,%r11

	mulxq	48(%rsi),%rbx,%r14
	adcq	%rax,%r12

	mulxq	56(%rsi),%rax,%r15
	movq	8(%rbp),%rdx
	adcq	%rbx,%r13
	adcq	%rax,%r14
	adcq	$0,%r15

	xorq	%rdi,%rdi
	jmp	.Loop_mulx

.align	32
.Loop_mulx:
	movq	%r8,%rbx
	mulxq	(%rsi),%rax,%r8
	adcxq	%rax,%rbx
	adoxq	%r9,%r8

	mulxq	8(%rsi),%rax,%r9
	adcxq	%rax,%r8
	adoxq	%r10,%r9

	mulxq	16(%rsi),%rax,%r10
	adcxq	%rax,%r9
	adoxq	%r11,%r10

	mulxq	24(%rsi),%rax,%r11
	adcxq	%rax,%r10
	adoxq	%r12,%r11

.byte	0x3e,0xc4,0x62,0xfb,0xf6,0xa6,0x20,0x00,0x00,0x00
	adcxq	%rax,%r11
	adoxq	%r13,%r12

	mulxq	40(%rsi),%rax,%r13
	adcxq	%rax,%r12
	adoxq	%r14,%r13

	mulxq	48(%rsi),%rax,%r14
	adcxq	%rax,%r13
	adoxq	%r15,%r14

	mulxq	56(%rsi),%rax,%r15
	movq	64(%rbp,%rcx,8),%rdx
	movq	%rbx,8+64-8(%rsp,%rcx,8)
	adcxq	%rax,%r14
	adoxq	%rdi,%r15
	adcxq	%rdi,%r15

	incq	%rcx
	jnz	.Loop_mulx

	movq	%r8,%rbx
	mulxq	(%rsi),%rax,%r8
	adcxq	%rax,%rbx
	adoxq	%r9,%r8

.byte	0xc4,0x62,0xfb,0xf6,0x8e,0x08,0x00,0x00,0x00
	adcxq	%rax,%r8
	adoxq	%r10,%r9

.byte	0xc4,0x62,0xfb,0xf6,0x96,0x10,0x00,0x00,0x00
	adcxq	%rax,%r9
	adoxq	%r11,%r10

	mulxq	24(%rsi),%rax,%r11
	adcxq	%rax,%r10
	adoxq	%r12,%r11

	mulxq	32(%rsi),%rax,%r12
	adcxq	%rax,%r11
	adoxq	%r13,%r12

	mulxq	40(%rsi),%rax,%r13
	adcxq	%rax,%r12
	adoxq	%r14,%r13

.byte	0xc4,0x62,0xfb,0xf6,0xb6,0x30,0x00,0x00,0x00
	adcxq	%rax,%r13
	adoxq	%r15,%r14

.byte	0xc4,0x62,0xfb,0xf6,0xbe,0x38,0x00,0x00,0x00
	adcxq	%rax,%r14
	adoxq	%rdi,%r15
	adcxq	%rdi,%r15

	movq	%rbx,8+64-8(%rsp)
	movq	%r8,8+64(%rsp)
	movq	%r9,8+64+8(%rsp)
	movq	%r10,8+64+16(%rsp)
	movq	%r11,8+64+24(%rsp)
	movq	%r12,8+64+32(%rsp)
	movq	%r13,8+64+40(%rsp)
	movq	%r14,8+64+48(%rsp)
	movq	%r15,8+64+56(%rsp)

	.byte	0xf3,0xc3
.cfi_endproc	
.size	__rsaz_512_mulx,.-__rsaz_512_mulx
.globl	rsaz_512_scatter4
.type	rsaz_512_scatter4,@function
.align	16
rsaz_512_scatter4:
.cfi_startproc	
	leaq	(%rdi,%rdx,8),%rdi
	movl	$8,%r9d
	jmp	.Loop_scatter
.align	16
.Loop_scatter:
	movq	(%rsi),%rax
	leaq	8(%rsi),%rsi
	movq	%rax,(%rdi)
	leaq	128(%rdi),%rdi
	decl	%r9d
	jnz	.Loop_scatter
	.byte	0xf3,0xc3
.cfi_endproc	
.size	rsaz_512_scatter4,.-rsaz_512_scatter4

.globl	rsaz_512_gather4
.type	rsaz_512_gather4,@function
.align	16
rsaz_512_gather4:
.cfi_startproc	
	movd	%edx,%xmm8
	movdqa	.Linc+16(%rip),%xmm1
	movdqa	.Linc(%rip),%xmm0

	pshufd	$0,%xmm8,%xmm8
	movdqa	%xmm1,%xmm7
	movdqa	%xmm1,%xmm2
	paddd	%xmm0,%xmm1
	pcmpeqd	%xmm8,%xmm0
	movdqa	%xmm7,%xmm3
	paddd	%xmm1,%xmm2
	pcmpeqd	%xmm8,%xmm1
	movdqa	%xmm7,%xmm4
	paddd	%xmm2,%xmm3
	pcmpeqd	%xmm8,%xmm2
	movdqa	%xmm7,%xmm5
	paddd	%xmm3,%xmm4
	pcmpeqd	%xmm8,%xmm3
	movdqa	%xmm7,%xmm6
	paddd	%xmm4,%xmm5
	pcmpeqd	%xmm8,%xmm4
	paddd	%xmm5,%xmm6
	pcmpeqd	%xmm8,%xmm5
	paddd	%xmm6,%xmm7
	pcmpeqd	%xmm8,%xmm6
	pcmpeqd	%xmm8,%xmm7
	movl	$8,%r9d
	jmp	.Loop_gather
.align	16
.Loop_gather:
	movdqa	0(%rsi),%xmm8
	movdqa	16(%rsi),%xmm9
	movdqa	32(%rsi),%xmm10
	movdqa	48(%rsi),%xmm11
	pand	%xmm0,%xmm8
	movdqa	64(%rsi),%xmm12
	pand	%xmm1,%xmm9
	movdqa	80(%rsi),%xmm13
	pand	%xmm2,%xmm10
	movdqa	96(%rsi),%xmm14
	pand	%xmm3,%xmm11
	movdqa	112(%rsi),%xmm15
	leaq	128(%rsi),%rsi
	pand	%xmm4,%xmm12
	pand	%xmm5,%xmm13
	pand	%xmm6,%xmm14
	pand	%xmm7,%xmm15
	por	%xmm10,%xmm8
	por	%xmm11,%xmm9
	por	%xmm12,%xmm8
	por	%xmm13,%xmm9
	por	%xmm14,%xmm8
	por	%xmm15,%xmm9

	por	%xmm9,%xmm8
	pshufd	$0x4e,%xmm8,%xmm9
	por	%xmm9,%xmm8
	movq	%xmm8,(%rdi)
	leaq	8(%rdi),%rdi
	decl	%r9d
	jnz	.Loop_gather
	.byte	0xf3,0xc3
.LSEH_end_rsaz_512_gather4:
.cfi_endproc	
.size	rsaz_512_gather4,.-rsaz_512_gather4

.align	64
.Linc:
.long	0,0, 1,1
.long	2,2, 2,2
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                                                                                                                                                                node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/bn/x86_64-gf2m.s                      0000664 0000000 0000000 00000013350 14746647661 0026307 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	

.type	_mul_1x1,@function
.align	16
_mul_1x1:
.cfi_startproc	
	subq	$128+8,%rsp
.cfi_adjust_cfa_offset	128+8
	movq	$-1,%r9
	leaq	(%rax,%rax,1),%rsi
	shrq	$3,%r9
	leaq	(,%rax,4),%rdi
	andq	%rax,%r9
	leaq	(,%rax,8),%r12
	sarq	$63,%rax
	leaq	(%r9,%r9,1),%r10
	sarq	$63,%rsi
	leaq	(,%r9,4),%r11
	andq	%rbp,%rax
	sarq	$63,%rdi
	movq	%rax,%rdx
	shlq	$63,%rax
	andq	%rbp,%rsi
	shrq	$1,%rdx
	movq	%rsi,%rcx
	shlq	$62,%rsi
	andq	%rbp,%rdi
	shrq	$2,%rcx
	xorq	%rsi,%rax
	movq	%rdi,%rbx
	shlq	$61,%rdi
	xorq	%rcx,%rdx
	shrq	$3,%rbx
	xorq	%rdi,%rax
	xorq	%rbx,%rdx

	movq	%r9,%r13
	movq	$0,0(%rsp)
	xorq	%r10,%r13
	movq	%r9,8(%rsp)
	movq	%r11,%r14
	movq	%r10,16(%rsp)
	xorq	%r12,%r14
	movq	%r13,24(%rsp)

	xorq	%r11,%r9
	movq	%r11,32(%rsp)
	xorq	%r11,%r10
	movq	%r9,40(%rsp)
	xorq	%r11,%r13
	movq	%r10,48(%rsp)
	xorq	%r14,%r9
	movq	%r13,56(%rsp)
	xorq	%r14,%r10

	movq	%r12,64(%rsp)
	xorq	%r14,%r13
	movq	%r9,72(%rsp)
	xorq	%r11,%r9
	movq	%r10,80(%rsp)
	xorq	%r11,%r10
	movq	%r13,88(%rsp)

	xorq	%r11,%r13
	movq	%r14,96(%rsp)
	movq	%r8,%rsi
	movq	%r9,104(%rsp)
	andq	%rbp,%rsi
	movq	%r10,112(%rsp)
	shrq	$4,%rbp
	movq	%r13,120(%rsp)
	movq	%r8,%rdi
	andq	%rbp,%rdi
	shrq	$4,%rbp

	movq	(%rsp,%rsi,8),%xmm0
	movq	%r8,%rsi
	andq	%rbp,%rsi
	shrq	$4,%rbp
	movq	(%rsp,%rdi,8),%rcx
	movq	%r8,%rdi
	movq	%rcx,%rbx
	shlq	$4,%rcx
	andq	%rbp,%rdi
	movq	(%rsp,%rsi,8),%xmm1
	shrq	$60,%rbx
	xorq	%rcx,%rax
	pslldq	$1,%xmm1
	movq	%r8,%rsi
	shrq	$4,%rbp
	xorq	%rbx,%rdx
	andq	%rbp,%rsi
	shrq	$4,%rbp
	pxor	%xmm1,%xmm0
	movq	(%rsp,%rdi,8),%rcx
	movq	%r8,%rdi
	movq	%rcx,%rbx
	shlq	$12,%rcx
	andq	%rbp,%rdi
	movq	(%rsp,%rsi,8),%xmm1
	shrq	$52,%rbx
	xorq	%rcx,%rax
	pslldq	$2,%xmm1
	movq	%r8,%rsi
	shrq	$4,%rbp
	xorq	%rbx,%rdx
	andq	%rbp,%rsi
	shrq	$4,%rbp
	pxor	%xmm1,%xmm0
	movq	(%rsp,%rdi,8),%rcx
	movq	%r8,%rdi
	movq	%rcx,%rbx
	shlq	$20,%rcx
	andq	%rbp,%rdi
	movq	(%rsp,%rsi,8),%xmm1
	shrq	$44,%rbx
	xorq	%rcx,%rax
	pslldq	$3,%xmm1
	movq	%r8,%rsi
	shrq	$4,%rbp
	xorq	%rbx,%rdx
	andq	%rbp,%rsi
	shrq	$4,%rbp
	pxor	%xmm1,%xmm0
	movq	(%rsp,%rdi,8),%rcx
	movq	%r8,%rdi
	movq	%rcx,%rbx
	shlq	$28,%rcx
	andq	%rbp,%rdi
	movq	(%rsp,%rsi,8),%xmm1
	shrq	$36,%rbx
	xorq	%rcx,%rax
	pslldq	$4,%xmm1
	movq	%r8,%rsi
	shrq	$4,%rbp
	xorq	%rbx,%rdx
	andq	%rbp,%rsi
	shrq	$4,%rbp
	pxor	%xmm1,%xmm0
	movq	(%rsp,%rdi,8),%rcx
	movq	%r8,%rdi
	movq	%rcx,%rbx
	shlq	$36,%rcx
	andq	%rbp,%rdi
	movq	(%rsp,%rsi,8),%xmm1
	shrq	$28,%rbx
	xorq	%rcx,%rax
	pslldq	$5,%xmm1
	movq	%r8,%rsi
	shrq	$4,%rbp
	xorq	%rbx,%rdx
	andq	%rbp,%rsi
	shrq	$4,%rbp
	pxor	%xmm1,%xmm0
	movq	(%rsp,%rdi,8),%rcx
	movq	%r8,%rdi
	movq	%rcx,%rbx
	shlq	$44,%rcx
	andq	%rbp,%rdi
	movq	(%rsp,%rsi,8),%xmm1
	shrq	$20,%rbx
	xorq	%rcx,%rax
	pslldq	$6,%xmm1
	movq	%r8,%rsi
	shrq	$4,%rbp
	xorq	%rbx,%rdx
	andq	%rbp,%rsi
	shrq	$4,%rbp
	pxor	%xmm1,%xmm0
	movq	(%rsp,%rdi,8),%rcx
	movq	%r8,%rdi
	movq	%rcx,%rbx
	shlq	$52,%rcx
	andq	%rbp,%rdi
	movq	(%rsp,%rsi,8),%xmm1
	shrq	$12,%rbx
	xorq	%rcx,%rax
	pslldq	$7,%xmm1
	movq	%r8,%rsi
	shrq	$4,%rbp
	xorq	%rbx,%rdx
	andq	%rbp,%rsi
	shrq	$4,%rbp
	pxor	%xmm1,%xmm0
	movq	(%rsp,%rdi,8),%rcx
	movq	%rcx,%rbx
	shlq	$60,%rcx
.byte	102,72,15,126,198
	shrq	$4,%rbx
	xorq	%rcx,%rax
	psrldq	$8,%xmm0
	xorq	%rbx,%rdx
.byte	102,72,15,126,199
	xorq	%rsi,%rax
	xorq	%rdi,%rdx

	addq	$128+8,%rsp
.cfi_adjust_cfa_offset	-128-8
	.byte	0xf3,0xc3
.Lend_mul_1x1:
.cfi_endproc	
.size	_mul_1x1,.-_mul_1x1

.globl	bn_GF2m_mul_2x2
.type	bn_GF2m_mul_2x2,@function
.align	16
bn_GF2m_mul_2x2:
.cfi_startproc	
	movq	%rsp,%rax
	movq	OPENSSL_ia32cap_P(%rip),%r10
	btq	$33,%r10
	jnc	.Lvanilla_mul_2x2

.byte	102,72,15,110,198
.byte	102,72,15,110,201
.byte	102,72,15,110,210
.byte	102,73,15,110,216
	movdqa	%xmm0,%xmm4
	movdqa	%xmm1,%xmm5
.byte	102,15,58,68,193,0
	pxor	%xmm2,%xmm4
	pxor	%xmm3,%xmm5
.byte	102,15,58,68,211,0
.byte	102,15,58,68,229,0
	xorps	%xmm0,%xmm4
	xorps	%xmm2,%xmm4
	movdqa	%xmm4,%xmm5
	pslldq	$8,%xmm4
	psrldq	$8,%xmm5
	pxor	%xmm4,%xmm2
	pxor	%xmm5,%xmm0
	movdqu	%xmm2,0(%rdi)
	movdqu	%xmm0,16(%rdi)
	.byte	0xf3,0xc3

.align	16
.Lvanilla_mul_2x2:
	leaq	-136(%rsp),%rsp
.cfi_adjust_cfa_offset	8*17
	movq	%r14,80(%rsp)
.cfi_rel_offset	%r14,8*10
	movq	%r13,88(%rsp)
.cfi_rel_offset	%r13,8*11
	movq	%r12,96(%rsp)
.cfi_rel_offset	%r12,8*12
	movq	%rbp,104(%rsp)
.cfi_rel_offset	%rbp,8*13
	movq	%rbx,112(%rsp)
.cfi_rel_offset	%rbx,8*14
.Lbody_mul_2x2:
	movq	%rdi,32(%rsp)
	movq	%rsi,40(%rsp)
	movq	%rdx,48(%rsp)
	movq	%rcx,56(%rsp)
	movq	%r8,64(%rsp)

	movq	$0xf,%r8
	movq	%rsi,%rax
	movq	%rcx,%rbp
	call	_mul_1x1
	movq	%rax,16(%rsp)
	movq	%rdx,24(%rsp)

	movq	48(%rsp),%rax
	movq	64(%rsp),%rbp
	call	_mul_1x1
	movq	%rax,0(%rsp)
	movq	%rdx,8(%rsp)

	movq	40(%rsp),%rax
	movq	56(%rsp),%rbp
	xorq	48(%rsp),%rax
	xorq	64(%rsp),%rbp
	call	_mul_1x1
	movq	0(%rsp),%rbx
	movq	8(%rsp),%rcx
	movq	16(%rsp),%rdi
	movq	24(%rsp),%rsi
	movq	32(%rsp),%rbp

	xorq	%rdx,%rax
	xorq	%rcx,%rdx
	xorq	%rbx,%rax
	movq	%rbx,0(%rbp)
	xorq	%rdi,%rdx
	movq	%rsi,24(%rbp)
	xorq	%rsi,%rax
	xorq	%rsi,%rdx
	xorq	%rdx,%rax
	movq	%rdx,16(%rbp)
	movq	%rax,8(%rbp)

	movq	80(%rsp),%r14
.cfi_restore	%r14
	movq	88(%rsp),%r13
.cfi_restore	%r13
	movq	96(%rsp),%r12
.cfi_restore	%r12
	movq	104(%rsp),%rbp
.cfi_restore	%rbp
	movq	112(%rsp),%rbx
.cfi_restore	%rbx
	leaq	136(%rsp),%rsp
.cfi_adjust_cfa_offset	-8*17
.Lepilogue_mul_2x2:
	.byte	0xf3,0xc3
.Lend_mul_2x2:
.cfi_endproc	
.size	bn_GF2m_mul_2x2,.-bn_GF2m_mul_2x2
.byte	71,70,40,50,94,109,41,32,77,117,108,116,105,112,108,105,99,97,116,105,111,110,32,102,111,114,32,120,56,54,95,54,52,44,32,67,82,89,80,84,79,71,65,77,83,32,98,121,32,60,97,112,112,114,111,64,111,112,101,110,115,115,108,46,111,114,103,62,0
.align	16
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                                                                                                                                        node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/bn/x86_64-mont.s                      0000664 0000000 0000000 00000050171 14746647661 0026433 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	



.globl	bn_mul_mont
.type	bn_mul_mont,@function
.align	16
bn_mul_mont:
.cfi_startproc	
	movl	%r9d,%r9d
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	testl	$3,%r9d
	jnz	.Lmul_enter
	cmpl	$8,%r9d
	jb	.Lmul_enter
	movl	OPENSSL_ia32cap_P+8(%rip),%r11d
	cmpq	%rsi,%rdx
	jne	.Lmul4x_enter
	testl	$7,%r9d
	jz	.Lsqr8x_enter
	jmp	.Lmul4x_enter

.align	16
.Lmul_enter:
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56

	negq	%r9
	movq	%rsp,%r11
	leaq	-16(%rsp,%r9,8),%r10
	negq	%r9
	andq	$-1024,%r10









	subq	%r10,%r11
	andq	$-4096,%r11
	leaq	(%r10,%r11,1),%rsp
	movq	(%rsp),%r11
	cmpq	%r10,%rsp
	ja	.Lmul_page_walk
	jmp	.Lmul_page_walk_done

.align	16
.Lmul_page_walk:
	leaq	-4096(%rsp),%rsp
	movq	(%rsp),%r11
	cmpq	%r10,%rsp
	ja	.Lmul_page_walk
.Lmul_page_walk_done:

	movq	%rax,8(%rsp,%r9,8)
.cfi_escape	0x0f,0x0a,0x77,0x08,0x79,0x00,0x38,0x1e,0x22,0x06,0x23,0x08
.Lmul_body:
	movq	%rdx,%r12
	movq	(%r8),%r8
	movq	(%r12),%rbx
	movq	(%rsi),%rax

	xorq	%r14,%r14
	xorq	%r15,%r15

	movq	%r8,%rbp
	mulq	%rbx
	movq	%rax,%r10
	movq	(%rcx),%rax

	imulq	%r10,%rbp
	movq	%rdx,%r11

	mulq	%rbp
	addq	%rax,%r10
	movq	8(%rsi),%rax
	adcq	$0,%rdx
	movq	%rdx,%r13

	leaq	1(%r15),%r15
	jmp	.L1st_enter

.align	16
.L1st:
	addq	%rax,%r13
	movq	(%rsi,%r15,8),%rax
	adcq	$0,%rdx
	addq	%r11,%r13
	movq	%r10,%r11
	adcq	$0,%rdx
	movq	%r13,-16(%rsp,%r15,8)
	movq	%rdx,%r13

.L1st_enter:
	mulq	%rbx
	addq	%rax,%r11
	movq	(%rcx,%r15,8),%rax
	adcq	$0,%rdx
	leaq	1(%r15),%r15
	movq	%rdx,%r10

	mulq	%rbp
	cmpq	%r9,%r15
	jne	.L1st

	addq	%rax,%r13
	movq	(%rsi),%rax
	adcq	$0,%rdx
	addq	%r11,%r13
	adcq	$0,%rdx
	movq	%r13,-16(%rsp,%r15,8)
	movq	%rdx,%r13
	movq	%r10,%r11

	xorq	%rdx,%rdx
	addq	%r11,%r13
	adcq	$0,%rdx
	movq	%r13,-8(%rsp,%r9,8)
	movq	%rdx,(%rsp,%r9,8)

	leaq	1(%r14),%r14
	jmp	.Louter
.align	16
.Louter:
	movq	(%r12,%r14,8),%rbx
	xorq	%r15,%r15
	movq	%r8,%rbp
	movq	(%rsp),%r10
	mulq	%rbx
	addq	%rax,%r10
	movq	(%rcx),%rax
	adcq	$0,%rdx

	imulq	%r10,%rbp
	movq	%rdx,%r11

	mulq	%rbp
	addq	%rax,%r10
	movq	8(%rsi),%rax
	adcq	$0,%rdx
	movq	8(%rsp),%r10
	movq	%rdx,%r13

	leaq	1(%r15),%r15
	jmp	.Linner_enter

.align	16
.Linner:
	addq	%rax,%r13
	movq	(%rsi,%r15,8),%rax
	adcq	$0,%rdx
	addq	%r10,%r13
	movq	(%rsp,%r15,8),%r10
	adcq	$0,%rdx
	movq	%r13,-16(%rsp,%r15,8)
	movq	%rdx,%r13

.Linner_enter:
	mulq	%rbx
	addq	%rax,%r11
	movq	(%rcx,%r15,8),%rax
	adcq	$0,%rdx
	addq	%r11,%r10
	movq	%rdx,%r11
	adcq	$0,%r11
	leaq	1(%r15),%r15

	mulq	%rbp
	cmpq	%r9,%r15
	jne	.Linner

	addq	%rax,%r13
	movq	(%rsi),%rax
	adcq	$0,%rdx
	addq	%r10,%r13
	movq	(%rsp,%r15,8),%r10
	adcq	$0,%rdx
	movq	%r13,-16(%rsp,%r15,8)
	movq	%rdx,%r13

	xorq	%rdx,%rdx
	addq	%r11,%r13
	adcq	$0,%rdx
	addq	%r10,%r13
	adcq	$0,%rdx
	movq	%r13,-8(%rsp,%r9,8)
	movq	%rdx,(%rsp,%r9,8)

	leaq	1(%r14),%r14
	cmpq	%r9,%r14
	jb	.Louter

	xorq	%r14,%r14
	movq	(%rsp),%rax
	movq	%r9,%r15

.align	16
.Lsub:	sbbq	(%rcx,%r14,8),%rax
	movq	%rax,(%rdi,%r14,8)
	movq	8(%rsp,%r14,8),%rax
	leaq	1(%r14),%r14
	decq	%r15
	jnz	.Lsub

	sbbq	$0,%rax
	movq	$-1,%rbx
	xorq	%rax,%rbx
	xorq	%r14,%r14
	movq	%r9,%r15

.Lcopy:
	movq	(%rdi,%r14,8),%rcx
	movq	(%rsp,%r14,8),%rdx
	andq	%rbx,%rcx
	andq	%rax,%rdx
	movq	%r9,(%rsp,%r14,8)
	orq	%rcx,%rdx
	movq	%rdx,(%rdi,%r14,8)
	leaq	1(%r14),%r14
	subq	$1,%r15
	jnz	.Lcopy

	movq	8(%rsp,%r9,8),%rsi
.cfi_def_cfa	%rsi,8
	movq	$1,%rax
	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lmul_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	bn_mul_mont,.-bn_mul_mont
.type	bn_mul4x_mont,@function
.align	16
bn_mul4x_mont:
.cfi_startproc	
	movl	%r9d,%r9d
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
.Lmul4x_enter:
	andl	$0x80100,%r11d
	cmpl	$0x80100,%r11d
	je	.Lmulx4x_enter
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56

	negq	%r9
	movq	%rsp,%r11
	leaq	-32(%rsp,%r9,8),%r10
	negq	%r9
	andq	$-1024,%r10

	subq	%r10,%r11
	andq	$-4096,%r11
	leaq	(%r10,%r11,1),%rsp
	movq	(%rsp),%r11
	cmpq	%r10,%rsp
	ja	.Lmul4x_page_walk
	jmp	.Lmul4x_page_walk_done

.Lmul4x_page_walk:
	leaq	-4096(%rsp),%rsp
	movq	(%rsp),%r11
	cmpq	%r10,%rsp
	ja	.Lmul4x_page_walk
.Lmul4x_page_walk_done:

	movq	%rax,8(%rsp,%r9,8)
.cfi_escape	0x0f,0x0a,0x77,0x08,0x79,0x00,0x38,0x1e,0x22,0x06,0x23,0x08
.Lmul4x_body:
	movq	%rdi,16(%rsp,%r9,8)
	movq	%rdx,%r12
	movq	(%r8),%r8
	movq	(%r12),%rbx
	movq	(%rsi),%rax

	xorq	%r14,%r14
	xorq	%r15,%r15

	movq	%r8,%rbp
	mulq	%rbx
	movq	%rax,%r10
	movq	(%rcx),%rax

	imulq	%r10,%rbp
	movq	%rdx,%r11

	mulq	%rbp
	addq	%rax,%r10
	movq	8(%rsi),%rax
	adcq	$0,%rdx
	movq	%rdx,%rdi

	mulq	%rbx
	addq	%rax,%r11
	movq	8(%rcx),%rax
	adcq	$0,%rdx
	movq	%rdx,%r10

	mulq	%rbp
	addq	%rax,%rdi
	movq	16(%rsi),%rax
	adcq	$0,%rdx
	addq	%r11,%rdi
	leaq	4(%r15),%r15
	adcq	$0,%rdx
	movq	%rdi,(%rsp)
	movq	%rdx,%r13
	jmp	.L1st4x
.align	16
.L1st4x:
	mulq	%rbx
	addq	%rax,%r10
	movq	-16(%rcx,%r15,8),%rax
	adcq	$0,%rdx
	movq	%rdx,%r11

	mulq	%rbp
	addq	%rax,%r13
	movq	-8(%rsi,%r15,8),%rax
	adcq	$0,%rdx
	addq	%r10,%r13
	adcq	$0,%rdx
	movq	%r13,-24(%rsp,%r15,8)
	movq	%rdx,%rdi

	mulq	%rbx
	addq	%rax,%r11
	movq	-8(%rcx,%r15,8),%rax
	adcq	$0,%rdx
	movq	%rdx,%r10

	mulq	%rbp
	addq	%rax,%rdi
	movq	(%rsi,%r15,8),%rax
	adcq	$0,%rdx
	addq	%r11,%rdi
	adcq	$0,%rdx
	movq	%rdi,-16(%rsp,%r15,8)
	movq	%rdx,%r13

	mulq	%rbx
	addq	%rax,%r10
	movq	(%rcx,%r15,8),%rax
	adcq	$0,%rdx
	movq	%rdx,%r11

	mulq	%rbp
	addq	%rax,%r13
	movq	8(%rsi,%r15,8),%rax
	adcq	$0,%rdx
	addq	%r10,%r13
	adcq	$0,%rdx
	movq	%r13,-8(%rsp,%r15,8)
	movq	%rdx,%rdi

	mulq	%rbx
	addq	%rax,%r11
	movq	8(%rcx,%r15,8),%rax
	adcq	$0,%rdx
	leaq	4(%r15),%r15
	movq	%rdx,%r10

	mulq	%rbp
	addq	%rax,%rdi
	movq	-16(%rsi,%r15,8),%rax
	adcq	$0,%rdx
	addq	%r11,%rdi
	adcq	$0,%rdx
	movq	%rdi,-32(%rsp,%r15,8)
	movq	%rdx,%r13
	cmpq	%r9,%r15
	jb	.L1st4x

	mulq	%rbx
	addq	%rax,%r10
	movq	-16(%rcx,%r15,8),%rax
	adcq	$0,%rdx
	movq	%rdx,%r11

	mulq	%rbp
	addq	%rax,%r13
	movq	-8(%rsi,%r15,8),%rax
	adcq	$0,%rdx
	addq	%r10,%r13
	adcq	$0,%rdx
	movq	%r13,-24(%rsp,%r15,8)
	movq	%rdx,%rdi

	mulq	%rbx
	addq	%rax,%r11
	movq	-8(%rcx,%r15,8),%rax
	adcq	$0,%rdx
	movq	%rdx,%r10

	mulq	%rbp
	addq	%rax,%rdi
	movq	(%rsi),%rax
	adcq	$0,%rdx
	addq	%r11,%rdi
	adcq	$0,%rdx
	movq	%rdi,-16(%rsp,%r15,8)
	movq	%rdx,%r13

	xorq	%rdi,%rdi
	addq	%r10,%r13
	adcq	$0,%rdi
	movq	%r13,-8(%rsp,%r15,8)
	movq	%rdi,(%rsp,%r15,8)

	leaq	1(%r14),%r14
.align	4
.Louter4x:
	movq	(%r12,%r14,8),%rbx
	xorq	%r15,%r15
	movq	(%rsp),%r10
	movq	%r8,%rbp
	mulq	%rbx
	addq	%rax,%r10
	movq	(%rcx),%rax
	adcq	$0,%rdx

	imulq	%r10,%rbp
	movq	%rdx,%r11

	mulq	%rbp
	addq	%rax,%r10
	movq	8(%rsi),%rax
	adcq	$0,%rdx
	movq	%rdx,%rdi

	mulq	%rbx
	addq	%rax,%r11
	movq	8(%rcx),%rax
	adcq	$0,%rdx
	addq	8(%rsp),%r11
	adcq	$0,%rdx
	movq	%rdx,%r10

	mulq	%rbp
	addq	%rax,%rdi
	movq	16(%rsi),%rax
	adcq	$0,%rdx
	addq	%r11,%rdi
	leaq	4(%r15),%r15
	adcq	$0,%rdx
	movq	%rdi,(%rsp)
	movq	%rdx,%r13
	jmp	.Linner4x
.align	16
.Linner4x:
	mulq	%rbx
	addq	%rax,%r10
	movq	-16(%rcx,%r15,8),%rax
	adcq	$0,%rdx
	addq	-16(%rsp,%r15,8),%r10
	adcq	$0,%rdx
	movq	%rdx,%r11

	mulq	%rbp
	addq	%rax,%r13
	movq	-8(%rsi,%r15,8),%rax
	adcq	$0,%rdx
	addq	%r10,%r13
	adcq	$0,%rdx
	movq	%r13,-24(%rsp,%r15,8)
	movq	%rdx,%rdi

	mulq	%rbx
	addq	%rax,%r11
	movq	-8(%rcx,%r15,8),%rax
	adcq	$0,%rdx
	addq	-8(%rsp,%r15,8),%r11
	adcq	$0,%rdx
	movq	%rdx,%r10

	mulq	%rbp
	addq	%rax,%rdi
	movq	(%rsi,%r15,8),%rax
	adcq	$0,%rdx
	addq	%r11,%rdi
	adcq	$0,%rdx
	movq	%rdi,-16(%rsp,%r15,8)
	movq	%rdx,%r13

	mulq	%rbx
	addq	%rax,%r10
	movq	(%rcx,%r15,8),%rax
	adcq	$0,%rdx
	addq	(%rsp,%r15,8),%r10
	adcq	$0,%rdx
	movq	%rdx,%r11

	mulq	%rbp
	addq	%rax,%r13
	movq	8(%rsi,%r15,8),%rax
	adcq	$0,%rdx
	addq	%r10,%r13
	adcq	$0,%rdx
	movq	%r13,-8(%rsp,%r15,8)
	movq	%rdx,%rdi

	mulq	%rbx
	addq	%rax,%r11
	movq	8(%rcx,%r15,8),%rax
	adcq	$0,%rdx
	addq	8(%rsp,%r15,8),%r11
	adcq	$0,%rdx
	leaq	4(%r15),%r15
	movq	%rdx,%r10

	mulq	%rbp
	addq	%rax,%rdi
	movq	-16(%rsi,%r15,8),%rax
	adcq	$0,%rdx
	addq	%r11,%rdi
	adcq	$0,%rdx
	movq	%rdi,-32(%rsp,%r15,8)
	movq	%rdx,%r13
	cmpq	%r9,%r15
	jb	.Linner4x

	mulq	%rbx
	addq	%rax,%r10
	movq	-16(%rcx,%r15,8),%rax
	adcq	$0,%rdx
	addq	-16(%rsp,%r15,8),%r10
	adcq	$0,%rdx
	movq	%rdx,%r11

	mulq	%rbp
	addq	%rax,%r13
	movq	-8(%rsi,%r15,8),%rax
	adcq	$0,%rdx
	addq	%r10,%r13
	adcq	$0,%rdx
	movq	%r13,-24(%rsp,%r15,8)
	movq	%rdx,%rdi

	mulq	%rbx
	addq	%rax,%r11
	movq	-8(%rcx,%r15,8),%rax
	adcq	$0,%rdx
	addq	-8(%rsp,%r15,8),%r11
	adcq	$0,%rdx
	leaq	1(%r14),%r14
	movq	%rdx,%r10

	mulq	%rbp
	addq	%rax,%rdi
	movq	(%rsi),%rax
	adcq	$0,%rdx
	addq	%r11,%rdi
	adcq	$0,%rdx
	movq	%rdi,-16(%rsp,%r15,8)
	movq	%rdx,%r13

	xorq	%rdi,%rdi
	addq	%r10,%r13
	adcq	$0,%rdi
	addq	(%rsp,%r9,8),%r13
	adcq	$0,%rdi
	movq	%r13,-8(%rsp,%r15,8)
	movq	%rdi,(%rsp,%r15,8)

	cmpq	%r9,%r14
	jb	.Louter4x
	movq	16(%rsp,%r9,8),%rdi
	leaq	-4(%r9),%r15
	movq	0(%rsp),%rax
	movq	8(%rsp),%rdx
	shrq	$2,%r15
	leaq	(%rsp),%rsi
	xorq	%r14,%r14

	subq	0(%rcx),%rax
	movq	16(%rsi),%rbx
	movq	24(%rsi),%rbp
	sbbq	8(%rcx),%rdx

.Lsub4x:
	movq	%rax,0(%rdi,%r14,8)
	movq	%rdx,8(%rdi,%r14,8)
	sbbq	16(%rcx,%r14,8),%rbx
	movq	32(%rsi,%r14,8),%rax
	movq	40(%rsi,%r14,8),%rdx
	sbbq	24(%rcx,%r14,8),%rbp
	movq	%rbx,16(%rdi,%r14,8)
	movq	%rbp,24(%rdi,%r14,8)
	sbbq	32(%rcx,%r14,8),%rax
	movq	48(%rsi,%r14,8),%rbx
	movq	56(%rsi,%r14,8),%rbp
	sbbq	40(%rcx,%r14,8),%rdx
	leaq	4(%r14),%r14
	decq	%r15
	jnz	.Lsub4x

	movq	%rax,0(%rdi,%r14,8)
	movq	32(%rsi,%r14,8),%rax
	sbbq	16(%rcx,%r14,8),%rbx
	movq	%rdx,8(%rdi,%r14,8)
	sbbq	24(%rcx,%r14,8),%rbp
	movq	%rbx,16(%rdi,%r14,8)

	sbbq	$0,%rax
	movq	%rbp,24(%rdi,%r14,8)
	pxor	%xmm0,%xmm0
.byte	102,72,15,110,224
	pcmpeqd	%xmm5,%xmm5
	pshufd	$0,%xmm4,%xmm4
	movq	%r9,%r15
	pxor	%xmm4,%xmm5
	shrq	$2,%r15
	xorl	%eax,%eax

	jmp	.Lcopy4x
.align	16
.Lcopy4x:
	movdqa	(%rsp,%rax,1),%xmm1
	movdqu	(%rdi,%rax,1),%xmm2
	pand	%xmm4,%xmm1
	pand	%xmm5,%xmm2
	movdqa	16(%rsp,%rax,1),%xmm3
	movdqa	%xmm0,(%rsp,%rax,1)
	por	%xmm2,%xmm1
	movdqu	16(%rdi,%rax,1),%xmm2
	movdqu	%xmm1,(%rdi,%rax,1)
	pand	%xmm4,%xmm3
	pand	%xmm5,%xmm2
	movdqa	%xmm0,16(%rsp,%rax,1)
	por	%xmm2,%xmm3
	movdqu	%xmm3,16(%rdi,%rax,1)
	leaq	32(%rax),%rax
	decq	%r15
	jnz	.Lcopy4x
	movq	8(%rsp,%r9,8),%rsi
.cfi_def_cfa	%rsi, 8
	movq	$1,%rax
	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lmul4x_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	bn_mul4x_mont,.-bn_mul4x_mont



.type	bn_sqr8x_mont,@function
.align	32
bn_sqr8x_mont:
.cfi_startproc	
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
.Lsqr8x_enter:
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
.Lsqr8x_prologue:

	movl	%r9d,%r10d
	shll	$3,%r9d
	shlq	$3+2,%r10
	negq	%r9






	leaq	-64(%rsp,%r9,2),%r11
	movq	%rsp,%rbp
	movq	(%r8),%r8
	subq	%rsi,%r11
	andq	$4095,%r11
	cmpq	%r11,%r10
	jb	.Lsqr8x_sp_alt
	subq	%r11,%rbp
	leaq	-64(%rbp,%r9,2),%rbp
	jmp	.Lsqr8x_sp_done

.align	32
.Lsqr8x_sp_alt:
	leaq	4096-64(,%r9,2),%r10
	leaq	-64(%rbp,%r9,2),%rbp
	subq	%r10,%r11
	movq	$0,%r10
	cmovcq	%r10,%r11
	subq	%r11,%rbp
.Lsqr8x_sp_done:
	andq	$-64,%rbp
	movq	%rsp,%r11
	subq	%rbp,%r11
	andq	$-4096,%r11
	leaq	(%r11,%rbp,1),%rsp
	movq	(%rsp),%r10
	cmpq	%rbp,%rsp
	ja	.Lsqr8x_page_walk
	jmp	.Lsqr8x_page_walk_done

.align	16
.Lsqr8x_page_walk:
	leaq	-4096(%rsp),%rsp
	movq	(%rsp),%r10
	cmpq	%rbp,%rsp
	ja	.Lsqr8x_page_walk
.Lsqr8x_page_walk_done:

	movq	%r9,%r10
	negq	%r9

	movq	%r8,32(%rsp)
	movq	%rax,40(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x28,0x06,0x23,0x08
.Lsqr8x_body:

.byte	102,72,15,110,209
	pxor	%xmm0,%xmm0
.byte	102,72,15,110,207
.byte	102,73,15,110,218
	movl	OPENSSL_ia32cap_P+8(%rip),%eax
	andl	$0x80100,%eax
	cmpl	$0x80100,%eax
	jne	.Lsqr8x_nox

	call	bn_sqrx8x_internal




	leaq	(%r8,%rcx,1),%rbx
	movq	%rcx,%r9
	movq	%rcx,%rdx
.byte	102,72,15,126,207
	sarq	$3+2,%rcx
	jmp	.Lsqr8x_sub

.align	32
.Lsqr8x_nox:
	call	bn_sqr8x_internal




	leaq	(%rdi,%r9,1),%rbx
	movq	%r9,%rcx
	movq	%r9,%rdx
.byte	102,72,15,126,207
	sarq	$3+2,%rcx
	jmp	.Lsqr8x_sub

.align	32
.Lsqr8x_sub:
	movq	0(%rbx),%r12
	movq	8(%rbx),%r13
	movq	16(%rbx),%r14
	movq	24(%rbx),%r15
	leaq	32(%rbx),%rbx
	sbbq	0(%rbp),%r12
	sbbq	8(%rbp),%r13
	sbbq	16(%rbp),%r14
	sbbq	24(%rbp),%r15
	leaq	32(%rbp),%rbp
	movq	%r12,0(%rdi)
	movq	%r13,8(%rdi)
	movq	%r14,16(%rdi)
	movq	%r15,24(%rdi)
	leaq	32(%rdi),%rdi
	incq	%rcx
	jnz	.Lsqr8x_sub

	sbbq	$0,%rax
	leaq	(%rbx,%r9,1),%rbx
	leaq	(%rdi,%r9,1),%rdi

.byte	102,72,15,110,200
	pxor	%xmm0,%xmm0
	pshufd	$0,%xmm1,%xmm1
	movq	40(%rsp),%rsi
.cfi_def_cfa	%rsi,8
	jmp	.Lsqr8x_cond_copy

.align	32
.Lsqr8x_cond_copy:
	movdqa	0(%rbx),%xmm2
	movdqa	16(%rbx),%xmm3
	leaq	32(%rbx),%rbx
	movdqu	0(%rdi),%xmm4
	movdqu	16(%rdi),%xmm5
	leaq	32(%rdi),%rdi
	movdqa	%xmm0,-32(%rbx)
	movdqa	%xmm0,-16(%rbx)
	movdqa	%xmm0,-32(%rbx,%rdx,1)
	movdqa	%xmm0,-16(%rbx,%rdx,1)
	pcmpeqd	%xmm1,%xmm0
	pand	%xmm1,%xmm2
	pand	%xmm1,%xmm3
	pand	%xmm0,%xmm4
	pand	%xmm0,%xmm5
	pxor	%xmm0,%xmm0
	por	%xmm2,%xmm4
	por	%xmm3,%xmm5
	movdqu	%xmm4,-32(%rdi)
	movdqu	%xmm5,-16(%rdi)
	addq	$32,%r9
	jnz	.Lsqr8x_cond_copy

	movq	$1,%rax
	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lsqr8x_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	bn_sqr8x_mont,.-bn_sqr8x_mont
.type	bn_mulx4x_mont,@function
.align	32
bn_mulx4x_mont:
.cfi_startproc	
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
.Lmulx4x_enter:
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
.Lmulx4x_prologue:

	shll	$3,%r9d
	xorq	%r10,%r10
	subq	%r9,%r10
	movq	(%r8),%r8
	leaq	-72(%rsp,%r10,1),%rbp
	andq	$-128,%rbp
	movq	%rsp,%r11
	subq	%rbp,%r11
	andq	$-4096,%r11
	leaq	(%r11,%rbp,1),%rsp
	movq	(%rsp),%r10
	cmpq	%rbp,%rsp
	ja	.Lmulx4x_page_walk
	jmp	.Lmulx4x_page_walk_done

.align	16
.Lmulx4x_page_walk:
	leaq	-4096(%rsp),%rsp
	movq	(%rsp),%r10
	cmpq	%rbp,%rsp
	ja	.Lmulx4x_page_walk
.Lmulx4x_page_walk_done:

	leaq	(%rdx,%r9,1),%r10












	movq	%r9,0(%rsp)
	shrq	$5,%r9
	movq	%r10,16(%rsp)
	subq	$1,%r9
	movq	%r8,24(%rsp)
	movq	%rdi,32(%rsp)
	movq	%rax,40(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x28,0x06,0x23,0x08
	movq	%r9,48(%rsp)
	jmp	.Lmulx4x_body

.align	32
.Lmulx4x_body:
	leaq	8(%rdx),%rdi
	movq	(%rdx),%rdx
	leaq	64+32(%rsp),%rbx
	movq	%rdx,%r9

	mulxq	0(%rsi),%r8,%rax
	mulxq	8(%rsi),%r11,%r14
	addq	%rax,%r11
	movq	%rdi,8(%rsp)
	mulxq	16(%rsi),%r12,%r13
	adcq	%r14,%r12
	adcq	$0,%r13

	movq	%r8,%rdi
	imulq	24(%rsp),%r8
	xorq	%rbp,%rbp

	mulxq	24(%rsi),%rax,%r14
	movq	%r8,%rdx
	leaq	32(%rsi),%rsi
	adcxq	%rax,%r13
	adcxq	%rbp,%r14

	mulxq	0(%rcx),%rax,%r10
	adcxq	%rax,%rdi
	adoxq	%r11,%r10
	mulxq	8(%rcx),%rax,%r11
	adcxq	%rax,%r10
	adoxq	%r12,%r11
.byte	0xc4,0x62,0xfb,0xf6,0xa1,0x10,0x00,0x00,0x00
	movq	48(%rsp),%rdi
	movq	%r10,-32(%rbx)
	adcxq	%rax,%r11
	adoxq	%r13,%r12
	mulxq	24(%rcx),%rax,%r15
	movq	%r9,%rdx
	movq	%r11,-24(%rbx)
	adcxq	%rax,%r12
	adoxq	%rbp,%r15
	leaq	32(%rcx),%rcx
	movq	%r12,-16(%rbx)

	jmp	.Lmulx4x_1st

.align	32
.Lmulx4x_1st:
	adcxq	%rbp,%r15
	mulxq	0(%rsi),%r10,%rax
	adcxq	%r14,%r10
	mulxq	8(%rsi),%r11,%r14
	adcxq	%rax,%r11
	mulxq	16(%rsi),%r12,%rax
	adcxq	%r14,%r12
	mulxq	24(%rsi),%r13,%r14
.byte	0x67,0x67
	movq	%r8,%rdx
	adcxq	%rax,%r13
	adcxq	%rbp,%r14
	leaq	32(%rsi),%rsi
	leaq	32(%rbx),%rbx

	adoxq	%r15,%r10
	mulxq	0(%rcx),%rax,%r15
	adcxq	%rax,%r10
	adoxq	%r15,%r11
	mulxq	8(%rcx),%rax,%r15
	adcxq	%rax,%r11
	adoxq	%r15,%r12
	mulxq	16(%rcx),%rax,%r15
	movq	%r10,-40(%rbx)
	adcxq	%rax,%r12
	movq	%r11,-32(%rbx)
	adoxq	%r15,%r13
	mulxq	24(%rcx),%rax,%r15
	movq	%r9,%rdx
	movq	%r12,-24(%rbx)
	adcxq	%rax,%r13
	adoxq	%rbp,%r15
	leaq	32(%rcx),%rcx
	movq	%r13,-16(%rbx)

	decq	%rdi
	jnz	.Lmulx4x_1st

	movq	0(%rsp),%rax
	movq	8(%rsp),%rdi
	adcq	%rbp,%r15
	addq	%r15,%r14
	sbbq	%r15,%r15
	movq	%r14,-8(%rbx)
	jmp	.Lmulx4x_outer

.align	32
.Lmulx4x_outer:
	movq	(%rdi),%rdx
	leaq	8(%rdi),%rdi
	subq	%rax,%rsi
	movq	%r15,(%rbx)
	leaq	64+32(%rsp),%rbx
	subq	%rax,%rcx

	mulxq	0(%rsi),%r8,%r11
	xorl	%ebp,%ebp
	movq	%rdx,%r9
	mulxq	8(%rsi),%r14,%r12
	adoxq	-32(%rbx),%r8
	adcxq	%r14,%r11
	mulxq	16(%rsi),%r15,%r13
	adoxq	-24(%rbx),%r11
	adcxq	%r15,%r12
	adoxq	-16(%rbx),%r12
	adcxq	%rbp,%r13
	adoxq	%rbp,%r13

	movq	%rdi,8(%rsp)
	movq	%r8,%r15
	imulq	24(%rsp),%r8
	xorl	%ebp,%ebp

	mulxq	24(%rsi),%rax,%r14
	movq	%r8,%rdx
	adcxq	%rax,%r13
	adoxq	-8(%rbx),%r13
	adcxq	%rbp,%r14
	leaq	32(%rsi),%rsi
	adoxq	%rbp,%r14

	mulxq	0(%rcx),%rax,%r10
	adcxq	%rax,%r15
	adoxq	%r11,%r10
	mulxq	8(%rcx),%rax,%r11
	adcxq	%rax,%r10
	adoxq	%r12,%r11
	mulxq	16(%rcx),%rax,%r12
	movq	%r10,-32(%rbx)
	adcxq	%rax,%r11
	adoxq	%r13,%r12
	mulxq	24(%rcx),%rax,%r15
	movq	%r9,%rdx
	movq	%r11,-24(%rbx)
	leaq	32(%rcx),%rcx
	adcxq	%rax,%r12
	adoxq	%rbp,%r15
	movq	48(%rsp),%rdi
	movq	%r12,-16(%rbx)

	jmp	.Lmulx4x_inner

.align	32
.Lmulx4x_inner:
	mulxq	0(%rsi),%r10,%rax
	adcxq	%rbp,%r15
	adoxq	%r14,%r10
	mulxq	8(%rsi),%r11,%r14
	adcxq	0(%rbx),%r10
	adoxq	%rax,%r11
	mulxq	16(%rsi),%r12,%rax
	adcxq	8(%rbx),%r11
	adoxq	%r14,%r12
	mulxq	24(%rsi),%r13,%r14
	movq	%r8,%rdx
	adcxq	16(%rbx),%r12
	adoxq	%rax,%r13
	adcxq	24(%rbx),%r13
	adoxq	%rbp,%r14
	leaq	32(%rsi),%rsi
	leaq	32(%rbx),%rbx
	adcxq	%rbp,%r14

	adoxq	%r15,%r10
	mulxq	0(%rcx),%rax,%r15
	adcxq	%rax,%r10
	adoxq	%r15,%r11
	mulxq	8(%rcx),%rax,%r15
	adcxq	%rax,%r11
	adoxq	%r15,%r12
	mulxq	16(%rcx),%rax,%r15
	movq	%r10,-40(%rbx)
	adcxq	%rax,%r12
	adoxq	%r15,%r13
	mulxq	24(%rcx),%rax,%r15
	movq	%r9,%rdx
	movq	%r11,-32(%rbx)
	movq	%r12,-24(%rbx)
	adcxq	%rax,%r13
	adoxq	%rbp,%r15
	leaq	32(%rcx),%rcx
	movq	%r13,-16(%rbx)

	decq	%rdi
	jnz	.Lmulx4x_inner

	movq	0(%rsp),%rax
	movq	8(%rsp),%rdi
	adcq	%rbp,%r15
	subq	0(%rbx),%rbp
	adcq	%r15,%r14
	sbbq	%r15,%r15
	movq	%r14,-8(%rbx)

	cmpq	16(%rsp),%rdi
	jne	.Lmulx4x_outer

	leaq	64(%rsp),%rbx
	subq	%rax,%rcx
	negq	%r15
	movq	%rax,%rdx
	shrq	$3+2,%rax
	movq	32(%rsp),%rdi
	jmp	.Lmulx4x_sub

.align	32
.Lmulx4x_sub:
	movq	0(%rbx),%r11
	movq	8(%rbx),%r12
	movq	16(%rbx),%r13
	movq	24(%rbx),%r14
	leaq	32(%rbx),%rbx
	sbbq	0(%rcx),%r11
	sbbq	8(%rcx),%r12
	sbbq	16(%rcx),%r13
	sbbq	24(%rcx),%r14
	leaq	32(%rcx),%rcx
	movq	%r11,0(%rdi)
	movq	%r12,8(%rdi)
	movq	%r13,16(%rdi)
	movq	%r14,24(%rdi)
	leaq	32(%rdi),%rdi
	decq	%rax
	jnz	.Lmulx4x_sub

	sbbq	$0,%r15
	leaq	64(%rsp),%rbx
	subq	%rdx,%rdi

.byte	102,73,15,110,207
	pxor	%xmm0,%xmm0
	pshufd	$0,%xmm1,%xmm1
	movq	40(%rsp),%rsi
.cfi_def_cfa	%rsi,8
	jmp	.Lmulx4x_cond_copy

.align	32
.Lmulx4x_cond_copy:
	movdqa	0(%rbx),%xmm2
	movdqa	16(%rbx),%xmm3
	leaq	32(%rbx),%rbx
	movdqu	0(%rdi),%xmm4
	movdqu	16(%rdi),%xmm5
	leaq	32(%rdi),%rdi
	movdqa	%xmm0,-32(%rbx)
	movdqa	%xmm0,-16(%rbx)
	pcmpeqd	%xmm1,%xmm0
	pand	%xmm1,%xmm2
	pand	%xmm1,%xmm3
	pand	%xmm0,%xmm4
	pand	%xmm0,%xmm5
	pxor	%xmm0,%xmm0
	por	%xmm2,%xmm4
	por	%xmm3,%xmm5
	movdqu	%xmm4,-32(%rdi)
	movdqu	%xmm5,-16(%rdi)
	subq	$32,%rdx
	jnz	.Lmulx4x_cond_copy

	movq	%rdx,(%rbx)

	movq	$1,%rax
	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lmulx4x_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	bn_mulx4x_mont,.-bn_mulx4x_mont
.byte	77,111,110,116,103,111,109,101,114,121,32,77,117,108,116,105,112,108,105,99,97,116,105,111,110,32,102,111,114,32,120,56,54,95,54,52,44,32,67,82,89,80,84,79,71,65,77,83,32,98,121,32,60,97,112,112,114,111,64,111,112,101,110,115,115,108,46,111,114,103,62,0
.align	16
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                                                                                                                                                                                                                                                       node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/bn/x86_64-mont5.s                     0000664 0000000 0000000 00000162461 14746647661 0026526 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	



.globl	bn_mul_mont_gather5
.type	bn_mul_mont_gather5,@function
.align	64
bn_mul_mont_gather5:
.cfi_startproc	
	movl	%r9d,%r9d
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	testl	$7,%r9d
	jnz	.Lmul_enter
	movl	OPENSSL_ia32cap_P+8(%rip),%r11d
	jmp	.Lmul4x_enter

.align	16
.Lmul_enter:
	movd	8(%rsp),%xmm5
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56

	negq	%r9
	movq	%rsp,%r11
	leaq	-280(%rsp,%r9,8),%r10
	negq	%r9
	andq	$-1024,%r10









	subq	%r10,%r11
	andq	$-4096,%r11
	leaq	(%r10,%r11,1),%rsp
	movq	(%rsp),%r11
	cmpq	%r10,%rsp
	ja	.Lmul_page_walk
	jmp	.Lmul_page_walk_done

.Lmul_page_walk:
	leaq	-4096(%rsp),%rsp
	movq	(%rsp),%r11
	cmpq	%r10,%rsp
	ja	.Lmul_page_walk
.Lmul_page_walk_done:

	leaq	.Linc(%rip),%r10
	movq	%rax,8(%rsp,%r9,8)
.cfi_escape	0x0f,0x0a,0x77,0x08,0x79,0x00,0x38,0x1e,0x22,0x06,0x23,0x08
.Lmul_body:

	leaq	128(%rdx),%r12
	movdqa	0(%r10),%xmm0
	movdqa	16(%r10),%xmm1
	leaq	24-112(%rsp,%r9,8),%r10
	andq	$-16,%r10

	pshufd	$0,%xmm5,%xmm5
	movdqa	%xmm1,%xmm4
	movdqa	%xmm1,%xmm2
	paddd	%xmm0,%xmm1
	pcmpeqd	%xmm5,%xmm0
.byte	0x67
	movdqa	%xmm4,%xmm3
	paddd	%xmm1,%xmm2
	pcmpeqd	%xmm5,%xmm1
	movdqa	%xmm0,112(%r10)
	movdqa	%xmm4,%xmm0

	paddd	%xmm2,%xmm3
	pcmpeqd	%xmm5,%xmm2
	movdqa	%xmm1,128(%r10)
	movdqa	%xmm4,%xmm1

	paddd	%xmm3,%xmm0
	pcmpeqd	%xmm5,%xmm3
	movdqa	%xmm2,144(%r10)
	movdqa	%xmm4,%xmm2

	paddd	%xmm0,%xmm1
	pcmpeqd	%xmm5,%xmm0
	movdqa	%xmm3,160(%r10)
	movdqa	%xmm4,%xmm3
	paddd	%xmm1,%xmm2
	pcmpeqd	%xmm5,%xmm1
	movdqa	%xmm0,176(%r10)
	movdqa	%xmm4,%xmm0

	paddd	%xmm2,%xmm3
	pcmpeqd	%xmm5,%xmm2
	movdqa	%xmm1,192(%r10)
	movdqa	%xmm4,%xmm1

	paddd	%xmm3,%xmm0
	pcmpeqd	%xmm5,%xmm3
	movdqa	%xmm2,208(%r10)
	movdqa	%xmm4,%xmm2

	paddd	%xmm0,%xmm1
	pcmpeqd	%xmm5,%xmm0
	movdqa	%xmm3,224(%r10)
	movdqa	%xmm4,%xmm3
	paddd	%xmm1,%xmm2
	pcmpeqd	%xmm5,%xmm1
	movdqa	%xmm0,240(%r10)
	movdqa	%xmm4,%xmm0

	paddd	%xmm2,%xmm3
	pcmpeqd	%xmm5,%xmm2
	movdqa	%xmm1,256(%r10)
	movdqa	%xmm4,%xmm1

	paddd	%xmm3,%xmm0
	pcmpeqd	%xmm5,%xmm3
	movdqa	%xmm2,272(%r10)
	movdqa	%xmm4,%xmm2

	paddd	%xmm0,%xmm1
	pcmpeqd	%xmm5,%xmm0
	movdqa	%xmm3,288(%r10)
	movdqa	%xmm4,%xmm3
	paddd	%xmm1,%xmm2
	pcmpeqd	%xmm5,%xmm1
	movdqa	%xmm0,304(%r10)

	paddd	%xmm2,%xmm3
.byte	0x67
	pcmpeqd	%xmm5,%xmm2
	movdqa	%xmm1,320(%r10)

	pcmpeqd	%xmm5,%xmm3
	movdqa	%xmm2,336(%r10)
	pand	64(%r12),%xmm0

	pand	80(%r12),%xmm1
	pand	96(%r12),%xmm2
	movdqa	%xmm3,352(%r10)
	pand	112(%r12),%xmm3
	por	%xmm2,%xmm0
	por	%xmm3,%xmm1
	movdqa	-128(%r12),%xmm4
	movdqa	-112(%r12),%xmm5
	movdqa	-96(%r12),%xmm2
	pand	112(%r10),%xmm4
	movdqa	-80(%r12),%xmm3
	pand	128(%r10),%xmm5
	por	%xmm4,%xmm0
	pand	144(%r10),%xmm2
	por	%xmm5,%xmm1
	pand	160(%r10),%xmm3
	por	%xmm2,%xmm0
	por	%xmm3,%xmm1
	movdqa	-64(%r12),%xmm4
	movdqa	-48(%r12),%xmm5
	movdqa	-32(%r12),%xmm2
	pand	176(%r10),%xmm4
	movdqa	-16(%r12),%xmm3
	pand	192(%r10),%xmm5
	por	%xmm4,%xmm0
	pand	208(%r10),%xmm2
	por	%xmm5,%xmm1
	pand	224(%r10),%xmm3
	por	%xmm2,%xmm0
	por	%xmm3,%xmm1
	movdqa	0(%r12),%xmm4
	movdqa	16(%r12),%xmm5
	movdqa	32(%r12),%xmm2
	pand	240(%r10),%xmm4
	movdqa	48(%r12),%xmm3
	pand	256(%r10),%xmm5
	por	%xmm4,%xmm0
	pand	272(%r10),%xmm2
	por	%xmm5,%xmm1
	pand	288(%r10),%xmm3
	por	%xmm2,%xmm0
	por	%xmm3,%xmm1
	por	%xmm1,%xmm0
	pshufd	$0x4e,%xmm0,%xmm1
	por	%xmm1,%xmm0
	leaq	256(%r12),%r12
.byte	102,72,15,126,195

	movq	(%r8),%r8
	movq	(%rsi),%rax

	xorq	%r14,%r14
	xorq	%r15,%r15

	movq	%r8,%rbp
	mulq	%rbx
	movq	%rax,%r10
	movq	(%rcx),%rax

	imulq	%r10,%rbp
	movq	%rdx,%r11

	mulq	%rbp
	addq	%rax,%r10
	movq	8(%rsi),%rax
	adcq	$0,%rdx
	movq	%rdx,%r13

	leaq	1(%r15),%r15
	jmp	.L1st_enter

.align	16
.L1st:
	addq	%rax,%r13
	movq	(%rsi,%r15,8),%rax
	adcq	$0,%rdx
	addq	%r11,%r13
	movq	%r10,%r11
	adcq	$0,%rdx
	movq	%r13,-16(%rsp,%r15,8)
	movq	%rdx,%r13

.L1st_enter:
	mulq	%rbx
	addq	%rax,%r11
	movq	(%rcx,%r15,8),%rax
	adcq	$0,%rdx
	leaq	1(%r15),%r15
	movq	%rdx,%r10

	mulq	%rbp
	cmpq	%r9,%r15
	jne	.L1st


	addq	%rax,%r13
	adcq	$0,%rdx
	addq	%r11,%r13
	adcq	$0,%rdx
	movq	%r13,-16(%rsp,%r9,8)
	movq	%rdx,%r13
	movq	%r10,%r11

	xorq	%rdx,%rdx
	addq	%r11,%r13
	adcq	$0,%rdx
	movq	%r13,-8(%rsp,%r9,8)
	movq	%rdx,(%rsp,%r9,8)

	leaq	1(%r14),%r14
	jmp	.Louter
.align	16
.Louter:
	leaq	24+128(%rsp,%r9,8),%rdx
	andq	$-16,%rdx
	pxor	%xmm4,%xmm4
	pxor	%xmm5,%xmm5
	movdqa	-128(%r12),%xmm0
	movdqa	-112(%r12),%xmm1
	movdqa	-96(%r12),%xmm2
	movdqa	-80(%r12),%xmm3
	pand	-128(%rdx),%xmm0
	pand	-112(%rdx),%xmm1
	por	%xmm0,%xmm4
	pand	-96(%rdx),%xmm2
	por	%xmm1,%xmm5
	pand	-80(%rdx),%xmm3
	por	%xmm2,%xmm4
	por	%xmm3,%xmm5
	movdqa	-64(%r12),%xmm0
	movdqa	-48(%r12),%xmm1
	movdqa	-32(%r12),%xmm2
	movdqa	-16(%r12),%xmm3
	pand	-64(%rdx),%xmm0
	pand	-48(%rdx),%xmm1
	por	%xmm0,%xmm4
	pand	-32(%rdx),%xmm2
	por	%xmm1,%xmm5
	pand	-16(%rdx),%xmm3
	por	%xmm2,%xmm4
	por	%xmm3,%xmm5
	movdqa	0(%r12),%xmm0
	movdqa	16(%r12),%xmm1
	movdqa	32(%r12),%xmm2
	movdqa	48(%r12),%xmm3
	pand	0(%rdx),%xmm0
	pand	16(%rdx),%xmm1
	por	%xmm0,%xmm4
	pand	32(%rdx),%xmm2
	por	%xmm1,%xmm5
	pand	48(%rdx),%xmm3
	por	%xmm2,%xmm4
	por	%xmm3,%xmm5
	movdqa	64(%r12),%xmm0
	movdqa	80(%r12),%xmm1
	movdqa	96(%r12),%xmm2
	movdqa	112(%r12),%xmm3
	pand	64(%rdx),%xmm0
	pand	80(%rdx),%xmm1
	por	%xmm0,%xmm4
	pand	96(%rdx),%xmm2
	por	%xmm1,%xmm5
	pand	112(%rdx),%xmm3
	por	%xmm2,%xmm4
	por	%xmm3,%xmm5
	por	%xmm5,%xmm4
	pshufd	$0x4e,%xmm4,%xmm0
	por	%xmm4,%xmm0
	leaq	256(%r12),%r12

	movq	(%rsi),%rax
.byte	102,72,15,126,195

	xorq	%r15,%r15
	movq	%r8,%rbp
	movq	(%rsp),%r10

	mulq	%rbx
	addq	%rax,%r10
	movq	(%rcx),%rax
	adcq	$0,%rdx

	imulq	%r10,%rbp
	movq	%rdx,%r11

	mulq	%rbp
	addq	%rax,%r10
	movq	8(%rsi),%rax
	adcq	$0,%rdx
	movq	8(%rsp),%r10
	movq	%rdx,%r13

	leaq	1(%r15),%r15
	jmp	.Linner_enter

.align	16
.Linner:
	addq	%rax,%r13
	movq	(%rsi,%r15,8),%rax
	adcq	$0,%rdx
	addq	%r10,%r13
	movq	(%rsp,%r15,8),%r10
	adcq	$0,%rdx
	movq	%r13,-16(%rsp,%r15,8)
	movq	%rdx,%r13

.Linner_enter:
	mulq	%rbx
	addq	%rax,%r11
	movq	(%rcx,%r15,8),%rax
	adcq	$0,%rdx
	addq	%r11,%r10
	movq	%rdx,%r11
	adcq	$0,%r11
	leaq	1(%r15),%r15

	mulq	%rbp
	cmpq	%r9,%r15
	jne	.Linner

	addq	%rax,%r13
	adcq	$0,%rdx
	addq	%r10,%r13
	movq	(%rsp,%r9,8),%r10
	adcq	$0,%rdx
	movq	%r13,-16(%rsp,%r9,8)
	movq	%rdx,%r13

	xorq	%rdx,%rdx
	addq	%r11,%r13
	adcq	$0,%rdx
	addq	%r10,%r13
	adcq	$0,%rdx
	movq	%r13,-8(%rsp,%r9,8)
	movq	%rdx,(%rsp,%r9,8)

	leaq	1(%r14),%r14
	cmpq	%r9,%r14
	jb	.Louter

	xorq	%r14,%r14
	movq	(%rsp),%rax
	leaq	(%rsp),%rsi
	movq	%r9,%r15
	jmp	.Lsub
.align	16
.Lsub:	sbbq	(%rcx,%r14,8),%rax
	movq	%rax,(%rdi,%r14,8)
	movq	8(%rsi,%r14,8),%rax
	leaq	1(%r14),%r14
	decq	%r15
	jnz	.Lsub

	sbbq	$0,%rax
	movq	$-1,%rbx
	xorq	%rax,%rbx
	xorq	%r14,%r14
	movq	%r9,%r15

.Lcopy:
	movq	(%rdi,%r14,8),%rcx
	movq	(%rsp,%r14,8),%rdx
	andq	%rbx,%rcx
	andq	%rax,%rdx
	movq	%r14,(%rsp,%r14,8)
	orq	%rcx,%rdx
	movq	%rdx,(%rdi,%r14,8)
	leaq	1(%r14),%r14
	subq	$1,%r15
	jnz	.Lcopy

	movq	8(%rsp,%r9,8),%rsi
.cfi_def_cfa	%rsi,8
	movq	$1,%rax

	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lmul_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	bn_mul_mont_gather5,.-bn_mul_mont_gather5
.type	bn_mul4x_mont_gather5,@function
.align	32
bn_mul4x_mont_gather5:
.cfi_startproc	
.byte	0x67
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
.Lmul4x_enter:
	andl	$0x80108,%r11d
	cmpl	$0x80108,%r11d
	je	.Lmulx4x_enter
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
.Lmul4x_prologue:

.byte	0x67
	shll	$3,%r9d
	leaq	(%r9,%r9,2),%r10
	negq	%r9










	leaq	-320(%rsp,%r9,2),%r11
	movq	%rsp,%rbp
	subq	%rdi,%r11
	andq	$4095,%r11
	cmpq	%r11,%r10
	jb	.Lmul4xsp_alt
	subq	%r11,%rbp
	leaq	-320(%rbp,%r9,2),%rbp
	jmp	.Lmul4xsp_done

.align	32
.Lmul4xsp_alt:
	leaq	4096-320(,%r9,2),%r10
	leaq	-320(%rbp,%r9,2),%rbp
	subq	%r10,%r11
	movq	$0,%r10
	cmovcq	%r10,%r11
	subq	%r11,%rbp
.Lmul4xsp_done:
	andq	$-64,%rbp
	movq	%rsp,%r11
	subq	%rbp,%r11
	andq	$-4096,%r11
	leaq	(%r11,%rbp,1),%rsp
	movq	(%rsp),%r10
	cmpq	%rbp,%rsp
	ja	.Lmul4x_page_walk
	jmp	.Lmul4x_page_walk_done

.Lmul4x_page_walk:
	leaq	-4096(%rsp),%rsp
	movq	(%rsp),%r10
	cmpq	%rbp,%rsp
	ja	.Lmul4x_page_walk
.Lmul4x_page_walk_done:

	negq	%r9

	movq	%rax,40(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x28,0x06,0x23,0x08
.Lmul4x_body:

	call	mul4x_internal

	movq	40(%rsp),%rsi
.cfi_def_cfa	%rsi,8
	movq	$1,%rax

	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lmul4x_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	bn_mul4x_mont_gather5,.-bn_mul4x_mont_gather5

.type	mul4x_internal,@function
.align	32
mul4x_internal:
.cfi_startproc	
	shlq	$5,%r9
	movd	8(%rax),%xmm5
	leaq	.Linc(%rip),%rax
	leaq	128(%rdx,%r9,1),%r13
	shrq	$5,%r9
	movdqa	0(%rax),%xmm0
	movdqa	16(%rax),%xmm1
	leaq	88-112(%rsp,%r9,1),%r10
	leaq	128(%rdx),%r12

	pshufd	$0,%xmm5,%xmm5
	movdqa	%xmm1,%xmm4
.byte	0x67,0x67
	movdqa	%xmm1,%xmm2
	paddd	%xmm0,%xmm1
	pcmpeqd	%xmm5,%xmm0
.byte	0x67
	movdqa	%xmm4,%xmm3
	paddd	%xmm1,%xmm2
	pcmpeqd	%xmm5,%xmm1
	movdqa	%xmm0,112(%r10)
	movdqa	%xmm4,%xmm0

	paddd	%xmm2,%xmm3
	pcmpeqd	%xmm5,%xmm2
	movdqa	%xmm1,128(%r10)
	movdqa	%xmm4,%xmm1

	paddd	%xmm3,%xmm0
	pcmpeqd	%xmm5,%xmm3
	movdqa	%xmm2,144(%r10)
	movdqa	%xmm4,%xmm2

	paddd	%xmm0,%xmm1
	pcmpeqd	%xmm5,%xmm0
	movdqa	%xmm3,160(%r10)
	movdqa	%xmm4,%xmm3
	paddd	%xmm1,%xmm2
	pcmpeqd	%xmm5,%xmm1
	movdqa	%xmm0,176(%r10)
	movdqa	%xmm4,%xmm0

	paddd	%xmm2,%xmm3
	pcmpeqd	%xmm5,%xmm2
	movdqa	%xmm1,192(%r10)
	movdqa	%xmm4,%xmm1

	paddd	%xmm3,%xmm0
	pcmpeqd	%xmm5,%xmm3
	movdqa	%xmm2,208(%r10)
	movdqa	%xmm4,%xmm2

	paddd	%xmm0,%xmm1
	pcmpeqd	%xmm5,%xmm0
	movdqa	%xmm3,224(%r10)
	movdqa	%xmm4,%xmm3
	paddd	%xmm1,%xmm2
	pcmpeqd	%xmm5,%xmm1
	movdqa	%xmm0,240(%r10)
	movdqa	%xmm4,%xmm0

	paddd	%xmm2,%xmm3
	pcmpeqd	%xmm5,%xmm2
	movdqa	%xmm1,256(%r10)
	movdqa	%xmm4,%xmm1

	paddd	%xmm3,%xmm0
	pcmpeqd	%xmm5,%xmm3
	movdqa	%xmm2,272(%r10)
	movdqa	%xmm4,%xmm2

	paddd	%xmm0,%xmm1
	pcmpeqd	%xmm5,%xmm0
	movdqa	%xmm3,288(%r10)
	movdqa	%xmm4,%xmm3
	paddd	%xmm1,%xmm2
	pcmpeqd	%xmm5,%xmm1
	movdqa	%xmm0,304(%r10)

	paddd	%xmm2,%xmm3
.byte	0x67
	pcmpeqd	%xmm5,%xmm2
	movdqa	%xmm1,320(%r10)

	pcmpeqd	%xmm5,%xmm3
	movdqa	%xmm2,336(%r10)
	pand	64(%r12),%xmm0

	pand	80(%r12),%xmm1
	pand	96(%r12),%xmm2
	movdqa	%xmm3,352(%r10)
	pand	112(%r12),%xmm3
	por	%xmm2,%xmm0
	por	%xmm3,%xmm1
	movdqa	-128(%r12),%xmm4
	movdqa	-112(%r12),%xmm5
	movdqa	-96(%r12),%xmm2
	pand	112(%r10),%xmm4
	movdqa	-80(%r12),%xmm3
	pand	128(%r10),%xmm5
	por	%xmm4,%xmm0
	pand	144(%r10),%xmm2
	por	%xmm5,%xmm1
	pand	160(%r10),%xmm3
	por	%xmm2,%xmm0
	por	%xmm3,%xmm1
	movdqa	-64(%r12),%xmm4
	movdqa	-48(%r12),%xmm5
	movdqa	-32(%r12),%xmm2
	pand	176(%r10),%xmm4
	movdqa	-16(%r12),%xmm3
	pand	192(%r10),%xmm5
	por	%xmm4,%xmm0
	pand	208(%r10),%xmm2
	por	%xmm5,%xmm1
	pand	224(%r10),%xmm3
	por	%xmm2,%xmm0
	por	%xmm3,%xmm1
	movdqa	0(%r12),%xmm4
	movdqa	16(%r12),%xmm5
	movdqa	32(%r12),%xmm2
	pand	240(%r10),%xmm4
	movdqa	48(%r12),%xmm3
	pand	256(%r10),%xmm5
	por	%xmm4,%xmm0
	pand	272(%r10),%xmm2
	por	%xmm5,%xmm1
	pand	288(%r10),%xmm3
	por	%xmm2,%xmm0
	por	%xmm3,%xmm1
	por	%xmm1,%xmm0
	pshufd	$0x4e,%xmm0,%xmm1
	por	%xmm1,%xmm0
	leaq	256(%r12),%r12
.byte	102,72,15,126,195

	movq	%r13,16+8(%rsp)
	movq	%rdi,56+8(%rsp)

	movq	(%r8),%r8
	movq	(%rsi),%rax
	leaq	(%rsi,%r9,1),%rsi
	negq	%r9

	movq	%r8,%rbp
	mulq	%rbx
	movq	%rax,%r10
	movq	(%rcx),%rax

	imulq	%r10,%rbp
	leaq	64+8(%rsp),%r14
	movq	%rdx,%r11

	mulq	%rbp
	addq	%rax,%r10
	movq	8(%rsi,%r9,1),%rax
	adcq	$0,%rdx
	movq	%rdx,%rdi

	mulq	%rbx
	addq	%rax,%r11
	movq	8(%rcx),%rax
	adcq	$0,%rdx
	movq	%rdx,%r10

	mulq	%rbp
	addq	%rax,%rdi
	movq	16(%rsi,%r9,1),%rax
	adcq	$0,%rdx
	addq	%r11,%rdi
	leaq	32(%r9),%r15
	leaq	32(%rcx),%rcx
	adcq	$0,%rdx
	movq	%rdi,(%r14)
	movq	%rdx,%r13
	jmp	.L1st4x

.align	32
.L1st4x:
	mulq	%rbx
	addq	%rax,%r10
	movq	-16(%rcx),%rax
	leaq	32(%r14),%r14
	adcq	$0,%rdx
	movq	%rdx,%r11

	mulq	%rbp
	addq	%rax,%r13
	movq	-8(%rsi,%r15,1),%rax
	adcq	$0,%rdx
	addq	%r10,%r13
	adcq	$0,%rdx
	movq	%r13,-24(%r14)
	movq	%rdx,%rdi

	mulq	%rbx
	addq	%rax,%r11
	movq	-8(%rcx),%rax
	adcq	$0,%rdx
	movq	%rdx,%r10

	mulq	%rbp
	addq	%rax,%rdi
	movq	(%rsi,%r15,1),%rax
	adcq	$0,%rdx
	addq	%r11,%rdi
	adcq	$0,%rdx
	movq	%rdi,-16(%r14)
	movq	%rdx,%r13

	mulq	%rbx
	addq	%rax,%r10
	movq	0(%rcx),%rax
	adcq	$0,%rdx
	movq	%rdx,%r11

	mulq	%rbp
	addq	%rax,%r13
	movq	8(%rsi,%r15,1),%rax
	adcq	$0,%rdx
	addq	%r10,%r13
	adcq	$0,%rdx
	movq	%r13,-8(%r14)
	movq	%rdx,%rdi

	mulq	%rbx
	addq	%rax,%r11
	movq	8(%rcx),%rax
	adcq	$0,%rdx
	movq	%rdx,%r10

	mulq	%rbp
	addq	%rax,%rdi
	movq	16(%rsi,%r15,1),%rax
	adcq	$0,%rdx
	addq	%r11,%rdi
	leaq	32(%rcx),%rcx
	adcq	$0,%rdx
	movq	%rdi,(%r14)
	movq	%rdx,%r13

	addq	$32,%r15
	jnz	.L1st4x

	mulq	%rbx
	addq	%rax,%r10
	movq	-16(%rcx),%rax
	leaq	32(%r14),%r14
	adcq	$0,%rdx
	movq	%rdx,%r11

	mulq	%rbp
	addq	%rax,%r13
	movq	-8(%rsi),%rax
	adcq	$0,%rdx
	addq	%r10,%r13
	adcq	$0,%rdx
	movq	%r13,-24(%r14)
	movq	%rdx,%rdi

	mulq	%rbx
	addq	%rax,%r11
	movq	-8(%rcx),%rax
	adcq	$0,%rdx
	movq	%rdx,%r10

	mulq	%rbp
	addq	%rax,%rdi
	movq	(%rsi,%r9,1),%rax
	adcq	$0,%rdx
	addq	%r11,%rdi
	adcq	$0,%rdx
	movq	%rdi,-16(%r14)
	movq	%rdx,%r13

	leaq	(%rcx,%r9,1),%rcx

	xorq	%rdi,%rdi
	addq	%r10,%r13
	adcq	$0,%rdi
	movq	%r13,-8(%r14)

	jmp	.Louter4x

.align	32
.Louter4x:
	leaq	16+128(%r14),%rdx
	pxor	%xmm4,%xmm4
	pxor	%xmm5,%xmm5
	movdqa	-128(%r12),%xmm0
	movdqa	-112(%r12),%xmm1
	movdqa	-96(%r12),%xmm2
	movdqa	-80(%r12),%xmm3
	pand	-128(%rdx),%xmm0
	pand	-112(%rdx),%xmm1
	por	%xmm0,%xmm4
	pand	-96(%rdx),%xmm2
	por	%xmm1,%xmm5
	pand	-80(%rdx),%xmm3
	por	%xmm2,%xmm4
	por	%xmm3,%xmm5
	movdqa	-64(%r12),%xmm0
	movdqa	-48(%r12),%xmm1
	movdqa	-32(%r12),%xmm2
	movdqa	-16(%r12),%xmm3
	pand	-64(%rdx),%xmm0
	pand	-48(%rdx),%xmm1
	por	%xmm0,%xmm4
	pand	-32(%rdx),%xmm2
	por	%xmm1,%xmm5
	pand	-16(%rdx),%xmm3
	por	%xmm2,%xmm4
	por	%xmm3,%xmm5
	movdqa	0(%r12),%xmm0
	movdqa	16(%r12),%xmm1
	movdqa	32(%r12),%xmm2
	movdqa	48(%r12),%xmm3
	pand	0(%rdx),%xmm0
	pand	16(%rdx),%xmm1
	por	%xmm0,%xmm4
	pand	32(%rdx),%xmm2
	por	%xmm1,%xmm5
	pand	48(%rdx),%xmm3
	por	%xmm2,%xmm4
	por	%xmm3,%xmm5
	movdqa	64(%r12),%xmm0
	movdqa	80(%r12),%xmm1
	movdqa	96(%r12),%xmm2
	movdqa	112(%r12),%xmm3
	pand	64(%rdx),%xmm0
	pand	80(%rdx),%xmm1
	por	%xmm0,%xmm4
	pand	96(%rdx),%xmm2
	por	%xmm1,%xmm5
	pand	112(%rdx),%xmm3
	por	%xmm2,%xmm4
	por	%xmm3,%xmm5
	por	%xmm5,%xmm4
	pshufd	$0x4e,%xmm4,%xmm0
	por	%xmm4,%xmm0
	leaq	256(%r12),%r12
.byte	102,72,15,126,195

	movq	(%r14,%r9,1),%r10
	movq	%r8,%rbp
	mulq	%rbx
	addq	%rax,%r10
	movq	(%rcx),%rax
	adcq	$0,%rdx

	imulq	%r10,%rbp
	movq	%rdx,%r11
	movq	%rdi,(%r14)

	leaq	(%r14,%r9,1),%r14

	mulq	%rbp
	addq	%rax,%r10
	movq	8(%rsi,%r9,1),%rax
	adcq	$0,%rdx
	movq	%rdx,%rdi

	mulq	%rbx
	addq	%rax,%r11
	movq	8(%rcx),%rax
	adcq	$0,%rdx
	addq	8(%r14),%r11
	adcq	$0,%rdx
	movq	%rdx,%r10

	mulq	%rbp
	addq	%rax,%rdi
	movq	16(%rsi,%r9,1),%rax
	adcq	$0,%rdx
	addq	%r11,%rdi
	leaq	32(%r9),%r15
	leaq	32(%rcx),%rcx
	adcq	$0,%rdx
	movq	%rdx,%r13
	jmp	.Linner4x

.align	32
.Linner4x:
	mulq	%rbx
	addq	%rax,%r10
	movq	-16(%rcx),%rax
	adcq	$0,%rdx
	addq	16(%r14),%r10
	leaq	32(%r14),%r14
	adcq	$0,%rdx
	movq	%rdx,%r11

	mulq	%rbp
	addq	%rax,%r13
	movq	-8(%rsi,%r15,1),%rax
	adcq	$0,%rdx
	addq	%r10,%r13
	adcq	$0,%rdx
	movq	%rdi,-32(%r14)
	movq	%rdx,%rdi

	mulq	%rbx
	addq	%rax,%r11
	movq	-8(%rcx),%rax
	adcq	$0,%rdx
	addq	-8(%r14),%r11
	adcq	$0,%rdx
	movq	%rdx,%r10

	mulq	%rbp
	addq	%rax,%rdi
	movq	(%rsi,%r15,1),%rax
	adcq	$0,%rdx
	addq	%r11,%rdi
	adcq	$0,%rdx
	movq	%r13,-24(%r14)
	movq	%rdx,%r13

	mulq	%rbx
	addq	%rax,%r10
	movq	0(%rcx),%rax
	adcq	$0,%rdx
	addq	(%r14),%r10
	adcq	$0,%rdx
	movq	%rdx,%r11

	mulq	%rbp
	addq	%rax,%r13
	movq	8(%rsi,%r15,1),%rax
	adcq	$0,%rdx
	addq	%r10,%r13
	adcq	$0,%rdx
	movq	%rdi,-16(%r14)
	movq	%rdx,%rdi

	mulq	%rbx
	addq	%rax,%r11
	movq	8(%rcx),%rax
	adcq	$0,%rdx
	addq	8(%r14),%r11
	adcq	$0,%rdx
	movq	%rdx,%r10

	mulq	%rbp
	addq	%rax,%rdi
	movq	16(%rsi,%r15,1),%rax
	adcq	$0,%rdx
	addq	%r11,%rdi
	leaq	32(%rcx),%rcx
	adcq	$0,%rdx
	movq	%r13,-8(%r14)
	movq	%rdx,%r13

	addq	$32,%r15
	jnz	.Linner4x

	mulq	%rbx
	addq	%rax,%r10
	movq	-16(%rcx),%rax
	adcq	$0,%rdx
	addq	16(%r14),%r10
	leaq	32(%r14),%r14
	adcq	$0,%rdx
	movq	%rdx,%r11

	mulq	%rbp
	addq	%rax,%r13
	movq	-8(%rsi),%rax
	adcq	$0,%rdx
	addq	%r10,%r13
	adcq	$0,%rdx
	movq	%rdi,-32(%r14)
	movq	%rdx,%rdi

	mulq	%rbx
	addq	%rax,%r11
	movq	%rbp,%rax
	movq	-8(%rcx),%rbp
	adcq	$0,%rdx
	addq	-8(%r14),%r11
	adcq	$0,%rdx
	movq	%rdx,%r10

	mulq	%rbp
	addq	%rax,%rdi
	movq	(%rsi,%r9,1),%rax
	adcq	$0,%rdx
	addq	%r11,%rdi
	adcq	$0,%rdx
	movq	%r13,-24(%r14)
	movq	%rdx,%r13

	movq	%rdi,-16(%r14)
	leaq	(%rcx,%r9,1),%rcx

	xorq	%rdi,%rdi
	addq	%r10,%r13
	adcq	$0,%rdi
	addq	(%r14),%r13
	adcq	$0,%rdi
	movq	%r13,-8(%r14)

	cmpq	16+8(%rsp),%r12
	jb	.Louter4x
	xorq	%rax,%rax
	subq	%r13,%rbp
	adcq	%r15,%r15
	orq	%r15,%rdi
	subq	%rdi,%rax
	leaq	(%r14,%r9,1),%rbx
	movq	(%rcx),%r12
	leaq	(%rcx),%rbp
	movq	%r9,%rcx
	sarq	$3+2,%rcx
	movq	56+8(%rsp),%rdi
	decq	%r12
	xorq	%r10,%r10
	movq	8(%rbp),%r13
	movq	16(%rbp),%r14
	movq	24(%rbp),%r15
	jmp	.Lsqr4x_sub_entry
.cfi_endproc	
.size	mul4x_internal,.-mul4x_internal
.globl	bn_power5
.type	bn_power5,@function
.align	32
bn_power5:
.cfi_startproc	
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	movl	OPENSSL_ia32cap_P+8(%rip),%r11d
	andl	$0x80108,%r11d
	cmpl	$0x80108,%r11d
	je	.Lpowerx5_enter
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
.Lpower5_prologue:

	shll	$3,%r9d
	leal	(%r9,%r9,2),%r10d
	negq	%r9
	movq	(%r8),%r8








	leaq	-320(%rsp,%r9,2),%r11
	movq	%rsp,%rbp
	subq	%rdi,%r11
	andq	$4095,%r11
	cmpq	%r11,%r10
	jb	.Lpwr_sp_alt
	subq	%r11,%rbp
	leaq	-320(%rbp,%r9,2),%rbp
	jmp	.Lpwr_sp_done

.align	32
.Lpwr_sp_alt:
	leaq	4096-320(,%r9,2),%r10
	leaq	-320(%rbp,%r9,2),%rbp
	subq	%r10,%r11
	movq	$0,%r10
	cmovcq	%r10,%r11
	subq	%r11,%rbp
.Lpwr_sp_done:
	andq	$-64,%rbp
	movq	%rsp,%r11
	subq	%rbp,%r11
	andq	$-4096,%r11
	leaq	(%r11,%rbp,1),%rsp
	movq	(%rsp),%r10
	cmpq	%rbp,%rsp
	ja	.Lpwr_page_walk
	jmp	.Lpwr_page_walk_done

.Lpwr_page_walk:
	leaq	-4096(%rsp),%rsp
	movq	(%rsp),%r10
	cmpq	%rbp,%rsp
	ja	.Lpwr_page_walk
.Lpwr_page_walk_done:

	movq	%r9,%r10
	negq	%r9










	movq	%r8,32(%rsp)
	movq	%rax,40(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x28,0x06,0x23,0x08
.Lpower5_body:
.byte	102,72,15,110,207
.byte	102,72,15,110,209
.byte	102,73,15,110,218
.byte	102,72,15,110,226

	call	__bn_sqr8x_internal
	call	__bn_post4x_internal
	call	__bn_sqr8x_internal
	call	__bn_post4x_internal
	call	__bn_sqr8x_internal
	call	__bn_post4x_internal
	call	__bn_sqr8x_internal
	call	__bn_post4x_internal
	call	__bn_sqr8x_internal
	call	__bn_post4x_internal

.byte	102,72,15,126,209
.byte	102,72,15,126,226
	movq	%rsi,%rdi
	movq	40(%rsp),%rax
	leaq	32(%rsp),%r8

	call	mul4x_internal

	movq	40(%rsp),%rsi
.cfi_def_cfa	%rsi,8
	movq	$1,%rax
	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lpower5_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	bn_power5,.-bn_power5

.globl	bn_sqr8x_internal
.hidden	bn_sqr8x_internal
.type	bn_sqr8x_internal,@function
.align	32
bn_sqr8x_internal:
__bn_sqr8x_internal:
.cfi_startproc	









































































	leaq	32(%r10),%rbp
	leaq	(%rsi,%r9,1),%rsi

	movq	%r9,%rcx


	movq	-32(%rsi,%rbp,1),%r14
	leaq	48+8(%rsp,%r9,2),%rdi
	movq	-24(%rsi,%rbp,1),%rax
	leaq	-32(%rdi,%rbp,1),%rdi
	movq	-16(%rsi,%rbp,1),%rbx
	movq	%rax,%r15

	mulq	%r14
	movq	%rax,%r10
	movq	%rbx,%rax
	movq	%rdx,%r11
	movq	%r10,-24(%rdi,%rbp,1)

	mulq	%r14
	addq	%rax,%r11
	movq	%rbx,%rax
	adcq	$0,%rdx
	movq	%r11,-16(%rdi,%rbp,1)
	movq	%rdx,%r10


	movq	-8(%rsi,%rbp,1),%rbx
	mulq	%r15
	movq	%rax,%r12
	movq	%rbx,%rax
	movq	%rdx,%r13

	leaq	(%rbp),%rcx
	mulq	%r14
	addq	%rax,%r10
	movq	%rbx,%rax
	movq	%rdx,%r11
	adcq	$0,%r11
	addq	%r12,%r10
	adcq	$0,%r11
	movq	%r10,-8(%rdi,%rcx,1)
	jmp	.Lsqr4x_1st

.align	32
.Lsqr4x_1st:
	movq	(%rsi,%rcx,1),%rbx
	mulq	%r15
	addq	%rax,%r13
	movq	%rbx,%rax
	movq	%rdx,%r12
	adcq	$0,%r12

	mulq	%r14
	addq	%rax,%r11
	movq	%rbx,%rax
	movq	8(%rsi,%rcx,1),%rbx
	movq	%rdx,%r10
	adcq	$0,%r10
	addq	%r13,%r11
	adcq	$0,%r10


	mulq	%r15
	addq	%rax,%r12
	movq	%rbx,%rax
	movq	%r11,(%rdi,%rcx,1)
	movq	%rdx,%r13
	adcq	$0,%r13

	mulq	%r14
	addq	%rax,%r10
	movq	%rbx,%rax
	movq	16(%rsi,%rcx,1),%rbx
	movq	%rdx,%r11
	adcq	$0,%r11
	addq	%r12,%r10
	adcq	$0,%r11

	mulq	%r15
	addq	%rax,%r13
	movq	%rbx,%rax
	movq	%r10,8(%rdi,%rcx,1)
	movq	%rdx,%r12
	adcq	$0,%r12

	mulq	%r14
	addq	%rax,%r11
	movq	%rbx,%rax
	movq	24(%rsi,%rcx,1),%rbx
	movq	%rdx,%r10
	adcq	$0,%r10
	addq	%r13,%r11
	adcq	$0,%r10


	mulq	%r15
	addq	%rax,%r12
	movq	%rbx,%rax
	movq	%r11,16(%rdi,%rcx,1)
	movq	%rdx,%r13
	adcq	$0,%r13
	leaq	32(%rcx),%rcx

	mulq	%r14
	addq	%rax,%r10
	movq	%rbx,%rax
	movq	%rdx,%r11
	adcq	$0,%r11
	addq	%r12,%r10
	adcq	$0,%r11
	movq	%r10,-8(%rdi,%rcx,1)

	cmpq	$0,%rcx
	jne	.Lsqr4x_1st

	mulq	%r15
	addq	%rax,%r13
	leaq	16(%rbp),%rbp
	adcq	$0,%rdx
	addq	%r11,%r13
	adcq	$0,%rdx

	movq	%r13,(%rdi)
	movq	%rdx,%r12
	movq	%rdx,8(%rdi)
	jmp	.Lsqr4x_outer

.align	32
.Lsqr4x_outer:
	movq	-32(%rsi,%rbp,1),%r14
	leaq	48+8(%rsp,%r9,2),%rdi
	movq	-24(%rsi,%rbp,1),%rax
	leaq	-32(%rdi,%rbp,1),%rdi
	movq	-16(%rsi,%rbp,1),%rbx
	movq	%rax,%r15

	mulq	%r14
	movq	-24(%rdi,%rbp,1),%r10
	addq	%rax,%r10
	movq	%rbx,%rax
	adcq	$0,%rdx
	movq	%r10,-24(%rdi,%rbp,1)
	movq	%rdx,%r11

	mulq	%r14
	addq	%rax,%r11
	movq	%rbx,%rax
	adcq	$0,%rdx
	addq	-16(%rdi,%rbp,1),%r11
	movq	%rdx,%r10
	adcq	$0,%r10
	movq	%r11,-16(%rdi,%rbp,1)

	xorq	%r12,%r12

	movq	-8(%rsi,%rbp,1),%rbx
	mulq	%r15
	addq	%rax,%r12
	movq	%rbx,%rax
	adcq	$0,%rdx
	addq	-8(%rdi,%rbp,1),%r12
	movq	%rdx,%r13
	adcq	$0,%r13

	mulq	%r14
	addq	%rax,%r10
	movq	%rbx,%rax
	adcq	$0,%rdx
	addq	%r12,%r10
	movq	%rdx,%r11
	adcq	$0,%r11
	movq	%r10,-8(%rdi,%rbp,1)

	leaq	(%rbp),%rcx
	jmp	.Lsqr4x_inner

.align	32
.Lsqr4x_inner:
	movq	(%rsi,%rcx,1),%rbx
	mulq	%r15
	addq	%rax,%r13
	movq	%rbx,%rax
	movq	%rdx,%r12
	adcq	$0,%r12
	addq	(%rdi,%rcx,1),%r13
	adcq	$0,%r12

.byte	0x67
	mulq	%r14
	addq	%rax,%r11
	movq	%rbx,%rax
	movq	8(%rsi,%rcx,1),%rbx
	movq	%rdx,%r10
	adcq	$0,%r10
	addq	%r13,%r11
	adcq	$0,%r10

	mulq	%r15
	addq	%rax,%r12
	movq	%r11,(%rdi,%rcx,1)
	movq	%rbx,%rax
	movq	%rdx,%r13
	adcq	$0,%r13
	addq	8(%rdi,%rcx,1),%r12
	leaq	16(%rcx),%rcx
	adcq	$0,%r13

	mulq	%r14
	addq	%rax,%r10
	movq	%rbx,%rax
	adcq	$0,%rdx
	addq	%r12,%r10
	movq	%rdx,%r11
	adcq	$0,%r11
	movq	%r10,-8(%rdi,%rcx,1)

	cmpq	$0,%rcx
	jne	.Lsqr4x_inner

.byte	0x67
	mulq	%r15
	addq	%rax,%r13
	adcq	$0,%rdx
	addq	%r11,%r13
	adcq	$0,%rdx

	movq	%r13,(%rdi)
	movq	%rdx,%r12
	movq	%rdx,8(%rdi)

	addq	$16,%rbp
	jnz	.Lsqr4x_outer


	movq	-32(%rsi),%r14
	leaq	48+8(%rsp,%r9,2),%rdi
	movq	-24(%rsi),%rax
	leaq	-32(%rdi,%rbp,1),%rdi
	movq	-16(%rsi),%rbx
	movq	%rax,%r15

	mulq	%r14
	addq	%rax,%r10
	movq	%rbx,%rax
	movq	%rdx,%r11
	adcq	$0,%r11

	mulq	%r14
	addq	%rax,%r11
	movq	%rbx,%rax
	movq	%r10,-24(%rdi)
	movq	%rdx,%r10
	adcq	$0,%r10
	addq	%r13,%r11
	movq	-8(%rsi),%rbx
	adcq	$0,%r10

	mulq	%r15
	addq	%rax,%r12
	movq	%rbx,%rax
	movq	%r11,-16(%rdi)
	movq	%rdx,%r13
	adcq	$0,%r13

	mulq	%r14
	addq	%rax,%r10
	movq	%rbx,%rax
	movq	%rdx,%r11
	adcq	$0,%r11
	addq	%r12,%r10
	adcq	$0,%r11
	movq	%r10,-8(%rdi)

	mulq	%r15
	addq	%rax,%r13
	movq	-16(%rsi),%rax
	adcq	$0,%rdx
	addq	%r11,%r13
	adcq	$0,%rdx

	movq	%r13,(%rdi)
	movq	%rdx,%r12
	movq	%rdx,8(%rdi)

	mulq	%rbx
	addq	$16,%rbp
	xorq	%r14,%r14
	subq	%r9,%rbp
	xorq	%r15,%r15

	addq	%r12,%rax
	adcq	$0,%rdx
	movq	%rax,8(%rdi)
	movq	%rdx,16(%rdi)
	movq	%r15,24(%rdi)

	movq	-16(%rsi,%rbp,1),%rax
	leaq	48+8(%rsp),%rdi
	xorq	%r10,%r10
	movq	8(%rdi),%r11

	leaq	(%r14,%r10,2),%r12
	shrq	$63,%r10
	leaq	(%rcx,%r11,2),%r13
	shrq	$63,%r11
	orq	%r10,%r13
	movq	16(%rdi),%r10
	movq	%r11,%r14
	mulq	%rax
	negq	%r15
	movq	24(%rdi),%r11
	adcq	%rax,%r12
	movq	-8(%rsi,%rbp,1),%rax
	movq	%r12,(%rdi)
	adcq	%rdx,%r13

	leaq	(%r14,%r10,2),%rbx
	movq	%r13,8(%rdi)
	sbbq	%r15,%r15
	shrq	$63,%r10
	leaq	(%rcx,%r11,2),%r8
	shrq	$63,%r11
	orq	%r10,%r8
	movq	32(%rdi),%r10
	movq	%r11,%r14
	mulq	%rax
	negq	%r15
	movq	40(%rdi),%r11
	adcq	%rax,%rbx
	movq	0(%rsi,%rbp,1),%rax
	movq	%rbx,16(%rdi)
	adcq	%rdx,%r8
	leaq	16(%rbp),%rbp
	movq	%r8,24(%rdi)
	sbbq	%r15,%r15
	leaq	64(%rdi),%rdi
	jmp	.Lsqr4x_shift_n_add

.align	32
.Lsqr4x_shift_n_add:
	leaq	(%r14,%r10,2),%r12
	shrq	$63,%r10
	leaq	(%rcx,%r11,2),%r13
	shrq	$63,%r11
	orq	%r10,%r13
	movq	-16(%rdi),%r10
	movq	%r11,%r14
	mulq	%rax
	negq	%r15
	movq	-8(%rdi),%r11
	adcq	%rax,%r12
	movq	-8(%rsi,%rbp,1),%rax
	movq	%r12,-32(%rdi)
	adcq	%rdx,%r13

	leaq	(%r14,%r10,2),%rbx
	movq	%r13,-24(%rdi)
	sbbq	%r15,%r15
	shrq	$63,%r10
	leaq	(%rcx,%r11,2),%r8
	shrq	$63,%r11
	orq	%r10,%r8
	movq	0(%rdi),%r10
	movq	%r11,%r14
	mulq	%rax
	negq	%r15
	movq	8(%rdi),%r11
	adcq	%rax,%rbx
	movq	0(%rsi,%rbp,1),%rax
	movq	%rbx,-16(%rdi)
	adcq	%rdx,%r8

	leaq	(%r14,%r10,2),%r12
	movq	%r8,-8(%rdi)
	sbbq	%r15,%r15
	shrq	$63,%r10
	leaq	(%rcx,%r11,2),%r13
	shrq	$63,%r11
	orq	%r10,%r13
	movq	16(%rdi),%r10
	movq	%r11,%r14
	mulq	%rax
	negq	%r15
	movq	24(%rdi),%r11
	adcq	%rax,%r12
	movq	8(%rsi,%rbp,1),%rax
	movq	%r12,0(%rdi)
	adcq	%rdx,%r13

	leaq	(%r14,%r10,2),%rbx
	movq	%r13,8(%rdi)
	sbbq	%r15,%r15
	shrq	$63,%r10
	leaq	(%rcx,%r11,2),%r8
	shrq	$63,%r11
	orq	%r10,%r8
	movq	32(%rdi),%r10
	movq	%r11,%r14
	mulq	%rax
	negq	%r15
	movq	40(%rdi),%r11
	adcq	%rax,%rbx
	movq	16(%rsi,%rbp,1),%rax
	movq	%rbx,16(%rdi)
	adcq	%rdx,%r8
	movq	%r8,24(%rdi)
	sbbq	%r15,%r15
	leaq	64(%rdi),%rdi
	addq	$32,%rbp
	jnz	.Lsqr4x_shift_n_add

	leaq	(%r14,%r10,2),%r12
.byte	0x67
	shrq	$63,%r10
	leaq	(%rcx,%r11,2),%r13
	shrq	$63,%r11
	orq	%r10,%r13
	movq	-16(%rdi),%r10
	movq	%r11,%r14
	mulq	%rax
	negq	%r15
	movq	-8(%rdi),%r11
	adcq	%rax,%r12
	movq	-8(%rsi),%rax
	movq	%r12,-32(%rdi)
	adcq	%rdx,%r13

	leaq	(%r14,%r10,2),%rbx
	movq	%r13,-24(%rdi)
	sbbq	%r15,%r15
	shrq	$63,%r10
	leaq	(%rcx,%r11,2),%r8
	shrq	$63,%r11
	orq	%r10,%r8
	mulq	%rax
	negq	%r15
	adcq	%rax,%rbx
	adcq	%rdx,%r8
	movq	%rbx,-16(%rdi)
	movq	%r8,-8(%rdi)
.byte	102,72,15,126,213
__bn_sqr8x_reduction:
	xorq	%rax,%rax
	leaq	(%r9,%rbp,1),%rcx
	leaq	48+8(%rsp,%r9,2),%rdx
	movq	%rcx,0+8(%rsp)
	leaq	48+8(%rsp,%r9,1),%rdi
	movq	%rdx,8+8(%rsp)
	negq	%r9
	jmp	.L8x_reduction_loop

.align	32
.L8x_reduction_loop:
	leaq	(%rdi,%r9,1),%rdi
.byte	0x66
	movq	0(%rdi),%rbx
	movq	8(%rdi),%r9
	movq	16(%rdi),%r10
	movq	24(%rdi),%r11
	movq	32(%rdi),%r12
	movq	40(%rdi),%r13
	movq	48(%rdi),%r14
	movq	56(%rdi),%r15
	movq	%rax,(%rdx)
	leaq	64(%rdi),%rdi

.byte	0x67
	movq	%rbx,%r8
	imulq	32+8(%rsp),%rbx
	movq	0(%rbp),%rax
	movl	$8,%ecx
	jmp	.L8x_reduce

.align	32
.L8x_reduce:
	mulq	%rbx
	movq	8(%rbp),%rax
	negq	%r8
	movq	%rdx,%r8
	adcq	$0,%r8

	mulq	%rbx
	addq	%rax,%r9
	movq	16(%rbp),%rax
	adcq	$0,%rdx
	addq	%r9,%r8
	movq	%rbx,48-8+8(%rsp,%rcx,8)
	movq	%rdx,%r9
	adcq	$0,%r9

	mulq	%rbx
	addq	%rax,%r10
	movq	24(%rbp),%rax
	adcq	$0,%rdx
	addq	%r10,%r9
	movq	32+8(%rsp),%rsi
	movq	%rdx,%r10
	adcq	$0,%r10

	mulq	%rbx
	addq	%rax,%r11
	movq	32(%rbp),%rax
	adcq	$0,%rdx
	imulq	%r8,%rsi
	addq	%r11,%r10
	movq	%rdx,%r11
	adcq	$0,%r11

	mulq	%rbx
	addq	%rax,%r12
	movq	40(%rbp),%rax
	adcq	$0,%rdx
	addq	%r12,%r11
	movq	%rdx,%r12
	adcq	$0,%r12

	mulq	%rbx
	addq	%rax,%r13
	movq	48(%rbp),%rax
	adcq	$0,%rdx
	addq	%r13,%r12
	movq	%rdx,%r13
	adcq	$0,%r13

	mulq	%rbx
	addq	%rax,%r14
	movq	56(%rbp),%rax
	adcq	$0,%rdx
	addq	%r14,%r13
	movq	%rdx,%r14
	adcq	$0,%r14

	mulq	%rbx
	movq	%rsi,%rbx
	addq	%rax,%r15
	movq	0(%rbp),%rax
	adcq	$0,%rdx
	addq	%r15,%r14
	movq	%rdx,%r15
	adcq	$0,%r15

	decl	%ecx
	jnz	.L8x_reduce

	leaq	64(%rbp),%rbp
	xorq	%rax,%rax
	movq	8+8(%rsp),%rdx
	cmpq	0+8(%rsp),%rbp
	jae	.L8x_no_tail

.byte	0x66
	addq	0(%rdi),%r8
	adcq	8(%rdi),%r9
	adcq	16(%rdi),%r10
	adcq	24(%rdi),%r11
	adcq	32(%rdi),%r12
	adcq	40(%rdi),%r13
	adcq	48(%rdi),%r14
	adcq	56(%rdi),%r15
	sbbq	%rsi,%rsi

	movq	48+56+8(%rsp),%rbx
	movl	$8,%ecx
	movq	0(%rbp),%rax
	jmp	.L8x_tail

.align	32
.L8x_tail:
	mulq	%rbx
	addq	%rax,%r8
	movq	8(%rbp),%rax
	movq	%r8,(%rdi)
	movq	%rdx,%r8
	adcq	$0,%r8

	mulq	%rbx
	addq	%rax,%r9
	movq	16(%rbp),%rax
	adcq	$0,%rdx
	addq	%r9,%r8
	leaq	8(%rdi),%rdi
	movq	%rdx,%r9
	adcq	$0,%r9

	mulq	%rbx
	addq	%rax,%r10
	movq	24(%rbp),%rax
	adcq	$0,%rdx
	addq	%r10,%r9
	movq	%rdx,%r10
	adcq	$0,%r10

	mulq	%rbx
	addq	%rax,%r11
	movq	32(%rbp),%rax
	adcq	$0,%rdx
	addq	%r11,%r10
	movq	%rdx,%r11
	adcq	$0,%r11

	mulq	%rbx
	addq	%rax,%r12
	movq	40(%rbp),%rax
	adcq	$0,%rdx
	addq	%r12,%r11
	movq	%rdx,%r12
	adcq	$0,%r12

	mulq	%rbx
	addq	%rax,%r13
	movq	48(%rbp),%rax
	adcq	$0,%rdx
	addq	%r13,%r12
	movq	%rdx,%r13
	adcq	$0,%r13

	mulq	%rbx
	addq	%rax,%r14
	movq	56(%rbp),%rax
	adcq	$0,%rdx
	addq	%r14,%r13
	movq	%rdx,%r14
	adcq	$0,%r14

	mulq	%rbx
	movq	48-16+8(%rsp,%rcx,8),%rbx
	addq	%rax,%r15
	adcq	$0,%rdx
	addq	%r15,%r14
	movq	0(%rbp),%rax
	movq	%rdx,%r15
	adcq	$0,%r15

	decl	%ecx
	jnz	.L8x_tail

	leaq	64(%rbp),%rbp
	movq	8+8(%rsp),%rdx
	cmpq	0+8(%rsp),%rbp
	jae	.L8x_tail_done

	movq	48+56+8(%rsp),%rbx
	negq	%rsi
	movq	0(%rbp),%rax
	adcq	0(%rdi),%r8
	adcq	8(%rdi),%r9
	adcq	16(%rdi),%r10
	adcq	24(%rdi),%r11
	adcq	32(%rdi),%r12
	adcq	40(%rdi),%r13
	adcq	48(%rdi),%r14
	adcq	56(%rdi),%r15
	sbbq	%rsi,%rsi

	movl	$8,%ecx
	jmp	.L8x_tail

.align	32
.L8x_tail_done:
	xorq	%rax,%rax
	addq	(%rdx),%r8
	adcq	$0,%r9
	adcq	$0,%r10
	adcq	$0,%r11
	adcq	$0,%r12
	adcq	$0,%r13
	adcq	$0,%r14
	adcq	$0,%r15
	adcq	$0,%rax

	negq	%rsi
.L8x_no_tail:
	adcq	0(%rdi),%r8
	adcq	8(%rdi),%r9
	adcq	16(%rdi),%r10
	adcq	24(%rdi),%r11
	adcq	32(%rdi),%r12
	adcq	40(%rdi),%r13
	adcq	48(%rdi),%r14
	adcq	56(%rdi),%r15
	adcq	$0,%rax
	movq	-8(%rbp),%rcx
	xorq	%rsi,%rsi

.byte	102,72,15,126,213

	movq	%r8,0(%rdi)
	movq	%r9,8(%rdi)
.byte	102,73,15,126,217
	movq	%r10,16(%rdi)
	movq	%r11,24(%rdi)
	movq	%r12,32(%rdi)
	movq	%r13,40(%rdi)
	movq	%r14,48(%rdi)
	movq	%r15,56(%rdi)
	leaq	64(%rdi),%rdi

	cmpq	%rdx,%rdi
	jb	.L8x_reduction_loop
	.byte	0xf3,0xc3
.cfi_endproc	
.size	bn_sqr8x_internal,.-bn_sqr8x_internal
.type	__bn_post4x_internal,@function
.align	32
__bn_post4x_internal:
.cfi_startproc	
	movq	0(%rbp),%r12
	leaq	(%rdi,%r9,1),%rbx
	movq	%r9,%rcx
.byte	102,72,15,126,207
	negq	%rax
.byte	102,72,15,126,206
	sarq	$3+2,%rcx
	decq	%r12
	xorq	%r10,%r10
	movq	8(%rbp),%r13
	movq	16(%rbp),%r14
	movq	24(%rbp),%r15
	jmp	.Lsqr4x_sub_entry

.align	16
.Lsqr4x_sub:
	movq	0(%rbp),%r12
	movq	8(%rbp),%r13
	movq	16(%rbp),%r14
	movq	24(%rbp),%r15
.Lsqr4x_sub_entry:
	leaq	32(%rbp),%rbp
	notq	%r12
	notq	%r13
	notq	%r14
	notq	%r15
	andq	%rax,%r12
	andq	%rax,%r13
	andq	%rax,%r14
	andq	%rax,%r15

	negq	%r10
	adcq	0(%rbx),%r12
	adcq	8(%rbx),%r13
	adcq	16(%rbx),%r14
	adcq	24(%rbx),%r15
	movq	%r12,0(%rdi)
	leaq	32(%rbx),%rbx
	movq	%r13,8(%rdi)
	sbbq	%r10,%r10
	movq	%r14,16(%rdi)
	movq	%r15,24(%rdi)
	leaq	32(%rdi),%rdi

	incq	%rcx
	jnz	.Lsqr4x_sub

	movq	%r9,%r10
	negq	%r9
	.byte	0xf3,0xc3
.cfi_endproc	
.size	__bn_post4x_internal,.-__bn_post4x_internal
.type	bn_mulx4x_mont_gather5,@function
.align	32
bn_mulx4x_mont_gather5:
.cfi_startproc	
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
.Lmulx4x_enter:
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
.Lmulx4x_prologue:

	shll	$3,%r9d
	leaq	(%r9,%r9,2),%r10
	negq	%r9
	movq	(%r8),%r8










	leaq	-320(%rsp,%r9,2),%r11
	movq	%rsp,%rbp
	subq	%rdi,%r11
	andq	$4095,%r11
	cmpq	%r11,%r10
	jb	.Lmulx4xsp_alt
	subq	%r11,%rbp
	leaq	-320(%rbp,%r9,2),%rbp
	jmp	.Lmulx4xsp_done

.Lmulx4xsp_alt:
	leaq	4096-320(,%r9,2),%r10
	leaq	-320(%rbp,%r9,2),%rbp
	subq	%r10,%r11
	movq	$0,%r10
	cmovcq	%r10,%r11
	subq	%r11,%rbp
.Lmulx4xsp_done:
	andq	$-64,%rbp
	movq	%rsp,%r11
	subq	%rbp,%r11
	andq	$-4096,%r11
	leaq	(%r11,%rbp,1),%rsp
	movq	(%rsp),%r10
	cmpq	%rbp,%rsp
	ja	.Lmulx4x_page_walk
	jmp	.Lmulx4x_page_walk_done

.Lmulx4x_page_walk:
	leaq	-4096(%rsp),%rsp
	movq	(%rsp),%r10
	cmpq	%rbp,%rsp
	ja	.Lmulx4x_page_walk
.Lmulx4x_page_walk_done:













	movq	%r8,32(%rsp)
	movq	%rax,40(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x28,0x06,0x23,0x08
.Lmulx4x_body:
	call	mulx4x_internal

	movq	40(%rsp),%rsi
.cfi_def_cfa	%rsi,8
	movq	$1,%rax

	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lmulx4x_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	bn_mulx4x_mont_gather5,.-bn_mulx4x_mont_gather5

.type	mulx4x_internal,@function
.align	32
mulx4x_internal:
.cfi_startproc	
	movq	%r9,8(%rsp)
	movq	%r9,%r10
	negq	%r9
	shlq	$5,%r9
	negq	%r10
	leaq	128(%rdx,%r9,1),%r13
	shrq	$5+5,%r9
	movd	8(%rax),%xmm5
	subq	$1,%r9
	leaq	.Linc(%rip),%rax
	movq	%r13,16+8(%rsp)
	movq	%r9,24+8(%rsp)
	movq	%rdi,56+8(%rsp)
	movdqa	0(%rax),%xmm0
	movdqa	16(%rax),%xmm1
	leaq	88-112(%rsp,%r10,1),%r10
	leaq	128(%rdx),%rdi

	pshufd	$0,%xmm5,%xmm5
	movdqa	%xmm1,%xmm4
.byte	0x67
	movdqa	%xmm1,%xmm2
.byte	0x67
	paddd	%xmm0,%xmm1
	pcmpeqd	%xmm5,%xmm0
	movdqa	%xmm4,%xmm3
	paddd	%xmm1,%xmm2
	pcmpeqd	%xmm5,%xmm1
	movdqa	%xmm0,112(%r10)
	movdqa	%xmm4,%xmm0

	paddd	%xmm2,%xmm3
	pcmpeqd	%xmm5,%xmm2
	movdqa	%xmm1,128(%r10)
	movdqa	%xmm4,%xmm1

	paddd	%xmm3,%xmm0
	pcmpeqd	%xmm5,%xmm3
	movdqa	%xmm2,144(%r10)
	movdqa	%xmm4,%xmm2

	paddd	%xmm0,%xmm1
	pcmpeqd	%xmm5,%xmm0
	movdqa	%xmm3,160(%r10)
	movdqa	%xmm4,%xmm3
	paddd	%xmm1,%xmm2
	pcmpeqd	%xmm5,%xmm1
	movdqa	%xmm0,176(%r10)
	movdqa	%xmm4,%xmm0

	paddd	%xmm2,%xmm3
	pcmpeqd	%xmm5,%xmm2
	movdqa	%xmm1,192(%r10)
	movdqa	%xmm4,%xmm1

	paddd	%xmm3,%xmm0
	pcmpeqd	%xmm5,%xmm3
	movdqa	%xmm2,208(%r10)
	movdqa	%xmm4,%xmm2

	paddd	%xmm0,%xmm1
	pcmpeqd	%xmm5,%xmm0
	movdqa	%xmm3,224(%r10)
	movdqa	%xmm4,%xmm3
	paddd	%xmm1,%xmm2
	pcmpeqd	%xmm5,%xmm1
	movdqa	%xmm0,240(%r10)
	movdqa	%xmm4,%xmm0

	paddd	%xmm2,%xmm3
	pcmpeqd	%xmm5,%xmm2
	movdqa	%xmm1,256(%r10)
	movdqa	%xmm4,%xmm1

	paddd	%xmm3,%xmm0
	pcmpeqd	%xmm5,%xmm3
	movdqa	%xmm2,272(%r10)
	movdqa	%xmm4,%xmm2

	paddd	%xmm0,%xmm1
	pcmpeqd	%xmm5,%xmm0
	movdqa	%xmm3,288(%r10)
	movdqa	%xmm4,%xmm3
.byte	0x67
	paddd	%xmm1,%xmm2
	pcmpeqd	%xmm5,%xmm1
	movdqa	%xmm0,304(%r10)

	paddd	%xmm2,%xmm3
	pcmpeqd	%xmm5,%xmm2
	movdqa	%xmm1,320(%r10)

	pcmpeqd	%xmm5,%xmm3
	movdqa	%xmm2,336(%r10)

	pand	64(%rdi),%xmm0
	pand	80(%rdi),%xmm1
	pand	96(%rdi),%xmm2
	movdqa	%xmm3,352(%r10)
	pand	112(%rdi),%xmm3
	por	%xmm2,%xmm0
	por	%xmm3,%xmm1
	movdqa	-128(%rdi),%xmm4
	movdqa	-112(%rdi),%xmm5
	movdqa	-96(%rdi),%xmm2
	pand	112(%r10),%xmm4
	movdqa	-80(%rdi),%xmm3
	pand	128(%r10),%xmm5
	por	%xmm4,%xmm0
	pand	144(%r10),%xmm2
	por	%xmm5,%xmm1
	pand	160(%r10),%xmm3
	por	%xmm2,%xmm0
	por	%xmm3,%xmm1
	movdqa	-64(%rdi),%xmm4
	movdqa	-48(%rdi),%xmm5
	movdqa	-32(%rdi),%xmm2
	pand	176(%r10),%xmm4
	movdqa	-16(%rdi),%xmm3
	pand	192(%r10),%xmm5
	por	%xmm4,%xmm0
	pand	208(%r10),%xmm2
	por	%xmm5,%xmm1
	pand	224(%r10),%xmm3
	por	%xmm2,%xmm0
	por	%xmm3,%xmm1
	movdqa	0(%rdi),%xmm4
	movdqa	16(%rdi),%xmm5
	movdqa	32(%rdi),%xmm2
	pand	240(%r10),%xmm4
	movdqa	48(%rdi),%xmm3
	pand	256(%r10),%xmm5
	por	%xmm4,%xmm0
	pand	272(%r10),%xmm2
	por	%xmm5,%xmm1
	pand	288(%r10),%xmm3
	por	%xmm2,%xmm0
	por	%xmm3,%xmm1
	pxor	%xmm1,%xmm0
	pshufd	$0x4e,%xmm0,%xmm1
	por	%xmm1,%xmm0
	leaq	256(%rdi),%rdi
.byte	102,72,15,126,194
	leaq	64+32+8(%rsp),%rbx

	movq	%rdx,%r9
	mulxq	0(%rsi),%r8,%rax
	mulxq	8(%rsi),%r11,%r12
	addq	%rax,%r11
	mulxq	16(%rsi),%rax,%r13
	adcq	%rax,%r12
	adcq	$0,%r13
	mulxq	24(%rsi),%rax,%r14

	movq	%r8,%r15
	imulq	32+8(%rsp),%r8
	xorq	%rbp,%rbp
	movq	%r8,%rdx

	movq	%rdi,8+8(%rsp)

	leaq	32(%rsi),%rsi
	adcxq	%rax,%r13
	adcxq	%rbp,%r14

	mulxq	0(%rcx),%rax,%r10
	adcxq	%rax,%r15
	adoxq	%r11,%r10
	mulxq	8(%rcx),%rax,%r11
	adcxq	%rax,%r10
	adoxq	%r12,%r11
	mulxq	16(%rcx),%rax,%r12
	movq	24+8(%rsp),%rdi
	movq	%r10,-32(%rbx)
	adcxq	%rax,%r11
	adoxq	%r13,%r12
	mulxq	24(%rcx),%rax,%r15
	movq	%r9,%rdx
	movq	%r11,-24(%rbx)
	adcxq	%rax,%r12
	adoxq	%rbp,%r15
	leaq	32(%rcx),%rcx
	movq	%r12,-16(%rbx)
	jmp	.Lmulx4x_1st

.align	32
.Lmulx4x_1st:
	adcxq	%rbp,%r15
	mulxq	0(%rsi),%r10,%rax
	adcxq	%r14,%r10
	mulxq	8(%rsi),%r11,%r14
	adcxq	%rax,%r11
	mulxq	16(%rsi),%r12,%rax
	adcxq	%r14,%r12
	mulxq	24(%rsi),%r13,%r14
.byte	0x67,0x67
	movq	%r8,%rdx
	adcxq	%rax,%r13
	adcxq	%rbp,%r14
	leaq	32(%rsi),%rsi
	leaq	32(%rbx),%rbx

	adoxq	%r15,%r10
	mulxq	0(%rcx),%rax,%r15
	adcxq	%rax,%r10
	adoxq	%r15,%r11
	mulxq	8(%rcx),%rax,%r15
	adcxq	%rax,%r11
	adoxq	%r15,%r12
	mulxq	16(%rcx),%rax,%r15
	movq	%r10,-40(%rbx)
	adcxq	%rax,%r12
	movq	%r11,-32(%rbx)
	adoxq	%r15,%r13
	mulxq	24(%rcx),%rax,%r15
	movq	%r9,%rdx
	movq	%r12,-24(%rbx)
	adcxq	%rax,%r13
	adoxq	%rbp,%r15
	leaq	32(%rcx),%rcx
	movq	%r13,-16(%rbx)

	decq	%rdi
	jnz	.Lmulx4x_1st

	movq	8(%rsp),%rax
	adcq	%rbp,%r15
	leaq	(%rsi,%rax,1),%rsi
	addq	%r15,%r14
	movq	8+8(%rsp),%rdi
	adcq	%rbp,%rbp
	movq	%r14,-8(%rbx)
	jmp	.Lmulx4x_outer

.align	32
.Lmulx4x_outer:
	leaq	16-256(%rbx),%r10
	pxor	%xmm4,%xmm4
.byte	0x67,0x67
	pxor	%xmm5,%xmm5
	movdqa	-128(%rdi),%xmm0
	movdqa	-112(%rdi),%xmm1
	movdqa	-96(%rdi),%xmm2
	pand	256(%r10),%xmm0
	movdqa	-80(%rdi),%xmm3
	pand	272(%r10),%xmm1
	por	%xmm0,%xmm4
	pand	288(%r10),%xmm2
	por	%xmm1,%xmm5
	pand	304(%r10),%xmm3
	por	%xmm2,%xmm4
	por	%xmm3,%xmm5
	movdqa	-64(%rdi),%xmm0
	movdqa	-48(%rdi),%xmm1
	movdqa	-32(%rdi),%xmm2
	pand	320(%r10),%xmm0
	movdqa	-16(%rdi),%xmm3
	pand	336(%r10),%xmm1
	por	%xmm0,%xmm4
	pand	352(%r10),%xmm2
	por	%xmm1,%xmm5
	pand	368(%r10),%xmm3
	por	%xmm2,%xmm4
	por	%xmm3,%xmm5
	movdqa	0(%rdi),%xmm0
	movdqa	16(%rdi),%xmm1
	movdqa	32(%rdi),%xmm2
	pand	384(%r10),%xmm0
	movdqa	48(%rdi),%xmm3
	pand	400(%r10),%xmm1
	por	%xmm0,%xmm4
	pand	416(%r10),%xmm2
	por	%xmm1,%xmm5
	pand	432(%r10),%xmm3
	por	%xmm2,%xmm4
	por	%xmm3,%xmm5
	movdqa	64(%rdi),%xmm0
	movdqa	80(%rdi),%xmm1
	movdqa	96(%rdi),%xmm2
	pand	448(%r10),%xmm0
	movdqa	112(%rdi),%xmm3
	pand	464(%r10),%xmm1
	por	%xmm0,%xmm4
	pand	480(%r10),%xmm2
	por	%xmm1,%xmm5
	pand	496(%r10),%xmm3
	por	%xmm2,%xmm4
	por	%xmm3,%xmm5
	por	%xmm5,%xmm4
	pshufd	$0x4e,%xmm4,%xmm0
	por	%xmm4,%xmm0
	leaq	256(%rdi),%rdi
.byte	102,72,15,126,194

	movq	%rbp,(%rbx)
	leaq	32(%rbx,%rax,1),%rbx
	mulxq	0(%rsi),%r8,%r11
	xorq	%rbp,%rbp
	movq	%rdx,%r9
	mulxq	8(%rsi),%r14,%r12
	adoxq	-32(%rbx),%r8
	adcxq	%r14,%r11
	mulxq	16(%rsi),%r15,%r13
	adoxq	-24(%rbx),%r11
	adcxq	%r15,%r12
	mulxq	24(%rsi),%rdx,%r14
	adoxq	-16(%rbx),%r12
	adcxq	%rdx,%r13
	leaq	(%rcx,%rax,1),%rcx
	leaq	32(%rsi),%rsi
	adoxq	-8(%rbx),%r13
	adcxq	%rbp,%r14
	adoxq	%rbp,%r14

	movq	%r8,%r15
	imulq	32+8(%rsp),%r8

	movq	%r8,%rdx
	xorq	%rbp,%rbp
	movq	%rdi,8+8(%rsp)

	mulxq	0(%rcx),%rax,%r10
	adcxq	%rax,%r15
	adoxq	%r11,%r10
	mulxq	8(%rcx),%rax,%r11
	adcxq	%rax,%r10
	adoxq	%r12,%r11
	mulxq	16(%rcx),%rax,%r12
	adcxq	%rax,%r11
	adoxq	%r13,%r12
	mulxq	24(%rcx),%rax,%r15
	movq	%r9,%rdx
	movq	24+8(%rsp),%rdi
	movq	%r10,-32(%rbx)
	adcxq	%rax,%r12
	movq	%r11,-24(%rbx)
	adoxq	%rbp,%r15
	movq	%r12,-16(%rbx)
	leaq	32(%rcx),%rcx
	jmp	.Lmulx4x_inner

.align	32
.Lmulx4x_inner:
	mulxq	0(%rsi),%r10,%rax
	adcxq	%rbp,%r15
	adoxq	%r14,%r10
	mulxq	8(%rsi),%r11,%r14
	adcxq	0(%rbx),%r10
	adoxq	%rax,%r11
	mulxq	16(%rsi),%r12,%rax
	adcxq	8(%rbx),%r11
	adoxq	%r14,%r12
	mulxq	24(%rsi),%r13,%r14
	movq	%r8,%rdx
	adcxq	16(%rbx),%r12
	adoxq	%rax,%r13
	adcxq	24(%rbx),%r13
	adoxq	%rbp,%r14
	leaq	32(%rsi),%rsi
	leaq	32(%rbx),%rbx
	adcxq	%rbp,%r14

	adoxq	%r15,%r10
	mulxq	0(%rcx),%rax,%r15
	adcxq	%rax,%r10
	adoxq	%r15,%r11
	mulxq	8(%rcx),%rax,%r15
	adcxq	%rax,%r11
	adoxq	%r15,%r12
	mulxq	16(%rcx),%rax,%r15
	movq	%r10,-40(%rbx)
	adcxq	%rax,%r12
	adoxq	%r15,%r13
	movq	%r11,-32(%rbx)
	mulxq	24(%rcx),%rax,%r15
	movq	%r9,%rdx
	leaq	32(%rcx),%rcx
	movq	%r12,-24(%rbx)
	adcxq	%rax,%r13
	adoxq	%rbp,%r15
	movq	%r13,-16(%rbx)

	decq	%rdi
	jnz	.Lmulx4x_inner

	movq	0+8(%rsp),%rax
	adcq	%rbp,%r15
	subq	0(%rbx),%rdi
	movq	8+8(%rsp),%rdi
	movq	16+8(%rsp),%r10
	adcq	%r15,%r14
	leaq	(%rsi,%rax,1),%rsi
	adcq	%rbp,%rbp
	movq	%r14,-8(%rbx)

	cmpq	%r10,%rdi
	jb	.Lmulx4x_outer

	movq	-8(%rcx),%r10
	movq	%rbp,%r8
	movq	(%rcx,%rax,1),%r12
	leaq	(%rcx,%rax,1),%rbp
	movq	%rax,%rcx
	leaq	(%rbx,%rax,1),%rdi
	xorl	%eax,%eax
	xorq	%r15,%r15
	subq	%r14,%r10
	adcq	%r15,%r15
	orq	%r15,%r8
	sarq	$3+2,%rcx
	subq	%r8,%rax
	movq	56+8(%rsp),%rdx
	decq	%r12
	movq	8(%rbp),%r13
	xorq	%r8,%r8
	movq	16(%rbp),%r14
	movq	24(%rbp),%r15
	jmp	.Lsqrx4x_sub_entry
.cfi_endproc	
.size	mulx4x_internal,.-mulx4x_internal
.type	bn_powerx5,@function
.align	32
bn_powerx5:
.cfi_startproc	
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
.Lpowerx5_enter:
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
.Lpowerx5_prologue:

	shll	$3,%r9d
	leaq	(%r9,%r9,2),%r10
	negq	%r9
	movq	(%r8),%r8








	leaq	-320(%rsp,%r9,2),%r11
	movq	%rsp,%rbp
	subq	%rdi,%r11
	andq	$4095,%r11
	cmpq	%r11,%r10
	jb	.Lpwrx_sp_alt
	subq	%r11,%rbp
	leaq	-320(%rbp,%r9,2),%rbp
	jmp	.Lpwrx_sp_done

.align	32
.Lpwrx_sp_alt:
	leaq	4096-320(,%r9,2),%r10
	leaq	-320(%rbp,%r9,2),%rbp
	subq	%r10,%r11
	movq	$0,%r10
	cmovcq	%r10,%r11
	subq	%r11,%rbp
.Lpwrx_sp_done:
	andq	$-64,%rbp
	movq	%rsp,%r11
	subq	%rbp,%r11
	andq	$-4096,%r11
	leaq	(%r11,%rbp,1),%rsp
	movq	(%rsp),%r10
	cmpq	%rbp,%rsp
	ja	.Lpwrx_page_walk
	jmp	.Lpwrx_page_walk_done

.Lpwrx_page_walk:
	leaq	-4096(%rsp),%rsp
	movq	(%rsp),%r10
	cmpq	%rbp,%rsp
	ja	.Lpwrx_page_walk
.Lpwrx_page_walk_done:

	movq	%r9,%r10
	negq	%r9












	pxor	%xmm0,%xmm0
.byte	102,72,15,110,207
.byte	102,72,15,110,209
.byte	102,73,15,110,218
.byte	102,72,15,110,226
	movq	%r8,32(%rsp)
	movq	%rax,40(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x28,0x06,0x23,0x08
.Lpowerx5_body:

	call	__bn_sqrx8x_internal
	call	__bn_postx4x_internal
	call	__bn_sqrx8x_internal
	call	__bn_postx4x_internal
	call	__bn_sqrx8x_internal
	call	__bn_postx4x_internal
	call	__bn_sqrx8x_internal
	call	__bn_postx4x_internal
	call	__bn_sqrx8x_internal
	call	__bn_postx4x_internal

	movq	%r10,%r9
	movq	%rsi,%rdi
.byte	102,72,15,126,209
.byte	102,72,15,126,226
	movq	40(%rsp),%rax

	call	mulx4x_internal

	movq	40(%rsp),%rsi
.cfi_def_cfa	%rsi,8
	movq	$1,%rax

	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lpowerx5_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	bn_powerx5,.-bn_powerx5

.globl	bn_sqrx8x_internal
.hidden	bn_sqrx8x_internal
.type	bn_sqrx8x_internal,@function
.align	32
bn_sqrx8x_internal:
__bn_sqrx8x_internal:
.cfi_startproc	








































	leaq	48+8(%rsp),%rdi
	leaq	(%rsi,%r9,1),%rbp
	movq	%r9,0+8(%rsp)
	movq	%rbp,8+8(%rsp)
	jmp	.Lsqr8x_zero_start

.align	32
.byte	0x66,0x66,0x66,0x2e,0x0f,0x1f,0x84,0x00,0x00,0x00,0x00,0x00
.Lsqrx8x_zero:
.byte	0x3e
	movdqa	%xmm0,0(%rdi)
	movdqa	%xmm0,16(%rdi)
	movdqa	%xmm0,32(%rdi)
	movdqa	%xmm0,48(%rdi)
.Lsqr8x_zero_start:
	movdqa	%xmm0,64(%rdi)
	movdqa	%xmm0,80(%rdi)
	movdqa	%xmm0,96(%rdi)
	movdqa	%xmm0,112(%rdi)
	leaq	128(%rdi),%rdi
	subq	$64,%r9
	jnz	.Lsqrx8x_zero

	movq	0(%rsi),%rdx

	xorq	%r10,%r10
	xorq	%r11,%r11
	xorq	%r12,%r12
	xorq	%r13,%r13
	xorq	%r14,%r14
	xorq	%r15,%r15
	leaq	48+8(%rsp),%rdi
	xorq	%rbp,%rbp
	jmp	.Lsqrx8x_outer_loop

.align	32
.Lsqrx8x_outer_loop:
	mulxq	8(%rsi),%r8,%rax
	adcxq	%r9,%r8
	adoxq	%rax,%r10
	mulxq	16(%rsi),%r9,%rax
	adcxq	%r10,%r9
	adoxq	%rax,%r11
.byte	0xc4,0xe2,0xab,0xf6,0x86,0x18,0x00,0x00,0x00
	adcxq	%r11,%r10
	adoxq	%rax,%r12
.byte	0xc4,0xe2,0xa3,0xf6,0x86,0x20,0x00,0x00,0x00
	adcxq	%r12,%r11
	adoxq	%rax,%r13
	mulxq	40(%rsi),%r12,%rax
	adcxq	%r13,%r12
	adoxq	%rax,%r14
	mulxq	48(%rsi),%r13,%rax
	adcxq	%r14,%r13
	adoxq	%r15,%rax
	mulxq	56(%rsi),%r14,%r15
	movq	8(%rsi),%rdx
	adcxq	%rax,%r14
	adoxq	%rbp,%r15
	adcq	64(%rdi),%r15
	movq	%r8,8(%rdi)
	movq	%r9,16(%rdi)
	sbbq	%rcx,%rcx
	xorq	%rbp,%rbp


	mulxq	16(%rsi),%r8,%rbx
	mulxq	24(%rsi),%r9,%rax
	adcxq	%r10,%r8
	adoxq	%rbx,%r9
	mulxq	32(%rsi),%r10,%rbx
	adcxq	%r11,%r9
	adoxq	%rax,%r10
.byte	0xc4,0xe2,0xa3,0xf6,0x86,0x28,0x00,0x00,0x00
	adcxq	%r12,%r10
	adoxq	%rbx,%r11
.byte	0xc4,0xe2,0x9b,0xf6,0x9e,0x30,0x00,0x00,0x00
	adcxq	%r13,%r11
	adoxq	%r14,%r12
.byte	0xc4,0x62,0x93,0xf6,0xb6,0x38,0x00,0x00,0x00
	movq	16(%rsi),%rdx
	adcxq	%rax,%r12
	adoxq	%rbx,%r13
	adcxq	%r15,%r13
	adoxq	%rbp,%r14
	adcxq	%rbp,%r14

	movq	%r8,24(%rdi)
	movq	%r9,32(%rdi)

	mulxq	24(%rsi),%r8,%rbx
	mulxq	32(%rsi),%r9,%rax
	adcxq	%r10,%r8
	adoxq	%rbx,%r9
	mulxq	40(%rsi),%r10,%rbx
	adcxq	%r11,%r9
	adoxq	%rax,%r10
.byte	0xc4,0xe2,0xa3,0xf6,0x86,0x30,0x00,0x00,0x00
	adcxq	%r12,%r10
	adoxq	%r13,%r11
.byte	0xc4,0x62,0x9b,0xf6,0xae,0x38,0x00,0x00,0x00
.byte	0x3e
	movq	24(%rsi),%rdx
	adcxq	%rbx,%r11
	adoxq	%rax,%r12
	adcxq	%r14,%r12
	movq	%r8,40(%rdi)
	movq	%r9,48(%rdi)
	mulxq	32(%rsi),%r8,%rax
	adoxq	%rbp,%r13
	adcxq	%rbp,%r13

	mulxq	40(%rsi),%r9,%rbx
	adcxq	%r10,%r8
	adoxq	%rax,%r9
	mulxq	48(%rsi),%r10,%rax
	adcxq	%r11,%r9
	adoxq	%r12,%r10
	mulxq	56(%rsi),%r11,%r12
	movq	32(%rsi),%rdx
	movq	40(%rsi),%r14
	adcxq	%rbx,%r10
	adoxq	%rax,%r11
	movq	48(%rsi),%r15
	adcxq	%r13,%r11
	adoxq	%rbp,%r12
	adcxq	%rbp,%r12

	movq	%r8,56(%rdi)
	movq	%r9,64(%rdi)

	mulxq	%r14,%r9,%rax
	movq	56(%rsi),%r8
	adcxq	%r10,%r9
	mulxq	%r15,%r10,%rbx
	adoxq	%rax,%r10
	adcxq	%r11,%r10
	mulxq	%r8,%r11,%rax
	movq	%r14,%rdx
	adoxq	%rbx,%r11
	adcxq	%r12,%r11

	adcxq	%rbp,%rax

	mulxq	%r15,%r14,%rbx
	mulxq	%r8,%r12,%r13
	movq	%r15,%rdx
	leaq	64(%rsi),%rsi
	adcxq	%r14,%r11
	adoxq	%rbx,%r12
	adcxq	%rax,%r12
	adoxq	%rbp,%r13

.byte	0x67,0x67
	mulxq	%r8,%r8,%r14
	adcxq	%r8,%r13
	adcxq	%rbp,%r14

	cmpq	8+8(%rsp),%rsi
	je	.Lsqrx8x_outer_break

	negq	%rcx
	movq	$-8,%rcx
	movq	%rbp,%r15
	movq	64(%rdi),%r8
	adcxq	72(%rdi),%r9
	adcxq	80(%rdi),%r10
	adcxq	88(%rdi),%r11
	adcq	96(%rdi),%r12
	adcq	104(%rdi),%r13
	adcq	112(%rdi),%r14
	adcq	120(%rdi),%r15
	leaq	(%rsi),%rbp
	leaq	128(%rdi),%rdi
	sbbq	%rax,%rax

	movq	-64(%rsi),%rdx
	movq	%rax,16+8(%rsp)
	movq	%rdi,24+8(%rsp)


	xorl	%eax,%eax
	jmp	.Lsqrx8x_loop

.align	32
.Lsqrx8x_loop:
	movq	%r8,%rbx
	mulxq	0(%rbp),%rax,%r8
	adcxq	%rax,%rbx
	adoxq	%r9,%r8

	mulxq	8(%rbp),%rax,%r9
	adcxq	%rax,%r8
	adoxq	%r10,%r9

	mulxq	16(%rbp),%rax,%r10
	adcxq	%rax,%r9
	adoxq	%r11,%r10

	mulxq	24(%rbp),%rax,%r11
	adcxq	%rax,%r10
	adoxq	%r12,%r11

.byte	0xc4,0x62,0xfb,0xf6,0xa5,0x20,0x00,0x00,0x00
	adcxq	%rax,%r11
	adoxq	%r13,%r12

	mulxq	40(%rbp),%rax,%r13
	adcxq	%rax,%r12
	adoxq	%r14,%r13

	mulxq	48(%rbp),%rax,%r14
	movq	%rbx,(%rdi,%rcx,8)
	movl	$0,%ebx
	adcxq	%rax,%r13
	adoxq	%r15,%r14

.byte	0xc4,0x62,0xfb,0xf6,0xbd,0x38,0x00,0x00,0x00
	movq	8(%rsi,%rcx,8),%rdx
	adcxq	%rax,%r14
	adoxq	%rbx,%r15
	adcxq	%rbx,%r15

.byte	0x67
	incq	%rcx
	jnz	.Lsqrx8x_loop

	leaq	64(%rbp),%rbp
	movq	$-8,%rcx
	cmpq	8+8(%rsp),%rbp
	je	.Lsqrx8x_break

	subq	16+8(%rsp),%rbx
.byte	0x66
	movq	-64(%rsi),%rdx
	adcxq	0(%rdi),%r8
	adcxq	8(%rdi),%r9
	adcq	16(%rdi),%r10
	adcq	24(%rdi),%r11
	adcq	32(%rdi),%r12
	adcq	40(%rdi),%r13
	adcq	48(%rdi),%r14
	adcq	56(%rdi),%r15
	leaq	64(%rdi),%rdi
.byte	0x67
	sbbq	%rax,%rax
	xorl	%ebx,%ebx
	movq	%rax,16+8(%rsp)
	jmp	.Lsqrx8x_loop

.align	32
.Lsqrx8x_break:
	xorq	%rbp,%rbp
	subq	16+8(%rsp),%rbx
	adcxq	%rbp,%r8
	movq	24+8(%rsp),%rcx
	adcxq	%rbp,%r9
	movq	0(%rsi),%rdx
	adcq	$0,%r10
	movq	%r8,0(%rdi)
	adcq	$0,%r11
	adcq	$0,%r12
	adcq	$0,%r13
	adcq	$0,%r14
	adcq	$0,%r15
	cmpq	%rcx,%rdi
	je	.Lsqrx8x_outer_loop

	movq	%r9,8(%rdi)
	movq	8(%rcx),%r9
	movq	%r10,16(%rdi)
	movq	16(%rcx),%r10
	movq	%r11,24(%rdi)
	movq	24(%rcx),%r11
	movq	%r12,32(%rdi)
	movq	32(%rcx),%r12
	movq	%r13,40(%rdi)
	movq	40(%rcx),%r13
	movq	%r14,48(%rdi)
	movq	48(%rcx),%r14
	movq	%r15,56(%rdi)
	movq	56(%rcx),%r15
	movq	%rcx,%rdi
	jmp	.Lsqrx8x_outer_loop

.align	32
.Lsqrx8x_outer_break:
	movq	%r9,72(%rdi)
.byte	102,72,15,126,217
	movq	%r10,80(%rdi)
	movq	%r11,88(%rdi)
	movq	%r12,96(%rdi)
	movq	%r13,104(%rdi)
	movq	%r14,112(%rdi)
	leaq	48+8(%rsp),%rdi
	movq	(%rsi,%rcx,1),%rdx

	movq	8(%rdi),%r11
	xorq	%r10,%r10
	movq	0+8(%rsp),%r9
	adoxq	%r11,%r11
	movq	16(%rdi),%r12
	movq	24(%rdi),%r13


.align	32
.Lsqrx4x_shift_n_add:
	mulxq	%rdx,%rax,%rbx
	adoxq	%r12,%r12
	adcxq	%r10,%rax
.byte	0x48,0x8b,0x94,0x0e,0x08,0x00,0x00,0x00
.byte	0x4c,0x8b,0x97,0x20,0x00,0x00,0x00
	adoxq	%r13,%r13
	adcxq	%r11,%rbx
	movq	40(%rdi),%r11
	movq	%rax,0(%rdi)
	movq	%rbx,8(%rdi)

	mulxq	%rdx,%rax,%rbx
	adoxq	%r10,%r10
	adcxq	%r12,%rax
	movq	16(%rsi,%rcx,1),%rdx
	movq	48(%rdi),%r12
	adoxq	%r11,%r11
	adcxq	%r13,%rbx
	movq	56(%rdi),%r13
	movq	%rax,16(%rdi)
	movq	%rbx,24(%rdi)

	mulxq	%rdx,%rax,%rbx
	adoxq	%r12,%r12
	adcxq	%r10,%rax
	movq	24(%rsi,%rcx,1),%rdx
	leaq	32(%rcx),%rcx
	movq	64(%rdi),%r10
	adoxq	%r13,%r13
	adcxq	%r11,%rbx
	movq	72(%rdi),%r11
	movq	%rax,32(%rdi)
	movq	%rbx,40(%rdi)

	mulxq	%rdx,%rax,%rbx
	adoxq	%r10,%r10
	adcxq	%r12,%rax
	jrcxz	.Lsqrx4x_shift_n_add_break
.byte	0x48,0x8b,0x94,0x0e,0x00,0x00,0x00,0x00
	adoxq	%r11,%r11
	adcxq	%r13,%rbx
	movq	80(%rdi),%r12
	movq	88(%rdi),%r13
	movq	%rax,48(%rdi)
	movq	%rbx,56(%rdi)
	leaq	64(%rdi),%rdi
	nop
	jmp	.Lsqrx4x_shift_n_add

.align	32
.Lsqrx4x_shift_n_add_break:
	adcxq	%r13,%rbx
	movq	%rax,48(%rdi)
	movq	%rbx,56(%rdi)
	leaq	64(%rdi),%rdi
.byte	102,72,15,126,213
__bn_sqrx8x_reduction:
	xorl	%eax,%eax
	movq	32+8(%rsp),%rbx
	movq	48+8(%rsp),%rdx
	leaq	-64(%rbp,%r9,1),%rcx

	movq	%rcx,0+8(%rsp)
	movq	%rdi,8+8(%rsp)

	leaq	48+8(%rsp),%rdi
	jmp	.Lsqrx8x_reduction_loop

.align	32
.Lsqrx8x_reduction_loop:
	movq	8(%rdi),%r9
	movq	16(%rdi),%r10
	movq	24(%rdi),%r11
	movq	32(%rdi),%r12
	movq	%rdx,%r8
	imulq	%rbx,%rdx
	movq	40(%rdi),%r13
	movq	48(%rdi),%r14
	movq	56(%rdi),%r15
	movq	%rax,24+8(%rsp)

	leaq	64(%rdi),%rdi
	xorq	%rsi,%rsi
	movq	$-8,%rcx
	jmp	.Lsqrx8x_reduce

.align	32
.Lsqrx8x_reduce:
	movq	%r8,%rbx
	mulxq	0(%rbp),%rax,%r8
	adcxq	%rbx,%rax
	adoxq	%r9,%r8

	mulxq	8(%rbp),%rbx,%r9
	adcxq	%rbx,%r8
	adoxq	%r10,%r9

	mulxq	16(%rbp),%rbx,%r10
	adcxq	%rbx,%r9
	adoxq	%r11,%r10

	mulxq	24(%rbp),%rbx,%r11
	adcxq	%rbx,%r10
	adoxq	%r12,%r11

.byte	0xc4,0x62,0xe3,0xf6,0xa5,0x20,0x00,0x00,0x00
	movq	%rdx,%rax
	movq	%r8,%rdx
	adcxq	%rbx,%r11
	adoxq	%r13,%r12

	mulxq	32+8(%rsp),%rbx,%rdx
	movq	%rax,%rdx
	movq	%rax,64+48+8(%rsp,%rcx,8)

	mulxq	40(%rbp),%rax,%r13
	adcxq	%rax,%r12
	adoxq	%r14,%r13

	mulxq	48(%rbp),%rax,%r14
	adcxq	%rax,%r13
	adoxq	%r15,%r14

	mulxq	56(%rbp),%rax,%r15
	movq	%rbx,%rdx
	adcxq	%rax,%r14
	adoxq	%rsi,%r15
	adcxq	%rsi,%r15

.byte	0x67,0x67,0x67
	incq	%rcx
	jnz	.Lsqrx8x_reduce

	movq	%rsi,%rax
	cmpq	0+8(%rsp),%rbp
	jae	.Lsqrx8x_no_tail

	movq	48+8(%rsp),%rdx
	addq	0(%rdi),%r8
	leaq	64(%rbp),%rbp
	movq	$-8,%rcx
	adcxq	8(%rdi),%r9
	adcxq	16(%rdi),%r10
	adcq	24(%rdi),%r11
	adcq	32(%rdi),%r12
	adcq	40(%rdi),%r13
	adcq	48(%rdi),%r14
	adcq	56(%rdi),%r15
	leaq	64(%rdi),%rdi
	sbbq	%rax,%rax

	xorq	%rsi,%rsi
	movq	%rax,16+8(%rsp)
	jmp	.Lsqrx8x_tail

.align	32
.Lsqrx8x_tail:
	movq	%r8,%rbx
	mulxq	0(%rbp),%rax,%r8
	adcxq	%rax,%rbx
	adoxq	%r9,%r8

	mulxq	8(%rbp),%rax,%r9
	adcxq	%rax,%r8
	adoxq	%r10,%r9

	mulxq	16(%rbp),%rax,%r10
	adcxq	%rax,%r9
	adoxq	%r11,%r10

	mulxq	24(%rbp),%rax,%r11
	adcxq	%rax,%r10
	adoxq	%r12,%r11

.byte	0xc4,0x62,0xfb,0xf6,0xa5,0x20,0x00,0x00,0x00
	adcxq	%rax,%r11
	adoxq	%r13,%r12

	mulxq	40(%rbp),%rax,%r13
	adcxq	%rax,%r12
	adoxq	%r14,%r13

	mulxq	48(%rbp),%rax,%r14
	adcxq	%rax,%r13
	adoxq	%r15,%r14

	mulxq	56(%rbp),%rax,%r15
	movq	72+48+8(%rsp,%rcx,8),%rdx
	adcxq	%rax,%r14
	adoxq	%rsi,%r15
	movq	%rbx,(%rdi,%rcx,8)
	movq	%r8,%rbx
	adcxq	%rsi,%r15

	incq	%rcx
	jnz	.Lsqrx8x_tail

	cmpq	0+8(%rsp),%rbp
	jae	.Lsqrx8x_tail_done

	subq	16+8(%rsp),%rsi
	movq	48+8(%rsp),%rdx
	leaq	64(%rbp),%rbp
	adcq	0(%rdi),%r8
	adcq	8(%rdi),%r9
	adcq	16(%rdi),%r10
	adcq	24(%rdi),%r11
	adcq	32(%rdi),%r12
	adcq	40(%rdi),%r13
	adcq	48(%rdi),%r14
	adcq	56(%rdi),%r15
	leaq	64(%rdi),%rdi
	sbbq	%rax,%rax
	subq	$8,%rcx

	xorq	%rsi,%rsi
	movq	%rax,16+8(%rsp)
	jmp	.Lsqrx8x_tail

.align	32
.Lsqrx8x_tail_done:
	xorq	%rax,%rax
	addq	24+8(%rsp),%r8
	adcq	$0,%r9
	adcq	$0,%r10
	adcq	$0,%r11
	adcq	$0,%r12
	adcq	$0,%r13
	adcq	$0,%r14
	adcq	$0,%r15
	adcq	$0,%rax

	subq	16+8(%rsp),%rsi
.Lsqrx8x_no_tail:
	adcq	0(%rdi),%r8
.byte	102,72,15,126,217
	adcq	8(%rdi),%r9
	movq	56(%rbp),%rsi
.byte	102,72,15,126,213
	adcq	16(%rdi),%r10
	adcq	24(%rdi),%r11
	adcq	32(%rdi),%r12
	adcq	40(%rdi),%r13
	adcq	48(%rdi),%r14
	adcq	56(%rdi),%r15
	adcq	$0,%rax

	movq	32+8(%rsp),%rbx
	movq	64(%rdi,%rcx,1),%rdx

	movq	%r8,0(%rdi)
	leaq	64(%rdi),%r8
	movq	%r9,8(%rdi)
	movq	%r10,16(%rdi)
	movq	%r11,24(%rdi)
	movq	%r12,32(%rdi)
	movq	%r13,40(%rdi)
	movq	%r14,48(%rdi)
	movq	%r15,56(%rdi)

	leaq	64(%rdi,%rcx,1),%rdi
	cmpq	8+8(%rsp),%r8
	jb	.Lsqrx8x_reduction_loop
	.byte	0xf3,0xc3
.cfi_endproc	
.size	bn_sqrx8x_internal,.-bn_sqrx8x_internal
.align	32
__bn_postx4x_internal:
.cfi_startproc	
	movq	0(%rbp),%r12
	movq	%rcx,%r10
	movq	%rcx,%r9
	negq	%rax
	sarq	$3+2,%rcx

.byte	102,72,15,126,202
.byte	102,72,15,126,206
	decq	%r12
	movq	8(%rbp),%r13
	xorq	%r8,%r8
	movq	16(%rbp),%r14
	movq	24(%rbp),%r15
	jmp	.Lsqrx4x_sub_entry

.align	16
.Lsqrx4x_sub:
	movq	0(%rbp),%r12
	movq	8(%rbp),%r13
	movq	16(%rbp),%r14
	movq	24(%rbp),%r15
.Lsqrx4x_sub_entry:
	andnq	%rax,%r12,%r12
	leaq	32(%rbp),%rbp
	andnq	%rax,%r13,%r13
	andnq	%rax,%r14,%r14
	andnq	%rax,%r15,%r15

	negq	%r8
	adcq	0(%rdi),%r12
	adcq	8(%rdi),%r13
	adcq	16(%rdi),%r14
	adcq	24(%rdi),%r15
	movq	%r12,0(%rdx)
	leaq	32(%rdi),%rdi
	movq	%r13,8(%rdx)
	sbbq	%r8,%r8
	movq	%r14,16(%rdx)
	movq	%r15,24(%rdx)
	leaq	32(%rdx),%rdx

	incq	%rcx
	jnz	.Lsqrx4x_sub

	negq	%r9

	.byte	0xf3,0xc3
.cfi_endproc	
.size	__bn_postx4x_internal,.-__bn_postx4x_internal
.globl	bn_get_bits5
.type	bn_get_bits5,@function
.align	16
bn_get_bits5:
.cfi_startproc	
	leaq	0(%rdi),%r10
	leaq	1(%rdi),%r11
	movl	%esi,%ecx
	shrl	$4,%esi
	andl	$15,%ecx
	leal	-8(%rcx),%eax
	cmpl	$11,%ecx
	cmovaq	%r11,%r10
	cmoval	%eax,%ecx
	movzwl	(%r10,%rsi,2),%eax
	shrl	%cl,%eax
	andl	$31,%eax
	.byte	0xf3,0xc3
.cfi_endproc	
.size	bn_get_bits5,.-bn_get_bits5

.globl	bn_scatter5
.type	bn_scatter5,@function
.align	16
bn_scatter5:
.cfi_startproc	
	cmpl	$0,%esi
	jz	.Lscatter_epilogue
	leaq	(%rdx,%rcx,8),%rdx
.Lscatter:
	movq	(%rdi),%rax
	leaq	8(%rdi),%rdi
	movq	%rax,(%rdx)
	leaq	256(%rdx),%rdx
	subl	$1,%esi
	jnz	.Lscatter
.Lscatter_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	bn_scatter5,.-bn_scatter5

.globl	bn_gather5
.type	bn_gather5,@function
.align	32
bn_gather5:
.LSEH_begin_bn_gather5:
.cfi_startproc	

.byte	0x4c,0x8d,0x14,0x24
.byte	0x48,0x81,0xec,0x08,0x01,0x00,0x00
	leaq	.Linc(%rip),%rax
	andq	$-16,%rsp

	movd	%ecx,%xmm5
	movdqa	0(%rax),%xmm0
	movdqa	16(%rax),%xmm1
	leaq	128(%rdx),%r11
	leaq	128(%rsp),%rax

	pshufd	$0,%xmm5,%xmm5
	movdqa	%xmm1,%xmm4
	movdqa	%xmm1,%xmm2
	paddd	%xmm0,%xmm1
	pcmpeqd	%xmm5,%xmm0
	movdqa	%xmm4,%xmm3

	paddd	%xmm1,%xmm2
	pcmpeqd	%xmm5,%xmm1
	movdqa	%xmm0,-128(%rax)
	movdqa	%xmm4,%xmm0

	paddd	%xmm2,%xmm3
	pcmpeqd	%xmm5,%xmm2
	movdqa	%xmm1,-112(%rax)
	movdqa	%xmm4,%xmm1

	paddd	%xmm3,%xmm0
	pcmpeqd	%xmm5,%xmm3
	movdqa	%xmm2,-96(%rax)
	movdqa	%xmm4,%xmm2
	paddd	%xmm0,%xmm1
	pcmpeqd	%xmm5,%xmm0
	movdqa	%xmm3,-80(%rax)
	movdqa	%xmm4,%xmm3

	paddd	%xmm1,%xmm2
	pcmpeqd	%xmm5,%xmm1
	movdqa	%xmm0,-64(%rax)
	movdqa	%xmm4,%xmm0

	paddd	%xmm2,%xmm3
	pcmpeqd	%xmm5,%xmm2
	movdqa	%xmm1,-48(%rax)
	movdqa	%xmm4,%xmm1

	paddd	%xmm3,%xmm0
	pcmpeqd	%xmm5,%xmm3
	movdqa	%xmm2,-32(%rax)
	movdqa	%xmm4,%xmm2
	paddd	%xmm0,%xmm1
	pcmpeqd	%xmm5,%xmm0
	movdqa	%xmm3,-16(%rax)
	movdqa	%xmm4,%xmm3

	paddd	%xmm1,%xmm2
	pcmpeqd	%xmm5,%xmm1
	movdqa	%xmm0,0(%rax)
	movdqa	%xmm4,%xmm0

	paddd	%xmm2,%xmm3
	pcmpeqd	%xmm5,%xmm2
	movdqa	%xmm1,16(%rax)
	movdqa	%xmm4,%xmm1

	paddd	%xmm3,%xmm0
	pcmpeqd	%xmm5,%xmm3
	movdqa	%xmm2,32(%rax)
	movdqa	%xmm4,%xmm2
	paddd	%xmm0,%xmm1
	pcmpeqd	%xmm5,%xmm0
	movdqa	%xmm3,48(%rax)
	movdqa	%xmm4,%xmm3

	paddd	%xmm1,%xmm2
	pcmpeqd	%xmm5,%xmm1
	movdqa	%xmm0,64(%rax)
	movdqa	%xmm4,%xmm0

	paddd	%xmm2,%xmm3
	pcmpeqd	%xmm5,%xmm2
	movdqa	%xmm1,80(%rax)
	movdqa	%xmm4,%xmm1

	paddd	%xmm3,%xmm0
	pcmpeqd	%xmm5,%xmm3
	movdqa	%xmm2,96(%rax)
	movdqa	%xmm4,%xmm2
	movdqa	%xmm3,112(%rax)
	jmp	.Lgather

.align	32
.Lgather:
	pxor	%xmm4,%xmm4
	pxor	%xmm5,%xmm5
	movdqa	-128(%r11),%xmm0
	movdqa	-112(%r11),%xmm1
	movdqa	-96(%r11),%xmm2
	pand	-128(%rax),%xmm0
	movdqa	-80(%r11),%xmm3
	pand	-112(%rax),%xmm1
	por	%xmm0,%xmm4
	pand	-96(%rax),%xmm2
	por	%xmm1,%xmm5
	pand	-80(%rax),%xmm3
	por	%xmm2,%xmm4
	por	%xmm3,%xmm5
	movdqa	-64(%r11),%xmm0
	movdqa	-48(%r11),%xmm1
	movdqa	-32(%r11),%xmm2
	pand	-64(%rax),%xmm0
	movdqa	-16(%r11),%xmm3
	pand	-48(%rax),%xmm1
	por	%xmm0,%xmm4
	pand	-32(%rax),%xmm2
	por	%xmm1,%xmm5
	pand	-16(%rax),%xmm3
	por	%xmm2,%xmm4
	por	%xmm3,%xmm5
	movdqa	0(%r11),%xmm0
	movdqa	16(%r11),%xmm1
	movdqa	32(%r11),%xmm2
	pand	0(%rax),%xmm0
	movdqa	48(%r11),%xmm3
	pand	16(%rax),%xmm1
	por	%xmm0,%xmm4
	pand	32(%rax),%xmm2
	por	%xmm1,%xmm5
	pand	48(%rax),%xmm3
	por	%xmm2,%xmm4
	por	%xmm3,%xmm5
	movdqa	64(%r11),%xmm0
	movdqa	80(%r11),%xmm1
	movdqa	96(%r11),%xmm2
	pand	64(%rax),%xmm0
	movdqa	112(%r11),%xmm3
	pand	80(%rax),%xmm1
	por	%xmm0,%xmm4
	pand	96(%rax),%xmm2
	por	%xmm1,%xmm5
	pand	112(%rax),%xmm3
	por	%xmm2,%xmm4
	por	%xmm3,%xmm5
	por	%xmm5,%xmm4
	leaq	256(%r11),%r11
	pshufd	$0x4e,%xmm4,%xmm0
	por	%xmm4,%xmm0
	movq	%xmm0,(%rdi)
	leaq	8(%rdi),%rdi
	subl	$1,%esi
	jnz	.Lgather

	leaq	(%r10),%rsp
	.byte	0xf3,0xc3
.LSEH_end_bn_gather5:
.cfi_endproc	
.size	bn_gather5,.-bn_gather5
.align	64
.Linc:
.long	0,0, 1,1
.long	2,2, 2,2
.byte	77,111,110,116,103,111,109,101,114,121,32,77,117,108,116,105,112,108,105,99,97,116,105,111,110,32,119,105,116,104,32,115,99,97,116,116,101,114,47,103,97,116,104,101,114,32,102,111,114,32,120,56,54,95,54,52,44,32,67,82,89,80,84,79,71,65,77,83,32,98,121,32,60,97,112,112,114,111,64,111,112,101,110,115,115,108,46,111,114,103,62,0
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                                                               node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/buildinf.h                            0000664 0000000 0000000 00000002476 14746647661 0025711 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /*
 * WARNING: do not edit!
 * Generated by util/mkbuildinf.pl
 *
 * Copyright 2014-2017 The OpenSSL Project Authors. All Rights Reserved.
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 */

#define PLATFORM "platform: linux-x86_64"
#define DATE "built on: Mon Sep 30 17:10:40 2024 UTC"

/*
 * Generate compiler_flags as an array of individual characters. This is a
 * workaround for the situation where CFLAGS gets too long for a C90 string
 * literal
 */
static const char compiler_flags[] = {
    'c','o','m','p','i','l','e','r',':',' ','g','c','c',' ','-','f',
    'P','I','C',' ','-','p','t','h','r','e','a','d',' ','-','m','6',
    '4',' ','-','W','a',',','-','-','n','o','e','x','e','c','s','t',
    'a','c','k',' ','-','W','a','l','l',' ','-','O','3',' ','-','D',
    'O','P','E','N','S','S','L','_','U','S','E','_','N','O','D','E',
    'L','E','T','E',' ','-','D','L','_','E','N','D','I','A','N',' ',
    '-','D','O','P','E','N','S','S','L','_','P','I','C',' ','-','D',
    'O','P','E','N','S','S','L','_','B','U','I','L','D','I','N','G',
    '_','O','P','E','N','S','S','L',' ','-','D','N','D','E','B','U',
    'G','\0'
};
                                                                                                                                                                                                  node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/camellia/                             0000775 0000000 0000000 00000000000 14746647661 0025502 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/camellia/cmll-x86_64.s                0000664 0000000 0000000 00000115607 14746647661 0027563 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	


.globl	Camellia_EncryptBlock
.type	Camellia_EncryptBlock,@function
.align	16
Camellia_EncryptBlock:
.cfi_startproc	
	movl	$128,%eax
	subl	%edi,%eax
	movl	$3,%edi
	adcl	$0,%edi
	jmp	.Lenc_rounds
.cfi_endproc	
.size	Camellia_EncryptBlock,.-Camellia_EncryptBlock

.globl	Camellia_EncryptBlock_Rounds
.type	Camellia_EncryptBlock_Rounds,@function
.align	16
.Lenc_rounds:
Camellia_EncryptBlock_Rounds:
.cfi_startproc	
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-24
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-32
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-40
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-48
.Lenc_prologue:


	movq	%rcx,%r13
	movq	%rdx,%r14

	shll	$6,%edi
	leaq	.LCamellia_SBOX(%rip),%rbp
	leaq	(%r14,%rdi,1),%r15

	movl	0(%rsi),%r8d
	movl	4(%rsi),%r9d
	movl	8(%rsi),%r10d
	bswapl	%r8d
	movl	12(%rsi),%r11d
	bswapl	%r9d
	bswapl	%r10d
	bswapl	%r11d

	call	_x86_64_Camellia_encrypt

	bswapl	%r8d
	bswapl	%r9d
	bswapl	%r10d
	movl	%r8d,0(%r13)
	bswapl	%r11d
	movl	%r9d,4(%r13)
	movl	%r10d,8(%r13)
	movl	%r11d,12(%r13)

	movq	0(%rsp),%r15
.cfi_restore	%r15
	movq	8(%rsp),%r14
.cfi_restore	%r14
	movq	16(%rsp),%r13
.cfi_restore	%r13
	movq	24(%rsp),%rbp
.cfi_restore	%rbp
	movq	32(%rsp),%rbx
.cfi_restore	%rbx
	leaq	40(%rsp),%rsp
.cfi_adjust_cfa_offset	-40
.Lenc_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	Camellia_EncryptBlock_Rounds,.-Camellia_EncryptBlock_Rounds

.type	_x86_64_Camellia_encrypt,@function
.align	16
_x86_64_Camellia_encrypt:
.cfi_startproc	
	xorl	0(%r14),%r9d
	xorl	4(%r14),%r8d
	xorl	8(%r14),%r11d
	xorl	12(%r14),%r10d
.align	16
.Leloop:
	movl	16(%r14),%ebx
	movl	20(%r14),%eax

	xorl	%r8d,%eax
	xorl	%r9d,%ebx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	movl	2052(%rbp,%rsi,8),%edx
	movl	0(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	shrl	$16,%eax
	movzbl	%bh,%edi
	xorl	4(%rbp,%rsi,8),%edx
	shrl	$16,%ebx
	xorl	4(%rbp,%rdi,8),%ecx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	xorl	0(%rbp,%rsi,8),%edx
	xorl	2052(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	movzbl	%bh,%edi
	xorl	2048(%rbp,%rsi,8),%edx
	xorl	2048(%rbp,%rdi,8),%ecx
	movl	24(%r14),%ebx
	movl	28(%r14),%eax
	xorl	%edx,%ecx
	rorl	$8,%edx
	xorl	%ecx,%r10d
	xorl	%ecx,%r11d
	xorl	%edx,%r11d
	xorl	%r10d,%eax
	xorl	%r11d,%ebx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	movl	2052(%rbp,%rsi,8),%edx
	movl	0(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	shrl	$16,%eax
	movzbl	%bh,%edi
	xorl	4(%rbp,%rsi,8),%edx
	shrl	$16,%ebx
	xorl	4(%rbp,%rdi,8),%ecx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	xorl	0(%rbp,%rsi,8),%edx
	xorl	2052(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	movzbl	%bh,%edi
	xorl	2048(%rbp,%rsi,8),%edx
	xorl	2048(%rbp,%rdi,8),%ecx
	movl	32(%r14),%ebx
	movl	36(%r14),%eax
	xorl	%edx,%ecx
	rorl	$8,%edx
	xorl	%ecx,%r8d
	xorl	%ecx,%r9d
	xorl	%edx,%r9d
	xorl	%r8d,%eax
	xorl	%r9d,%ebx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	movl	2052(%rbp,%rsi,8),%edx
	movl	0(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	shrl	$16,%eax
	movzbl	%bh,%edi
	xorl	4(%rbp,%rsi,8),%edx
	shrl	$16,%ebx
	xorl	4(%rbp,%rdi,8),%ecx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	xorl	0(%rbp,%rsi,8),%edx
	xorl	2052(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	movzbl	%bh,%edi
	xorl	2048(%rbp,%rsi,8),%edx
	xorl	2048(%rbp,%rdi,8),%ecx
	movl	40(%r14),%ebx
	movl	44(%r14),%eax
	xorl	%edx,%ecx
	rorl	$8,%edx
	xorl	%ecx,%r10d
	xorl	%ecx,%r11d
	xorl	%edx,%r11d
	xorl	%r10d,%eax
	xorl	%r11d,%ebx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	movl	2052(%rbp,%rsi,8),%edx
	movl	0(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	shrl	$16,%eax
	movzbl	%bh,%edi
	xorl	4(%rbp,%rsi,8),%edx
	shrl	$16,%ebx
	xorl	4(%rbp,%rdi,8),%ecx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	xorl	0(%rbp,%rsi,8),%edx
	xorl	2052(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	movzbl	%bh,%edi
	xorl	2048(%rbp,%rsi,8),%edx
	xorl	2048(%rbp,%rdi,8),%ecx
	movl	48(%r14),%ebx
	movl	52(%r14),%eax
	xorl	%edx,%ecx
	rorl	$8,%edx
	xorl	%ecx,%r8d
	xorl	%ecx,%r9d
	xorl	%edx,%r9d
	xorl	%r8d,%eax
	xorl	%r9d,%ebx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	movl	2052(%rbp,%rsi,8),%edx
	movl	0(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	shrl	$16,%eax
	movzbl	%bh,%edi
	xorl	4(%rbp,%rsi,8),%edx
	shrl	$16,%ebx
	xorl	4(%rbp,%rdi,8),%ecx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	xorl	0(%rbp,%rsi,8),%edx
	xorl	2052(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	movzbl	%bh,%edi
	xorl	2048(%rbp,%rsi,8),%edx
	xorl	2048(%rbp,%rdi,8),%ecx
	movl	56(%r14),%ebx
	movl	60(%r14),%eax
	xorl	%edx,%ecx
	rorl	$8,%edx
	xorl	%ecx,%r10d
	xorl	%ecx,%r11d
	xorl	%edx,%r11d
	xorl	%r10d,%eax
	xorl	%r11d,%ebx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	movl	2052(%rbp,%rsi,8),%edx
	movl	0(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	shrl	$16,%eax
	movzbl	%bh,%edi
	xorl	4(%rbp,%rsi,8),%edx
	shrl	$16,%ebx
	xorl	4(%rbp,%rdi,8),%ecx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	xorl	0(%rbp,%rsi,8),%edx
	xorl	2052(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	movzbl	%bh,%edi
	xorl	2048(%rbp,%rsi,8),%edx
	xorl	2048(%rbp,%rdi,8),%ecx
	movl	64(%r14),%ebx
	movl	68(%r14),%eax
	xorl	%edx,%ecx
	rorl	$8,%edx
	xorl	%ecx,%r8d
	xorl	%ecx,%r9d
	xorl	%edx,%r9d
	leaq	64(%r14),%r14
	cmpq	%r15,%r14
	movl	8(%r14),%edx
	movl	12(%r14),%ecx
	je	.Ledone

	andl	%r8d,%eax
	orl	%r11d,%edx
	roll	$1,%eax
	xorl	%edx,%r10d
	xorl	%eax,%r9d
	andl	%r10d,%ecx
	orl	%r9d,%ebx
	roll	$1,%ecx
	xorl	%ebx,%r8d
	xorl	%ecx,%r11d
	jmp	.Leloop

.align	16
.Ledone:
	xorl	%r10d,%eax
	xorl	%r11d,%ebx
	xorl	%r8d,%ecx
	xorl	%r9d,%edx

	movl	%eax,%r8d
	movl	%ebx,%r9d
	movl	%ecx,%r10d
	movl	%edx,%r11d

.byte	0xf3,0xc3
.cfi_endproc	
.size	_x86_64_Camellia_encrypt,.-_x86_64_Camellia_encrypt


.globl	Camellia_DecryptBlock
.type	Camellia_DecryptBlock,@function
.align	16
Camellia_DecryptBlock:
.cfi_startproc	
	movl	$128,%eax
	subl	%edi,%eax
	movl	$3,%edi
	adcl	$0,%edi
	jmp	.Ldec_rounds
.cfi_endproc	
.size	Camellia_DecryptBlock,.-Camellia_DecryptBlock

.globl	Camellia_DecryptBlock_Rounds
.type	Camellia_DecryptBlock_Rounds,@function
.align	16
.Ldec_rounds:
Camellia_DecryptBlock_Rounds:
.cfi_startproc	
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-24
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-32
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-40
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-48
.Ldec_prologue:


	movq	%rcx,%r13
	movq	%rdx,%r15

	shll	$6,%edi
	leaq	.LCamellia_SBOX(%rip),%rbp
	leaq	(%r15,%rdi,1),%r14

	movl	0(%rsi),%r8d
	movl	4(%rsi),%r9d
	movl	8(%rsi),%r10d
	bswapl	%r8d
	movl	12(%rsi),%r11d
	bswapl	%r9d
	bswapl	%r10d
	bswapl	%r11d

	call	_x86_64_Camellia_decrypt

	bswapl	%r8d
	bswapl	%r9d
	bswapl	%r10d
	movl	%r8d,0(%r13)
	bswapl	%r11d
	movl	%r9d,4(%r13)
	movl	%r10d,8(%r13)
	movl	%r11d,12(%r13)

	movq	0(%rsp),%r15
.cfi_restore	%r15
	movq	8(%rsp),%r14
.cfi_restore	%r14
	movq	16(%rsp),%r13
.cfi_restore	%r13
	movq	24(%rsp),%rbp
.cfi_restore	%rbp
	movq	32(%rsp),%rbx
.cfi_restore	%rbx
	leaq	40(%rsp),%rsp
.cfi_adjust_cfa_offset	-40
.Ldec_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	Camellia_DecryptBlock_Rounds,.-Camellia_DecryptBlock_Rounds

.type	_x86_64_Camellia_decrypt,@function
.align	16
_x86_64_Camellia_decrypt:
.cfi_startproc	
	xorl	0(%r14),%r9d
	xorl	4(%r14),%r8d
	xorl	8(%r14),%r11d
	xorl	12(%r14),%r10d
.align	16
.Ldloop:
	movl	-8(%r14),%ebx
	movl	-4(%r14),%eax

	xorl	%r8d,%eax
	xorl	%r9d,%ebx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	movl	2052(%rbp,%rsi,8),%edx
	movl	0(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	shrl	$16,%eax
	movzbl	%bh,%edi
	xorl	4(%rbp,%rsi,8),%edx
	shrl	$16,%ebx
	xorl	4(%rbp,%rdi,8),%ecx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	xorl	0(%rbp,%rsi,8),%edx
	xorl	2052(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	movzbl	%bh,%edi
	xorl	2048(%rbp,%rsi,8),%edx
	xorl	2048(%rbp,%rdi,8),%ecx
	movl	-16(%r14),%ebx
	movl	-12(%r14),%eax
	xorl	%edx,%ecx
	rorl	$8,%edx
	xorl	%ecx,%r10d
	xorl	%ecx,%r11d
	xorl	%edx,%r11d
	xorl	%r10d,%eax
	xorl	%r11d,%ebx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	movl	2052(%rbp,%rsi,8),%edx
	movl	0(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	shrl	$16,%eax
	movzbl	%bh,%edi
	xorl	4(%rbp,%rsi,8),%edx
	shrl	$16,%ebx
	xorl	4(%rbp,%rdi,8),%ecx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	xorl	0(%rbp,%rsi,8),%edx
	xorl	2052(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	movzbl	%bh,%edi
	xorl	2048(%rbp,%rsi,8),%edx
	xorl	2048(%rbp,%rdi,8),%ecx
	movl	-24(%r14),%ebx
	movl	-20(%r14),%eax
	xorl	%edx,%ecx
	rorl	$8,%edx
	xorl	%ecx,%r8d
	xorl	%ecx,%r9d
	xorl	%edx,%r9d
	xorl	%r8d,%eax
	xorl	%r9d,%ebx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	movl	2052(%rbp,%rsi,8),%edx
	movl	0(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	shrl	$16,%eax
	movzbl	%bh,%edi
	xorl	4(%rbp,%rsi,8),%edx
	shrl	$16,%ebx
	xorl	4(%rbp,%rdi,8),%ecx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	xorl	0(%rbp,%rsi,8),%edx
	xorl	2052(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	movzbl	%bh,%edi
	xorl	2048(%rbp,%rsi,8),%edx
	xorl	2048(%rbp,%rdi,8),%ecx
	movl	-32(%r14),%ebx
	movl	-28(%r14),%eax
	xorl	%edx,%ecx
	rorl	$8,%edx
	xorl	%ecx,%r10d
	xorl	%ecx,%r11d
	xorl	%edx,%r11d
	xorl	%r10d,%eax
	xorl	%r11d,%ebx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	movl	2052(%rbp,%rsi,8),%edx
	movl	0(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	shrl	$16,%eax
	movzbl	%bh,%edi
	xorl	4(%rbp,%rsi,8),%edx
	shrl	$16,%ebx
	xorl	4(%rbp,%rdi,8),%ecx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	xorl	0(%rbp,%rsi,8),%edx
	xorl	2052(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	movzbl	%bh,%edi
	xorl	2048(%rbp,%rsi,8),%edx
	xorl	2048(%rbp,%rdi,8),%ecx
	movl	-40(%r14),%ebx
	movl	-36(%r14),%eax
	xorl	%edx,%ecx
	rorl	$8,%edx
	xorl	%ecx,%r8d
	xorl	%ecx,%r9d
	xorl	%edx,%r9d
	xorl	%r8d,%eax
	xorl	%r9d,%ebx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	movl	2052(%rbp,%rsi,8),%edx
	movl	0(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	shrl	$16,%eax
	movzbl	%bh,%edi
	xorl	4(%rbp,%rsi,8),%edx
	shrl	$16,%ebx
	xorl	4(%rbp,%rdi,8),%ecx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	xorl	0(%rbp,%rsi,8),%edx
	xorl	2052(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	movzbl	%bh,%edi
	xorl	2048(%rbp,%rsi,8),%edx
	xorl	2048(%rbp,%rdi,8),%ecx
	movl	-48(%r14),%ebx
	movl	-44(%r14),%eax
	xorl	%edx,%ecx
	rorl	$8,%edx
	xorl	%ecx,%r10d
	xorl	%ecx,%r11d
	xorl	%edx,%r11d
	xorl	%r10d,%eax
	xorl	%r11d,%ebx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	movl	2052(%rbp,%rsi,8),%edx
	movl	0(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	shrl	$16,%eax
	movzbl	%bh,%edi
	xorl	4(%rbp,%rsi,8),%edx
	shrl	$16,%ebx
	xorl	4(%rbp,%rdi,8),%ecx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	xorl	0(%rbp,%rsi,8),%edx
	xorl	2052(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	movzbl	%bh,%edi
	xorl	2048(%rbp,%rsi,8),%edx
	xorl	2048(%rbp,%rdi,8),%ecx
	movl	-56(%r14),%ebx
	movl	-52(%r14),%eax
	xorl	%edx,%ecx
	rorl	$8,%edx
	xorl	%ecx,%r8d
	xorl	%ecx,%r9d
	xorl	%edx,%r9d
	leaq	-64(%r14),%r14
	cmpq	%r15,%r14
	movl	0(%r14),%edx
	movl	4(%r14),%ecx
	je	.Lddone

	andl	%r8d,%eax
	orl	%r11d,%edx
	roll	$1,%eax
	xorl	%edx,%r10d
	xorl	%eax,%r9d
	andl	%r10d,%ecx
	orl	%r9d,%ebx
	roll	$1,%ecx
	xorl	%ebx,%r8d
	xorl	%ecx,%r11d

	jmp	.Ldloop

.align	16
.Lddone:
	xorl	%r10d,%ecx
	xorl	%r11d,%edx
	xorl	%r8d,%eax
	xorl	%r9d,%ebx

	movl	%ecx,%r8d
	movl	%edx,%r9d
	movl	%eax,%r10d
	movl	%ebx,%r11d

.byte	0xf3,0xc3
.cfi_endproc	
.size	_x86_64_Camellia_decrypt,.-_x86_64_Camellia_decrypt
.globl	Camellia_Ekeygen
.type	Camellia_Ekeygen,@function
.align	16
Camellia_Ekeygen:
.cfi_startproc	
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-24
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-32
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-40
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-48
.Lkey_prologue:

	movl	%edi,%r15d
	movq	%rdx,%r13

	movl	0(%rsi),%r8d
	movl	4(%rsi),%r9d
	movl	8(%rsi),%r10d
	movl	12(%rsi),%r11d

	bswapl	%r8d
	bswapl	%r9d
	bswapl	%r10d
	bswapl	%r11d
	movl	%r9d,0(%r13)
	movl	%r8d,4(%r13)
	movl	%r11d,8(%r13)
	movl	%r10d,12(%r13)
	cmpq	$128,%r15
	je	.L1st128

	movl	16(%rsi),%r8d
	movl	20(%rsi),%r9d
	cmpq	$192,%r15
	je	.L1st192
	movl	24(%rsi),%r10d
	movl	28(%rsi),%r11d
	jmp	.L1st256
.L1st192:
	movl	%r8d,%r10d
	movl	%r9d,%r11d
	notl	%r10d
	notl	%r11d
.L1st256:
	bswapl	%r8d
	bswapl	%r9d
	bswapl	%r10d
	bswapl	%r11d
	movl	%r9d,32(%r13)
	movl	%r8d,36(%r13)
	movl	%r11d,40(%r13)
	movl	%r10d,44(%r13)
	xorl	0(%r13),%r9d
	xorl	4(%r13),%r8d
	xorl	8(%r13),%r11d
	xorl	12(%r13),%r10d

.L1st128:
	leaq	.LCamellia_SIGMA(%rip),%r14
	leaq	.LCamellia_SBOX(%rip),%rbp

	movl	0(%r14),%ebx
	movl	4(%r14),%eax
	xorl	%r8d,%eax
	xorl	%r9d,%ebx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	movl	2052(%rbp,%rsi,8),%edx
	movl	0(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	shrl	$16,%eax
	movzbl	%bh,%edi
	xorl	4(%rbp,%rsi,8),%edx
	shrl	$16,%ebx
	xorl	4(%rbp,%rdi,8),%ecx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	xorl	0(%rbp,%rsi,8),%edx
	xorl	2052(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	movzbl	%bh,%edi
	xorl	2048(%rbp,%rsi,8),%edx
	xorl	2048(%rbp,%rdi,8),%ecx
	movl	8(%r14),%ebx
	movl	12(%r14),%eax
	xorl	%edx,%ecx
	rorl	$8,%edx
	xorl	%ecx,%r10d
	xorl	%ecx,%r11d
	xorl	%edx,%r11d
	xorl	%r10d,%eax
	xorl	%r11d,%ebx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	movl	2052(%rbp,%rsi,8),%edx
	movl	0(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	shrl	$16,%eax
	movzbl	%bh,%edi
	xorl	4(%rbp,%rsi,8),%edx
	shrl	$16,%ebx
	xorl	4(%rbp,%rdi,8),%ecx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	xorl	0(%rbp,%rsi,8),%edx
	xorl	2052(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	movzbl	%bh,%edi
	xorl	2048(%rbp,%rsi,8),%edx
	xorl	2048(%rbp,%rdi,8),%ecx
	movl	16(%r14),%ebx
	movl	20(%r14),%eax
	xorl	%edx,%ecx
	rorl	$8,%edx
	xorl	%ecx,%r8d
	xorl	%ecx,%r9d
	xorl	%edx,%r9d
	xorl	0(%r13),%r9d
	xorl	4(%r13),%r8d
	xorl	8(%r13),%r11d
	xorl	12(%r13),%r10d
	xorl	%r8d,%eax
	xorl	%r9d,%ebx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	movl	2052(%rbp,%rsi,8),%edx
	movl	0(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	shrl	$16,%eax
	movzbl	%bh,%edi
	xorl	4(%rbp,%rsi,8),%edx
	shrl	$16,%ebx
	xorl	4(%rbp,%rdi,8),%ecx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	xorl	0(%rbp,%rsi,8),%edx
	xorl	2052(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	movzbl	%bh,%edi
	xorl	2048(%rbp,%rsi,8),%edx
	xorl	2048(%rbp,%rdi,8),%ecx
	movl	24(%r14),%ebx
	movl	28(%r14),%eax
	xorl	%edx,%ecx
	rorl	$8,%edx
	xorl	%ecx,%r10d
	xorl	%ecx,%r11d
	xorl	%edx,%r11d
	xorl	%r10d,%eax
	xorl	%r11d,%ebx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	movl	2052(%rbp,%rsi,8),%edx
	movl	0(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	shrl	$16,%eax
	movzbl	%bh,%edi
	xorl	4(%rbp,%rsi,8),%edx
	shrl	$16,%ebx
	xorl	4(%rbp,%rdi,8),%ecx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	xorl	0(%rbp,%rsi,8),%edx
	xorl	2052(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	movzbl	%bh,%edi
	xorl	2048(%rbp,%rsi,8),%edx
	xorl	2048(%rbp,%rdi,8),%ecx
	movl	32(%r14),%ebx
	movl	36(%r14),%eax
	xorl	%edx,%ecx
	rorl	$8,%edx
	xorl	%ecx,%r8d
	xorl	%ecx,%r9d
	xorl	%edx,%r9d
	cmpq	$128,%r15
	jne	.L2nd256

	leaq	128(%r13),%r13
	shlq	$32,%r8
	shlq	$32,%r10
	orq	%r9,%r8
	orq	%r11,%r10
	movq	-128(%r13),%rax
	movq	-120(%r13),%rbx
	movq	%r8,-112(%r13)
	movq	%r10,-104(%r13)
	movq	%rax,%r11
	shlq	$15,%rax
	movq	%rbx,%r9
	shrq	$49,%r9
	shrq	$49,%r11
	orq	%r9,%rax
	shlq	$15,%rbx
	orq	%r11,%rbx
	movq	%rax,-96(%r13)
	movq	%rbx,-88(%r13)
	movq	%r8,%r11
	shlq	$15,%r8
	movq	%r10,%r9
	shrq	$49,%r9
	shrq	$49,%r11
	orq	%r9,%r8
	shlq	$15,%r10
	orq	%r11,%r10
	movq	%r8,-80(%r13)
	movq	%r10,-72(%r13)
	movq	%r8,%r11
	shlq	$15,%r8
	movq	%r10,%r9
	shrq	$49,%r9
	shrq	$49,%r11
	orq	%r9,%r8
	shlq	$15,%r10
	orq	%r11,%r10
	movq	%r8,-64(%r13)
	movq	%r10,-56(%r13)
	movq	%rax,%r11
	shlq	$30,%rax
	movq	%rbx,%r9
	shrq	$34,%r9
	shrq	$34,%r11
	orq	%r9,%rax
	shlq	$30,%rbx
	orq	%r11,%rbx
	movq	%rax,-48(%r13)
	movq	%rbx,-40(%r13)
	movq	%r8,%r11
	shlq	$15,%r8
	movq	%r10,%r9
	shrq	$49,%r9
	shrq	$49,%r11
	orq	%r9,%r8
	shlq	$15,%r10
	orq	%r11,%r10
	movq	%r8,-32(%r13)
	movq	%rax,%r11
	shlq	$15,%rax
	movq	%rbx,%r9
	shrq	$49,%r9
	shrq	$49,%r11
	orq	%r9,%rax
	shlq	$15,%rbx
	orq	%r11,%rbx
	movq	%rbx,-24(%r13)
	movq	%r8,%r11
	shlq	$15,%r8
	movq	%r10,%r9
	shrq	$49,%r9
	shrq	$49,%r11
	orq	%r9,%r8
	shlq	$15,%r10
	orq	%r11,%r10
	movq	%r8,-16(%r13)
	movq	%r10,-8(%r13)
	movq	%rax,%r11
	shlq	$17,%rax
	movq	%rbx,%r9
	shrq	$47,%r9
	shrq	$47,%r11
	orq	%r9,%rax
	shlq	$17,%rbx
	orq	%r11,%rbx
	movq	%rax,0(%r13)
	movq	%rbx,8(%r13)
	movq	%rax,%r11
	shlq	$17,%rax
	movq	%rbx,%r9
	shrq	$47,%r9
	shrq	$47,%r11
	orq	%r9,%rax
	shlq	$17,%rbx
	orq	%r11,%rbx
	movq	%rax,16(%r13)
	movq	%rbx,24(%r13)
	movq	%r8,%r11
	shlq	$34,%r8
	movq	%r10,%r9
	shrq	$30,%r9
	shrq	$30,%r11
	orq	%r9,%r8
	shlq	$34,%r10
	orq	%r11,%r10
	movq	%r8,32(%r13)
	movq	%r10,40(%r13)
	movq	%rax,%r11
	shlq	$17,%rax
	movq	%rbx,%r9
	shrq	$47,%r9
	shrq	$47,%r11
	orq	%r9,%rax
	shlq	$17,%rbx
	orq	%r11,%rbx
	movq	%rax,48(%r13)
	movq	%rbx,56(%r13)
	movq	%r8,%r11
	shlq	$17,%r8
	movq	%r10,%r9
	shrq	$47,%r9
	shrq	$47,%r11
	orq	%r9,%r8
	shlq	$17,%r10
	orq	%r11,%r10
	movq	%r8,64(%r13)
	movq	%r10,72(%r13)
	movl	$3,%eax
	jmp	.Ldone
.align	16
.L2nd256:
	movl	%r9d,48(%r13)
	movl	%r8d,52(%r13)
	movl	%r11d,56(%r13)
	movl	%r10d,60(%r13)
	xorl	32(%r13),%r9d
	xorl	36(%r13),%r8d
	xorl	40(%r13),%r11d
	xorl	44(%r13),%r10d
	xorl	%r8d,%eax
	xorl	%r9d,%ebx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	movl	2052(%rbp,%rsi,8),%edx
	movl	0(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	shrl	$16,%eax
	movzbl	%bh,%edi
	xorl	4(%rbp,%rsi,8),%edx
	shrl	$16,%ebx
	xorl	4(%rbp,%rdi,8),%ecx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	xorl	0(%rbp,%rsi,8),%edx
	xorl	2052(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	movzbl	%bh,%edi
	xorl	2048(%rbp,%rsi,8),%edx
	xorl	2048(%rbp,%rdi,8),%ecx
	movl	40(%r14),%ebx
	movl	44(%r14),%eax
	xorl	%edx,%ecx
	rorl	$8,%edx
	xorl	%ecx,%r10d
	xorl	%ecx,%r11d
	xorl	%edx,%r11d
	xorl	%r10d,%eax
	xorl	%r11d,%ebx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	movl	2052(%rbp,%rsi,8),%edx
	movl	0(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	shrl	$16,%eax
	movzbl	%bh,%edi
	xorl	4(%rbp,%rsi,8),%edx
	shrl	$16,%ebx
	xorl	4(%rbp,%rdi,8),%ecx
	movzbl	%ah,%esi
	movzbl	%bl,%edi
	xorl	0(%rbp,%rsi,8),%edx
	xorl	2052(%rbp,%rdi,8),%ecx
	movzbl	%al,%esi
	movzbl	%bh,%edi
	xorl	2048(%rbp,%rsi,8),%edx
	xorl	2048(%rbp,%rdi,8),%ecx
	movl	48(%r14),%ebx
	movl	52(%r14),%eax
	xorl	%edx,%ecx
	rorl	$8,%edx
	xorl	%ecx,%r8d
	xorl	%ecx,%r9d
	xorl	%edx,%r9d
	movq	0(%r13),%rax
	movq	8(%r13),%rbx
	movq	32(%r13),%rcx
	movq	40(%r13),%rdx
	movq	48(%r13),%r14
	movq	56(%r13),%r15
	leaq	128(%r13),%r13
	shlq	$32,%r8
	shlq	$32,%r10
	orq	%r9,%r8
	orq	%r11,%r10
	movq	%r8,-112(%r13)
	movq	%r10,-104(%r13)
	movq	%rcx,%r11
	shlq	$15,%rcx
	movq	%rdx,%r9
	shrq	$49,%r9
	shrq	$49,%r11
	orq	%r9,%rcx
	shlq	$15,%rdx
	orq	%r11,%rdx
	movq	%rcx,-96(%r13)
	movq	%rdx,-88(%r13)
	movq	%r14,%r11
	shlq	$15,%r14
	movq	%r15,%r9
	shrq	$49,%r9
	shrq	$49,%r11
	orq	%r9,%r14
	shlq	$15,%r15
	orq	%r11,%r15
	movq	%r14,-80(%r13)
	movq	%r15,-72(%r13)
	movq	%rcx,%r11
	shlq	$15,%rcx
	movq	%rdx,%r9
	shrq	$49,%r9
	shrq	$49,%r11
	orq	%r9,%rcx
	shlq	$15,%rdx
	orq	%r11,%rdx
	movq	%rcx,-64(%r13)
	movq	%rdx,-56(%r13)
	movq	%r8,%r11
	shlq	$30,%r8
	movq	%r10,%r9
	shrq	$34,%r9
	shrq	$34,%r11
	orq	%r9,%r8
	shlq	$30,%r10
	orq	%r11,%r10
	movq	%r8,-48(%r13)
	movq	%r10,-40(%r13)
	movq	%rax,%r11
	shlq	$45,%rax
	movq	%rbx,%r9
	shrq	$19,%r9
	shrq	$19,%r11
	orq	%r9,%rax
	shlq	$45,%rbx
	orq	%r11,%rbx
	movq	%rax,-32(%r13)
	movq	%rbx,-24(%r13)
	movq	%r14,%r11
	shlq	$30,%r14
	movq	%r15,%r9
	shrq	$34,%r9
	shrq	$34,%r11
	orq	%r9,%r14
	shlq	$30,%r15
	orq	%r11,%r15
	movq	%r14,-16(%r13)
	movq	%r15,-8(%r13)
	movq	%rax,%r11
	shlq	$15,%rax
	movq	%rbx,%r9
	shrq	$49,%r9
	shrq	$49,%r11
	orq	%r9,%rax
	shlq	$15,%rbx
	orq	%r11,%rbx
	movq	%rax,0(%r13)
	movq	%rbx,8(%r13)
	movq	%rcx,%r11
	shlq	$30,%rcx
	movq	%rdx,%r9
	shrq	$34,%r9
	shrq	$34,%r11
	orq	%r9,%rcx
	shlq	$30,%rdx
	orq	%r11,%rdx
	movq	%rcx,16(%r13)
	movq	%rdx,24(%r13)
	movq	%r8,%r11
	shlq	$30,%r8
	movq	%r10,%r9
	shrq	$34,%r9
	shrq	$34,%r11
	orq	%r9,%r8
	shlq	$30,%r10
	orq	%r11,%r10
	movq	%r8,32(%r13)
	movq	%r10,40(%r13)
	movq	%rax,%r11
	shlq	$17,%rax
	movq	%rbx,%r9
	shrq	$47,%r9
	shrq	$47,%r11
	orq	%r9,%rax
	shlq	$17,%rbx
	orq	%r11,%rbx
	movq	%rax,48(%r13)
	movq	%rbx,56(%r13)
	movq	%r14,%r11
	shlq	$32,%r14
	movq	%r15,%r9
	shrq	$32,%r9
	shrq	$32,%r11
	orq	%r9,%r14
	shlq	$32,%r15
	orq	%r11,%r15
	movq	%r14,64(%r13)
	movq	%r15,72(%r13)
	movq	%rcx,%r11
	shlq	$34,%rcx
	movq	%rdx,%r9
	shrq	$30,%r9
	shrq	$30,%r11
	orq	%r9,%rcx
	shlq	$34,%rdx
	orq	%r11,%rdx
	movq	%rcx,80(%r13)
	movq	%rdx,88(%r13)
	movq	%r14,%r11
	shlq	$17,%r14
	movq	%r15,%r9
	shrq	$47,%r9
	shrq	$47,%r11
	orq	%r9,%r14
	shlq	$17,%r15
	orq	%r11,%r15
	movq	%r14,96(%r13)
	movq	%r15,104(%r13)
	movq	%rax,%r11
	shlq	$34,%rax
	movq	%rbx,%r9
	shrq	$30,%r9
	shrq	$30,%r11
	orq	%r9,%rax
	shlq	$34,%rbx
	orq	%r11,%rbx
	movq	%rax,112(%r13)
	movq	%rbx,120(%r13)
	movq	%r8,%r11
	shlq	$51,%r8
	movq	%r10,%r9
	shrq	$13,%r9
	shrq	$13,%r11
	orq	%r9,%r8
	shlq	$51,%r10
	orq	%r11,%r10
	movq	%r8,128(%r13)
	movq	%r10,136(%r13)
	movl	$4,%eax
.Ldone:
	movq	0(%rsp),%r15
.cfi_restore	%r15
	movq	8(%rsp),%r14
.cfi_restore	%r14
	movq	16(%rsp),%r13
.cfi_restore	%r13
	movq	24(%rsp),%rbp
.cfi_restore	%rbp
	movq	32(%rsp),%rbx
.cfi_restore	%rbx
	leaq	40(%rsp),%rsp
.cfi_adjust_cfa_offset	-40
.Lkey_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	Camellia_Ekeygen,.-Camellia_Ekeygen
.align	64
.LCamellia_SIGMA:
.long	0x3bcc908b, 0xa09e667f, 0x4caa73b2, 0xb67ae858
.long	0xe94f82be, 0xc6ef372f, 0xf1d36f1c, 0x54ff53a5
.long	0xde682d1d, 0x10e527fa, 0xb3e6c1fd, 0xb05688c2
.long	0,          0,          0,          0
.LCamellia_SBOX:
.long	0x70707000,0x70700070
.long	0x82828200,0x2c2c002c
.long	0x2c2c2c00,0xb3b300b3
.long	0xececec00,0xc0c000c0
.long	0xb3b3b300,0xe4e400e4
.long	0x27272700,0x57570057
.long	0xc0c0c000,0xeaea00ea
.long	0xe5e5e500,0xaeae00ae
.long	0xe4e4e400,0x23230023
.long	0x85858500,0x6b6b006b
.long	0x57575700,0x45450045
.long	0x35353500,0xa5a500a5
.long	0xeaeaea00,0xeded00ed
.long	0x0c0c0c00,0x4f4f004f
.long	0xaeaeae00,0x1d1d001d
.long	0x41414100,0x92920092
.long	0x23232300,0x86860086
.long	0xefefef00,0xafaf00af
.long	0x6b6b6b00,0x7c7c007c
.long	0x93939300,0x1f1f001f
.long	0x45454500,0x3e3e003e
.long	0x19191900,0xdcdc00dc
.long	0xa5a5a500,0x5e5e005e
.long	0x21212100,0x0b0b000b
.long	0xededed00,0xa6a600a6
.long	0x0e0e0e00,0x39390039
.long	0x4f4f4f00,0xd5d500d5
.long	0x4e4e4e00,0x5d5d005d
.long	0x1d1d1d00,0xd9d900d9
.long	0x65656500,0x5a5a005a
.long	0x92929200,0x51510051
.long	0xbdbdbd00,0x6c6c006c
.long	0x86868600,0x8b8b008b
.long	0xb8b8b800,0x9a9a009a
.long	0xafafaf00,0xfbfb00fb
.long	0x8f8f8f00,0xb0b000b0
.long	0x7c7c7c00,0x74740074
.long	0xebebeb00,0x2b2b002b
.long	0x1f1f1f00,0xf0f000f0
.long	0xcecece00,0x84840084
.long	0x3e3e3e00,0xdfdf00df
.long	0x30303000,0xcbcb00cb
.long	0xdcdcdc00,0x34340034
.long	0x5f5f5f00,0x76760076
.long	0x5e5e5e00,0x6d6d006d
.long	0xc5c5c500,0xa9a900a9
.long	0x0b0b0b00,0xd1d100d1
.long	0x1a1a1a00,0x04040004
.long	0xa6a6a600,0x14140014
.long	0xe1e1e100,0x3a3a003a
.long	0x39393900,0xdede00de
.long	0xcacaca00,0x11110011
.long	0xd5d5d500,0x32320032
.long	0x47474700,0x9c9c009c
.long	0x5d5d5d00,0x53530053
.long	0x3d3d3d00,0xf2f200f2
.long	0xd9d9d900,0xfefe00fe
.long	0x01010100,0xcfcf00cf
.long	0x5a5a5a00,0xc3c300c3
.long	0xd6d6d600,0x7a7a007a
.long	0x51515100,0x24240024
.long	0x56565600,0xe8e800e8
.long	0x6c6c6c00,0x60600060
.long	0x4d4d4d00,0x69690069
.long	0x8b8b8b00,0xaaaa00aa
.long	0x0d0d0d00,0xa0a000a0
.long	0x9a9a9a00,0xa1a100a1
.long	0x66666600,0x62620062
.long	0xfbfbfb00,0x54540054
.long	0xcccccc00,0x1e1e001e
.long	0xb0b0b000,0xe0e000e0
.long	0x2d2d2d00,0x64640064
.long	0x74747400,0x10100010
.long	0x12121200,0x00000000
.long	0x2b2b2b00,0xa3a300a3
.long	0x20202000,0x75750075
.long	0xf0f0f000,0x8a8a008a
.long	0xb1b1b100,0xe6e600e6
.long	0x84848400,0x09090009
.long	0x99999900,0xdddd00dd
.long	0xdfdfdf00,0x87870087
.long	0x4c4c4c00,0x83830083
.long	0xcbcbcb00,0xcdcd00cd
.long	0xc2c2c200,0x90900090
.long	0x34343400,0x73730073
.long	0x7e7e7e00,0xf6f600f6
.long	0x76767600,0x9d9d009d
.long	0x05050500,0xbfbf00bf
.long	0x6d6d6d00,0x52520052
.long	0xb7b7b700,0xd8d800d8
.long	0xa9a9a900,0xc8c800c8
.long	0x31313100,0xc6c600c6
.long	0xd1d1d100,0x81810081
.long	0x17171700,0x6f6f006f
.long	0x04040400,0x13130013
.long	0xd7d7d700,0x63630063
.long	0x14141400,0xe9e900e9
.long	0x58585800,0xa7a700a7
.long	0x3a3a3a00,0x9f9f009f
.long	0x61616100,0xbcbc00bc
.long	0xdedede00,0x29290029
.long	0x1b1b1b00,0xf9f900f9
.long	0x11111100,0x2f2f002f
.long	0x1c1c1c00,0xb4b400b4
.long	0x32323200,0x78780078
.long	0x0f0f0f00,0x06060006
.long	0x9c9c9c00,0xe7e700e7
.long	0x16161600,0x71710071
.long	0x53535300,0xd4d400d4
.long	0x18181800,0xabab00ab
.long	0xf2f2f200,0x88880088
.long	0x22222200,0x8d8d008d
.long	0xfefefe00,0x72720072
.long	0x44444400,0xb9b900b9
.long	0xcfcfcf00,0xf8f800f8
.long	0xb2b2b200,0xacac00ac
.long	0xc3c3c300,0x36360036
.long	0xb5b5b500,0x2a2a002a
.long	0x7a7a7a00,0x3c3c003c
.long	0x91919100,0xf1f100f1
.long	0x24242400,0x40400040
.long	0x08080800,0xd3d300d3
.long	0xe8e8e800,0xbbbb00bb
.long	0xa8a8a800,0x43430043
.long	0x60606000,0x15150015
.long	0xfcfcfc00,0xadad00ad
.long	0x69696900,0x77770077
.long	0x50505000,0x80800080
.long	0xaaaaaa00,0x82820082
.long	0xd0d0d000,0xecec00ec
.long	0xa0a0a000,0x27270027
.long	0x7d7d7d00,0xe5e500e5
.long	0xa1a1a100,0x85850085
.long	0x89898900,0x35350035
.long	0x62626200,0x0c0c000c
.long	0x97979700,0x41410041
.long	0x54545400,0xefef00ef
.long	0x5b5b5b00,0x93930093
.long	0x1e1e1e00,0x19190019
.long	0x95959500,0x21210021
.long	0xe0e0e000,0x0e0e000e
.long	0xffffff00,0x4e4e004e
.long	0x64646400,0x65650065
.long	0xd2d2d200,0xbdbd00bd
.long	0x10101000,0xb8b800b8
.long	0xc4c4c400,0x8f8f008f
.long	0x00000000,0xebeb00eb
.long	0x48484800,0xcece00ce
.long	0xa3a3a300,0x30300030
.long	0xf7f7f700,0x5f5f005f
.long	0x75757500,0xc5c500c5
.long	0xdbdbdb00,0x1a1a001a
.long	0x8a8a8a00,0xe1e100e1
.long	0x03030300,0xcaca00ca
.long	0xe6e6e600,0x47470047
.long	0xdadada00,0x3d3d003d
.long	0x09090900,0x01010001
.long	0x3f3f3f00,0xd6d600d6
.long	0xdddddd00,0x56560056
.long	0x94949400,0x4d4d004d
.long	0x87878700,0x0d0d000d
.long	0x5c5c5c00,0x66660066
.long	0x83838300,0xcccc00cc
.long	0x02020200,0x2d2d002d
.long	0xcdcdcd00,0x12120012
.long	0x4a4a4a00,0x20200020
.long	0x90909000,0xb1b100b1
.long	0x33333300,0x99990099
.long	0x73737300,0x4c4c004c
.long	0x67676700,0xc2c200c2
.long	0xf6f6f600,0x7e7e007e
.long	0xf3f3f300,0x05050005
.long	0x9d9d9d00,0xb7b700b7
.long	0x7f7f7f00,0x31310031
.long	0xbfbfbf00,0x17170017
.long	0xe2e2e200,0xd7d700d7
.long	0x52525200,0x58580058
.long	0x9b9b9b00,0x61610061
.long	0xd8d8d800,0x1b1b001b
.long	0x26262600,0x1c1c001c
.long	0xc8c8c800,0x0f0f000f
.long	0x37373700,0x16160016
.long	0xc6c6c600,0x18180018
.long	0x3b3b3b00,0x22220022
.long	0x81818100,0x44440044
.long	0x96969600,0xb2b200b2
.long	0x6f6f6f00,0xb5b500b5
.long	0x4b4b4b00,0x91910091
.long	0x13131300,0x08080008
.long	0xbebebe00,0xa8a800a8
.long	0x63636300,0xfcfc00fc
.long	0x2e2e2e00,0x50500050
.long	0xe9e9e900,0xd0d000d0
.long	0x79797900,0x7d7d007d
.long	0xa7a7a700,0x89890089
.long	0x8c8c8c00,0x97970097
.long	0x9f9f9f00,0x5b5b005b
.long	0x6e6e6e00,0x95950095
.long	0xbcbcbc00,0xffff00ff
.long	0x8e8e8e00,0xd2d200d2
.long	0x29292900,0xc4c400c4
.long	0xf5f5f500,0x48480048
.long	0xf9f9f900,0xf7f700f7
.long	0xb6b6b600,0xdbdb00db
.long	0x2f2f2f00,0x03030003
.long	0xfdfdfd00,0xdada00da
.long	0xb4b4b400,0x3f3f003f
.long	0x59595900,0x94940094
.long	0x78787800,0x5c5c005c
.long	0x98989800,0x02020002
.long	0x06060600,0x4a4a004a
.long	0x6a6a6a00,0x33330033
.long	0xe7e7e700,0x67670067
.long	0x46464600,0xf3f300f3
.long	0x71717100,0x7f7f007f
.long	0xbababa00,0xe2e200e2
.long	0xd4d4d400,0x9b9b009b
.long	0x25252500,0x26260026
.long	0xababab00,0x37370037
.long	0x42424200,0x3b3b003b
.long	0x88888800,0x96960096
.long	0xa2a2a200,0x4b4b004b
.long	0x8d8d8d00,0xbebe00be
.long	0xfafafa00,0x2e2e002e
.long	0x72727200,0x79790079
.long	0x07070700,0x8c8c008c
.long	0xb9b9b900,0x6e6e006e
.long	0x55555500,0x8e8e008e
.long	0xf8f8f800,0xf5f500f5
.long	0xeeeeee00,0xb6b600b6
.long	0xacacac00,0xfdfd00fd
.long	0x0a0a0a00,0x59590059
.long	0x36363600,0x98980098
.long	0x49494900,0x6a6a006a
.long	0x2a2a2a00,0x46460046
.long	0x68686800,0xbaba00ba
.long	0x3c3c3c00,0x25250025
.long	0x38383800,0x42420042
.long	0xf1f1f100,0xa2a200a2
.long	0xa4a4a400,0xfafa00fa
.long	0x40404000,0x07070007
.long	0x28282800,0x55550055
.long	0xd3d3d300,0xeeee00ee
.long	0x7b7b7b00,0x0a0a000a
.long	0xbbbbbb00,0x49490049
.long	0xc9c9c900,0x68680068
.long	0x43434300,0x38380038
.long	0xc1c1c100,0xa4a400a4
.long	0x15151500,0x28280028
.long	0xe3e3e300,0x7b7b007b
.long	0xadadad00,0xc9c900c9
.long	0xf4f4f400,0xc1c100c1
.long	0x77777700,0xe3e300e3
.long	0xc7c7c700,0xf4f400f4
.long	0x80808000,0xc7c700c7
.long	0x9e9e9e00,0x9e9e009e
.long	0x00e0e0e0,0x38003838
.long	0x00050505,0x41004141
.long	0x00585858,0x16001616
.long	0x00d9d9d9,0x76007676
.long	0x00676767,0xd900d9d9
.long	0x004e4e4e,0x93009393
.long	0x00818181,0x60006060
.long	0x00cbcbcb,0xf200f2f2
.long	0x00c9c9c9,0x72007272
.long	0x000b0b0b,0xc200c2c2
.long	0x00aeaeae,0xab00abab
.long	0x006a6a6a,0x9a009a9a
.long	0x00d5d5d5,0x75007575
.long	0x00181818,0x06000606
.long	0x005d5d5d,0x57005757
.long	0x00828282,0xa000a0a0
.long	0x00464646,0x91009191
.long	0x00dfdfdf,0xf700f7f7
.long	0x00d6d6d6,0xb500b5b5
.long	0x00272727,0xc900c9c9
.long	0x008a8a8a,0xa200a2a2
.long	0x00323232,0x8c008c8c
.long	0x004b4b4b,0xd200d2d2
.long	0x00424242,0x90009090
.long	0x00dbdbdb,0xf600f6f6
.long	0x001c1c1c,0x07000707
.long	0x009e9e9e,0xa700a7a7
.long	0x009c9c9c,0x27002727
.long	0x003a3a3a,0x8e008e8e
.long	0x00cacaca,0xb200b2b2
.long	0x00252525,0x49004949
.long	0x007b7b7b,0xde00dede
.long	0x000d0d0d,0x43004343
.long	0x00717171,0x5c005c5c
.long	0x005f5f5f,0xd700d7d7
.long	0x001f1f1f,0xc700c7c7
.long	0x00f8f8f8,0x3e003e3e
.long	0x00d7d7d7,0xf500f5f5
.long	0x003e3e3e,0x8f008f8f
.long	0x009d9d9d,0x67006767
.long	0x007c7c7c,0x1f001f1f
.long	0x00606060,0x18001818
.long	0x00b9b9b9,0x6e006e6e
.long	0x00bebebe,0xaf00afaf
.long	0x00bcbcbc,0x2f002f2f
.long	0x008b8b8b,0xe200e2e2
.long	0x00161616,0x85008585
.long	0x00343434,0x0d000d0d
.long	0x004d4d4d,0x53005353
.long	0x00c3c3c3,0xf000f0f0
.long	0x00727272,0x9c009c9c
.long	0x00959595,0x65006565
.long	0x00ababab,0xea00eaea
.long	0x008e8e8e,0xa300a3a3
.long	0x00bababa,0xae00aeae
.long	0x007a7a7a,0x9e009e9e
.long	0x00b3b3b3,0xec00ecec
.long	0x00020202,0x80008080
.long	0x00b4b4b4,0x2d002d2d
.long	0x00adadad,0x6b006b6b
.long	0x00a2a2a2,0xa800a8a8
.long	0x00acacac,0x2b002b2b
.long	0x00d8d8d8,0x36003636
.long	0x009a9a9a,0xa600a6a6
.long	0x00171717,0xc500c5c5
.long	0x001a1a1a,0x86008686
.long	0x00353535,0x4d004d4d
.long	0x00cccccc,0x33003333
.long	0x00f7f7f7,0xfd00fdfd
.long	0x00999999,0x66006666
.long	0x00616161,0x58005858
.long	0x005a5a5a,0x96009696
.long	0x00e8e8e8,0x3a003a3a
.long	0x00242424,0x09000909
.long	0x00565656,0x95009595
.long	0x00404040,0x10001010
.long	0x00e1e1e1,0x78007878
.long	0x00636363,0xd800d8d8
.long	0x00090909,0x42004242
.long	0x00333333,0xcc00cccc
.long	0x00bfbfbf,0xef00efef
.long	0x00989898,0x26002626
.long	0x00979797,0xe500e5e5
.long	0x00858585,0x61006161
.long	0x00686868,0x1a001a1a
.long	0x00fcfcfc,0x3f003f3f
.long	0x00ececec,0x3b003b3b
.long	0x000a0a0a,0x82008282
.long	0x00dadada,0xb600b6b6
.long	0x006f6f6f,0xdb00dbdb
.long	0x00535353,0xd400d4d4
.long	0x00626262,0x98009898
.long	0x00a3a3a3,0xe800e8e8
.long	0x002e2e2e,0x8b008b8b
.long	0x00080808,0x02000202
.long	0x00afafaf,0xeb00ebeb
.long	0x00282828,0x0a000a0a
.long	0x00b0b0b0,0x2c002c2c
.long	0x00747474,0x1d001d1d
.long	0x00c2c2c2,0xb000b0b0
.long	0x00bdbdbd,0x6f006f6f
.long	0x00363636,0x8d008d8d
.long	0x00222222,0x88008888
.long	0x00383838,0x0e000e0e
.long	0x00646464,0x19001919
.long	0x001e1e1e,0x87008787
.long	0x00393939,0x4e004e4e
.long	0x002c2c2c,0x0b000b0b
.long	0x00a6a6a6,0xa900a9a9
.long	0x00303030,0x0c000c0c
.long	0x00e5e5e5,0x79007979
.long	0x00444444,0x11001111
.long	0x00fdfdfd,0x7f007f7f
.long	0x00888888,0x22002222
.long	0x009f9f9f,0xe700e7e7
.long	0x00656565,0x59005959
.long	0x00878787,0xe100e1e1
.long	0x006b6b6b,0xda00dada
.long	0x00f4f4f4,0x3d003d3d
.long	0x00232323,0xc800c8c8
.long	0x00484848,0x12001212
.long	0x00101010,0x04000404
.long	0x00d1d1d1,0x74007474
.long	0x00515151,0x54005454
.long	0x00c0c0c0,0x30003030
.long	0x00f9f9f9,0x7e007e7e
.long	0x00d2d2d2,0xb400b4b4
.long	0x00a0a0a0,0x28002828
.long	0x00555555,0x55005555
.long	0x00a1a1a1,0x68006868
.long	0x00414141,0x50005050
.long	0x00fafafa,0xbe00bebe
.long	0x00434343,0xd000d0d0
.long	0x00131313,0xc400c4c4
.long	0x00c4c4c4,0x31003131
.long	0x002f2f2f,0xcb00cbcb
.long	0x00a8a8a8,0x2a002a2a
.long	0x00b6b6b6,0xad00adad
.long	0x003c3c3c,0x0f000f0f
.long	0x002b2b2b,0xca00caca
.long	0x00c1c1c1,0x70007070
.long	0x00ffffff,0xff00ffff
.long	0x00c8c8c8,0x32003232
.long	0x00a5a5a5,0x69006969
.long	0x00202020,0x08000808
.long	0x00898989,0x62006262
.long	0x00000000,0x00000000
.long	0x00909090,0x24002424
.long	0x00474747,0xd100d1d1
.long	0x00efefef,0xfb00fbfb
.long	0x00eaeaea,0xba00baba
.long	0x00b7b7b7,0xed00eded
.long	0x00151515,0x45004545
.long	0x00060606,0x81008181
.long	0x00cdcdcd,0x73007373
.long	0x00b5b5b5,0x6d006d6d
.long	0x00121212,0x84008484
.long	0x007e7e7e,0x9f009f9f
.long	0x00bbbbbb,0xee00eeee
.long	0x00292929,0x4a004a4a
.long	0x000f0f0f,0xc300c3c3
.long	0x00b8b8b8,0x2e002e2e
.long	0x00070707,0xc100c1c1
.long	0x00040404,0x01000101
.long	0x009b9b9b,0xe600e6e6
.long	0x00949494,0x25002525
.long	0x00212121,0x48004848
.long	0x00666666,0x99009999
.long	0x00e6e6e6,0xb900b9b9
.long	0x00cecece,0xb300b3b3
.long	0x00ededed,0x7b007b7b
.long	0x00e7e7e7,0xf900f9f9
.long	0x003b3b3b,0xce00cece
.long	0x00fefefe,0xbf00bfbf
.long	0x007f7f7f,0xdf00dfdf
.long	0x00c5c5c5,0x71007171
.long	0x00a4a4a4,0x29002929
.long	0x00373737,0xcd00cdcd
.long	0x00b1b1b1,0x6c006c6c
.long	0x004c4c4c,0x13001313
.long	0x00919191,0x64006464
.long	0x006e6e6e,0x9b009b9b
.long	0x008d8d8d,0x63006363
.long	0x00767676,0x9d009d9d
.long	0x00030303,0xc000c0c0
.long	0x002d2d2d,0x4b004b4b
.long	0x00dedede,0xb700b7b7
.long	0x00969696,0xa500a5a5
.long	0x00262626,0x89008989
.long	0x007d7d7d,0x5f005f5f
.long	0x00c6c6c6,0xb100b1b1
.long	0x005c5c5c,0x17001717
.long	0x00d3d3d3,0xf400f4f4
.long	0x00f2f2f2,0xbc00bcbc
.long	0x004f4f4f,0xd300d3d3
.long	0x00191919,0x46004646
.long	0x003f3f3f,0xcf00cfcf
.long	0x00dcdcdc,0x37003737
.long	0x00797979,0x5e005e5e
.long	0x001d1d1d,0x47004747
.long	0x00525252,0x94009494
.long	0x00ebebeb,0xfa00fafa
.long	0x00f3f3f3,0xfc00fcfc
.long	0x006d6d6d,0x5b005b5b
.long	0x005e5e5e,0x97009797
.long	0x00fbfbfb,0xfe00fefe
.long	0x00696969,0x5a005a5a
.long	0x00b2b2b2,0xac00acac
.long	0x00f0f0f0,0x3c003c3c
.long	0x00313131,0x4c004c4c
.long	0x000c0c0c,0x03000303
.long	0x00d4d4d4,0x35003535
.long	0x00cfcfcf,0xf300f3f3
.long	0x008c8c8c,0x23002323
.long	0x00e2e2e2,0xb800b8b8
.long	0x00757575,0x5d005d5d
.long	0x00a9a9a9,0x6a006a6a
.long	0x004a4a4a,0x92009292
.long	0x00575757,0xd500d5d5
.long	0x00848484,0x21002121
.long	0x00111111,0x44004444
.long	0x00454545,0x51005151
.long	0x001b1b1b,0xc600c6c6
.long	0x00f5f5f5,0x7d007d7d
.long	0x00e4e4e4,0x39003939
.long	0x000e0e0e,0x83008383
.long	0x00737373,0xdc00dcdc
.long	0x00aaaaaa,0xaa00aaaa
.long	0x00f1f1f1,0x7c007c7c
.long	0x00dddddd,0x77007777
.long	0x00595959,0x56005656
.long	0x00141414,0x05000505
.long	0x006c6c6c,0x1b001b1b
.long	0x00929292,0xa400a4a4
.long	0x00545454,0x15001515
.long	0x00d0d0d0,0x34003434
.long	0x00787878,0x1e001e1e
.long	0x00707070,0x1c001c1c
.long	0x00e3e3e3,0xf800f8f8
.long	0x00494949,0x52005252
.long	0x00808080,0x20002020
.long	0x00505050,0x14001414
.long	0x00a7a7a7,0xe900e9e9
.long	0x00f6f6f6,0xbd00bdbd
.long	0x00777777,0xdd00dddd
.long	0x00939393,0xe400e4e4
.long	0x00868686,0xa100a1a1
.long	0x00838383,0xe000e0e0
.long	0x002a2a2a,0x8a008a8a
.long	0x00c7c7c7,0xf100f1f1
.long	0x005b5b5b,0xd600d6d6
.long	0x00e9e9e9,0x7a007a7a
.long	0x00eeeeee,0xbb00bbbb
.long	0x008f8f8f,0xe300e3e3
.long	0x00010101,0x40004040
.long	0x003d3d3d,0x4f004f4f
.globl	Camellia_cbc_encrypt
.type	Camellia_cbc_encrypt,@function
.align	16
Camellia_cbc_encrypt:
.cfi_startproc	
.byte	243,15,30,250
	cmpq	$0,%rdx
	je	.Lcbc_abort
	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-56
.Lcbc_prologue:

	movq	%rsp,%rbp
.cfi_def_cfa_register	%rbp
	subq	$64,%rsp
	andq	$-64,%rsp



	leaq	-64-63(%rcx),%r10
	subq	%rsp,%r10
	negq	%r10
	andq	$0x3C0,%r10
	subq	%r10,%rsp


	movq	%rdi,%r12
	movq	%rsi,%r13
	movq	%r8,%rbx
	movq	%rcx,%r14
	movl	272(%rcx),%r15d

	movq	%r8,40(%rsp)
	movq	%rbp,48(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x30,0x06,0x23,0x38

.Lcbc_body:
	leaq	.LCamellia_SBOX(%rip),%rbp

	movl	$32,%ecx
.align	4
.Lcbc_prefetch_sbox:
	movq	0(%rbp),%rax
	movq	32(%rbp),%rsi
	movq	64(%rbp),%rdi
	movq	96(%rbp),%r11
	leaq	128(%rbp),%rbp
	loop	.Lcbc_prefetch_sbox
	subq	$4096,%rbp
	shlq	$6,%r15
	movq	%rdx,%rcx
	leaq	(%r14,%r15,1),%r15

	cmpl	$0,%r9d
	je	.LCBC_DECRYPT

	andq	$-16,%rdx
	andq	$15,%rcx
	leaq	(%r12,%rdx,1),%rdx
	movq	%r14,0(%rsp)
	movq	%rdx,8(%rsp)
	movq	%rcx,16(%rsp)

	cmpq	%r12,%rdx
	movl	0(%rbx),%r8d
	movl	4(%rbx),%r9d
	movl	8(%rbx),%r10d
	movl	12(%rbx),%r11d
	je	.Lcbc_enc_tail
	jmp	.Lcbc_eloop

.align	16
.Lcbc_eloop:
	xorl	0(%r12),%r8d
	xorl	4(%r12),%r9d
	xorl	8(%r12),%r10d
	bswapl	%r8d
	xorl	12(%r12),%r11d
	bswapl	%r9d
	bswapl	%r10d
	bswapl	%r11d

	call	_x86_64_Camellia_encrypt

	movq	0(%rsp),%r14
	bswapl	%r8d
	movq	8(%rsp),%rdx
	bswapl	%r9d
	movq	16(%rsp),%rcx
	bswapl	%r10d
	movl	%r8d,0(%r13)
	bswapl	%r11d
	movl	%r9d,4(%r13)
	movl	%r10d,8(%r13)
	leaq	16(%r12),%r12
	movl	%r11d,12(%r13)
	cmpq	%rdx,%r12
	leaq	16(%r13),%r13
	jne	.Lcbc_eloop

	cmpq	$0,%rcx
	jne	.Lcbc_enc_tail

	movq	40(%rsp),%r13
	movl	%r8d,0(%r13)
	movl	%r9d,4(%r13)
	movl	%r10d,8(%r13)
	movl	%r11d,12(%r13)
	jmp	.Lcbc_done

.align	16
.Lcbc_enc_tail:
	xorq	%rax,%rax
	movq	%rax,0+24(%rsp)
	movq	%rax,8+24(%rsp)
	movq	%rax,16(%rsp)

.Lcbc_enc_pushf:
	pushfq
	cld
	movq	%r12,%rsi
	leaq	8+24(%rsp),%rdi
.long	0x9066A4F3
	popfq
.Lcbc_enc_popf:

	leaq	24(%rsp),%r12
	leaq	16+24(%rsp),%rax
	movq	%rax,8(%rsp)
	jmp	.Lcbc_eloop

.align	16
.LCBC_DECRYPT:
	xchgq	%r14,%r15
	addq	$15,%rdx
	andq	$15,%rcx
	andq	$-16,%rdx
	movq	%r14,0(%rsp)
	leaq	(%r12,%rdx,1),%rdx
	movq	%rdx,8(%rsp)
	movq	%rcx,16(%rsp)

	movq	(%rbx),%rax
	movq	8(%rbx),%rbx
	jmp	.Lcbc_dloop
.align	16
.Lcbc_dloop:
	movl	0(%r12),%r8d
	movl	4(%r12),%r9d
	movl	8(%r12),%r10d
	bswapl	%r8d
	movl	12(%r12),%r11d
	bswapl	%r9d
	movq	%rax,0+24(%rsp)
	bswapl	%r10d
	movq	%rbx,8+24(%rsp)
	bswapl	%r11d

	call	_x86_64_Camellia_decrypt

	movq	0(%rsp),%r14
	movq	8(%rsp),%rdx
	movq	16(%rsp),%rcx

	bswapl	%r8d
	movq	(%r12),%rax
	bswapl	%r9d
	movq	8(%r12),%rbx
	bswapl	%r10d
	xorl	0+24(%rsp),%r8d
	bswapl	%r11d
	xorl	4+24(%rsp),%r9d
	xorl	8+24(%rsp),%r10d
	leaq	16(%r12),%r12
	xorl	12+24(%rsp),%r11d
	cmpq	%rdx,%r12
	je	.Lcbc_ddone

	movl	%r8d,0(%r13)
	movl	%r9d,4(%r13)
	movl	%r10d,8(%r13)
	movl	%r11d,12(%r13)

	leaq	16(%r13),%r13
	jmp	.Lcbc_dloop

.align	16
.Lcbc_ddone:
	movq	40(%rsp),%rdx
	cmpq	$0,%rcx
	jne	.Lcbc_dec_tail

	movl	%r8d,0(%r13)
	movl	%r9d,4(%r13)
	movl	%r10d,8(%r13)
	movl	%r11d,12(%r13)

	movq	%rax,(%rdx)
	movq	%rbx,8(%rdx)
	jmp	.Lcbc_done
.align	16
.Lcbc_dec_tail:
	movl	%r8d,0+24(%rsp)
	movl	%r9d,4+24(%rsp)
	movl	%r10d,8+24(%rsp)
	movl	%r11d,12+24(%rsp)

.Lcbc_dec_pushf:
	pushfq
	cld
	leaq	8+24(%rsp),%rsi
	leaq	(%r13),%rdi
.long	0x9066A4F3
	popfq
.Lcbc_dec_popf:

	movq	%rax,(%rdx)
	movq	%rbx,8(%rdx)
	jmp	.Lcbc_done

.align	16
.Lcbc_done:
	movq	48(%rsp),%rcx
.cfi_def_cfa	%rcx,56
	movq	0(%rcx),%r15
.cfi_restore	%r15
	movq	8(%rcx),%r14
.cfi_restore	%r14
	movq	16(%rcx),%r13
.cfi_restore	%r13
	movq	24(%rcx),%r12
.cfi_restore	%r12
	movq	32(%rcx),%rbp
.cfi_restore	%rbp
	movq	40(%rcx),%rbx
.cfi_restore	%rbx
	leaq	48(%rcx),%rsp
.cfi_def_cfa	%rsp,8
.Lcbc_abort:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	Camellia_cbc_encrypt,.-Camellia_cbc_encrypt

.byte	67,97,109,101,108,108,105,97,32,102,111,114,32,120,56,54,95,54,52,32,98,121,32,60,97,112,112,114,111,64,111,112,101,110,115,115,108,46,111,114,103,62,0
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                         node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/chacha/                               0000775 0000000 0000000 00000000000 14746647661 0025142 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/chacha/chacha-x86_64.s                0000664 0000000 0000000 00000221245 14746647661 0027477 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	



.align	64
.Lzero:
.long	0,0,0,0
.Lone:
.long	1,0,0,0
.Linc:
.long	0,1,2,3
.Lfour:
.long	4,4,4,4
.Lincy:
.long	0,2,4,6,1,3,5,7
.Leight:
.long	8,8,8,8,8,8,8,8
.Lrot16:
.byte	0x2,0x3,0x0,0x1, 0x6,0x7,0x4,0x5, 0xa,0xb,0x8,0x9, 0xe,0xf,0xc,0xd
.Lrot24:
.byte	0x3,0x0,0x1,0x2, 0x7,0x4,0x5,0x6, 0xb,0x8,0x9,0xa, 0xf,0xc,0xd,0xe
.Ltwoy:
.long	2,0,0,0, 2,0,0,0
.align	64
.Lzeroz:
.long	0,0,0,0, 1,0,0,0, 2,0,0,0, 3,0,0,0
.Lfourz:
.long	4,0,0,0, 4,0,0,0, 4,0,0,0, 4,0,0,0
.Lincz:
.long	0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15
.Lsixteen:
.long	16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16
.Lsigma:
.byte	101,120,112,97,110,100,32,51,50,45,98,121,116,101,32,107,0
.byte	67,104,97,67,104,97,50,48,32,102,111,114,32,120,56,54,95,54,52,44,32,67,82,89,80,84,79,71,65,77,83,32,98,121,32,60,97,112,112,114,111,64,111,112,101,110,115,115,108,46,111,114,103,62,0
.globl	ChaCha20_ctr32
.type	ChaCha20_ctr32,@function
.align	64
ChaCha20_ctr32:
.cfi_startproc	
	cmpq	$0,%rdx
	je	.Lno_data
	movq	OPENSSL_ia32cap_P+4(%rip),%r10
	btq	$48,%r10
	jc	.LChaCha20_avx512
	testq	%r10,%r10
	js	.LChaCha20_avx512vl
	testl	$512,%r10d
	jnz	.LChaCha20_ssse3

	pushq	%rbx
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_adjust_cfa_offset	8
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_adjust_cfa_offset	8
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_adjust_cfa_offset	8
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_adjust_cfa_offset	8
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_adjust_cfa_offset	8
.cfi_offset	%r15,-56
	subq	$64+24,%rsp
.cfi_adjust_cfa_offset	64+24
.Lctr32_body:


	movdqu	(%rcx),%xmm1
	movdqu	16(%rcx),%xmm2
	movdqu	(%r8),%xmm3
	movdqa	.Lone(%rip),%xmm4


	movdqa	%xmm1,16(%rsp)
	movdqa	%xmm2,32(%rsp)
	movdqa	%xmm3,48(%rsp)
	movq	%rdx,%rbp
	jmp	.Loop_outer

.align	32
.Loop_outer:
	movl	$0x61707865,%eax
	movl	$0x3320646e,%ebx
	movl	$0x79622d32,%ecx
	movl	$0x6b206574,%edx
	movl	16(%rsp),%r8d
	movl	20(%rsp),%r9d
	movl	24(%rsp),%r10d
	movl	28(%rsp),%r11d
	movd	%xmm3,%r12d
	movl	52(%rsp),%r13d
	movl	56(%rsp),%r14d
	movl	60(%rsp),%r15d

	movq	%rbp,64+0(%rsp)
	movl	$10,%ebp
	movq	%rsi,64+8(%rsp)
.byte	102,72,15,126,214
	movq	%rdi,64+16(%rsp)
	movq	%rsi,%rdi
	shrq	$32,%rdi
	jmp	.Loop

.align	32
.Loop:
	addl	%r8d,%eax
	xorl	%eax,%r12d
	roll	$16,%r12d
	addl	%r9d,%ebx
	xorl	%ebx,%r13d
	roll	$16,%r13d
	addl	%r12d,%esi
	xorl	%esi,%r8d
	roll	$12,%r8d
	addl	%r13d,%edi
	xorl	%edi,%r9d
	roll	$12,%r9d
	addl	%r8d,%eax
	xorl	%eax,%r12d
	roll	$8,%r12d
	addl	%r9d,%ebx
	xorl	%ebx,%r13d
	roll	$8,%r13d
	addl	%r12d,%esi
	xorl	%esi,%r8d
	roll	$7,%r8d
	addl	%r13d,%edi
	xorl	%edi,%r9d
	roll	$7,%r9d
	movl	%esi,32(%rsp)
	movl	%edi,36(%rsp)
	movl	40(%rsp),%esi
	movl	44(%rsp),%edi
	addl	%r10d,%ecx
	xorl	%ecx,%r14d
	roll	$16,%r14d
	addl	%r11d,%edx
	xorl	%edx,%r15d
	roll	$16,%r15d
	addl	%r14d,%esi
	xorl	%esi,%r10d
	roll	$12,%r10d
	addl	%r15d,%edi
	xorl	%edi,%r11d
	roll	$12,%r11d
	addl	%r10d,%ecx
	xorl	%ecx,%r14d
	roll	$8,%r14d
	addl	%r11d,%edx
	xorl	%edx,%r15d
	roll	$8,%r15d
	addl	%r14d,%esi
	xorl	%esi,%r10d
	roll	$7,%r10d
	addl	%r15d,%edi
	xorl	%edi,%r11d
	roll	$7,%r11d
	addl	%r9d,%eax
	xorl	%eax,%r15d
	roll	$16,%r15d
	addl	%r10d,%ebx
	xorl	%ebx,%r12d
	roll	$16,%r12d
	addl	%r15d,%esi
	xorl	%esi,%r9d
	roll	$12,%r9d
	addl	%r12d,%edi
	xorl	%edi,%r10d
	roll	$12,%r10d
	addl	%r9d,%eax
	xorl	%eax,%r15d
	roll	$8,%r15d
	addl	%r10d,%ebx
	xorl	%ebx,%r12d
	roll	$8,%r12d
	addl	%r15d,%esi
	xorl	%esi,%r9d
	roll	$7,%r9d
	addl	%r12d,%edi
	xorl	%edi,%r10d
	roll	$7,%r10d
	movl	%esi,40(%rsp)
	movl	%edi,44(%rsp)
	movl	32(%rsp),%esi
	movl	36(%rsp),%edi
	addl	%r11d,%ecx
	xorl	%ecx,%r13d
	roll	$16,%r13d
	addl	%r8d,%edx
	xorl	%edx,%r14d
	roll	$16,%r14d
	addl	%r13d,%esi
	xorl	%esi,%r11d
	roll	$12,%r11d
	addl	%r14d,%edi
	xorl	%edi,%r8d
	roll	$12,%r8d
	addl	%r11d,%ecx
	xorl	%ecx,%r13d
	roll	$8,%r13d
	addl	%r8d,%edx
	xorl	%edx,%r14d
	roll	$8,%r14d
	addl	%r13d,%esi
	xorl	%esi,%r11d
	roll	$7,%r11d
	addl	%r14d,%edi
	xorl	%edi,%r8d
	roll	$7,%r8d
	decl	%ebp
	jnz	.Loop
	movl	%edi,36(%rsp)
	movl	%esi,32(%rsp)
	movq	64(%rsp),%rbp
	movdqa	%xmm2,%xmm1
	movq	64+8(%rsp),%rsi
	paddd	%xmm4,%xmm3
	movq	64+16(%rsp),%rdi

	addl	$0x61707865,%eax
	addl	$0x3320646e,%ebx
	addl	$0x79622d32,%ecx
	addl	$0x6b206574,%edx
	addl	16(%rsp),%r8d
	addl	20(%rsp),%r9d
	addl	24(%rsp),%r10d
	addl	28(%rsp),%r11d
	addl	48(%rsp),%r12d
	addl	52(%rsp),%r13d
	addl	56(%rsp),%r14d
	addl	60(%rsp),%r15d
	paddd	32(%rsp),%xmm1

	cmpq	$64,%rbp
	jb	.Ltail

	xorl	0(%rsi),%eax
	xorl	4(%rsi),%ebx
	xorl	8(%rsi),%ecx
	xorl	12(%rsi),%edx
	xorl	16(%rsi),%r8d
	xorl	20(%rsi),%r9d
	xorl	24(%rsi),%r10d
	xorl	28(%rsi),%r11d
	movdqu	32(%rsi),%xmm0
	xorl	48(%rsi),%r12d
	xorl	52(%rsi),%r13d
	xorl	56(%rsi),%r14d
	xorl	60(%rsi),%r15d
	leaq	64(%rsi),%rsi
	pxor	%xmm1,%xmm0

	movdqa	%xmm2,32(%rsp)
	movd	%xmm3,48(%rsp)

	movl	%eax,0(%rdi)
	movl	%ebx,4(%rdi)
	movl	%ecx,8(%rdi)
	movl	%edx,12(%rdi)
	movl	%r8d,16(%rdi)
	movl	%r9d,20(%rdi)
	movl	%r10d,24(%rdi)
	movl	%r11d,28(%rdi)
	movdqu	%xmm0,32(%rdi)
	movl	%r12d,48(%rdi)
	movl	%r13d,52(%rdi)
	movl	%r14d,56(%rdi)
	movl	%r15d,60(%rdi)
	leaq	64(%rdi),%rdi

	subq	$64,%rbp
	jnz	.Loop_outer

	jmp	.Ldone

.align	16
.Ltail:
	movl	%eax,0(%rsp)
	movl	%ebx,4(%rsp)
	xorq	%rbx,%rbx
	movl	%ecx,8(%rsp)
	movl	%edx,12(%rsp)
	movl	%r8d,16(%rsp)
	movl	%r9d,20(%rsp)
	movl	%r10d,24(%rsp)
	movl	%r11d,28(%rsp)
	movdqa	%xmm1,32(%rsp)
	movl	%r12d,48(%rsp)
	movl	%r13d,52(%rsp)
	movl	%r14d,56(%rsp)
	movl	%r15d,60(%rsp)

.Loop_tail:
	movzbl	(%rsi,%rbx,1),%eax
	movzbl	(%rsp,%rbx,1),%edx
	leaq	1(%rbx),%rbx
	xorl	%edx,%eax
	movb	%al,-1(%rdi,%rbx,1)
	decq	%rbp
	jnz	.Loop_tail

.Ldone:
	leaq	64+24+48(%rsp),%rsi
.cfi_def_cfa	%rsi,8
	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lno_data:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	ChaCha20_ctr32,.-ChaCha20_ctr32
.type	ChaCha20_ssse3,@function
.align	32
ChaCha20_ssse3:
.cfi_startproc	
.LChaCha20_ssse3:
	movq	%rsp,%r9
.cfi_def_cfa_register	%r9
	testl	$2048,%r10d
	jnz	.LChaCha20_4xop
	cmpq	$128,%rdx
	je	.LChaCha20_128
	ja	.LChaCha20_4x

.Ldo_sse3_after_all:
	subq	$64+8,%rsp
	movdqa	.Lsigma(%rip),%xmm0
	movdqu	(%rcx),%xmm1
	movdqu	16(%rcx),%xmm2
	movdqu	(%r8),%xmm3
	movdqa	.Lrot16(%rip),%xmm6
	movdqa	.Lrot24(%rip),%xmm7

	movdqa	%xmm0,0(%rsp)
	movdqa	%xmm1,16(%rsp)
	movdqa	%xmm2,32(%rsp)
	movdqa	%xmm3,48(%rsp)
	movq	$10,%r8
	jmp	.Loop_ssse3

.align	32
.Loop_outer_ssse3:
	movdqa	.Lone(%rip),%xmm3
	movdqa	0(%rsp),%xmm0
	movdqa	16(%rsp),%xmm1
	movdqa	32(%rsp),%xmm2
	paddd	48(%rsp),%xmm3
	movq	$10,%r8
	movdqa	%xmm3,48(%rsp)
	jmp	.Loop_ssse3

.align	32
.Loop_ssse3:
	paddd	%xmm1,%xmm0
	pxor	%xmm0,%xmm3
.byte	102,15,56,0,222
	paddd	%xmm3,%xmm2
	pxor	%xmm2,%xmm1
	movdqa	%xmm1,%xmm4
	psrld	$20,%xmm1
	pslld	$12,%xmm4
	por	%xmm4,%xmm1
	paddd	%xmm1,%xmm0
	pxor	%xmm0,%xmm3
.byte	102,15,56,0,223
	paddd	%xmm3,%xmm2
	pxor	%xmm2,%xmm1
	movdqa	%xmm1,%xmm4
	psrld	$25,%xmm1
	pslld	$7,%xmm4
	por	%xmm4,%xmm1
	pshufd	$78,%xmm2,%xmm2
	pshufd	$57,%xmm1,%xmm1
	pshufd	$147,%xmm3,%xmm3
	nop
	paddd	%xmm1,%xmm0
	pxor	%xmm0,%xmm3
.byte	102,15,56,0,222
	paddd	%xmm3,%xmm2
	pxor	%xmm2,%xmm1
	movdqa	%xmm1,%xmm4
	psrld	$20,%xmm1
	pslld	$12,%xmm4
	por	%xmm4,%xmm1
	paddd	%xmm1,%xmm0
	pxor	%xmm0,%xmm3
.byte	102,15,56,0,223
	paddd	%xmm3,%xmm2
	pxor	%xmm2,%xmm1
	movdqa	%xmm1,%xmm4
	psrld	$25,%xmm1
	pslld	$7,%xmm4
	por	%xmm4,%xmm1
	pshufd	$78,%xmm2,%xmm2
	pshufd	$147,%xmm1,%xmm1
	pshufd	$57,%xmm3,%xmm3
	decq	%r8
	jnz	.Loop_ssse3
	paddd	0(%rsp),%xmm0
	paddd	16(%rsp),%xmm1
	paddd	32(%rsp),%xmm2
	paddd	48(%rsp),%xmm3

	cmpq	$64,%rdx
	jb	.Ltail_ssse3

	movdqu	0(%rsi),%xmm4
	movdqu	16(%rsi),%xmm5
	pxor	%xmm4,%xmm0
	movdqu	32(%rsi),%xmm4
	pxor	%xmm5,%xmm1
	movdqu	48(%rsi),%xmm5
	leaq	64(%rsi),%rsi
	pxor	%xmm4,%xmm2
	pxor	%xmm5,%xmm3

	movdqu	%xmm0,0(%rdi)
	movdqu	%xmm1,16(%rdi)
	movdqu	%xmm2,32(%rdi)
	movdqu	%xmm3,48(%rdi)
	leaq	64(%rdi),%rdi

	subq	$64,%rdx
	jnz	.Loop_outer_ssse3

	jmp	.Ldone_ssse3

.align	16
.Ltail_ssse3:
	movdqa	%xmm0,0(%rsp)
	movdqa	%xmm1,16(%rsp)
	movdqa	%xmm2,32(%rsp)
	movdqa	%xmm3,48(%rsp)
	xorq	%r8,%r8

.Loop_tail_ssse3:
	movzbl	(%rsi,%r8,1),%eax
	movzbl	(%rsp,%r8,1),%ecx
	leaq	1(%r8),%r8
	xorl	%ecx,%eax
	movb	%al,-1(%rdi,%r8,1)
	decq	%rdx
	jnz	.Loop_tail_ssse3

.Ldone_ssse3:
	leaq	(%r9),%rsp
.cfi_def_cfa_register	%rsp
.Lssse3_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	ChaCha20_ssse3,.-ChaCha20_ssse3
.type	ChaCha20_128,@function
.align	32
ChaCha20_128:
.cfi_startproc	
.LChaCha20_128:
	movq	%rsp,%r9
.cfi_def_cfa_register	%r9
	subq	$64+8,%rsp
	movdqa	.Lsigma(%rip),%xmm8
	movdqu	(%rcx),%xmm9
	movdqu	16(%rcx),%xmm2
	movdqu	(%r8),%xmm3
	movdqa	.Lone(%rip),%xmm1
	movdqa	.Lrot16(%rip),%xmm6
	movdqa	.Lrot24(%rip),%xmm7

	movdqa	%xmm8,%xmm10
	movdqa	%xmm8,0(%rsp)
	movdqa	%xmm9,%xmm11
	movdqa	%xmm9,16(%rsp)
	movdqa	%xmm2,%xmm0
	movdqa	%xmm2,32(%rsp)
	paddd	%xmm3,%xmm1
	movdqa	%xmm3,48(%rsp)
	movq	$10,%r8
	jmp	.Loop_128

.align	32
.Loop_128:
	paddd	%xmm9,%xmm8
	pxor	%xmm8,%xmm3
	paddd	%xmm11,%xmm10
	pxor	%xmm10,%xmm1
.byte	102,15,56,0,222
.byte	102,15,56,0,206
	paddd	%xmm3,%xmm2
	paddd	%xmm1,%xmm0
	pxor	%xmm2,%xmm9
	pxor	%xmm0,%xmm11
	movdqa	%xmm9,%xmm4
	psrld	$20,%xmm9
	movdqa	%xmm11,%xmm5
	pslld	$12,%xmm4
	psrld	$20,%xmm11
	por	%xmm4,%xmm9
	pslld	$12,%xmm5
	por	%xmm5,%xmm11
	paddd	%xmm9,%xmm8
	pxor	%xmm8,%xmm3
	paddd	%xmm11,%xmm10
	pxor	%xmm10,%xmm1
.byte	102,15,56,0,223
.byte	102,15,56,0,207
	paddd	%xmm3,%xmm2
	paddd	%xmm1,%xmm0
	pxor	%xmm2,%xmm9
	pxor	%xmm0,%xmm11
	movdqa	%xmm9,%xmm4
	psrld	$25,%xmm9
	movdqa	%xmm11,%xmm5
	pslld	$7,%xmm4
	psrld	$25,%xmm11
	por	%xmm4,%xmm9
	pslld	$7,%xmm5
	por	%xmm5,%xmm11
	pshufd	$78,%xmm2,%xmm2
	pshufd	$57,%xmm9,%xmm9
	pshufd	$147,%xmm3,%xmm3
	pshufd	$78,%xmm0,%xmm0
	pshufd	$57,%xmm11,%xmm11
	pshufd	$147,%xmm1,%xmm1
	paddd	%xmm9,%xmm8
	pxor	%xmm8,%xmm3
	paddd	%xmm11,%xmm10
	pxor	%xmm10,%xmm1
.byte	102,15,56,0,222
.byte	102,15,56,0,206
	paddd	%xmm3,%xmm2
	paddd	%xmm1,%xmm0
	pxor	%xmm2,%xmm9
	pxor	%xmm0,%xmm11
	movdqa	%xmm9,%xmm4
	psrld	$20,%xmm9
	movdqa	%xmm11,%xmm5
	pslld	$12,%xmm4
	psrld	$20,%xmm11
	por	%xmm4,%xmm9
	pslld	$12,%xmm5
	por	%xmm5,%xmm11
	paddd	%xmm9,%xmm8
	pxor	%xmm8,%xmm3
	paddd	%xmm11,%xmm10
	pxor	%xmm10,%xmm1
.byte	102,15,56,0,223
.byte	102,15,56,0,207
	paddd	%xmm3,%xmm2
	paddd	%xmm1,%xmm0
	pxor	%xmm2,%xmm9
	pxor	%xmm0,%xmm11
	movdqa	%xmm9,%xmm4
	psrld	$25,%xmm9
	movdqa	%xmm11,%xmm5
	pslld	$7,%xmm4
	psrld	$25,%xmm11
	por	%xmm4,%xmm9
	pslld	$7,%xmm5
	por	%xmm5,%xmm11
	pshufd	$78,%xmm2,%xmm2
	pshufd	$147,%xmm9,%xmm9
	pshufd	$57,%xmm3,%xmm3
	pshufd	$78,%xmm0,%xmm0
	pshufd	$147,%xmm11,%xmm11
	pshufd	$57,%xmm1,%xmm1
	decq	%r8
	jnz	.Loop_128
	paddd	0(%rsp),%xmm8
	paddd	16(%rsp),%xmm9
	paddd	32(%rsp),%xmm2
	paddd	48(%rsp),%xmm3
	paddd	.Lone(%rip),%xmm1
	paddd	0(%rsp),%xmm10
	paddd	16(%rsp),%xmm11
	paddd	32(%rsp),%xmm0
	paddd	48(%rsp),%xmm1

	movdqu	0(%rsi),%xmm4
	movdqu	16(%rsi),%xmm5
	pxor	%xmm4,%xmm8
	movdqu	32(%rsi),%xmm4
	pxor	%xmm5,%xmm9
	movdqu	48(%rsi),%xmm5
	pxor	%xmm4,%xmm2
	movdqu	64(%rsi),%xmm4
	pxor	%xmm5,%xmm3
	movdqu	80(%rsi),%xmm5
	pxor	%xmm4,%xmm10
	movdqu	96(%rsi),%xmm4
	pxor	%xmm5,%xmm11
	movdqu	112(%rsi),%xmm5
	pxor	%xmm4,%xmm0
	pxor	%xmm5,%xmm1

	movdqu	%xmm8,0(%rdi)
	movdqu	%xmm9,16(%rdi)
	movdqu	%xmm2,32(%rdi)
	movdqu	%xmm3,48(%rdi)
	movdqu	%xmm10,64(%rdi)
	movdqu	%xmm11,80(%rdi)
	movdqu	%xmm0,96(%rdi)
	movdqu	%xmm1,112(%rdi)
	leaq	(%r9),%rsp
.cfi_def_cfa_register	%rsp
.L128_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	ChaCha20_128,.-ChaCha20_128
.type	ChaCha20_4x,@function
.align	32
ChaCha20_4x:
.cfi_startproc	
.LChaCha20_4x:
	movq	%rsp,%r9
.cfi_def_cfa_register	%r9
	movq	%r10,%r11
	shrq	$32,%r10
	testq	$32,%r10
	jnz	.LChaCha20_8x
	cmpq	$192,%rdx
	ja	.Lproceed4x

	andq	$71303168,%r11
	cmpq	$4194304,%r11
	je	.Ldo_sse3_after_all

.Lproceed4x:
	subq	$0x140+8,%rsp
	movdqa	.Lsigma(%rip),%xmm11
	movdqu	(%rcx),%xmm15
	movdqu	16(%rcx),%xmm7
	movdqu	(%r8),%xmm3
	leaq	256(%rsp),%rcx
	leaq	.Lrot16(%rip),%r10
	leaq	.Lrot24(%rip),%r11

	pshufd	$0x00,%xmm11,%xmm8
	pshufd	$0x55,%xmm11,%xmm9
	movdqa	%xmm8,64(%rsp)
	pshufd	$0xaa,%xmm11,%xmm10
	movdqa	%xmm9,80(%rsp)
	pshufd	$0xff,%xmm11,%xmm11
	movdqa	%xmm10,96(%rsp)
	movdqa	%xmm11,112(%rsp)

	pshufd	$0x00,%xmm15,%xmm12
	pshufd	$0x55,%xmm15,%xmm13
	movdqa	%xmm12,128-256(%rcx)
	pshufd	$0xaa,%xmm15,%xmm14
	movdqa	%xmm13,144-256(%rcx)
	pshufd	$0xff,%xmm15,%xmm15
	movdqa	%xmm14,160-256(%rcx)
	movdqa	%xmm15,176-256(%rcx)

	pshufd	$0x00,%xmm7,%xmm4
	pshufd	$0x55,%xmm7,%xmm5
	movdqa	%xmm4,192-256(%rcx)
	pshufd	$0xaa,%xmm7,%xmm6
	movdqa	%xmm5,208-256(%rcx)
	pshufd	$0xff,%xmm7,%xmm7
	movdqa	%xmm6,224-256(%rcx)
	movdqa	%xmm7,240-256(%rcx)

	pshufd	$0x00,%xmm3,%xmm0
	pshufd	$0x55,%xmm3,%xmm1
	paddd	.Linc(%rip),%xmm0
	pshufd	$0xaa,%xmm3,%xmm2
	movdqa	%xmm1,272-256(%rcx)
	pshufd	$0xff,%xmm3,%xmm3
	movdqa	%xmm2,288-256(%rcx)
	movdqa	%xmm3,304-256(%rcx)

	jmp	.Loop_enter4x

.align	32
.Loop_outer4x:
	movdqa	64(%rsp),%xmm8
	movdqa	80(%rsp),%xmm9
	movdqa	96(%rsp),%xmm10
	movdqa	112(%rsp),%xmm11
	movdqa	128-256(%rcx),%xmm12
	movdqa	144-256(%rcx),%xmm13
	movdqa	160-256(%rcx),%xmm14
	movdqa	176-256(%rcx),%xmm15
	movdqa	192-256(%rcx),%xmm4
	movdqa	208-256(%rcx),%xmm5
	movdqa	224-256(%rcx),%xmm6
	movdqa	240-256(%rcx),%xmm7
	movdqa	256-256(%rcx),%xmm0
	movdqa	272-256(%rcx),%xmm1
	movdqa	288-256(%rcx),%xmm2
	movdqa	304-256(%rcx),%xmm3
	paddd	.Lfour(%rip),%xmm0

.Loop_enter4x:
	movdqa	%xmm6,32(%rsp)
	movdqa	%xmm7,48(%rsp)
	movdqa	(%r10),%xmm7
	movl	$10,%eax
	movdqa	%xmm0,256-256(%rcx)
	jmp	.Loop4x

.align	32
.Loop4x:
	paddd	%xmm12,%xmm8
	paddd	%xmm13,%xmm9
	pxor	%xmm8,%xmm0
	pxor	%xmm9,%xmm1
.byte	102,15,56,0,199
.byte	102,15,56,0,207
	paddd	%xmm0,%xmm4
	paddd	%xmm1,%xmm5
	pxor	%xmm4,%xmm12
	pxor	%xmm5,%xmm13
	movdqa	%xmm12,%xmm6
	pslld	$12,%xmm12
	psrld	$20,%xmm6
	movdqa	%xmm13,%xmm7
	pslld	$12,%xmm13
	por	%xmm6,%xmm12
	psrld	$20,%xmm7
	movdqa	(%r11),%xmm6
	por	%xmm7,%xmm13
	paddd	%xmm12,%xmm8
	paddd	%xmm13,%xmm9
	pxor	%xmm8,%xmm0
	pxor	%xmm9,%xmm1
.byte	102,15,56,0,198
.byte	102,15,56,0,206
	paddd	%xmm0,%xmm4
	paddd	%xmm1,%xmm5
	pxor	%xmm4,%xmm12
	pxor	%xmm5,%xmm13
	movdqa	%xmm12,%xmm7
	pslld	$7,%xmm12
	psrld	$25,%xmm7
	movdqa	%xmm13,%xmm6
	pslld	$7,%xmm13
	por	%xmm7,%xmm12
	psrld	$25,%xmm6
	movdqa	(%r10),%xmm7
	por	%xmm6,%xmm13
	movdqa	%xmm4,0(%rsp)
	movdqa	%xmm5,16(%rsp)
	movdqa	32(%rsp),%xmm4
	movdqa	48(%rsp),%xmm5
	paddd	%xmm14,%xmm10
	paddd	%xmm15,%xmm11
	pxor	%xmm10,%xmm2
	pxor	%xmm11,%xmm3
.byte	102,15,56,0,215
.byte	102,15,56,0,223
	paddd	%xmm2,%xmm4
	paddd	%xmm3,%xmm5
	pxor	%xmm4,%xmm14
	pxor	%xmm5,%xmm15
	movdqa	%xmm14,%xmm6
	pslld	$12,%xmm14
	psrld	$20,%xmm6
	movdqa	%xmm15,%xmm7
	pslld	$12,%xmm15
	por	%xmm6,%xmm14
	psrld	$20,%xmm7
	movdqa	(%r11),%xmm6
	por	%xmm7,%xmm15
	paddd	%xmm14,%xmm10
	paddd	%xmm15,%xmm11
	pxor	%xmm10,%xmm2
	pxor	%xmm11,%xmm3
.byte	102,15,56,0,214
.byte	102,15,56,0,222
	paddd	%xmm2,%xmm4
	paddd	%xmm3,%xmm5
	pxor	%xmm4,%xmm14
	pxor	%xmm5,%xmm15
	movdqa	%xmm14,%xmm7
	pslld	$7,%xmm14
	psrld	$25,%xmm7
	movdqa	%xmm15,%xmm6
	pslld	$7,%xmm15
	por	%xmm7,%xmm14
	psrld	$25,%xmm6
	movdqa	(%r10),%xmm7
	por	%xmm6,%xmm15
	paddd	%xmm13,%xmm8
	paddd	%xmm14,%xmm9
	pxor	%xmm8,%xmm3
	pxor	%xmm9,%xmm0
.byte	102,15,56,0,223
.byte	102,15,56,0,199
	paddd	%xmm3,%xmm4
	paddd	%xmm0,%xmm5
	pxor	%xmm4,%xmm13
	pxor	%xmm5,%xmm14
	movdqa	%xmm13,%xmm6
	pslld	$12,%xmm13
	psrld	$20,%xmm6
	movdqa	%xmm14,%xmm7
	pslld	$12,%xmm14
	por	%xmm6,%xmm13
	psrld	$20,%xmm7
	movdqa	(%r11),%xmm6
	por	%xmm7,%xmm14
	paddd	%xmm13,%xmm8
	paddd	%xmm14,%xmm9
	pxor	%xmm8,%xmm3
	pxor	%xmm9,%xmm0
.byte	102,15,56,0,222
.byte	102,15,56,0,198
	paddd	%xmm3,%xmm4
	paddd	%xmm0,%xmm5
	pxor	%xmm4,%xmm13
	pxor	%xmm5,%xmm14
	movdqa	%xmm13,%xmm7
	pslld	$7,%xmm13
	psrld	$25,%xmm7
	movdqa	%xmm14,%xmm6
	pslld	$7,%xmm14
	por	%xmm7,%xmm13
	psrld	$25,%xmm6
	movdqa	(%r10),%xmm7
	por	%xmm6,%xmm14
	movdqa	%xmm4,32(%rsp)
	movdqa	%xmm5,48(%rsp)
	movdqa	0(%rsp),%xmm4
	movdqa	16(%rsp),%xmm5
	paddd	%xmm15,%xmm10
	paddd	%xmm12,%xmm11
	pxor	%xmm10,%xmm1
	pxor	%xmm11,%xmm2
.byte	102,15,56,0,207
.byte	102,15,56,0,215
	paddd	%xmm1,%xmm4
	paddd	%xmm2,%xmm5
	pxor	%xmm4,%xmm15
	pxor	%xmm5,%xmm12
	movdqa	%xmm15,%xmm6
	pslld	$12,%xmm15
	psrld	$20,%xmm6
	movdqa	%xmm12,%xmm7
	pslld	$12,%xmm12
	por	%xmm6,%xmm15
	psrld	$20,%xmm7
	movdqa	(%r11),%xmm6
	por	%xmm7,%xmm12
	paddd	%xmm15,%xmm10
	paddd	%xmm12,%xmm11
	pxor	%xmm10,%xmm1
	pxor	%xmm11,%xmm2
.byte	102,15,56,0,206
.byte	102,15,56,0,214
	paddd	%xmm1,%xmm4
	paddd	%xmm2,%xmm5
	pxor	%xmm4,%xmm15
	pxor	%xmm5,%xmm12
	movdqa	%xmm15,%xmm7
	pslld	$7,%xmm15
	psrld	$25,%xmm7
	movdqa	%xmm12,%xmm6
	pslld	$7,%xmm12
	por	%xmm7,%xmm15
	psrld	$25,%xmm6
	movdqa	(%r10),%xmm7
	por	%xmm6,%xmm12
	decl	%eax
	jnz	.Loop4x

	paddd	64(%rsp),%xmm8
	paddd	80(%rsp),%xmm9
	paddd	96(%rsp),%xmm10
	paddd	112(%rsp),%xmm11

	movdqa	%xmm8,%xmm6
	punpckldq	%xmm9,%xmm8
	movdqa	%xmm10,%xmm7
	punpckldq	%xmm11,%xmm10
	punpckhdq	%xmm9,%xmm6
	punpckhdq	%xmm11,%xmm7
	movdqa	%xmm8,%xmm9
	punpcklqdq	%xmm10,%xmm8
	movdqa	%xmm6,%xmm11
	punpcklqdq	%xmm7,%xmm6
	punpckhqdq	%xmm10,%xmm9
	punpckhqdq	%xmm7,%xmm11
	paddd	128-256(%rcx),%xmm12
	paddd	144-256(%rcx),%xmm13
	paddd	160-256(%rcx),%xmm14
	paddd	176-256(%rcx),%xmm15

	movdqa	%xmm8,0(%rsp)
	movdqa	%xmm9,16(%rsp)
	movdqa	32(%rsp),%xmm8
	movdqa	48(%rsp),%xmm9

	movdqa	%xmm12,%xmm10
	punpckldq	%xmm13,%xmm12
	movdqa	%xmm14,%xmm7
	punpckldq	%xmm15,%xmm14
	punpckhdq	%xmm13,%xmm10
	punpckhdq	%xmm15,%xmm7
	movdqa	%xmm12,%xmm13
	punpcklqdq	%xmm14,%xmm12
	movdqa	%xmm10,%xmm15
	punpcklqdq	%xmm7,%xmm10
	punpckhqdq	%xmm14,%xmm13
	punpckhqdq	%xmm7,%xmm15
	paddd	192-256(%rcx),%xmm4
	paddd	208-256(%rcx),%xmm5
	paddd	224-256(%rcx),%xmm8
	paddd	240-256(%rcx),%xmm9

	movdqa	%xmm6,32(%rsp)
	movdqa	%xmm11,48(%rsp)

	movdqa	%xmm4,%xmm14
	punpckldq	%xmm5,%xmm4
	movdqa	%xmm8,%xmm7
	punpckldq	%xmm9,%xmm8
	punpckhdq	%xmm5,%xmm14
	punpckhdq	%xmm9,%xmm7
	movdqa	%xmm4,%xmm5
	punpcklqdq	%xmm8,%xmm4
	movdqa	%xmm14,%xmm9
	punpcklqdq	%xmm7,%xmm14
	punpckhqdq	%xmm8,%xmm5
	punpckhqdq	%xmm7,%xmm9
	paddd	256-256(%rcx),%xmm0
	paddd	272-256(%rcx),%xmm1
	paddd	288-256(%rcx),%xmm2
	paddd	304-256(%rcx),%xmm3

	movdqa	%xmm0,%xmm8
	punpckldq	%xmm1,%xmm0
	movdqa	%xmm2,%xmm7
	punpckldq	%xmm3,%xmm2
	punpckhdq	%xmm1,%xmm8
	punpckhdq	%xmm3,%xmm7
	movdqa	%xmm0,%xmm1
	punpcklqdq	%xmm2,%xmm0
	movdqa	%xmm8,%xmm3
	punpcklqdq	%xmm7,%xmm8
	punpckhqdq	%xmm2,%xmm1
	punpckhqdq	%xmm7,%xmm3
	cmpq	$256,%rdx
	jb	.Ltail4x

	movdqu	0(%rsi),%xmm6
	movdqu	16(%rsi),%xmm11
	movdqu	32(%rsi),%xmm2
	movdqu	48(%rsi),%xmm7
	pxor	0(%rsp),%xmm6
	pxor	%xmm12,%xmm11
	pxor	%xmm4,%xmm2
	pxor	%xmm0,%xmm7

	movdqu	%xmm6,0(%rdi)
	movdqu	64(%rsi),%xmm6
	movdqu	%xmm11,16(%rdi)
	movdqu	80(%rsi),%xmm11
	movdqu	%xmm2,32(%rdi)
	movdqu	96(%rsi),%xmm2
	movdqu	%xmm7,48(%rdi)
	movdqu	112(%rsi),%xmm7
	leaq	128(%rsi),%rsi
	pxor	16(%rsp),%xmm6
	pxor	%xmm13,%xmm11
	pxor	%xmm5,%xmm2
	pxor	%xmm1,%xmm7

	movdqu	%xmm6,64(%rdi)
	movdqu	0(%rsi),%xmm6
	movdqu	%xmm11,80(%rdi)
	movdqu	16(%rsi),%xmm11
	movdqu	%xmm2,96(%rdi)
	movdqu	32(%rsi),%xmm2
	movdqu	%xmm7,112(%rdi)
	leaq	128(%rdi),%rdi
	movdqu	48(%rsi),%xmm7
	pxor	32(%rsp),%xmm6
	pxor	%xmm10,%xmm11
	pxor	%xmm14,%xmm2
	pxor	%xmm8,%xmm7

	movdqu	%xmm6,0(%rdi)
	movdqu	64(%rsi),%xmm6
	movdqu	%xmm11,16(%rdi)
	movdqu	80(%rsi),%xmm11
	movdqu	%xmm2,32(%rdi)
	movdqu	96(%rsi),%xmm2
	movdqu	%xmm7,48(%rdi)
	movdqu	112(%rsi),%xmm7
	leaq	128(%rsi),%rsi
	pxor	48(%rsp),%xmm6
	pxor	%xmm15,%xmm11
	pxor	%xmm9,%xmm2
	pxor	%xmm3,%xmm7
	movdqu	%xmm6,64(%rdi)
	movdqu	%xmm11,80(%rdi)
	movdqu	%xmm2,96(%rdi)
	movdqu	%xmm7,112(%rdi)
	leaq	128(%rdi),%rdi

	subq	$256,%rdx
	jnz	.Loop_outer4x

	jmp	.Ldone4x

.Ltail4x:
	cmpq	$192,%rdx
	jae	.L192_or_more4x
	cmpq	$128,%rdx
	jae	.L128_or_more4x
	cmpq	$64,%rdx
	jae	.L64_or_more4x


	xorq	%r10,%r10

	movdqa	%xmm12,16(%rsp)
	movdqa	%xmm4,32(%rsp)
	movdqa	%xmm0,48(%rsp)
	jmp	.Loop_tail4x

.align	32
.L64_or_more4x:
	movdqu	0(%rsi),%xmm6
	movdqu	16(%rsi),%xmm11
	movdqu	32(%rsi),%xmm2
	movdqu	48(%rsi),%xmm7
	pxor	0(%rsp),%xmm6
	pxor	%xmm12,%xmm11
	pxor	%xmm4,%xmm2
	pxor	%xmm0,%xmm7
	movdqu	%xmm6,0(%rdi)
	movdqu	%xmm11,16(%rdi)
	movdqu	%xmm2,32(%rdi)
	movdqu	%xmm7,48(%rdi)
	je	.Ldone4x

	movdqa	16(%rsp),%xmm6
	leaq	64(%rsi),%rsi
	xorq	%r10,%r10
	movdqa	%xmm6,0(%rsp)
	movdqa	%xmm13,16(%rsp)
	leaq	64(%rdi),%rdi
	movdqa	%xmm5,32(%rsp)
	subq	$64,%rdx
	movdqa	%xmm1,48(%rsp)
	jmp	.Loop_tail4x

.align	32
.L128_or_more4x:
	movdqu	0(%rsi),%xmm6
	movdqu	16(%rsi),%xmm11
	movdqu	32(%rsi),%xmm2
	movdqu	48(%rsi),%xmm7
	pxor	0(%rsp),%xmm6
	pxor	%xmm12,%xmm11
	pxor	%xmm4,%xmm2
	pxor	%xmm0,%xmm7

	movdqu	%xmm6,0(%rdi)
	movdqu	64(%rsi),%xmm6
	movdqu	%xmm11,16(%rdi)
	movdqu	80(%rsi),%xmm11
	movdqu	%xmm2,32(%rdi)
	movdqu	96(%rsi),%xmm2
	movdqu	%xmm7,48(%rdi)
	movdqu	112(%rsi),%xmm7
	pxor	16(%rsp),%xmm6
	pxor	%xmm13,%xmm11
	pxor	%xmm5,%xmm2
	pxor	%xmm1,%xmm7
	movdqu	%xmm6,64(%rdi)
	movdqu	%xmm11,80(%rdi)
	movdqu	%xmm2,96(%rdi)
	movdqu	%xmm7,112(%rdi)
	je	.Ldone4x

	movdqa	32(%rsp),%xmm6
	leaq	128(%rsi),%rsi
	xorq	%r10,%r10
	movdqa	%xmm6,0(%rsp)
	movdqa	%xmm10,16(%rsp)
	leaq	128(%rdi),%rdi
	movdqa	%xmm14,32(%rsp)
	subq	$128,%rdx
	movdqa	%xmm8,48(%rsp)
	jmp	.Loop_tail4x

.align	32
.L192_or_more4x:
	movdqu	0(%rsi),%xmm6
	movdqu	16(%rsi),%xmm11
	movdqu	32(%rsi),%xmm2
	movdqu	48(%rsi),%xmm7
	pxor	0(%rsp),%xmm6
	pxor	%xmm12,%xmm11
	pxor	%xmm4,%xmm2
	pxor	%xmm0,%xmm7

	movdqu	%xmm6,0(%rdi)
	movdqu	64(%rsi),%xmm6
	movdqu	%xmm11,16(%rdi)
	movdqu	80(%rsi),%xmm11
	movdqu	%xmm2,32(%rdi)
	movdqu	96(%rsi),%xmm2
	movdqu	%xmm7,48(%rdi)
	movdqu	112(%rsi),%xmm7
	leaq	128(%rsi),%rsi
	pxor	16(%rsp),%xmm6
	pxor	%xmm13,%xmm11
	pxor	%xmm5,%xmm2
	pxor	%xmm1,%xmm7

	movdqu	%xmm6,64(%rdi)
	movdqu	0(%rsi),%xmm6
	movdqu	%xmm11,80(%rdi)
	movdqu	16(%rsi),%xmm11
	movdqu	%xmm2,96(%rdi)
	movdqu	32(%rsi),%xmm2
	movdqu	%xmm7,112(%rdi)
	leaq	128(%rdi),%rdi
	movdqu	48(%rsi),%xmm7
	pxor	32(%rsp),%xmm6
	pxor	%xmm10,%xmm11
	pxor	%xmm14,%xmm2
	pxor	%xmm8,%xmm7
	movdqu	%xmm6,0(%rdi)
	movdqu	%xmm11,16(%rdi)
	movdqu	%xmm2,32(%rdi)
	movdqu	%xmm7,48(%rdi)
	je	.Ldone4x

	movdqa	48(%rsp),%xmm6
	leaq	64(%rsi),%rsi
	xorq	%r10,%r10
	movdqa	%xmm6,0(%rsp)
	movdqa	%xmm15,16(%rsp)
	leaq	64(%rdi),%rdi
	movdqa	%xmm9,32(%rsp)
	subq	$192,%rdx
	movdqa	%xmm3,48(%rsp)

.Loop_tail4x:
	movzbl	(%rsi,%r10,1),%eax
	movzbl	(%rsp,%r10,1),%ecx
	leaq	1(%r10),%r10
	xorl	%ecx,%eax
	movb	%al,-1(%rdi,%r10,1)
	decq	%rdx
	jnz	.Loop_tail4x

.Ldone4x:
	leaq	(%r9),%rsp
.cfi_def_cfa_register	%rsp
.L4x_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	ChaCha20_4x,.-ChaCha20_4x
.type	ChaCha20_4xop,@function
.align	32
ChaCha20_4xop:
.cfi_startproc	
.LChaCha20_4xop:
	movq	%rsp,%r9
.cfi_def_cfa_register	%r9
	subq	$0x140+8,%rsp
	vzeroupper

	vmovdqa	.Lsigma(%rip),%xmm11
	vmovdqu	(%rcx),%xmm3
	vmovdqu	16(%rcx),%xmm15
	vmovdqu	(%r8),%xmm7
	leaq	256(%rsp),%rcx

	vpshufd	$0x00,%xmm11,%xmm8
	vpshufd	$0x55,%xmm11,%xmm9
	vmovdqa	%xmm8,64(%rsp)
	vpshufd	$0xaa,%xmm11,%xmm10
	vmovdqa	%xmm9,80(%rsp)
	vpshufd	$0xff,%xmm11,%xmm11
	vmovdqa	%xmm10,96(%rsp)
	vmovdqa	%xmm11,112(%rsp)

	vpshufd	$0x00,%xmm3,%xmm0
	vpshufd	$0x55,%xmm3,%xmm1
	vmovdqa	%xmm0,128-256(%rcx)
	vpshufd	$0xaa,%xmm3,%xmm2
	vmovdqa	%xmm1,144-256(%rcx)
	vpshufd	$0xff,%xmm3,%xmm3
	vmovdqa	%xmm2,160-256(%rcx)
	vmovdqa	%xmm3,176-256(%rcx)

	vpshufd	$0x00,%xmm15,%xmm12
	vpshufd	$0x55,%xmm15,%xmm13
	vmovdqa	%xmm12,192-256(%rcx)
	vpshufd	$0xaa,%xmm15,%xmm14
	vmovdqa	%xmm13,208-256(%rcx)
	vpshufd	$0xff,%xmm15,%xmm15
	vmovdqa	%xmm14,224-256(%rcx)
	vmovdqa	%xmm15,240-256(%rcx)

	vpshufd	$0x00,%xmm7,%xmm4
	vpshufd	$0x55,%xmm7,%xmm5
	vpaddd	.Linc(%rip),%xmm4,%xmm4
	vpshufd	$0xaa,%xmm7,%xmm6
	vmovdqa	%xmm5,272-256(%rcx)
	vpshufd	$0xff,%xmm7,%xmm7
	vmovdqa	%xmm6,288-256(%rcx)
	vmovdqa	%xmm7,304-256(%rcx)

	jmp	.Loop_enter4xop

.align	32
.Loop_outer4xop:
	vmovdqa	64(%rsp),%xmm8
	vmovdqa	80(%rsp),%xmm9
	vmovdqa	96(%rsp),%xmm10
	vmovdqa	112(%rsp),%xmm11
	vmovdqa	128-256(%rcx),%xmm0
	vmovdqa	144-256(%rcx),%xmm1
	vmovdqa	160-256(%rcx),%xmm2
	vmovdqa	176-256(%rcx),%xmm3
	vmovdqa	192-256(%rcx),%xmm12
	vmovdqa	208-256(%rcx),%xmm13
	vmovdqa	224-256(%rcx),%xmm14
	vmovdqa	240-256(%rcx),%xmm15
	vmovdqa	256-256(%rcx),%xmm4
	vmovdqa	272-256(%rcx),%xmm5
	vmovdqa	288-256(%rcx),%xmm6
	vmovdqa	304-256(%rcx),%xmm7
	vpaddd	.Lfour(%rip),%xmm4,%xmm4

.Loop_enter4xop:
	movl	$10,%eax
	vmovdqa	%xmm4,256-256(%rcx)
	jmp	.Loop4xop

.align	32
.Loop4xop:
	vpaddd	%xmm0,%xmm8,%xmm8
	vpaddd	%xmm1,%xmm9,%xmm9
	vpaddd	%xmm2,%xmm10,%xmm10
	vpaddd	%xmm3,%xmm11,%xmm11
	vpxor	%xmm4,%xmm8,%xmm4
	vpxor	%xmm5,%xmm9,%xmm5
	vpxor	%xmm6,%xmm10,%xmm6
	vpxor	%xmm7,%xmm11,%xmm7
.byte	143,232,120,194,228,16
.byte	143,232,120,194,237,16
.byte	143,232,120,194,246,16
.byte	143,232,120,194,255,16
	vpaddd	%xmm4,%xmm12,%xmm12
	vpaddd	%xmm5,%xmm13,%xmm13
	vpaddd	%xmm6,%xmm14,%xmm14
	vpaddd	%xmm7,%xmm15,%xmm15
	vpxor	%xmm0,%xmm12,%xmm0
	vpxor	%xmm1,%xmm13,%xmm1
	vpxor	%xmm14,%xmm2,%xmm2
	vpxor	%xmm15,%xmm3,%xmm3
.byte	143,232,120,194,192,12
.byte	143,232,120,194,201,12
.byte	143,232,120,194,210,12
.byte	143,232,120,194,219,12
	vpaddd	%xmm8,%xmm0,%xmm8
	vpaddd	%xmm9,%xmm1,%xmm9
	vpaddd	%xmm2,%xmm10,%xmm10
	vpaddd	%xmm3,%xmm11,%xmm11
	vpxor	%xmm4,%xmm8,%xmm4
	vpxor	%xmm5,%xmm9,%xmm5
	vpxor	%xmm6,%xmm10,%xmm6
	vpxor	%xmm7,%xmm11,%xmm7
.byte	143,232,120,194,228,8
.byte	143,232,120,194,237,8
.byte	143,232,120,194,246,8
.byte	143,232,120,194,255,8
	vpaddd	%xmm4,%xmm12,%xmm12
	vpaddd	%xmm5,%xmm13,%xmm13
	vpaddd	%xmm6,%xmm14,%xmm14
	vpaddd	%xmm7,%xmm15,%xmm15
	vpxor	%xmm0,%xmm12,%xmm0
	vpxor	%xmm1,%xmm13,%xmm1
	vpxor	%xmm14,%xmm2,%xmm2
	vpxor	%xmm15,%xmm3,%xmm3
.byte	143,232,120,194,192,7
.byte	143,232,120,194,201,7
.byte	143,232,120,194,210,7
.byte	143,232,120,194,219,7
	vpaddd	%xmm1,%xmm8,%xmm8
	vpaddd	%xmm2,%xmm9,%xmm9
	vpaddd	%xmm3,%xmm10,%xmm10
	vpaddd	%xmm0,%xmm11,%xmm11
	vpxor	%xmm7,%xmm8,%xmm7
	vpxor	%xmm4,%xmm9,%xmm4
	vpxor	%xmm5,%xmm10,%xmm5
	vpxor	%xmm6,%xmm11,%xmm6
.byte	143,232,120,194,255,16
.byte	143,232,120,194,228,16
.byte	143,232,120,194,237,16
.byte	143,232,120,194,246,16
	vpaddd	%xmm7,%xmm14,%xmm14
	vpaddd	%xmm4,%xmm15,%xmm15
	vpaddd	%xmm5,%xmm12,%xmm12
	vpaddd	%xmm6,%xmm13,%xmm13
	vpxor	%xmm1,%xmm14,%xmm1
	vpxor	%xmm2,%xmm15,%xmm2
	vpxor	%xmm12,%xmm3,%xmm3
	vpxor	%xmm13,%xmm0,%xmm0
.byte	143,232,120,194,201,12
.byte	143,232,120,194,210,12
.byte	143,232,120,194,219,12
.byte	143,232,120,194,192,12
	vpaddd	%xmm8,%xmm1,%xmm8
	vpaddd	%xmm9,%xmm2,%xmm9
	vpaddd	%xmm3,%xmm10,%xmm10
	vpaddd	%xmm0,%xmm11,%xmm11
	vpxor	%xmm7,%xmm8,%xmm7
	vpxor	%xmm4,%xmm9,%xmm4
	vpxor	%xmm5,%xmm10,%xmm5
	vpxor	%xmm6,%xmm11,%xmm6
.byte	143,232,120,194,255,8
.byte	143,232,120,194,228,8
.byte	143,232,120,194,237,8
.byte	143,232,120,194,246,8
	vpaddd	%xmm7,%xmm14,%xmm14
	vpaddd	%xmm4,%xmm15,%xmm15
	vpaddd	%xmm5,%xmm12,%xmm12
	vpaddd	%xmm6,%xmm13,%xmm13
	vpxor	%xmm1,%xmm14,%xmm1
	vpxor	%xmm2,%xmm15,%xmm2
	vpxor	%xmm12,%xmm3,%xmm3
	vpxor	%xmm13,%xmm0,%xmm0
.byte	143,232,120,194,201,7
.byte	143,232,120,194,210,7
.byte	143,232,120,194,219,7
.byte	143,232,120,194,192,7
	decl	%eax
	jnz	.Loop4xop

	vpaddd	64(%rsp),%xmm8,%xmm8
	vpaddd	80(%rsp),%xmm9,%xmm9
	vpaddd	96(%rsp),%xmm10,%xmm10
	vpaddd	112(%rsp),%xmm11,%xmm11

	vmovdqa	%xmm14,32(%rsp)
	vmovdqa	%xmm15,48(%rsp)

	vpunpckldq	%xmm9,%xmm8,%xmm14
	vpunpckldq	%xmm11,%xmm10,%xmm15
	vpunpckhdq	%xmm9,%xmm8,%xmm8
	vpunpckhdq	%xmm11,%xmm10,%xmm10
	vpunpcklqdq	%xmm15,%xmm14,%xmm9
	vpunpckhqdq	%xmm15,%xmm14,%xmm14
	vpunpcklqdq	%xmm10,%xmm8,%xmm11
	vpunpckhqdq	%xmm10,%xmm8,%xmm8
	vpaddd	128-256(%rcx),%xmm0,%xmm0
	vpaddd	144-256(%rcx),%xmm1,%xmm1
	vpaddd	160-256(%rcx),%xmm2,%xmm2
	vpaddd	176-256(%rcx),%xmm3,%xmm3

	vmovdqa	%xmm9,0(%rsp)
	vmovdqa	%xmm14,16(%rsp)
	vmovdqa	32(%rsp),%xmm9
	vmovdqa	48(%rsp),%xmm14

	vpunpckldq	%xmm1,%xmm0,%xmm10
	vpunpckldq	%xmm3,%xmm2,%xmm15
	vpunpckhdq	%xmm1,%xmm0,%xmm0
	vpunpckhdq	%xmm3,%xmm2,%xmm2
	vpunpcklqdq	%xmm15,%xmm10,%xmm1
	vpunpckhqdq	%xmm15,%xmm10,%xmm10
	vpunpcklqdq	%xmm2,%xmm0,%xmm3
	vpunpckhqdq	%xmm2,%xmm0,%xmm0
	vpaddd	192-256(%rcx),%xmm12,%xmm12
	vpaddd	208-256(%rcx),%xmm13,%xmm13
	vpaddd	224-256(%rcx),%xmm9,%xmm9
	vpaddd	240-256(%rcx),%xmm14,%xmm14

	vpunpckldq	%xmm13,%xmm12,%xmm2
	vpunpckldq	%xmm14,%xmm9,%xmm15
	vpunpckhdq	%xmm13,%xmm12,%xmm12
	vpunpckhdq	%xmm14,%xmm9,%xmm9
	vpunpcklqdq	%xmm15,%xmm2,%xmm13
	vpunpckhqdq	%xmm15,%xmm2,%xmm2
	vpunpcklqdq	%xmm9,%xmm12,%xmm14
	vpunpckhqdq	%xmm9,%xmm12,%xmm12
	vpaddd	256-256(%rcx),%xmm4,%xmm4
	vpaddd	272-256(%rcx),%xmm5,%xmm5
	vpaddd	288-256(%rcx),%xmm6,%xmm6
	vpaddd	304-256(%rcx),%xmm7,%xmm7

	vpunpckldq	%xmm5,%xmm4,%xmm9
	vpunpckldq	%xmm7,%xmm6,%xmm15
	vpunpckhdq	%xmm5,%xmm4,%xmm4
	vpunpckhdq	%xmm7,%xmm6,%xmm6
	vpunpcklqdq	%xmm15,%xmm9,%xmm5
	vpunpckhqdq	%xmm15,%xmm9,%xmm9
	vpunpcklqdq	%xmm6,%xmm4,%xmm7
	vpunpckhqdq	%xmm6,%xmm4,%xmm4
	vmovdqa	0(%rsp),%xmm6
	vmovdqa	16(%rsp),%xmm15

	cmpq	$256,%rdx
	jb	.Ltail4xop

	vpxor	0(%rsi),%xmm6,%xmm6
	vpxor	16(%rsi),%xmm1,%xmm1
	vpxor	32(%rsi),%xmm13,%xmm13
	vpxor	48(%rsi),%xmm5,%xmm5
	vpxor	64(%rsi),%xmm15,%xmm15
	vpxor	80(%rsi),%xmm10,%xmm10
	vpxor	96(%rsi),%xmm2,%xmm2
	vpxor	112(%rsi),%xmm9,%xmm9
	leaq	128(%rsi),%rsi
	vpxor	0(%rsi),%xmm11,%xmm11
	vpxor	16(%rsi),%xmm3,%xmm3
	vpxor	32(%rsi),%xmm14,%xmm14
	vpxor	48(%rsi),%xmm7,%xmm7
	vpxor	64(%rsi),%xmm8,%xmm8
	vpxor	80(%rsi),%xmm0,%xmm0
	vpxor	96(%rsi),%xmm12,%xmm12
	vpxor	112(%rsi),%xmm4,%xmm4
	leaq	128(%rsi),%rsi

	vmovdqu	%xmm6,0(%rdi)
	vmovdqu	%xmm1,16(%rdi)
	vmovdqu	%xmm13,32(%rdi)
	vmovdqu	%xmm5,48(%rdi)
	vmovdqu	%xmm15,64(%rdi)
	vmovdqu	%xmm10,80(%rdi)
	vmovdqu	%xmm2,96(%rdi)
	vmovdqu	%xmm9,112(%rdi)
	leaq	128(%rdi),%rdi
	vmovdqu	%xmm11,0(%rdi)
	vmovdqu	%xmm3,16(%rdi)
	vmovdqu	%xmm14,32(%rdi)
	vmovdqu	%xmm7,48(%rdi)
	vmovdqu	%xmm8,64(%rdi)
	vmovdqu	%xmm0,80(%rdi)
	vmovdqu	%xmm12,96(%rdi)
	vmovdqu	%xmm4,112(%rdi)
	leaq	128(%rdi),%rdi

	subq	$256,%rdx
	jnz	.Loop_outer4xop

	jmp	.Ldone4xop

.align	32
.Ltail4xop:
	cmpq	$192,%rdx
	jae	.L192_or_more4xop
	cmpq	$128,%rdx
	jae	.L128_or_more4xop
	cmpq	$64,%rdx
	jae	.L64_or_more4xop

	xorq	%r10,%r10
	vmovdqa	%xmm6,0(%rsp)
	vmovdqa	%xmm1,16(%rsp)
	vmovdqa	%xmm13,32(%rsp)
	vmovdqa	%xmm5,48(%rsp)
	jmp	.Loop_tail4xop

.align	32
.L64_or_more4xop:
	vpxor	0(%rsi),%xmm6,%xmm6
	vpxor	16(%rsi),%xmm1,%xmm1
	vpxor	32(%rsi),%xmm13,%xmm13
	vpxor	48(%rsi),%xmm5,%xmm5
	vmovdqu	%xmm6,0(%rdi)
	vmovdqu	%xmm1,16(%rdi)
	vmovdqu	%xmm13,32(%rdi)
	vmovdqu	%xmm5,48(%rdi)
	je	.Ldone4xop

	leaq	64(%rsi),%rsi
	vmovdqa	%xmm15,0(%rsp)
	xorq	%r10,%r10
	vmovdqa	%xmm10,16(%rsp)
	leaq	64(%rdi),%rdi
	vmovdqa	%xmm2,32(%rsp)
	subq	$64,%rdx
	vmovdqa	%xmm9,48(%rsp)
	jmp	.Loop_tail4xop

.align	32
.L128_or_more4xop:
	vpxor	0(%rsi),%xmm6,%xmm6
	vpxor	16(%rsi),%xmm1,%xmm1
	vpxor	32(%rsi),%xmm13,%xmm13
	vpxor	48(%rsi),%xmm5,%xmm5
	vpxor	64(%rsi),%xmm15,%xmm15
	vpxor	80(%rsi),%xmm10,%xmm10
	vpxor	96(%rsi),%xmm2,%xmm2
	vpxor	112(%rsi),%xmm9,%xmm9

	vmovdqu	%xmm6,0(%rdi)
	vmovdqu	%xmm1,16(%rdi)
	vmovdqu	%xmm13,32(%rdi)
	vmovdqu	%xmm5,48(%rdi)
	vmovdqu	%xmm15,64(%rdi)
	vmovdqu	%xmm10,80(%rdi)
	vmovdqu	%xmm2,96(%rdi)
	vmovdqu	%xmm9,112(%rdi)
	je	.Ldone4xop

	leaq	128(%rsi),%rsi
	vmovdqa	%xmm11,0(%rsp)
	xorq	%r10,%r10
	vmovdqa	%xmm3,16(%rsp)
	leaq	128(%rdi),%rdi
	vmovdqa	%xmm14,32(%rsp)
	subq	$128,%rdx
	vmovdqa	%xmm7,48(%rsp)
	jmp	.Loop_tail4xop

.align	32
.L192_or_more4xop:
	vpxor	0(%rsi),%xmm6,%xmm6
	vpxor	16(%rsi),%xmm1,%xmm1
	vpxor	32(%rsi),%xmm13,%xmm13
	vpxor	48(%rsi),%xmm5,%xmm5
	vpxor	64(%rsi),%xmm15,%xmm15
	vpxor	80(%rsi),%xmm10,%xmm10
	vpxor	96(%rsi),%xmm2,%xmm2
	vpxor	112(%rsi),%xmm9,%xmm9
	leaq	128(%rsi),%rsi
	vpxor	0(%rsi),%xmm11,%xmm11
	vpxor	16(%rsi),%xmm3,%xmm3
	vpxor	32(%rsi),%xmm14,%xmm14
	vpxor	48(%rsi),%xmm7,%xmm7

	vmovdqu	%xmm6,0(%rdi)
	vmovdqu	%xmm1,16(%rdi)
	vmovdqu	%xmm13,32(%rdi)
	vmovdqu	%xmm5,48(%rdi)
	vmovdqu	%xmm15,64(%rdi)
	vmovdqu	%xmm10,80(%rdi)
	vmovdqu	%xmm2,96(%rdi)
	vmovdqu	%xmm9,112(%rdi)
	leaq	128(%rdi),%rdi
	vmovdqu	%xmm11,0(%rdi)
	vmovdqu	%xmm3,16(%rdi)
	vmovdqu	%xmm14,32(%rdi)
	vmovdqu	%xmm7,48(%rdi)
	je	.Ldone4xop

	leaq	64(%rsi),%rsi
	vmovdqa	%xmm8,0(%rsp)
	xorq	%r10,%r10
	vmovdqa	%xmm0,16(%rsp)
	leaq	64(%rdi),%rdi
	vmovdqa	%xmm12,32(%rsp)
	subq	$192,%rdx
	vmovdqa	%xmm4,48(%rsp)

.Loop_tail4xop:
	movzbl	(%rsi,%r10,1),%eax
	movzbl	(%rsp,%r10,1),%ecx
	leaq	1(%r10),%r10
	xorl	%ecx,%eax
	movb	%al,-1(%rdi,%r10,1)
	decq	%rdx
	jnz	.Loop_tail4xop

.Ldone4xop:
	vzeroupper
	leaq	(%r9),%rsp
.cfi_def_cfa_register	%rsp
.L4xop_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	ChaCha20_4xop,.-ChaCha20_4xop
.type	ChaCha20_8x,@function
.align	32
ChaCha20_8x:
.cfi_startproc	
.LChaCha20_8x:
	movq	%rsp,%r9
.cfi_def_cfa_register	%r9
	subq	$0x280+8,%rsp
	andq	$-32,%rsp
	vzeroupper










	vbroadcasti128	.Lsigma(%rip),%ymm11
	vbroadcasti128	(%rcx),%ymm3
	vbroadcasti128	16(%rcx),%ymm15
	vbroadcasti128	(%r8),%ymm7
	leaq	256(%rsp),%rcx
	leaq	512(%rsp),%rax
	leaq	.Lrot16(%rip),%r10
	leaq	.Lrot24(%rip),%r11

	vpshufd	$0x00,%ymm11,%ymm8
	vpshufd	$0x55,%ymm11,%ymm9
	vmovdqa	%ymm8,128-256(%rcx)
	vpshufd	$0xaa,%ymm11,%ymm10
	vmovdqa	%ymm9,160-256(%rcx)
	vpshufd	$0xff,%ymm11,%ymm11
	vmovdqa	%ymm10,192-256(%rcx)
	vmovdqa	%ymm11,224-256(%rcx)

	vpshufd	$0x00,%ymm3,%ymm0
	vpshufd	$0x55,%ymm3,%ymm1
	vmovdqa	%ymm0,256-256(%rcx)
	vpshufd	$0xaa,%ymm3,%ymm2
	vmovdqa	%ymm1,288-256(%rcx)
	vpshufd	$0xff,%ymm3,%ymm3
	vmovdqa	%ymm2,320-256(%rcx)
	vmovdqa	%ymm3,352-256(%rcx)

	vpshufd	$0x00,%ymm15,%ymm12
	vpshufd	$0x55,%ymm15,%ymm13
	vmovdqa	%ymm12,384-512(%rax)
	vpshufd	$0xaa,%ymm15,%ymm14
	vmovdqa	%ymm13,416-512(%rax)
	vpshufd	$0xff,%ymm15,%ymm15
	vmovdqa	%ymm14,448-512(%rax)
	vmovdqa	%ymm15,480-512(%rax)

	vpshufd	$0x00,%ymm7,%ymm4
	vpshufd	$0x55,%ymm7,%ymm5
	vpaddd	.Lincy(%rip),%ymm4,%ymm4
	vpshufd	$0xaa,%ymm7,%ymm6
	vmovdqa	%ymm5,544-512(%rax)
	vpshufd	$0xff,%ymm7,%ymm7
	vmovdqa	%ymm6,576-512(%rax)
	vmovdqa	%ymm7,608-512(%rax)

	jmp	.Loop_enter8x

.align	32
.Loop_outer8x:
	vmovdqa	128-256(%rcx),%ymm8
	vmovdqa	160-256(%rcx),%ymm9
	vmovdqa	192-256(%rcx),%ymm10
	vmovdqa	224-256(%rcx),%ymm11
	vmovdqa	256-256(%rcx),%ymm0
	vmovdqa	288-256(%rcx),%ymm1
	vmovdqa	320-256(%rcx),%ymm2
	vmovdqa	352-256(%rcx),%ymm3
	vmovdqa	384-512(%rax),%ymm12
	vmovdqa	416-512(%rax),%ymm13
	vmovdqa	448-512(%rax),%ymm14
	vmovdqa	480-512(%rax),%ymm15
	vmovdqa	512-512(%rax),%ymm4
	vmovdqa	544-512(%rax),%ymm5
	vmovdqa	576-512(%rax),%ymm6
	vmovdqa	608-512(%rax),%ymm7
	vpaddd	.Leight(%rip),%ymm4,%ymm4

.Loop_enter8x:
	vmovdqa	%ymm14,64(%rsp)
	vmovdqa	%ymm15,96(%rsp)
	vbroadcasti128	(%r10),%ymm15
	vmovdqa	%ymm4,512-512(%rax)
	movl	$10,%eax
	jmp	.Loop8x

.align	32
.Loop8x:
	vpaddd	%ymm0,%ymm8,%ymm8
	vpxor	%ymm4,%ymm8,%ymm4
	vpshufb	%ymm15,%ymm4,%ymm4
	vpaddd	%ymm1,%ymm9,%ymm9
	vpxor	%ymm5,%ymm9,%ymm5
	vpshufb	%ymm15,%ymm5,%ymm5
	vpaddd	%ymm4,%ymm12,%ymm12
	vpxor	%ymm0,%ymm12,%ymm0
	vpslld	$12,%ymm0,%ymm14
	vpsrld	$20,%ymm0,%ymm0
	vpor	%ymm0,%ymm14,%ymm0
	vbroadcasti128	(%r11),%ymm14
	vpaddd	%ymm5,%ymm13,%ymm13
	vpxor	%ymm1,%ymm13,%ymm1
	vpslld	$12,%ymm1,%ymm15
	vpsrld	$20,%ymm1,%ymm1
	vpor	%ymm1,%ymm15,%ymm1
	vpaddd	%ymm0,%ymm8,%ymm8
	vpxor	%ymm4,%ymm8,%ymm4
	vpshufb	%ymm14,%ymm4,%ymm4
	vpaddd	%ymm1,%ymm9,%ymm9
	vpxor	%ymm5,%ymm9,%ymm5
	vpshufb	%ymm14,%ymm5,%ymm5
	vpaddd	%ymm4,%ymm12,%ymm12
	vpxor	%ymm0,%ymm12,%ymm0
	vpslld	$7,%ymm0,%ymm15
	vpsrld	$25,%ymm0,%ymm0
	vpor	%ymm0,%ymm15,%ymm0
	vbroadcasti128	(%r10),%ymm15
	vpaddd	%ymm5,%ymm13,%ymm13
	vpxor	%ymm1,%ymm13,%ymm1
	vpslld	$7,%ymm1,%ymm14
	vpsrld	$25,%ymm1,%ymm1
	vpor	%ymm1,%ymm14,%ymm1
	vmovdqa	%ymm12,0(%rsp)
	vmovdqa	%ymm13,32(%rsp)
	vmovdqa	64(%rsp),%ymm12
	vmovdqa	96(%rsp),%ymm13
	vpaddd	%ymm2,%ymm10,%ymm10
	vpxor	%ymm6,%ymm10,%ymm6
	vpshufb	%ymm15,%ymm6,%ymm6
	vpaddd	%ymm3,%ymm11,%ymm11
	vpxor	%ymm7,%ymm11,%ymm7
	vpshufb	%ymm15,%ymm7,%ymm7
	vpaddd	%ymm6,%ymm12,%ymm12
	vpxor	%ymm2,%ymm12,%ymm2
	vpslld	$12,%ymm2,%ymm14
	vpsrld	$20,%ymm2,%ymm2
	vpor	%ymm2,%ymm14,%ymm2
	vbroadcasti128	(%r11),%ymm14
	vpaddd	%ymm7,%ymm13,%ymm13
	vpxor	%ymm3,%ymm13,%ymm3
	vpslld	$12,%ymm3,%ymm15
	vpsrld	$20,%ymm3,%ymm3
	vpor	%ymm3,%ymm15,%ymm3
	vpaddd	%ymm2,%ymm10,%ymm10
	vpxor	%ymm6,%ymm10,%ymm6
	vpshufb	%ymm14,%ymm6,%ymm6
	vpaddd	%ymm3,%ymm11,%ymm11
	vpxor	%ymm7,%ymm11,%ymm7
	vpshufb	%ymm14,%ymm7,%ymm7
	vpaddd	%ymm6,%ymm12,%ymm12
	vpxor	%ymm2,%ymm12,%ymm2
	vpslld	$7,%ymm2,%ymm15
	vpsrld	$25,%ymm2,%ymm2
	vpor	%ymm2,%ymm15,%ymm2
	vbroadcasti128	(%r10),%ymm15
	vpaddd	%ymm7,%ymm13,%ymm13
	vpxor	%ymm3,%ymm13,%ymm3
	vpslld	$7,%ymm3,%ymm14
	vpsrld	$25,%ymm3,%ymm3
	vpor	%ymm3,%ymm14,%ymm3
	vpaddd	%ymm1,%ymm8,%ymm8
	vpxor	%ymm7,%ymm8,%ymm7
	vpshufb	%ymm15,%ymm7,%ymm7
	vpaddd	%ymm2,%ymm9,%ymm9
	vpxor	%ymm4,%ymm9,%ymm4
	vpshufb	%ymm15,%ymm4,%ymm4
	vpaddd	%ymm7,%ymm12,%ymm12
	vpxor	%ymm1,%ymm12,%ymm1
	vpslld	$12,%ymm1,%ymm14
	vpsrld	$20,%ymm1,%ymm1
	vpor	%ymm1,%ymm14,%ymm1
	vbroadcasti128	(%r11),%ymm14
	vpaddd	%ymm4,%ymm13,%ymm13
	vpxor	%ymm2,%ymm13,%ymm2
	vpslld	$12,%ymm2,%ymm15
	vpsrld	$20,%ymm2,%ymm2
	vpor	%ymm2,%ymm15,%ymm2
	vpaddd	%ymm1,%ymm8,%ymm8
	vpxor	%ymm7,%ymm8,%ymm7
	vpshufb	%ymm14,%ymm7,%ymm7
	vpaddd	%ymm2,%ymm9,%ymm9
	vpxor	%ymm4,%ymm9,%ymm4
	vpshufb	%ymm14,%ymm4,%ymm4
	vpaddd	%ymm7,%ymm12,%ymm12
	vpxor	%ymm1,%ymm12,%ymm1
	vpslld	$7,%ymm1,%ymm15
	vpsrld	$25,%ymm1,%ymm1
	vpor	%ymm1,%ymm15,%ymm1
	vbroadcasti128	(%r10),%ymm15
	vpaddd	%ymm4,%ymm13,%ymm13
	vpxor	%ymm2,%ymm13,%ymm2
	vpslld	$7,%ymm2,%ymm14
	vpsrld	$25,%ymm2,%ymm2
	vpor	%ymm2,%ymm14,%ymm2
	vmovdqa	%ymm12,64(%rsp)
	vmovdqa	%ymm13,96(%rsp)
	vmovdqa	0(%rsp),%ymm12
	vmovdqa	32(%rsp),%ymm13
	vpaddd	%ymm3,%ymm10,%ymm10
	vpxor	%ymm5,%ymm10,%ymm5
	vpshufb	%ymm15,%ymm5,%ymm5
	vpaddd	%ymm0,%ymm11,%ymm11
	vpxor	%ymm6,%ymm11,%ymm6
	vpshufb	%ymm15,%ymm6,%ymm6
	vpaddd	%ymm5,%ymm12,%ymm12
	vpxor	%ymm3,%ymm12,%ymm3
	vpslld	$12,%ymm3,%ymm14
	vpsrld	$20,%ymm3,%ymm3
	vpor	%ymm3,%ymm14,%ymm3
	vbroadcasti128	(%r11),%ymm14
	vpaddd	%ymm6,%ymm13,%ymm13
	vpxor	%ymm0,%ymm13,%ymm0
	vpslld	$12,%ymm0,%ymm15
	vpsrld	$20,%ymm0,%ymm0
	vpor	%ymm0,%ymm15,%ymm0
	vpaddd	%ymm3,%ymm10,%ymm10
	vpxor	%ymm5,%ymm10,%ymm5
	vpshufb	%ymm14,%ymm5,%ymm5
	vpaddd	%ymm0,%ymm11,%ymm11
	vpxor	%ymm6,%ymm11,%ymm6
	vpshufb	%ymm14,%ymm6,%ymm6
	vpaddd	%ymm5,%ymm12,%ymm12
	vpxor	%ymm3,%ymm12,%ymm3
	vpslld	$7,%ymm3,%ymm15
	vpsrld	$25,%ymm3,%ymm3
	vpor	%ymm3,%ymm15,%ymm3
	vbroadcasti128	(%r10),%ymm15
	vpaddd	%ymm6,%ymm13,%ymm13
	vpxor	%ymm0,%ymm13,%ymm0
	vpslld	$7,%ymm0,%ymm14
	vpsrld	$25,%ymm0,%ymm0
	vpor	%ymm0,%ymm14,%ymm0
	decl	%eax
	jnz	.Loop8x

	leaq	512(%rsp),%rax
	vpaddd	128-256(%rcx),%ymm8,%ymm8
	vpaddd	160-256(%rcx),%ymm9,%ymm9
	vpaddd	192-256(%rcx),%ymm10,%ymm10
	vpaddd	224-256(%rcx),%ymm11,%ymm11

	vpunpckldq	%ymm9,%ymm8,%ymm14
	vpunpckldq	%ymm11,%ymm10,%ymm15
	vpunpckhdq	%ymm9,%ymm8,%ymm8
	vpunpckhdq	%ymm11,%ymm10,%ymm10
	vpunpcklqdq	%ymm15,%ymm14,%ymm9
	vpunpckhqdq	%ymm15,%ymm14,%ymm14
	vpunpcklqdq	%ymm10,%ymm8,%ymm11
	vpunpckhqdq	%ymm10,%ymm8,%ymm8
	vpaddd	256-256(%rcx),%ymm0,%ymm0
	vpaddd	288-256(%rcx),%ymm1,%ymm1
	vpaddd	320-256(%rcx),%ymm2,%ymm2
	vpaddd	352-256(%rcx),%ymm3,%ymm3

	vpunpckldq	%ymm1,%ymm0,%ymm10
	vpunpckldq	%ymm3,%ymm2,%ymm15
	vpunpckhdq	%ymm1,%ymm0,%ymm0
	vpunpckhdq	%ymm3,%ymm2,%ymm2
	vpunpcklqdq	%ymm15,%ymm10,%ymm1
	vpunpckhqdq	%ymm15,%ymm10,%ymm10
	vpunpcklqdq	%ymm2,%ymm0,%ymm3
	vpunpckhqdq	%ymm2,%ymm0,%ymm0
	vperm2i128	$0x20,%ymm1,%ymm9,%ymm15
	vperm2i128	$0x31,%ymm1,%ymm9,%ymm1
	vperm2i128	$0x20,%ymm10,%ymm14,%ymm9
	vperm2i128	$0x31,%ymm10,%ymm14,%ymm10
	vperm2i128	$0x20,%ymm3,%ymm11,%ymm14
	vperm2i128	$0x31,%ymm3,%ymm11,%ymm3
	vperm2i128	$0x20,%ymm0,%ymm8,%ymm11
	vperm2i128	$0x31,%ymm0,%ymm8,%ymm0
	vmovdqa	%ymm15,0(%rsp)
	vmovdqa	%ymm9,32(%rsp)
	vmovdqa	64(%rsp),%ymm15
	vmovdqa	96(%rsp),%ymm9

	vpaddd	384-512(%rax),%ymm12,%ymm12
	vpaddd	416-512(%rax),%ymm13,%ymm13
	vpaddd	448-512(%rax),%ymm15,%ymm15
	vpaddd	480-512(%rax),%ymm9,%ymm9

	vpunpckldq	%ymm13,%ymm12,%ymm2
	vpunpckldq	%ymm9,%ymm15,%ymm8
	vpunpckhdq	%ymm13,%ymm12,%ymm12
	vpunpckhdq	%ymm9,%ymm15,%ymm15
	vpunpcklqdq	%ymm8,%ymm2,%ymm13
	vpunpckhqdq	%ymm8,%ymm2,%ymm2
	vpunpcklqdq	%ymm15,%ymm12,%ymm9
	vpunpckhqdq	%ymm15,%ymm12,%ymm12
	vpaddd	512-512(%rax),%ymm4,%ymm4
	vpaddd	544-512(%rax),%ymm5,%ymm5
	vpaddd	576-512(%rax),%ymm6,%ymm6
	vpaddd	608-512(%rax),%ymm7,%ymm7

	vpunpckldq	%ymm5,%ymm4,%ymm15
	vpunpckldq	%ymm7,%ymm6,%ymm8
	vpunpckhdq	%ymm5,%ymm4,%ymm4
	vpunpckhdq	%ymm7,%ymm6,%ymm6
	vpunpcklqdq	%ymm8,%ymm15,%ymm5
	vpunpckhqdq	%ymm8,%ymm15,%ymm15
	vpunpcklqdq	%ymm6,%ymm4,%ymm7
	vpunpckhqdq	%ymm6,%ymm4,%ymm4
	vperm2i128	$0x20,%ymm5,%ymm13,%ymm8
	vperm2i128	$0x31,%ymm5,%ymm13,%ymm5
	vperm2i128	$0x20,%ymm15,%ymm2,%ymm13
	vperm2i128	$0x31,%ymm15,%ymm2,%ymm15
	vperm2i128	$0x20,%ymm7,%ymm9,%ymm2
	vperm2i128	$0x31,%ymm7,%ymm9,%ymm7
	vperm2i128	$0x20,%ymm4,%ymm12,%ymm9
	vperm2i128	$0x31,%ymm4,%ymm12,%ymm4
	vmovdqa	0(%rsp),%ymm6
	vmovdqa	32(%rsp),%ymm12

	cmpq	$512,%rdx
	jb	.Ltail8x

	vpxor	0(%rsi),%ymm6,%ymm6
	vpxor	32(%rsi),%ymm8,%ymm8
	vpxor	64(%rsi),%ymm1,%ymm1
	vpxor	96(%rsi),%ymm5,%ymm5
	leaq	128(%rsi),%rsi
	vmovdqu	%ymm6,0(%rdi)
	vmovdqu	%ymm8,32(%rdi)
	vmovdqu	%ymm1,64(%rdi)
	vmovdqu	%ymm5,96(%rdi)
	leaq	128(%rdi),%rdi

	vpxor	0(%rsi),%ymm12,%ymm12
	vpxor	32(%rsi),%ymm13,%ymm13
	vpxor	64(%rsi),%ymm10,%ymm10
	vpxor	96(%rsi),%ymm15,%ymm15
	leaq	128(%rsi),%rsi
	vmovdqu	%ymm12,0(%rdi)
	vmovdqu	%ymm13,32(%rdi)
	vmovdqu	%ymm10,64(%rdi)
	vmovdqu	%ymm15,96(%rdi)
	leaq	128(%rdi),%rdi

	vpxor	0(%rsi),%ymm14,%ymm14
	vpxor	32(%rsi),%ymm2,%ymm2
	vpxor	64(%rsi),%ymm3,%ymm3
	vpxor	96(%rsi),%ymm7,%ymm7
	leaq	128(%rsi),%rsi
	vmovdqu	%ymm14,0(%rdi)
	vmovdqu	%ymm2,32(%rdi)
	vmovdqu	%ymm3,64(%rdi)
	vmovdqu	%ymm7,96(%rdi)
	leaq	128(%rdi),%rdi

	vpxor	0(%rsi),%ymm11,%ymm11
	vpxor	32(%rsi),%ymm9,%ymm9
	vpxor	64(%rsi),%ymm0,%ymm0
	vpxor	96(%rsi),%ymm4,%ymm4
	leaq	128(%rsi),%rsi
	vmovdqu	%ymm11,0(%rdi)
	vmovdqu	%ymm9,32(%rdi)
	vmovdqu	%ymm0,64(%rdi)
	vmovdqu	%ymm4,96(%rdi)
	leaq	128(%rdi),%rdi

	subq	$512,%rdx
	jnz	.Loop_outer8x

	jmp	.Ldone8x

.Ltail8x:
	cmpq	$448,%rdx
	jae	.L448_or_more8x
	cmpq	$384,%rdx
	jae	.L384_or_more8x
	cmpq	$320,%rdx
	jae	.L320_or_more8x
	cmpq	$256,%rdx
	jae	.L256_or_more8x
	cmpq	$192,%rdx
	jae	.L192_or_more8x
	cmpq	$128,%rdx
	jae	.L128_or_more8x
	cmpq	$64,%rdx
	jae	.L64_or_more8x

	xorq	%r10,%r10
	vmovdqa	%ymm6,0(%rsp)
	vmovdqa	%ymm8,32(%rsp)
	jmp	.Loop_tail8x

.align	32
.L64_or_more8x:
	vpxor	0(%rsi),%ymm6,%ymm6
	vpxor	32(%rsi),%ymm8,%ymm8
	vmovdqu	%ymm6,0(%rdi)
	vmovdqu	%ymm8,32(%rdi)
	je	.Ldone8x

	leaq	64(%rsi),%rsi
	xorq	%r10,%r10
	vmovdqa	%ymm1,0(%rsp)
	leaq	64(%rdi),%rdi
	subq	$64,%rdx
	vmovdqa	%ymm5,32(%rsp)
	jmp	.Loop_tail8x

.align	32
.L128_or_more8x:
	vpxor	0(%rsi),%ymm6,%ymm6
	vpxor	32(%rsi),%ymm8,%ymm8
	vpxor	64(%rsi),%ymm1,%ymm1
	vpxor	96(%rsi),%ymm5,%ymm5
	vmovdqu	%ymm6,0(%rdi)
	vmovdqu	%ymm8,32(%rdi)
	vmovdqu	%ymm1,64(%rdi)
	vmovdqu	%ymm5,96(%rdi)
	je	.Ldone8x

	leaq	128(%rsi),%rsi
	xorq	%r10,%r10
	vmovdqa	%ymm12,0(%rsp)
	leaq	128(%rdi),%rdi
	subq	$128,%rdx
	vmovdqa	%ymm13,32(%rsp)
	jmp	.Loop_tail8x

.align	32
.L192_or_more8x:
	vpxor	0(%rsi),%ymm6,%ymm6
	vpxor	32(%rsi),%ymm8,%ymm8
	vpxor	64(%rsi),%ymm1,%ymm1
	vpxor	96(%rsi),%ymm5,%ymm5
	vpxor	128(%rsi),%ymm12,%ymm12
	vpxor	160(%rsi),%ymm13,%ymm13
	vmovdqu	%ymm6,0(%rdi)
	vmovdqu	%ymm8,32(%rdi)
	vmovdqu	%ymm1,64(%rdi)
	vmovdqu	%ymm5,96(%rdi)
	vmovdqu	%ymm12,128(%rdi)
	vmovdqu	%ymm13,160(%rdi)
	je	.Ldone8x

	leaq	192(%rsi),%rsi
	xorq	%r10,%r10
	vmovdqa	%ymm10,0(%rsp)
	leaq	192(%rdi),%rdi
	subq	$192,%rdx
	vmovdqa	%ymm15,32(%rsp)
	jmp	.Loop_tail8x

.align	32
.L256_or_more8x:
	vpxor	0(%rsi),%ymm6,%ymm6
	vpxor	32(%rsi),%ymm8,%ymm8
	vpxor	64(%rsi),%ymm1,%ymm1
	vpxor	96(%rsi),%ymm5,%ymm5
	vpxor	128(%rsi),%ymm12,%ymm12
	vpxor	160(%rsi),%ymm13,%ymm13
	vpxor	192(%rsi),%ymm10,%ymm10
	vpxor	224(%rsi),%ymm15,%ymm15
	vmovdqu	%ymm6,0(%rdi)
	vmovdqu	%ymm8,32(%rdi)
	vmovdqu	%ymm1,64(%rdi)
	vmovdqu	%ymm5,96(%rdi)
	vmovdqu	%ymm12,128(%rdi)
	vmovdqu	%ymm13,160(%rdi)
	vmovdqu	%ymm10,192(%rdi)
	vmovdqu	%ymm15,224(%rdi)
	je	.Ldone8x

	leaq	256(%rsi),%rsi
	xorq	%r10,%r10
	vmovdqa	%ymm14,0(%rsp)
	leaq	256(%rdi),%rdi
	subq	$256,%rdx
	vmovdqa	%ymm2,32(%rsp)
	jmp	.Loop_tail8x

.align	32
.L320_or_more8x:
	vpxor	0(%rsi),%ymm6,%ymm6
	vpxor	32(%rsi),%ymm8,%ymm8
	vpxor	64(%rsi),%ymm1,%ymm1
	vpxor	96(%rsi),%ymm5,%ymm5
	vpxor	128(%rsi),%ymm12,%ymm12
	vpxor	160(%rsi),%ymm13,%ymm13
	vpxor	192(%rsi),%ymm10,%ymm10
	vpxor	224(%rsi),%ymm15,%ymm15
	vpxor	256(%rsi),%ymm14,%ymm14
	vpxor	288(%rsi),%ymm2,%ymm2
	vmovdqu	%ymm6,0(%rdi)
	vmovdqu	%ymm8,32(%rdi)
	vmovdqu	%ymm1,64(%rdi)
	vmovdqu	%ymm5,96(%rdi)
	vmovdqu	%ymm12,128(%rdi)
	vmovdqu	%ymm13,160(%rdi)
	vmovdqu	%ymm10,192(%rdi)
	vmovdqu	%ymm15,224(%rdi)
	vmovdqu	%ymm14,256(%rdi)
	vmovdqu	%ymm2,288(%rdi)
	je	.Ldone8x

	leaq	320(%rsi),%rsi
	xorq	%r10,%r10
	vmovdqa	%ymm3,0(%rsp)
	leaq	320(%rdi),%rdi
	subq	$320,%rdx
	vmovdqa	%ymm7,32(%rsp)
	jmp	.Loop_tail8x

.align	32
.L384_or_more8x:
	vpxor	0(%rsi),%ymm6,%ymm6
	vpxor	32(%rsi),%ymm8,%ymm8
	vpxor	64(%rsi),%ymm1,%ymm1
	vpxor	96(%rsi),%ymm5,%ymm5
	vpxor	128(%rsi),%ymm12,%ymm12
	vpxor	160(%rsi),%ymm13,%ymm13
	vpxor	192(%rsi),%ymm10,%ymm10
	vpxor	224(%rsi),%ymm15,%ymm15
	vpxor	256(%rsi),%ymm14,%ymm14
	vpxor	288(%rsi),%ymm2,%ymm2
	vpxor	320(%rsi),%ymm3,%ymm3
	vpxor	352(%rsi),%ymm7,%ymm7
	vmovdqu	%ymm6,0(%rdi)
	vmovdqu	%ymm8,32(%rdi)
	vmovdqu	%ymm1,64(%rdi)
	vmovdqu	%ymm5,96(%rdi)
	vmovdqu	%ymm12,128(%rdi)
	vmovdqu	%ymm13,160(%rdi)
	vmovdqu	%ymm10,192(%rdi)
	vmovdqu	%ymm15,224(%rdi)
	vmovdqu	%ymm14,256(%rdi)
	vmovdqu	%ymm2,288(%rdi)
	vmovdqu	%ymm3,320(%rdi)
	vmovdqu	%ymm7,352(%rdi)
	je	.Ldone8x

	leaq	384(%rsi),%rsi
	xorq	%r10,%r10
	vmovdqa	%ymm11,0(%rsp)
	leaq	384(%rdi),%rdi
	subq	$384,%rdx
	vmovdqa	%ymm9,32(%rsp)
	jmp	.Loop_tail8x

.align	32
.L448_or_more8x:
	vpxor	0(%rsi),%ymm6,%ymm6
	vpxor	32(%rsi),%ymm8,%ymm8
	vpxor	64(%rsi),%ymm1,%ymm1
	vpxor	96(%rsi),%ymm5,%ymm5
	vpxor	128(%rsi),%ymm12,%ymm12
	vpxor	160(%rsi),%ymm13,%ymm13
	vpxor	192(%rsi),%ymm10,%ymm10
	vpxor	224(%rsi),%ymm15,%ymm15
	vpxor	256(%rsi),%ymm14,%ymm14
	vpxor	288(%rsi),%ymm2,%ymm2
	vpxor	320(%rsi),%ymm3,%ymm3
	vpxor	352(%rsi),%ymm7,%ymm7
	vpxor	384(%rsi),%ymm11,%ymm11
	vpxor	416(%rsi),%ymm9,%ymm9
	vmovdqu	%ymm6,0(%rdi)
	vmovdqu	%ymm8,32(%rdi)
	vmovdqu	%ymm1,64(%rdi)
	vmovdqu	%ymm5,96(%rdi)
	vmovdqu	%ymm12,128(%rdi)
	vmovdqu	%ymm13,160(%rdi)
	vmovdqu	%ymm10,192(%rdi)
	vmovdqu	%ymm15,224(%rdi)
	vmovdqu	%ymm14,256(%rdi)
	vmovdqu	%ymm2,288(%rdi)
	vmovdqu	%ymm3,320(%rdi)
	vmovdqu	%ymm7,352(%rdi)
	vmovdqu	%ymm11,384(%rdi)
	vmovdqu	%ymm9,416(%rdi)
	je	.Ldone8x

	leaq	448(%rsi),%rsi
	xorq	%r10,%r10
	vmovdqa	%ymm0,0(%rsp)
	leaq	448(%rdi),%rdi
	subq	$448,%rdx
	vmovdqa	%ymm4,32(%rsp)

.Loop_tail8x:
	movzbl	(%rsi,%r10,1),%eax
	movzbl	(%rsp,%r10,1),%ecx
	leaq	1(%r10),%r10
	xorl	%ecx,%eax
	movb	%al,-1(%rdi,%r10,1)
	decq	%rdx
	jnz	.Loop_tail8x

.Ldone8x:
	vzeroall
	leaq	(%r9),%rsp
.cfi_def_cfa_register	%rsp
.L8x_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	ChaCha20_8x,.-ChaCha20_8x
.type	ChaCha20_avx512,@function
.align	32
ChaCha20_avx512:
.cfi_startproc	
.LChaCha20_avx512:
	movq	%rsp,%r9
.cfi_def_cfa_register	%r9
	cmpq	$512,%rdx
	ja	.LChaCha20_16x

	subq	$64+8,%rsp
	vbroadcasti32x4	.Lsigma(%rip),%zmm0
	vbroadcasti32x4	(%rcx),%zmm1
	vbroadcasti32x4	16(%rcx),%zmm2
	vbroadcasti32x4	(%r8),%zmm3

	vmovdqa32	%zmm0,%zmm16
	vmovdqa32	%zmm1,%zmm17
	vmovdqa32	%zmm2,%zmm18
	vpaddd	.Lzeroz(%rip),%zmm3,%zmm3
	vmovdqa32	.Lfourz(%rip),%zmm20
	movq	$10,%r8
	vmovdqa32	%zmm3,%zmm19
	jmp	.Loop_avx512

.align	16
.Loop_outer_avx512:
	vmovdqa32	%zmm16,%zmm0
	vmovdqa32	%zmm17,%zmm1
	vmovdqa32	%zmm18,%zmm2
	vpaddd	%zmm20,%zmm19,%zmm3
	movq	$10,%r8
	vmovdqa32	%zmm3,%zmm19
	jmp	.Loop_avx512

.align	32
.Loop_avx512:
	vpaddd	%zmm1,%zmm0,%zmm0
	vpxord	%zmm0,%zmm3,%zmm3
	vprold	$16,%zmm3,%zmm3
	vpaddd	%zmm3,%zmm2,%zmm2
	vpxord	%zmm2,%zmm1,%zmm1
	vprold	$12,%zmm1,%zmm1
	vpaddd	%zmm1,%zmm0,%zmm0
	vpxord	%zmm0,%zmm3,%zmm3
	vprold	$8,%zmm3,%zmm3
	vpaddd	%zmm3,%zmm2,%zmm2
	vpxord	%zmm2,%zmm1,%zmm1
	vprold	$7,%zmm1,%zmm1
	vpshufd	$78,%zmm2,%zmm2
	vpshufd	$57,%zmm1,%zmm1
	vpshufd	$147,%zmm3,%zmm3
	vpaddd	%zmm1,%zmm0,%zmm0
	vpxord	%zmm0,%zmm3,%zmm3
	vprold	$16,%zmm3,%zmm3
	vpaddd	%zmm3,%zmm2,%zmm2
	vpxord	%zmm2,%zmm1,%zmm1
	vprold	$12,%zmm1,%zmm1
	vpaddd	%zmm1,%zmm0,%zmm0
	vpxord	%zmm0,%zmm3,%zmm3
	vprold	$8,%zmm3,%zmm3
	vpaddd	%zmm3,%zmm2,%zmm2
	vpxord	%zmm2,%zmm1,%zmm1
	vprold	$7,%zmm1,%zmm1
	vpshufd	$78,%zmm2,%zmm2
	vpshufd	$147,%zmm1,%zmm1
	vpshufd	$57,%zmm3,%zmm3
	decq	%r8
	jnz	.Loop_avx512
	vpaddd	%zmm16,%zmm0,%zmm0
	vpaddd	%zmm17,%zmm1,%zmm1
	vpaddd	%zmm18,%zmm2,%zmm2
	vpaddd	%zmm19,%zmm3,%zmm3

	subq	$64,%rdx
	jb	.Ltail64_avx512

	vpxor	0(%rsi),%xmm0,%xmm4
	vpxor	16(%rsi),%xmm1,%xmm5
	vpxor	32(%rsi),%xmm2,%xmm6
	vpxor	48(%rsi),%xmm3,%xmm7
	leaq	64(%rsi),%rsi

	vmovdqu	%xmm4,0(%rdi)
	vmovdqu	%xmm5,16(%rdi)
	vmovdqu	%xmm6,32(%rdi)
	vmovdqu	%xmm7,48(%rdi)
	leaq	64(%rdi),%rdi

	jz	.Ldone_avx512

	vextracti32x4	$1,%zmm0,%xmm4
	vextracti32x4	$1,%zmm1,%xmm5
	vextracti32x4	$1,%zmm2,%xmm6
	vextracti32x4	$1,%zmm3,%xmm7

	subq	$64,%rdx
	jb	.Ltail_avx512

	vpxor	0(%rsi),%xmm4,%xmm4
	vpxor	16(%rsi),%xmm5,%xmm5
	vpxor	32(%rsi),%xmm6,%xmm6
	vpxor	48(%rsi),%xmm7,%xmm7
	leaq	64(%rsi),%rsi

	vmovdqu	%xmm4,0(%rdi)
	vmovdqu	%xmm5,16(%rdi)
	vmovdqu	%xmm6,32(%rdi)
	vmovdqu	%xmm7,48(%rdi)
	leaq	64(%rdi),%rdi

	jz	.Ldone_avx512

	vextracti32x4	$2,%zmm0,%xmm4
	vextracti32x4	$2,%zmm1,%xmm5
	vextracti32x4	$2,%zmm2,%xmm6
	vextracti32x4	$2,%zmm3,%xmm7

	subq	$64,%rdx
	jb	.Ltail_avx512

	vpxor	0(%rsi),%xmm4,%xmm4
	vpxor	16(%rsi),%xmm5,%xmm5
	vpxor	32(%rsi),%xmm6,%xmm6
	vpxor	48(%rsi),%xmm7,%xmm7
	leaq	64(%rsi),%rsi

	vmovdqu	%xmm4,0(%rdi)
	vmovdqu	%xmm5,16(%rdi)
	vmovdqu	%xmm6,32(%rdi)
	vmovdqu	%xmm7,48(%rdi)
	leaq	64(%rdi),%rdi

	jz	.Ldone_avx512

	vextracti32x4	$3,%zmm0,%xmm4
	vextracti32x4	$3,%zmm1,%xmm5
	vextracti32x4	$3,%zmm2,%xmm6
	vextracti32x4	$3,%zmm3,%xmm7

	subq	$64,%rdx
	jb	.Ltail_avx512

	vpxor	0(%rsi),%xmm4,%xmm4
	vpxor	16(%rsi),%xmm5,%xmm5
	vpxor	32(%rsi),%xmm6,%xmm6
	vpxor	48(%rsi),%xmm7,%xmm7
	leaq	64(%rsi),%rsi

	vmovdqu	%xmm4,0(%rdi)
	vmovdqu	%xmm5,16(%rdi)
	vmovdqu	%xmm6,32(%rdi)
	vmovdqu	%xmm7,48(%rdi)
	leaq	64(%rdi),%rdi

	jnz	.Loop_outer_avx512

	jmp	.Ldone_avx512

.align	16
.Ltail64_avx512:
	vmovdqa	%xmm0,0(%rsp)
	vmovdqa	%xmm1,16(%rsp)
	vmovdqa	%xmm2,32(%rsp)
	vmovdqa	%xmm3,48(%rsp)
	addq	$64,%rdx
	jmp	.Loop_tail_avx512

.align	16
.Ltail_avx512:
	vmovdqa	%xmm4,0(%rsp)
	vmovdqa	%xmm5,16(%rsp)
	vmovdqa	%xmm6,32(%rsp)
	vmovdqa	%xmm7,48(%rsp)
	addq	$64,%rdx

.Loop_tail_avx512:
	movzbl	(%rsi,%r8,1),%eax
	movzbl	(%rsp,%r8,1),%ecx
	leaq	1(%r8),%r8
	xorl	%ecx,%eax
	movb	%al,-1(%rdi,%r8,1)
	decq	%rdx
	jnz	.Loop_tail_avx512

	vmovdqu32	%zmm16,0(%rsp)

.Ldone_avx512:
	vzeroall
	leaq	(%r9),%rsp
.cfi_def_cfa_register	%rsp
.Lavx512_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	ChaCha20_avx512,.-ChaCha20_avx512
.type	ChaCha20_avx512vl,@function
.align	32
ChaCha20_avx512vl:
.cfi_startproc	
.LChaCha20_avx512vl:
	movq	%rsp,%r9
.cfi_def_cfa_register	%r9
	cmpq	$128,%rdx
	ja	.LChaCha20_8xvl

	subq	$64+8,%rsp
	vbroadcasti128	.Lsigma(%rip),%ymm0
	vbroadcasti128	(%rcx),%ymm1
	vbroadcasti128	16(%rcx),%ymm2
	vbroadcasti128	(%r8),%ymm3

	vmovdqa32	%ymm0,%ymm16
	vmovdqa32	%ymm1,%ymm17
	vmovdqa32	%ymm2,%ymm18
	vpaddd	.Lzeroz(%rip),%ymm3,%ymm3
	vmovdqa32	.Ltwoy(%rip),%ymm20
	movq	$10,%r8
	vmovdqa32	%ymm3,%ymm19
	jmp	.Loop_avx512vl

.align	16
.Loop_outer_avx512vl:
	vmovdqa32	%ymm18,%ymm2
	vpaddd	%ymm20,%ymm19,%ymm3
	movq	$10,%r8
	vmovdqa32	%ymm3,%ymm19
	jmp	.Loop_avx512vl

.align	32
.Loop_avx512vl:
	vpaddd	%ymm1,%ymm0,%ymm0
	vpxor	%ymm0,%ymm3,%ymm3
	vprold	$16,%ymm3,%ymm3
	vpaddd	%ymm3,%ymm2,%ymm2
	vpxor	%ymm2,%ymm1,%ymm1
	vprold	$12,%ymm1,%ymm1
	vpaddd	%ymm1,%ymm0,%ymm0
	vpxor	%ymm0,%ymm3,%ymm3
	vprold	$8,%ymm3,%ymm3
	vpaddd	%ymm3,%ymm2,%ymm2
	vpxor	%ymm2,%ymm1,%ymm1
	vprold	$7,%ymm1,%ymm1
	vpshufd	$78,%ymm2,%ymm2
	vpshufd	$57,%ymm1,%ymm1
	vpshufd	$147,%ymm3,%ymm3
	vpaddd	%ymm1,%ymm0,%ymm0
	vpxor	%ymm0,%ymm3,%ymm3
	vprold	$16,%ymm3,%ymm3
	vpaddd	%ymm3,%ymm2,%ymm2
	vpxor	%ymm2,%ymm1,%ymm1
	vprold	$12,%ymm1,%ymm1
	vpaddd	%ymm1,%ymm0,%ymm0
	vpxor	%ymm0,%ymm3,%ymm3
	vprold	$8,%ymm3,%ymm3
	vpaddd	%ymm3,%ymm2,%ymm2
	vpxor	%ymm2,%ymm1,%ymm1
	vprold	$7,%ymm1,%ymm1
	vpshufd	$78,%ymm2,%ymm2
	vpshufd	$147,%ymm1,%ymm1
	vpshufd	$57,%ymm3,%ymm3
	decq	%r8
	jnz	.Loop_avx512vl
	vpaddd	%ymm16,%ymm0,%ymm0
	vpaddd	%ymm17,%ymm1,%ymm1
	vpaddd	%ymm18,%ymm2,%ymm2
	vpaddd	%ymm19,%ymm3,%ymm3

	subq	$64,%rdx
	jb	.Ltail64_avx512vl

	vpxor	0(%rsi),%xmm0,%xmm4
	vpxor	16(%rsi),%xmm1,%xmm5
	vpxor	32(%rsi),%xmm2,%xmm6
	vpxor	48(%rsi),%xmm3,%xmm7
	leaq	64(%rsi),%rsi

	vmovdqu	%xmm4,0(%rdi)
	vmovdqu	%xmm5,16(%rdi)
	vmovdqu	%xmm6,32(%rdi)
	vmovdqu	%xmm7,48(%rdi)
	leaq	64(%rdi),%rdi

	jz	.Ldone_avx512vl

	vextracti128	$1,%ymm0,%xmm4
	vextracti128	$1,%ymm1,%xmm5
	vextracti128	$1,%ymm2,%xmm6
	vextracti128	$1,%ymm3,%xmm7

	subq	$64,%rdx
	jb	.Ltail_avx512vl

	vpxor	0(%rsi),%xmm4,%xmm4
	vpxor	16(%rsi),%xmm5,%xmm5
	vpxor	32(%rsi),%xmm6,%xmm6
	vpxor	48(%rsi),%xmm7,%xmm7
	leaq	64(%rsi),%rsi

	vmovdqu	%xmm4,0(%rdi)
	vmovdqu	%xmm5,16(%rdi)
	vmovdqu	%xmm6,32(%rdi)
	vmovdqu	%xmm7,48(%rdi)
	leaq	64(%rdi),%rdi

	vmovdqa32	%ymm16,%ymm0
	vmovdqa32	%ymm17,%ymm1
	jnz	.Loop_outer_avx512vl

	jmp	.Ldone_avx512vl

.align	16
.Ltail64_avx512vl:
	vmovdqa	%xmm0,0(%rsp)
	vmovdqa	%xmm1,16(%rsp)
	vmovdqa	%xmm2,32(%rsp)
	vmovdqa	%xmm3,48(%rsp)
	addq	$64,%rdx
	jmp	.Loop_tail_avx512vl

.align	16
.Ltail_avx512vl:
	vmovdqa	%xmm4,0(%rsp)
	vmovdqa	%xmm5,16(%rsp)
	vmovdqa	%xmm6,32(%rsp)
	vmovdqa	%xmm7,48(%rsp)
	addq	$64,%rdx

.Loop_tail_avx512vl:
	movzbl	(%rsi,%r8,1),%eax
	movzbl	(%rsp,%r8,1),%ecx
	leaq	1(%r8),%r8
	xorl	%ecx,%eax
	movb	%al,-1(%rdi,%r8,1)
	decq	%rdx
	jnz	.Loop_tail_avx512vl

	vmovdqu32	%ymm16,0(%rsp)
	vmovdqu32	%ymm16,32(%rsp)

.Ldone_avx512vl:
	vzeroall
	leaq	(%r9),%rsp
.cfi_def_cfa_register	%rsp
.Lavx512vl_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	ChaCha20_avx512vl,.-ChaCha20_avx512vl
.type	ChaCha20_16x,@function
.align	32
ChaCha20_16x:
.cfi_startproc	
.LChaCha20_16x:
	movq	%rsp,%r9
.cfi_def_cfa_register	%r9
	subq	$64+8,%rsp
	andq	$-64,%rsp
	vzeroupper

	leaq	.Lsigma(%rip),%r10
	vbroadcasti32x4	(%r10),%zmm3
	vbroadcasti32x4	(%rcx),%zmm7
	vbroadcasti32x4	16(%rcx),%zmm11
	vbroadcasti32x4	(%r8),%zmm15

	vpshufd	$0x00,%zmm3,%zmm0
	vpshufd	$0x55,%zmm3,%zmm1
	vpshufd	$0xaa,%zmm3,%zmm2
	vpshufd	$0xff,%zmm3,%zmm3
	vmovdqa64	%zmm0,%zmm16
	vmovdqa64	%zmm1,%zmm17
	vmovdqa64	%zmm2,%zmm18
	vmovdqa64	%zmm3,%zmm19

	vpshufd	$0x00,%zmm7,%zmm4
	vpshufd	$0x55,%zmm7,%zmm5
	vpshufd	$0xaa,%zmm7,%zmm6
	vpshufd	$0xff,%zmm7,%zmm7
	vmovdqa64	%zmm4,%zmm20
	vmovdqa64	%zmm5,%zmm21
	vmovdqa64	%zmm6,%zmm22
	vmovdqa64	%zmm7,%zmm23

	vpshufd	$0x00,%zmm11,%zmm8
	vpshufd	$0x55,%zmm11,%zmm9
	vpshufd	$0xaa,%zmm11,%zmm10
	vpshufd	$0xff,%zmm11,%zmm11
	vmovdqa64	%zmm8,%zmm24
	vmovdqa64	%zmm9,%zmm25
	vmovdqa64	%zmm10,%zmm26
	vmovdqa64	%zmm11,%zmm27

	vpshufd	$0x00,%zmm15,%zmm12
	vpshufd	$0x55,%zmm15,%zmm13
	vpshufd	$0xaa,%zmm15,%zmm14
	vpshufd	$0xff,%zmm15,%zmm15
	vpaddd	.Lincz(%rip),%zmm12,%zmm12
	vmovdqa64	%zmm12,%zmm28
	vmovdqa64	%zmm13,%zmm29
	vmovdqa64	%zmm14,%zmm30
	vmovdqa64	%zmm15,%zmm31

	movl	$10,%eax
	jmp	.Loop16x

.align	32
.Loop_outer16x:
	vpbroadcastd	0(%r10),%zmm0
	vpbroadcastd	4(%r10),%zmm1
	vpbroadcastd	8(%r10),%zmm2
	vpbroadcastd	12(%r10),%zmm3
	vpaddd	.Lsixteen(%rip),%zmm28,%zmm28
	vmovdqa64	%zmm20,%zmm4
	vmovdqa64	%zmm21,%zmm5
	vmovdqa64	%zmm22,%zmm6
	vmovdqa64	%zmm23,%zmm7
	vmovdqa64	%zmm24,%zmm8
	vmovdqa64	%zmm25,%zmm9
	vmovdqa64	%zmm26,%zmm10
	vmovdqa64	%zmm27,%zmm11
	vmovdqa64	%zmm28,%zmm12
	vmovdqa64	%zmm29,%zmm13
	vmovdqa64	%zmm30,%zmm14
	vmovdqa64	%zmm31,%zmm15

	vmovdqa64	%zmm0,%zmm16
	vmovdqa64	%zmm1,%zmm17
	vmovdqa64	%zmm2,%zmm18
	vmovdqa64	%zmm3,%zmm19

	movl	$10,%eax
	jmp	.Loop16x

.align	32
.Loop16x:
	vpaddd	%zmm4,%zmm0,%zmm0
	vpaddd	%zmm5,%zmm1,%zmm1
	vpaddd	%zmm6,%zmm2,%zmm2
	vpaddd	%zmm7,%zmm3,%zmm3
	vpxord	%zmm0,%zmm12,%zmm12
	vpxord	%zmm1,%zmm13,%zmm13
	vpxord	%zmm2,%zmm14,%zmm14
	vpxord	%zmm3,%zmm15,%zmm15
	vprold	$16,%zmm12,%zmm12
	vprold	$16,%zmm13,%zmm13
	vprold	$16,%zmm14,%zmm14
	vprold	$16,%zmm15,%zmm15
	vpaddd	%zmm12,%zmm8,%zmm8
	vpaddd	%zmm13,%zmm9,%zmm9
	vpaddd	%zmm14,%zmm10,%zmm10
	vpaddd	%zmm15,%zmm11,%zmm11
	vpxord	%zmm8,%zmm4,%zmm4
	vpxord	%zmm9,%zmm5,%zmm5
	vpxord	%zmm10,%zmm6,%zmm6
	vpxord	%zmm11,%zmm7,%zmm7
	vprold	$12,%zmm4,%zmm4
	vprold	$12,%zmm5,%zmm5
	vprold	$12,%zmm6,%zmm6
	vprold	$12,%zmm7,%zmm7
	vpaddd	%zmm4,%zmm0,%zmm0
	vpaddd	%zmm5,%zmm1,%zmm1
	vpaddd	%zmm6,%zmm2,%zmm2
	vpaddd	%zmm7,%zmm3,%zmm3
	vpxord	%zmm0,%zmm12,%zmm12
	vpxord	%zmm1,%zmm13,%zmm13
	vpxord	%zmm2,%zmm14,%zmm14
	vpxord	%zmm3,%zmm15,%zmm15
	vprold	$8,%zmm12,%zmm12
	vprold	$8,%zmm13,%zmm13
	vprold	$8,%zmm14,%zmm14
	vprold	$8,%zmm15,%zmm15
	vpaddd	%zmm12,%zmm8,%zmm8
	vpaddd	%zmm13,%zmm9,%zmm9
	vpaddd	%zmm14,%zmm10,%zmm10
	vpaddd	%zmm15,%zmm11,%zmm11
	vpxord	%zmm8,%zmm4,%zmm4
	vpxord	%zmm9,%zmm5,%zmm5
	vpxord	%zmm10,%zmm6,%zmm6
	vpxord	%zmm11,%zmm7,%zmm7
	vprold	$7,%zmm4,%zmm4
	vprold	$7,%zmm5,%zmm5
	vprold	$7,%zmm6,%zmm6
	vprold	$7,%zmm7,%zmm7
	vpaddd	%zmm5,%zmm0,%zmm0
	vpaddd	%zmm6,%zmm1,%zmm1
	vpaddd	%zmm7,%zmm2,%zmm2
	vpaddd	%zmm4,%zmm3,%zmm3
	vpxord	%zmm0,%zmm15,%zmm15
	vpxord	%zmm1,%zmm12,%zmm12
	vpxord	%zmm2,%zmm13,%zmm13
	vpxord	%zmm3,%zmm14,%zmm14
	vprold	$16,%zmm15,%zmm15
	vprold	$16,%zmm12,%zmm12
	vprold	$16,%zmm13,%zmm13
	vprold	$16,%zmm14,%zmm14
	vpaddd	%zmm15,%zmm10,%zmm10
	vpaddd	%zmm12,%zmm11,%zmm11
	vpaddd	%zmm13,%zmm8,%zmm8
	vpaddd	%zmm14,%zmm9,%zmm9
	vpxord	%zmm10,%zmm5,%zmm5
	vpxord	%zmm11,%zmm6,%zmm6
	vpxord	%zmm8,%zmm7,%zmm7
	vpxord	%zmm9,%zmm4,%zmm4
	vprold	$12,%zmm5,%zmm5
	vprold	$12,%zmm6,%zmm6
	vprold	$12,%zmm7,%zmm7
	vprold	$12,%zmm4,%zmm4
	vpaddd	%zmm5,%zmm0,%zmm0
	vpaddd	%zmm6,%zmm1,%zmm1
	vpaddd	%zmm7,%zmm2,%zmm2
	vpaddd	%zmm4,%zmm3,%zmm3
	vpxord	%zmm0,%zmm15,%zmm15
	vpxord	%zmm1,%zmm12,%zmm12
	vpxord	%zmm2,%zmm13,%zmm13
	vpxord	%zmm3,%zmm14,%zmm14
	vprold	$8,%zmm15,%zmm15
	vprold	$8,%zmm12,%zmm12
	vprold	$8,%zmm13,%zmm13
	vprold	$8,%zmm14,%zmm14
	vpaddd	%zmm15,%zmm10,%zmm10
	vpaddd	%zmm12,%zmm11,%zmm11
	vpaddd	%zmm13,%zmm8,%zmm8
	vpaddd	%zmm14,%zmm9,%zmm9
	vpxord	%zmm10,%zmm5,%zmm5
	vpxord	%zmm11,%zmm6,%zmm6
	vpxord	%zmm8,%zmm7,%zmm7
	vpxord	%zmm9,%zmm4,%zmm4
	vprold	$7,%zmm5,%zmm5
	vprold	$7,%zmm6,%zmm6
	vprold	$7,%zmm7,%zmm7
	vprold	$7,%zmm4,%zmm4
	decl	%eax
	jnz	.Loop16x

	vpaddd	%zmm16,%zmm0,%zmm0
	vpaddd	%zmm17,%zmm1,%zmm1
	vpaddd	%zmm18,%zmm2,%zmm2
	vpaddd	%zmm19,%zmm3,%zmm3

	vpunpckldq	%zmm1,%zmm0,%zmm18
	vpunpckldq	%zmm3,%zmm2,%zmm19
	vpunpckhdq	%zmm1,%zmm0,%zmm0
	vpunpckhdq	%zmm3,%zmm2,%zmm2
	vpunpcklqdq	%zmm19,%zmm18,%zmm1
	vpunpckhqdq	%zmm19,%zmm18,%zmm18
	vpunpcklqdq	%zmm2,%zmm0,%zmm3
	vpunpckhqdq	%zmm2,%zmm0,%zmm0
	vpaddd	%zmm20,%zmm4,%zmm4
	vpaddd	%zmm21,%zmm5,%zmm5
	vpaddd	%zmm22,%zmm6,%zmm6
	vpaddd	%zmm23,%zmm7,%zmm7

	vpunpckldq	%zmm5,%zmm4,%zmm2
	vpunpckldq	%zmm7,%zmm6,%zmm19
	vpunpckhdq	%zmm5,%zmm4,%zmm4
	vpunpckhdq	%zmm7,%zmm6,%zmm6
	vpunpcklqdq	%zmm19,%zmm2,%zmm5
	vpunpckhqdq	%zmm19,%zmm2,%zmm2
	vpunpcklqdq	%zmm6,%zmm4,%zmm7
	vpunpckhqdq	%zmm6,%zmm4,%zmm4
	vshufi32x4	$0x44,%zmm5,%zmm1,%zmm19
	vshufi32x4	$0xee,%zmm5,%zmm1,%zmm5
	vshufi32x4	$0x44,%zmm2,%zmm18,%zmm1
	vshufi32x4	$0xee,%zmm2,%zmm18,%zmm2
	vshufi32x4	$0x44,%zmm7,%zmm3,%zmm18
	vshufi32x4	$0xee,%zmm7,%zmm3,%zmm7
	vshufi32x4	$0x44,%zmm4,%zmm0,%zmm3
	vshufi32x4	$0xee,%zmm4,%zmm0,%zmm4
	vpaddd	%zmm24,%zmm8,%zmm8
	vpaddd	%zmm25,%zmm9,%zmm9
	vpaddd	%zmm26,%zmm10,%zmm10
	vpaddd	%zmm27,%zmm11,%zmm11

	vpunpckldq	%zmm9,%zmm8,%zmm6
	vpunpckldq	%zmm11,%zmm10,%zmm0
	vpunpckhdq	%zmm9,%zmm8,%zmm8
	vpunpckhdq	%zmm11,%zmm10,%zmm10
	vpunpcklqdq	%zmm0,%zmm6,%zmm9
	vpunpckhqdq	%zmm0,%zmm6,%zmm6
	vpunpcklqdq	%zmm10,%zmm8,%zmm11
	vpunpckhqdq	%zmm10,%zmm8,%zmm8
	vpaddd	%zmm28,%zmm12,%zmm12
	vpaddd	%zmm29,%zmm13,%zmm13
	vpaddd	%zmm30,%zmm14,%zmm14
	vpaddd	%zmm31,%zmm15,%zmm15

	vpunpckldq	%zmm13,%zmm12,%zmm10
	vpunpckldq	%zmm15,%zmm14,%zmm0
	vpunpckhdq	%zmm13,%zmm12,%zmm12
	vpunpckhdq	%zmm15,%zmm14,%zmm14
	vpunpcklqdq	%zmm0,%zmm10,%zmm13
	vpunpckhqdq	%zmm0,%zmm10,%zmm10
	vpunpcklqdq	%zmm14,%zmm12,%zmm15
	vpunpckhqdq	%zmm14,%zmm12,%zmm12
	vshufi32x4	$0x44,%zmm13,%zmm9,%zmm0
	vshufi32x4	$0xee,%zmm13,%zmm9,%zmm13
	vshufi32x4	$0x44,%zmm10,%zmm6,%zmm9
	vshufi32x4	$0xee,%zmm10,%zmm6,%zmm10
	vshufi32x4	$0x44,%zmm15,%zmm11,%zmm6
	vshufi32x4	$0xee,%zmm15,%zmm11,%zmm15
	vshufi32x4	$0x44,%zmm12,%zmm8,%zmm11
	vshufi32x4	$0xee,%zmm12,%zmm8,%zmm12
	vshufi32x4	$0x88,%zmm0,%zmm19,%zmm16
	vshufi32x4	$0xdd,%zmm0,%zmm19,%zmm19
	vshufi32x4	$0x88,%zmm13,%zmm5,%zmm0
	vshufi32x4	$0xdd,%zmm13,%zmm5,%zmm13
	vshufi32x4	$0x88,%zmm9,%zmm1,%zmm17
	vshufi32x4	$0xdd,%zmm9,%zmm1,%zmm1
	vshufi32x4	$0x88,%zmm10,%zmm2,%zmm9
	vshufi32x4	$0xdd,%zmm10,%zmm2,%zmm10
	vshufi32x4	$0x88,%zmm6,%zmm18,%zmm14
	vshufi32x4	$0xdd,%zmm6,%zmm18,%zmm18
	vshufi32x4	$0x88,%zmm15,%zmm7,%zmm6
	vshufi32x4	$0xdd,%zmm15,%zmm7,%zmm15
	vshufi32x4	$0x88,%zmm11,%zmm3,%zmm8
	vshufi32x4	$0xdd,%zmm11,%zmm3,%zmm3
	vshufi32x4	$0x88,%zmm12,%zmm4,%zmm11
	vshufi32x4	$0xdd,%zmm12,%zmm4,%zmm12
	cmpq	$1024,%rdx
	jb	.Ltail16x

	vpxord	0(%rsi),%zmm16,%zmm16
	vpxord	64(%rsi),%zmm17,%zmm17
	vpxord	128(%rsi),%zmm14,%zmm14
	vpxord	192(%rsi),%zmm8,%zmm8
	vmovdqu32	%zmm16,0(%rdi)
	vmovdqu32	%zmm17,64(%rdi)
	vmovdqu32	%zmm14,128(%rdi)
	vmovdqu32	%zmm8,192(%rdi)

	vpxord	256(%rsi),%zmm19,%zmm19
	vpxord	320(%rsi),%zmm1,%zmm1
	vpxord	384(%rsi),%zmm18,%zmm18
	vpxord	448(%rsi),%zmm3,%zmm3
	vmovdqu32	%zmm19,256(%rdi)
	vmovdqu32	%zmm1,320(%rdi)
	vmovdqu32	%zmm18,384(%rdi)
	vmovdqu32	%zmm3,448(%rdi)

	vpxord	512(%rsi),%zmm0,%zmm0
	vpxord	576(%rsi),%zmm9,%zmm9
	vpxord	640(%rsi),%zmm6,%zmm6
	vpxord	704(%rsi),%zmm11,%zmm11
	vmovdqu32	%zmm0,512(%rdi)
	vmovdqu32	%zmm9,576(%rdi)
	vmovdqu32	%zmm6,640(%rdi)
	vmovdqu32	%zmm11,704(%rdi)

	vpxord	768(%rsi),%zmm13,%zmm13
	vpxord	832(%rsi),%zmm10,%zmm10
	vpxord	896(%rsi),%zmm15,%zmm15
	vpxord	960(%rsi),%zmm12,%zmm12
	leaq	1024(%rsi),%rsi
	vmovdqu32	%zmm13,768(%rdi)
	vmovdqu32	%zmm10,832(%rdi)
	vmovdqu32	%zmm15,896(%rdi)
	vmovdqu32	%zmm12,960(%rdi)
	leaq	1024(%rdi),%rdi

	subq	$1024,%rdx
	jnz	.Loop_outer16x

	jmp	.Ldone16x

.align	32
.Ltail16x:
	xorq	%r10,%r10
	subq	%rsi,%rdi
	cmpq	$64,%rdx
	jb	.Less_than_64_16x
	vpxord	(%rsi),%zmm16,%zmm16
	vmovdqu32	%zmm16,(%rdi,%rsi,1)
	je	.Ldone16x
	vmovdqa32	%zmm17,%zmm16
	leaq	64(%rsi),%rsi

	cmpq	$128,%rdx
	jb	.Less_than_64_16x
	vpxord	(%rsi),%zmm17,%zmm17
	vmovdqu32	%zmm17,(%rdi,%rsi,1)
	je	.Ldone16x
	vmovdqa32	%zmm14,%zmm16
	leaq	64(%rsi),%rsi

	cmpq	$192,%rdx
	jb	.Less_than_64_16x
	vpxord	(%rsi),%zmm14,%zmm14
	vmovdqu32	%zmm14,(%rdi,%rsi,1)
	je	.Ldone16x
	vmovdqa32	%zmm8,%zmm16
	leaq	64(%rsi),%rsi

	cmpq	$256,%rdx
	jb	.Less_than_64_16x
	vpxord	(%rsi),%zmm8,%zmm8
	vmovdqu32	%zmm8,(%rdi,%rsi,1)
	je	.Ldone16x
	vmovdqa32	%zmm19,%zmm16
	leaq	64(%rsi),%rsi

	cmpq	$320,%rdx
	jb	.Less_than_64_16x
	vpxord	(%rsi),%zmm19,%zmm19
	vmovdqu32	%zmm19,(%rdi,%rsi,1)
	je	.Ldone16x
	vmovdqa32	%zmm1,%zmm16
	leaq	64(%rsi),%rsi

	cmpq	$384,%rdx
	jb	.Less_than_64_16x
	vpxord	(%rsi),%zmm1,%zmm1
	vmovdqu32	%zmm1,(%rdi,%rsi,1)
	je	.Ldone16x
	vmovdqa32	%zmm18,%zmm16
	leaq	64(%rsi),%rsi

	cmpq	$448,%rdx
	jb	.Less_than_64_16x
	vpxord	(%rsi),%zmm18,%zmm18
	vmovdqu32	%zmm18,(%rdi,%rsi,1)
	je	.Ldone16x
	vmovdqa32	%zmm3,%zmm16
	leaq	64(%rsi),%rsi

	cmpq	$512,%rdx
	jb	.Less_than_64_16x
	vpxord	(%rsi),%zmm3,%zmm3
	vmovdqu32	%zmm3,(%rdi,%rsi,1)
	je	.Ldone16x
	vmovdqa32	%zmm0,%zmm16
	leaq	64(%rsi),%rsi

	cmpq	$576,%rdx
	jb	.Less_than_64_16x
	vpxord	(%rsi),%zmm0,%zmm0
	vmovdqu32	%zmm0,(%rdi,%rsi,1)
	je	.Ldone16x
	vmovdqa32	%zmm9,%zmm16
	leaq	64(%rsi),%rsi

	cmpq	$640,%rdx
	jb	.Less_than_64_16x
	vpxord	(%rsi),%zmm9,%zmm9
	vmovdqu32	%zmm9,(%rdi,%rsi,1)
	je	.Ldone16x
	vmovdqa32	%zmm6,%zmm16
	leaq	64(%rsi),%rsi

	cmpq	$704,%rdx
	jb	.Less_than_64_16x
	vpxord	(%rsi),%zmm6,%zmm6
	vmovdqu32	%zmm6,(%rdi,%rsi,1)
	je	.Ldone16x
	vmovdqa32	%zmm11,%zmm16
	leaq	64(%rsi),%rsi

	cmpq	$768,%rdx
	jb	.Less_than_64_16x
	vpxord	(%rsi),%zmm11,%zmm11
	vmovdqu32	%zmm11,(%rdi,%rsi,1)
	je	.Ldone16x
	vmovdqa32	%zmm13,%zmm16
	leaq	64(%rsi),%rsi

	cmpq	$832,%rdx
	jb	.Less_than_64_16x
	vpxord	(%rsi),%zmm13,%zmm13
	vmovdqu32	%zmm13,(%rdi,%rsi,1)
	je	.Ldone16x
	vmovdqa32	%zmm10,%zmm16
	leaq	64(%rsi),%rsi

	cmpq	$896,%rdx
	jb	.Less_than_64_16x
	vpxord	(%rsi),%zmm10,%zmm10
	vmovdqu32	%zmm10,(%rdi,%rsi,1)
	je	.Ldone16x
	vmovdqa32	%zmm15,%zmm16
	leaq	64(%rsi),%rsi

	cmpq	$960,%rdx
	jb	.Less_than_64_16x
	vpxord	(%rsi),%zmm15,%zmm15
	vmovdqu32	%zmm15,(%rdi,%rsi,1)
	je	.Ldone16x
	vmovdqa32	%zmm12,%zmm16
	leaq	64(%rsi),%rsi

.Less_than_64_16x:
	vmovdqa32	%zmm16,0(%rsp)
	leaq	(%rdi,%rsi,1),%rdi
	andq	$63,%rdx

.Loop_tail16x:
	movzbl	(%rsi,%r10,1),%eax
	movzbl	(%rsp,%r10,1),%ecx
	leaq	1(%r10),%r10
	xorl	%ecx,%eax
	movb	%al,-1(%rdi,%r10,1)
	decq	%rdx
	jnz	.Loop_tail16x

	vpxord	%zmm16,%zmm16,%zmm16
	vmovdqa32	%zmm16,0(%rsp)

.Ldone16x:
	vzeroall
	leaq	(%r9),%rsp
.cfi_def_cfa_register	%rsp
.L16x_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	ChaCha20_16x,.-ChaCha20_16x
.type	ChaCha20_8xvl,@function
.align	32
ChaCha20_8xvl:
.cfi_startproc	
.LChaCha20_8xvl:
	movq	%rsp,%r9
.cfi_def_cfa_register	%r9
	subq	$64+8,%rsp
	andq	$-64,%rsp
	vzeroupper

	leaq	.Lsigma(%rip),%r10
	vbroadcasti128	(%r10),%ymm3
	vbroadcasti128	(%rcx),%ymm7
	vbroadcasti128	16(%rcx),%ymm11
	vbroadcasti128	(%r8),%ymm15

	vpshufd	$0x00,%ymm3,%ymm0
	vpshufd	$0x55,%ymm3,%ymm1
	vpshufd	$0xaa,%ymm3,%ymm2
	vpshufd	$0xff,%ymm3,%ymm3
	vmovdqa64	%ymm0,%ymm16
	vmovdqa64	%ymm1,%ymm17
	vmovdqa64	%ymm2,%ymm18
	vmovdqa64	%ymm3,%ymm19

	vpshufd	$0x00,%ymm7,%ymm4
	vpshufd	$0x55,%ymm7,%ymm5
	vpshufd	$0xaa,%ymm7,%ymm6
	vpshufd	$0xff,%ymm7,%ymm7
	vmovdqa64	%ymm4,%ymm20
	vmovdqa64	%ymm5,%ymm21
	vmovdqa64	%ymm6,%ymm22
	vmovdqa64	%ymm7,%ymm23

	vpshufd	$0x00,%ymm11,%ymm8
	vpshufd	$0x55,%ymm11,%ymm9
	vpshufd	$0xaa,%ymm11,%ymm10
	vpshufd	$0xff,%ymm11,%ymm11
	vmovdqa64	%ymm8,%ymm24
	vmovdqa64	%ymm9,%ymm25
	vmovdqa64	%ymm10,%ymm26
	vmovdqa64	%ymm11,%ymm27

	vpshufd	$0x00,%ymm15,%ymm12
	vpshufd	$0x55,%ymm15,%ymm13
	vpshufd	$0xaa,%ymm15,%ymm14
	vpshufd	$0xff,%ymm15,%ymm15
	vpaddd	.Lincy(%rip),%ymm12,%ymm12
	vmovdqa64	%ymm12,%ymm28
	vmovdqa64	%ymm13,%ymm29
	vmovdqa64	%ymm14,%ymm30
	vmovdqa64	%ymm15,%ymm31

	movl	$10,%eax
	jmp	.Loop8xvl

.align	32
.Loop_outer8xvl:


	vpbroadcastd	8(%r10),%ymm2
	vpbroadcastd	12(%r10),%ymm3
	vpaddd	.Leight(%rip),%ymm28,%ymm28
	vmovdqa64	%ymm20,%ymm4
	vmovdqa64	%ymm21,%ymm5
	vmovdqa64	%ymm22,%ymm6
	vmovdqa64	%ymm23,%ymm7
	vmovdqa64	%ymm24,%ymm8
	vmovdqa64	%ymm25,%ymm9
	vmovdqa64	%ymm26,%ymm10
	vmovdqa64	%ymm27,%ymm11
	vmovdqa64	%ymm28,%ymm12
	vmovdqa64	%ymm29,%ymm13
	vmovdqa64	%ymm30,%ymm14
	vmovdqa64	%ymm31,%ymm15

	vmovdqa64	%ymm0,%ymm16
	vmovdqa64	%ymm1,%ymm17
	vmovdqa64	%ymm2,%ymm18
	vmovdqa64	%ymm3,%ymm19

	movl	$10,%eax
	jmp	.Loop8xvl

.align	32
.Loop8xvl:
	vpaddd	%ymm4,%ymm0,%ymm0
	vpaddd	%ymm5,%ymm1,%ymm1
	vpaddd	%ymm6,%ymm2,%ymm2
	vpaddd	%ymm7,%ymm3,%ymm3
	vpxor	%ymm0,%ymm12,%ymm12
	vpxor	%ymm1,%ymm13,%ymm13
	vpxor	%ymm2,%ymm14,%ymm14
	vpxor	%ymm3,%ymm15,%ymm15
	vprold	$16,%ymm12,%ymm12
	vprold	$16,%ymm13,%ymm13
	vprold	$16,%ymm14,%ymm14
	vprold	$16,%ymm15,%ymm15
	vpaddd	%ymm12,%ymm8,%ymm8
	vpaddd	%ymm13,%ymm9,%ymm9
	vpaddd	%ymm14,%ymm10,%ymm10
	vpaddd	%ymm15,%ymm11,%ymm11
	vpxor	%ymm8,%ymm4,%ymm4
	vpxor	%ymm9,%ymm5,%ymm5
	vpxor	%ymm10,%ymm6,%ymm6
	vpxor	%ymm11,%ymm7,%ymm7
	vprold	$12,%ymm4,%ymm4
	vprold	$12,%ymm5,%ymm5
	vprold	$12,%ymm6,%ymm6
	vprold	$12,%ymm7,%ymm7
	vpaddd	%ymm4,%ymm0,%ymm0
	vpaddd	%ymm5,%ymm1,%ymm1
	vpaddd	%ymm6,%ymm2,%ymm2
	vpaddd	%ymm7,%ymm3,%ymm3
	vpxor	%ymm0,%ymm12,%ymm12
	vpxor	%ymm1,%ymm13,%ymm13
	vpxor	%ymm2,%ymm14,%ymm14
	vpxor	%ymm3,%ymm15,%ymm15
	vprold	$8,%ymm12,%ymm12
	vprold	$8,%ymm13,%ymm13
	vprold	$8,%ymm14,%ymm14
	vprold	$8,%ymm15,%ymm15
	vpaddd	%ymm12,%ymm8,%ymm8
	vpaddd	%ymm13,%ymm9,%ymm9
	vpaddd	%ymm14,%ymm10,%ymm10
	vpaddd	%ymm15,%ymm11,%ymm11
	vpxor	%ymm8,%ymm4,%ymm4
	vpxor	%ymm9,%ymm5,%ymm5
	vpxor	%ymm10,%ymm6,%ymm6
	vpxor	%ymm11,%ymm7,%ymm7
	vprold	$7,%ymm4,%ymm4
	vprold	$7,%ymm5,%ymm5
	vprold	$7,%ymm6,%ymm6
	vprold	$7,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm0,%ymm0
	vpaddd	%ymm6,%ymm1,%ymm1
	vpaddd	%ymm7,%ymm2,%ymm2
	vpaddd	%ymm4,%ymm3,%ymm3
	vpxor	%ymm0,%ymm15,%ymm15
	vpxor	%ymm1,%ymm12,%ymm12
	vpxor	%ymm2,%ymm13,%ymm13
	vpxor	%ymm3,%ymm14,%ymm14
	vprold	$16,%ymm15,%ymm15
	vprold	$16,%ymm12,%ymm12
	vprold	$16,%ymm13,%ymm13
	vprold	$16,%ymm14,%ymm14
	vpaddd	%ymm15,%ymm10,%ymm10
	vpaddd	%ymm12,%ymm11,%ymm11
	vpaddd	%ymm13,%ymm8,%ymm8
	vpaddd	%ymm14,%ymm9,%ymm9
	vpxor	%ymm10,%ymm5,%ymm5
	vpxor	%ymm11,%ymm6,%ymm6
	vpxor	%ymm8,%ymm7,%ymm7
	vpxor	%ymm9,%ymm4,%ymm4
	vprold	$12,%ymm5,%ymm5
	vprold	$12,%ymm6,%ymm6
	vprold	$12,%ymm7,%ymm7
	vprold	$12,%ymm4,%ymm4
	vpaddd	%ymm5,%ymm0,%ymm0
	vpaddd	%ymm6,%ymm1,%ymm1
	vpaddd	%ymm7,%ymm2,%ymm2
	vpaddd	%ymm4,%ymm3,%ymm3
	vpxor	%ymm0,%ymm15,%ymm15
	vpxor	%ymm1,%ymm12,%ymm12
	vpxor	%ymm2,%ymm13,%ymm13
	vpxor	%ymm3,%ymm14,%ymm14
	vprold	$8,%ymm15,%ymm15
	vprold	$8,%ymm12,%ymm12
	vprold	$8,%ymm13,%ymm13
	vprold	$8,%ymm14,%ymm14
	vpaddd	%ymm15,%ymm10,%ymm10
	vpaddd	%ymm12,%ymm11,%ymm11
	vpaddd	%ymm13,%ymm8,%ymm8
	vpaddd	%ymm14,%ymm9,%ymm9
	vpxor	%ymm10,%ymm5,%ymm5
	vpxor	%ymm11,%ymm6,%ymm6
	vpxor	%ymm8,%ymm7,%ymm7
	vpxor	%ymm9,%ymm4,%ymm4
	vprold	$7,%ymm5,%ymm5
	vprold	$7,%ymm6,%ymm6
	vprold	$7,%ymm7,%ymm7
	vprold	$7,%ymm4,%ymm4
	decl	%eax
	jnz	.Loop8xvl

	vpaddd	%ymm16,%ymm0,%ymm0
	vpaddd	%ymm17,%ymm1,%ymm1
	vpaddd	%ymm18,%ymm2,%ymm2
	vpaddd	%ymm19,%ymm3,%ymm3

	vpunpckldq	%ymm1,%ymm0,%ymm18
	vpunpckldq	%ymm3,%ymm2,%ymm19
	vpunpckhdq	%ymm1,%ymm0,%ymm0
	vpunpckhdq	%ymm3,%ymm2,%ymm2
	vpunpcklqdq	%ymm19,%ymm18,%ymm1
	vpunpckhqdq	%ymm19,%ymm18,%ymm18
	vpunpcklqdq	%ymm2,%ymm0,%ymm3
	vpunpckhqdq	%ymm2,%ymm0,%ymm0
	vpaddd	%ymm20,%ymm4,%ymm4
	vpaddd	%ymm21,%ymm5,%ymm5
	vpaddd	%ymm22,%ymm6,%ymm6
	vpaddd	%ymm23,%ymm7,%ymm7

	vpunpckldq	%ymm5,%ymm4,%ymm2
	vpunpckldq	%ymm7,%ymm6,%ymm19
	vpunpckhdq	%ymm5,%ymm4,%ymm4
	vpunpckhdq	%ymm7,%ymm6,%ymm6
	vpunpcklqdq	%ymm19,%ymm2,%ymm5
	vpunpckhqdq	%ymm19,%ymm2,%ymm2
	vpunpcklqdq	%ymm6,%ymm4,%ymm7
	vpunpckhqdq	%ymm6,%ymm4,%ymm4
	vshufi32x4	$0,%ymm5,%ymm1,%ymm19
	vshufi32x4	$3,%ymm5,%ymm1,%ymm5
	vshufi32x4	$0,%ymm2,%ymm18,%ymm1
	vshufi32x4	$3,%ymm2,%ymm18,%ymm2
	vshufi32x4	$0,%ymm7,%ymm3,%ymm18
	vshufi32x4	$3,%ymm7,%ymm3,%ymm7
	vshufi32x4	$0,%ymm4,%ymm0,%ymm3
	vshufi32x4	$3,%ymm4,%ymm0,%ymm4
	vpaddd	%ymm24,%ymm8,%ymm8
	vpaddd	%ymm25,%ymm9,%ymm9
	vpaddd	%ymm26,%ymm10,%ymm10
	vpaddd	%ymm27,%ymm11,%ymm11

	vpunpckldq	%ymm9,%ymm8,%ymm6
	vpunpckldq	%ymm11,%ymm10,%ymm0
	vpunpckhdq	%ymm9,%ymm8,%ymm8
	vpunpckhdq	%ymm11,%ymm10,%ymm10
	vpunpcklqdq	%ymm0,%ymm6,%ymm9
	vpunpckhqdq	%ymm0,%ymm6,%ymm6
	vpunpcklqdq	%ymm10,%ymm8,%ymm11
	vpunpckhqdq	%ymm10,%ymm8,%ymm8
	vpaddd	%ymm28,%ymm12,%ymm12
	vpaddd	%ymm29,%ymm13,%ymm13
	vpaddd	%ymm30,%ymm14,%ymm14
	vpaddd	%ymm31,%ymm15,%ymm15

	vpunpckldq	%ymm13,%ymm12,%ymm10
	vpunpckldq	%ymm15,%ymm14,%ymm0
	vpunpckhdq	%ymm13,%ymm12,%ymm12
	vpunpckhdq	%ymm15,%ymm14,%ymm14
	vpunpcklqdq	%ymm0,%ymm10,%ymm13
	vpunpckhqdq	%ymm0,%ymm10,%ymm10
	vpunpcklqdq	%ymm14,%ymm12,%ymm15
	vpunpckhqdq	%ymm14,%ymm12,%ymm12
	vperm2i128	$0x20,%ymm13,%ymm9,%ymm0
	vperm2i128	$0x31,%ymm13,%ymm9,%ymm13
	vperm2i128	$0x20,%ymm10,%ymm6,%ymm9
	vperm2i128	$0x31,%ymm10,%ymm6,%ymm10
	vperm2i128	$0x20,%ymm15,%ymm11,%ymm6
	vperm2i128	$0x31,%ymm15,%ymm11,%ymm15
	vperm2i128	$0x20,%ymm12,%ymm8,%ymm11
	vperm2i128	$0x31,%ymm12,%ymm8,%ymm12
	cmpq	$512,%rdx
	jb	.Ltail8xvl

	movl	$0x80,%eax
	vpxord	0(%rsi),%ymm19,%ymm19
	vpxor	32(%rsi),%ymm0,%ymm0
	vpxor	64(%rsi),%ymm5,%ymm5
	vpxor	96(%rsi),%ymm13,%ymm13
	leaq	(%rsi,%rax,1),%rsi
	vmovdqu32	%ymm19,0(%rdi)
	vmovdqu	%ymm0,32(%rdi)
	vmovdqu	%ymm5,64(%rdi)
	vmovdqu	%ymm13,96(%rdi)
	leaq	(%rdi,%rax,1),%rdi

	vpxor	0(%rsi),%ymm1,%ymm1
	vpxor	32(%rsi),%ymm9,%ymm9
	vpxor	64(%rsi),%ymm2,%ymm2
	vpxor	96(%rsi),%ymm10,%ymm10
	leaq	(%rsi,%rax,1),%rsi
	vmovdqu	%ymm1,0(%rdi)
	vmovdqu	%ymm9,32(%rdi)
	vmovdqu	%ymm2,64(%rdi)
	vmovdqu	%ymm10,96(%rdi)
	leaq	(%rdi,%rax,1),%rdi

	vpxord	0(%rsi),%ymm18,%ymm18
	vpxor	32(%rsi),%ymm6,%ymm6
	vpxor	64(%rsi),%ymm7,%ymm7
	vpxor	96(%rsi),%ymm15,%ymm15
	leaq	(%rsi,%rax,1),%rsi
	vmovdqu32	%ymm18,0(%rdi)
	vmovdqu	%ymm6,32(%rdi)
	vmovdqu	%ymm7,64(%rdi)
	vmovdqu	%ymm15,96(%rdi)
	leaq	(%rdi,%rax,1),%rdi

	vpxor	0(%rsi),%ymm3,%ymm3
	vpxor	32(%rsi),%ymm11,%ymm11
	vpxor	64(%rsi),%ymm4,%ymm4
	vpxor	96(%rsi),%ymm12,%ymm12
	leaq	(%rsi,%rax,1),%rsi
	vmovdqu	%ymm3,0(%rdi)
	vmovdqu	%ymm11,32(%rdi)
	vmovdqu	%ymm4,64(%rdi)
	vmovdqu	%ymm12,96(%rdi)
	leaq	(%rdi,%rax,1),%rdi

	vpbroadcastd	0(%r10),%ymm0
	vpbroadcastd	4(%r10),%ymm1

	subq	$512,%rdx
	jnz	.Loop_outer8xvl

	jmp	.Ldone8xvl

.align	32
.Ltail8xvl:
	vmovdqa64	%ymm19,%ymm8
	xorq	%r10,%r10
	subq	%rsi,%rdi
	cmpq	$64,%rdx
	jb	.Less_than_64_8xvl
	vpxor	0(%rsi),%ymm8,%ymm8
	vpxor	32(%rsi),%ymm0,%ymm0
	vmovdqu	%ymm8,0(%rdi,%rsi,1)
	vmovdqu	%ymm0,32(%rdi,%rsi,1)
	je	.Ldone8xvl
	vmovdqa	%ymm5,%ymm8
	vmovdqa	%ymm13,%ymm0
	leaq	64(%rsi),%rsi

	cmpq	$128,%rdx
	jb	.Less_than_64_8xvl
	vpxor	0(%rsi),%ymm5,%ymm5
	vpxor	32(%rsi),%ymm13,%ymm13
	vmovdqu	%ymm5,0(%rdi,%rsi,1)
	vmovdqu	%ymm13,32(%rdi,%rsi,1)
	je	.Ldone8xvl
	vmovdqa	%ymm1,%ymm8
	vmovdqa	%ymm9,%ymm0
	leaq	64(%rsi),%rsi

	cmpq	$192,%rdx
	jb	.Less_than_64_8xvl
	vpxor	0(%rsi),%ymm1,%ymm1
	vpxor	32(%rsi),%ymm9,%ymm9
	vmovdqu	%ymm1,0(%rdi,%rsi,1)
	vmovdqu	%ymm9,32(%rdi,%rsi,1)
	je	.Ldone8xvl
	vmovdqa	%ymm2,%ymm8
	vmovdqa	%ymm10,%ymm0
	leaq	64(%rsi),%rsi

	cmpq	$256,%rdx
	jb	.Less_than_64_8xvl
	vpxor	0(%rsi),%ymm2,%ymm2
	vpxor	32(%rsi),%ymm10,%ymm10
	vmovdqu	%ymm2,0(%rdi,%rsi,1)
	vmovdqu	%ymm10,32(%rdi,%rsi,1)
	je	.Ldone8xvl
	vmovdqa32	%ymm18,%ymm8
	vmovdqa	%ymm6,%ymm0
	leaq	64(%rsi),%rsi

	cmpq	$320,%rdx
	jb	.Less_than_64_8xvl
	vpxord	0(%rsi),%ymm18,%ymm18
	vpxor	32(%rsi),%ymm6,%ymm6
	vmovdqu32	%ymm18,0(%rdi,%rsi,1)
	vmovdqu	%ymm6,32(%rdi,%rsi,1)
	je	.Ldone8xvl
	vmovdqa	%ymm7,%ymm8
	vmovdqa	%ymm15,%ymm0
	leaq	64(%rsi),%rsi

	cmpq	$384,%rdx
	jb	.Less_than_64_8xvl
	vpxor	0(%rsi),%ymm7,%ymm7
	vpxor	32(%rsi),%ymm15,%ymm15
	vmovdqu	%ymm7,0(%rdi,%rsi,1)
	vmovdqu	%ymm15,32(%rdi,%rsi,1)
	je	.Ldone8xvl
	vmovdqa	%ymm3,%ymm8
	vmovdqa	%ymm11,%ymm0
	leaq	64(%rsi),%rsi

	cmpq	$448,%rdx
	jb	.Less_than_64_8xvl
	vpxor	0(%rsi),%ymm3,%ymm3
	vpxor	32(%rsi),%ymm11,%ymm11
	vmovdqu	%ymm3,0(%rdi,%rsi,1)
	vmovdqu	%ymm11,32(%rdi,%rsi,1)
	je	.Ldone8xvl
	vmovdqa	%ymm4,%ymm8
	vmovdqa	%ymm12,%ymm0
	leaq	64(%rsi),%rsi

.Less_than_64_8xvl:
	vmovdqa	%ymm8,0(%rsp)
	vmovdqa	%ymm0,32(%rsp)
	leaq	(%rdi,%rsi,1),%rdi
	andq	$63,%rdx

.Loop_tail8xvl:
	movzbl	(%rsi,%r10,1),%eax
	movzbl	(%rsp,%r10,1),%ecx
	leaq	1(%r10),%r10
	xorl	%ecx,%eax
	movb	%al,-1(%rdi,%r10,1)
	decq	%rdx
	jnz	.Loop_tail8xvl

	vpxor	%ymm8,%ymm8,%ymm8
	vmovdqa	%ymm8,0(%rsp)
	vmovdqa	%ymm8,32(%rsp)

.Ldone8xvl:
	vzeroall
	leaq	(%r9),%rsp
.cfi_def_cfa_register	%rsp
.L8xvl_epilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	ChaCha20_8xvl,.-ChaCha20_8xvl
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                                                                                                                                                                                                           node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/ec/                                   0000775 0000000 0000000 00000000000 14746647661 0024322 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/openssl/config/archs/linux-x86_64/asm/crypto/ec/ecp_nistz256-x86_64.s              0000664 0000000 0000000 00001757303 14746647661 0027715 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	
.globl	ecp_nistz256_precomputed
.type	ecp_nistz256_precomputed,@object
.align	4096
ecp_nistz256_precomputed:
.long	0x18a9143c,0x79e730d4,0x5fedb601,0x75ba95fc,0x77622510,0x79fb732b,0xa53755c6,0x18905f76,0xce95560a,0xddf25357,0xba19e45c,0x8b4ab8e4,0xdd21f325,0xd2e88688,0x25885d85,0x8571ff18
.long	0x10ddd64d,0x850046d4,0xa433827d,0xaa6ae3c1,0x8d1490d9,0x73220503,0x3dcf3a3b,0xf6bb32e4,0x61bee1a5,0x2f3648d3,0xeb236ff8,0x152cd7cb,0x92042dbe,0x19a8fb0e,0x0a5b8a3b,0x78c57751
.long	0x4eebc127,0xffac3f90,0x087d81fb,0xb027f84a,0x87cbbc98,0x66ad77dd,0xb6ff747e,0x26936a3f,0xc983a7eb,0xb04c5c1f,0x0861fe1a,0x583e47ad,0x1a2ee98e,0x78820831,0xe587cc07,0xd5f06a29
.long	0x46918dcc,0x74b0b50d,0xc623c173,0x4650a6ed,0xe8100af2,0x0cdaacac,0x41b0176b,0x577362f5,0xe4cbaba6,0x2d96f24c,0xfad6f447,0x17628471,0xe5ddd22e,0x6b6c36de,0x4c5ab863,0x84b14c39
.long	0xc45c61f5,0xbe1b8aae,0x94b9537d,0x90ec649a,0xd076c20c,0x941cb5aa,0x890523c8,0xc9079605,0xe7ba4f10,0xeb309b4a,0xe5eb882b,0x73c568ef,0x7e7a1f68,0x3540a987,0x2dd1e916,0x73a076bb
.long	0x3e77664a,0x40394737,0x346cee3e,0x55ae744f,0x5b17a3ad,0xd50a961a,0x54213673,0x13074b59,0xd377e44b,0x93d36220,0xadff14b5,0x299c2b53,0xef639f11,0xf424d44c,0x4a07f75f,0xa4c9916d
.long	0xa0173b4f,0x0746354e,0xd23c00f7,0x2bd20213,0x0c23bb08,0xf43eaab5,0xc3123e03,0x13ba5119,0x3f5b9d4d,0x2847d030,0x5da67bdd,0x6742f2f2,0x77c94195,0xef933bdc,0x6e240867,0xeaedd915
.long	0x9499a78f,0x27f14cd1,0x6f9b3455,0x462ab5c5,0xf02cfc6b,0x8f90f02a,0xb265230d,0xb763891e,0x532d4977,0xf59da3a9,0xcf9eba15,0x21e3327d,0xbe60bbf0,0x123c7b84,0x7706df76,0x56ec12f2
.long	0x264e20e8,0x75c96e8f,0x59a7a841,0xabe6bfed,0x44c8eb00,0x2cc09c04,0xf0c4e16b,0xe05b3080,0xa45f3314,0x1eb7777a,0xce5d45e3,0x56af7bed,0x88b12f1a,0x2b6e019a,0xfd835f9b,0x086659cd
.long	0x9dc21ec8,0x2c18dbd1,0x0fcf8139,0x98f9868a,0x48250b49,0x737d2cd6,0x24b3428f,0xcc61c947,0x80dd9e76,0x0c2b4078,0x383fbe08,0xc43a8991,0x779be5d2,0x5f7d2d65,0xeb3b4ab5,0x78719a54
.long	0x6245e404,0xea7d260a,0x6e7fdfe0,0x9de40795,0x8dac1ab5,0x1ff3a415,0x649c9073,0x3e7090f1,0x2b944e88,0x1a768561,0xe57f61c8,0x250f939e,0x1ead643d,0x0c0daa89,0xe125b88e,0x68930023
.long	0xd2697768,0x04b71aa7,0xca345a33,0xabdedef5,0xee37385e,0x2409d29d,0xcb83e156,0x4ee1df77,0x1cbb5b43,0x0cac12d9,0xca895637,0x170ed2f6,0x8ade6d66,0x28228cfa,0x53238aca,0x7ff57c95
.long	0x4b2ed709,0xccc42563,0x856fd30d,0x0e356769,0x559e9811,0xbcbcd43f,0x5395b759,0x738477ac,0xc00ee17f,0x35752b90,0x742ed2e3,0x68748390,0xbd1f5bc1,0x7cd06422,0xc9e7b797,0xfbc08769
.long	0xb0cf664a,0xa242a35b,0x7f9707e3,0x126e48f7,0xc6832660,0x1717bf54,0xfd12c72e,0xfaae7332,0x995d586b,0x27b52db7,0x832237c2,0xbe29569e,0x2a65e7db,0xe8e4193e,0x2eaa1bbb,0x152706dc
.long	0xbc60055b,0x72bcd8b7,0x56e27e4b,0x03cc23ee,0xe4819370,0xee337424,0x0ad3da09,0xe2aa0e43,0x6383c45d,0x40b8524f,0x42a41b25,0xd7663554,0x778a4797,0x64efa6de,0x7079adf4,0x2042170a
.long	0x0bc6fb80,0x808b0b65,0x3ffe2e6b,0x5882e075,0x2c83f549,0xd5ef2f7c,0x9103b723,0x54d63c80,0x52a23f9b,0xf2f11bd6,0x4b0b6587,0x3670c319,0xb1580e9e,0x55c4623b,0x01efe220,0x64edf7b2
.long	0xd53c5c9d,0x97091dcb,0xac0a177b,0xf17624b6,0x2cfe2dff,0xb0f13975,0x6c7a574e,0xc1a35c0a,0x93e79987,0x227d3146,0xe89cb80e,0x0575bf30,0x0d1883bb,0x2f4e247f,0x3274c3d0,0xebd51226
.long	0x56ada97a,0x5f3e51c8,0x8f8b403e,0x4afc964d,0x412e2979,0xa6f247ab,0x6f80ebda,0x675abd1b,0x5e485a1d,0x66a2bd72,0x8f4f0b3c,0x4b2a5caf,0x1b847bba,0x2626927f,0x0502394d,0x6c6fc7d9
.long	0xa5659ae8,0xfea912ba,0x25e1a16e,0x68363aba,0x752c41ac,0xb8842277,0x2897c3fc,0xfe545c28,0xdc4c696b,0x2d36e9e7,0xfba977c5,0x5806244a,0xe39508c1,0x85665e9b,0x6d12597b,0xf720ee25
.long	0xd2337a31,0x8a979129,0x0f862bdc,0x5916868f,0x5dd283ba,0x048099d9,0xfe5bfb4e,0xe2d1eeb6,0x7884005d,0x82ef1c41,0xffffcbae,0xa2d4ec17,0x8aa95e66,0x9161c53f,0xc5fee0d0,0x5ee104e1
.long	0xc135b208,0x562e4cec,0x4783f47d,0x74e1b265,0x5a3f3b30,0x6d2a506c,0xc16762fc,0xecead9f4,0xe286e5b9,0xf29dd4b2,0x83bb3c61,0x1b0fadc0,0x7fac29a4,0x7a75023e,0xc9477fa3,0xc086d5f1
.long	0x2f6f3076,0x0fc61135,0xe3912a9a,0xc99ffa23,0xd2f8ba3d,0x6a0b0685,0xe93358a4,0xfdc777e8,0x35415f04,0x94a787bb,0x4d23fea4,0x640c2d6a,0x153a35b5,0x9de917da,0x5d5cd074,0x793e8d07
.long	0x2de45068,0xf4f87653,0x9e2e1f6e,0x37c7a7e8,0xa3584069,0xd0825fa2,0x1727bf42,0xaf2cea7c,0x9e4785a9,0x0360a4fb,0x27299f4a,0xe5fda49c,0x71ac2f71,0x48068e13,0x9077666f,0x83d0687b
.long	0x15d02819,0x6d3883b2,0x40dd9a35,0x6d0d7550,0x1d2b469f,0x61d7cbf9,0x2efc3115,0xf97b232f,0xb24bcbc7,0xa551d750,0x88a1e356,0x11ea4949,0x93cb7501,0x7669f031,0xca737b8a,0x595dc55e
.long	0xd837879f,0xa4a319ac,0xed6b67b0,0x6fc1b49e,0x32f1f3af,0xe3959933,0x65432a2e,0x966742eb,0xb4966228,0x4b8dc9fe,0x43f43950,0x96cc6312,0xc9b731ee,0x12068859,0x56f79968,0x7b948dc3
.long	0xed1f8008,0x61e4ad32,0xd8b17538,0xe6c9267a,0x857ff6fb,0x1ac7c5eb,0x55f2fb10,0x994baaa8,0x1d248018,0x84cf14e1,0x628ac508,0x5a39898b,0x5fa944f5,0x14fde97b,0xd12e5ac7,0xed178030
.long	0x97e2feb4,0x042c2af4,0xaebf7313,0xd36a42d7,0x084ffdd7,0x49d2c9eb,0x2ef7c76a,0x9f8aa54b,0x09895e70,0x9200b7ba,0xddb7fb58,0x3bd0c66f,0x78eb4cbb,0x2d97d108,0xd84bde31,0x2d431068
.long	0x172ccd1f,0x4b523eb7,0x30a6a892,0x7323cb28,0xcfe153eb,0x97082ec0,0xf2aadb97,0xe97f6b6a,0xd1a83da1,0x1d3d393e,0x804b2a68,0xa6a7f9c7,0x2d0cb71e,0x4a688b48,0x40585278,0xa9b4cc5f
.long	0xcb66e132,0x5e5db46a,0x0d925880,0xf1be963a,0x0317b9e2,0x944a7027,0x48603d48,0xe266f959,0x5c208899,0x98db6673,0xa2fb18a3,0x90472447,0x777c619f,0x8a966939,0x2a3be21b,0x3798142a
.long	0x3298b343,0xb4241cb1,0xb44f65a1,0xa3a14e49,0x3ac77acd,0xc5f4d6cd,0x52b6fc3c,0xd0288cb5,0x1c040abc,0xd5cc8c2f,0x06bf9b4a,0xb675511e,0x9b3aa441,0xd667da37,0x51601f72,0x460d45ce
.long	0x6755ff89,0xe2f73c69,0x473017e6,0xdd3cf7e7,0x3cf7600d,0x8ef5689d,0xb1fc87b4,0x948dc4f8,0x4ea53299,0xd9e9fe81,0x98eb6028,0x2d921ca2,0x0c9803fc,0xfaecedfd,0x4d7b4745,0xf38ae891
.long	0xc5e3a3d8,0xd8c5fccf,0x4079dfbf,0xbefd904c,0xfead0197,0xbc6d6a58,0x695532a4,0x39227077,0xdbef42f5,0x09e23e6d,0x480a9908,0x7e449b64,0xad9a2e40,0x7b969c1a,0x9591c2a4,0x6231d792
.long	0x0f664534,0x87151456,0x4b68f103,0x85ceae7c,0x65578ab9,0xac09c4ae,0xf044b10c,0x33ec6868,0x3a8ec1f1,0x6ac4832b,0x5847d5ef,0x5509d128,0x763f1574,0xf909604f,0xc32f63c4,0xb16c4303
.long	0x7ca23cd3,0xb6ab2014,0xa391849d,0xcaa7a5c6,0x75678d94,0x5b0673a3,0xdd303e64,0xc982ddd4,0x5db6f971,0xfd7b000b,0x6f876f92,0xbba2cb1f,0x3c569426,0xc77332a3,0x570d74f8,0xa159100c
.long	0xdec67ef5,0xfd16847f,0x233e76b7,0x742ee464,0xefc2b4c8,0x0b8e4134,0x42a3e521,0xca640b86,0x8ceb6aa9,0x653a0190,0x547852d5,0x313c300c,0x6b237af7,0x24e4ab12,0x8bb47af8,0x2ba90162
.long	0xa8219bb7,0x3d5e58d6,0x1b06c57f,0xc691d0bd,0xd257576e,0x0ae4cb10,0xd54a3dc3,0x3569656c,0x94cda03a,0xe5ebaebd,0x162bfe13,0x934e82d3,0xe251a0c6,0x450ac0ba,0xdd6da526,0x480b9e11
.long	0x8cce08b5,0x00467bc5,0x7f178d55,0xb636458c,0xa677d806,0xc5748bae,0xdfa394eb,0x2763a387,0x7d3cebb6,0xa12b448a,0x6f20d850,0xe7adda3e,0x1558462c,0xf63ebce5,0x620088a8,0x58b36143
.long	0x4d63c0ee,0x8a2cc3ca,0x0fe948ce,0x51233117,0x222ef33b,0x7463fd85,0x7c603d6c,0xadf0c7dc,0xfe7765e5,0x0ec32d3b,0xbf380409,0xccaab359,0x8e59319c,0xbdaa84d6,0x9c80c34d,0xd9a4c280
.long	0xa059c142,0xa9d89488,0xff0b9346,0x6f5ae714,0x16fb3664,0x068f237d,0x363186ac,0x5853e4c4,0x63c52f98,0xe2d87d23,0x81828876,0x2ec4a766,0xe14e7b1c,0x47b864fa,0x69192408,0x0c0bc0e5
.long	0xb82e9f3e,0xe4d7681d,0xdf25e13c,0x83200f0b,0x66f27280,0x8909984c,0x75f73227,0x462d7b00,0xf2651798,0xd90ba188,0x36ab1c34,0x74c6e18c,0x5ef54359,0xab256ea3,0xd1aa702f,0x03466612
.long	0x2ed22e91,0x624d6049,0x6f072822,0x6fdfe0b5,0x39ce2271,0xeeca1115,0xdb01614f,0x98100a4f,0xa35c628f,0xb6b0daa2,0xc87e9a47,0xb6f94d2e,0x1d57d9ce,0xc6773259,0x03884a7b,0xf70bfeec
.long	0xed2bad01,0x5fb35ccf,0x1da6a5c7,0xa155cbe3,0x30a92f8f,0xc2e2594c,0x5bfafe43,0x649c89ce,0xe9ff257a,0xd158667d,0xf32c50ae,0x9b359611,0x906014cf,0x4b00b20b,0x89bc7d3d,0xf3a8cfe3
.long	0x248a7d06,0x4ff23ffd,0x878873fa,0x80c5bfb4,0x05745981,0xb7d9ad90,0x3db01994,0x179c85db,0x61a6966c,0xba41b062,0xeadce5a8,0x4d82d052,0xa5e6a318,0x9e91cd3b,0x95b2dda0,0x47795f4f
.long	0xd55a897c,0xecfd7c1f,0xb29110fb,0x009194ab,0xe381d3b0,0x5f0e2046,0xa98dd291,0x5f3425f6,0x730d50da,0xbfa06687,0x4b083b7f,0x0423446c,0xd69d3417,0x397a247d,0x387ba42a,0xeb629f90
.long	0xd5cd79bf,0x1ee426cc,0x946c6e18,0x0032940b,0x57477f58,0x1b1e8ae0,0x6d823278,0xe94f7d34,0x782ba21a,0xc747cb96,0xf72b33a5,0xc5254469,0xc7f80c81,0x772ef6de,0x2cd9e6b5,0xd73acbfe
.long	0x49ee90d9,0x4075b5b1,0xa06e9eba,0x785c339a,0xabf825e0,0xa1030d5b,0xa42931dc,0xcec684c3,0xc1586e63,0x42ab62c9,0x5ab43f2b,0x45431d66,0x55f7835d,0x57c8b2c0,0xc1b7f865,0x033da338
.long	0xcaa76097,0x283c7513,0x36c83906,0x0a624fa9,0x715af2c7,0x6b20afec,0xeba78bfd,0x4b969974,0xd921d60e,0x220755cc,0x7baeca13,0x9b944e10,0x5ded93d4,0x04819d51,0x6dddfd27,0x9bbff86e
.long	0x77adc612,0x6b344130,0xbbd803a0,0xa7496529,0x6d8805bd,0x1a1baaa7,0x470343ad,0xc8403902,0x175adff1,0x39f59f66,0xb7d8c5b7,0x0b26d7fb,0x529d75e3,0xa875f5ce,0x41325cc2,0x85efc7e9
.long	0x1ff6acd3,0x21950b42,0x53dc6909,0xffe70484,0x28766127,0xff4cd0b2,0x4fb7db2b,0xabdbe608,0x5e1109e8,0x837c9228,0xf4645b5a,0x26147d27,0xf7818ed8,0x4d78f592,0xf247fa36,0xd394077e
.long	0x488c171a,0x0fb9c2d0,0x13685278,0xa78bfbaa,0xd5b1fa6a,0xedfbe268,0x2b7eaba7,0x0dceb8db,0x9ae2b710,0xbf9e8089,0xa4449c96,0xefde7ae6,0xcc143a46,0x43b7716b,0xc3628c13,0xd7d34194
.long	0x3b3f64c9,0x508cec1c,0x1e5edf3f,0xe20bc0ba,0x2f4318d4,0xda1deb85,0x5c3fa443,0xd20ebe0d,0x73241ea3,0x370b4ea7,0x5e1a5f65,0x61f1511c,0x82681c62,0x99a5e23d,0xa2f54c2d,0xd731e383
.long	0x83445904,0x2692f36e,0xaf45f9c0,0x2e0ec469,0xc67528b7,0x905a3201,0xd0e5e542,0x88f77f34,0x5864687c,0xf67a8d29,0x22df3562,0x23b92eae,0x9bbec39e,0x5c27014b,0x9c0f0f8d,0x7ef2f226
.long	0x546c4d8d,0x97359638,0x92f24679,0x5f9c3fc4,0xa8c8acd9,0x912e8bed,0x306634b0,0xec3a318d,0xc31cb264,0x80167f41,0x522113f2,0x3db82f6f,0xdcafe197,0xb155bcd2,0x43465283,0xfba1da59
.long	0xb212cf53,0xa0425b8e,0xf8557c5f,0x4f2e512e,0x25c4d56c,0xc1286ff9,0xee26c851,0xbb8a0fea,0xe7d6107e,0xc28f70d2,0xe76265aa,0x7ee0c444,0x1d1936b1,0x3df277a4,0xea9595eb,0x1a556e3f
.long	0xe7305683,0x258bbbf9,0x07ef5be6,0x31eea5bf,0x46c814c1,0x0deb0e4a,0xa7b730dd,0x5cee8449,0xa0182bde,0xeab495c5,0x9e27a6b4,0xee759f87,0x80e518ca,0xc2cf6a68,0xf14cf3f4,0x25e8013f
.long	0x7e8d7a14,0x8fc44140,0x9556f36a,0xbb1ff3ca,0x14600044,0x6a844385,0x7451ae63,0xba3f0c4a,0x1f9af32a,0xdfcac25b,0xb1f2214b,0x01e0db86,0xa4b596ac,0x4e9a5bc2,0x026c2c08,0x83927681
.long	0x7acaca28,0x3ec832e7,0xc7385b29,0x1bfeea57,0xfd1eaf38,0x068212e3,0x6acf8ccc,0xc1329830,0x2aac9e59,0xb909f2db,0xb661782a,0x5748060d,0xc79b7a01,0xc5ab2632,0x00017626,0xda44c6c6
.long	0xa7ea82f0,0xf26c00e8,0xe4299aaf,0x99cac80d,0x7ed78be1,0xd66fe3b6,0x648d02cd,0x305f725f,0x623fb21b,0x33ed1bc4,0x7a6319ad,0xfa70533e,0xbe5ffb3e,0x17ab562d,0x56674741,0x06374994
.long	0x5c46aa8e,0x69d44ed6,0xa8d063d1,0x2100d5d3,0xa2d17c36,0xcb9727ea,0x8add53b7,0x4c2bab1b,0x15426704,0xa084e90c,0xa837ebea,0x778afcd3,0x7ce477f8,0x6651f701,0x46fb7a8b,0xa0624998
.long	0xed8a6e19,0xdc1e6828,0x4189d9c7,0x33fc2336,0x671c39bc,0x026f8fe2,0xbc6f9915,0xd40c4ccd,0xf80e75ca,0xafa135bb,0x22adff2c,0x12c651a0,0x4f51ad96,0xc40a04bd,0xbbe4e832,0x04820109
.long	0x7f4c04cc,0x3667eb1a,0xa9404f84,0x59556621,0x7eceb50a,0x71cdf653,0x9b8335fa,0x994a44a6,0xdbeb9b69,0xd7faf819,0xeed4350d,0x473c5680,0xda44bba2,0xb6658466,0x872bdbf3,0x0d1bc780
.long	0xa1962f91,0xe535f175,0xed58f5a7,0x6ed7e061,0x2089a233,0x177aa4c0,0xe539b413,0x0dbcb03a,0xbb32e38e,0xe3dc424e,0x6806701e,0x6472e5ef,0x814be9ee,0xdd47ff98,0x35ace009,0x6b60cfff
.long	0x9ff91fe5,0xb8d3d931,0xf0518eed,0x039c4800,0x9182cb26,0x95c37632,0x82fc568d,0x0763a434,0x383e76ba,0x707c04d5,0x824e8197,0xac98b930,0x91230de0,0x92bf7c8f,0x40959b70,0x90876a01
.long	0x05968b80,0xdb6d96f3,0x089f73b9,0x380a0913,0xc2c61e01,0x7da70b83,0x569b38c7,0x95fb8394,0x80edfe2f,0x9a3c6512,0x8faeaf82,0x8f726bb9,0x78424bf8,0x8010a4a0,0x0e844970,0x29672044
.long	0x7a2ad62a,0x63c5cb81,0xac62ff54,0x7ef2b6b9,0xb3ad9db5,0x3749bba4,0x46d5a617,0xad311f2c,0xc2ff3b6d,0xb77a8087,0x367834ff,0xb46feaf3,0x75d6b138,0xf8aa266d,0xec008188,0xfa38d320
.long	0x696946fc,0x486d8ffa,0xb9cba56d,0x50fbc6d8,0x90f35a15,0x7e3d423e,0xc0dd962c,0x7c3da195,0x3cfd5d8b,0xe673fdb0,0x889dfca5,0x0704b7c2,0xf52305aa,0xf6ce581f,0x914d5e53,0x399d49eb
.long	0x6ec293cd,0x380a496d,0x8e7051f5,0x733dbda7,0xb849140a,0x037e388d,0x5946dbf6,0xee4b32b0,0xcae368d1,0xb1c4fda9,0xfdb0b2f3,0x5001a7b0,0x2e3ac46e,0x6df59374,0x39b3e656,0x4af675f2
.long	0x39949296,0x44e38110,0x361db1b5,0x5b63827b,0x206eaff5,0x3e5323ed,0xc21f4290,0x942370d2,0xe0d985a1,0xf2caaf2e,0x7239846d,0x192cc64b,0xae6312f8,0x7c0b8f47,0x96620108,0x7dc61f91
.long	0xc2da7de9,0xb830fb5b,0x0ff8d3be,0xd0e643df,0x188a9641,0x31ee77ba,0xbcf6d502,0x4e8aa3aa,0x9a49110f,0xf9fb6532,0x2dd6b220,0xd18317f6,0x52c3ea5a,0x7e3ced41,0x7d579c4a,0x0d296a14
.long	0xed4c3717,0x35d6a53e,0x3d0ed2a3,0x9f8240cf,0xe5543aa5,0x8c0d4d05,0xdd33b4b4,0x45d5bbfb,0x137fd28e,0xfa04cc73,0xc73b3ffd,0x862ac6ef,0x31f51ef2,0x403ff9f5,0xbc73f5a2,0x34d5e0fc
.long	0x08913f4f,0xf2526820,0xeac93d95,0xea20ed61,0x6ca6b26c,0x51ed38b4,0xea4327b0,0x8662dcbc,0x725d2aaa,0x6daf295c,0x8e52dcda,0xbad2752f,0x0b17dacc,0x2210e721,0xd51e8232,0xa37f7912
.long	0x44cc3add,0x4f7081e1,0x87be82cf,0xd5ffa1d6,0x0edd6472,0x89890b6c,0x3ed17863,0xada26e1a,0x63483caa,0x276f2715,0x2f6077fd,0xe6924cd9,0x0a466e3c,0x05a7fe98,0xb1902d1f,0xf1c794b0
.long	0x82a8042c,0xe5213688,0xcd278298,0xd931cfaf,0xf597a740,0x069a0ae0,0xeb59107c,0x0adbb3f3,0x5eaa8eb8,0x983e951e,0x11b48e78,0xe663a8b5,0x8a03f2c5,0x1631cc0d,0x11e271e2,0x7577c11e
.long	0x08369a90,0x33b2385c,0x190eb4f8,0x2990c59b,0xc68eac80,0x819a6145,0x2ec4a014,0x7a786d62,0x20ac3a8d,0x33faadbe,0x5aba2d30,0x31a21781,0xdba4f565,0x209d2742,0x55aa0fbb,0xdb2ce9e3
.long	0x168984df,0x8cef334b,0x33879638,0xe81dce17,0x263720f0,0xf6e6949c,0xf593cbec,0x5c56feaf,0xfde58c84,0x8bff5601,0x2eccb314,0x74e24117,0x4c9a8a78,0xbcf01b61,0x544c9868,0xa233e35e
.long	0x8bd7aff1,0xb3156bf3,0x1d81b146,0x1b5ee4cb,0xd628a915,0x7ba1ac41,0xfd89699e,0x8f3a8f9c,0xa0748be7,0x7329b9c9,0xa92e621f,0x1d391c95,0x4d10a837,0xe51e6b21,0x4947b435,0xd255f53a
.long	0xf1788ee3,0x07669e04,0xa86938a2,0xc14f27af,0xe93a01c0,0x8b47a334,0xd9366808,0xff627438,0xca2a5965,0x7a0985d8,0xd6e9b9b3,0x3d9a5542,0x4cf972e8,0xc23eb80b,0x4fdf72fd,0x5c1c33bb
.long	0x74a86108,0x0c4a58d4,0xee4c5d90,0xf8048a8f,0xe86d4c80,0xe3c7c924,0x056a1e60,0x28c889de,0xb214a040,0x57e2662e,0x37e10347,0xe8c48e98,0x80ac748a,0x87742862,0x186b06f2,0xf1c24022
.long	0x5f74040a,0xac2dd4c3,0xfceac957,0x409aeb71,0x55c4ec23,0x4fbad782,0x8a7b76ec,0xb359ed61,0xed6f4a60,0x12744926,0x4b912de3,0xe21e8d7f,0xfc705a59,0xe2575a59,0xed2dbc0e,0x72f1d4de
.long	0xeb7926b8,0x3d2b24b9,0xcdbe5509,0xbff88cb3,0xe4dd640b,0xd0f399af,0x2f76ed45,0x3c5fe130,0x3764fb3d,0x6f3562f4,0x3151b62d,0x7b5af318,0xd79ce5f3,0xd5bd0bc7,0xec66890f,0xfdaf6b20
.long	0x6063540c,0x735c67ec,0xe5f9cb8f,0x50b259c2,0x3f99c6ab,0xb8734f9a,0xa3a7bc85,0xf8cc13d5,0xc5217659,0x80c1b305,0x4ec12a54,0xfe5364d4,0x681345fe,0xbd87045e,0x582f897f,0x7f8efeb1
.long	0xd5923359,0xe8cbf1e5,0x539b9fb0,0xdb0cea9d,0x49859b98,0x0c5b34cf,0xa4403cc6,0x5e583c56,0xd48185b7,0x11fc1a2d,0x6e521787,0xc93fbc7e,0x05105b8b,0x47e7a058,0xdb8260c8,0x7b4d4d58
.long	0x46eb842a,0xe33930b0,0x7bdae56d,0x8e844a9a,0x13f7fdfc,0x34ef3a9e,0x636ca176,0xb3768f82,0x4e09e61c,0x2821f4e0,0xa0c7cddc,0x414dc3a1,0x54945fcd,0xd5379437,0xb3555ff1,0x151b6eef
.long	0x6339c083,0xb31bd613,0xdfb64701,0x39ff8155,0xe29604ab,0x7c3388d2,0xa6b10442,0x1e19084b,0xeccd47ef,0x17cf54c0,0x4a5dfb30,0x89693385,0x47daf9f6,0x69d023fb,0x7d91d959,0x9222840b
.long	0x803bac62,0x439108f5,0x379bd45f,0x0b7dd91d,0xca63c581,0xd651e827,0x509c104f,0x5c5d75f6,0x1f2dc308,0x7d5fc738,0xd98454be,0x20faa7bf,0xa517b031,0x95374bee,0x642692ac,0xf036b9b1
.long	0x39842194,0xc5106109,0x49d05295,0xb7e2353e,0xefb42ee0,0xfc8c1d5c,0x08ce811c,0xe04884eb,0x7419f40e,0xf1f75d81,0xa995c241,0x5b0ac162,0xc4c55646,0x120921bb,0x8d33cf97,0x713520c2
.long	0xe98c5100,0xb4a65a5c,0x2ddd0f5a,0x6cec871d,0x9ba2e78b,0x251f0b7f,0xce3a2a5f,0x224a8434,0x25f5c46f,0x26827f61,0x48545ec0,0x6a22bedc,0xb1bb5cdc,0x25ae5fa0,0xfcb9b98f,0xd693682f
.long	0x91e5d7d3,0x32027fe8,0x73a07678,0xf14b7d17,0xc0dfdd61,0xf88497b3,0x2a8c4f48,0xf7c2eec0,0x3756e621,0xaa5573f4,0x1825b948,0xc013a240,0x63878572,0x1c03b345,0x653a4184,0xa0472bea
.long	0x0ac69a80,0xf4222e27,0xf51e54f6,0x34096d25,0x8fffa591,0x00a648cb,0x69b6527f,0x4e87acdc,0xe285ccb4,0x0575e037,0x50ddcf52,0x188089e4,0x870ff719,0xaa96c9a8,0x1fc7e369,0x74a56cd8
.long	0x1726931a,0x41d04ee2,0x3660ecfd,0x0bbbb2c8,0x24818e18,0xa6ef6de5,0xe7d57887,0xe421cc51,0xbea87be6,0xf127d208,0xb1cdd682,0x16a475d3,0x439b63f7,0x9db1b684,0xf0f113b6,0x5359b3db
.long	0x8bf06e31,0xdfccf1de,0xdd383901,0x1fdf8f44,0x5017e7d2,0x10775cad,0x58d11eef,0xdfc3a597,0xb1ecff10,0x6ec9c8a0,0x28400549,0xee6ed6cc,0x1b4f8d73,0xb5ad7bae,0xe00aaab9,0x61b4f11d
.long	0xd4eff2d7,0x7b32d69b,0x4288b60f,0x88ae6771,0x37a1e723,0x159461b4,0x570aae8c,0x1f3d4789,0x7f9871da,0x869118c0,0xf635e278,0x35fbda78,0xe1541dac,0x738f3641,0xc0dae45f,0x6794b13a
.long	0x09cc0917,0x065064ac,0xc68540fd,0x27c53729,0xef227671,0x0d2d4c8e,0xa1785a04,0xd23a9f80,0x52650359,0x98c59528,0x74a1acad,0xfa09ad01,0x0b55bf5c,0x082d5a29,0x419b8084,0xa40f1c67
.long	0xdcc18770,0x3a5c752e,0x8825c3a5,0x4baf1f2f,0x21b153ed,0xebd63f74,0xb2f64723,0xa2383e47,0x2646d19a,0xe7bf620a,0x03c83ffd,0x56cb44ec,0x4f6be9f1,0xaf7267c9,0xc06bb5e9,0x8b2dfd7b
.long	0xa672c5c7,0xb87072f2,0x0d53c5e2,0xeacb11c8,0xff435932,0x22dac29d,0x4408693c,0x37bdb99d,0x2899c20f,0xf6e62fb6,0x447ece24,0x3535d512,0xff577ce3,0xfbdc6b88,0x190575f2,0x726693bd
.long	0xab4b35a2,0x6772b0e5,0xf5eeaacf,0x1d8b6001,0x795b9580,0x728f7ce4,0x41fb81da,0x4a20ed2a,0x4fec01e6,0x9f685cd4,0xa7ff50ad,0x3ed7ddcc,0x0c2d97fd,0x460fd264,0xeb82f4f9,0x3a241426
.long	0x6a8ea820,0x17d1df2c,0xf22cc254,0xb2b50d3b,0xb7291426,0x03856cba,0x04f5ee39,0x87fd26ae,0x02bee4ba,0x9cb696cc,0x06820fd6,0x53121804,0x0212e985,0xa5dfc269,0x160f9a09,0x666f7ffa
.long	0xbccd9617,0xc503cd33,0xba7730a3,0x365dede4,0x5ddb0786,0x798c6355,0xfc9cd3bc,0xa6c3200e,0xe5e35efd,0x060ffb2c,0x5555a1c1,0x99a4e25b,0xf70b3751,0x11d95375,0x160e1bf6,0x0a57354a
.long	0xf8e4b065,0xecb3ae4b,0x2e53022b,0x07a834c4,0x8692ed96,0x1cd300b3,0x61ee14ec,0x16a6f792,0x6a8649ed,0x8f1063c6,0x869f3e14,0xfbcdfcfe,0x00a7b3ec,0x2cfb97c1,0x7130c2f1,0xcea49b3c
.long	0xe9d96488,0x462d044f,0x8182a0c1,0x4b53d52e,0x0391e9e9,0x84b6ddd3,0xb1741a09,0x80ab7b48,0x27d3317f,0xec0e15d4,0x1a64671e,0x8dfc1ddb,0xd49c5b92,0x93cc5d5f,0x3674a331,0xc995d53d
.long	0x090090ae,0x302e41ec,0xedb06830,0x2278a0cc,0xfbc99690,0x1d025932,0xb80d68da,0x0c32fbd2,0xf341a6c1,0xd79146da,0x1bef68a0,0xae0ba139,0x8d774b3a,0xc6b8a563,0x880ba4d7,0x1cf307bd
.long	0x19803511,0xc033bdc7,0x8888c3be,0xa9f97b3b,0x85c6d05e,0x3d68aebc,0x193919eb,0xc3b88a9d,0xc48b0ee3,0x2d300748,0x07a746c1,0x7506bc7c,0x6e6d57f3,0xfc48437c,0xcfeaa91a,0x5bd71587
.long	0xc1bc5225,0xa4ed0408,0x2719226d,0xd0b946db,0x758d2d43,0x109ecd62,0x2751759b,0x75c8485a,0x9ce4177a,0xb0b75f49,0x79c10c3d,0x4fa61a1e,0xa167fcd7,0xc062d300,0x750f0fa8,0x4df3874c
.long	0x83dfedc9,0x29ae2cf9,0x8d87631a,0xf8437134,0x7429c8d2,0xaf571711,0x146d9272,0x18d15867,0x69769bb7,0x83053ecf,0xc479ab82,0xc55eb856,0x21b0f4b2,0x5ef7791c,0x3d491525,0xaa5956ba
.long	0x9fe20eba,0x407a96c2,0xe52a5ad3,0xf27168bb,0xbf1d9d89,0x43b60ab3,0x710e727a,0xe45c51ef,0x099b4221,0xdfca5276,0x2557a159,0x8dc6407c,0x91035895,0x0ead8335,0x9c55dc32,0x0a9db957
.long	0xdf61bc76,0xe40736d3,0x3f778cdb,0x13a619c0,0xc56ea28f,0x6dd921a4,0x2fa647b4,0x76a52433,0xac5bdc5d,0x23591891,0xbac7dc01,0xff4a1a72,0x62df8453,0x9905e261,0xe63b265f,0x3ac045df
.long	0xad53dba7,0x8a3f341b,0x837b625a,0x8ec269cc,0x3ae31189,0xd71a2782,0x55e96120,0x8fb4f9a3,0xff9875cf,0x804af823,0x5d442a9b,0x23224f57,0xecc62679,0x1c4d3b9e,0xa0e7ddb1,0x91da22fb
.long	0x6c04a661,0xa370324d,0x5e376d17,0x9710d3b6,0x3044e357,0xed8c98f0,0x6422701c,0xc364ebbe,0x7733d61c,0x347f5d51,0xcea826c3,0xd55644b9,0x55a25548,0x80c6e0ad,0x844220a7,0x0aa7641d
.long	0x31810660,0x1438ec81,0xde4b4043,0x9dfa6507,0xcc3e0273,0x10b515d8,0x28d8cfb2,0x1b6066dd,0x9c9efebd,0xd3b04591,0xa21c1ff4,0x425d4bdf,0xd57607d3,0x5fe5af19,0x54481084,0xbbf773f7
.long	0x94b03ed1,0x8435bd69,0x634cc546,0xd9ad1de3,0x00e420ca,0x2cf423fc,0xa03096dd,0xeed26d80,0xa4db09d2,0xd7f60be7,0x960622f7,0xf47f569d,0x7296c729,0xe5925fd7,0x26ca2715,0xeff2db26
.long	0xb913e759,0xa6fcd014,0x8ff4de93,0x53da4786,0xc32068e1,0x14616d79,0xccdf352e,0xb187d664,0x1dc90b59,0xf7afb650,0x7daa1b26,0x8170e943,0x700c0a84,0xc8e3bdd8,0x6482bdfa,0x6e8d345f
.long	0xc5c5ea50,0x84cfbfa1,0x67960681,0xd3baf14c,0x0dd50942,0x26398403,0x4716a663,0xe4b7839c,0xe7de6dc0,0xd5f1f794,0x622aa7ce,0x5cd0f4d4,0x59acfeec,0x5295f3f1,0x953e0607,0x8d933552
.long	0x776c5722,0xc7db8ec5,0x2b5f290c,0xdc467e62,0x4ff425a9,0xd4297e70,0x0cf7bb72,0x4be924c1,0xa1892131,0x0d5dc5ae,0xa705c992,0x8bf8a8e3,0x7a305ac5,0x73a0b064,0x9a8c77a8,0x00c9ca4e
.long	0x83774bdd,0x5dfee80f,0x85734485,0x63131602,0x914a69a9,0xa1b524ae,0xd4e300d7,0xebc2ffaf,0x7cfa46a5,0x52c93db7,0x21653b50,0x71e6161f,0xa4bc580a,0x3574fc57,0xe1bc1253,0xc09015dd
.long	0xd174d7aa,0x4b7b47b2,0xf3a15d04,0x4072d8e8,0xd6fa07ed,0xeeb7d47f,0xedbdafb1,0x6f2b9ff9,0x3760fe8a,0x18c51615,0xf06c6c13,0x7a96e6bf,0x0ea2d071,0x4d7a0410,0x0be2a5ce,0xa1914e9b
.long	0xd8a3c5cf,0x5726e357,0x2abb2b13,0x1197ecc3,0x31ae88dd,0x6c0d7f7f,0xfdbb3efe,0x15b20d1a,0x70584039,0xcd06aa26,0xa7dc9747,0x2277c969,0x7855d815,0xbca69587,0x5188b32a,0x899ea238
.long	0x760c1c9d,0x37d9228b,0x9b5c18da,0xc7efbb11,0x19f6dbc5,0x7f0d1bc8,0x07e6905b,0x4875384b,0x3ba8cd86,0xc7c50baa,0xc2905de0,0xb0ce40fb,0x7a231952,0x70840673,0xcf43de26,0xa912a262
.long	0xeb5b76c1,0x9c38ddcc,0x26fc0ab4,0x746f5285,0xd62c269f,0x52a63a50,0x99458621,0x60049c55,0x3c2f7c9e,0xe7f48f82,0x917d5cf3,0x6bd99043,0x8701f469,0xeb1317a8,0x9a449fe0,0xbd3fe2ed
.long	0x12ef3d36,0x421e79ca,0x3e7ea5de,0x9ee3c36c,0xcdff36f7,0xe48198b5,0xc6b82228,0xaff4f967,0xc47adb7e,0x15e19dd0,0x032e7dfa,0x45699b23,0x1fae026a,0x40680c8b,0x550dbf4d,0x5a347a48
.long	0x3cef0d7d,0xe652533b,0x2bbb4381,0xd94f7b18,0x0e80f500,0x838752be,0x9e9c9bfb,0x8e6e2488,0x16caca6a,0xc9751697,0x38531ad9,0x866c49d8,0x7151ade1,0xc917e239,0x6037c407,0x2d016ec1
.long	0x00eac3f9,0xa407ccc9,0xe2ed4748,0x835f6280,0x1cc98e0d,0xcc54c347,0xdcb572eb,0x0e969937,0x8f30c9cb,0x1b16c8e8,0x373c4661,0xa606ae75,0x35502cab,0x47aa689b,0x4d9bb64f,0xf89014ae
.long	0x31c71f7b,0x202f6a9c,0x296ffe5c,0x01f95aa3,0x53cec3a3,0x5fc06014,0x5f498a45,0xeb991237,0x5d91ba87,0xae9a935e,0x0b564a19,0xc6ac6281,0x3bd44e69,0x8a8fe81c,0x9dd11d45,0x7c8b467f
.long	0xea5b8e69,0xf772251f,0xc5b75fbc,0xaeecb3bd,0x887ff0e5,0x1aca3331,0x19f0a131,0xbe5d49ff,0xe5c8646f,0x582c13aa,0x20e19980,0xdbaa12e8,0xf7abbd94,0x8f40f31a,0x1dfc7663,0x1f13f5a8
.long	0xaceb4fc0,0x5d81f1ee,0x5e6f0f42,0x36256002,0x751370c8,0x4b67d6d7,0x03e80589,0x2608b698,0x05268301,0xcfc0d2fc,0x40309212,0xa6943d39,0x1fd0e1c2,0x192a90c2,0x37f1dc76,0xb209f113
.long	0x97bf1298,0xefcc5e06,0x219d639e,0xcbdb6730,0xb81e8c6f,0xd009c116,0x1a7ce2e5,0xa3ffdde3,0xa914d3ba,0xc53fbaaa,0x88df85ee,0x836d500f,0x66ee0751,0xd98dc71b,0x714516fd,0x5a3d7005
.long	0x39eedbba,0x21d3634d,0x0455a46d,0x35cd2e68,0xf9d7eb0c,0xc8cafe65,0x00cefb3e,0xbda3ce9e,0x2c9cf7a4,0xddc17a60,0x7bcb8773,0x01572ee4,0x8c7548df,0xa92b2b01,0xa84600e3,0x732fd309
.long	0x16543a40,0xe22109c7,0xfede3c6c,0x9acafd36,0x6824e614,0xfb206852,0xda25dca0,0x2a4544a9,0x91d60b06,0x25985262,0x28753545,0x281b7be9,0x90f13b27,0xec667b1a,0x940e2eb4,0x33a83aff
.long	0xd5d721d5,0x80009862,0x5bd3a182,0x0c3357a3,0x7aa2cda4,0x27f3a83b,0xf6f83085,0xb58ae74e,0x2e6dad6b,0x2a911a81,0xf43d6c5b,0xde286051,0xf996c4d8,0x4bdccc41,0x0ae1e24e,0xe7312ec0
.long	0x6e6485b3,0xf8d112e7,0x771c52f8,0x4d3e24db,0x684a2f6d,0x48e3ee41,0x21d95551,0x7161957d,0xcdb12a6c,0x19631283,0x2e50e164,0xbf3fa882,0x3166cc73,0xf6254b63,0xaee8cc38,0x3aefa7ae
.long	0x3b36f9fd,0x79b0fe62,0xfde19fc0,0x26543b23,0x958482ef,0x136e64a0,0x9b095825,0x23f63771,0xb6a1142e,0x14cfd596,0x335aac0b,0x5ea6aac6,0xf3081dd5,0x86a0e8bd,0x003dc12a,0x5fb89d79
.long	0xf72e34d4,0xf615c33a,0x110eec35,0x0bd9ea40,0xc1dea34e,0x1c12bc5b,0x49ae4699,0x686584c9,0x8c97b942,0x13ad95d3,0x4e5c7562,0x4609561a,0xf2737f89,0x9e94a4ae,0x371c78b6,0xf57594c6
.long	0xe3779ee3,0x0f0165fc,0xbd495d9e,0xe00e7f9d,0x20284e7a,0x1fa4efa2,0x47ac6219,0x4564bade,0xc4708e8e,0x90e6312a,0xa71e9adf,0x4f5725fb,0x3d684b9f,0xe95f55ae,0x1e94b415,0x47f7ccb1
.long	0x8d946581,0x7322851b,0xbdf4a012,0xf0d13133,0x6584dae0,0xa3510f69,0x3c9f6c6d,0x03a7c171,0xe475381a,0x5be97f38,0x85823334,0xca1ba422,0x0be17dda,0xf83cc5c7,0x0b918c0f,0x158b1494
.long	0x522e6b69,0xda3a77e5,0xbbcd6c18,0x69c908c3,0xd924fd56,0x1f1b9e48,0xaa4bb3f7,0x37c64e36,0xee478d7d,0x5a4fdbdf,0x0193f7a0,0xba75c8bc,0x56cd16df,0x84bc1e84,0x46fad151,0x1fb08f08
.long	0x842e9f30,0x8a7cabf9,0x5eab83af,0xa331d4bf,0x017f2a6a,0xd272cfba,0x83aba0e3,0x27560abc,0x0e3a6b75,0x94b83387,0x6b9f50f5,0x25c6aea2,0xb5fdf6d0,0x803d691d,0xe6333514,0x03b77509
.long	0x61a341c1,0x36178903,0x0cfd6142,0x3604dc60,0x8533316c,0x022295eb,0x44af2922,0x3dbde4ac,0x1c7eef69,0x898afc5d,0xd14f4fa1,0x58896805,0x203c21ca,0x05002160,0x40ef730b,0x6f0d1f30
.long	0x196224f8,0x8e8c44d4,0x374d079d,0x75a4ab95,0x7d48f123,0x79085ecc,0x1bf65ad8,0x56f04d31,0xbda602b2,0xe220bf1c,0xf9612c69,0x73ee1742,0x084fd06b,0x76008fc8,0xf11380d1,0x4000ef9f
.long	0x12cfe297,0x48201b4b,0x292f74e5,0x3eee129c,0xc9e874e8,0xe1fe114e,0x92c5fc41,0x899b055c,0x3a39c8cf,0x4e477a64,0x78963cc9,0x82f09efe,0xd333f863,0x6fd3fd8f,0xdc949c63,0x85132b2a
.long	0x516eb17b,0x7e06a3ab,0xd2c7372b,0x73bec06f,0xba896da6,0xe4f74f55,0x8e9eb40f,0xbb4afef8,0xe61d66b0,0x2d75bec8,0xef29300b,0x02bda4b4,0x026baa5a,0x8bbaa8de,0xa07f4440,0xff54befd
.long	0xbe7a2af3,0xbd9b8b1d,0x4fb74a72,0xec51caa9,0x63879697,0xb9937a4b,0xec2687d5,0x7c9a9d20,0x6ef5f014,0x1773e44f,0xe90c6900,0x8abcf412,0x8142161e,0x387bd022,0xfcb6ff2a,0x50393755
.long	0xed6def63,0x9813fd56,0x7d53106c,0x53cf6482,0x431f7ac1,0x991a35bd,0x63e65faf,0xf1e274dd,0x44cc7880,0xf63ffa3c,0x7c256981,0x411a426b,0x93a420e0,0xb698b9fd,0xae53f8fe,0x89fdddc0
.long	0x32398baa,0x766e0722,0x5cfca031,0x205fee42,0x7a029cf2,0xa49f5341,0x4023890d,0xa88c68b8,0x7337aaa8,0xbc275041,0x0eb384f4,0x9ed364ad,0x29aba92f,0xe0816f85,0x04e38a88,0x2e9e1941
.long	0x3dafd2d5,0x57eef44a,0x97ed98d8,0x35d1fae5,0x2307f9b1,0x50628c09,0xd6cba5c6,0x09d84aae,0x88aaa691,0x67071bc7,0xafe6cb03,0x2dea57a9,0x3d78ac01,0xdfe11bb4,0x7fd7aa51,0x7286418c
.long	0x77f7195a,0xfabf7709,0xadeb838f,0x8ec86167,0xbb4f012d,0xea1285a8,0x9a3eab3f,0xd6883503,0x309004c2,0xee5d24f8,0x13ffe95e,0xa96e4b76,0xbd223ea4,0x0cdffe12,0xb6739a53,0x8f5c2ee5
.long	0xdd968198,0x5cb4aaa5,0x72413a6c,0xfa131c52,0x9536d903,0x53d46a90,0x48606d8e,0xb270f0d3,0xa053a3bc,0x518c7564,0x1a86caef,0x088254b7,0x0ab5efd0,0xb3ba8cb4,0x4605945d,0x5c59900e
.long	0xa1887395,0xecace1dd,0x932a65de,0x40960f36,0x3aa95529,0x9611ff5c,0x7c1e5a36,0xc58215b0,0xf0e1a524,0xd48c9b58,0xf590dfb8,0xb406856b,0x9cd95662,0xc7605e04,0xa33ecf82,0x0dd036ee
.long	0xc33156b3,0xa50171ac,0x4a80172e,0xf09d24ea,0x76dc8eef,0x4e1f72c6,0x5e3d44ee,0xe60caadc,0x979b1d8f,0x006ef8a6,0x97788d26,0x60908a1c,0x266feec0,0x6e08f95b,0x22e8c94e,0x618427c2
.long	0x59145a65,0x3d613339,0xfa406337,0xcd9bc368,0x2d8a52a0,0x82d11be3,0x97a1c590,0xf6877b27,0xf5cbdb25,0x837a819b,0xde090249,0x2a4fd1d8,0x74990e5f,0x622a7de7,0x7945511b,0x840fa5a0
.long	0x6558842d,0x30b974be,0x17f3d0a6,0x70df8c64,0x7542e46d,0x7c803520,0xe4ecc823,0x7251fe7f,0x5e9aac9a,0xe59134cb,0xf0045d71,0x11bb0934,0xdbcb1d4e,0x53e5d9b5,0x92defc91,0x8d97a905
.long	0x7946d3f9,0xfe289327,0x07472273,0xe132bd24,0x1eb6ae86,0xeeeb510c,0xf0595067,0x777708c5,0x1297029e,0x18e2c8cd,0xbbf9305e,0x2c61095c,0x6b85d6d9,0xe466c258,0xda1ea530,0x8ac06c36
.long	0xa1304668,0xa365dc39,0x07f89606,0xe4a9c885,0xacc7228d,0x65a4898f,0x84ca8303,0x3e2347ff,0xea7d23a3,0xa5f6fb77,0x672a71cd,0x2fac257d,0x7e6a44d3,0x6908bef8,0x891d3d7a,0x8ff87566
.long	0x6b0cf82e,0xe58e90b3,0x2615b5e7,0x6438d246,0x669c145a,0x07b1f8fc,0x36f1e1cb,0xb0d8b2da,0xd9184c4d,0x54d5dadb,0xf93d9976,0x3dbb18d5,0xd1147d47,0x0a3e0f56,0xa0a48609,0x2afa8c8d
.long	0xbc36742c,0x275353e8,0xeea0ed90,0x898f427e,0x3e477b00,0x26f4947e,0x308741e3,0x8ad8848a,0xd74a2a46,0x6c703c38,0x9ba17ba2,0x5e3e05a9,0x4ab9a9e4,0xc1fa6f66,0x3841d6ec,0x474a2d9a
.long	0x653ae326,0x871239ad,0xa74cbb43,0x14bcf72a,0x20d4c083,0x8737650e,0x110ed4af,0x3df86536,0xb53ca555,0xd2d86fe7,0xabd5d538,0x688cb00d,0x1ad38468,0xcf81bda3,0xf01167b6,0x7ccfe3cc
.long	0x6c4c1fe6,0xcf4f47e0,0x298bbb79,0x557e1f1a,0x30d45a14,0xf93b974f,0x0baf97c4,0x174a1d2d,0xc51fbf53,0x7a003b30,0xee68b225,0xd8940991,0x1c0f4173,0x5b0aa7b7,0xa20a7153,0x975797c9
.long	0xe3533d77,0x26e08c07,0x2e341c99,0xd7222e6a,0x8d2dc4ed,0x9d60ec3d,0x7c476cf8,0xbdfe0d8f,0x1d056605,0x1fe59ab6,0x86a8551f,0xa9ea9df6,0x47fb8d8c,0x8489941e,0x4a7f1b10,0xfeb874eb
.long	0x7ee0d98f,0xfe5fea86,0xdbf61864,0x201ad34b,0x37c031d4,0x45d8fe47,0x795f0822,0xd5f49fae,0xc7f4a40c,0xdb0fb291,0x730ddd92,0x2e69d9c1,0x49d76987,0x754e1054,0x7662db87,0x8a24911d
.long	0x60a71676,0x61fc1810,0xf66a8ad1,0xe852d1a8,0x6417231e,0x172bbd65,0x3babb11f,0x0d6de7bd,0xc8e347f8,0x6fde6f88,0x9bd99cc3,0x1c587547,0x34076950,0x78e54ed0,0x796e83ba,0x97f0f334
.long	0x4924867a,0xe4dbe1ce,0x60b84917,0xbd5f51b0,0x3cb09a79,0x37530040,0xff1743d8,0xdb3fe0f8,0x556fa9db,0xed7894d8,0x23412fbf,0xfa262169,0xba7b9291,0x563be0db,0x0c9fb234,0x6ca8b8c0
.long	0xbd763802,0xed406aa9,0x65303da1,0xc21486a0,0xc7e62ec4,0x61ae291e,0xdf99333e,0x622a0492,0xbb7a8ee0,0x7fd80c9d,0x6c01aedb,0xdc2ed3bc,0x08be74ec,0x35c35a12,0x469f671f,0xd540cb1a
.long	0xcf84f6c7,0xd16ced4e,0x2d090f43,0x8561fb9c,0x6f239db4,0x7e693d79,0x77bd0d94,0xa736f928,0x2c1950ee,0x07b4d929,0x56dc11b3,0xda177543,0x7a6a878e,0xa5dfbbaa,0x4decb08a,0x1c70cb29
.long	0x6f0f7c50,0xfba28c8b,0x854dcc6d,0xa8eba2b8,0x36b78642,0x5ff8e89a,0xf6873adf,0x070c1c8e,0x6484d2e4,0xbbd3c371,0x0d414129,0xfb78318f,0x6ad93b0b,0x2621a39c,0xa9e917f7,0x979d74c2
.long	0x61fb0428,0xfc195647,0xbee624d4,0x4d78954a,0xb8ae86fd,0xb94896e0,0xc91c8b13,0x6667ac0c,0x43bcf832,0x9f180512,0xa0010137,0xfbadf8b7,0xb3ba8aa7,0xc69b4089,0xe687ce85,0xfac4bacd
.long	0x977eab40,0x9164088d,0x2760b390,0x51f4c5b6,0x340dd553,0xd238238f,0xdb1d31c9,0x358566c3,0x5068f5ff,0x3a5ad69e,0xdaff6b06,0xf31435fc,0xd6debff0,0xae549a5b,0x75e01331,0x59e5f0b7
.long	0x98559acf,0x5d492fb8,0x4db79b50,0x96018c2e,0x609f66aa,0x55f4a48f,0x4900a14f,0x1943b3af,0x15a40d39,0xc22496df,0x4c20f7c5,0xb2a44684,0x3b98404c,0x76a35afa,0xff5d1b77,0xbec75725
.long	0xbea06444,0xb67aa163,0xf724b6f2,0x27e95bb2,0xd238c8ab,0x3c20e3e9,0xddd6ae17,0x1213754e,0x716e0f74,0x8c431020,0xffc095c2,0x6679c82e,0xd0ac2932,0x2eb3adf4,0x01bb7a76,0x2cc970d3
.long	0x740f0e66,0x70c71f2f,0x2b6b23cc,0x545c616b,0xb40a8bd7,0x4528cfcb,0x2ab27722,0xff839633,0x025ac99a,0x049127d9,0x2b63e33b,0xd314d4a0,0x28d84519,0xc8c310e7,0xb3bc84ba,0x0fcb8983
.long	0x38634818,0x2cc52261,0xb44c2e0b,0x501814f4,0x54dfdba3,0xf7e181aa,0xe759718c,0xcfd58ff0,0xd3b507a8,0xf90cdb14,0xc50bdad8,0x57bd478e,0x50e5f9aa,0x29c197e2,0xe40bc855,0x4db6eef8
.long	0xd1fc0654,0x2cc8f21a,0x81269d73,0xc71cc963,0x077f49f9,0xecfbb204,0xca56b793,0xdde92571,0xf97ad8f7,0x9abed6a3,0x924de3bd,0xe6c19d3f,0xa140a800,0x8dce92f4,0x1337af07,0x85f44d1e
.long	0x09d64c52,0x5953c08b,0xf5df9749,0xa1b5e49f,0x52735f7d,0x336a8fb8,0x9add676b,0xb332b6db,0xb4511aa4,0x558b88a0,0xdbd5cc55,0x09788752,0xd8cd52bd,0x16b43b9c,0xc2a2696b,0x7f0bc5a0
.long	0xc11f61ef,0x146e12d4,0x3a83e79e,0x9ce10754,0x6cbfca15,0x08ec73d9,0x5b49653f,0x09ff29ad,0xe7da946e,0xe31b72bd,0xee80a4f2,0xebf9eb3b,0x17598ce4,0xd1aabd08,0x53f37e80,0x18b5fef4
.long	0x5958cd79,0xd5d5cdd3,0x1d373114,0x3580a1b5,0xfa935726,0xa36e4c91,0xef20d760,0xa38c534d,0x2ff5845b,0x7088e40a,0xbd78177f,0xe5bb40bd,0x857f9920,0x4f06a7a8,0xe968f05d,0xe3cc3e50
.long	0xe5682d26,0x1d68b7fe,0xaec7f87c,0x5206f76f,0x041951ab,0x41110530,0xd4b5a71a,0x58ec52c1,0x0f75cf9a,0xf3488f99,0xba82d0d5,0xf411951f,0x618895ab,0x27ee75be,0x6d8aab14,0xeae060d4
.long	0x7fb54dc2,0x9ae1df73,0x25963649,0x1f3e391b,0xfe055081,0x242ec32a,0x8491c9bd,0x5bd450ef,0x981eb389,0x367efc67,0x3a0550d5,0xed7e1928,0xab3ce75c,0x362e776b,0x1f24c523,0xe890e308
.long	0xfeccef76,0xb961b682,0x8bba6d92,0x8b8e11f5,0x2b2375c4,0x8f2ccc4c,0xe2f86cfa,0x0d7f7a52,0x9efe5633,0xfd94d30a,0x5451f934,0x2d8d246b,0x244e6a00,0x2234c6e3,0xddec8c50,0xde2b5b0d
.long	0xbf776f5b,0x2ce53c5a,0x60357b05,0x6f724071,0x71bf3f7a,0xb2593717,0x440c4a9f,0x87d2501c,0x87b05340,0x440552e1,0x21624c32,0xb7bf7cc8,0x22facddb,0x4155a6ce,0x889837ef,0x5a4228cb
.long	0xfd4fd671,0xef87d6d6,0xc2daa10e,0xa233687e,0x03c0eb96,0x75622244,0x8bf19be6,0x7632d184,0x40735ff4,0x05d0f8e9,0xc00931f1,0x3a3e6e13,0xdafe3f18,0x31ccde6a,0xcfe51207,0xf381366a
.long	0x60167d92,0x24c222a9,0x7529f18c,0x62f9d6f8,0x0353b114,0x412397c0,0xef808043,0x334d89dc,0x2a4383ce,0xd9ec63ba,0x5cf92ba0,0xcec8e937,0xc8be74c0,0xfb8b4288,0x105d4391,0x67d6912f
.long	0x1b913149,0x7b996c46,0x3a4e02da,0x36aae2ef,0x972de594,0xb68aa003,0x4ec6d545,0x284ec70d,0x61391d54,0xf3d2b2d0,0xfe114e92,0x69c5d5d6,0xb4482dff,0xbe0f00b5,0xf5bf33c5,0xe1596fa5
.long	0x96a71cba,0x10595b56,0xfdcadeb7,0x944938b2,0xfccd8471,0xa282da4c,0x0d37bfe1,0x98ec05f3,0x0698304a,0xe171ce1b,0x21bdf79b,0x2d691444,0x1b21dec1,0xd0cd3b74,0x16a15f71,0x712ecd8b
.long	0x00fd56e1,0x8d4c00a7,0xf9527c18,0x02ec9692,0x4a3e42e1,0x21c44937,0x1392ae0a,0x9176fbab,0x44b7b618,0x8726f1ba,0xf1de491c,0xb4d7aae9,0x07b582c0,0xf91df7b9,0xef60aa3a,0x7e116c30
.long	0x466265d7,0x99270f81,0x4df7adf0,0xb15b6fe2,0xf9738f7f,0xfe33b2d3,0xd6d70f95,0x48553ab9,0xc21e94db,0x2cc72ac8,0xbdc0bbee,0x795ac38d,0x2e40478f,0x0a1be449,0x052bde55,0x81bd3394
.long	0x56b3c4f2,0x63c8dbe9,0x904177cc,0x017a99cf,0x4d010fc1,0x947bbddb,0xbb2c9b21,0xacf9b00b,0x47173611,0x2970bc8d,0xac7d756f,0x1a4cbe08,0x67d541a2,0x06d9f4aa,0x59c2cf44,0xa3e8b689
.long	0x4d88f1dd,0xaad066da,0x7ad35dea,0xc604f165,0x4478ca67,0x7edc0720,0xba02ce06,0xa10dfae0,0xaf36f4e4,0xeceb1c76,0xaf3f8f48,0x994b2292,0x77c8a68c,0xbf9ed77b,0x51744c9d,0x74f544ea
.long	0x8113a757,0x82d05bb9,0x8a9885e4,0x4ef2d2b4,0x1aa7865f,0x1e332be5,0x290d1a52,0x22b76b18,0x44351683,0x308a2310,0xa3f22840,0x9d861896,0x841ed947,0x5959ddcd,0x154b73bf,0x0def0c94
.long	0x4c7c15e0,0xf0105417,0x3a277c32,0x539bfb02,0xf9dccf5f,0xe699268e,0x0247a3bd,0x9f5796a5,0x4f157269,0x8b839de8,0x7a30196b,0xc825c1e5,0xdc8a5a91,0x6ef0aabc,0x498b7fe6,0xf4a8ce6c
.long	0x70cbac78,0x1cce35a7,0xf6b23958,0x83488e9b,0xd76cb011,0x0341a070,0xae1b2658,0xda6c9d06,0xdd648c52,0xb701fb30,0x52fb9fd1,0x994ca02c,0x6f563086,0x06933117,0x17856bab,0x3d2b8100
.long	0x5963a46e,0xe89f48c8,0xa99e61c7,0x658ab875,0x4b8517b4,0x6e296f87,0xfc1bc656,0x36c4fcdc,0xa3906def,0xde5227a1,0x62418945,0x9fe95f57,0xfdd96cde,0x20c91e81,0xda4480de,0x5adbe47e
.long	0x396de2b6,0xa009370f,0xf0ecc7bd,0x98583d4b,0xe51d0672,0xf44f6b57,0x556b1984,0x03d6b078,0xb0b64912,0x27dbdd93,0x15687b09,0x9b3a3434,0x51ec20a9,0x0dba6461,0xff28187c,0xec93db7f
.long	0x66e48bdd,0x00ff8c24,0x11ccd78e,0x2514f2f9,0xe1250603,0xeba11f4f,0x243fa156,0x8a22cd41,0xb283e4c6,0xa4e58df4,0x8b39783f,0x78c29859,0xa5259809,0x5235aee2,0x0e0227dd,0xc16284b5
.long	0x1338830d,0xa5f57916,0xd2123fca,0x6d4b8a6b,0xf9c546f8,0x236ea68a,0xfa608d36,0xc1d36873,0x8d436d13,0xcd76e495,0x8fb080af,0xd4d9c221,0xe8ad3fb5,0x665c1728,0xb3d572e0,0xcf1ebe4d
.long	0x584c5e20,0xa7a8746a,0xb9dc7035,0x267e4ea1,0xb9548c9b,0x593a15cf,0x4bd012f3,0x5e6e2135,0x8c8f936e,0xdf31cc6a,0xb5c241dc,0x8af84d04,0x345efb86,0x63990a6f,0xb9b962cb,0x6fef4e61
.long	0x25722608,0xf6368f09,0x131cf5c6,0x131260db,0xfab4f7ac,0x40eb353b,0x37eee829,0x85c78880,0xc3bdf24e,0x4c1581ff,0xf5c3c5a8,0x5bff75cb,0xa14e6f40,0x35e8c83f,0x0295e0ca,0xb81d1c0f
.long	0xf43a730f,0xfcde7cc8,0x33ab590e,0xe89b6f3c,0xad03240b,0xc823f529,0x98bea5db,0x82b79afe,0x962fe5de,0x568f2856,0x60c591f3,0x0c590adb,0x4a28a858,0x1fc74a14,0xb3203f4c,0x3b662498
.long	0x6c39765a,0x91e3cf0d,0xac3cca0b,0xa2db3acd,0xcb953b50,0x288f2f08,0xcf43cf1a,0x2414582c,0x60eee9a8,0x8dec8bbc,0x729aa042,0x54c79f02,0x6532f5d5,0xd81cd5ec,0xcf82e15f,0xa672303a
.long	0x719c0563,0x376aafa8,0xbc5fc79f,0xcd8ad2dc,0xcb750cd3,0x303fdb9f,0x4418b08e,0x14ff052f,0x3e2d6520,0xf75084cf,0x144ed509,0x7ebdf0f8,0xd3f25b98,0xf43bf0f2,0xa354d837,0x86ad71cf
.long	0x26f43572,0xb827fe92,0x5d824758,0xdfd3ab5b,0x539094c1,0x315dd23a,0x66623d68,0x85c0e37a,0x7be19ae0,0x575c7972,0xdf0d36b5,0x616a3396,0x26b1ff7e,0xa1ebb3c8,0x140ad453,0x635b9485
.long	0xda430c0b,0x92bf3cda,0x3a96dac6,0x4702850e,0x15ac326a,0xc91cf0a5,0xab8c25e4,0x95de4f49,0xe265c17c,0xb01bad09,0x087b3881,0x24e45464,0xe1fac5ca,0xd43e583c,0x6ead97a6,0xe17cb318
.long	0x74dcec46,0x6cc39243,0x54c2b73f,0x33cfc02d,0xf26cd99c,0x82917844,0xd1773f89,0x8819dd95,0x0871f427,0x09572aa6,0xf6f01c34,0x8e0cf365,0xbff1f5af,0x7fa52988,0xe75e8e50,0x4eb357ea
.long	0x868af75d,0xd9d0c8c4,0x45c8c7ea,0xd7325cff,0xcc81ecb0,0xab471996,0x611824ed,0xff5d55f3,0x1977a0ee,0xbe314541,0x722038c6,0x5085c4c5,0xf94bb495,0x2d5335bf,0xc8e2a082,0x894ad8a6
.long	0xada35438,0x5c3e2341,0x049b8c4e,0xf4a9fc89,0x9f17cf34,0xbeeb355a,0x6c91fe10,0x3f311e0e,0x92ab9891,0xc2d20038,0x3e8ce9a9,0x257bdcc1,0x88c53bee,0x1b2d9789,0xcdba143a,0x927ce89a
.long	0x523db280,0xb0a32cca,0x50d43783,0x5c889f8a,0x4897d16f,0x503e04b3,0x08f5f2e8,0x8cdb6e78,0x179c8e74,0x6ab91cf0,0x48211d60,0xd8874e52,0xea851200,0xf948d4d5,0xe6f9840a,0x4076d41e
.long	0x47b517ea,0xc20e263c,0x30685e5e,0x79a448fd,0xf90631a0,0xe55f6f78,0xa79e6346,0x88a790b1,0x80969fe8,0x62160c7d,0x41491bb9,0x54f92fd4,0x5c957526,0xa6645c23,0xbea3ce7b,0xf44cc5ae
.long	0x8b1e68b7,0xf7628327,0x303f29d3,0xc731ad7a,0x57d03ecb,0xfe5a9ca9,0x41bc97a7,0x96c0d50c,0x9b4f7f24,0xc4669fe7,0x3d9967ef,0xfdd781d8,0x5d2c208d,0x7892c7c3,0xae545cb3,0x8bf64f7c
.long	0x467be912,0xc01f862c,0xc73d30cc,0xf4c85ee9,0x6ab83ec7,0x1fa6f4be,0x4e3e3cf9,0xa07a3c1c,0x0c00beb3,0x87f8ef45,0x000d4c3e,0x30e2c2b3,0xfe08bf5b,0x1aa00b94,0x9224ef52,0x32c133aa
.long	0x32e5685d,0x38df16bb,0x58e6f544,0x68a9e069,0xcdc5ebc6,0x495aaff7,0x378b135f,0xf894a645,0x09e27ecf,0xf316350a,0x58f7179d,0xeced201e,0xe97861ba,0x2eec273c,0xd693be2e,0x47ec2cae
.long	0xf68367ce,0xfa4c97c4,0xbe5a5755,0xe4f47d0b,0xb298a979,0x17de815d,0xc177dc7d,0xd7eca659,0x49ded0a3,0x20fdbb71,0xfb34d3c5,0x4cb2aad4,0x60858a33,0x2cf31d28,0xa24aa40f,0x3b6873ef
.long	0x2c11bb37,0x540234b2,0xed4c74a3,0x2d0366dd,0xeec5f25d,0xf9a968da,0x67b63142,0x36601068,0x68d7b6d4,0x07cd6d2c,0x0c842942,0xa8f74f09,0x7768b1ee,0xe2751404,0xfe62aee4,0x4b5f7e89
.long	0x89070d26,0xc6a77177,0xdd1c8bc7,0xa1f28e4e,0x469e1f17,0xea5f4f06,0xfbdb78e0,0x78fc242a,0x8b0588f1,0xc9c7c592,0x1535921e,0xb6b7a0fd,0xbde5ae35,0xcc5bdb91,0x12ff1864,0xb42c485e
.long	0xdbab98aa,0xa1113e13,0xa17b1024,0xde9d469b,0xc0462d3a,0x23f48b37,0x7c5c078d,0x3752e537,0x15544eb9,0xe3a86add,0x80fba279,0xf013aea7,0xf22001b5,0x8b5bb76c,0xf02891ab,0xe617ba14
.long	0x936219d3,0xd39182a6,0xae51cb19,0x5ce1f194,0xbf07a74c,0xc78f8598,0x22cbf1bc,0x6d7158f2,0xe300ce18,0x3b846b21,0x2d11275d,0x35fba630,0xa0239b9b,0x5fe25c36,0xdf05d940,0xd8beb35d
.long	0x1f7e320d,0x4db02bb0,0x6da320ea,0x0641c364,0x821389a3,0x6d95fa5d,0x8fcd8e3d,0x92699748,0xceb6c143,0x316fef17,0xd933762b,0x67fcb841,0x118b17f8,0xbb837e35,0x9fd24821,0x4b92552f
.long	0x46aca793,0xae6bc70e,0xe579311b,0x1cf0b0e4,0x5802f716,0x8dc631be,0xbddbee4d,0x099bdc6f,0x0caf8b05,0xcc352bb2,0x72d63df2,0xf74d505a,0x91c4f408,0xb9876d4b,0x9e229b2d,0x1ce18473
.long	0x83abdb4a,0x49507597,0xdee84b18,0x850fbcb6,0x609e67dc,0x6325236e,0x9336c6d8,0x04d831d9,0xfa12d45d,0x8deaae3b,0x4746e246,0xe425f8ce,0x24f5f31e,0x8004c175,0xad62c3b7,0xaca16d8f
.long	0x9152f934,0x0dc15a6a,0xed0e12c1,0xf1235e5d,0xda477dac,0xc33c06ec,0xb2ea0006,0x76be8732,0x0c0cd313,0xcf3f7831,0xa614260d,0x3c524553,0xcab22d15,0x31a756f8,0x77827a20,0x03ee10d1
.long	0x1994ef20,0xd1e059b2,0x638ae318,0x2a653b69,0x2f699010,0x70d5eb58,0x09f5f84a,0x279739f7,0x8b799336,0x5da4663c,0x203c37eb,0xfdfdf14d,0xa1dbfb2d,0x32d8a9dc,0x77d48f9b,0xab40cff0
.long	0xd20b42d5,0xc018b383,0x9f78845f,0xf9a810ef,0xbdba9df0,0x40af3753,0x131dfdf9,0xb90bdcfc,0xf01ab782,0x18720591,0x6af12a88,0xc823f211,0x0dc14401,0xa51b80f3,0xfb2dfbe3,0xde248f77
.long	0x0cafe751,0xef5a44e5,0xd4dcd221,0x73997c9c,0xde854024,0x32fd86d1,0xa09b84bb,0xd5b53adc,0xdcedd8d1,0x008d7a11,0x74b32c84,0x406bd1c8,0x05dde8b1,0x5d4472ff,0xfce2b32f,0x2e25f2cd
.long	0x29dfc254,0xbec0dd5e,0x2b98b267,0x4455fcf6,0xc72df2ad,0x0b4d43a5,0x48a75397,0xea70e6be,0x5820f3bf,0x2aad6169,0x9e37f68f,0xf410d2dd,0x7be5ac83,0x70fb7dba,0x36ec3eec,0x636bb645
.long	0x9754e21c,0x27104ea3,0x8d63c373,0xbc87a3e6,0x4109db9a,0x483351d7,0x60134da7,0x0fa724e3,0xb0720b16,0x9ff44c29,0x06aceead,0x2dd0cf13,0xe26929a6,0x5942758c,0xb766a92b,0x96c5db92
.long	0x5f18395e,0xcec7d4c0,0x1f80d032,0xd3f22744,0xcb86075b,0x7a68b37a,0xafef92db,0x074764dd,0x7bc7f389,0xded1e950,0xb9756460,0xc580c850,0x7da48157,0xaeeec2a4,0x82c587b3,0x3f0b4e7f
.long	0xa9f19c53,0x231c6de8,0x6974e34e,0x5717bd73,0xf1508fa9,0xd9e1d216,0xdadaa124,0x9f112361,0x823b7348,0x80145e31,0xac634069,0x4dd8f0d5,0x2297c258,0xe3d82fc7,0x9cee7431,0x276fcfee
.long	0x2bc0aea9,0x8eb61b5e,0xde329431,0x4f668fd5,0x38e4b87e,0x03a32ab1,0x73d0ef0b,0xe1374517,0x853ac983,0x1a46f7e6,0x68e78a57,0xc3bdf42e,0x2ea96dd1,0xacf20785,0xf1638460,0xa10649b9
.long	0x879fbbed,0xf2369f0b,0xda9d1869,0x0ff0ae86,0x56766f45,0x5251d759,0x2be8d0fc,0x4984d8c0,0xd21008f0,0x7ecc95a6,0x3a1a1c49,0x29bd54a0,0xd26c50f3,0xab9828c5,0x51d0d251,0x32c0087c
.long	0x0c1cdb26,0x9bac3ce6,0x557ca205,0xcd94d947,0x9db1fdcd,0x1b1bd598,0xa3d8b149,0x0eda0108,0x56152fcc,0x95066610,0xe7192b33,0xc2f037e6,0xc92e05a4,0xdeffb41a,0xc2f6c62e,0x1105f6c2
.long	0x8733913c,0x68e73500,0x3f3adc40,0xcce86163,0x38a278e9,0xf407a942,0x2ab21292,0xd13c1b9d,0x1c74cf5c,0x93ed7ec7,0xf1a4c1b4,0x8887dc48,0x4b3a11f1,0x3830ff30,0x58937cb6,0x358c5a3c
.long	0x89022829,0x027dc404,0x3b798f79,0x40e93977,0x38be6ead,0x90ad3337,0xf34c0a5d,0x9c23f6bc,0xfbffd8bb,0xd1711a35,0x1949d3dd,0x60fcfb49,0x7825d93a,0x09c8ef4b,0xa0a8c968,0x24233cff
.long	0xe6d982af,0x67ade46c,0xe7544d7c,0xebb6bf3e,0x3d8bd087,0xd6b9ba76,0x4dc61280,0x46fe382d,0xb5bdbd75,0xbd39a7e8,0xb8f228fe,0xab381331,0xce1c4300,0x0709a77c,0xf337ceac,0x6a247e56
.long	0x636288be,0x8f34f21b,0xc8a7c305,0x9dfdca74,0xea919e04,0x6decfd1b,0x8e1991f8,0xcdf2688d,0xd0f8a67e,0xe607df44,0x0b58d010,0xd985df4b,0x0c24f8f4,0x57f834c5,0xa0bf01ae,0xe976ef56
.long	0xa1c32373,0x536395ac,0x734c0a13,0x351027aa,0x5e6bd5bc,0xd2f1b5d6,0x223debed,0x2b539e24,0x0eaa1d71,0xd4994cec,0x661dcf65,0x2a83381d,0x7b54c740,0x5f1aed2f,0xd6dda5ee,0x0bea3fa5
.long	0x36cc6134,0x9d4fb684,0xc0a443dd,0x8eb9bbf3,0x383b7d2a,0xfc500e2e,0x5b775257,0x7aad621c,0x0a8f7cc0,0x69284d74,0x07562d65,0xe820c2ce,0x499758ee,0xbf9531b9,0x6ee0cc2d,0x73e95ca5
.long	0xfbaf50a5,0xf61790ab,0x684e0750,0xdf55e76b,0xf176b005,0xec516da7,0x7a2dddc7,0x575553bb,0x553afa73,0x37c87ca3,0x4d55c251,0x315f3ffc,0xaf3e5d35,0xe846442a,0x6495ff28,0x61b91149
.long	0xfa326dc3,0x23cc95d3,0x18fc2cea,0x1df4da1f,0xd0a37d59,0x24bf9adc,0x320d6e1e,0xb6710053,0x618344d1,0x96f9667e,0xa06445af,0xcc7ce042,0xd68dbc3a,0xa02d8514,0x280b5a5b,0x4ea109e4
.long	0xb40961bf,0x5741a7ac,0x6aa56bfa,0x4ada5937,0x02b765d1,0x7feb9145,0xe6ad1582,0x561e97be,0xda3982f5,0xbbc4a5b6,0xb546f468,0x0c2659ed,0x59612d20,0xb8e7e6aa,0xac19e8e0,0xd83dfe20
.long	0xb835398c,0x8530c45f,0xb38a41c2,0x6106a8bf,0x35f5dcdb,0x21e8f9a6,0xcae498ed,0x39707137,0xd8249f00,0x70c23834,0xab2537a0,0x9f14b58f,0x5f61c0c2,0xd043c365,0x09a194a7,0xdc5926d6
.long	0x8e77738a,0xddec0339,0xfba46426,0xd07a63ef,0xee7f6e86,0x2e58e79c,0xff32d241,0xe59b0459,0x20fa0338,0xc5ec84e5,0xeaff5ace,0x97939ac8,0xb4a38313,0x0310a4e3,0x8f9d9885,0x9115fba2
.long	0x5fadf8c3,0x8dd710c2,0xce19c0e2,0x66be38a2,0x4cfe5022,0xd42a279c,0x0e24e1b8,0x597bb530,0xc153ca7f,0x3cde86b7,0x707d63bd,0xa8d30fb3,0xbd60d21e,0xac905f92,0x7b9a54ab,0x98e7ffb6
.long	0xe9726a30,0xd7147df8,0xafce3533,0xb5e216ff,0x2ff1ec40,0xb550b799,0xa1e953fd,0x6b613b87,0x792d5610,0x87b88dba,0xa190fbe1,0x2ee1270a,0x2ef581da,0x02f4e2dc,0xeff82a95,0x016530e4
.long	0x8fd6ee89,0xcbb93dfd,0x46848fff,0x16d3d986,0x1da47adf,0x600eff24,0x0ad47a71,0x1b9754a0,0x70c33b98,0x8f9266df,0xdf34186e,0xaadc87ae,0x4ad24132,0x0d2ce8e1,0x19946eba,0x8a47cbfc
.long	0x62b5f3af,0x47feeb66,0x0abb3734,0xcefab561,0x19f35cb1,0x449de60e,0x157f0eb9,0x39f8db14,0x3c61bfd6,0xffaecc5b,0x41216703,0xa5a4d41d,0x224e1cc2,0x7f8fabed,0x871ad953,0x0d5a8186
.long	0xd22da9a9,0xf10774f7,0xcc8a9b0d,0x45b8a678,0xbdc32cff,0xd9c2e722,0x337202a5,0xbf71b5f5,0x69fc4db9,0x95c57f2f,0x765d01e1,0xb6dad34c,0xcb904635,0x7e0bd13f,0x763a588c,0x61751253
.long	0x81af2c2d,0xd85c2997,0x81b9d7da,0xc0f7d9c4,0x08533e8d,0x838a34ae,0x311d8311,0x15c4cb08,0x8e121e14,0x97f83285,0x85000a5f,0xeea7dc1e,0x5d256274,0x0c6059b6,0xb95075c0,0xec9beace
.long	0x1df97828,0x173daad7,0xa8937877,0xbf851cb5,0x01646f3c,0xb083c594,0x50c6d352,0x3bad30cf,0x496bbcea,0xfeb2b202,0x18a1e8ba,0x3cf9fd4f,0x1c066029,0xd26de7ff,0x4e9ed4f8,0x39c81e9e
.long	0x7b390d35,0xd8be0cb9,0x964aab27,0x01df2bbd,0xc3ef64f8,0x3e8c1a65,0x716ed1dd,0x567291d1,0x5f5406d3,0x95499c6c,0x5ba8e23f,0x71fdda39,0xd5096ece,0xcfeb320e,0xca66dd16,0xbe7ba92b
.long	0xc6fb5a7d,0x4608d36b,0x6d2dd0e0,0xe3eea15a,0x8f97a36a,0x75b0a3eb,0x1c83de1e,0xf59814cc,0x1c33c23f,0x56c9c5b0,0x6faa4136,0xa96c1da4,0xde316551,0x46bf2074,0x1f756c8f,0x3b866e7b
.long	0x1495ed6b,0x727727d8,0xb682dce7,0xb2394243,0x758610f3,0x8ab8454e,0x857d72a4,0xc243ce84,0xdbbf370f,0x7b320d71,0x78e0f7ca,0xff9afa37,0xea7b523f,0x0119d1e0,0x058c7d42,0xb997f8cb
.long	0x37bbb184,0x285bcd2a,0xa45d1fa6,0x51dcec49,0xe29634cb,0x6ade3b64,0x26b86ef1,0x080c94a7,0x2283fbe3,0xba583db1,0x5a9315ed,0x902bddc8,0x86964bec,0x07c1ccb3,0xb6258301,0x78f4eacf
.long	0x56f90823,0x4bdf3a49,0x741d777b,0xba0f5080,0xf38bf760,0x091d71c3,0x9b625b02,0x9633d50f,0xb8c9de61,0x03ecb743,0x5de74720,0xb4751254,0x74ce1cb2,0x9f9defc9,0x00bd32ef,0x774a4f6a
.long	0x73848f22,0xaca385f7,0xf3f8558e,0x53dad716,0x93c471f9,0xab7b34b0,0x19644bc7,0xf530e069,0xdd59d31a,0x3d9fb1ff,0x08daa795,0x4382e0df,0xd5cc88d7,0x165c6f4b,0x4a18c900,0xeaa392d5
.long	0x648024ee,0x94203c67,0x8c2fabcd,0x188763f2,0xbbaec835,0xa80f87ac,0xf29d8d54,0x632c96e0,0x4c00a95e,0x29b0a60e,0xe011e9fa,0x2ef17f40,0x15b77223,0xf6c0e1d1,0x14b04e32,0xaaec2c62
.long	0x3d84e58c,0xd35688d8,0x958571db,0x2af5094c,0x760682a6,0x4fff7e19,0xe39a407c,0x4cb27077,0x4ff0e321,0x0f59c547,0x1b34c8ff,0x169f34a6,0x52bc1ba7,0x2bff1096,0x83583544,0xa25423b7
.long	0x0ac8b782,0x5d55d5d5,0x2db3c892,0xff6622ec,0x6b8bb642,0x48fce741,0x69d7e3dc,0x31d6998c,0xcadcaed0,0xdbaf8004,0xd81d053c,0x801b0142,0x59630ec6,0x94b189fc,0xaf762c8e,0x120e9934
.long	0xfdc6a404,0x53a29aa4,0xa1909948,0x19d8e01e,0xd7e89681,0x3cfcabf1,0x4e132d37,0x3321a50d,0xe9a86111,0xd0496863,0x06a3bc65,0x8c0cde61,0xfc9f8eef,0xaf866c49,0xff7f5141,0x2066350e
.long	0xe56ddfbd,0x4f8a4689,0xfe32983a,0xea1b0c07,0x873cb8cb,0x2b317462,0x2d93229f,0x658deddc,0x0f64ef58,0x65efaf4d,0x730cc7a8,0xfe43287d,0x3d047d70,0xaebc0c72,0xd92d26c9,0x92efa539
.long	0x94b56526,0x06e78457,0x0961002d,0x415cb80f,0x76dcb10f,0x89e5c565,0xff9259fe,0x8bbb6982,0x9abc2668,0x4fe8795b,0x1e678fb1,0xb5d4f534,0x7b7da2b9,0x6601f3be,0xa13d6805,0x98da59e2
.long	0x01799a52,0x190d8ea6,0xb86d2952,0xa20cec41,0x7fff2a7c,0x3062ffb2,0x79f19d37,0x741b32e5,0x4eb57d47,0xf80d8181,0x16aef06b,0x7a2d0ed4,0x1cecb588,0x09735fb0,0xc6061f5b,0x1641caaa
.long	0x20151427,0x7f99824f,0x92430206,0x206828b6,0xe1112357,0xaa9097d7,0x09e414ec,0xacf9a2f2,0x27915356,0xdbdac9da,0x001efee3,0x7e0734b7,0xd2b288e2,0x54fab5bb,0xf62dd09c,0x4c630fc4
.long	0x1ac2703b,0x8537107a,0x6bc857b5,0xb49258d8,0xbcdaccd1,0x57df14de,0xc4ae8529,0x24ab68d7,0x734e59d0,0x7ed8b5d4,0xc495cc80,0x5f8740c8,0x291db9b3,0x84aedd5a,0x4fb995be,0x80b360f8
.long	0x5fa067d1,0xae915f5d,0x9668960c,0x4134b57f,0xa48edaac,0xbd3656d6,0xfc1d7436,0xdac1e3e4,0xd81fbb26,0x674ff869,0xb26c33d4,0x449ed3ec,0xd94203e8,0x85138705,0xbeeb6f4a,0xccde538b
.long	0xa61a76fa,0x55d5c68d,0xca1554dc,0x598b441d,0x773b279c,0xd39923b9,0x36bf9efc,0x33331d3c,0x298de399,0x2d4c848e,0xa1a27f56,0xcfdb8e77,0x57b8ab70,0x94c855ea,0x6f7879ba,0xdcdb9dae
.long	0x019f2a59,0x7bdff8c2,0xcb4fbc74,0xb3ce5bb3,0x8a9173dd,0xea907f68,0x95a75439,0x6cd3d0d3,0xefed021c,0x92ecc4d6,0x6a77339a,0x09a9f9b0,0x7188c64a,0x87ca6b15,0x44899158,0x10c29968
.long	0xed6e82ef,0x5859a229,0x65ebaf4e,0x16f338e3,0x5ead67ae,0x0cd31387,0x54ef0bb4,0x1c73d228,0x74a5c8c7,0x4cb55131,0x7f69ad6a,0x01cd2970,0xe966f87e,0xa04d00dd,0x0b7b0321,0xd96fe447
.long	0x88fbd381,0x342ac06e,0x5c35a493,0x02cd4a84,0x54f1bbcd,0xe8fa89de,0x2575ed4c,0x341d6367,0xd238202b,0xebe357fb,0xa984ead9,0x600b4d1a,0x52436ea0,0xc35c9f44,0xa370751b,0x96fe0a39
.long	0x7f636a38,0x4c4f0736,0x0e76d5cb,0x9f943fb7,0xa8b68b8b,0xb03510ba,0x9ed07a1f,0xc246780a,0x6d549fc2,0x3c051415,0x607781ca,0xc2953f31,0xd8d95413,0x955e2c69,0x7bd282e3,0xb300fadc
.long	0x87e9189f,0x81fe7b50,0xf42dda27,0xdb17375c,0xcf0a5904,0x22f7d896,0xebe348e6,0xa0e57c5a,0xf40e3c80,0xa61011d3,0x8db705c5,0xb1189321,0x50fedec3,0x4ed9309e,0x4d6d5c1d,0xdcf14a10
.long	0x55691342,0x056c265b,0x91049dc7,0xe8e08504,0xc9bae20a,0x131329f5,0xd9dccdb4,0x96c8b3e8,0xfb4ee6b4,0x8c5ff838,0x41e8ccf0,0xfc5a9aeb,0xfae050c6,0x7417b764,0x00452080,0x0953c3d7
.long	0x38dfe7e8,0x21372682,0x2bb79d4b,0xea417e15,0x76e7cf2d,0x59641f1c,0xea0bcfcc,0x271e3059,0x7253ecbd,0x624c7dfd,0x4fca6186,0x2f552e25,0x4d866e9c,0xcbf84ecd,0xf68d4610,0x73967709
.long	0xc27901b4,0xa14b1163,0x899b8bf3,0xfd9236e0,0xcbc6da0a,0x42b091ec,0x5ad1d297,0xbb1dac6f,0xa91cf76e,0x80e61d53,0xd31f1ee7,0x4110a412,0x13efcf77,0x2d87c3ba,0xdf450d76,0x1f374bb4
.long	0x0d188dab,0x5e78e2f2,0xf4b885ef,0xe3968ed0,0x7314570f,0x46c0568e,0x01170521,0x31616338,0x4f0c8afe,0x18e1e7e2,0xdeea78da,0x4caa75ff,0x7c5d8a51,0x82db67f2,0x6f505370,0x36a44d86
.long	0x0333974f,0xd72c5bda,0x27a70146,0x5db516ae,0x210ef921,0x34705281,0x0c9c38e5,0xbff17a8f,0x12476da1,0x78f4814e,0x33c16980,0xc1e16613,0x424d4bca,0x9e5b386f,0xc85740de,0x4c274e87
.long	0x6c2f5226,0xb6a9b88d,0x550d7ca8,0x14d1b944,0x1fc41709,0x580c85fc,0x54c6d519,0xc1da368b,0xd5113cf7,0x2b0785ce,0x5a34708f,0x0670f633,0x15cc3f88,0x46e23767,0x50c72c8f,0x1b480cfa
.long	0x4147519a,0x20288602,0x26b372f0,0xd0981eac,0xa785ebc8,0xa9d4a7ca,0xdbdf58e9,0xd953c50d,0xfd590f8f,0x9d6361cc,0x44e6c917,0x72e9626b,0x22eb64cf,0x7fd96110,0x9eb288f3,0x863ebb7e
.long	0x6aca8ee7,0x6e6ab761,0xd7b40358,0x97d10b39,0x1e5feb0d,0x1687d377,0x8265a27a,0xc83e50e4,0xc954b313,0x8f75a9fe,0x310d1f61,0xcc2e8f47,0x6557d0e0,0xf5ba81c5,0x3eaf6207,0x25f9680c
.long	0x4354080b,0xf95c6609,0x7bf2fe1c,0x5225bfa5,0x5c7d98fa,0xc5c004e2,0x019aaf60,0x3561bf1c,0xba151474,0x5e6f9f17,0xb04f6eca,0xdec2f934,0x269acb1e,0x64e368a1,0x0cdda493,0x1332d9e4
.long	0xdf23de05,0x60d6cf69,0x009339a0,0x66d17da2,0x0a693923,0x9fcac985,0xed7c6a6d,0xbcf057fc,0xf0b5662c,0xc3c5c8c5,0xdcba4f24,0x25318dd8,0x082b69ff,0x60e8cb75,0x1e728c01,0x7c23b3ee
.long	0x097e4403,0x15e10a0a,0x19854665,0xcb3d0a86,0xd67d4826,0x88d8e211,0x0b9d2839,0xb39af66e,0xbd475ca8,0xa5f94588,0xc077b80b,0xe06b7966,0xda27c26c,0xfedb1485,0xfe0fd5e0,0xd290d33a
.long	0xf34fb0fa,0xa40bcc47,0x1fb1ab09,0xb4760cc8,0xa273bfe3,0x8fca0993,0xf70b213c,0x13e4fe07,0xfdb05163,0x3bcdb992,0x0c2b19b6,0x8c484b11,0xaaf2e3e2,0x1acb815f,0xb89ff1b4,0xc6905935
.long	0x586e74e1,0xb2ad6f9d,0x67b80484,0x488883ad,0x369c3ddb,0x758aa2c7,0x9f9afd31,0x8ab74e69,0x5e21beb1,0x10fc2d28,0x318c42f9,0x3484518a,0x53cf40c3,0x377427dc,0x391bc1d9,0x9de0781a
.long	0x693807e1,0x8faee858,0x4e81ccc7,0xa3865327,0x6f835b84,0x02c30ff2,0x0d3d38d4,0xb604437b,0x5ca1823d,0xb3fc8a98,0x03be0324,0xb82f7ec9,0xcf684a33,0xee36d761,0x9f29bf7d,0x5a01df0e
.long	0x1306583d,0x686202f3,0x437c622e,0x05b10da0,0x076a7bc8,0xbf9aaa0f,0x8f8f4e43,0x25e94efb,0xfa3dc26d,0x8a35c9b7,0x96ff03c5,0xe0e5fb93,0xebc394ce,0xa77e3843,0x8361de60,0xcede6595
.long	0xa1993545,0xd27c22f6,0x24d671ba,0xab01cc36,0xa169c28e,0x63fa2877,0x2eb08376,0x925ef904,0x53aa0b32,0x3b2fa3cf,0x71c49d7a,0xb27beb5b,0xd105e27f,0xb60e1834,0x4f68570d,0xd6089788
.long	0xd6fbc2ac,0x23094ce0,0x815ff551,0x738037a1,0x6bef119c,0xda73b1bb,0xeef506ba,0xdcf6c430,0xe3ef104a,0x00e4fe7b,0x0a065628,0xebdd9a2c,0x8792043e,0x853a81c3,0xb3b59108,0x22ad6ece
.long	0x39cd297d,0x9fb813c0,0x05bda5d9,0x8ec7e16e,0x0d104b96,0x2834797c,0x7c511510,0xcc11a2e7,0x96ee6380,0x96ca5a53,0xcea38742,0x054c8655,0xd54dfa7d,0xb5946852,0x1f4ab207,0x97c422e7
.long	0x0c22b540,0xbf907509,0xb7c267d4,0x2cde42aa,0x5ab0d693,0xba18f9ed,0x6e4660d9,0x3ba62aa6,0xab9ea96a,0xb24bf97b,0xe3b60e32,0x5d039642,0x7c4d9bd5,0x4e6a4506,0x7ed4a6a4,0x666c5b9e
.long	0x8edbd7cc,0xfa3fdcd9,0xc6ccd753,0x4660bb87,0x21e6b64f,0x9ae90820,0xb36bfb3f,0x8a56a713,0x5726d47f,0xabfce096,0x0b1a9a7f,0x9eed01b2,0x4eb74a37,0x30e9cad4,0x53e9666d,0x7b2524cc
.long	0x8f4b002f,0x6a29683b,0x41f4fc20,0xc2200d7a,0x3a338acc,0xcf3af47a,0xe7128975,0x6539a4fb,0xc33c7fcf,0xcec31c14,0xc7be322b,0x7eb6799b,0x6646f623,0x119ef4e9,0x54d7299b,0x7b7a26a5
.long	0x403f46f2,0xcb37f08d,0x1a0ec0c7,0x94b8fc43,0xc332142f,0xbb8514e3,0xe80d2a7a,0xf3ed2c33,0xb639126c,0x8d2080af,0xe3553ade,0xf7b6be60,0x1c7e2b09,0x3950aa9f,0x6410f02b,0x847ff958
.long	0x678a31b0,0x877b7cf5,0x3998b620,0xd50301ae,0xc00fb396,0x734257c5,0x04e672a6,0xf9fb18a0,0xe8758851,0xff8bd8eb,0x5d99ba44,0x1e64e4c6,0x7dfd93b7,0x4b8eaedf,0x04e76b8c,0xba2f2a98
.long	0xe8053433,0x7d790cba,0x3d2c9585,0xc8e725a0,0xcdd8f5ed,0x58c5c476,0xefa9fe1d,0xd106b952,0x0eff13a9,0x3c5c775b,0xe057b930,0x242442ba,0xc9b70cbd,0xe9f458d4,0xa3cdb89a,0x69b71448
.long	0x0e2ed742,0x41ee46f6,0x40067493,0x573f1045,0x9d54c304,0xb1e154ff,0x8d3a7502,0x2ad0436a,0x431a8121,0xee4aaa2d,0x886f11ed,0xcd38b3ab,0x034a0eb7,0x57d49ea6,0xf7e85e58,0xd2b773bd
.long	0x9b5c1f14,0x4a559ac4,0x3e54df2b,0xc444be1a,0xeda41891,0x13aad704,0x5eb5c788,0xcd927bec,0xe48c8a34,0xeb3c8516,0x4b546669,0x1b7ac812,0x594df8ec,0x1815f896,0x79227865,0x87c6a79c
.long	0x9b56ddbd,0xae02a2f0,0x8a2f1cf3,0x1339b5ac,0x839dff0d,0xf2b569c7,0xfee9a43d,0xb0b9e864,0x77bb064e,0x4ff8ca41,0xfd249f63,0x145a2812,0xf86f689a,0x3ab7beac,0x01d35f5e,0x9bafec27
.long	0x4265aa91,0x28054c65,0x035efe42,0xa4b18304,0x9639dec7,0x6887b0e6,0x3d52aea5,0xf4b8f6ad,0x971a8a13,0xfb9293cc,0x4c934d07,0x3f159e5d,0x09acbc29,0x2c50e9b1,0x7154d129,0x08eb65e6
.long	0x30b75c3e,0x4feff589,0x94491c93,0x0bb82fe2,0x89af62bb,0xd8ac377a,0x9685e49f,0xd7b51490,0x04497f19,0xabca9a7b,0x1a7ad13f,0x1b35ed0a,0x3ec86ed6,0x6b601e21,0xce0c76f1,0xda91fcb9
.long	0xd7ab27e1,0x9e28507b,0x63945b7b,0x7c19a555,0xaafc9827,0x6b43f0a1,0x3aa55b91,0x443b4fbd,0x6962c88f,0x962b2e65,0xce0db0ca,0x139da8d4,0x1b8d6c4f,0xb93f05dd,0x180b9824,0x779cdff7
.long	0xae57c7b7,0xbba23fdd,0x1b932522,0x345342f2,0x556d4aa3,0xfd9c80fe,0x6525bb61,0xa03907ba,0xff218933,0x38b010e1,0xaa52117b,0xc066b654,0x94f2e6ea,0x8e141920,0x0d32f2b2,0x66a27dca
.long	0x048b3717,0x69c7f993,0xb178ae1c,0xbf5a989a,0x564f1d6b,0x49fa9058,0xd31fde4e,0x27ec6e15,0x7276e7fc,0x4cce0373,0x89d6bf02,0x64086d79,0x4ccdd979,0x5a72f046,0x47775631,0x909c3566
.long	0x75dd7125,0x1c07bc6b,0x87a0428d,0xb4c6bc97,0xfdeb6b9d,0x507ece52,0xb2c95432,0xfca56512,0xd0e8bd06,0x15d97181,0xc6bb46ea,0x384dd317,0x3952b624,0x5441ea20,0x4e7dc2fb,0xbcf70dee
.long	0x6628e8c3,0x372b016e,0xb60a7522,0x07a0d667,0x0a344ee2,0xcf05751b,0x118bdeec,0x0ec09a48,0xd83dce46,0x6e4b3d4e,0x99d2fc6e,0x43a6316d,0x56cf044c,0xa99d8989,0xae3e5fb7,0x7c7f4454
.long	0xfbabbe92,0xb2e6b121,0xe1330076,0x281850fb,0x97890015,0x093581ec,0x75ff77f5,0x69b1dded,0xab105105,0x7cf0b18f,0xa89ccfef,0x953ced31,0xeb914009,0x3151f85f,0x88ed48ad,0x3c9f1b87
.long	0x4a7eadcb,0xc9aba1a1,0x522e71cf,0x928e7501,0x3a2e4f83,0xeaede727,0x1ce3bbd3,0x467e10d1,0xb955dcf0,0xf3442ac3,0xd3d5e527,0xba96307d,0xfd77f474,0xf763a10e,0x6a6e1ff0,0x5d744bd0
.long	0xa777899e,0xd287282a,0xd03f3cde,0xe20eda8f,0x50b07d31,0x6a7e75bb,0x6f379de4,0x0b7e2a94,0x19f593cf,0x31cb64ad,0x1e76ef1d,0x7b1a9e4f,0xb62d609c,0xe18c9c9d,0xe779a650,0x439bad6d
.long	0xe032f144,0x219d9066,0xe8b2ec6a,0x1db632b8,0xfda12f78,0xff0d0fd4,0x2a25d265,0x56fb4c2d,0x255a03f1,0x5f4e2ee1,0xe96af176,0x61cd6af2,0xd068bc97,0xe0317ba8,0x264b988e,0x927d6bab
.long	0xe90fb21e,0xa18f07e0,0xbba7fca1,0x00fd2b80,0x95cd67b5,0x20387f27,0xd39707f7,0x5b89a4e7,0x894407ce,0x8f83ad3f,0x6c226132,0xa0025b94,0xf906c13b,0xc79563c7,0x4e7bb025,0x5f548f31
.long	0xeac6d113,0x2b4c6b8f,0x0e813c76,0xa67e3f9c,0x3fe1f4b9,0x3982717c,0x26d8050e,0x58865819,0xf7f06f20,0x99f3640c,0x2a66ebc2,0xdc610216,0x767a1e08,0x52f2c175,0x5999871b,0x05660e1a
.long	0x6d3c4693,0x6b0f1762,0x37ed7bea,0xf0e7d627,0xb75b226d,0xc51758c7,0x1f91613b,0x40a88628,0xbbb38ce0,0x889dbaa7,0xbddcad81,0xe0404b65,0x8bc9671f,0xfebccd3a,0xee1f5375,0xfbf9a357
.long	0x28f33398,0x5dc169b0,0x72e90f65,0xb07ec11d,0xfaab1eb1,0xae7f3b4a,0x5f17538a,0xd970195e,0x0181e640,0x52b05cbe,0x2643313d,0xf5debd62,0x5df31f82,0x76148154,0x3a9e13c5,0x23e03b33
.long	0x4fde0c1f,0xff758949,0xe5b6ec20,0xbf8a1abe,0x87e1db6c,0x702278fb,0x35ed658f,0xc447ad7a,0x03d0ccf2,0x48d4aa38,0x819a7c03,0x80acb338,0x6e17cecc,0x9bc7c89e,0x03be1d82,0x46736b8b
.long	0xc0432f96,0xd65d7b60,0xdeb5442f,0xddebe7a3,0x7dff69a2,0x79a25307,0x02cf3122,0x37a56d94,0xf2350d0a,0x8bab8aed,0x037b0d9a,0x13c3f276,0x44c65cae,0xc664957c,0xc2e71a88,0x88b44089
.long	0x5cb02664,0xdb88e5a3,0x8686c72e,0x5d4c0bf1,0xa682d53e,0xea3d9b62,0x0b2ad431,0x9b605ef4,0xc69645d0,0x71bac202,0x6a1b66e7,0xa115f03a,0x158f4dc4,0xfe2c563a,0x4d12a78c,0xf715b3a0
.long	0xd413213a,0x8f7f0a48,0xc04becdb,0x2035806d,0x5d8587f5,0xecd34a99,0x9f6d3a71,0x4d8c3079,0x8d95a8f6,0x1b2a2a67,0xf2110d0d,0xc58c9d7d,0xcf8fba3f,0xdeee81d5,0x0c7cdf68,0xa42be3c0
.long	0xd43b5eaa,0x2126f742,0xdfa59b85,0x054a0766,0x126bfd45,0x9d0d5e36,0x384f8a8f,0xa1f8fbd7,0xd563fccc,0x317680f5,0xf280a928,0x48ca5055,0x27b578cf,0xe00b81b2,0x2994a514,0x10aad918
.long	0xb7bdc953,0xd9e07b62,0x5bc086dd,0x9f0f6ff2,0x655eee77,0x09d1ccff,0x5bef7df1,0x45475f79,0x86f702cc,0x3faa28fa,0x0f021f07,0x92e60905,0x7f8fa8c6,0xe9e62968,0xf036ea2c,0xbd71419a
.long	0x6028da9a,0x171ee1cc,0xc251f573,0x5352fe1a,0x3fa997f4,0xf8ff236e,0xa5749d5f,0xd831b6c9,0xe350e2c2,0x7c872e1d,0x1e0ce403,0xc56240d9,0x6974f5cb,0xf9deb077,0x961c3728,0x7d50ba87
.long	0x5a3a2518,0xd6f89426,0xc6303d43,0xcf817799,0x619e5696,0x510a0471,0x3a5e307b,0xab049ff6,0xfeb13ec7,0xe4cdf9b0,0x9d8ff90c,0xd5e97117,0x9afa96af,0xf6f64d06,0x9d2012a2,0x00d0bf5e
.long	0x358bcdc0,0xe63f301f,0x0a9d47f8,0x07689e99,0x4f43d43a,0x1f689e2f,0x90920904,0x4d542a16,0x9ca0a707,0xaea293d5,0x8ac68065,0xd061fe45,0x0090008c,0x1033bf1b,0xc08a6db6,0x29749558
.long	0xc1d5d034,0x74b5fc59,0x67e215e0,0xf712e9f6,0x860200e6,0xfd520cbd,0x3ea22588,0x0229acb4,0xfff0c82e,0x9cd1e14c,0x59c69e73,0x87684b62,0x96ccb989,0xda85e61c,0xa3d06493,0x2d5dbb02
.long	0xe86b173c,0xf22ad33a,0xa79ff0e3,0xe8e41ea5,0xdd0d0c10,0x01d2d725,0x032d28f9,0x31f39088,0x7829839e,0x7b3f71e1,0x4502ae58,0x0cf691b4,0xbefc6115,0xef658dbd,0xb3ab5314,0xa5cd6ee5
.long	0x5f1d2347,0x206c8d7b,0x4cc2253a,0x794645ba,0x58389e08,0xd517d8ff,0x9f847288,0x4fa20dee,0xd797770a,0xeba072d8,0xbf429e26,0x7360c91d,0x80af8279,0x7200a3b3,0x82dadce3,0x6a1c9150
.long	0xc35d8794,0x0ee6d3a7,0x0356bae5,0x042e6558,0x643322fd,0x9f59698d,0x50a61967,0x9379ae15,0xfcc9981e,0x64b9ae62,0x6d2934c6,0xaed3d631,0x5e4e65eb,0x2454b302,0xf9950428,0xab09f647
.long	0x22248acc,0xb2083a12,0x3264e366,0x1f6ec0ef,0x5afdee28,0x5659b704,0xe6430bb5,0x7a823a40,0xe1900a79,0x24592a04,0xc9ee6576,0xcde09d4a,0x4b5ea54a,0x52b6463f,0xd3ca65a7,0x1efe9ed3
.long	0x305406dd,0xe27a6dbe,0xdd5d1957,0x8eb7dc7f,0x387d4d8f,0xf54a6876,0xc7762de4,0x9c479409,0x99b30778,0xbe4d5b5d,0x6e793682,0x25380c56,0xdac740e3,0x602d37f3,0x1566e4ae,0x140deabe
.long	0xafd32acf,0x4481d067,0xe1f71ccf,0xd8f0fcca,0xb596f2da,0xd208dd0c,0x9aad93f9,0xd049d730,0x42ab580e,0xc79f263d,0x23f707b4,0x09411bb1,0x835e0eda,0x8cfde1ff,0x90f03402,0x72707490
.long	0xc49a861e,0xeaee6126,0xe14f0d06,0x024f3b65,0xc69bfc17,0x51a3f1e8,0xa7686381,0xc3c3a8e9,0xb103d4c8,0x3400752c,0x9218b36b,0x02bc4613,0x7651504a,0xc67f75eb,0xd02aebfa,0xd6848b56
.long	0xc30fa92b,0xbd9802e6,0x9a552784,0x5a70d96d,0x3f83169b,0x9085c4ea,0x06908228,0xfa9423bb,0xfe97a5b9,0x2ffebe12,0x71b99118,0x85da6049,0x63178846,0x9cbc2f7f,0x9153218e,0xfd96bc70
.long	0x1782269b,0x958381db,0x2597e550,0xae34bf79,0x5f385153,0xbb5c6064,0xe3088048,0x6f0e96af,0x77884456,0xbf6a0215,0x69310ea7,0xb3b5688c,0x04fad2de,0x17c94295,0x17896d4d,0xe020f0e5
.long	0x0976505f,0x730ba0ab,0x095e2ec5,0x567f6813,0x6331ab71,0x47062010,0x41d22b9f,0x72cfa977,0x8a2373da,0x33e55ead,0x7ba45a68,0xa8d0d5f4,0x03029d15,0xba1d8f9c,0xfc55b9f3,0x8f34f1cc
.long	0xbbe5a1a9,0xcca4428d,0x3126bd67,0x8187fd5f,0x48105826,0x0036973a,0xb8bd61a0,0xa39b6663,0x2d65a808,0x6d42deef,0x94636b19,0x4969044f,0xdd5d564c,0xf611ee47,0xd2873077,0x7b2f3a49
.long	0x300eb294,0x94157d45,0x169c1494,0x2b2a656e,0xd3a47aa9,0xc000dd76,0xa6243ea4,0xa2864e4f,0xdb89842e,0x82716c47,0x61479fb7,0x12dfd7d7,0xe0b2f6dc,0x3b9a2c56,0xd7f85d67,0x46be862a
.long	0x0f82b214,0x03b0d8dd,0xf103cbc6,0x460c34f9,0x18d79e19,0xf32e5c03,0xa84117f8,0x8b8888ba,0xc0722677,0x8f3c37dc,0x1c1c0f27,0x10d21be9,0xe0f7a0c6,0xd47c8468,0xadecc0e0,0x9bf02213
.long	0x42b48b99,0x0baa7d12,0x48424096,0x1bcb665d,0xebfb5cfb,0x8b847cd6,0x9ad4d10d,0x87c2ae56,0x0de36726,0xf1cbb122,0x3fdfbd21,0xe7043c68,0x4e79d460,0x4bd0826a,0x4bd1a2cb,0x11f5e598
.long	0xb7fe7b6e,0x97554160,0x400a3fb2,0x7d16189a,0xe328ca1e,0xd73e9bea,0xe793d8cc,0x0dd04b97,0x506db8cc,0xa9c83c9b,0xcf38814c,0x5cd47aae,0xb64b45e6,0x26fc430d,0xd818ea84,0x079b5499
.long	0xc1c24a3b,0xebb01102,0x1c161c1a,0xca24e568,0x36f00a4a,0x103eea69,0x76176c7b,0x9ad76ee8,0x538e0ff7,0x97451fc2,0x6604b3b0,0x94f89809,0x3249cfd7,0x6311436e,0x41224f69,0x27b4a7bd
.long	0xe0ac2941,0x03b5d21a,0xc2d31937,0x279b0254,0xcac992d0,0x3307c052,0xefa8b1f3,0x6aa7cb92,0x0d37c7a5,0x5a182580,0x342d5422,0x13380c37,0xd5d2ef92,0x92ac2d66,0x030c63c6,0x035a70c9
.long	0x4ce4f152,0xc16025dd,0xf9df7c06,0x1f419a71,0x91e4bb14,0x6d5b2214,0x839fb4ce,0xfc43c6cc,0x925d6b2d,0x49f06591,0x62186598,0x4b37d9d3,0xd01b1629,0x8c54a971,0x51d50e05,0xe1a9c29f
.long	0x71ba1861,0x5109b785,0xd0c8f93d,0x48b22d5c,0x8633bb93,0xe8fa84a7,0x5aebbd08,0x53fba6ba,0xe5eea7d8,0x7ff27df3,0x68ca7158,0x521c8796,0xce6f1a05,0xb9d5133b,0xfd0ebee4,0x2d50cd53
.long	0xc5a3ef16,0xc82115d6,0xba079221,0x993eff9d,0x4b5da81c,0xe4da2c5e,0x8033fd85,0x9a89dbdb,0x2b892891,0x60819ebf,0x5d14a4d5,0x53902b21,0xd7fda421,0x6ac35051,0x61c83284,0xcc6ab885
.long	0xf74cff17,0x14eba133,0xecb813f2,0x240aaa03,0x6f665bee,0xcfbb6540,0xa425ad73,0x084b1fe4,0xd081f6a6,0x009d5d16,0xeef82c90,0x35304fe8,0xaa9eaa22,0xf20346d5,0xac1c91e3,0x0ada9f07
.long	0x968a6144,0xa6e21678,0x07b31a1e,0x54c1f77c,0x5781fbe1,0xd6bb787e,0xe31f1c4a,0x61bd2ee0,0x781105fc,0xf25aa1e9,0x7b2f8e80,0x9cf2971f,0xcdff919b,0x26d15412,0x34bc896e,0x01db4ebe
.long	0xb40df1cf,0x7d9b3e23,0x94e971b4,0x59337373,0x669cf921,0xbf57bd14,0x0c1a1064,0x865daedf,0x83279125,0x3eb70bd3,0x34ecdaab,0xbc3d5b9f,0x5f755caf,0x91e3ed7e,0xd41e6f02,0x49699f54
.long	0xd4a7a15b,0x185770e1,0xeaac87e7,0x08f3587a,0x473133ea,0x352018db,0x04fd30fc,0x674ce719,0x088b3e0e,0x7b8d9835,0x5d0d47a1,0x7a0356a9,0x6474a3c4,0x9d9e7659,0xff66966c,0x61ea48a7
.long	0x0f3e4834,0x30417758,0x17a9afcb,0xfdbb21c2,0x2f9a67b3,0x756fa17f,0xa245c1a8,0x2a6b2421,0x4af02291,0x64be2794,0x2a5804fe,0xade465c6,0xa6f08fd7,0x8dffbd39,0xaa14403b,0xc4efa84c
.long	0x442b0f5c,0xa1b91b2a,0xcf997736,0xb748e317,0xcee90e16,0x8d1b62bf,0x0b2078c0,0x907ae271,0x0c9bcddd,0xdf31534b,0x39adce83,0x043fb054,0xd826846a,0x99031043,0xb144f393,0x61a9c0d6
.long	0x47718427,0xdab48046,0x6e830f8b,0xdf17ff9b,0xe49a1347,0x408d7ee8,0x91c1d4ae,0x6ac71e23,0x1defd73c,0xc8cbb9fd,0xbbbbfec5,0x19840657,0x9e7ef8ea,0x39db1cb5,0x64105f30,0x78aa8296
.long	0xa3738c29,0xa3d9b7f0,0xbc3250a3,0x0a2f235a,0x445e4caf,0x55e506f6,0x33475f7a,0x0974f73d,0x5ba2f5a8,0xd37dbba3,0x6af40066,0x542c6e63,0xc5d73e2c,0x26d99b53,0x6c3ca33e,0x06060d7d
.long	0x065fef4a,0xcdbef1c2,0xfd5b92e3,0x77e60f7d,0x26708350,0xd7c549f0,0x34f121bf,0x201b3ad0,0x0334fc14,0x5fcac2a1,0x344552f6,0x8a9a9e09,0x97653082,0x7dd8a1d3,0x79d4f289,0x5fc0738f
.long	0x17d2d8c3,0x787d244d,0x70830684,0xeffc6345,0xe4f73ae5,0x5ddb96dd,0x172549a5,0x8efb14b1,0x2245ae7a,0x6eb73eee,0xea11f13e,0xbca4061e,0x30b01f5d,0xb577421d,0x782e152c,0xaa688b24
.long	0xbd3502ba,0x67608e71,0xb4de75a0,0x4ef41f24,0xfd6125e5,0xb08dde5e,0xa409543f,0xde484825,0x65cc2295,0x1f198d98,0x6e0edfa2,0x428a3771,0xadf35fc7,0x4f9697a2,0xf7cac3c7,0x01a43c79
.long	0x0fd3659a,0xb05d7059,0xbb7f2d9a,0x8927f30c,0x8cf984d3,0x4023d1ac,0x02897a45,0x32125ed3,0x3d414205,0xfb572dad,0xe3fa82a9,0x73000ef2,0xf10a5581,0x4c0868e9,0x6b0b3ca5,0x5b61fc67
.long	0x7cae440c,0xc1258d5b,0x402b7531,0x21c08b41,0xde932321,0xf61a8955,0x2d1408af,0x3568faf8,0x9ecf965b,0x71b15e99,0xe917276f,0xf14ed248,0x820cf9e2,0xc6f4caa1,0x18d83c7e,0x681b20b2
.long	0xc6c01120,0x6cde738d,0xae70e0db,0x71db0813,0x74afe18c,0x95fc0644,0x129e2be7,0x34619053,0xdb2a3b15,0x80615cea,0xdb4c7073,0x0a49a19e,0x8fd2d367,0x0e1b84c8,0x033fb8aa,0xd74bf462
.long	0x533ef217,0x889f6d65,0xc3ca2e87,0x7158c7e4,0xdc2b4167,0xfb670dfb,0x844c257f,0x75910a01,0xcf88577d,0xf336bf07,0xe45e2ace,0x22245250,0x7ca23d85,0x2ed92e8d,0x2b812f58,0x29f8be4c
.long	0x076fe12b,0xdd9ebaa7,0xae1537f9,0x3f2400cb,0x17bdfb46,0x1aa93528,0x67883b41,0xc0f98430,0x0170911d,0x5590ede1,0x34d4b17f,0x7562f5bb,0x1826b8d2,0xe1fa1df2,0x6bd80d59,0xb40b796a
.long	0x3467ba92,0xd65bf197,0xf70954b0,0x8c9b46db,0x0e78f15d,0x97c8a0f3,0x85a4c961,0xa8f3a69a,0x61e4ce9b,0x4242660f,0x6ea6790c,0xbf06aab3,0xec986416,0xc6706f8e,0x9a9fc225,0x9e56dec1
.long	0x9a9898d9,0x527c46f4,0x5633cdef,0xd799e77b,0x7d9e4297,0x24eacc16,0x6b1cb734,0xabb61cea,0xf778443c,0xbee2e8a7,0x29de2fe6,0x3bb42bf1,0x3003bb6f,0xcbed86a1,0xd781cdf6,0xd3918e6c
.long	0x9a5103f1,0x4bee3271,0xf50eac06,0x5243efc6,0x6adcc119,0xb8e122cb,0xc0b80a08,0x1b7faa84,0x6dfcd08c,0x32c3d1bd,0x0be427de,0x129dec4e,0x1d263c83,0x98ab679c,0xcef64eff,0xafc83cb7
.long	0x2fa6be76,0x85eb6088,0x1328cbfe,0x892585fb,0xcf618dda,0xc154d3ed,0x3abaf26e,0xc44f601b,0x2be1fdfd,0x7bf57d0b,0x21137fee,0xa833bd2d,0x2db591a8,0x9353af36,0x5562a056,0xc76f26dc
.long	0x3fdf5a51,0x1d87e47d,0x55c9cab0,0x7afb5f93,0x89e0586e,0x91bbf58f,0x0d843709,0x7c72c018,0x99b5c3dc,0xa9a5aafb,0x3844aeb0,0xa48a0f1d,0xb667e482,0x7178b7dd,0x6e23a59a,0x453985e9
.long	0x01b25dd8,0x4a54c860,0xfb897c8a,0x0dd37f48,0x0ea90cd9,0x5f8aa610,0x16d5830d,0xc8892c68,0xef514ca5,0xeb4befc0,0xe72c9ee6,0x478eb679,0xdbc40d5f,0x9bca20da,0xdde4f64a,0xf015de21
.long	0xeaf4b8a5,0xaa6a4de0,0x4bc60e32,0x68cfd9ca,0x7fd15e70,0x668a4b01,0xf27dc09d,0xd9f0694a,0xba708bcd,0xf6c3cad5,0x5bb95c2a,0x5cd2ba69,0x33c0a58f,0xaa28c1d3,0xabc77870,0x23e274e3
.long	0xdfd20a4a,0x44c3692d,0x81a66653,0x091c5fd3,0x09a0757d,0x6c0bb691,0x667343ea,0x9072e8b9,0x80848bec,0x31d40eb0,0x79fd36cc,0x95bd480a,0x65ed43f5,0x01a77c61,0x2e0d40bf,0xafccd127
.long	0x1cc1884b,0xeccfc82d,0x5d4753b4,0xc85ac201,0x658e099f,0xc7a6caac,0x04b27390,0xcf46369e,0x506467ea,0xe2e7d049,0x37cdeccc,0x481b63a2,0xed80143a,0x4029abd8,0xbcb00b88,0x28bfe3c7
.long	0x0643d84a,0x3bec1009,0xabd11041,0x885f3668,0xf83a34d6,0xdb02432c,0x719ceebe,0x32f7b360,0xdad1fe7a,0xf06c7837,0x5441a0b0,0x60a157a9,0xe2d47550,0x704970e9,0x271b9020,0xcd2bd553
.long	0x33e24a0b,0xff57f82f,0xf2565079,0x9cbee23f,0xeb5f5825,0x16353427,0xe948d662,0x276feec4,0xda10032b,0xd1b62bc6,0xf0e72a53,0x718351dd,0x2420e7ba,0x93452076,0x3a00118d,0x96368fff
.long	0x150a49e4,0x00ce2d26,0x3f04706b,0x0c28b636,0x58b196d0,0xbad65a46,0xec9f8b7c,0x6c8455fc,0x2d71867e,0xe90c895f,0xedf9f38c,0x5c0be31b,0xd8f6ec04,0x2a37a15e,0x8cd85251,0x239639e7
.long	0x9c7c4c6b,0xd8975315,0xd7409af7,0x603aa3c0,0x007132fb,0xb8d53d0c,0xa6849238,0x68d12af7,0xbf5d9279,0xbe0607e7,0xaada74ce,0x9aa50055,0xba7e8ccb,0xe81079cb,0xa5f4ff5e,0x610c71d1
.long	0x5aa07093,0x9e2ee1a7,0xa75da47c,0xca84004b,0x3de75401,0x074d3951,0xbb311592,0xf938f756,0x00a43421,0x96197618,0x07bc78c8,0x39a25362,0x0a171276,0x278f710a,0x8d1a8f08,0xb28446ea
.long	0xe3b6a661,0x184781bf,0xe6d279f7,0x7751cb1d,0xc59eb662,0xf8ff95d6,0x58d3dea7,0x186d90b7,0xdfb4f754,0x0e4bb6c1,0x2b2801dc,0x5c5cf56b,0x1f54564d,0xc561e452,0xf0dd7f13,0xb4fb8c60
.long	0x33ff98c7,0xf8849630,0xcf17769c,0x9619fffa,0x1bfdd80a,0xf8090bf6,0x422cfe63,0x14d9a149,0x6f6df9ea,0xb354c360,0x218f17ea,0xdbcf770d,0x79eb3480,0x207db7c8,0x559b6a26,0x213dbda8
.long	0x29fc81b3,0xac4c200b,0x171d87c1,0xebc3e09f,0x1481aa9e,0x91799530,0x92e114fa,0x051b92e1,0xecb5537f,0xdf8f92e9,0x290c7483,0x44b1b2cc,0x2adeb016,0xa711455a,0x81a10c2c,0x964b6856
.long	0xcec03623,0x4f159d99,0xef3271ea,0x05532225,0xc5ee4849,0xb231bea3,0x7094f103,0x57a54f50,0x9598b352,0x3e2d421d,0x67412ab4,0xe865a49c,0x1cc3a912,0xd2998a25,0x0c74d65d,0x5d092808
.long	0x4088567a,0x73f45908,0x1f214a61,0xeb6b280e,0xcaf0c13d,0x8c9adc34,0xf561fb80,0x39d12938,0xbc6edfb4,0xb2dc3a5e,0xfe4d210e,0x7485b1b1,0xe186ae72,0x062e0400,0x6eeb3b88,0x91e32d5c
.long	0x4be59224,0x6df574d7,0x716d55f3,0xebc88ccc,0xcad6ed33,0x26c2e6d0,0x0d3e8b10,0xc6e21e7d,0x5bcc36bb,0x2cc5840e,0x7da74f69,0x9292445e,0x4e5193a8,0x8be8d321,0x8df06413,0x3ec23629
.long	0xb134defa,0xc7e9ae85,0x1bb2d475,0x6073b1d0,0x2863c00d,0xb9ad615e,0x525f4ac4,0x9e29493d,0x4e9acf4f,0xc32b1dea,0xa50db88d,0x3e1f01c8,0x04da916c,0xb05d70ea,0xd865803e,0x714b0d0a
.long	0x9920cb5e,0x4bd493fc,0x92c7a3ac,0x5b44b1f7,0xbcec9235,0xa2a77293,0xcd378553,0x5ee06e87,0xda621607,0xceff8173,0x99f5d290,0x2bb03e4c,0xa6f734ac,0x2945106a,0xd25c4732,0xb5056604
.long	0xe079afee,0x5945920c,0x6789831f,0x686e17a0,0xb74a5ae5,0x5966bee8,0x1e258d46,0x38a673a2,0x83141c95,0xbd1cc1f2,0x0e96e486,0x3b2ecf4f,0x74e5fc78,0xcd3aa896,0x2482fa7a,0x415ec10c
.long	0x80503380,0x15234419,0xd314b392,0x513d917a,0x63caecae,0xb0b52f4e,0x2dc7780b,0x07bf22ad,0xe4306839,0xe761e8a1,0x5dd7feaa,0x1b3be962,0x74c778f1,0x4fe728de,0x5e0070f6,0xf1fa0bda
.long	0x6ec3f510,0x85205a31,0xd2980475,0x2c7e4a14,0x6f30ebfd,0xde3c19c0,0xd4b7e644,0xdb1c1f38,0x5dce364a,0xfe291a75,0x058f5be3,0xb7b22a3c,0x37fea38c,0x2cd2c302,0x2e17be17,0x2930967a
.long	0x0c061c65,0x87f009de,0xedc6ed44,0xcb014aac,0x3bafb1eb,0x49bd1cb4,0x282d3688,0x81bd8b5c,0xf01a17af,0x1cdab87e,0xe710063b,0x21f37ac4,0x42fc8193,0x5a6c5676,0x56a6015c,0xf4753e70
.long	0xa15b0a44,0x020f795e,0x8958a958,0x8f37c8d7,0xa4b675b5,0x63b7e89b,0x0fc31aea,0xb4fb0c0c,0xa7ff1f2e,0xed95e639,0x619614fb,0x9880f5a3,0x947151ab,0xdeb6ff02,0xa868dcdb,0x5bc5118c
.long	0x4c20cea5,0xd8da2055,0x14c4d69a,0xcac2776e,0x622d599b,0xcccb22c1,0x68a9bb50,0xa4ddb653,0x1b4941b4,0x2c4ff151,0x6efba588,0xe1ff19b4,0xc48345e0,0x35034363,0x1e29dfc4,0x45542e3d
.long	0x349f7aed,0xf197cb91,0x8fca8420,0x3b2b5a00,0x23aaf6d8,0x7c175ee8,0x35af32b6,0x54dcf421,0x27d6561e,0x0ba14307,0xd175b1e2,0x879d5ee4,0x99807db5,0xc7c43673,0x9cd55bcd,0x77a54455
.long	0x0105c072,0xe6c2ff13,0x8dda7da4,0x18f7a99f,0x0e2d35c1,0x4c301820,0xd9cc6c82,0x06a53ca0,0xf1aa1d9e,0xaa21cc1e,0x4a75b1e8,0x32414334,0x0ebe9fdc,0x2a6d1328,0x98a4755a,0x16bd173f
.long	0x2133ffd9,0xfbb9b245,0x830f1a20,0x39a8b2f1,0xd5a1f52a,0x484bc97d,0xa40eddf8,0xd6aebf56,0x76ccdac6,0x32257acb,0x1586ff27,0xaf4d36ec,0xf8de7dd1,0x8eaa8863,0x88647c16,0x0045d5cf
.long	0xc005979d,0xa6f3d574,0x6a40e350,0xc2072b42,0x8de2ecf9,0xfca5c156,0xa515344e,0xa8c8bf5b,0x114df14a,0x97aee555,0xfdc5ec6b,0xd4374a4d,0x2ca85418,0x754cc28f,0xd3c41f78,0x71cb9e27
.long	0x03605c39,0x89105079,0xa142c96c,0xf0843d9e,0x16923684,0xf3744934,0xfa0a2893,0x732caa2f,0x61160170,0xb2e8c270,0x437fbaa3,0xc32788cc,0xa6eda3ac,0x39cd818e,0x9e2b2e07,0xe2e94239
.long	0x0260e52a,0x6967d39b,0x90653325,0xd42585cc,0x21ca7954,0x0d9bd605,0x81ed57b3,0x4fa20877,0xe34a0bbe,0x60c1eff8,0x84f6ef64,0x56b0040c,0xb1af8483,0x28be2b24,0xf5531614,0xb2278163
.long	0x5922ac1c,0x8df27545,0xa52b3f63,0xa7b3ef5c,0x71de57c4,0x8e77b214,0x834c008b,0x31682c10,0x4bd55d31,0xc76824f0,0x17b61c71,0xb6d1c086,0xc2a5089d,0x31db0903,0x184e5d3f,0x9c092172
.long	0xc00cc638,0xdd7ced5b,0x61278fc2,0x1a2015eb,0x6a37f8d6,0x2e8e5288,0xe79933ad,0xc457786f,0x2c51211a,0xb3fe4cce,0x24c20498,0xad9b10b2,0xd28db5e5,0x90d87a4f,0x3aca2fc3,0x698cd105
.long	0xe91b536d,0x4f112d07,0x9eba09d6,0xceb982f2,0x197c396f,0x3c157b2c,0x7b66eb24,0xe23c2d41,0x3f330d37,0x480c57d9,0x79108deb,0xb3a4c8a1,0xcb199ce5,0x702388de,0xb944a8d4,0x0b019211
.long	0x840bb336,0x24f2a692,0xa669fa7b,0x7c353bdc,0xdec9c300,0xda20d6fc,0xa13a4f17,0x625fbe2f,0xdbc17328,0xa2b1b61a,0xa9515621,0x008965bf,0xc620ff46,0x49690939,0x8717e91c,0x182dd27d
.long	0xea6c3997,0x5ace5035,0xc2610bef,0x54259aaa,0x3c80dd39,0xef18bb3f,0x5fc3fa39,0x6910b95b,0x43e09aee,0xfce2f510,0xa7675665,0xced56c9f,0xd872db61,0x10e265ac,0xae9fce69,0x6982812e
.long	0xce800998,0x29be11c6,0xb90360d9,0x72bb1752,0x5a4ad590,0x2c193197,0x9fc1dbc0,0x2ba2f548,0xe490ebe0,0x7fe4eebb,0x7fae11c0,0x12a0a4cd,0xe903ba37,0x7197cf81,0xde1c6dd8,0xcf7d4aa8
.long	0x3fd5684c,0x92af6bf4,0x80360aa1,0x2b26eecf,0x00546a82,0xbd960f30,0xf59ad8fe,0x407b3c43,0x249c82ba,0x86cae5fe,0x2463744c,0x9e0faec7,0x94916272,0x87f551e8,0x6ceb0615,0x033f9344
.long	0x8be82e84,0x1e5eb0d1,0x7a582fef,0x89967f0e,0xa6e921fa,0xbcf687d5,0xd37a09ba,0xdfee4cf3,0xb493c465,0x94f06965,0x7635c030,0x638b9a1c,0x66f05e9f,0x76667864,0xc04da725,0xccaf6808
.long	0x768fccfc,0xca2eb690,0xb835b362,0xf402d37d,0xe2fdfcce,0x0efac0d0,0xb638d990,0xefc9cdef,0xd1669a8b,0x2af12b72,0x5774ccbd,0x33c536bc,0xfb34870e,0x30b21909,0x7df25aca,0xc38fa2f7
.long	0xbf81f3f5,0x74c5f02b,0xaf7e4581,0x0525a5ae,0x433c54ae,0x88d2aaba,0x806a56c5,0xed9775db,0xc0edb37d,0xd320738a,0x66cc1f51,0x25fdb6ee,0x10600d76,0xac661d17,0xbdd1ed76,0x931ec1f3
.long	0x19ee43f1,0x65c11d62,0x60829d97,0x5cd57c3e,0x984be6e8,0xd26c91a3,0x8b0c53bd,0xf08d9309,0xc016e4ea,0x94bc9e5b,0x11d43d2b,0xd3916839,0x73701155,0x886c5ad7,0x20b00715,0xe0377626
.long	0xaa80ba59,0x7f01c9ec,0x68538e51,0x3083411a,0xe88128af,0x970370f1,0x91dec14b,0x625cc3db,0x01ac3107,0xfef9666c,0xd5057ac3,0xb2a8d577,0x92be5df7,0xb0f26299,0x00353924,0xf579c8e5
.long	0x1341ed7a,0xb8fa3d93,0xa7b59d49,0x4223272c,0x83b8c4a4,0x3dcb1947,0xed1302e4,0x4e413c01,0xe17e44ce,0x6d999127,0x33b3adfb,0xee86bf75,0x25aa96ca,0xf6902fe6,0xe5aae47d,0xb73540e4
.long	0x1b4a158c,0x32801d7b,0x27e2a369,0xe571c99e,0x10d9f197,0x40cb76c0,0x3167c0ae,0xc308c289,0xeb7958f2,0xa6ef9dd3,0x300879b1,0xa7226dfc,0x7edf0636,0x6cd0b362,0x7bc37eed,0x4efbce6c
.long	0x8d699021,0x75f92a05,0x772566e3,0x586d4c79,0x761ad23a,0x378ca5f1,0x1465a8ac,0x650d86fc,0x842ba251,0x7a4ed457,0x42234933,0x6b65e3e6,0x31aad657,0xaf1543b7,0xcbfec369,0xa4cefe98
.long	0x9f47befb,0xb587da90,0x41312d13,0x6562e9fb,0xeff1cefe,0xa691ea59,0x05fc4cf6,0xcc30477a,0x0b0ffd3d,0xa1632461,0x5b355956,0xa1f16f3b,0x4224ec24,0x5b148d53,0xf977012a,0xdc834e7b
.long	0xb2c69dbc,0x7bfc5e75,0x03c3da6c,0x3aa77a29,0xca910271,0xde0df03c,0x7806dc55,0xcbd5ca4a,0x6db476cb,0xe1ca5807,0x5f37a31e,0xfde15d62,0xf41af416,0xf49af520,0x7d342db5,0x96c5c5b1
.long	0xeb4ceb9b,0x155c43b7,0x4e77371a,0x2e993010,0x675d43af,0x1d2987da,0x8599fd72,0xef2bc1c0,0x9342f6b2,0x96894b7b,0x7c8e71f0,0x201eadf2,0x4a1f3efc,0xf3479d9f,0x702a9704,0xe0f8a742
.long	0xb3eba40c,0xeafd44b6,0xc1c1e0d0,0xf9739f29,0x619d505e,0x0091471a,0x9d7c263e,0xc15f9c96,0x83afbe33,0x5be47285,0x04f1e092,0xa3b6d6af,0x751a9d11,0xe76526b9,0x9a4ae4d2,0x2ec5b26d
.long	0x02f6fb8d,0xeb66f4d9,0x96912164,0x4063c561,0x80ef3000,0xeb7050c1,0xeaa5b3f0,0x288d1c33,0x07806fd8,0xe87c68d6,0x4bbbf50f,0xb2f7f9d5,0xac8d6627,0x25972f3a,0x10e8c13b,0xf8547774
.long	0x872b4a60,0xcc50ef6c,0x4613521b,0xab2a34a4,0x983e15d1,0x39c5c190,0x59905512,0x61dde5df,0x9f2275f3,0xe417f621,0x451d894b,0x0750c8b6,0x78b0bdaa,0x75b04ab9,0x458589bd,0x3bfd9fd4
.long	0xee9120b6,0xf1013e30,0x23a4743e,0x2b51af93,0x48d14d9e,0xea96ffae,0x698a1d32,0x71dc0dbe,0x0180cca4,0x914962d2,0xc3568963,0x1ae60677,0x437bc444,0x8cf227b1,0xc9962c7a,0xc650c83b
.long	0xfe7ccfc4,0x23c2c7dd,0x1b929d48,0xf925c89d,0x06783c33,0x4460f74b,0xa590475a,0xac2c8d49,0xb807bba0,0xfb40b407,0x69ff8f3a,0x9d1e362d,0xcbef64a4,0xa33e9681,0x332fb4b2,0x67ece5fa
.long	0x739f10e3,0x6900a99b,0xff525925,0xc3341ca9,0xa9e2d041,0xee18a626,0x29580ddd,0xa5a83685,0x9d7de3cd,0xf3470c81,0x2062cf9c,0xedf02586,0xc010edb0,0xf43522fa,0x13a4b1ae,0x30314135
.long	0xdb22b94b,0xc792e02a,0xa1eaa45b,0x993d8ae9,0xcd1e1c63,0x8aad6cd3,0xc5ce688a,0x89529ca7,0xe572a253,0x2ccee3aa,0x02a21efb,0xe02b6438,0xc9430358,0xa7091b6e,0x9d7db504,0x06d1b1fa
.long	0xc4744733,0x58846d32,0x379f9e34,0x40517c71,0x130ef6ca,0x2f65655f,0xf1f3503f,0x526e4488,0x7ee4a976,0x8467bd17,0x921363d1,0x1d9dc913,0xb069e041,0xd8d24c33,0x2cdf7f51,0x5eb5da0a
.long	0x197b994f,0x1c0f3cb1,0x2843eae9,0x3c95a6c5,0xa6097ea5,0x7766ffc9,0xd723b867,0x7bea4093,0x4db378f9,0xb48e1f73,0xe37b77ac,0x70025b00,0xaf24ad46,0x943dc8e7,0x16d00a85,0xb98a15ac
.long	0x2743b004,0x3adc38ba,0x334415ee,0xb1c7f4f7,0x1e62d05a,0xea43df8f,0x9d76a3b6,0x32618905,0xa23a0f46,0x2fbd0bb5,0x6a01918c,0x5bc971db,0xb4743f94,0x7801d94a,0x676ae22b,0xb94df65e
.long	0xaf95894c,0xaafcbfab,0x276b2241,0x7b9bdc07,0x5bdda48b,0xeaf98362,0xa3fcb4df,0x5977faf2,0x052c4b5b,0xbed042ef,0x067591f0,0x9fe87f71,0x22f24ec7,0xc89c73ca,0xe64a9f1b,0x7d37fa9e
.long	0x15562627,0x2710841a,0xc243b034,0x2c01a613,0x2bc68609,0x1d135c56,0x8b03f1f6,0xc2ca1715,0x3eb81d82,0xc9966c2d,0x8f6df13e,0xc02abf4a,0x8f72b43b,0x77b34bd7,0x360c82b0,0xaff6218f
.long	0x8d55b9d2,0x0aa5726c,0x99e9bffb,0xdc0adbe9,0xefb9e72a,0x9097549c,0x9dfb3111,0x16755712,0xf26847f9,0xdd8bf984,0xdfb30cb7,0xbcb8e387,0x5171ef9c,0xc1fd32a7,0x389b363f,0x977f3fc7
.long	0xf4babda0,0x116eaf2b,0xf7113c8e,0xfeab68bd,0xb7def526,0xd1e3f064,0xe0b3fa02,0x1ac30885,0x40142d9d,0x1c5a6e7b,0x30921c0b,0x839b5603,0x36a116a3,0x48f301fa,0xcfd9ee6d,0x380e1107
.long	0x58854be1,0x7945ead8,0xcbd4d49d,0x4111c12e,0x3a29c2ef,0xece3b1ec,0x8d3616f5,0x6356d404,0x594d320e,0x9f0d6a8f,0xf651ccd2,0x0989316d,0x0f8fdde4,0x6c32117a,0xa26a9bbc,0x9abe5cc5
.long	0x9723f671,0xcff560fb,0x7f3d593c,0x21b2a12d,0x24ba0696,0xe4cb18da,0xc3543384,0x186e2220,0x88312c29,0x722f64e0,0x17dc7752,0x94282a99,0x5a85ee89,0x62467bbf,0xf10076a0,0xf435c650
.long	0x43b3a50b,0xc9ff1539,0x1a53efbc,0x7132130c,0xf7b0c5b7,0x31bfe063,0x4ea994cc,0xb0179a7d,0xc85f455b,0x12d064b3,0x8f6e0062,0x47259328,0xb875d6d9,0xf64e590b,0xad92bcc7,0x22dd6225
.long	0xb9c3bd6d,0xb658038e,0xfbba27c8,0x00cdb0d6,0x1062c45d,0x0c681337,0x2d33407d,0xd8515b8c,0x8cbb5ecf,0xcb8f699e,0xc608d7d8,0x8c4347f8,0xbb3e00db,0x2c11850a,0xecb49d19,0x20a8dafd
.long	0x45ee2f40,0xbd781480,0x416b60cf,0x75e354af,0x8d49a8c4,0xde0b58a1,0xfa359536,0xe40e94e2,0x62accd76,0xbd4fa59f,0x8c762837,0x05cf466a,0x448c277b,0xb5abda99,0x48b13740,0x5a9e01bf
.long	0x326aad8d,0x9d457798,0xc396f7e7,0xbdef4954,0xc253e292,0x6fb274a2,0x1cfe53e7,0x2800bf0a,0x44438fd4,0x22426d31,0x5e259f9a,0xef233923,0x03f66264,0x4188503c,0x7f9fdfab,0x9e5e7f13
.long	0x5fcc1aba,0x565eb76c,0x59b5bff8,0xea632548,0xaab6d3fa,0x5587c087,0x6ce39c1b,0x92b639ea,0x953b135c,0x0706e782,0x425268ef,0x7308912e,0x090e7469,0x599e92c7,0x9bc35e75,0x83b90f52
.long	0x244975b3,0x4750b3d0,0x11965d72,0xf3a44358,0x9c8dc751,0x179c6774,0xd23d9ff0,0xff18cdfe,0x2028e247,0xc4013833,0xf3bfbc79,0x96e280e2,0xd0880a84,0xf60417bd,0x2a568151,0x263c9f3d
.long	0x2d2ce811,0x36be15b3,0xf8291d21,0x846dc0c2,0x789fcfdb,0x5cfa0ecb,0xd7535b9a,0x45a0beed,0x96d69af1,0xec8e9f07,0x599ab6dc,0x31a7c5b8,0xf9e2e09f,0xd36d45ef,0xdcee954b,0x3cf49ef1
.long	0x086cff9b,0x6be34cf3,0x39a3360f,0x88dbd491,0x0dbfbd1d,0x1e96b8cc,0xcb7e2552,0xc1e5f7bf,0x28819d98,0x0547b214,0x7aea9dcb,0xc770dd9c,0x041d68c8,0xaef0d4c7,0x13cb9ba8,0xcc2b9818
.long	0xfe86c607,0x7fc7bc76,0x502a9a95,0x6b7b9337,0xd14dab63,0x1948dc27,0xdae047be,0x249dd198,0xa981a202,0xe8356584,0x3a893387,0x3531dd18,0xc85c7209,0x1be11f90,0xe2a52b5a,0x93d2fe1e
.long	0xec6d6b97,0x8225bfe2,0xbd0aa5de,0x9cf6d6f4,0x54779f5f,0x911459cb,0x86aeb1f3,0x5649cddb,0x3f26ce5a,0x32133579,0x550f431e,0xc289a102,0x73b84c6f,0x559dcfda,0xee3ac4d7,0x84973819
.long	0xf2606a82,0xb51e55e6,0x90f2fb57,0xe25f7061,0xb1a4e37c,0xacef6c2a,0x5dcf2706,0x864e359d,0x7ce57316,0x479e6b18,0x3a96b23d,0x2cab2500,0x8ef16df7,0xed489862,0xef3758b5,0x2056538c
.long	0xf15d3101,0xa7df865e,0x61b553d7,0x80c5533a,0x4ed14294,0x366e1997,0xb3c0bcd6,0x6620741f,0xedc45418,0x21d1d9c4,0xc1cc4a9d,0x005b859e,0xa1c462f0,0xdf01f630,0xf26820c7,0x15d06cf3
.long	0x3484be47,0x9f7f24ee,0x4a0c902f,0x2ff33e96,0x5a0bc453,0x00bdf457,0x1aa238db,0x2378dfaf,0x856720f2,0x272420ec,0x96797291,0x2ad9d95b,0x768a1558,0xd1242cc6,0x5cc86aa8,0x2e287f8b
.long	0x990cecaa,0x796873d0,0x675d4080,0xade55f81,0x21f0cd84,0x2645eea3,0xb4e17d02,0x7a1efa0f,0x037cc061,0xf6858420,0xd5d43e12,0x682e05f0,0x27218710,0x59c36994,0x3f7cd2fc,0x85cbba4d
.long	0x7a3cd22a,0x726f9729,0x4a628397,0x9f8cd5dc,0xc23165ed,0x17b93ab9,0x122823d4,0xff5f5dbf,0x654a446d,0xc1e4e4b5,0x677257ba,0xd1a9496f,0xde766a56,0x6387ba94,0x521ec74a,0x23608bc8
.long	0x6688c4d4,0x16a522d7,0x07373abd,0x9d6b4282,0xb42efaa3,0xa62f07ac,0xe3b90180,0xf73e00f7,0x49421c3e,0x36175fec,0x3dcf2678,0xc4e44f9b,0x7220f09f,0x76df436b,0x3aa8b6cf,0x172755fb
.long	0x446139cc,0xbab89d57,0x5fe0208f,0x0a0a6e02,0x11e5d399,0xcdbb63e2,0xa8977f0b,0x33ecaa12,0xf7c42664,0x59598b21,0xab65d08a,0xb3e91b32,0xf4502526,0x035822ee,0x720a82a9,0x1dcf0176
.long	0x3d589e02,0x50f8598f,0xb1d63d2c,0xdf0478ff,0x1571cd07,0x8b8068bd,0xd79670cd,0x30c3aa4f,0x941ade7f,0x25e8fd4b,0x32790011,0x3d1debdc,0x3a3f9ff0,0x65b6dcbd,0x793de69c,0x282736a4
.long	0xd41d3bd3,0xef69a0c3,0x07a26bde,0xb533b8c9,0xdb2edf9f,0xe2801d97,0xe1877af0,0xdc4a8269,0x3d590dbe,0x6c1c5851,0xee4e9357,0x84632f6b,0x79b33374,0xd36d36b7,0x9bbca2e6,0xb46833e3
.long	0xf7fc0586,0x37893913,0x66bf4719,0x385315f7,0xb31855dc,0x72c56293,0x849061fe,0xd1416d4e,0x51047213,0xbeb3ab78,0xf040c996,0x447f6e61,0x638b1d0c,0xd06d310d,0xbad1522e,0xe28a413f
.long	0x82003f86,0x685a76cb,0x0bcdbca3,0x610d07f7,0x9ca4c455,0x6ff66021,0xcea10eec,0x7df39b87,0xe22db218,0xb9255f96,0x08a34c44,0x8cc6d9eb,0x859f9276,0xcd4ffb86,0x50d07335,0x8fa15eb2
.long	0xcf2c24b5,0xdf553845,0x52f9c3ba,0x89f66a9f,0xe4a7ceb3,0x8f22b5b9,0x0e134686,0xaffef809,0x8eb8fac2,0x3e53e1c6,0x28aec98e,0x93c1e4eb,0x32a43bcb,0xb6b91ec5,0xb2d74a51,0x2dbfa947
.long	0xca84bad7,0xe065d190,0xad58e65c,0xfb13919f,0xf1cb6e31,0x3c41718b,0x06d05c3f,0x688969f0,0x21264d45,0xd4f94ce7,0x7367532b,0xfdfb65e9,0x0945a39d,0x5b1be8b1,0x2b8baf3b,0x229f789c
.long	0x6f49f15d,0xd8f41f3e,0x907f0792,0x678ce828,0xfca6e867,0xc69ace82,0xd01dcc89,0x106451ae,0x19fc32d2,0x1bb4f7f0,0xb00c52d2,0x64633dfc,0xad9ea445,0x8f13549a,0xfb323705,0x99a3bf50
.long	0x534d4dbc,0x0c9625a2,0xc2a2fea3,0x45b8f1d1,0xa530fc1a,0x76ec21a1,0x9e5bd734,0x4bac9c2a,0x7b4e3587,0x5996d76a,0x1182d9e3,0x0045cdee,0x1207f13d,0x1aee24b9,0x97345a41,0x66452e97
.long	0x9f950cd0,0x16e5b054,0xd7fdd075,0x9cc72fb1,0x66249663,0x6edd61e7,0xf043cccb,0xde4caa4d,0x55c7ac17,0x11b1f57a,0x1a85e24d,0x779cbd44,0xe46081e7,0x78030f86,0x8e20f643,0xfd4a6032
.long	0x0a750c0f,0xcc7a6488,0x4e548e83,0x39bacfe3,0x0c110f05,0x3d418c76,0xb1f11588,0x3e4daa4c,0x5ffc69ff,0x2733e7b5,0x92053127,0x46f147bc,0xd722df94,0x885b2434,0xe6fc6b7c,0x6a444f65
.long	0xc3f16ea8,0x7a1a465a,0xb2f1d11c,0x115a461d,0x6c68a172,0x4767dd95,0xd13a4698,0x3392f2eb,0xe526cdc7,0xc7a99ccd,0x22292b81,0x8e537fdc,0xa6d39198,0x76d8cf69,0x2446852d,0xffc5ff43
.long	0xa90567e6,0x97b14f7e,0xb6ae5cb7,0x513257b7,0x9f10903d,0x85454a3c,0x69bc3724,0xd8d2c9ad,0x6b29cb44,0x38da9324,0x77c8cbac,0xb540a21d,0x01918e42,0x9bbfe435,0x56c3614e,0xfffa707a
.long	0xd4e353b7,0x0ce4e3f1,0xef46b0a0,0x062d8a14,0x574b73fd,0x6408d5ab,0xd3273ffd,0xbc41d1c9,0x6be77800,0x3538e1e7,0xc5655031,0x71fe8b37,0x6b9b331a,0x1cd91621,0xbb388f73,0xad825d0b
.long	0x1cb76219,0x56c2e05b,0x71567e7e,0x0ec0bf91,0x61c4c910,0xe7076f86,0xbabc04d9,0xd67b085b,0x5e93a96a,0x9fb90459,0xfbdc249a,0x7526c1ea,0xecdd0bb7,0x0d44d367,0x9dc0d695,0x95399917
.long	0x9e240d18,0x61360ee9,0xb4b94466,0x057cdcac,0x2fe5325c,0xe7667cd1,0x21974e3b,0x1fa297b5,0xdb083d76,0xfa4081e7,0xf206bd15,0x31993be6,0x14c19f8c,0x8949269b,0xa9d92357,0x21468d72
.long	0xa4c506ec,0x2ccbc583,0xd1acfe97,0x957ed188,0x12f1aea2,0x8baed833,0x8325362d,0xef2a6cb4,0x8e195c43,0x130dde42,0x0e6050c6,0xc842025a,0x08686a5d,0x2da972a7,0xe508b4a8,0xb52999a1
.long	0x10a5a8bd,0xd9f090b9,0x096864da,0xca91d249,0x3f67dbc1,0x8e6a93be,0xf5f4764c,0xacae6fba,0xd21411a0,0x1563c6e0,0xda0a4ad8,0x28fa787f,0x908c8030,0xd524491c,0x4c795f07,0x1257ba0e
.long	0xceca9754,0x83f49167,0x4b7939a0,0x426d2cf6,0x723fd0bf,0x2555e355,0xc4f144e2,0xa96e6d06,0x87880e61,0x4768a8dd,0xe508e4d5,0x15543815,0xb1b65e15,0x09d7e772,0xac302fa0,0x63439dd6
.long	0xc14e35c2,0xb93f802f,0x4341333c,0x71735b7c,0x16d4f362,0x03a25104,0xbf433c8e,0x3f4d069b,0xf78f5a7c,0x0d83ae01,0x7c4eed07,0x50a8ffbe,0x76e10f83,0xc74f8906,0x9ddaf8e1,0x7d080966
.long	0x698e04cc,0xb11df8e1,0x169005c8,0x877be203,0x4f3c6179,0x32749e8c,0x7853fc05,0x2dbc9d0a,0x9454d937,0x187d4f93,0xb4800e1b,0xe682ce9d,0x165e68e8,0xa9129ad8,0xbe7f785b,0x0fe29735
.long	0x5b9e02b7,0x5303f40c,0x35ee04e8,0xa37c9692,0x34d6632b,0x5f46cc20,0x96ac545b,0x55ef72b2,0x7b91b062,0xabec5c1f,0xbb33e821,0x0a79e1c7,0x3a9f4117,0xbb04b428,0xfd2a475a,0x0de1f28f
.long	0x3a4434b4,0x31019ccf,0x1a7954dc,0xa3458111,0xe34972a7,0xa9dac80d,0x74f6b8dd,0xb043d054,0x11137b1a,0x021c319e,0xed5cc03f,0x00a754ce,0xcbea5ad4,0x0aa2c794,0x70c015b6,0x093e67f4
.long	0xc97e3f6b,0x72cdfee9,0xb6da7461,0xc10bcab4,0xb59806b9,0x3b02d2fc,0xa1de6f47,0x85185e89,0x0eb6c4d4,0x39e6931f,0xd4fa5b04,0x4d4440bd,0x34be7eb8,0x5418786e,0x9d7259bc,0x6380e521
.long	0xd598d710,0x20ac0351,0xcb3a4da4,0x272c4166,0xca71de1f,0xdb82fe1a,0xd8f54b0f,0x746e79f2,0x4b573e9b,0x6e7fc736,0xfd4b5040,0x75d03f46,0x0b98d87b,0x5c1cc36d,0x1f472da1,0x513ba3f1
.long	0xabb177dd,0x79d0af26,0x7891d564,0xf82ab568,0x72232173,0x2b6768a9,0x8c1f6619,0xefbb3bb0,0xa6d18358,0xb29c11db,0xb0916d3a,0x519e2797,0x9188e290,0xd4dc18f0,0x98b0ca7f,0x648e86e3
.long	0x983c38b5,0x859d3145,0x637abc8b,0xb14f176c,0xcaff7be6,0x2793fb9d,0x35a66a5a,0xebe5a55f,0x9f87dc59,0x7cec1dcd,0xfbdbf560,0x7c595cd3,0x26eb3257,0x5b543b22,0xc4c935fd,0x69080646
.long	0x81e9ede3,0x7f2e4403,0xcaf6df0a,0x243c3894,0x1c073b11,0x7c605bb1,0xba6a4a62,0xcd06a541,0x49d4e2e5,0x29168949,0x4af66880,0x33649d07,0xe9a85035,0xbfc0c885,0xfc410f4b,0xb4e52113
.long	0x78a6513b,0xdca3b706,0x9edb1943,0x92ea4a2a,0xdb6e2dd8,0x02642216,0x9fd57894,0x9b45d0b4,0xc69d11ae,0x114e70db,0x4c57595f,0x1477dd19,0xec77c272,0xbc2208b4,0xdb68f59c,0x95c5b4d7
.long	0x42e532b7,0xb8c4fc63,0x9ae35290,0x386ba422,0xd201ecbc,0xfb5dda42,0xa0e38fd6,0x2353dc8b,0x68f7e978,0x9a0b85ea,0x2ad6d11f,0x96ec5682,0xe5f6886d,0x5e279d6c,0x3cb1914d,0xd3fe03cd
.long	0x7ea67c77,0xfe541fa4,0xe3ea810c,0x952bd2af,0x8d01d374,0x791fef56,0x0f11336e,0xa3a1c621,0xc7ec6d79,0x5ad0d5a9,0x3225c342,0xff7038af,0xbc69601b,0x003c6689,0x45e8747d,0x25059bc7
.long	0xf2086fbf,0xfa4965b2,0x86916078,0xf6840ea6,0x70081d6c,0xd7ac7620,0xb5328645,0xe600da31,0x529b8a80,0x01916f63,0x2d7d6f3e,0xe80e4858,0xd664ca7c,0x29eb0fe8,0xe7b43b0c,0xf017637b
.long	0x76cb2566,0x9a75c806,0xb24892d9,0x8f76acb1,0x1f08fe45,0x7ae7b9cc,0x6a4907d8,0x19ef7329,0x5f228bf0,0x2db4ab71,0x817032d7,0xf3cdea39,0xdcabe3c0,0x0b1f482e,0xbb86325c,0x3baf76b4
.long	0x10089465,0xd49065e0,0x8e77c596,0x3bab5d29,0x193dbd95,0x7636c3a6,0xb246e499,0xdef5d294,0x286b2475,0xb22c58b9,0xcd80862b,0xa0b93939,0xf0992388,0x3002c83a,0xeacbe14c,0x6de01f9b
.long	0xadd70482,0x6aac688e,0x7b4a4e8a,0x708de92a,0x758a6eef,0x75b6dd73,0x725b3c43,0xea4bf352,0x87912868,0x10041f2c,0xef09297a,0xb1b1be95,0xa9f3860a,0x19ae23c5,0x515dcf4b,0xc4f0f839
.long	0x97f6306a,0x3c7ecca3,0x68a3a4b0,0x744c44ae,0xb3a1d8a2,0x69cd13a0,0x5256b578,0x7cad0a1e,0x33791d9e,0xea653fcd,0x74b2e05f,0x9cc2a05d,0xfd7affa2,0x73b391dc,0xb6b05442,0xddb7091e
.long	0x8538a5c6,0xc71e27bf,0x89abff17,0x195c63dd,0x1b71e3da,0xfd315285,0xfa680fa0,0x9cbdfda7,0x849d7eab,0x9db876ca,0x3c273271,0xebe2764b,0xf208dcea,0x663357e3,0x565b1b70,0x8c5bd833
.long	0x9837fc0d,0xccc3b4f5,0xa79cf00f,0x9b641ba8,0xdfdf3990,0x7428243d,0x020786b1,0x83a594c4,0x526c4502,0xb712451a,0x6adb3f93,0x9d39438e,0xe9ff0ccd,0xfdb261e3,0xe07af4c3,0x80344e3c
.long	0x2fa4f126,0x75900d7c,0x5c99a232,0x08a3b865,0xdb25e0c3,0x2478b6bf,0x71db2edf,0x482cc2c2,0x5f321bb8,0x37df7e64,0x9a8005b4,0x8a93821b,0xcc8c1958,0x3fa2f10c,0x2c269d0a,0x0d332218
.long	0xe246b0e6,0x20ab8119,0xd349fd17,0xb39781e4,0xb31aa100,0xd293231e,0xbb032168,0x4b779c97,0xc8470500,0x4b3f19e1,0x0c4c869d,0x45b7efe9,0xa1a6bbcc,0xdb84f38a,0xb2fddbc1,0x3b59cb15
.long	0x3fd165e8,0xba5514df,0x061f8811,0x499fd6a9,0xbfef9f00,0x72cd1fe0,0x79ad7e8a,0x120a4bb9,0x5f4a5ac5,0xf2ffd095,0x95a7a2f0,0xcfd174f1,0x9d17baf1,0xd42301ba,0x77f22089,0xd2fa487a
.long	0xb1dc77e1,0x9cb09efe,0x21c99682,0xe9566939,0x6c6067bb,0x8c546901,0x61c24456,0xfd378574,0x81796b33,0x2b6a6cbe,0x58e87f8b,0x62d550f6,0x7f1b01b4,0x1b763e1c,0x1b1b5e12,0x4b93cfea
.long	0x1d531696,0xb9345238,0x88cdde69,0x57201c00,0x9a86afc7,0xdde92251,0xbd35cea8,0xe3043895,0x8555970d,0x7608c1e1,0x2535935e,0x8267dfa9,0x322ea38b,0xd4c60a57,0x804ef8b5,0xe0bf7977
.long	0xc06fece4,0x1a0dab28,0x94e7b49d,0xd405991e,0x706dab28,0xc542b6d2,0xa91618fb,0xcb228da3,0x107d1cea,0x224e4164,0xd0f5d8f1,0xeb9fdab3,0x0d6e41cd,0xc02ba386,0x9b1f7146,0x676a72c5
.long	0x4d6cb00b,0xffd6dd98,0xde2e8d7c,0xcef9c5ca,0x641c7936,0xa1bbf5d7,0xee8f772e,0x1b95b230,0xe8ac25b1,0xf765a92e,0x3a18b7c6,0xceb04cfc,0x0acc8966,0x27944cef,0x434c1004,0xcbb3c957
.long	0xa43ff93c,0x9c9971a1,0xa1e358a9,0x5bc2db17,0xa8d9bc82,0x45b4862e,0x2201e052,0x70ebfbfb,0x92871591,0xafdf64c7,0xb42d0219,0xea5bcae6,0x2ad8f03c,0xde536c55,0xa76aa33c,0xcd6c3f4d
.long	0x0bca6de3,0xbeb5f623,0xb1e706fd,0xdd20dd99,0xac9059d4,0x90b3ff9d,0x7ccccc4e,0x2d7b2902,0xce98840f,0x8a090a59,0x8410680a,0xa5d947e0,0x923379a5,0x49ae346a,0xb28a3156,0x7dbc84f9
.long	0x54a1aff2,0xfd40d916,0x3a78fb9b,0xabf318ba,0x3029f95e,0x50152ed8,0xc58ad7fa,0x9fc1dd77,0x13595c17,0x5fa57915,0x8f62b3a9,0xb9504668,0xff3055b0,0x907b5b24,0x9a84f125,0x2e995e35
.long	0x7e9bbcfb,0x87dacf69,0xe86d96e3,0x95d0c1d6,0x2d95a75c,0x65726e3c,0xacd27f21,0x2c3c9001,0x6c973f57,0x1deab561,0xa5221643,0x108b7e2c,0xc4ef79d4,0x5fee9859,0x40d4b8c6,0xbd62b88a
.long	0x197c75d6,0xb4dd29c4,0xb7076feb,0x266a6df2,0x4bf2df11,0x9512d0ea,0x6b0cc9ec,0x1320c24f,0x01a59596,0x6bb1e0e1,0xeff9aaac,0x8317c5bb,0x385aa6c9,0x65bb405e,0x8f07988f,0x613439c1
.long	0x16a66e91,0xd730049f,0xfa1b0e0d,0xe97f2820,0x304c28ea,0x4131e003,0x526bac62,0x820ab732,0x28714423,0xb2ac9ef9,0xadb10cb2,0x54ecfffa,0xf886a4cc,0x8781476e,0xdb2f8d49,0x4b2c87b5
.long	0x0a44295d,0xe857cd20,0x58c6b044,0x707d7d21,0xf596757c,0xae8521f9,0x67b2b714,0x87448f03,0x5ebcd58d,0x13a9bc45,0x9122d3c1,0x79bcced9,0x9e076642,0x3c644247,0x2df4767d,0x0cf22778
.long	0x71d444b6,0x5e61aee4,0xc5084a1d,0x211236bf,0x4fd3eaf6,0x7e15bc9a,0xab622bf5,0x68df2c34,0x59bf4f36,0x9e674f0f,0xd7f34d73,0xf883669b,0x31497b1d,0xc48ac1b8,0x5106703b,0x323b925d
.long	0x74082008,0x22156f42,0xc8482bcb,0xeffc521a,0x12173479,0x5c6831bf,0xc4739490,0xcaa2528f,0x8f1b3c4d,0x84d2102a,0x2d9bec0d,0xcf64dfc1,0x78a546ef,0x433febad,0x7b73cef1,0x1f621ec3
.long	0x37338615,0x6aecd627,0x01d8edf6,0x162082ab,0x19e86b66,0x833a8119,0xd299b5db,0x6023a251,0xbbf04b89,0xf5bb0c3a,0xae749a44,0x6735eb69,0x4713de3b,0xd0e058c5,0x2c3d4ccd,0xfdf2593e
.long	0xfdd23667,0x1b8f414e,0xfa2015ee,0xdd52aaca,0xbd9625ff,0x3e31b517,0x8db5918c,0x5ec9322d,0xa96f5294,0xbc73ac85,0x61a0666a,0x82aa5bf3,0xbf08ac42,0x49755810,0x891cedfc,0xd21cdfd5
.long	0x67f8be10,0x918cb57b,0x56ffa726,0x365d1a7c,0x6532de93,0x2435c504,0x2674cd02,0xc0fc5e10,0x9cbbb142,0x6e51fcf8,0xafc50692,0x1d436e5a,0x3fbcae22,0x766bffff,0xfd55d3b8,0x3148c2fd
.long	0x233222fa,0x52c7fdc9,0xe419fb6b,0x89ff1092,0x25254977,0x3cd6db99,0x1cf12ca7,0x2e85a161,0xdc810bc9,0xadd2547c,0x9d257c22,0xea3f458f,0x27d6b19b,0x642c1fbe,0x140481a6,0xed07e6b5
.long	0x86d2e0f8,0x6ada1d42,0x0e8a9fd5,0xe5920122,0x708c1b49,0x02c936af,0x2b4bfaff,0x60f30fee,0x858e6a61,0x6637ad06,0x3fd374d0,0xce4c7767,0x7188defb,0x39d54b2d,0xf56a6b66,0xa8c9d250
.long	0xb24fe1dc,0x58fc0f5e,0x6b73f24c,0x9eaf9dee,0x33650705,0xa90d588b,0xaf2ec729,0xde5b62c5,0xd3c2b36e,0x5c72cfae,0x034435da,0x868c19d5,0xe17ee145,0x88605f93,0x77a5d5b1,0xaa60c4ee
.long	0x3b60c472,0xbcf5bfd2,0xeb1d3049,0xaf4ef13c,0xe13895c9,0x373f44fc,0x0cbc9822,0xf29b382f,0x73efaef6,0x1bfcb853,0xa8c96f40,0xcf56ac9c,0x7a191e24,0xd7adf109,0xbf8a8dc2,0x98035f44
.long	0x1e750c84,0xf40a71b9,0x5dc6c469,0xc57f7b0c,0x6fbc19c1,0x49a0e79c,0xa48ebdb8,0x6b0f5889,0xa07c4e9f,0x5d3fd084,0xab27de14,0xc3830111,0x33e08dcc,0x0e4929fe,0x40bb73a3,0xf4a5ad24
.long	0x490f97ca,0xde86c2bf,0x67a1ce18,0x288f09c6,0x1844478d,0x364bb886,0xceedb040,0x7840fa42,0x5a631b37,0x1269fdd2,0xa47c8b7d,0x94761f1e,0x481c6266,0xfc0c2e17,0x3daa5fa7,0x85e16ea2
.long	0x92491048,0xccd86033,0xf4d402d7,0x0c2f6963,0xdf6a865c,0x6336f7df,0xb5c02a87,0x0a2a463c,0xbf2f12ee,0xb0e29be7,0x66bad988,0xf0a22002,0x9123c1d7,0x27f87e03,0x328a8c98,0x21669c55
.long	0x92f14529,0x186b9803,0x63954df3,0xd3d056cc,0x175a46f6,0x2f03fd58,0x11558558,0x63e34ebe,0x5b80cfa5,0xe13fedee,0xd401dbd1,0xe872a120,0xe8a9d667,0x52657616,0xe08d6693,0xbc8da4b6
.long	0x1b703e75,0x370fb9bb,0xd4338363,0x6773b186,0xecef7bff,0x18dad378,0x995677da,0xaac787ed,0x0437164b,0x4801ea8b,0x73fe795e,0xf430ad20,0x8ee5eb73,0xb164154d,0x108f7c0e,0x0884ecd8
.long	0x5f520698,0x0e6ec096,0x44f7b8d9,0x640631fe,0xa35a68b9,0x92fd34fc,0x4d40cf4e,0x9c5a4b66,0x80b6783d,0x949454bf,0x3a320a10,0x80e701fe,0x1a0a39b2,0x8d1a564a,0x320587db,0x1436d53d
.long	0x6556c362,0xf5096e6d,0xe2455d7e,0xbc23a3c0,0x807230f9,0x3a7aee54,0x22ae82fd,0x9ba1cfa6,0x99c5d706,0x833a057a,0x842315c9,0x8be85f4b,0x66a72f12,0xd083179a,0xcdcc73cd,0x2fc77d5d
.long	0x5616ee30,0x22b88a80,0xe7ab1083,0xfb09548f,0x511270cd,0x8ad6ab0d,0x6924d9ab,0x61f6c57a,0x90aecb08,0xa0f7bf72,0x0df784a4,0x849f87c9,0xcfaf1d03,0x27c79c15,0xc463face,0xbbf9f675
.long	0x765ba543,0x91502c65,0x42ea60dd,0x18ce3cac,0x6e43ecb3,0xe5cee6ac,0x68f2aeeb,0x63e4e910,0xc85932ee,0x26234fa3,0x4c90c44d,0x96883e8b,0xa18a50f6,0x29b9e738,0x3f0420df,0xbfc62b2a
.long	0x6d3e1fa9,0xd22a7d90,0xfe05b8a3,0x17115618,0xbb2b9c01,0x2a0c9926,0xe07e76a2,0xc739fcc6,0x165e439a,0x540e9157,0x6a9063d8,0x06353a62,0x61e927a3,0x84d95594,0xe2e0be7f,0x013b9b26
.long	0x973497f1,0x4feaec3b,0x093ebc2d,0x15c0f94e,0x33af0583,0x6af5f227,0xc61f3340,0x0c2af206,0x4457397c,0xd25dbdf1,0xcabcbae0,0x2e8ed017,0xc2815306,0xe3010938,0xe8c6cd68,0xbaa99337
.long	0x3b0ec7de,0x08513182,0x58df05df,0x1e1b822b,0xa5c3b683,0x5c14842f,0x3eba34ce,0x98fe977e,0x0d5e8873,0xfd2316c2,0xbd0d427d,0xe48d839a,0x623fc961,0x495b2218,0xb46fba5e,0x24ee56e7
.long	0x91e4de58,0x9184a55b,0xdfdea288,0xa7488ca5,0xa8dcc943,0xa723862e,0x849dc0fc,0x92d762b2,0x091ff4a9,0x3c444a12,0x0cada274,0x581113fa,0x30d8eae2,0xb9de0a45,0xdf6b41ea,0x5e0fcd85
.long	0xc094dbb5,0x6233ea68,0xd968d410,0xb77d062e,0x58b3002d,0x3e719bbc,0x3dc49d58,0x68e7dd3d,0x013a5e58,0x8d825740,0x3c9e3c1b,0x21311747,0x7c99b6ab,0x0cb0a2a7,0xc2f888f2,0x5c48a3b3
.long	0x991724f3,0xc7913e91,0x39cbd686,0x5eda799c,0x63d4fc1e,0xddb595c7,0xac4fed54,0x6b63b80b,0x7e5fb516,0x6ea0fc69,0xd0f1c964,0x737708ba,0x11a92ca5,0x9628745f,0x9a86967a,0x61f37958
.long	0xaa665072,0x9af39b2c,0xefd324ef,0x78322fa4,0xc327bd31,0x3d153394,0x3129dab0,0x81d5f271,0xf48027f5,0xc72e0c42,0x8536e717,0xaa40cdbc,0x2d369d0f,0xf45a657a,0xea7f74e6,0xb03bbfc4
.long	0x0d738ded,0x46a8c418,0xe0de5729,0x6f1a5bb0,0x8ba81675,0xf10230b9,0x112b33d4,0x32c6f30c,0xd8fffb62,0x7559129d,0xb459bf05,0x6a281b47,0xfa3b6776,0x77c1bd3a,0x7829973a,0x0709b380
.long	0xa3326505,0x8c26b232,0xee1d41bf,0x38d69272,0xffe32afa,0x0459453e,0x7cb3ea87,0xce8143ad,0x7e6ab666,0x932ec1fa,0x22286264,0x6cd2d230,0x6736f8ed,0x459a46fe,0x9eca85bb,0x50bf0d00
.long	0x877a21ec,0x0b825852,0x0f537a94,0x300414a7,0x21a9a6a2,0x3f1cba40,0x76943c00,0x50824eee,0xf83cba5d,0xa0dbfcec,0x93b4f3c0,0xf9538148,0x48f24dd7,0x61744162,0xe4fb09dd,0x5322d64d
.long	0x3d9325f3,0x57447384,0xf371cb84,0xa9bef2d0,0xa61e36c5,0x77d2188b,0xc602df72,0xbbd6a7d7,0x8f61bc0b,0xba3aa902,0x6ed0b6a1,0xf49085ed,0xae6e8298,0x8bc625d6,0xa2e9c01d,0x832b0b1d
.long	0xf1f0ced1,0xa337c447,0x9492dd2b,0x800cc793,0xbea08efa,0x4b93151d,0xde0a741e,0x820cf3f8,0x1c0f7d13,0xff1982dc,0x84dde6ca,0xef921960,0x45f96ee3,0x1ad7d972,0x29dea0c7,0x319c8dbe
.long	0x7b82b99b,0xd3ea3871,0x470eb624,0x75922d4d,0x3b95d466,0x8f66ec54,0xbee1e346,0x66e673cc,0xb5f2b89a,0x6afe67c4,0x290e5cd3,0x3de9c1e6,0x310a2ada,0x8c278bb6,0x0bdb323b,0x420fa384
.long	0x0eb919b0,0x0ae1d63b,0xa74b9620,0xd74ee51d,0xa674290c,0x395458d0,0x4620a510,0x324c930f,0xfbac27d4,0x2d1f4d19,0x9bedeeac,0x4086e8ca,0x9b679ab8,0x0cdd211b,0x7090fec4,0x5970167d
.long	0xfaf1fc63,0x3420f2c9,0x328c8bb4,0x616d333a,0x57f1fe4a,0x7d65364c,0x55e5c73a,0x9343e877,0xe970e78c,0x5795176b,0x60533627,0xa36ccebf,0x09cdfc1b,0xfc7c7380,0xb3fec326,0xb39a2afe
.long	0x6224408a,0xb7ff1ba1,0x247cfc5e,0xcc856e92,0xc18bc493,0x01f102e7,0x2091c727,0x4613ab74,0xc420bf2b,0xaa25e89c,0x90337ec2,0x00a53176,0x7d025fc7,0xd2be9f43,0x6e6fe3dc,0x3316fb85
.long	0x9ac50814,0x27520af5,0x9a8e4223,0xfdf95e78,0x56bec5a0,0xb7e7df2a,0xdf159e5d,0xf7022f7d,0xcac1fe8f,0x93eeeab1,0x37451168,0x8040188c,0xd967dce6,0x7ee8aa8a,0x3abc9299,0xfa0e79e7
.long	0x2064cfd1,0x67332cfc,0xb0651934,0x339c31de,0x2a3bcbea,0x719b28d5,0x9d6ae5c6,0xee74c82b,0xbaf28ee6,0x0927d05e,0x9d719028,0x82cecf2c,0xddb30289,0x0b0d353e,0xfddb2e29,0xfe4bb977
.long	0x640bfd9e,0xbb5bb990,0x82f62108,0xd226e277,0x02ffdd56,0x4bf00985,0x2ca1b1b5,0x7756758a,0x5285fe91,0xc32b62a3,0x8c9cd140,0xedbc546a,0xaf5cb008,0x1e47a013,0x073ce8f2,0xbca7e720
.long	0x17a91cae,0xe10b2ab8,0x08e27f63,0xb89aab65,0xdba3ddf9,0x7b3074a7,0x330c2972,0x1c20ce09,0x5fcf7e33,0x6b9917b4,0x945ceb42,0xe6793743,0x5c633d19,0x18fc2215,0xc7485474,0xad1adb3c
.long	0x6424c49b,0x646f9679,0x67c241c9,0xf888dfe8,0x24f68b49,0xe12d4b93,0xa571df20,0x9a6b62d8,0x179483cb,0x81b4b26d,0x9511fae2,0x666f9632,0xd53aa51f,0xd281b3e4,0x7f3dbd16,0x7f96a765
.long	0x074a30ce,0xa7f8b5bf,0x005a32e6,0xd7f52107,0x50237ed4,0x6f9e0907,0x8096fa2b,0x2f21da47,0xeec863a0,0xf3e19cb4,0x9527620a,0xd18f77fd,0x407c1cf8,0x9505c81c,0x1b6ec284,0x9998db4e
.long	0xc247d44d,0x7e3389e5,0x3f4f3d80,0x12507141,0x4a78a6c7,0xd4ba0110,0x767720be,0x312874a0,0x75944370,0xded059a6,0x3b2c0bdd,0xd6123d90,0x51c108e3,0xa56b717b,0x070623e9,0x9bb7940e
.long	0x84ac066c,0x794e2d59,0xe68c69a0,0xf5954a92,0x4fd99dcc,0x28c52458,0xb1012517,0x60e639fc,0x7de79248,0xc2e60125,0xf12fc6d7,0xe9ef6404,0x2a3b5d32,0x4c4f2808,0xc768eb8a,0x865ad32e
.long	0x13fb70b6,0xac02331b,0x95599b27,0x037b44c1,0x60bd082c,0x1a860fc4,0xc980cd01,0xa2e25745,0x1da0263e,0xee3387a8,0x2d10f3d6,0x931bfb95,0xa1f24a32,0x5b687270,0xca494b86,0xf140e65d
.long	0xb2f1ac7a,0x4f4ddf91,0x760fee27,0xf99eaabb,0x49c228e5,0x57f4008a,0x1cf713bb,0x090be440,0x5004f022,0xac91fbe4,0x569e1af6,0xd838c2c2,0x0f1daaa5,0xd6c7d20b,0x1bbb02c0,0xaa063ac1
.long	0x59558a78,0x0938a422,0x8435da2f,0x5343c669,0x034410dc,0x96f67b18,0x84510804,0x7cc1e424,0x16dfbb7d,0x86a1543f,0x5b5bd592,0x921fa942,0xb33dd03c,0x9dcccb6e,0xb843f51e,0x8581ddd9
.long	0x81d73c9e,0x54935fcb,0x0a5e97ab,0x6d07e979,0xcf3a6bab,0x4dc7b30a,0x170bee11,0x147ab1f3,0x9fafdee4,0x0aaf8e3d,0x538a8b95,0xfab3dbcb,0x6ef13871,0x405df4b3,0x088d5a49,0xf1f4e9cb
.long	0x66b33f1d,0x9bcd24d3,0x5ce445c0,0x3b97b820,0xba93ff61,0xe2926549,0x4dafe616,0xd9c341ce,0x16efb6f3,0xfb30a76e,0x605b953c,0xdf24b8ca,0xc2fffb9f,0x8bd52afe,0xe19d0b96,0xbbac5ff7
.long	0x459afccd,0x43c01b87,0xb7432652,0x6bd45143,0x55b5d78e,0x84734530,0x1554ba7d,0x81088fdb,0x1e269375,0xada0a52c,0x2dc5ec10,0xf9f037c4,0x94bfbc11,0xc0660607,0xc9c40d2f,0xc0a630bb
.long	0xab64c31e,0x5efc797e,0x74507144,0xffdb1dab,0x1ca6790c,0xf6124287,0xe69bf1bf,0xe9609d81,0x00d24fc9,0xdb898595,0xe51fb417,0x9c750333,0xfef7bbde,0x51830a91,0x945f585c,0x0ce67dc8
.long	0x4763eb50,0x9a730ed4,0xc1ab0d66,0x24a0e221,0x648748f3,0x643b6393,0x6d3c6291,0x1982daa1,0x8bbc5549,0x6f00a9f7,0x7f36384e,0x7a1783e1,0xde977f50,0xe8346323,0xb245502a,0x91ab688d
.long	0x6d0bdd66,0x331ab6b5,0x64b71229,0x0a6ef32e,0xfe7c352f,0x1028150e,0xce7b39d3,0x27e04350,0xc1070c82,0x2a3c8acd,0x80c9feef,0xfb2034d3,0x709f3729,0x2d729621,0x62cb4549,0x8df290bf
.long	0xfc2e4326,0x02f99f33,0x5eddf032,0x3b30076d,0x0c652fb5,0xbb21f8cf,0xed91cf7b,0x314fb49e,0x2f700750,0xa013eca5,0x712a4575,0x2b9e3c23,0xaf30fbb0,0xe5355557,0x7c77e771,0x1ada3516
.long	0x7b135670,0x45f6ecb2,0x7cfc202e,0xe85d19df,0x58d1be9f,0x0f1b50c7,0xead2e344,0x5ebf2c0a,0xabc199c9,0x1531fe4e,0x56bab0ae,0xc7032592,0x6c1fec54,0x16ab2e48,0x04280188,0x0f87fda8
.long	0x609e4a74,0xdc9f46fc,0xba667f91,0x2a44a143,0xb4d83436,0xbc3d8b95,0xc7bd2958,0xa01e4bd0,0x73483c90,0x7b182932,0xa7c7b598,0xa79c6aa1,0xeaaac07e,0xbf3983c6,0x96e0d4e6,0x8f18181e
.long	0x051af62b,0x8553d37c,0x0bf94496,0xe9a998eb,0xb0d59aa1,0xe0844f9f,0xe6afb813,0x983fd558,0x65d69804,0x9670c0ca,0x6ea5ff2d,0x732b22de,0x5fd8623b,0xd7640ba9,0xa6351782,0x9f619163
.long	0xacee5043,0x0bfc27ee,0x2eb10f02,0xae419e73,0x8943fb05,0x19c028d1,0xff13aa2a,0x71f01cf7,0x8887a132,0x7790737e,0x66318410,0x67513309,0x7ddb795e,0x9819e8a3,0xdad100b2,0xfecb8ef5
.long	0x3021926a,0x59f74a22,0x6f9b4c1c,0xb7c28a49,0x912ad0ab,0xed1a733f,0x01a5659c,0x42a910af,0x7bd68cab,0x3842c6e0,0x76d70ac8,0x2b57fa38,0x3c53aaeb,0x8a6707a8,0x65b4db18,0x62c1c510
.long	0xb2d09dc7,0x8de2c1fb,0x266bd23b,0xc3dfed12,0xd5b27db6,0x927d039b,0x103243da,0x2fb2f0f1,0x80be7399,0xf855a07b,0x1f9f27a8,0xed9327ce,0x729bdef7,0xa0bd99c7,0x28250d88,0x2b67125e
.long	0x8670ced7,0x784b26e8,0xc31bd3b4,0xe3dfe41f,0xbcc85cbc,0x9e353a06,0x60178a9d,0x302e2909,0xa6eac16e,0x860abf11,0xaa2b3aac,0x76447000,0x850afdab,0x46ff9d19,0xfdb2d4c1,0x35bdd6a5
.long	0x7e5c9ce9,0xe82594b0,0x20af346e,0x0f379e53,0xbc65ad4a,0x608b31e3,0x267c4826,0x710c6b12,0x71954cf1,0x51c966f9,0x0d0aa215,0xb1cec793,0x86bd23a8,0x1f155989,0xf9452e86,0xae2ff99c
.long	0x340ceaa2,0xd8dd953c,0x2e2e9333,0x26355275,0x8586f06d,0x15d4e5f9,0xf7cab546,0xd6bf94a8,0xb76a9af0,0x33c59a0a,0xba095af7,0x52740ab3,0x24389ca0,0xc444de8a,0x706da0cb,0xcc6f9863
.long	0x6b2515cf,0xb5a741a7,0x9585c749,0x71c41601,0xe683de97,0x78350d4f,0x63d0b5f5,0x31d61524,0xfbce090b,0x7a0cc5e1,0xfbcb2a5b,0xaac927ed,0x20d84c35,0xe920de49,0x22b4de26,0x8c06a0b6
.long	0xafe7ddf3,0xd34dd58b,0xc1e6e55b,0x55851fed,0x960696e7,0xd1395616,0x5f22705f,0x940304b2,0xb0a2a860,0x6f43f861,0x0e7cc981,0xcf121282,0x0ab64a96,0x12186212,0xb789383c,0x09215b9a
.long	0x37387c09,0x311eb305,0xf03ee760,0xc5832fce,0x32f7ea19,0x30358f58,0x91d53551,0xe01d3c34,0xda48ea80,0x1ca5ee41,0xcf4fa4c1,0x34e71e8e,0x7af1e1c7,0x312abd25,0x2153f4a5,0xe3afcdeb
.long	0x00235e9a,0x9d5c84d7,0x8c4c836f,0x0308d3f4,0x89332de5,0xc0a66b04,0x89e566ef,0x610dd399,0xd1ac1635,0xf8eea460,0x20a2c0df,0x84cbb3fb,0xe74a48c5,0x40afb488,0xd326b150,0x29738198
.long	0xa6d74081,0x2a17747f,0x55a26214,0x60ea4c05,0x1f88c5fe,0x53514bb4,0x7e83426c,0xedd64567,0x96460b25,0xd5d6cbec,0x68dc115e,0xa12fd0ce,0x697840ea,0xc5bc3ed2,0xa6331e31,0x969876a8
.long	0x472ff580,0x60c36217,0x4ad41393,0xf4229705,0xa03b8b92,0x4bd99ef0,0xc144f4f6,0x501c7317,0x18464945,0x159009b3,0x74c5c6be,0x6d5e594c,0x321a3660,0x2d587011,0x3898d022,0xd1e184b1
.long	0x4c6a7e04,0x5ba04752,0x45550b65,0x47fa1e2b,0x48c0a9a5,0x9419daf0,0x7c243236,0x66362953,0x5cb12a88,0xcd0744b1,0x2b646188,0x561b6f9a,0x66c2c0c0,0x599415a5,0x0f83f09a,0xbe3f0859
.long	0xb92041b8,0x9141c5be,0x26477d0d,0x01ae38c7,0xd12c7a94,0xca8b71f3,0x765c70db,0xfab5b31f,0x487443e9,0x76ae7492,0x990d1349,0x8595a310,0x7d460a37,0xf8dbeda8,0x1e45a38f,0x7f7ad082
.long	0x1059705a,0xed1d4db6,0xe6b9c697,0xa3dd492a,0x6eb38bd5,0x4b92ee3a,0x67cc0bb7,0xbab2609d,0x6e70ee82,0x7fc4fe89,0x13e6b7e3,0xeff2c56e,0x34d26fca,0x9b18959e,0x889d6b45,0x2517ab66
.long	0xbdefdd4f,0xf167b4e0,0xf366e401,0x69958465,0xa73bbec0,0x5aa368ab,0x7b240c21,0x12148709,0x18969006,0x378c3233,0xe1fe53d1,0xcb4d73ce,0x130c4361,0x5f50a80e,0x7ef5212b,0xd67f5951
.long	0x9e70c72e,0xf145e21e,0x5566d2fb,0xb2e52e29,0x032397f5,0x44eaba4a,0x7e31a7de,0x5e56937b,0x456c61e1,0x68dcf517,0xa8b0a388,0xbc2e954a,0x60a8b755,0xe3552fa7,0x73ad0cde,0x03442dae
.long	0xceb26210,0x37ffe747,0x787baef9,0x983545e8,0x86a3de31,0x8b8c8535,0xfacd46db,0xc621dbcb,0x59266fbb,0x82e442e9,0x339d471c,0xa3514c37,0x62cdad96,0x3a11b771,0xecf9bdf0,0xf0cb3b3c
.long	0x478e2135,0x3fcbdbce,0xbda35342,0x7547b5cf,0x8a677af6,0xa97e81f1,0x28817987,0xc8c2bf83,0x45580985,0xdf07eaaf,0xc93b45cb,0xc68d1f05,0xc77b4cac,0x106aa2fe,0x04a7ae86,0x4c1d8afc
.long	0x9eb45ab2,0xdb41c3fd,0xd4b22e74,0x5b234b5b,0xf215958a,0xda253dec,0xa04edfa0,0x67e0606e,0xef751b11,0xabbbf070,0xf6f06dce,0xf352f175,0x6839f6b4,0xdfc4b6af,0x9959848e,0x53ddf9a8
.long	0xc21520b0,0xda49c379,0xdbd5d1b6,0x90864ff0,0x5f49c7f7,0x2f055d23,0xa796b2d8,0xe51e4e6a,0x5c9dc340,0xc361a67f,0xbca7c620,0x5ad53c37,0x32c756d0,0xda1d6588,0x8bb67e13,0xad60d911
.long	0x0eeec8c6,0xd6c47bdf,0x078a1821,0x4a27fec1,0xc3099524,0x081f7415,0x82cd8060,0x8effdf0b,0x65842df8,0xdb70ec1c,0xd319a901,0x8821b358,0xde42b529,0x72ee56ee,0x236e4286,0x5bb39592
.long	0xfd6f7140,0xd1183316,0xbd8e81f7,0xf9fadb5b,0x5a02d962,0x701d5e0c,0x1b601324,0xfdee4dbf,0x35d7620e,0xbed17407,0xf48c0012,0x04e3c2c3,0x3455449a,0x9ee29da7,0x91a836c4,0x562cdef4
.long	0x47701097,0x8f682a5f,0xff88d0c2,0x617125d8,0x57bb86dd,0x948fda24,0x289f7286,0x348abb8f,0x99d94bbd,0xeb10eab5,0x4684d160,0xd51ba28e,0x30c8f41a,0xabe0e51c,0x13254f4a,0x66588b45
.long	0xfad097a5,0x147ebf01,0x610e815d,0x49883ea8,0x8a11de56,0xe44d60ba,0x827a7a6d,0xa970de6e,0x5e17fc19,0x2be41424,0x01214057,0xd833c657,0x363e723f,0x1375813b,0xe6a52e9b,0x6820bb88
.long	0xd875d56a,0x7e7f6970,0x51fbf6bf,0xd6a0a9ac,0xa3083c12,0x54ba8790,0x6ae7eb64,0xebaeb23d,0xb99a907a,0xa8685c3a,0x026bf40b,0xf1e74550,0xc802cd9e,0x7b73a027,0x4fef4635,0x9a8a927c
.long	0x08191224,0xe1b6f60c,0xde4ec091,0xc4126ebb,0x4ae38d84,0xe1dff4dc,0x4f2ef985,0xde3f57db,0xd446a1dd,0x34964337,0x859e77f6,0x7bf217a0,0x8e1d13f5,0x8ff10527,0x74eeae27,0xa304ef03
.long	0xd19dfa5a,0xfc6f5e47,0x7fad982b,0xdb007de3,0x613715f5,0x28205ad1,0x7889529e,0x251e6729,0x1ae98e78,0x72705184,0x271cac32,0xf818537d,0xb7f410f5,0xc8a15b7e,0x81f62393,0xc474356f
.long	0xc242316b,0x92dbdc5a,0xdbf4aff5,0xabe060ac,0x909a8ec6,0x6e8c38fe,0x6116cb94,0x43e514e5,0x07d784f9,0x2078fa38,0xf4b5b357,0x1161a880,0x13adea3d,0x5283ce79,0xcc6a910b,0x0756c3e6
.long	0xaaa79697,0x60bcfe01,0x56391db1,0x04a73b29,0x189b45a0,0xdd8dad47,0x48d5b8d9,0xbfac0dd0,0x7d3d2ec2,0x34ab3af5,0x207bd3af,0x6fa2fc2d,0x66550ded,0x9ff40092,0x1fd5b913,0x719b3e87
.long	0x6d17fbc7,0xa573a496,0x73d2b24e,0x0cd1a70a,0xb2676937,0x34e2c5ca,0xbf669f21,0xe7050b06,0x1ede9046,0xfbe948b6,0x97662659,0xa0530051,0xf10124c5,0x58cbd4ed,0xdd6c06c8,0xde2646e4
.long	0x8cad38c0,0x332f8108,0x6bd68ae2,0x471b7e90,0x0d8e27a3,0x56ac3fb2,0x136b4b0d,0xb54660db,0xa6fd8de4,0x123a1e11,0xa37799ef,0x44dbffea,0xce6ac17c,0x4540b977,0xaf60acef,0x495173a8
.long	0x391c2a82,0x9ebb284d,0x158308e8,0xbcdd4863,0x83f1edca,0x006f16ec,0x695dc6c8,0xa13e2c37,0x4a057a87,0x2ab756f0,0xa6b48f98,0xa8765500,0x68651c44,0x4252face,0xe1765e02,0xa52b540b
.long	0x16a0d2bb,0x4f922fc5,0x1a623499,0x0d5cc16c,0x57c62c8b,0x9241cf3a,0xfd1b667f,0x2f5e6961,0xf5a01797,0x5c15c70b,0x60956192,0x3d20b44d,0x071fdb52,0x04911b37,0x8d6f0f7b,0xf648f916
.long	0xe60b7cf7,0x6dc1acaf,0x84a9d869,0x25860a50,0xe7ba8ac4,0x56fc6f09,0x6148d29e,0x828c5bd0,0xdc55ae5f,0xac6b435e,0xc0117411,0xa527f56c,0xfd24342c,0x94d5045e,0x70b67c0d,0x2c4c0a35
.long	0xfac61d9a,0x027cc8b8,0xe3c6fe8a,0x7d25e062,0xe5bff503,0xe08805bf,0x6ff632f7,0x13271e6c,0x232f76a5,0x55dca6c0,0x701ef426,0x8957c32d,0xa10a5178,0xee728bcb,0xb62c5173,0x5ea60411
.long	0xd0b8892b,0xfc4e964e,0x9301bb74,0x9ea17683,0xfcc48626,0x6265c5ae,0xbb3e9102,0xe60cf82e,0xd4df5531,0x57adf797,0x8deeefe2,0x235b59a1,0x3f306eb1,0x60adcf58,0x3d09492d,0x105c2753
.long	0xb5def996,0x4090914b,0x233dd1e7,0x1cb69c83,0x9b3d5e76,0xc1e9c1d3,0xfccf6012,0x1f3338ed,0x2f5378a8,0xb1e95d0d,0x2f00cd21,0xacf4c2c7,0xeb5fe290,0x6e984240,0x248088ae,0xd66c038d
.long	0xf94d70cf,0x804d264a,0x7314bf7e,0xbdb802ef,0x4333ed02,0x8fb54de2,0x285635d9,0x740461e0,0x365e9383,0x4113b2c8,0x3fdef652,0xea762c83,0x47b956c1,0x4eec6e2e,0x65620fa4,0xa3d814be
.long	0xb4d8bc50,0x9ad5462b,0xa9195770,0x181c0b16,0x78412a68,0xebd4fe1c,0xc0dff48c,0xae0341bc,0x7003e866,0xb6bc45cf,0x8a24a41b,0xf11a6dea,0xd04c24c2,0x5407151a,0xda5b7b68,0x62c9d27d
.long	0x88cceff6,0x2e964235,0x8b07ed69,0x8594c54f,0xc84d0d0d,0x1578e73c,0xff532868,0x7b4e1055,0xb5ec995a,0xa348c0d5,0x14289a54,0xbf4b9d55,0x58fbd777,0x9ba155a6,0x1a84491d,0x186ed7a8
.long	0x614c0900,0xd4992b30,0xbd00c24b,0xda98d121,0x7ec4bfa1,0x7f534dc8,0x37dc34bc,0x4a5ff674,0x1d7ea1d7,0x68c196b8,0x80a6d208,0x38cf2893,0xe3cbbd6e,0xfd56cd09,0x4205a5b6,0xec72e27e
.long	0xa44f77f7,0x15ea68f5,0xb43c52bc,0x7aa5f9fd,0x94f0e609,0x86ff676f,0x2e2d432b,0xa4cde963,0xeee470af,0x8cafa0c0,0x8a3f5ec8,0x84137d0e,0xfaa31231,0xebb40411,0x6f7f7ccf,0xa239c13f
.long	0xa8afd30b,0x32865719,0x8a826dce,0x86798328,0xc4a8fbe0,0xdf04e891,0xebf56ad3,0xbb6b6e1b,0x471f1ff0,0x0a695b11,0xbe15baf0,0xd76c3389,0xbe96c43e,0x018edb95,0x90794158,0xf2beaaf4
.long	0xc3076a27,0x152db09e,0xe416545d,0x5e82908e,0x356d6f2e,0xa2c41272,0x31fd74e1,0xdc9c9642,0x519bf615,0x66ceb88d,0x05a2274e,0xe29ecd76,0xbf5e2fa0,0x3a0473c4,0x64284e67,0x6b6eb671
.long	0xb88756dd,0xe8b97932,0xf17e3e61,0xed4e8652,0x3ee1c4a4,0xc2dd1499,0x597f8c0e,0xc0aaee17,0x6c168af3,0x15c4edb9,0xb39ae875,0x6563c7bf,0x20adb436,0xadfadb6f,0x9a042ac0,0xad55e8c9
.long	0xb76da1f5,0x975a1ed8,0xa58acb94,0x10dfa466,0xac060282,0x8dd7f7e3,0x572a051e,0x6813e66a,0x350cb901,0xb4ccae1e,0x50cb7822,0xb653d656,0xdfab3b87,0x42484710,0x9b670fd0,0xcd7ee537
.long	0x523b8bf6,0x0a50b12e,0x8f910c1b,0x8009eb5b,0x4a167588,0xf535af82,0xfb2a2abd,0x0f835f9c,0x2afceb62,0xf59b2931,0x169d383f,0xc797df2a,0x66ac02b0,0xeb3f5fb0,0xdaa2d0ca,0x029d4c6f
.long	0xafab4bc5,0xd4059bc1,0x56783247,0x833f5c6f,0x8d2d3605,0xb5346630,0xd34d8433,0x83387891,0xadd9419a,0xd973b30f,0xafe3fce8,0xbcca1099,0x0809aac6,0x08178315,0x540f0f11,0x01b7f21a
.long	0x909523c8,0x65c29219,0xa3a1c741,0xa62f648f,0x60c9e55a,0x88598d4f,0x0e4f347a,0xbce9141b,0x35f9b988,0x9af97d84,0x320475b6,0x0210da62,0x9191476c,0x3c076e22,0x44fc7834,0x7520dbd9
.long	0xc1ab1bbd,0x6a6b2cfe,0xdc650938,0xef8a65be,0x805d7bc4,0x72855540,0xed11fdfd,0xda389396,0x74660876,0xa9d5bd36,0xb45dff35,0x11d67c54,0xa4f5da94,0x6af7d148,0xc0bbeb31,0xbb8d4c3f
.long	0xe0a1b12a,0x87a7ebd1,0x770ba95f,0x1e4ef88d,0xdc2ae9cb,0x8c33345c,0x01cc8403,0xcecf1276,0x1b39b80f,0x687c012e,0x35c33ba4,0xfd90d0ad,0x5c9661c2,0xa3ef5a67,0xe017429e,0x368fc88e
.long	0x196a2fa2,0xd30c6761,0xbd5b312e,0x931b9817,0x72f54a31,0xba01000c,0x66eaa541,0xa203d2c8,0x98939db3,0xf2abdee0,0x3e606c02,0xe37d6c2c,0x521ff643,0xf2921574,0xd7e2fca3,0x2781b3c4
.long	0x7850ec06,0x664300b0,0x7d3a10cf,0xac5a38b9,0xe34ab39d,0x9233188d,0x5072cbb9,0xe77057e4,0xb59e78df,0xbcf0c042,0x1d97de52,0x4cfc91e8,0x3ee0ca4a,0x4661a26c,0xfb8507bc,0x5620a4c1
.long	0x049f842c,0x4b44d4aa,0x1540e82b,0xceabc5d5,0x15c6f156,0x306710fd,0x63db1d72,0xbe5ae52b,0x334957f1,0x06f1e7e6,0x31144a70,0x57e388f0,0xdf96447b,0xfb69bb2f,0x73e38a12,0x0f78ebd3
.long	0x2b7ce542,0xb8222605,0x7472bde1,0xe6d4ce99,0x09d2f4da,0x53e16ebe,0x53b92b2e,0x180ff42e,0x2c34a1c6,0xc59bcc02,0x422c46c2,0x3803d6f9,0x5c14a8a2,0x18aff74f,0x10a08b28,0x55aebf80
.long	0x7135593f,0x66097d58,0x2be570cd,0x32e6eff7,0x2a8c860d,0x584e6a10,0xa2eb4163,0xcd185890,0x6d97e134,0x7ceae99d,0xdd8447ce,0xd42c6b70,0xb8c50273,0x59ddbb4a,0x3cf34e1e,0x03c612df
.long	0x04b6c5a0,0x84b9ca15,0x18f0e3a3,0x35216f39,0xbd986c00,0x3ec2d2bc,0xd19228fe,0x8bf546d9,0x4cd623c3,0xd1c655a4,0x502b8e5a,0x366ce718,0xeea0bfe7,0x2cfc84b4,0xcf443e8e,0xe01d5cee
.long	0x036520f8,0x8ec045d9,0x92d40e98,0xdfb3c3d1,0xcc559a04,0x0bac4cce,0x240ea6b1,0x35eccae5,0xf8a5a0ac,0x180b32db,0xeb699700,0x547972a5,0xca26bca0,0xa3765801,0xa647f25a,0x57e09d0e
.long	0x2fdd23cc,0xb956970e,0x5682e971,0xb80288bc,0x9ae86ebc,0xe6e6d91e,0x8c9f1939,0x0564c83f,0x39560368,0x551932a2,0x049c28e2,0xe893752b,0xa6a158c3,0x0b03cee5,0x04964263,0xe12d656b
.long	0x63e3bc1d,0x4b47554e,0x45044ff7,0xc719b6a2,0xe48daa07,0x4f24d30a,0xc8c1edc3,0xa3f37556,0x0700d360,0x9a47bf76,0x822ae4e2,0xbb1a1824,0x89f1fb4c,0x22e275a3,0x9968c5f5,0x72b1aa23
.long	0xbe063f64,0xa75feaca,0xbce47a09,0x9b392f43,0x1ad07aca,0xd4241509,0x8d26cd0f,0x4b0c591b,0x92f1169a,0x2d42ddfd,0x4cbf2392,0x63aeb1ac,0x0691a2af,0x1de9e877,0xd98021da,0xebe79af7
.long	0x40e50acf,0xcfdf2a4e,0xaf01d665,0xf0a98ad7,0x1831be1f,0xefb640bf,0x80e9ada0,0x6fe8bd2f,0x6cafbc91,0x94c103a1,0x8308e08c,0x170f8759,0x9780ff4f,0x5de2d2ab,0x45b201f2,0x666466bc
.long	0xf5b343bc,0x58af2010,0xf2f142fe,0x0f2e400a,0xa85f4bdf,0x3483bfde,0x03bfeaa9,0xf0b1d093,0xc7081603,0x2ea01b95,0x3dba1097,0xe943e4c9,0xb438f3a6,0x47be92ad,0xe5bf6636,0x00bb7742
.long	0x824297b4,0x136b7083,0x5584455f,0x9d0e5580,0xf1c7d69e,0xab48cedc,0x2a256e76,0x53a9e481,0x65eb2413,0x0402b0e0,0x8fc407a7,0xdadbbb84,0x8d7f5492,0xa65cd5a4,0x74bae294,0x21d44293
.long	0x3b5f1cc4,0x66917ce6,0xce872e62,0x37ae52ea,0x2905f244,0xbb087b72,0x1e6af74f,0x12077086,0x1058edea,0x4b644e49,0xb638ca1d,0x827510e3,0x6038591c,0x8cf2b704,0xfe635063,0xffc8b47a
.long	0x1b4d5e63,0x3ae220e6,0x9d961b4b,0xbd864742,0x9bd16bed,0x610c107e,0x1127147b,0x4270352a,0x64cfc50e,0x7d17ffe6,0x1e36cb42,0x50dee01a,0x35dc5f9a,0x068a7622,0xdf53f62c,0x9a08d536
.long	0x6be5f7de,0x4ed71457,0xc2263c9e,0xd93006f8,0xcacacb36,0xe073694c,0x3ae118ab,0x2ff7a5b4,0xcd871236,0x3cce53f1,0xc2aa6d52,0xf156a39d,0xb198d76d,0x9cc5f271,0x81383d39,0xbc615b6f
.long	0xde3eee6b,0xa54538e8,0xab910d91,0x58c77538,0x58d278bd,0x31e5bdbc,0xb963acae,0x3cde4adf,0x5302169c,0xb1881fd2,0xa989ed8b,0x8ca60fa0,0xff96a0ee,0xa1999458,0xac6c283d,0xc1141f03
.long	0x6dfafed3,0x7677408d,0x39661588,0x33a01653,0x0b726fa0,0x3c9c15ec,0x6c9b56da,0x090cfd93,0xa3c40af5,0xe34f4bae,0xd21129f1,0x3469eadb,0x1e207ce8,0xcc51674a,0xc83b1ef9,0x1e293b24
.long	0x1e6c0bb4,0x17173d13,0x90776d35,0x19004695,0x6de6f922,0xe7980e34,0xf4dd9a22,0x873554cb,0xcbf18a51,0x0316c627,0x3032c081,0x4d93651b,0x3946834d,0x207f2771,0x30cdbf80,0x2c08d7b4
.long	0x86df2a61,0x137a4fb4,0xecf7b4a2,0xa1ed9c07,0x7bd042ff,0xb2e460e2,0x5f62f5ec,0xb7f5e2fa,0xcc2423b7,0x7aa6ec6b,0xba63eea7,0x75ce0a7f,0xf250a6e1,0x67a45fb1,0xe53cdc9f,0x93bc919c
.long	0x871942df,0x9271f56f,0x7859ad66,0x2372ff6f,0x33cb1a78,0x5f4c2b96,0x5838aa83,0xe3e29101,0xe4e8110c,0xa7ed1611,0x330198ce,0x2a2d70d5,0x6720efe0,0xbdf132e8,0x66a471bf,0xe61a8962
.long	0x825808bd,0x796d3a85,0x3fd6e902,0x51dc3cb7,0x916219d1,0x643c768a,0xa2ad7d32,0x36cd7685,0xb22922a4,0xe3db9d05,0xdba29660,0x6494c87e,0xbcd2ebc7,0xf0ac91df,0x45107f8d,0x4deb57a0
.long	0xc3d12a73,0x42271f59,0xa5c2c51d,0x5f71687c,0x05797bcb,0xcb1f50c6,0xd6d34eb0,0x29ed0ed9,0x4683c2eb,0xe5fe5b47,0x97447c46,0x4956eeb5,0x71207167,0x5b163a43,0x0248c5ef,0x93fa2fed
.long	0x31f63950,0x67930af2,0x14caa2c9,0xa77797c1,0x27ac7e62,0x526e80ee,0x58b28aec,0xe1e6e626,0xb3c9fef0,0x636178b0,0x6d5f90be,0xaf7752e0,0xeece51cf,0x94ecaf18,0xca806e1f,0x2864d0ed
.long	0x97c69134,0x6de2e383,0xeb291293,0x5a42c316,0x6a60bae0,0xc7779219,0x6b7599d1,0xa24de346,0xb75d4941,0x49d374aa,0x2d501ff0,0x98900586,0xeb7974cf,0x9f16d40e,0xcdd8c115,0x1033860b
.long	0x2094cec3,0xb6c69ac8,0x403b770c,0x9976fb88,0x4859590d,0x1dea026c,0x8562d1fd,0xb6acbb46,0x44569d85,0x7cd6c461,0x97f0891d,0xc3190a36,0x48d5a17d,0xc6f53195,0xd749abc8,0x7d919966
.long	0xdd1c8a20,0x65104837,0x2f683419,0x7e5410c8,0xbe94022e,0x958c3ca8,0x6145dac2,0x605c3197,0x01683d54,0x3fc07501,0x595b1234,0x1d7127c5,0x9481277f,0x10b8f87c,0xe65a1adb,0x677db2a8
.long	0xddce3345,0xec2fccaa,0x012a4350,0x2a6811b7,0xac598bdc,0x96760ff1,0xd1bf4128,0x054d652a,0x92a21005,0x0a1151d4,0x33110fdf,0xad7f3971,0x1960100f,0x8c95928c,0x7bf03362,0x6c91c825
.long	0xce309f06,0xc8c8b2a2,0xca27204b,0xfdb27b59,0x0848e32e,0xd223eaa5,0xe7bfaf1e,0xb93e4b2e,0x44aa3ded,0xc5308ae6,0xc015d573,0x317a666a,0x1a979707,0xc888ce23,0x0d5c4958,0xf141c1e6
.long	0x61906373,0xb53b7de5,0xeb999595,0x858dbade,0xa59e5c36,0x8cbb47b2,0xdcf4e842,0x660318b3,0x12ba4b7a,0xbd161ccd,0xf8c8282a,0xf399daab,0xeeb2130d,0x1587633a,0xda38dd7d,0xa465311a
.long	0x64d3779b,0x5f75eec8,0xad64c171,0x3c5d0476,0x2a914428,0x87410371,0x90e2fc29,0x8096a891,0x23b3ebc2,0xd3d2ae9d,0xa580cfd6,0x90bdd6db,0xc5b01f6c,0x52dbb7f3,0xe102a2dc,0xe68eded4
.long	0x99eb6df0,0x17785b77,0x7386b779,0x26c3cc51,0x6417a48e,0x345ed988,0x07d6ef31,0xe990b4e4,0x2586abba,0x0f456b7e,0x59c96e9a,0x239ca6a5,0xe2eb4206,0xe327459c,0xa002b90a,0x3a4c3313
.long	0xf6a3f6fb,0x2a114806,0x85c251dd,0xad5cad2f,0xf5a784d3,0x92c1f613,0x349766d5,0xec7bfacf,0x3e23cb3b,0x04b3cd33,0xc5a64b2d,0x3979fe84,0x7e589106,0x192e2720,0xa15b527f,0xa60c43d1
.long	0xbe7cf3a6,0x2dae9082,0xbc967274,0xcc86ba92,0xaea0a8a9,0xf28a2ce8,0x6ee988b3,0x404ca6d9,0x005921b8,0xfd7e9c5d,0x44e79bf9,0xf56297f1,0x0d75ddc2,0xa163b460,0xa1f2be87,0x30b23616
.long	0xbfe50e2b,0x4b070d21,0xe1bfede1,0x7ef8cfd0,0x2aac4ae0,0xadba0011,0xb9ebd033,0x2a3e7d01,0xe38d9d1c,0x995277ec,0x9c5d2de3,0xb500249e,0xf13ca8c9,0x8912b820,0x877793af,0xc8798114
.long	0xec3f1dec,0x19e6125d,0x911178da,0x07b1f040,0x904a6738,0xd93ededa,0x0bebedcd,0x55187a5a,0xeb329d41,0xf7d04722,0xf170b391,0xf449099e,0xca99f828,0xfd317a69,0x34a4976d,0x50c3db2b
.long	0x3757b392,0xe9ba7784,0xaa3ca05a,0x326caefd,0xf1e593d4,0x78e5293b,0x0d98fd13,0x7842a937,0x5f96b10d,0xe694bf96,0x06a8cd05,0x373a9df6,0xe8f0c7fc,0x997d1e51,0x63fd972e,0x1d019790
.long	0x5499fb32,0x0064d858,0x77a8aeb7,0x7b67bad9,0x2d08eec5,0x1d3eb977,0xcbabae1d,0x5fc047a6,0xe54a64bb,0x0577d159,0xc43497e4,0x8862201b,0x2ce0608d,0xad6b4e28,0x0b167aac,0x8b687b7d
.long	0x8b2ecfa9,0x6ed4d367,0xa90c3c38,0x24dfe62d,0x3fe5c42b,0xa1862e10,0xd5732a9f,0x1ca73dca,0x76bb87ad,0x35f038b7,0xf242b81f,0x674976ab,0xb0fd90cd,0x4f2bde7e,0xa7fdf092,0x6efc172e
.long	0x92222f1f,0x3806b69b,0x6cf7ae70,0x5a2459ca,0xa85217ee,0x6789f69c,0xe3dc85ac,0x5f232b5e,0x48e9e516,0x660e3ec5,0x3197eb31,0x124b4e47,0xaafcca23,0x10a0cb13,0x8213224f,0x7bd63ba4
.long	0x290a7f4f,0xaffad7cc,0x0286b461,0x6b409c9e,0xffa407af,0x58ab809f,0xc68ac073,0xc3122eed,0x4ef24d7e,0x17bf9e50,0x3e2a5811,0x5d929794,0x02902e01,0x519bc867,0x39c8a851,0x76bba5da
.long	0xda94951e,0xe9f9669c,0x66b8d418,0x4b6af58d,0x17d426a4,0xfa321074,0x9dde6027,0xc78e66a9,0x4a53b964,0x0516c083,0xff602330,0xfc659d38,0x58c5c897,0x0ab55e5c,0x838bc5df,0x985099b2
.long	0xc52fc238,0x061d9efc,0x6ac1da3f,0x712b2728,0x9283fe08,0xfb658149,0xb8aaa2f7,0x4954ac94,0x7fb2e74f,0x85c0ada4,0xb89926b0,0xee8ba98e,0x23d1af5b,0xe4f9d37d,0xba9b015e,0x14ccdbf9
.long	0x7bfe7178,0xb674481b,0x65405868,0x4e1debae,0xc48c867d,0x061b2821,0x513b30ea,0x69c15b35,0x36871088,0x3b4a1666,0x1220b1ff,0xe5e29f5d,0x233d9f4d,0x4b82bb35,0x18cdc675,0x4e076333
.long	0xa3e6fced,0x0d53f5c7,0xf45fbdeb,0xe8cbbdd5,0x13339a70,0xf85c01df,0x142ceb81,0x0ff71880,0xbd70437a,0x4c4e8774,0xba0bda6a,0x5fb32891,0xf18bd26e,0x1cdbebd2,0x03a9d522,0x2f9526f1
.long	0x92c4d684,0x40ce3051,0x7612efcd,0x8b04d725,0x6f9cae20,0xb9dcda36,0xf058856c,0x0edc4d24,0x85427900,0x64f2e6bf,0xdc09dfea,0x3de81295,0x379bf26c,0xd41b4487,0x6df135a9,0x50b62c6d
.long	0xc72dfe67,0xd4f8e3b4,0x90e19fdf,0xc416b0f6,0x4c13bd35,0x18b9098d,0x15b8cb9e,0xac11118a,0xf0062841,0xf598a318,0x89f356f4,0xbfe0602f,0x30177a0c,0x7ae3637e,0x61136537,0x34097747
.long	0xd005832a,0x0db2fb5e,0x91042e4f,0x5f5efd3b,0xed70f8ca,0x8c4ffdc6,0xb52da9cc,0xe4645d0b,0xc9001d1f,0x9596f58b,0x4e117205,0x52c8f0bc,0xe398a084,0xfd4aa0d2,0x104f49de,0x815bfe3a
.long	0x23885e5f,0x97e5443f,0xe8433aab,0xf72f8f99,0xe4d4e604,0xbd00b154,0xe5e173ff,0xd0b35e6a,0x9164722d,0x57b2a048,0x88761ec8,0x3e3c665b,0x3da83832,0x6bdd1397,0x73dafe3b,0x3c8b1a1e
.long	0x54317cac,0x4497ace6,0x521771b3,0xbe600ab9,0xb0dfe8b8,0xb42e409e,0x3942310f,0x386a67d7,0x4431cc28,0x25548d8d,0x985dc524,0xa7cff142,0x93c4be32,0x4d60f5a1,0xd071c6e1,0x83ebd5c8
.long	0xb1fd2b0b,0xba3a80a7,0x5bec33e8,0x9b3ad396,0x79743fb3,0xb3868d61,0xfdb462fa,0xcfd169fc,0x9ce0a6af,0xd3b499d7,0xe42d3ff8,0x55dc1cf1,0xc6c3e1b2,0x04fb9e6c,0x6f69a474,0x47e6961d
.long	0xe548b37b,0x54eb3acc,0x84d40549,0xb38e7542,0x7b341b4f,0x8c3daa51,0x690bf7fa,0x2f6928ec,0x86ce6c41,0x0496b323,0x10adadcd,0x01be1c55,0x4bb5faf9,0xc04e67e7,0xe15c9985,0x3cbaf678
.long	0x50ca4247,0x8cd12145,0xe7dd30aa,0xba1aa47a,0xe58fee24,0x2f81ddf1,0xeec9b0e8,0x03452936,0x243aea96,0x8bdc3b81,0x15c3d0e5,0x9a2919af,0x10948361,0x9ea640ec,0x6e0bcccf,0x5ac86d5b
.long	0xc36cf440,0xf892d918,0xc939719c,0xaed3e837,0xc0218b64,0xb07b08d2,0xce9790dd,0x6f1bcbba,0x60919b8e,0x4a84d6ed,0x8ac1f9eb,0xd8900791,0x0dd5daef,0xf84941aa,0x67fd62c5,0xb22fe40a
.long	0x157f2db3,0x97e15ba2,0x8e28ca9c,0xbda2fc8f,0x37b9f454,0x5d050da4,0x2379d72e,0x3d57eb57,0xfb5ee997,0xe9b5eba2,0xe11538ca,0x01648ca2,0xf6327974,0x32bb76f6,0xff3f4bb7,0x338f14b8
.long	0xd7ab9a2d,0x524d226a,0x7dfae958,0x9c00090d,0x8751d8c2,0x0ba5f539,0x3ab8262d,0x8afcbcdd,0xe99d043b,0x57392729,0xaebc943a,0xef51263b,0x20862935,0x9feace93,0xb06c817b,0x639efc03
.long	0x66b4be7a,0x1fe054b3,0x84a37a1e,0x3f25a9de,0x78d75cd9,0xf39ef1ad,0x5062c1b5,0xd7b58f49,0xff563436,0x6f74f9a9,0xe8af51e7,0xf718ff29,0x15e97fec,0x5234d313,0x292f1c0a,0xb6a8e2b1
.long	0x327720c1,0xa7f53aa8,0xba092cc8,0x956ca322,0x28746c4d,0x8f03d64a,0x66d0d392,0x51fe1782,0x3c832c80,0xd19b34db,0x6da2e3b4,0x60dccc5c,0x0a104ccc,0x245dd62e,0x620b21fd,0xa7ab1de1
.long	0x3893d123,0xb293ae0b,0xb15ee71c,0xf7b75783,0x42a9468b,0x5aa3c614,0xdb15d744,0xd686123c,0xa7ab4116,0x8c616891,0xa4e6a459,0x6fcd72c8,0x77e5fad7,0xac219110,0x704fa46b,0xfb6a20e7
.long	0x341d81dc,0xe839be7d,0x32148379,0xcddb6889,0xf7026ead,0xda6211a1,0xf4d1cc5e,0xf3b2575f,0xa7a73ae6,0x40cfc8f6,0x61d5b483,0x83879a5e,0x41a50ebc,0xc5acb1ed,0x3c07d8fa,0x59a60cc8
.long	0xb1876262,0x1b73bdce,0x12af4ee9,0x2b0d79f0,0xd46e1d07,0x8bcf3b0b,0xe45d152f,0x17d6af9d,0x6d736451,0x73520461,0x56b0bf5a,0x43cbbd97,0xd5999b9d,0xb0833a5b,0xeb72e398,0x702614f0
.long	0x59c3e9f8,0x0aadf01a,0xce6b3d16,0x40200e77,0xdeddafad,0xda22bdd3,0x310d72e1,0x76dedaf4,0x4bc2e88f,0x49ef807c,0x146dd5a5,0x6ba81291,0x7d8d59e9,0xa1a4077a,0x802db349,0x87b6a2e7
.long	0x1b4e598e,0xd5679997,0x06fe4b1d,0xf499ef1f,0xfcb267c5,0x3978d3ae,0x235786d0,0xb582b557,0x1715cb07,0x32b3b2ca,0x8480241d,0x4c3de6a2,0xcb571ecd,0x63b5ffed,0xed2fe9a9,0xeaf53900
.long	0xc3b81990,0xdec98d4a,0x9e0cc8fe,0x1cb83722,0xd2b427b9,0xfe0b0491,0xe983a66c,0x0f2386ac,0xb3291213,0x930c4d1e,0x59a62ae4,0xa2f82b2e,0xf93e89e3,0x77233853,0x11777c7f,0x7f8063ac
.long	0x59ad2877,0xff0eb567,0x9865c754,0x6f454642,0x236e9a84,0xe6fe701a,0x06e40fc3,0xc586ef16,0x24bafad9,0x3f62b6e0,0x64da906a,0xc8b42bd2,0xda3276a0,0xc98e1eb4,0x06cbf852,0x30d0e5fc
.long	0xe8b4dfd4,0x1b6b2ae1,0x8301cbac,0xd754d5c7,0x112a39ac,0x66097629,0x93ba4ab9,0xf86b5999,0x99f9d581,0x26c9dea7,0xc2fafeaa,0x0473b1a8,0x3b2505a5,0x1469af55,0xd6a43323,0x227d16d7
.long	0xad3d97f9,0x3316f73c,0x1f137455,0x52bf3bb5,0x09954e7c,0x953eafeb,0xdd732411,0xa721dfed,0x141d4579,0xb4929821,0xaa3bd435,0x3411321c,0x17fa6015,0xafb355aa,0x18e42f0e,0xb4e7ef4a
.long	0x59371000,0x604ac97c,0x7f759c18,0xe1c48c70,0xa5db6b65,0x3f62ecc5,0x38a21495,0x0a78b173,0xbcc8ad94,0x6be1819d,0xd89c3400,0x70dc04f6,0xa6b4840a,0x462557b4,0x60bd21c0,0x544c6ade
.long	0x907a544b,0x6a00f24e,0x313da210,0xa7520dcb,0x11e4994b,0xfe939b75,0xbc275d70,0x918b6ba6,0x644be892,0xd3e5e0fc,0xfdaf6c42,0x707a9816,0xf15c13fe,0x60145567,0xe130a54a,0x4818ebaa
.long	0x58d2f767,0x28aad3ad,0xd7e7c773,0xdc5267fd,0xc3afcc98,0x4919cc88,0x2db8cd4b,0xaa2e6ab0,0xd0c63eaa,0xd46fec04,0x19ffa832,0xa1cb92c5,0xe43a631f,0x678dd178,0x3dc788b3,0xfb5ae1cd
.long	0x6e77de04,0x68b4fb90,0xf06dbb97,0x7992bcf0,0xc417c01d,0x896e6a13,0xb956be01,0x8d96332c,0x413aa2b9,0x902fc93a,0xfc98c8a5,0x99a4d915,0x565f1137,0x52c29407,0x21e4f281,0x4072690f
.long	0x02ff6072,0x36e607cf,0x8ad98cdc,0xa47d2ca9,0xf5f56609,0xbf471d1e,0xf264ada0,0xbcf86623,0xaa9e5cb6,0xb70c0687,0x17401c6c,0xc98124f2,0xd4a61435,0x8189635f,0xa9d98ea6,0xd28fb8af
.long	0x40c251f8,0xb9a67c2a,0xa2da44be,0x88cd5d87,0xe09b5423,0x437deb96,0x64287dc1,0x150467db,0xcdabb839,0xe161debb,0xf1839a3e,0xa79e9742,0x652d202b,0xbb8dd3c2,0xe9f97d96,0x7b3e67f7
.long	0xb1cb6ac9,0x5aa5d78f,0xca1d0d45,0xffa13e8e,0x2ba5bf95,0x369295dd,0x39aff05e,0xd68bd1f8,0x26d783f2,0xaf0d86f9,0xfc3aafc1,0x543a59b3,0x7b7da97c,0x3fcf81d2,0xd25dee46,0xc990a056
.long	0x519cce2c,0x3e6775b8,0xae13d863,0xfc9af71f,0x47c1605c,0x774a4a6f,0x2fd205e8,0x46ba4245,0xd3fd524d,0xa06feea4,0x6de1acc2,0x1e724641,0x334e2b42,0xf53816f1,0x922f0024,0x49e5918e
.long	0x65c7322d,0x439530b6,0xb3c1b3fb,0xcf12cc01,0x0172f685,0xc70b0186,0x1b58391d,0xb915ee22,0xa317db24,0x9afdf03b,0x17b8ffc4,0x87dec659,0xe4d3d050,0x7f46597b,0x006500e7,0x80a1c1ed
.long	0x78bf030e,0x84902a96,0x50560148,0xfb5e9c9a,0x63362426,0x6dae0a92,0xa9e30c40,0xdcaeecf4,0x518d0c6b,0xc0d887bb,0xcb985b9d,0x99181152,0xef7bc381,0xad186898,0x9ee46201,0x18168ffb
.long	0x2502753c,0x9a04cdaa,0x51407c41,0xbb279e26,0xf23564e5,0xeacb03aa,0x71e61016,0x18336582,0xeb809877,0x8684b8c4,0xea0e672e,0xb336e18d,0x34ee5867,0xefb601f0,0x1341cfd1,0x2733edbe
.long	0x26025c3c,0xb15e809a,0x9350df88,0xe6e981a6,0x8502fd8e,0x92376237,0x0c12be9b,0x4791f216,0x25f02425,0xb7256789,0x7a974443,0xec863194,0xfb41cc52,0x7c0ce882,0xf25c07f2,0xc266ff7e
.long	0x017025f3,0x3d4da8c3,0xfb9579b4,0xefcf628c,0x1f3716ec,0x5c4d0016,0x6801116e,0x9c27ebc4,0x1da1767e,0x5eba0ea1,0x47004c57,0xfe151452,0x8c2373b7,0x3ace6df6,0x5dbc37ac,0x75c3dffe
.long	0xddc925fc,0x3dc32a73,0x2f65ee0b,0xb679c841,0x451cbfeb,0x715a3295,0xf76e9a29,0xd9889768,0xb28ad247,0xec20ce7f,0x00894d79,0xe99146c4,0x9f5e3ea7,0x71457d7c,0x38030031,0x097b2662
.long	0xcf9f82a8,0xdb7f6ae6,0x438f473a,0x319decb9,0x283856c3,0xa63ab386,0xb06a361b,0x13e3172f,0x7d5a006c,0x2959f8dc,0x75fba752,0x2dbc27c6,0x87c22c9e,0xc1227ab2,0x71a268b2,0x06f61f75
.long	0x04779ce2,0x1b6bb971,0x0aadcb1d,0xaca83812,0xaeaab2d5,0x297ae0bc,0x5bfb9f13,0xa5c14ee7,0xf17a62c7,0xaa00c583,0x173759f6,0x39eb962c,0x86c9a88f,0x1eeba1d4,0xdf016c5e,0x0ab6c37a
.long	0xa28a0749,0xa2a147db,0xee519165,0x246c20d6,0xd3810715,0x5068d1b1,0x748160b9,0xb1e7018c,0xf380ff62,0x03f5b1fa,0xf3cb2c1e,0xef7fb1dd,0xfc91a7da,0xeab539a8,0xf3f9b561,0x83ddb707
.long	0xfe7df7a4,0xc550e211,0x063f6f40,0xa7cd07f2,0x2976879c,0xb0de3635,0xe55741da,0xb5f83f85,0xf3d8ac3d,0x4ea9d25e,0x62819f02,0x6fe2066f,0xcef4a564,0x4ab2b9c2,0x5ffa2de3,0x1e155d96
.long	0xc3a72d00,0x0eb0a19b,0x8513c31b,0x4037665b,0x04c64637,0x2fb2b6bf,0x08cdc639,0x45c34d6e,0xf01fd796,0x56f1e10f,0xfe3667b8,0x4dfb8101,0x9021d0c0,0xe0eda253,0x8a06c6ab,0x7a94e9ff
.long	0xbb9aa882,0x2d3bb0d9,0xec05fd10,0xea20e4e5,0x1a1ca64e,0xed7eeb5f,0xc6327cbd,0x2fa6b43c,0x3aa91121,0xb577e3cf,0x3a34079b,0x8c6bd5ea,0x60e02fc0,0xd7e5ba39,0x90141bf8,0xf16dd2c3
.long	0x80101b98,0xb57276d9,0xb82f0f66,0x760883fd,0x4bc3eff3,0x89d7de75,0x5dc2ab40,0x03b60643,0xe05beeac,0xcd6e53df,0xbc3325cd,0xf2f1e862,0x774f03c3,0xdd0f7921,0x4552cc1b,0x97ca7221
.long	0x1cd19f72,0x5a0d6afe,0xf183fbeb,0xa20915dc,0x832c403c,0x9fda4b40,0xbe425442,0x32738edd,0xb5eccf1a,0x469a1df6,0x28bbe1f0,0x4b5aff42,0x570dfc93,0x31359d7f,0xf0088628,0xa18be235
.long	0xb00ed3a9,0xa5b30fba,0x73cdf8be,0x34c61374,0xabc56797,0x2c5c5f46,0xb82a8ae2,0x5cecf93d,0xa968fbf0,0x7d3dbe41,0x1a5c7f3d,0xd23d4583,0xc087a9c7,0xf28f69a0,0x474471ca,0xc2d75471
.long	0x4eb732ec,0x36ec9f4a,0xb1ca6bed,0x6c943bbd,0xf2457892,0xd64535e1,0xf7e2ac06,0x8b84a8ea,0x2499dd5f,0xe0936cd3,0x0ed04e57,0x12053d7e,0xe4305d9d,0x4bdd0076,0x1f67f0a2,0x34a527b9
.long	0x9cec46ea,0xe79a4af0,0x658b9bc7,0xb15347a1,0x35af2f75,0x6bd2796f,0x4051c435,0xac957990,0xc33a655d,0x2669dda3,0x88514aa3,0x5d503c2e,0x3753dd41,0xdfa11337,0x0b754f78,0x3f054673
.long	0x496125bd,0xbf185677,0x3775006c,0xfb0023c8,0x3a037899,0xfa0f072f,0x0e4aea57,0x4222b6eb,0x7866d25a,0x3dde5e76,0x4837aa6f,0xb6eb04f8,0x2cf1cdb8,0x5315591a,0x2d4e683c,0x6dfb4f41
.long	0x48ee1f3a,0x7e923ea4,0x05a2afd5,0x9604d9f7,0x40ea4948,0xbe1d4a33,0xb44cbd2f,0x5b45f1f4,0x4acc757e,0x5faf8376,0x63d68ff7,0xa7cf9ab8,0xdf0e404b,0x8ad62f69,0x12bdafdf,0xd65f33c2
.long	0xa377b14e,0xc365de15,0x8e39f60c,0x6bf5463b,0x2ce68148,0x62030d2d,0xe6f843a8,0xd95867ef,0xef5ab017,0xd39a0244,0x4ab55d12,0x0bd2d8c1,0x41639169,0xc9503db3,0xf7660c8a,0x2d4e25b0
.long	0xe224c5d7,0x760cb3b5,0x68616919,0xfa3baf8c,0x8d142552,0x9fbca113,0x7669ebf5,0x1ab18bf1,0x9bdf25dd,0x55e6f53e,0xcb6cd154,0x04cc0bf3,0x95e89080,0x595bef49,0x104a9ac1,0xfe9459a8
.long	0xcce9bb32,0xad2d89ca,0xf7de8285,0xddea65e1,0xb351bd4b,0x62ed8c35,0x0c0e19a7,0x4150ff36,0x345f4e47,0x86e3c801,0x203a266c,0x3bf21f71,0x855b1f13,0x7ae110d4,0x07262517,0x5d6aaf6a
.long	0x813d28f1,0x1e0f12e1,0x7ad7a523,0x6000e11d,0xc744a17b,0xc7d8deef,0x14c05a00,0x1e990b48,0x93e976d5,0x68fddaee,0x46610d63,0x696241d1,0x893dda88,0xb204e7c3,0x6a3a6946,0x8bccfa65
.long	0xc5cd1411,0xb59425b4,0xff3658b1,0x701b4042,0x4784cf93,0xe3e56bca,0x8fe68d60,0x27de5f15,0xf8d53f19,0x4ab9cfce,0xa40a730d,0xddb10311,0x4eee0a8a,0x6fa73cd1,0x5249719d,0xfd548748
.long	0xa8123ef0,0x49d66316,0xe7f95438,0x73c32db4,0x0d9e7854,0x2e2ed209,0x9d9f0507,0xf98a9329,0x0c6aa20a,0xc5d33cf6,0x75279bb2,0x9a32ba14,0x774a7307,0x7e3202cb,0xe8c42dbd,0x64ed4bc4
.long	0xd4caed0d,0xc20f1a06,0x171d22b3,0xb8021407,0xd13268d7,0xd426ca04,0x25f4d126,0x92377007,0x71f21a85,0x4204cbc3,0xf82369ba,0x18461b7a,0x3fc858f9,0xc0c07d31,0xe2bab569,0x5deb5a50
.long	0xd5eea89e,0xd5959d46,0x08437f4b,0xfdff8424,0x3cfe254f,0xf21071e4,0x95468321,0x72417696,0x102cae3e,0x5d8288b9,0xf1965dff,0x2d143e3d,0xa078d847,0x00c9a376,0x26028731,0x6fc0da31
.long	0xe45083a2,0xa2baeadf,0x5e5b4bcd,0x66bc7218,0xd04b8e7f,0x2c826442,0x6c4b586b,0xc19f5451,0x5b7eeed5,0x60182c49,0x7aa9dfa1,0xd9954ecd,0xc73884ad,0xa403a8ec,0x9bb39041,0x7fb17de2
.long	0xabb020e8,0x694b64c5,0x19c4eec7,0x3d18c184,0x1c4793e5,0x9c4673ef,0x056092e6,0xc7b8aeb5,0xf0f8c16b,0x3aa1ca43,0xd679b2f6,0x224ed5ec,0x55a205c9,0x0d56eeaf,0x4b8e028b,0xbfe115ba
.long	0x3927f4fe,0x97e60849,0x759aa7c5,0xf91fbf94,0x6be90a51,0x985af769,0x78ccb823,0xc1277b78,0xe7a75952,0x395b656e,0x928da5f5,0x00df7de0,0x4ca4454f,0x09c23175,0x7aa2d3c1,0x4ec971f4
.long	0xe75d9ccc,0x45c3c507,0x3dc90306,0x63b7be8a,0x5db44bdc,0x37e09c66,0x6841c6a2,0x50d60da1,0x08df1b12,0x6f9b65ee,0x7ff089df,0x38734879,0x3fe8013d,0x9c331a66,0x5f42fcc8,0x017f5de9
.long	0xe8e57567,0x43077866,0xf9fcdb18,0xc9f781ce,0x9b12e174,0x38131dda,0x8a03752a,0x25d84aa3,0x4d0c0ce2,0x45e09e09,0x92bebba5,0x1564008b,0xa87284c7,0xf7e8ad31,0x97e7bbaa,0xb7c4b46c
.long	0x97acf4ec,0x3e22a7b3,0x5ea8b640,0x0426c400,0x4e969285,0x5e3295a6,0xa6a45670,0x22aabc59,0x5f5942bc,0xb929714c,0xfa3182ed,0x9a6168bd,0x104152ba,0x2216a665,0xb6926368,0x46908d03
.long	0x5a1251fb,0xa9f5d874,0xc72725c7,0x967747a8,0x31ffe89e,0x195c33e5,0xe964935e,0x609d210f,0x2fe12227,0xcafd6ca8,0x0426469d,0xaf9b5b96,0x5693183c,0x2e9ee04c,0xc8146fef,0x1084a333
.long	0xaed1d1f7,0x96649933,0x50563090,0x566eaff3,0xad2e39cf,0x345057f0,0x1f832124,0x148ff65b,0xcf94cf0d,0x042e89d4,0x520c58b3,0x319bec84,0x5361aa0d,0x2a267626,0x8fbc87ad,0xc86fa302
.long	0x5c8b06d5,0xfc83d2ab,0xfe4eac46,0xb1a785a2,0x846f7779,0xb99315bc,0xef9ea505,0xcf31d816,0x15d7dc85,0x2391fe6a,0xb4016b33,0x2f132b04,0x181cb4c7,0x29547fe3,0x650155a1,0xdb66d8a6
.long	0xadc1696f,0x6b66d7e1,0x0acd72d0,0x98ebe593,0xcc1b7435,0x65f24550,0xb4b9a5ec,0xce231393,0xdb067df9,0x234a22d4,0xcaff9b00,0x98dda095,0x6100c9c1,0x1bbc75a0,0x939cf695,0x1560a9c8
.long	0x99e0925f,0xcf006d3e,0x6322375a,0x2dd74a96,0xb56af5ba,0xc58b446a,0xe0b9b4f1,0x50292683,0x1aeaffa3,0xe2c34cb4,0x9b9587c1,0x8b17203f,0xead1350c,0x6d559207,0xfb7f9604,0x2b66a215
.long	0xfe51bf74,0x0850325e,0x5e460094,0x9c4f579e,0x76da2f25,0x5c87b92a,0x6febef33,0x889de4e0,0x646083ce,0x6900ec06,0xbfe12773,0xbe2a0335,0xc5344110,0xadd1da35,0xb802cd20,0x757568b7
.long	0x00f7e6c8,0x75559779,0x0facd2f0,0x38e8b94f,0x03fde375,0xfea1f3af,0x75881dfc,0x5e11a1d8,0xc1e2f2ef,0xb3a6b02e,0xc605a6c5,0x193d2bbb,0x339a0b2d,0x325ffeee,0x9e0c8846,0x27b6a724
.long	0xf1c367ca,0xe4050f1c,0xc90fbc7d,0x9bc85a9b,0xe1a11032,0xa373c4a2,0xad0393a9,0xb64232b7,0x167dad29,0xf5577eb0,0x94b78ab2,0x1604f301,0xe829348b,0x0baa94af,0x41654342,0x77fbd8dd
.long	0xb964e39a,0xdab50ea5,0xd0d3c76e,0xd4c29e3c,0x56d11964,0x80dae67c,0xe5ffcc2f,0x7307a8bf,0x91708c3b,0x65bbc1aa,0x28bf0eeb,0xa151e62c,0x6fa34db7,0x6cb53381,0xa29403a8,0x5139e05c
.long	0x94a7cd2e,0x6ff651b4,0x0699336c,0x5671ffd1,0x979a896a,0x6f5fd2cc,0xd8148cef,0x11e893a8,0x65cf7b10,0x988906a1,0xc50d8485,0x81b67178,0x8a35b3de,0x7c0deb35,0xc1d29799,0x423ac855
.long	0xdac50b74,0xaf580d87,0x5869734c,0x28b2b89f,0x874e28fb,0x99a3b936,0x25f3f73a,0xbb2c9190,0x84a9d5b7,0x199f6918,0x7e770374,0x7ebe2325,0x0738efe2,0xf442e107,0xcf9082d2,0xcf9f3f56
.long	0x09618708,0x719f69e1,0xc183f9b1,0xcc9e8364,0x366a21af,0xec203a95,0x068b141f,0x6aec5d6d,0x994f04e9,0xee2df78a,0x271245b0,0xb39ccae8,0x97e43f4f,0xb875a4a9,0xdb2cea98,0x507dfe11
.long	0x489b03e9,0x4fbf81cb,0x6ec414fa,0xdb86ec5b,0xf51b3ae5,0xfad444f9,0x1914e3fe,0xca7d33d6,0x0ae6c4d0,0xa9c32f5c,0x73969568,0xa9ca1d1e,0x1aa7467e,0x98043c31,0xe21b5ac6,0xe832e75c
.long	0x5232123d,0x314b7aea,0x65ae86db,0x08307c8c,0xaa4668ed,0x06e7165c,0xb4d3ec39,0xb170458b,0xc19bb986,0x4d2e3ec6,0xae0304ed,0xc5f34846,0x6c9f9722,0x917695a0,0x4cab1c0a,0x6c7f7317
.long	0x9d6d2e8b,0x6295940e,0x549f7c97,0xd318b8c1,0x97713885,0x22453204,0xa8a440fe,0x468d834b,0xbfba796e,0xd81fe5b2,0x6d71f116,0x152364db,0xb5b66e53,0xbb8c7c59,0x2641a192,0x0b12c61b
.long	0xfcf0a7fd,0x31f14802,0x5488b01e,0x42fd0789,0x9952b498,0x71d78d6d,0x07ac5201,0x8eb572d9,0x4d194a88,0xe0a2a44c,0xba017e66,0xd2b63fd9,0xf888aefc,0x78efc6c8,0x4a881a11,0xb76f6bda
.long	0xb46c2397,0x187f314b,0x5ded2819,0x004cf566,0x38764d34,0xa9ea5704,0x78084709,0xbba45217,0x1171121e,0x06474571,0xe7c9b671,0xad7b7eb1,0x730f7507,0xdacfbc40,0xc7ad7bd1,0x178cd8c6
.long	0xb2a67238,0xbf0be101,0xaf9c14f2,0x3556d367,0xa5662075,0x104b7831,0x79d9e60a,0x58ca59bb,0xa569a73b,0x4bc45392,0x5698f6c9,0x517a52e8,0xaeadd755,0x85643da5,0x2a581b84,0x1aed0cd5
.long	0x80af1372,0xb9b4ff84,0xf1ba5d1f,0x244c3113,0xf5f98d31,0x2a5dacbe,0x4375bc2a,0x2c3323e8,0x5594b1dd,0x17a3ab4a,0xceb4797e,0xa1928bfb,0xe4886a19,0xe83af245,0x72b5a74a,0x8979d546
.long	0x19f9e967,0xa0f726bc,0xe8fbbf4e,0xd9d03152,0xb7707d40,0xcfd6f51d,0x63f6e6e0,0x633084d9,0x55667eaf,0xedcd9cdc,0x2e44d56f,0x73b7f92b,0x4e962b14,0xfb2e39b6,0xf671fcbf,0x7d408f6e
.long	0x164a89bb,0xcc634ddc,0x3ef3bd05,0x74a42bb2,0x428decbb,0x1280dbb2,0x402c8596,0x6103f6bb,0x355a5752,0xfa2bf581,0x00946674,0x562f96a8,0x6da0223b,0x4e4ca16d,0x28d3aa25,0xfe47819f
.long	0xf8dfcf8a,0x9eea3075,0x95669825,0xa284f0aa,0x867d3fd8,0xb3fca250,0x269d691e,0x20757b5f,0x93b8a5de,0xf2c24020,0xebc06da6,0xd3f93359,0xb2739c33,0x1178293e,0xbcd686e5,0xd2a3e770
.long	0xcd941534,0xa76f49f4,0xe3c71c0e,0x0d37406b,0x3b97f7e3,0x172d9397,0xbd7fd0de,0xec17e239,0x6f496ba2,0xe3290551,0x36ad50e7,0x6a693172,0x83e7eff5,0xc4e539a2,0x18e1b4cf,0x752737e7
.long	0x68af43ee,0xa2f7932c,0x703d00bd,0x5502468e,0x2fb061f5,0xe5dc978f,0x28c815ad,0xc9a1904a,0x470c56a4,0xd3af538d,0x193d8ced,0x159abc5f,0x20108ef3,0x2a37245f,0x223f7178,0xfa17081e
.long	0x10c8c0f5,0x27b0fb2b,0x40650547,0x2102c3ea,0x8ac3bfa7,0x594564df,0x509dad96,0x98102033,0xf1d18a13,0x6989643f,0xd7fc5af0,0x35eebd91,0xfaeaafd8,0x078d096a,0xdef3de98,0xb7a89341
.long	0xecf2a73a,0x2a206e8d,0x8e551994,0x066a6397,0xb98d53a2,0x3a6a088a,0x2d1124aa,0x0ce7c67c,0x759a113c,0x48cec671,0x4f6f67fa,0xe3b373d3,0xfd36727b,0x5455d479,0xa13c0d81,0xe5a428ee
.long	0x1c86682b,0xb853dbc8,0xb8d02b2a,0xb78d2727,0x8ebc329a,0xaaf69bed,0x293b2148,0xdb6b40b3,0xb8c4961f,0xe42ea77d,0x20e5e0ab,0xb1a12f7c,0x79e8b05e,0xa0ec5274,0xfab60a80,0x68027391
.long	0x16b1bd5e,0x6bfeea5f,0x4de30ad3,0xf957e420,0x6a353b9e,0xcbaf664e,0x26d14feb,0x5c873312,0xb65f57cb,0x4e87f98c,0x5e0cdd41,0xdb60a621,0xa6881440,0x67c16865,0x46ab52aa,0x1093ef1a
.long	0x3f4ece64,0xc095afb5,0x7604551a,0x6a6bb02e,0x0b26b8cd,0x55d44b4e,0xf971268a,0xe5f9a999,0x11a7de84,0xc08ec425,0xfda469dd,0x83568095,0x6c6c90a2,0x737bfba1,0xbe229831,0x1cb9c4a0
.long	0xbb2eec64,0x93bccbba,0xda03adbe,0xa0c23b64,0xe0e86ac4,0x5f7aa00a,0xfc1401e6,0x470b941e,0x9df43574,0x5ad8d679,0x0f65d810,0x4ccfb8a9,0xaa7fbd81,0x1bce80e3,0x9508d20a,0x273291ad
.long	0x42a92806,0xf5c4b46b,0xa86ab44a,0x810684ec,0xca0bc9f8,0x4591640b,0x5c4b6054,0xb5efcdfc,0x6e9edd12,0x16fc8907,0xd4d792f9,0xe29d0b50,0x9b03116d,0xa45fd01c,0xc81765a4,0x85035235
.long	0xb4b4b67c,0x1fe2a9b2,0xe8020604,0xc1d10df0,0xbc8058d8,0x9d64abfc,0x712a0fbb,0x8943b9b2,0x3b3def04,0x90eed914,0x4ce775ff,0x85ab3aa2,0x7bbc9040,0x605fd4ca,0xe2c75dfb,0x8b34a564
.long	0x10358560,0x41ffc94a,0x9e5c28aa,0x2d8a5072,0x4cc7eb15,0xe915a0fc,0x8f6d0f5d,0xe9efab05,0xd19e9b91,0xdbab47a9,0x0276154c,0x8cfed745,0x2cfede0d,0x154357ae,0x19f5a4ef,0x520630df
.long	0xe382360f,0x25759f7c,0x88bf5857,0xb6db05c9,0x6c58d46c,0x2917d61d,0xfd20cb7a,0x14f8e491,0x11c20340,0xb68a727a,0xaf7ccbb6,0x0386f86f,0xfee09a20,0x5c8bc6cc,0xbb7eea35,0x7d76ff4a
.long	0xdb15be7a,0xa7bdebe7,0xd89f0302,0x67a08054,0xc1193364,0x56bf0ea9,0x62837ebe,0xc8244467,0x20d841b8,0x32bd8e8b,0xdbb8a54f,0x127a0548,0x63b20236,0x83dd4ca6,0x203491fa,0x87714718
.long	0xaa8a5288,0x4dabcaaa,0xaf23a1c9,0x91cc0c8a,0x3f220e0c,0x34c72c6a,0x1232144a,0xbcc20bdf,0xa20ede1b,0x6e2f42da,0x74a00515,0xc441f00c,0x734b8c4b,0xbf46a5b6,0x7b56c9a4,0x57409503
.long	0xe4585d45,0x9f735261,0x6734e642,0x9231faed,0xbe70ee6c,0x1158a176,0x7c3501bf,0x35f1068d,0xa2d26115,0x6beef900,0xef0afee3,0x649406f2,0xbc2420a1,0x3f43a60a,0xd5aee4ac,0x509002a7
.long	0x3ff3571b,0xb46836a5,0x837927c1,0x24f98b78,0x4533c716,0x6254256a,0xd07ee196,0xf27abb0b,0x5c6d5bfd,0xd7cf64fc,0xf0cd7a77,0x6915c751,0x8798f534,0xd9f59012,0xf81d8b5f,0x772b0da8
.long	0x2e03fa69,0x1244260c,0x3be1a374,0x36cf0e3a,0xef06b960,0x6e7c1633,0x671f90f6,0xa71a4c55,0x33c673db,0x7a941251,0x73e8c131,0xc0bea510,0xd4f6c734,0x61a8a699,0x341ed001,0x25e78c88
.long	0x8e2f7d90,0x5c18acf8,0x77be32cd,0xfdbf33d7,0xd2eb5ee9,0x0a085cd7,0xb3201115,0x2d702cfb,0x85c88ce8,0xb6e0ebdb,0x1e01d617,0x23a3ce3c,0x567333ac,0x3041618e,0x157edb6b,0x9dd0fd8f
.long	0xb57872b8,0x27f74702,0x657d5fe1,0x2ef26b4f,0x57cf3d40,0x95426f0a,0x65a6067a,0x847e2ad1,0x09996a74,0xd474d9a0,0x2a26115c,0x16a56acd,0xd16f4d43,0x02a615c3,0xaadb85b7,0xcc3fc965
.long	0xce07d1b0,0x386bda73,0x58ad4178,0xd82910c2,0xcd2617f4,0x124f82cf,0xef691770,0xcc2f5e8d,0xb8c30ccc,0x82702550,0x1a8e575a,0x7b856aea,0xb1ab9459,0xbb822fef,0xec24e38e,0x085928bc
.long	0xba8f4b4d,0x5d0402ec,0x00b4d58b,0xc07cd4ba,0x29227e7a,0x5d8dffd5,0x31bf386f,0x61d44d0c,0x135e6f4d,0xe486dc2b,0xe79410ef,0x680962eb,0xf10088b5,0xa61bd343,0xe2e28686,0x6aa76076
.long	0x8fb98871,0x80463d11,0xbbc76aff,0xcb26f5c3,0xfbe03614,0xd4ab8edd,0xc0cf2dee,0xc8eb579b,0xc93bae41,0xcc004c15,0x3aeca3b2,0x46fbae5d,0x0f1e9ab1,0x671235cf,0x9ec285c1,0xadfba934
.long	0xf216c980,0x88ded013,0xf79e0bc1,0xc8ac4fb8,0xfb97a237,0xa29b89c6,0x9922d8e7,0xb697b780,0xddb945b5,0x3142c639,0xe094c3a9,0x447b06c7,0x72266c90,0xcdcb3642,0xa9385046,0x633aad08
.long	0xb57c6477,0xa36c936b,0xe94dbcc6,0x871f8b64,0xa591a67b,0x28d0fb62,0xc1d926f5,0x9d40e081,0xf2d84b5a,0x3111eaf6,0xa565b644,0x228993f9,0x2c83188b,0x0ccbf592,0x3df3e197,0xf87b30ab
.long	0x7642bca8,0xb8658b31,0x52800f17,0x1a032d7f,0x79bf9445,0x051dcae5,0x54a2e253,0xeba6b8ee,0xd4485692,0x5c8b9cad,0x8986e9be,0x84bda40e,0x2f0db448,0xd16d16a4,0xa14d4188,0x8ec80050
.long	0x98fa7aaa,0xb2b26107,0xf073aa4e,0x41209ee4,0xf2d6b19b,0xf1570359,0xfc577caf,0xcbe6868c,0x32c04dd3,0x186c4bdc,0xcfeee397,0xa6c35fae,0xf086c0cf,0xb4a1b312,0xd9461fe2,0xe0a5ccc6
.long	0x1536189f,0xc32278aa,0xba6df571,0x1126c55f,0xb194560e,0x0f71a602,0x324bd6e1,0x8b2d7405,0x3738be71,0x8481939e,0x1a4d97a9,0xb5090b1a,0xf05ba915,0x116c65a3,0xaae448aa,0x21863ad3
.long	0xa7aae5d3,0xd24e2679,0x0de5c1c4,0x7076013d,0xbb05b629,0x2d50f8ba,0x6e66efbb,0x73c1abe2,0xf2488af7,0xefd4b422,0x663ba575,0xe4105d02,0x53a69457,0x7eb60a8b,0xc945973b,0x62210008
.long	0x77a50ec6,0xfb255478,0x0a37a72c,0xbf0392f7,0x4be18e7a,0xa0a7a19c,0x25b1e0af,0x90d8ea16,0xef953f57,0x7582a293,0xbdc5465a,0x90a64d05,0xe2510717,0xca79c497,0x18cb641f,0x560dbb7c
.long	0x4b66abfb,0x1d8e3286,0x59030900,0xd26f52e5,0x5584941a,0x1ee3f643,0x569f5958,0x6d3b3730,0x4789dba5,0x9ff2a62f,0x72b5c9b7,0x91fcb815,0x6c8f9a0e,0xf446cb7d,0x39b7ecb5,0x48f625c1
.long	0x1c6219b8,0xbabae801,0x28ac2f23,0xe7a562d9,0x26e20588,0xe1b48732,0x775af051,0x06ee1cad,0xfaff79f7,0xda29ae43,0x652ee9e0,0xc141a412,0x195f4bd0,0x1e127f6f,0x072f34f8,0x29c6ab4f
.long	0x30448112,0x7b7c1477,0xe4a38656,0x82b51af1,0x2f315010,0x2bf2028a,0x6ea88cd4,0xc9a4a01f,0x257e5818,0xf63e95d8,0xb4519b16,0xdd8efa10,0x0da910bf,0xed8973e0,0x5c0fe4a9,0xed49d077
.long	0xb7caee1e,0xac3aac5e,0xa7f4da57,0x1033898d,0x5c6669b9,0x42145c0e,0xc1aa2aa0,0x42daa688,0x1a1d885a,0x629cc15c,0xf4b76817,0x25572ec0,0x9c8f8f28,0x8312e435,0x81965490,0x8107f8cd
.long	0x6fa6110c,0x516ff3a3,0xfb93561f,0x74fb1eb1,0x8457522b,0x6c0c9047,0x6bb8bdc6,0xcfd32104,0xcc80ad57,0x2d6884a2,0x86a9b637,0x7c27fc35,0xadf4e8cd,0x3461baed,0x617242f0,0x1d56251a
.long	0xc955bef4,0x0b80d209,0x06adb047,0xdf02cad2,0x5ec74fee,0xf0d7cb91,0x1111ba44,0xd2503375,0xdf53cb36,0x9671755e,0x3368551b,0x54dcb612,0xc8a025a4,0x66d69aac,0xe77ef445,0x6be946c6
.long	0xa995e094,0x719946d1,0xe51e04d8,0x65e848f6,0x6a1e3113,0xe62f3300,0x501de503,0x1541c7c1,0xf4acfade,0x4daac9fa,0x44cd0b71,0x0e585897,0x0a51cd77,0x544fd869,0x0031016d,0x60fc20ed
.long	0xa4276867,0x58b404ec,0x34f34993,0x46f6c3cc,0xc636e5bd,0x477ca007,0x7c458b47,0x8018f5e5,0xe47b668f,0xa1202270,0xee14f203,0xcef48ccd,0x62ff9b4d,0x23f98bae,0xc589eddd,0x55acc035
.long	0x64db4444,0x3fe712af,0xbecdd480,0x19e9d634,0xa930978a,0xe08bc047,0xa1280733,0x2dbf24ec,0x2cd706b2,0x3c0ae38c,0x359017b9,0x5b012a5b,0x72e0f5ae,0x3943c38c,0x57176fa3,0x786167ea
.long	0x594881dc,0xe5f9897d,0xcfb820c1,0x6b5efad8,0xd55018de,0xb2179093,0x0bac56ce,0x39ad7d32,0x2cfc0e81,0xb55122e0,0xf6d89daa,0x117c4661,0xcb64fa09,0x362d01e1,0x3e9c4ddd,0x6a309b4e
.long	0xabea49b1,0xfa979fb7,0x10e2c6c5,0xb4b1d27d,0x23afde7a,0xbd61c2c4,0x9786d358,0xeb6614f8,0x7f6f7459,0x4a5d816b,0x09360e7b,0xe431a44f,0xc309914c,0x8c27a032,0xcaede3d8,0xcea5d68a
.long	0x3a0a3f95,0x3668f665,0x7ceba27b,0x89369416,0xe4728fe9,0x89981fad,0x8a093562,0x7102c8a0,0x235d21c8,0xbb80310e,0xbefb7f7b,0x505e55d1,0x12958a67,0xa0a90811,0x4d851fef,0xd67e106a
.long	0x431dd80e,0xb84011a9,0x73306cd9,0xeb7c7cca,0xd1b3b730,0x20fadd29,0xfe37b3d3,0x83858b5b,0xb6251d5c,0xbf4cd193,0x1352d952,0x1cca1fd3,0x90fbc051,0xc66157a4,0x89b98636,0x7990a638
.long	0x87dec0e1,0xe5aa692a,0xf7b39d00,0x010ded8d,0x54cfa0b5,0x7b1b80c8,0xa0f8ea28,0x66beb876,0x3476cd0e,0x50d7f531,0xb08d3949,0xa63d0e65,0x53479fc6,0x1a09eea9,0xf499e742,0x82ae9891
.long	0x5ca7d866,0xab58b910,0x3adb3b34,0x582967e2,0xcceac0bc,0x89ae4447,0x7bf56af5,0x919c667c,0x60f5dcd7,0x9aec17b1,0xddcaadbc,0xec697b9f,0x463467f5,0x0b98f341,0xa967132f,0xb187f1f7
.long	0x214aeb18,0x90fe7a1d,0x741432f7,0x1506af3c,0xe591a0c4,0xbb5565f9,0xb44f1bc3,0x10d41a77,0xa84bde96,0xa09d65e4,0xf20a6a1c,0x42f060d8,0xf27f9ce7,0x652a3bfd,0x3b3d739f,0xb6bdb65c
.long	0xec7fae9f,0xeb5ddcb6,0xefb66e5a,0x995f2714,0x69445d52,0xdee95d8e,0x09e27620,0x1b6c2d46,0x8129d716,0x32621c31,0x0958c1aa,0xb03909f1,0x1af4af63,0x8c468ef9,0xfba5cdf6,0x162c429f
.long	0x753b9371,0x2f682343,0x5f1f9cd7,0x29cab45a,0xb245db96,0x571623ab,0x3fd79999,0xc507db09,0xaf036c32,0x4e2ef652,0x05018e5c,0x86f0cc78,0xab8be350,0xc10a73d4,0x7e826327,0x6519b397
.long	0x9c053df7,0xe8cb5eef,0xb300ea6f,0x8de25b37,0xc849cffb,0xdb03fa92,0xe84169bb,0x242e43a7,0xdd6f958e,0xe4fa51f4,0xf4445a8d,0x6925a77f,0xe90d8949,0xe6e72a50,0x2b1f6390,0xc66648e3
.long	0x173e460c,0xb2ab1957,0x30704590,0x1bbbce75,0xdb1c7162,0xc0a90dbd,0x15cdd65d,0x505e399e,0x57797ab7,0x68434dcb,0x6a2ca8e8,0x60ad35ba,0xde3336c1,0x4bfdb1e0,0xd8b39015,0xbbef99eb
.long	0x1711ebec,0x6c3b96f3,0xce98fdc4,0x2da40f1f,0x57b4411f,0xb99774d3,0x15b65bb6,0x87c8bdf4,0xc2eef12d,0xda3a89e3,0x3c7471f3,0xde95bb9b,0xd812c594,0x600f225b,0x2b75a56b,0x54907c5d
.long	0x8db60e35,0xa93cc5f0,0xfa833319,0x743e3cd6,0xf81683c9,0x7dad5c41,0x9c34107e,0x70c1e7d9,0xa6be0907,0x0edc4a39,0x86d0b7d3,0x36d47035,0x272bfa60,0x8c76da03,0x0f08a414,0x0b4a07ea
.long	0x45c1dd53,0x699e4d29,0x231debb5,0xcadc5898,0xa77f00e0,0xdf49fcc7,0xa73e5a0e,0x93057bbf,0x027a4cd1,0x2f8b7ecd,0xc614011a,0x114734b3,0x67677c68,0xe7a01db7,0x7e273f4f,0x89d9be5e
.long	0x089808ef,0xd225cb2e,0xd59e4107,0xf1f7a27d,0x8211b9c9,0x53afc761,0xe6819159,0x0361bc67,0x7f071426,0x2a865d0b,0xe7072567,0x6a3c1810,0x0d6bcabd,0x3e3bca1e,0x408591bc,0xa1b02bc1
.long	0x31fba239,0xe0deee59,0x98bd91d1,0xf47424d3,0x071a3c1d,0x0f8886f4,0xa819233b,0x3f7d41e8,0xcf6eb998,0x708623c2,0x609a287f,0x86bb49af,0x63c90762,0x942bb249,0x55a9654b,0x0ef6eea5
.long	0x36f5defe,0x5f6d2d72,0x56f99176,0xfa9922dc,0xf78ce0c7,0x6c8c5ece,0xbe09b55e,0x7b44589d,0x9ea83770,0xe11b3bca,0x2ab71547,0xd7fa2c7f,0x2a1ddcc0,0x2a3dd6fa,0x5a7b7707,0x09acb430
.long	0x649d4e57,0x4add4a2e,0x1917526e,0xcd53a2b0,0x20b44ac4,0xc5262330,0xbaa2c31d,0x4028746a,0x64291d4c,0x51318390,0xee5ad909,0xbf48f151,0x7b185681,0xcce57f59,0x4854d442,0x7c3ac1b0
.long	0xc093c171,0x65587dc3,0x24f42b65,0xae7acb24,0x955996cb,0x5a338adb,0x6051f91b,0xc8e65675,0x28b8d0b1,0x66711fba,0xb6c10a90,0x15d74137,0x3a232a80,0x70cdd7eb,0x6191ed24,0xc9e2f07f
.long	0xf79588c0,0xa80d1db6,0xb55768cc,0xfa52fc69,0x7f54438a,0x0b4df1ae,0xf9b46a4f,0x0cadd1a7,0x1803dd6f,0xb40ea6b3,0x55eaae35,0x488e4fa5,0x382e4e16,0x9f047d55,0x2f6e0c98,0xc9b5b7e0
.long	0x95762649,0x6b1bd2d3,0xc7aea3f6,0xa9604ee7,0x6dc6f896,0x3646ff27,0x2860bad1,0x9bf0e7f5,0x7cb44b92,0x2d92c821,0xaea9c182,0xa2f5ce63,0x9154a5fd,0xd0a2afb1,0x95801da6,0x482e474c
.long	0xb611c24b,0xc19972d0,0x60a8f351,0x1d468e65,0x7bcf6421,0xeb758069,0x88fbc491,0xec9dd0ee,0x956c2e32,0x5b59d2bf,0xdcddf94e,0x73dc6864,0xbcee7665,0xfd5e2321,0x5e9a06c4,0xa7b4f8ef
.long	0x7280f855,0xfba918dd,0x8baec688,0xbbaac260,0x33400f42,0xa3b3f00f,0x66f2e6e4,0x3d2dba29,0x98509375,0xb6f71a94,0xcea423cc,0x8f33031f,0x4807e6fb,0x009b8dd0,0x5cdb954c,0x5163cfe5
.long	0xcf41c6e8,0x03cc8f17,0x037b925c,0xf1f03c2a,0x66d2427c,0xc39c19cc,0x7b6c18e4,0x823d24ba,0x901f0b4f,0x32ef9013,0xf8941c2e,0x684360f1,0x2c28092e,0x0ebaff52,0x256c932f,0x7891e4e3
.long	0xac445e3d,0x51264319,0x8ea74381,0x553432e7,0x67e9c50a,0xe6eeaa69,0x62e628c7,0x27ced284,0x7a4afa57,0x3f96d375,0xe484c150,0xde0a14c3,0x38bd9923,0x364a24eb,0xe5177422,0x1df18da0
.long	0xd8d38a9b,0x174e8f82,0xe7de1391,0x2e97c600,0xa1c175dd,0xc5709850,0x32ae5035,0x969041a0,0x76a2086b,0xcbfd533b,0xd7c2e8fe,0xd6bba71b,0x099dfb67,0xb2d58ee6,0x064a85d9,0x3a8b342d
.long	0x522f9be3,0x3bc07649,0xdf1f49a8,0x690c075b,0x3854ec42,0x80e1aee8,0x17689dc7,0x2a7dbf44,0x3faf4078,0xc004fc0e,0xdf11862c,0xb2f02e9e,0xa0a1b7b3,0xf10a5e0f,0x8936ec80,0x30aca623
.long	0x02f40d9a,0xf83cbf05,0x2c318a4d,0x4681c468,0x0e9c2674,0x98575618,0x1847092e,0xbe79d046,0x78bd01e0,0xaf1e480a,0x72a51db9,0x6dd359e4,0xe3afbab6,0x62ce3821,0x17733199,0xc5cee5b6
.long	0x6ffd9fbb,0xe08b30d4,0x36c610b7,0x6e5bc699,0x9ce262cf,0xf343cff2,0x68b914c1,0xca2e4e35,0x16de36c5,0x011d64c0,0x42e2b829,0xe0b10fdd,0x6685aaf8,0x78942981,0x230ede97,0xe7511708
.long	0x3b922bf8,0x671ed8fc,0x4c29b133,0xe4d8c0a0,0x3b6e99c4,0x87eb1239,0x8793beba,0xaff3974c,0x2c18df9b,0x03749405,0x91007139,0xc5c3a293,0xe37a0b95,0x6a77234f,0xb661c96b,0x02c29a21
.long	0x141ecf61,0xc3aaf1d6,0x3bb22f53,0x9195509e,0x22d51357,0x29597404,0x537bed60,0x1b083822,0xe07289f0,0xcd7d6e35,0x6dd86eff,0x1f94c48c,0xeb0f9cfa,0xc8bb1f82,0x1b2eb97d,0x9ee0b7e6
.long	0x34d74e31,0x5a52fe2e,0x3bf79ab6,0xa352c310,0xabfeeb8f,0x97ff6c5a,0xf5c97305,0xbfbe8fef,0xa7904608,0xd6081ce6,0xc4fca249,0x1f812f3a,0xb9e5e200,0x9b24bc9a,0x38012ee8,0x91022c67
.long	0x30a713a1,0xe83d9c5d,0x84ef0f93,0x4876e3f0,0xc1fbf928,0xc9777029,0xbce7d2a4,0xef7a6bb3,0xdfa2a659,0xb8067228,0xd877a48f,0xd5cd3398,0x025d0f3f,0xbea4fd8f,0x2eae7c2b,0xd67d2e35
.long	0xcc5f4394,0x184de7d7,0x4536e142,0xb5551b5c,0xd34aa60a,0x2e89b212,0xf50051d5,0x14a96fea,0x0d12bb0b,0x4e21ef74,0x60b9677e,0xc522f020,0x2df7731d,0x8b12e467,0x7b326d31,0x39f80382
.long	0x39024a94,0xdfb8630c,0x97319452,0xaacb96a8,0xeda3867c,0xd68a3961,0x77c4ffca,0x0c58e2b0,0x4da919fa,0x3d545d63,0xf15e2289,0xef79b69a,0x808bab10,0x54bc3d3d,0x45f82c37,0xc8ab3007
.long	0x7c4a658a,0xc12738b6,0x40e72182,0xb3c47639,0x8798e44f,0x3b77be46,0x17a7f85f,0xdc047df2,0x5e59d92d,0x2439d4c5,0xe8e64d8d,0xcedca475,0x87ca9b16,0xa724cd0d,0xa5540dfe,0x35e4fd59
.long	0xe4bcf6b1,0xf8c1ff18,0x295018fa,0x856d6285,0x3263c949,0x433f665c,0xa1f21409,0xa6a76dd6,0xcc7b4f79,0x17d32334,0x06720e4a,0xa1d03122,0x81d9bed5,0xadb6661d,0x11db15d1,0xf0d6fb02
.long	0x1fb747d2,0x7fd11ad5,0x3033762b,0xab50f959,0xfbefaf5a,0x2a7e711b,0x3fef2bbf,0xc7393278,0x0df6f9be,0xe29fa244,0x71efd215,0x9092757b,0x4f3d6fd9,0xee60e311,0x0acfb78b,0x338542d4
.long	0x38961a0f,0x44a23f08,0x986987ca,0x1426eade,0x4a863cc6,0x36e6ee2e,0x628b8b79,0x48059420,0x7396e1de,0x30303ad8,0x38c5aad1,0x5c8bdc48,0x5c8f5066,0x3e40e11f,0x8d246bbd,0xabd6e768
.long	0x23330a01,0x68aa40bb,0xc34eafa0,0xd23f5ee4,0x5de02c21,0x3bbee315,0xd1d8dd06,0x18dd4397,0x122d7b44,0x3ba1939a,0xa33870d6,0xe6d3b40a,0x1c4fe3f8,0x8e620f70,0xd3a50cbf,0xf6bba1a5
.long	0xcfc0aee0,0x4a78bde5,0xc08c50bd,0x847edc46,0xad63c9b2,0xbaa2439c,0x10fc2acb,0xceb4a728,0x26da033d,0xa419e40e,0x03e02683,0x6cc3889d,0xfdccf725,0x1cd28559,0x8d13d208,0x0fd7e0f1
.long	0x1f0df9d4,0x01b9733b,0xa2b5e4f3,0x8cc2c5f3,0x3a304fd4,0x43053bfa,0x0a9f1aa7,0x8e87665c,0xd73dc965,0x087f29ec,0x3e9023db,0x15ace455,0x2bce28b4,0x2370e309,0xb6b1e84a,0xf9723442
.long	0xb72d9f26,0xbeee662e,0xf0e47109,0xb19396de,0xe13289d0,0x85b1fa73,0x54e58e32,0x436cf77e,0xe990ef77,0x0ec833b3,0x1b11fc25,0x7373e3ed,0x0fc332ce,0xbe0eda87,0x8d7ea856,0xced04970
.long	0x7e977ca0,0xf85ff785,0xdfdd5d2b,0xb66ee8da,0x905af461,0xf5e37950,0x966d487c,0x587b9090,0x32ba0127,0x6a198a1b,0x141615ac,0xa7720e07,0x996ef2f2,0xa23f3499,0x470bcb3d,0xef5f64b4
.long	0x92b8c559,0xa526a962,0x69740a0f,0x0c14aac0,0xa6bdc0a5,0x0d41a9e3,0x9c48aef4,0x97d52106,0x3e7c253b,0xcf16bd30,0x47fdedc1,0xcc834b1a,0x373aab2e,0x7362c6e5,0xc5f590ff,0x264ed85e
.long	0x66d41870,0x7a46d9c0,0x4787ba09,0xa50c20b1,0xe3d44635,0x185e7e51,0x31e2d8dc,0xb3b3e080,0xa179e9d9,0xbed1e558,0x74a76781,0x2daa3f79,0x3a40864f,0x4372baf2,0x4fe75cb5,0x46900c54
.long	0xf76765d0,0xb95f171e,0x95c87502,0x4ad726d2,0x4d7c99bd,0x2ec769da,0xc36cdfa8,0x5e2ddd19,0xa93e6dea,0xc22117fc,0x93771123,0xe8a2583b,0xfa08a3a2,0xbe2f6089,0x8f0e1112,0x4809d5ed
.long	0xda7a095e,0x3b414aa3,0x26f5aadd,0x9049acf1,0x6be8b84a,0x78d46a4d,0xb732b9b3,0xd66b1963,0xde6e9555,0x5c2ac2a0,0xb5bd8770,0xcf52d098,0x0fd28921,0x15a15fa6,0x8b27536d,0x56ccb81e
.long	0x9f4ccbb8,0x0f0d8ab8,0xdb221729,0xed5f44d2,0x00bed10c,0x43141988,0x1d735b8b,0xc94348a4,0x29ef8479,0x79f3e9c4,0x614c693f,0x4c13a4e3,0x8e143a14,0x32c9af56,0xe29ac5c4,0xbc517799
.long	0x2774856f,0x05e17992,0x6c1bf55f,0x6e52fb05,0xe4f19e16,0xaeda4225,0xaf5ccb26,0x70f4728a,0xb2947f22,0x5d2118d1,0x281d6fb9,0xc827ea16,0x8cf0eabd,0x8412328d,0x03ef9dcf,0x45ee9fb2
.long	0xbb937d63,0x8e700421,0xcc4b37a6,0xdf8ff2d5,0x5ced7b68,0xa4c0d5b2,0xc7308f59,0x6537c1ef,0x3b37f8e8,0x25ce6a26,0xdeebc6ce,0x170e9a9b,0x8728d72c,0xdd037952,0x850154bc,0x445b0e55
.long	0x83a7337b,0x4b7d0e06,0xffecf249,0x1e3416d4,0x66a2b71f,0x24840eff,0xb37cc26d,0xd0d9a50a,0x6fe28ef7,0xe2198150,0x23324c7f,0x3cc5ef16,0x769b5263,0x220f3455,0xa10bf475,0xe2ade2f1
.long	0x458d3671,0x28cd20fa,0x2dc4847b,0x1549722c,0x591941e3,0x6dd01e55,0x27128ccb,0x0e6fbcea,0x3bef0262,0xae1a1e6b,0x8f54e103,0xfa8c472c,0x72c052ec,0x7539c0a8,0x5a3490e9,0xd7b27369
.long	0x71684349,0x143fe1f1,0x32e19b97,0x36b4722e,0x90980aff,0xdc059227,0x9e13d674,0x175c9c88,0x6e6bfdb1,0xa7de5b22,0xbedb4b46,0x5ea5b7b2,0xd34a6e44,0xd5570191,0xa24ff7e6,0xfcf60d2e
.long	0x677819e1,0x614a392d,0xaa5a29e8,0x7be74c7e,0x63c85f3f,0xab50fece,0x46cab337,0xaca2e2a9,0x122a6fe3,0x7f700388,0x882a04a8,0xdb69f703,0xcf7aed57,0x9a77935d,0x8d91c86f,0xdf16207c
.long	0x63ed9998,0x2fca49ab,0xa77ddf96,0xa3125c44,0x24344072,0x05dd8a86,0xfec3fb56,0xa023dda2,0x0c743032,0x421b41fc,0x5e438639,0x4f2120c1,0xc83c1b07,0xfb7cae51,0xcac2171a,0xb2370caa
.long	0x6cc820fb,0x2eb2d962,0xb85a44bf,0x59feee5c,0x5b6598f0,0x94620fca,0x7e314051,0x6b922cae,0x106bed4e,0xff8745ad,0xdfa1e9ab,0x546e71f5,0x1ec29487,0x935c1e48,0x4d936530,0x9509216c
.long	0x85c9a2db,0xc7ca3067,0x6be8606f,0xd6ae5152,0xe14c651d,0x09dbcae6,0x9bc32f96,0xc9536e23,0x34521b03,0xa90535a9,0x878756ff,0xf39c526c,0x8aedf03c,0x383172ec,0xefe0c034,0x20a8075e
.long	0x64026422,0xf22f9c62,0x24b9d076,0x8dd10780,0x3bef2950,0x944c742a,0x88a2b00b,0x55b9502e,0x86a09817,0xa59e14b4,0x47bb4071,0xa39dd3ac,0x3be0592f,0x55137f66,0xc9e63f5b,0x07fcafd4
.long	0x346eb226,0x963652ee,0xec2facb7,0x7dfab085,0x691add26,0x273bf2b8,0xf2b46c44,0x30d74540,0xf2c2d065,0x05e8e73e,0xd42eeac9,0xff9b8a00,0x97209d22,0x2fcbd205,0xde14ea2c,0xeb740ffa
.long	0xa8aef518,0xc71ff913,0xfff4cfa2,0x7bfc74bb,0xb6b36048,0x1716680c,0x9ef79af1,0x121b2cce,0xa01eb3d3,0xbff3c836,0x5f79077b,0x50eb1c6a,0xa004bbcf,0xa48c32d6,0x7d64f61d,0x47a59316
.long	0x93102016,0x6068147f,0x94d12576,0x12c5f654,0xc9bc6b91,0xefb071a7,0x6e23ea95,0x7c2da0c5,0xd4a1dd5d,0xf4fd45b6,0x9122b13c,0x3e7ad9b6,0xe6f57a48,0x342ca118,0x06f8288f,0x1c2e94a7
.long	0x5a97d231,0x99e68f07,0x4d838758,0x7c80de97,0x05872727,0xbce0f5d0,0x19c4d016,0xbe5d95c2,0x9c2492ee,0x921d5cb1,0x404d6fb3,0x42192dc1,0x32f988d3,0x4c84dcd1,0xa17b8e85,0xde26d61f
.long	0x137c7408,0xc466dcb6,0x36a266da,0x9a38d7b6,0x83bebf1b,0x7ef5cb06,0x0fd014e3,0xe5cdcbbf,0xf65965a0,0x30aa376d,0xebb3e95e,0x60fe88c2,0x66ee6f20,0x33fd0b61,0x3f41f0a0,0x8827dcdb
.long	0x0c56c690,0xbf8a9d24,0xddb7641d,0x40265dad,0x3a6b662b,0x522b05bf,0xb1478c9b,0x466d1dfe,0x1484469b,0xaa616962,0x02df8f9f,0x0db60549,0x3cb8bf51,0xc37bca02,0x21371ce8,0x5effe346
.long	0xff112c32,0xe8f65264,0x7b971fb2,0x8a9c736d,0x7b75080d,0xa4f19470,0x8839c59b,0xfc3f2c5a,0x5aeb49c2,0x1d6c777e,0xda1addfe,0xf3db034d,0x5535affc,0xd76fee5a,0xb92251fd,0x0853ac70
.long	0x8b2a29d5,0x37e3d594,0x4de00ddb,0x28f1f457,0xf42c328b,0x8083c1b5,0xe493c73b,0xd8ef1d8f,0x41dc61bd,0x96fb6260,0x27ee2f8a,0xf74e8a9d,0x2c946a5d,0x7c605a80,0x3839ccfd,0xeed48d65
.long	0x3a29467a,0x9894344f,0xc51eba6d,0xde81e949,0xa5e5c2f2,0xdaea066b,0x08c8c7b3,0x3fc8a614,0x06d0de9f,0x7adff88f,0x3b75ce0a,0xbbc11cf5,0xfbbc87d5,0x9fbb7acc,0x7badfde2,0xa1458e26
.long	0xe039c256,0x1cb43668,0x7c17fd5d,0x5f26fb8b,0x79aa062b,0xeee426af,0xd78fbf04,0x072002d0,0xe84fb7e3,0x4c9ca237,0x0c82133d,0xb401d8a1,0x6d7e4181,0xaaa52592,0x73dbb152,0xe9430833
.long	0xbe24319a,0xf92dda31,0xe095a8e7,0x03f7d28b,0x98782185,0xa52fe840,0x29c24dbc,0x276ddafe,0x1d7a64eb,0x80cd5496,0x7f1dbe42,0xe4360889,0x8438d2d5,0x2f81a877,0x85169036,0x7e4d52a8
.long	0x1d59715d,0x19e3d5b1,0xd788983e,0xc7eaa762,0xabf1f248,0xe5a730b0,0xfae3fd83,0xfbab8084,0x53765b2f,0x65e50d21,0xfa127f3d,0xbdd4e083,0x397b1b10,0x9cf3c074,0xb1b59fd3,0x59f8090c
.long	0x615faa8f,0x7b15fd9d,0x968554ed,0x8fa1eb40,0x7aa44882,0x7bb4447e,0x029fff32,0x2bb2d0d1,0x6caa6d2f,0x075e2a64,0x22e7351b,0x8eb879de,0x9a506c62,0xbcd5624e,0xa87e24dc,0x218eaef0
.long	0x44ddfa35,0x37e56847,0xdab3f747,0x9ccfc5c5,0x1ee96cf4,0x9ac1df3f,0x3b480b8f,0x0c0571a1,0x4b3a7b3c,0x2fbeb3d5,0x5dcdbb99,0x35c03669,0xb2415b3a,0x52a0f5dc,0x4413ed9a,0xd57759b4
.long	0x3d30a2c5,0x1fe647d8,0xf78a81dc,0x0857f77e,0x131a4a9b,0x11d5a334,0x29d393f5,0xc0a94af9,0xdaa6ec1a,0xbc3a5c0b,0x88d2d7ed,0xba9fe493,0xbb614797,0xbb4335b4,0x72f83533,0x991c4d68
.long	0xd2f01cb3,0x53258c28,0xd75db0b1,0x93d6eaa3,0xe87d0db4,0x419a2b0d,0xd8fe8493,0xa1e48f03,0xc508b23a,0xf747faf6,0x35d53549,0xf137571a,0xfcf9b838,0x9f5e58e2,0xa7fd3cf5,0xc7186cee
.long	0xe978a1d3,0x77b868ce,0x7ab92d04,0xe3a68b33,0x87a5b862,0x51029794,0x3a61d41d,0x5f0606c3,0x6f9326f1,0x2814be27,0xc6fe3c2e,0x2f521c14,0xacdf7351,0x17464d7d,0x777f7e44,0x10f5f9d3
.long	0x269fb37d,0xce8e616b,0x7de62de5,0xaaf73804,0x4fdd4153,0xaba11175,0x3770b49b,0x515759ba,0xaa423a61,0x8b09ebf8,0xcd41fb92,0x592245a1,0x9b4c8936,0x1cba8ec1,0xaf36710e,0xa87e91e3
.long	0x3d34a2e3,0x1fd84ce4,0xb43b5d61,0xee3759ce,0x619186c7,0x895bc78c,0xcbb9725a,0xf19c3809,0xde744b1f,0xc0be21aa,0x60f8056b,0xa7d222b0,0xb23efe11,0x74be6157,0x0cd68253,0x6fab2b4f
.long	0x4bf1d725,0xad33ea5f,0x4f6c950f,0x9c1d8ee2,0xa377af06,0x544ee78a,0x94a113e1,0x54f489bb,0x992fb7e8,0x8f11d634,0xa2a44347,0x0169a7aa,0x95020e00,0x1d49d4af,0xe08e120b,0x95945722
.long	0xa4d32282,0xb6e33878,0x48020ae7,0xe36e029d,0x37a9b7