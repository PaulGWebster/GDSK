dqa	%xmm12,%xmm7
	prefetcht0	63(%r9)

	por	%xmm9,%xmm8
	pslld	$30,%xmm7
	paddd	%xmm6,%xmm10
	prefetcht0	63(%r10)

	psrld	$2,%xmm12
	paddd	%xmm8,%xmm10
.byte	102,15,56,0,197
	prefetcht0	63(%r11)
	por	%xmm7,%xmm12
	movdqa	16-128(%rax),%xmm2
	pxor	%xmm3,%xmm1
	movdqa	32-128(%rax),%xmm3

	movdqa	%xmm10,%xmm8
	pxor	128-128(%rax),%xmm1
	paddd	%xmm15,%xmm14
	movdqa	%xmm11,%xmm7
	pslld	$5,%xmm8
	pxor	%xmm3,%xmm1
	movdqa	%xmm11,%xmm6
	pandn	%xmm13,%xmm7
	movdqa	%xmm1,%xmm5
	pand	%xmm12,%xmm6
	movdqa	%xmm10,%xmm9
	psrld	$31,%xmm5
	paddd	%xmm1,%xmm1

	movdqa	%xmm0,240-128(%rax)
	paddd	%xmm0,%xmm14
	psrld	$27,%xmm9
	pxor	%xmm7,%xmm6

	movdqa	%xmm11,%xmm7
	por	%xmm9,%xmm8
	pslld	$30,%xmm7
	paddd	%xmm6,%xmm14

	psrld	$2,%xmm11
	paddd	%xmm8,%xmm14
	por	%xmm5,%xmm1
	por	%xmm7,%xmm11
	pxor	%xmm4,%xmm2
	movdqa	48-128(%rax),%xmm4

	movdqa	%xmm14,%xmm8
	pxor	144-128(%rax),%xmm2
	paddd	%xmm15,%xmm13
	movdqa	%xmm10,%xmm7
	pslld	$5,%xmm8
	pxor	%xmm4,%xmm2
	movdqa	%xmm10,%xmm6
	pandn	%xmm12,%xmm7
	movdqa	%xmm2,%xmm5
	pand	%xmm11,%xmm6
	movdqa	%xmm14,%xmm9
	psrld	$31,%xmm5
	paddd	%xmm2,%xmm2

	movdqa	%xmm1,0-128(%rax)
	paddd	%xmm1,%xmm13
	psrld	$27,%xmm9
	pxor	%xmm7,%xmm6

	movdqa	%xmm10,%xmm7
	por	%xmm9,%xmm8
	pslld	$30,%xmm7
	paddd	%xmm6,%xmm13

	psrld	$2,%xmm10
	paddd	%xmm8,%xmm13
	por	%xmm5,%xmm2
	por	%xmm7,%xmm10
	pxor	%xmm0,%xmm3
	movdqa	64-128(%rax),%xmm0

	movdqa	%xmm13,%xmm8
	pxor	160-128(%rax),%xmm3
	paddd	%xmm15,%xmm12
	movdqa	%xmm14,%xmm7
	pslld	$5,%xmm8
	pxor	%xmm0,%xmm3
	movdqa	%xmm14,%xmm6
	pandn	%xmm11,%xmm7
	movdqa	%xmm3,%xmm5
	pand	%xmm10,%xmm6
	movdqa	%xmm13,%xmm9
	psrld	$31,%xmm5
	paddd	%xmm3,%xmm3

	movdqa	%xmm2,16-128(%rax)
	paddd	%xmm2,%xmm12
	psrld	$27,%xmm9
	pxor	%xmm7,%xmm6

	movdqa	%xmm14,%xmm7
	por	%xmm9,%xmm8
	pslld	$30,%xmm7
	paddd	%xmm6,%xmm12

	psrld	$2,%xmm14
	paddd	%xmm8,%xmm12
	por	%xmm5,%xmm3
	por	%xmm7,%xmm14
	pxor	%xmm1,%xmm4
	movdqa	80-128(%rax),%xmm1

	movdqa	%xmm12,%xmm8
	pxor	176-128(%rax),%xmm4
	paddd	%xmm15,%xmm11
	movdqa	%xmm13,%xmm7
	pslld	$5,%xmm8
	pxor	%xmm1,%xmm4
	movdqa	%xmm13,%xmm6
	pandn	%xmm10,%xmm7
	movdqa	%xmm4,%xmm5
	pand	%xmm14,%xmm6
	movdqa	%xmm12,%xmm9
	psrld	$31,%xmm5
	paddd	%xmm4,%xmm4

	movdqa	%xmm3,32-128(%rax)
	paddd	%xmm3,%xmm11
	psrld	$27,%xmm9
	pxor	%xmm7,%xmm6

	movdqa	%xmm13,%xmm7
	por	%xmm9,%xmm8
	pslld	$30,%xmm7
	paddd	%xmm6,%xmm11

	psrld	$2,%xmm13
	paddd	%xmm8,%xmm11
	por	%xmm5,%xmm4
	por	%xmm7,%xmm13
	pxor	%xmm2,%xmm0
	movdqa	96-128(%rax),%xmm2

	movdqa	%xmm11,%xmm8
	pxor	192-128(%rax),%xmm0
	paddd	%xmm15,%xmm10
	movdqa	%xmm12,%xmm7
	pslld	$5,%xmm8
	pxor	%xmm2,%xmm0
	movdqa	%xmm12,%xmm6
	pandn	%xmm14,%xmm7
	movdqa	%xmm0,%xmm5
	pand	%xmm13,%xmm6
	movdqa	%xmm11,%xmm9
	psrld	$31,%xmm5
	paddd	%xmm0,%xmm0

	movdqa	%xmm4,48-128(%rax)
	paddd	%xmm4,%xmm10
	psrld	$27,%xmm9
	pxor	%xmm7,%xmm6

	movdqa	%xmm12,%xmm7
	por	%xmm9,%xmm8
	pslld	$30,%xmm7
	paddd	%xmm6,%xmm10

	psrld	$2,%xmm12
	paddd	%xmm8,%xmm10
	por	%xmm5,%xmm0
	por	%xmm7,%xmm12
	movdqa	0(%rbp),%xmm15
	pxor	%xmm3,%xmm1
	movdqa	112-128(%rax),%xmm3

	movdqa	%xmm10,%xmm8
	movdqa	%xmm13,%xmm6
	pxor	208-128(%rax),%xmm1
	paddd	%xmm15,%xmm14
	pslld	$5,%xmm8
	pxor	%xmm11,%xmm6

	movdqa	%xmm10,%xmm9
	movdqa	%xmm0,64-128(%rax)
	paddd	%xmm0,%xmm14
	pxor	%xmm3,%xmm1
	psrld	$27,%xmm9
	pxor	%xmm12,%xmm6
	movdqa	%xmm11,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm1,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm14
	paddd	%xmm1,%xmm1

	psrld	$2,%xmm11
	paddd	%xmm8,%xmm14
	por	%xmm5,%xmm1
	por	%xmm7,%xmm11
	pxor	%xmm4,%xmm2
	movdqa	128-128(%rax),%xmm4

	movdqa	%xmm14,%xmm8
	movdqa	%xmm12,%xmm6
	pxor	224-128(%rax),%xmm2
	paddd	%xmm15,%xmm13
	pslld	$5,%xmm8
	pxor	%xmm10,%xmm6

	movdqa	%xmm14,%xmm9
	movdqa	%xmm1,80-128(%rax)
	paddd	%xmm1,%xmm13
	pxor	%xmm4,%xmm2
	psrld	$27,%xmm9
	pxor	%xmm11,%xmm6
	movdqa	%xmm10,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm2,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm13
	paddd	%xmm2,%xmm2

	psrld	$2,%xmm10
	paddd	%xmm8,%xmm13
	por	%xmm5,%xmm2
	por	%xmm7,%xmm10
	pxor	%xmm0,%xmm3
	movdqa	144-128(%rax),%xmm0

	movdqa	%xmm13,%xmm8
	movdqa	%xmm11,%xmm6
	pxor	240-128(%rax),%xmm3
	paddd	%xmm15,%xmm12
	pslld	$5,%xmm8
	pxor	%xmm14,%xmm6

	movdqa	%xmm13,%xmm9
	movdqa	%xmm2,96-128(%rax)
	paddd	%xmm2,%xmm12
	pxor	%xmm0,%xmm3
	psrld	$27,%xmm9
	pxor	%xmm10,%xmm6
	movdqa	%xmm14,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm3,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm12
	paddd	%xmm3,%xmm3

	psrld	$2,%xmm14
	paddd	%xmm8,%xmm12
	por	%xmm5,%xmm3
	por	%xmm7,%xmm14
	pxor	%xmm1,%xmm4
	movdqa	160-128(%rax),%xmm1

	movdqa	%xmm12,%xmm8
	movdqa	%xmm10,%xmm6
	pxor	0-128(%rax),%xmm4
	paddd	%xmm15,%xmm11
	pslld	$5,%xmm8
	pxor	%xmm13,%xmm6

	movdqa	%xmm12,%xmm9
	movdqa	%xmm3,112-128(%rax)
	paddd	%xmm3,%xmm11
	pxor	%xmm1,%xmm4
	psrld	$27,%xmm9
	pxor	%xmm14,%xmm6
	movdqa	%xmm13,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm4,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm11
	paddd	%xmm4,%xmm4

	psrld	$2,%xmm13
	paddd	%xmm8,%xmm11
	por	%xmm5,%xmm4
	por	%xmm7,%xmm13
	pxor	%xmm2,%xmm0
	movdqa	176-128(%rax),%xmm2

	movdqa	%xmm11,%xmm8
	movdqa	%xmm14,%xmm6
	pxor	16-128(%rax),%xmm0
	paddd	%xmm15,%xmm10
	pslld	$5,%xmm8
	pxor	%xmm12,%xmm6

	movdqa	%xmm11,%xmm9
	movdqa	%xmm4,128-128(%rax)
	paddd	%xmm4,%xmm10
	pxor	%xmm2,%xmm0
	psrld	$27,%xmm9
	pxor	%xmm13,%xmm6
	movdqa	%xmm12,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm0,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm10
	paddd	%xmm0,%xmm0

	psrld	$2,%xmm12
	paddd	%xmm8,%xmm10
	por	%xmm5,%xmm0
	por	%xmm7,%xmm12
	pxor	%xmm3,%xmm1
	movdqa	192-128(%rax),%xmm3

	movdqa	%xmm10,%xmm8
	movdqa	%xmm13,%xmm6
	pxor	32-128(%rax),%xmm1
	paddd	%xmm15,%xmm14
	pslld	$5,%xmm8
	pxor	%xmm11,%xmm6

	movdqa	%xmm10,%xmm9
	movdqa	%xmm0,144-128(%rax)
	paddd	%xmm0,%xmm14
	pxor	%xmm3,%xmm1
	psrld	$27,%xmm9
	pxor	%xmm12,%xmm6
	movdqa	%xmm11,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm1,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm14
	paddd	%xmm1,%xmm1

	psrld	$2,%xmm11
	paddd	%xmm8,%xmm14
	por	%xmm5,%xmm1
	por	%xmm7,%xmm11
	pxor	%xmm4,%xmm2
	movdqa	208-128(%rax),%xmm4

	movdqa	%xmm14,%xmm8
	movdqa	%xmm12,%xmm6
	pxor	48-128(%rax),%xmm2
	paddd	%xmm15,%xmm13
	pslld	$5,%xmm8
	pxor	%xmm10,%xmm6

	movdqa	%xmm14,%xmm9
	movdqa	%xmm1,160-128(%rax)
	paddd	%xmm1,%xmm13
	pxor	%xmm4,%xmm2
	psrld	$27,%xmm9
	pxor	%xmm11,%xmm6
	movdqa	%xmm10,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm2,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm13
	paddd	%xmm2,%xmm2

	psrld	$2,%xmm10
	paddd	%xmm8,%xmm13
	por	%xmm5,%xmm2
	por	%xmm7,%xmm10
	pxor	%xmm0,%xmm3
	movdqa	224-128(%rax),%xmm0

	movdqa	%xmm13,%xmm8
	movdqa	%xmm11,%xmm6
	pxor	64-128(%rax),%xmm3
	paddd	%xmm15,%xmm12
	pslld	$5,%xmm8
	pxor	%xmm14,%xmm6

	movdqa	%xmm13,%xmm9
	movdqa	%xmm2,176-128(%rax)
	paddd	%xmm2,%xmm12
	pxor	%xmm0,%xmm3
	psrld	$27,%xmm9
	pxor	%xmm10,%xmm6
	movdqa	%xmm14,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm3,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm12
	paddd	%xmm3,%xmm3

	psrld	$2,%xmm14
	paddd	%xmm8,%xmm12
	por	%xmm5,%xmm3
	por	%xmm7,%xmm14
	pxor	%xmm1,%xmm4
	movdqa	240-128(%rax),%xmm1

	movdqa	%xmm12,%xmm8
	movdqa	%xmm10,%xmm6
	pxor	80-128(%rax),%xmm4
	paddd	%xmm15,%xmm11
	pslld	$5,%xmm8
	pxor	%xmm13,%xmm6

	movdqa	%xmm12,%xmm9
	movdqa	%xmm3,192-128(%rax)
	paddd	%xmm3,%xmm11
	pxor	%xmm1,%xmm4
	psrld	$27,%xmm9
	pxor	%xmm14,%xmm6
	movdqa	%xmm13,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm4,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm11
	paddd	%xmm4,%xmm4

	psrld	$2,%xmm13
	paddd	%xmm8,%xmm11
	por	%xmm5,%xmm4
	por	%xmm7,%xmm13
	pxor	%xmm2,%xmm0
	movdqa	0-128(%rax),%xmm2

	movdqa	%xmm11,%xmm8
	movdqa	%xmm14,%xmm6
	pxor	96-128(%rax),%xmm0
	paddd	%xmm15,%xmm10
	pslld	$5,%xmm8
	pxor	%xmm12,%xmm6

	movdqa	%xmm11,%xmm9
	movdqa	%xmm4,208-128(%rax)
	paddd	%xmm4,%xmm10
	pxor	%xmm2,%xmm0
	psrld	$27,%xmm9
	pxor	%xmm13,%xmm6
	movdqa	%xmm12,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm0,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm10
	paddd	%xmm0,%xmm0

	psrld	$2,%xmm12
	paddd	%xmm8,%xmm10
	por	%xmm5,%xmm0
	por	%xmm7,%xmm12
	pxor	%xmm3,%xmm1
	movdqa	16-128(%rax),%xmm3

	movdqa	%xmm10,%xmm8
	movdqa	%xmm13,%xmm6
	pxor	112-128(%rax),%xmm1
	paddd	%xmm15,%xmm14
	pslld	$5,%xmm8
	pxor	%xmm11,%xmm6

	movdqa	%xmm10,%xmm9
	movdqa	%xmm0,224-128(%rax)
	paddd	%xmm0,%xmm14
	pxor	%xmm3,%xmm1
	psrld	$27,%xmm9
	pxor	%xmm12,%xmm6
	movdqa	%xmm11,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm1,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm14
	paddd	%xmm1,%xmm1

	psrld	$2,%xmm11
	paddd	%xmm8,%xmm14
	por	%xmm5,%xmm1
	por	%xmm7,%xmm11
	pxor	%xmm4,%xmm2
	movdqa	32-128(%rax),%xmm4

	movdqa	%xmm14,%xmm8
	movdqa	%xmm12,%xmm6
	pxor	128-128(%rax),%xmm2
	paddd	%xmm15,%xmm13
	pslld	$5,%xmm8
	pxor	%xmm10,%xmm6

	movdqa	%xmm14,%xmm9
	movdqa	%xmm1,240-128(%rax)
	paddd	%xmm1,%xmm13
	pxor	%xmm4,%xmm2
	psrld	$27,%xmm9
	pxor	%xmm11,%xmm6
	movdqa	%xmm10,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm2,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm13
	paddd	%xmm2,%xmm2

	psrld	$2,%xmm10
	paddd	%xmm8,%xmm13
	por	%xmm5,%xmm2
	por	%xmm7,%xmm10
	pxor	%xmm0,%xmm3
	movdqa	48-128(%rax),%xmm0

	movdqa	%xmm13,%xmm8
	movdqa	%xmm11,%xmm6
	pxor	144-128(%rax),%xmm3
	paddd	%xmm15,%xmm12
	pslld	$5,%xmm8
	pxor	%xmm14,%xmm6

	movdqa	%xmm13,%xmm9
	movdqa	%xmm2,0-128(%rax)
	paddd	%xmm2,%xmm12
	pxor	%xmm0,%xmm3
	psrld	$27,%xmm9
	pxor	%xmm10,%xmm6
	movdqa	%xmm14,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm3,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm12
	paddd	%xmm3,%xmm3

	psrld	$2,%xmm14
	paddd	%xmm8,%xmm12
	por	%xmm5,%xmm3
	por	%xmm7,%xmm14
	pxor	%xmm1,%xmm4
	movdqa	64-128(%rax),%xmm1

	movdqa	%xmm12,%xmm8
	movdqa	%xmm10,%xmm6
	pxor	160-128(%rax),%xmm4
	paddd	%xmm15,%xmm11
	pslld	$5,%xmm8
	pxor	%xmm13,%xmm6

	movdqa	%xmm12,%xmm9
	movdqa	%xmm3,16-128(%rax)
	paddd	%xmm3,%xmm11
	pxor	%xmm1,%xmm4
	psrld	$27,%xmm9
	pxor	%xmm14,%xmm6
	movdqa	%xmm13,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm4,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm11
	paddd	%xmm4,%xmm4

	psrld	$2,%xmm13
	paddd	%xmm8,%xmm11
	por	%xmm5,%xmm4
	por	%xmm7,%xmm13
	pxor	%xmm2,%xmm0
	movdqa	80-128(%rax),%xmm2

	movdqa	%xmm11,%xmm8
	movdqa	%xmm14,%xmm6
	pxor	176-128(%rax),%xmm0
	paddd	%xmm15,%xmm10
	pslld	$5,%xmm8
	pxor	%xmm12,%xmm6

	movdqa	%xmm11,%xmm9
	movdqa	%xmm4,32-128(%rax)
	paddd	%xmm4,%xmm10
	pxor	%xmm2,%xmm0
	psrld	$27,%xmm9
	pxor	%xmm13,%xmm6
	movdqa	%xmm12,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm0,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm10
	paddd	%xmm0,%xmm0

	psrld	$2,%xmm12
	paddd	%xmm8,%xmm10
	por	%xmm5,%xmm0
	por	%xmm7,%xmm12
	pxor	%xmm3,%xmm1
	movdqa	96-128(%rax),%xmm3

	movdqa	%xmm10,%xmm8
	movdqa	%xmm13,%xmm6
	pxor	192-128(%rax),%xmm1
	paddd	%xmm15,%xmm14
	pslld	$5,%xmm8
	pxor	%xmm11,%xmm6

	movdqa	%xmm10,%xmm9
	movdqa	%xmm0,48-128(%rax)
	paddd	%xmm0,%xmm14
	pxor	%xmm3,%xmm1
	psrld	$27,%xmm9
	pxor	%xmm12,%xmm6
	movdqa	%xmm11,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm1,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm14
	paddd	%xmm1,%xmm1

	psrld	$2,%xmm11
	paddd	%xmm8,%xmm14
	por	%xmm5,%xmm1
	por	%xmm7,%xmm11
	pxor	%xmm4,%xmm2
	movdqa	112-128(%rax),%xmm4

	movdqa	%xmm14,%xmm8
	movdqa	%xmm12,%xmm6
	pxor	208-128(%rax),%xmm2
	paddd	%xmm15,%xmm13
	pslld	$5,%xmm8
	pxor	%xmm10,%xmm6

	movdqa	%xmm14,%xmm9
	movdqa	%xmm1,64-128(%rax)
	paddd	%xmm1,%xmm13
	pxor	%xmm4,%xmm2
	psrld	$27,%xmm9
	pxor	%xmm11,%xmm6
	movdqa	%xmm10,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm2,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm13
	paddd	%xmm2,%xmm2

	psrld	$2,%xmm10
	paddd	%xmm8,%xmm13
	por	%xmm5,%xmm2
	por	%xmm7,%xmm10
	pxor	%xmm0,%xmm3
	movdqa	128-128(%rax),%xmm0

	movdqa	%xmm13,%xmm8
	movdqa	%xmm11,%xmm6
	pxor	224-128(%rax),%xmm3
	paddd	%xmm15,%xmm12
	pslld	$5,%xmm8
	pxor	%xmm14,%xmm6

	movdqa	%xmm13,%xmm9
	movdqa	%xmm2,80-128(%rax)
	paddd	%xmm2,%xmm12
	pxor	%xmm0,%xmm3
	psrld	$27,%xmm9
	pxor	%xmm10,%xmm6
	movdqa	%xmm14,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm3,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm12
	paddd	%xmm3,%xmm3

	psrld	$2,%xmm14
	paddd	%xmm8,%xmm12
	por	%xmm5,%xmm3
	por	%xmm7,%xmm14
	pxor	%xmm1,%xmm4
	movdqa	144-128(%rax),%xmm1

	movdqa	%xmm12,%xmm8
	movdqa	%xmm10,%xmm6
	pxor	240-128(%rax),%xmm4
	paddd	%xmm15,%xmm11
	pslld	$5,%xmm8
	pxor	%xmm13,%xmm6

	movdqa	%xmm12,%xmm9
	movdqa	%xmm3,96-128(%rax)
	paddd	%xmm3,%xmm11
	pxor	%xmm1,%xmm4
	psrld	$27,%xmm9
	pxor	%xmm14,%xmm6
	movdqa	%xmm13,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm4,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm11
	paddd	%xmm4,%xmm4

	psrld	$2,%xmm13
	paddd	%xmm8,%xmm11
	por	%xmm5,%xmm4
	por	%xmm7,%xmm13
	pxor	%xmm2,%xmm0
	movdqa	160-128(%rax),%xmm2

	movdqa	%xmm11,%xmm8
	movdqa	%xmm14,%xmm6
	pxor	0-128(%rax),%xmm0
	paddd	%xmm15,%xmm10
	pslld	$5,%xmm8
	pxor	%xmm12,%xmm6

	movdqa	%xmm11,%xmm9
	movdqa	%xmm4,112-128(%rax)
	paddd	%xmm4,%xmm10
	pxor	%xmm2,%xmm0
	psrld	$27,%xmm9
	pxor	%xmm13,%xmm6
	movdqa	%xmm12,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm0,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm10
	paddd	%xmm0,%xmm0

	psrld	$2,%xmm12
	paddd	%xmm8,%xmm10
	por	%xmm5,%xmm0
	por	%xmm7,%xmm12
	movdqa	32(%rbp),%xmm15
	pxor	%xmm3,%xmm1
	movdqa	176-128(%rax),%xmm3

	movdqa	%xmm10,%xmm8
	movdqa	%xmm13,%xmm7
	pxor	16-128(%rax),%xmm1
	pxor	%xmm3,%xmm1
	paddd	%xmm15,%xmm14
	pslld	$5,%xmm8
	movdqa	%xmm10,%xmm9
	pand	%xmm12,%xmm7

	movdqa	%xmm13,%xmm6
	movdqa	%xmm1,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm14
	pxor	%xmm12,%xmm6

	movdqa	%xmm0,128-128(%rax)
	paddd	%xmm0,%xmm14
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm11,%xmm6
	movdqa	%xmm11,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm1,%xmm1
	paddd	%xmm6,%xmm14

	psrld	$2,%xmm11
	paddd	%xmm8,%xmm14
	por	%xmm5,%xmm1
	por	%xmm7,%xmm11
	pxor	%xmm4,%xmm2
	movdqa	192-128(%rax),%xmm4

	movdqa	%xmm14,%xmm8
	movdqa	%xmm12,%xmm7
	pxor	32-128(%rax),%xmm2
	pxor	%xmm4,%xmm2
	paddd	%xmm15,%xmm13
	pslld	$5,%xmm8
	movdqa	%xmm14,%xmm9
	pand	%xmm11,%xmm7

	movdqa	%xmm12,%xmm6
	movdqa	%xmm2,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm13
	pxor	%xmm11,%xmm6

	movdqa	%xmm1,144-128(%rax)
	paddd	%xmm1,%xmm13
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm10,%xmm6
	movdqa	%xmm10,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm2,%xmm2
	paddd	%xmm6,%xmm13

	psrld	$2,%xmm10
	paddd	%xmm8,%xmm13
	por	%xmm5,%xmm2
	por	%xmm7,%xmm10
	pxor	%xmm0,%xmm3
	movdqa	208-128(%rax),%xmm0

	movdqa	%xmm13,%xmm8
	movdqa	%xmm11,%xmm7
	pxor	48-128(%rax),%xmm3
	pxor	%xmm0,%xmm3
	paddd	%xmm15,%xmm12
	pslld	$5,%xmm8
	movdqa	%xmm13,%xmm9
	pand	%xmm10,%xmm7

	movdqa	%xmm11,%xmm6
	movdqa	%xmm3,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm12
	pxor	%xmm10,%xmm6

	movdqa	%xmm2,160-128(%rax)
	paddd	%xmm2,%xmm12
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm14,%xmm6
	movdqa	%xmm14,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm3,%xmm3
	paddd	%xmm6,%xmm12

	psrld	$2,%xmm14
	paddd	%xmm8,%xmm12
	por	%xmm5,%xmm3
	por	%xmm7,%xmm14
	pxor	%xmm1,%xmm4
	movdqa	224-128(%rax),%xmm1

	movdqa	%xmm12,%xmm8
	movdqa	%xmm10,%xmm7
	pxor	64-128(%rax),%xmm4
	pxor	%xmm1,%xmm4
	paddd	%xmm15,%xmm11
	pslld	$5,%xmm8
	movdqa	%xmm12,%xmm9
	pand	%xmm14,%xmm7

	movdqa	%xmm10,%xmm6
	movdqa	%xmm4,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm11
	pxor	%xmm14,%xmm6

	movdqa	%xmm3,176-128(%rax)
	paddd	%xmm3,%xmm11
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm13,%xmm6
	movdqa	%xmm13,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm4,%xmm4
	paddd	%xmm6,%xmm11

	psrld	$2,%xmm13
	paddd	%xmm8,%xmm11
	por	%xmm5,%xmm4
	por	%xmm7,%xmm13
	pxor	%xmm2,%xmm0
	movdqa	240-128(%rax),%xmm2

	movdqa	%xmm11,%xmm8
	movdqa	%xmm14,%xmm7
	pxor	80-128(%rax),%xmm0
	pxor	%xmm2,%xmm0
	paddd	%xmm15,%xmm10
	pslld	$5,%xmm8
	movdqa	%xmm11,%xmm9
	pand	%xmm13,%xmm7

	movdqa	%xmm14,%xmm6
	movdqa	%xmm0,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm10
	pxor	%xmm13,%xmm6

	movdqa	%xmm4,192-128(%rax)
	paddd	%xmm4,%xmm10
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm12,%xmm6
	movdqa	%xmm12,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm0,%xmm0
	paddd	%xmm6,%xmm10

	psrld	$2,%xmm12
	paddd	%xmm8,%xmm10
	por	%xmm5,%xmm0
	por	%xmm7,%xmm12
	pxor	%xmm3,%xmm1
	movdqa	0-128(%rax),%xmm3

	movdqa	%xmm10,%xmm8
	movdqa	%xmm13,%xmm7
	pxor	96-128(%rax),%xmm1
	pxor	%xmm3,%xmm1
	paddd	%xmm15,%xmm14
	pslld	$5,%xmm8
	movdqa	%xmm10,%xmm9
	pand	%xmm12,%xmm7

	movdqa	%xmm13,%xmm6
	movdqa	%xmm1,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm14
	pxor	%xmm12,%xmm6

	movdqa	%xmm0,208-128(%rax)
	paddd	%xmm0,%xmm14
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm11,%xmm6
	movdqa	%xmm11,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm1,%xmm1
	paddd	%xmm6,%xmm14

	psrld	$2,%xmm11
	paddd	%xmm8,%xmm14
	por	%xmm5,%xmm1
	por	%xmm7,%xmm11
	pxor	%xmm4,%xmm2
	movdqa	16-128(%rax),%xmm4

	movdqa	%xmm14,%xmm8
	movdqa	%xmm12,%xmm7
	pxor	112-128(%rax),%xmm2
	pxor	%xmm4,%xmm2
	paddd	%xmm15,%xmm13
	pslld	$5,%xmm8
	movdqa	%xmm14,%xmm9
	pand	%xmm11,%xmm7

	movdqa	%xmm12,%xmm6
	movdqa	%xmm2,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm13
	pxor	%xmm11,%xmm6

	movdqa	%xmm1,224-128(%rax)
	paddd	%xmm1,%xmm13
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm10,%xmm6
	movdqa	%xmm10,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm2,%xmm2
	paddd	%xmm6,%xmm13

	psrld	$2,%xmm10
	paddd	%xmm8,%xmm13
	por	%xmm5,%xmm2
	por	%xmm7,%xmm10
	pxor	%xmm0,%xmm3
	movdqa	32-128(%rax),%xmm0

	movdqa	%xmm13,%xmm8
	movdqa	%xmm11,%xmm7
	pxor	128-128(%rax),%xmm3
	pxor	%xmm0,%xmm3
	paddd	%xmm15,%xmm12
	pslld	$5,%xmm8
	movdqa	%xmm13,%xmm9
	pand	%xmm10,%xmm7

	movdqa	%xmm11,%xmm6
	movdqa	%xmm3,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm12
	pxor	%xmm10,%xmm6

	movdqa	%xmm2,240-128(%rax)
	paddd	%xmm2,%xmm12
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm14,%xmm6
	movdqa	%xmm14,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm3,%xmm3
	paddd	%xmm6,%xmm12

	psrld	$2,%xmm14
	paddd	%xmm8,%xmm12
	por	%xmm5,%xmm3
	por	%xmm7,%xmm14
	pxor	%xmm1,%xmm4
	movdqa	48-128(%rax),%xmm1

	movdqa	%xmm12,%xmm8
	movdqa	%xmm10,%xmm7
	pxor	144-128(%rax),%xmm4
	pxor	%xmm1,%xmm4
	paddd	%xmm15,%xmm11
	pslld	$5,%xmm8
	movdqa	%xmm12,%xmm9
	pand	%xmm14,%xmm7

	movdqa	%xmm10,%xmm6
	movdqa	%xmm4,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm11
	pxor	%xmm14,%xmm6

	movdqa	%xmm3,0-128(%rax)
	paddd	%xmm3,%xmm11
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm13,%xmm6
	movdqa	%xmm13,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm4,%xmm4
	paddd	%xmm6,%xmm11

	psrld	$2,%xmm13
	paddd	%xmm8,%xmm11
	por	%xmm5,%xmm4
	por	%xmm7,%xmm13
	pxor	%xmm2,%xmm0
	movdqa	64-128(%rax),%xmm2

	movdqa	%xmm11,%xmm8
	movdqa	%xmm14,%xmm7
	pxor	160-128(%rax),%xmm0
	pxor	%xmm2,%xmm0
	paddd	%xmm15,%xmm10
	pslld	$5,%xmm8
	movdqa	%xmm11,%xmm9
	pand	%xmm13,%xmm7

	movdqa	%xmm14,%xmm6
	movdqa	%xmm0,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm10
	pxor	%xmm13,%xmm6

	movdqa	%xmm4,16-128(%rax)
	paddd	%xmm4,%xmm10
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm12,%xmm6
	movdqa	%xmm12,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm0,%xmm0
	paddd	%xmm6,%xmm10

	psrld	$2,%xmm12
	paddd	%xmm8,%xmm10
	por	%xmm5,%xmm0
	por	%xmm7,%xmm12
	pxor	%xmm3,%xmm1
	movdqa	80-128(%rax),%xmm3

	movdqa	%xmm10,%xmm8
	movdqa	%xmm13,%xmm7
	pxor	176-128(%rax),%xmm1
	pxor	%xmm3,%xmm1
	paddd	%xmm15,%xmm14
	pslld	$5,%xmm8
	movdqa	%xmm10,%xmm9
	pand	%xmm12,%xmm7

	movdqa	%xmm13,%xmm6
	movdqa	%xmm1,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm14
	pxor	%xmm12,%xmm6

	movdqa	%xmm0,32-128(%rax)
	paddd	%xmm0,%xmm14
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm11,%xmm6
	movdqa	%xmm11,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm1,%xmm1
	paddd	%xmm6,%xmm14

	psrld	$2,%xmm11
	paddd	%xmm8,%xmm14
	por	%xmm5,%xmm1
	por	%xmm7,%xmm11
	pxor	%xmm4,%xmm2
	movdqa	96-128(%rax),%xmm4

	movdqa	%xmm14,%xmm8
	movdqa	%xmm12,%xmm7
	pxor	192-128(%rax),%xmm2
	pxor	%xmm4,%xmm2
	paddd	%xmm15,%xmm13
	pslld	$5,%xmm8
	movdqa	%xmm14,%xmm9
	pand	%xmm11,%xmm7

	movdqa	%xmm12,%xmm6
	movdqa	%xmm2,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm13
	pxor	%xmm11,%xmm6

	movdqa	%xmm1,48-128(%rax)
	paddd	%xmm1,%xmm13
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm10,%xmm6
	movdqa	%xmm10,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm2,%xmm2
	paddd	%xmm6,%xmm13

	psrld	$2,%xmm10
	paddd	%xmm8,%xmm13
	por	%xmm5,%xmm2
	por	%xmm7,%xmm10
	pxor	%xmm0,%xmm3
	movdqa	112-128(%rax),%xmm0

	movdqa	%xmm13,%xmm8
	movdqa	%xmm11,%xmm7
	pxor	208-128(%rax),%xmm3
	pxor	%xmm0,%xmm3
	paddd	%xmm15,%xmm12
	pslld	$5,%xmm8
	movdqa	%xmm13,%xmm9
	pand	%xmm10,%xmm7

	movdqa	%xmm11,%xmm6
	movdqa	%xmm3,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm12
	pxor	%xmm10,%xmm6

	movdqa	%xmm2,64-128(%rax)
	paddd	%xmm2,%xmm12
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm14,%xmm6
	movdqa	%xmm14,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm3,%xmm3
	paddd	%xmm6,%xmm12

	psrld	$2,%xmm14
	paddd	%xmm8,%xmm12
	por	%xmm5,%xmm3
	por	%xmm7,%xmm14
	pxor	%xmm1,%xmm4
	movdqa	128-128(%rax),%xmm1

	movdqa	%xmm12,%xmm8
	movdqa	%xmm10,%xmm7
	pxor	224-128(%rax),%xmm4
	pxor	%xmm1,%xmm4
	paddd	%xmm15,%xmm11
	pslld	$5,%xmm8
	movdqa	%xmm12,%xmm9
	pand	%xmm14,%xmm7

	movdqa	%xmm10,%xmm6
	movdqa	%xmm4,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm11
	pxor	%xmm14,%xmm6

	movdqa	%xmm3,80-128(%rax)
	paddd	%xmm3,%xmm11
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm13,%xmm6
	movdqa	%xmm13,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm4,%xmm4
	paddd	%xmm6,%xmm11

	psrld	$2,%xmm13
	paddd	%xmm8,%xmm11
	por	%xmm5,%xmm4
	por	%xmm7,%xmm13
	pxor	%xmm2,%xmm0
	movdqa	144-128(%rax),%xmm2

	movdqa	%xmm11,%xmm8
	movdqa	%xmm14,%xmm7
	pxor	240-128(%rax),%xmm0
	pxor	%xmm2,%xmm0
	paddd	%xmm15,%xmm10
	pslld	$5,%xmm8
	movdqa	%xmm11,%xmm9
	pand	%xmm13,%xmm7

	movdqa	%xmm14,%xmm6
	movdqa	%xmm0,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm10
	pxor	%xmm13,%xmm6

	movdqa	%xmm4,96-128(%rax)
	paddd	%xmm4,%xmm10
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm12,%xmm6
	movdqa	%xmm12,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm0,%xmm0
	paddd	%xmm6,%xmm10

	psrld	$2,%xmm12
	paddd	%xmm8,%xmm10
	por	%xmm5,%xmm0
	por	%xmm7,%xmm12
	pxor	%xmm3,%xmm1
	movdqa	160-128(%rax),%xmm3

	movdqa	%xmm10,%xmm8
	movdqa	%xmm13,%xmm7
	pxor	0-128(%rax),%xmm1
	pxor	%xmm3,%xmm1
	paddd	%xmm15,%xmm14
	pslld	$5,%xmm8
	movdqa	%xmm10,%xmm9
	pand	%xmm12,%xmm7

	movdqa	%xmm13,%xmm6
	movdqa	%xmm1,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm14
	pxor	%xmm12,%xmm6

	movdqa	%xmm0,112-128(%rax)
	paddd	%xmm0,%xmm14
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm11,%xmm6
	movdqa	%xmm11,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm1,%xmm1
	paddd	%xmm6,%xmm14

	psrld	$2,%xmm11
	paddd	%xmm8,%xmm14
	por	%xmm5,%xmm1
	por	%xmm7,%xmm11
	pxor	%xmm4,%xmm2
	movdqa	176-128(%rax),%xmm4

	movdqa	%xmm14,%xmm8
	movdqa	%xmm12,%xmm7
	pxor	16-128(%rax),%xmm2
	pxor	%xmm4,%xmm2
	paddd	%xmm15,%xmm13
	pslld	$5,%xmm8
	movdqa	%xmm14,%xmm9
	pand	%xmm11,%xmm7

	movdqa	%xmm12,%xmm6
	movdqa	%xmm2,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm13
	pxor	%xmm11,%xmm6

	movdqa	%xmm1,128-128(%rax)
	paddd	%xmm1,%xmm13
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm10,%xmm6
	movdqa	%xmm10,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm2,%xmm2
	paddd	%xmm6,%xmm13

	psrld	$2,%xmm10
	paddd	%xmm8,%xmm13
	por	%xmm5,%xmm2
	por	%xmm7,%xmm10
	pxor	%xmm0,%xmm3
	movdqa	192-128(%rax),%xmm0

	movdqa	%xmm13,%xmm8
	movdqa	%xmm11,%xmm7
	pxor	32-128(%rax),%xmm3
	pxor	%xmm0,%xmm3
	paddd	%xmm15,%xmm12
	pslld	$5,%xmm8
	movdqa	%xmm13,%xmm9
	pand	%xmm10,%xmm7

	movdqa	%xmm11,%xmm6
	movdqa	%xmm3,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm12
	pxor	%xmm10,%xmm6

	movdqa	%xmm2,144-128(%rax)
	paddd	%xmm2,%xmm12
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm14,%xmm6
	movdqa	%xmm14,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm3,%xmm3
	paddd	%xmm6,%xmm12

	psrld	$2,%xmm14
	paddd	%xmm8,%xmm12
	por	%xmm5,%xmm3
	por	%xmm7,%xmm14
	pxor	%xmm1,%xmm4
	movdqa	208-128(%rax),%xmm1

	movdqa	%xmm12,%xmm8
	movdqa	%xmm10,%xmm7
	pxor	48-128(%rax),%xmm4
	pxor	%xmm1,%xmm4
	paddd	%xmm15,%xmm11
	pslld	$5,%xmm8
	movdqa	%xmm12,%xmm9
	pand	%xmm14,%xmm7

	movdqa	%xmm10,%xmm6
	movdqa	%xmm4,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm11
	pxor	%xmm14,%xmm6

	movdqa	%xmm3,160-128(%rax)
	paddd	%xmm3,%xmm11
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm13,%xmm6
	movdqa	%xmm13,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm4,%xmm4
	paddd	%xmm6,%xmm11

	psrld	$2,%xmm13
	paddd	%xmm8,%xmm11
	por	%xmm5,%xmm4
	por	%xmm7,%xmm13
	pxor	%xmm2,%xmm0
	movdqa	224-128(%rax),%xmm2

	movdqa	%xmm11,%xmm8
	movdqa	%xmm14,%xmm7
	pxor	64-128(%rax),%xmm0
	pxor	%xmm2,%xmm0
	paddd	%xmm15,%xmm10
	pslld	$5,%xmm8
	movdqa	%xmm11,%xmm9
	pand	%xmm13,%xmm7

	movdqa	%xmm14,%xmm6
	movdqa	%xmm0,%xmm5
	psrld	$27,%xmm9
	paddd	%xmm7,%xmm10
	pxor	%xmm13,%xmm6

	movdqa	%xmm4,176-128(%rax)
	paddd	%xmm4,%xmm10
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	pand	%xmm12,%xmm6
	movdqa	%xmm12,%xmm7

	pslld	$30,%xmm7
	paddd	%xmm0,%xmm0
	paddd	%xmm6,%xmm10

	psrld	$2,%xmm12
	paddd	%xmm8,%xmm10
	por	%xmm5,%xmm0
	por	%xmm7,%xmm12
	movdqa	64(%rbp),%xmm15
	pxor	%xmm3,%xmm1
	movdqa	240-128(%rax),%xmm3

	movdqa	%xmm10,%xmm8
	movdqa	%xmm13,%xmm6
	pxor	80-128(%rax),%xmm1
	paddd	%xmm15,%xmm14
	pslld	$5,%xmm8
	pxor	%xmm11,%xmm6

	movdqa	%xmm10,%xmm9
	movdqa	%xmm0,192-128(%rax)
	paddd	%xmm0,%xmm14
	pxor	%xmm3,%xmm1
	psrld	$27,%xmm9
	pxor	%xmm12,%xmm6
	movdqa	%xmm11,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm1,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm14
	paddd	%xmm1,%xmm1

	psrld	$2,%xmm11
	paddd	%xmm8,%xmm14
	por	%xmm5,%xmm1
	por	%xmm7,%xmm11
	pxor	%xmm4,%xmm2
	movdqa	0-128(%rax),%xmm4

	movdqa	%xmm14,%xmm8
	movdqa	%xmm12,%xmm6
	pxor	96-128(%rax),%xmm2
	paddd	%xmm15,%xmm13
	pslld	$5,%xmm8
	pxor	%xmm10,%xmm6

	movdqa	%xmm14,%xmm9
	movdqa	%xmm1,208-128(%rax)
	paddd	%xmm1,%xmm13
	pxor	%xmm4,%xmm2
	psrld	$27,%xmm9
	pxor	%xmm11,%xmm6
	movdqa	%xmm10,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm2,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm13
	paddd	%xmm2,%xmm2

	psrld	$2,%xmm10
	paddd	%xmm8,%xmm13
	por	%xmm5,%xmm2
	por	%xmm7,%xmm10
	pxor	%xmm0,%xmm3
	movdqa	16-128(%rax),%xmm0

	movdqa	%xmm13,%xmm8
	movdqa	%xmm11,%xmm6
	pxor	112-128(%rax),%xmm3
	paddd	%xmm15,%xmm12
	pslld	$5,%xmm8
	pxor	%xmm14,%xmm6

	movdqa	%xmm13,%xmm9
	movdqa	%xmm2,224-128(%rax)
	paddd	%xmm2,%xmm12
	pxor	%xmm0,%xmm3
	psrld	$27,%xmm9
	pxor	%xmm10,%xmm6
	movdqa	%xmm14,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm3,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm12
	paddd	%xmm3,%xmm3

	psrld	$2,%xmm14
	paddd	%xmm8,%xmm12
	por	%xmm5,%xmm3
	por	%xmm7,%xmm14
	pxor	%xmm1,%xmm4
	movdqa	32-128(%rax),%xmm1

	movdqa	%xmm12,%xmm8
	movdqa	%xmm10,%xmm6
	pxor	128-128(%rax),%xmm4
	paddd	%xmm15,%xmm11
	pslld	$5,%xmm8
	pxor	%xmm13,%xmm6

	movdqa	%xmm12,%xmm9
	movdqa	%xmm3,240-128(%rax)
	paddd	%xmm3,%xmm11
	pxor	%xmm1,%xmm4
	psrld	$27,%xmm9
	pxor	%xmm14,%xmm6
	movdqa	%xmm13,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm4,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm11
	paddd	%xmm4,%xmm4

	psrld	$2,%xmm13
	paddd	%xmm8,%xmm11
	por	%xmm5,%xmm4
	por	%xmm7,%xmm13
	pxor	%xmm2,%xmm0
	movdqa	48-128(%rax),%xmm2

	movdqa	%xmm11,%xmm8
	movdqa	%xmm14,%xmm6
	pxor	144-128(%rax),%xmm0
	paddd	%xmm15,%xmm10
	pslld	$5,%xmm8
	pxor	%xmm12,%xmm6

	movdqa	%xmm11,%xmm9
	movdqa	%xmm4,0-128(%rax)
	paddd	%xmm4,%xmm10
	pxor	%xmm2,%xmm0
	psrld	$27,%xmm9
	pxor	%xmm13,%xmm6
	movdqa	%xmm12,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm0,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm10
	paddd	%xmm0,%xmm0

	psrld	$2,%xmm12
	paddd	%xmm8,%xmm10
	por	%xmm5,%xmm0
	por	%xmm7,%xmm12
	pxor	%xmm3,%xmm1
	movdqa	64-128(%rax),%xmm3

	movdqa	%xmm10,%xmm8
	movdqa	%xmm13,%xmm6
	pxor	160-128(%rax),%xmm1
	paddd	%xmm15,%xmm14
	pslld	$5,%xmm8
	pxor	%xmm11,%xmm6

	movdqa	%xmm10,%xmm9
	movdqa	%xmm0,16-128(%rax)
	paddd	%xmm0,%xmm14
	pxor	%xmm3,%xmm1
	psrld	$27,%xmm9
	pxor	%xmm12,%xmm6
	movdqa	%xmm11,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm1,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm14
	paddd	%xmm1,%xmm1

	psrld	$2,%xmm11
	paddd	%xmm8,%xmm14
	por	%xmm5,%xmm1
	por	%xmm7,%xmm11
	pxor	%xmm4,%xmm2
	movdqa	80-128(%rax),%xmm4

	movdqa	%xmm14,%xmm8
	movdqa	%xmm12,%xmm6
	pxor	176-128(%rax),%xmm2
	paddd	%xmm15,%xmm13
	pslld	$5,%xmm8
	pxor	%xmm10,%xmm6

	movdqa	%xmm14,%xmm9
	movdqa	%xmm1,32-128(%rax)
	paddd	%xmm1,%xmm13
	pxor	%xmm4,%xmm2
	psrld	$27,%xmm9
	pxor	%xmm11,%xmm6
	movdqa	%xmm10,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm2,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm13
	paddd	%xmm2,%xmm2

	psrld	$2,%xmm10
	paddd	%xmm8,%xmm13
	por	%xmm5,%xmm2
	por	%xmm7,%xmm10
	pxor	%xmm0,%xmm3
	movdqa	96-128(%rax),%xmm0

	movdqa	%xmm13,%xmm8
	movdqa	%xmm11,%xmm6
	pxor	192-128(%rax),%xmm3
	paddd	%xmm15,%xmm12
	pslld	$5,%xmm8
	pxor	%xmm14,%xmm6

	movdqa	%xmm13,%xmm9
	movdqa	%xmm2,48-128(%rax)
	paddd	%xmm2,%xmm12
	pxor	%xmm0,%xmm3
	psrld	$27,%xmm9
	pxor	%xmm10,%xmm6
	movdqa	%xmm14,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm3,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm12
	paddd	%xmm3,%xmm3

	psrld	$2,%xmm14
	paddd	%xmm8,%xmm12
	por	%xmm5,%xmm3
	por	%xmm7,%xmm14
	pxor	%xmm1,%xmm4
	movdqa	112-128(%rax),%xmm1

	movdqa	%xmm12,%xmm8
	movdqa	%xmm10,%xmm6
	pxor	208-128(%rax),%xmm4
	paddd	%xmm15,%xmm11
	pslld	$5,%xmm8
	pxor	%xmm13,%xmm6

	movdqa	%xmm12,%xmm9
	movdqa	%xmm3,64-128(%rax)
	paddd	%xmm3,%xmm11
	pxor	%xmm1,%xmm4
	psrld	$27,%xmm9
	pxor	%xmm14,%xmm6
	movdqa	%xmm13,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm4,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm11
	paddd	%xmm4,%xmm4

	psrld	$2,%xmm13
	paddd	%xmm8,%xmm11
	por	%xmm5,%xmm4
	por	%xmm7,%xmm13
	pxor	%xmm2,%xmm0
	movdqa	128-128(%rax),%xmm2

	movdqa	%xmm11,%xmm8
	movdqa	%xmm14,%xmm6
	pxor	224-128(%rax),%xmm0
	paddd	%xmm15,%xmm10
	pslld	$5,%xmm8
	pxor	%xmm12,%xmm6

	movdqa	%xmm11,%xmm9
	movdqa	%xmm4,80-128(%rax)
	paddd	%xmm4,%xmm10
	pxor	%xmm2,%xmm0
	psrld	$27,%xmm9
	pxor	%xmm13,%xmm6
	movdqa	%xmm12,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm0,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm10
	paddd	%xmm0,%xmm0

	psrld	$2,%xmm12
	paddd	%xmm8,%xmm10
	por	%xmm5,%xmm0
	por	%xmm7,%xmm12
	pxor	%xmm3,%xmm1
	movdqa	144-128(%rax),%xmm3

	movdqa	%xmm10,%xmm8
	movdqa	%xmm13,%xmm6
	pxor	240-128(%rax),%xmm1
	paddd	%xmm15,%xmm14
	pslld	$5,%xmm8
	pxor	%xmm11,%xmm6

	movdqa	%xmm10,%xmm9
	movdqa	%xmm0,96-128(%rax)
	paddd	%xmm0,%xmm14
	pxor	%xmm3,%xmm1
	psrld	$27,%xmm9
	pxor	%xmm12,%xmm6
	movdqa	%xmm11,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm1,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm14
	paddd	%xmm1,%xmm1

	psrld	$2,%xmm11
	paddd	%xmm8,%xmm14
	por	%xmm5,%xmm1
	por	%xmm7,%xmm11
	pxor	%xmm4,%xmm2
	movdqa	160-128(%rax),%xmm4

	movdqa	%xmm14,%xmm8
	movdqa	%xmm12,%xmm6
	pxor	0-128(%rax),%xmm2
	paddd	%xmm15,%xmm13
	pslld	$5,%xmm8
	pxor	%xmm10,%xmm6

	movdqa	%xmm14,%xmm9
	movdqa	%xmm1,112-128(%rax)
	paddd	%xmm1,%xmm13
	pxor	%xmm4,%xmm2
	psrld	$27,%xmm9
	pxor	%xmm11,%xmm6
	movdqa	%xmm10,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm2,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm13
	paddd	%xmm2,%xmm2

	psrld	$2,%xmm10
	paddd	%xmm8,%xmm13
	por	%xmm5,%xmm2
	por	%xmm7,%xmm10
	pxor	%xmm0,%xmm3
	movdqa	176-128(%rax),%xmm0

	movdqa	%xmm13,%xmm8
	movdqa	%xmm11,%xmm6
	pxor	16-128(%rax),%xmm3
	paddd	%xmm15,%xmm12
	pslld	$5,%xmm8
	pxor	%xmm14,%xmm6

	movdqa	%xmm13,%xmm9
	paddd	%xmm2,%xmm12
	pxor	%xmm0,%xmm3
	psrld	$27,%xmm9
	pxor	%xmm10,%xmm6
	movdqa	%xmm14,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm3,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm12
	paddd	%xmm3,%xmm3

	psrld	$2,%xmm14
	paddd	%xmm8,%xmm12
	por	%xmm5,%xmm3
	por	%xmm7,%xmm14
	pxor	%xmm1,%xmm4
	movdqa	192-128(%rax),%xmm1

	movdqa	%xmm12,%xmm8
	movdqa	%xmm10,%xmm6
	pxor	32-128(%rax),%xmm4
	paddd	%xmm15,%xmm11
	pslld	$5,%xmm8
	pxor	%xmm13,%xmm6

	movdqa	%xmm12,%xmm9
	paddd	%xmm3,%xmm11
	pxor	%xmm1,%xmm4
	psrld	$27,%xmm9
	pxor	%xmm14,%xmm6
	movdqa	%xmm13,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm4,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm11
	paddd	%xmm4,%xmm4

	psrld	$2,%xmm13
	paddd	%xmm8,%xmm11
	por	%xmm5,%xmm4
	por	%xmm7,%xmm13
	pxor	%xmm2,%xmm0
	movdqa	208-128(%rax),%xmm2

	movdqa	%xmm11,%xmm8
	movdqa	%xmm14,%xmm6
	pxor	48-128(%rax),%xmm0
	paddd	%xmm15,%xmm10
	pslld	$5,%xmm8
	pxor	%xmm12,%xmm6

	movdqa	%xmm11,%xmm9
	paddd	%xmm4,%xmm10
	pxor	%xmm2,%xmm0
	psrld	$27,%xmm9
	pxor	%xmm13,%xmm6
	movdqa	%xmm12,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm0,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm10
	paddd	%xmm0,%xmm0

	psrld	$2,%xmm12
	paddd	%xmm8,%xmm10
	por	%xmm5,%xmm0
	por	%xmm7,%xmm12
	pxor	%xmm3,%xmm1
	movdqa	224-128(%rax),%xmm3

	movdqa	%xmm10,%xmm8
	movdqa	%xmm13,%xmm6
	pxor	64-128(%rax),%xmm1
	paddd	%xmm15,%xmm14
	pslld	$5,%xmm8
	pxor	%xmm11,%xmm6

	movdqa	%xmm10,%xmm9
	paddd	%xmm0,%xmm14
	pxor	%xmm3,%xmm1
	psrld	$27,%xmm9
	pxor	%xmm12,%xmm6
	movdqa	%xmm11,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm1,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm14
	paddd	%xmm1,%xmm1

	psrld	$2,%xmm11
	paddd	%xmm8,%xmm14
	por	%xmm5,%xmm1
	por	%xmm7,%xmm11
	pxor	%xmm4,%xmm2
	movdqa	240-128(%rax),%xmm4

	movdqa	%xmm14,%xmm8
	movdqa	%xmm12,%xmm6
	pxor	80-128(%rax),%xmm2
	paddd	%xmm15,%xmm13
	pslld	$5,%xmm8
	pxor	%xmm10,%xmm6

	movdqa	%xmm14,%xmm9
	paddd	%xmm1,%xmm13
	pxor	%xmm4,%xmm2
	psrld	$27,%xmm9
	pxor	%xmm11,%xmm6
	movdqa	%xmm10,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm2,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm13
	paddd	%xmm2,%xmm2

	psrld	$2,%xmm10
	paddd	%xmm8,%xmm13
	por	%xmm5,%xmm2
	por	%xmm7,%xmm10
	pxor	%xmm0,%xmm3
	movdqa	0-128(%rax),%xmm0

	movdqa	%xmm13,%xmm8
	movdqa	%xmm11,%xmm6
	pxor	96-128(%rax),%xmm3
	paddd	%xmm15,%xmm12
	pslld	$5,%xmm8
	pxor	%xmm14,%xmm6

	movdqa	%xmm13,%xmm9
	paddd	%xmm2,%xmm12
	pxor	%xmm0,%xmm3
	psrld	$27,%xmm9
	pxor	%xmm10,%xmm6
	movdqa	%xmm14,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm3,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm12
	paddd	%xmm3,%xmm3

	psrld	$2,%xmm14
	paddd	%xmm8,%xmm12
	por	%xmm5,%xmm3
	por	%xmm7,%xmm14
	pxor	%xmm1,%xmm4
	movdqa	16-128(%rax),%xmm1

	movdqa	%xmm12,%xmm8
	movdqa	%xmm10,%xmm6
	pxor	112-128(%rax),%xmm4
	paddd	%xmm15,%xmm11
	pslld	$5,%xmm8
	pxor	%xmm13,%xmm6

	movdqa	%xmm12,%xmm9
	paddd	%xmm3,%xmm11
	pxor	%xmm1,%xmm4
	psrld	$27,%xmm9
	pxor	%xmm14,%xmm6
	movdqa	%xmm13,%xmm7

	pslld	$30,%xmm7
	movdqa	%xmm4,%xmm5
	por	%xmm9,%xmm8
	psrld	$31,%xmm5
	paddd	%xmm6,%xmm11
	paddd	%xmm4,%xmm4

	psrld	$2,%xmm13
	paddd	%xmm8,%xmm11
	por	%xmm5,%xmm4
	por	%xmm7,%xmm13
	movdqa	%xmm11,%xmm8
	paddd	%xmm15,%xmm10
	movdqa	%xmm14,%xmm6
	pslld	$5,%xmm8
	pxor	%xmm12,%xmm6

	movdqa	%xmm11,%xmm9
	paddd	%xmm4,%xmm10
	psrld	$27,%xmm9
	movdqa	%xmm12,%xmm7
	pxor	%xmm13,%xmm6

	pslld	$30,%xmm7
	por	%xmm9,%xmm8
	paddd	%xmm6,%xmm10

	psrld	$2,%xmm12
	paddd	%xmm8,%xmm10
	por	%xmm7,%xmm12
	movdqa	(%rbx),%xmm0
	movl	$1,%ecx
	cmpl	0(%rbx),%ecx
	pxor	%xmm8,%xmm8
	cmovgeq	%rbp,%r8
	cmpl	4(%rbx),%ecx
	movdqa	%xmm0,%xmm1
	cmovgeq	%rbp,%r9
	cmpl	8(%rbx),%ecx
	pcmpgtd	%xmm8,%xmm1
	cmovgeq	%rbp,%r10
	cmpl	12(%rbx),%ecx
	paddd	%xmm1,%xmm0
	cmovgeq	%rbp,%r11

	movdqu	0(%rdi),%xmm6
	pand	%xmm1,%xmm10
	movdqu	32(%rdi),%xmm7
	pand	%xmm1,%xmm11
	paddd	%xmm6,%xmm10
	movdqu	64(%rdi),%xmm8
	pand	%xmm1,%xmm12
	paddd	%xmm7,%xmm11
	movdqu	96(%rdi),%xmm9
	pand	%xmm1,%xmm13
	paddd	%xmm8,%xmm12
	movdqu	128(%rdi),%xmm5
	pand	%xmm1,%xmm14
	movdqu	%xmm10,0(%rdi)
	paddd	%xmm9,%xmm13
	movdqu	%xmm11,32(%rdi)
	paddd	%xmm5,%xmm14
	movdqu	%xmm12,64(%rdi)
	movdqu	%xmm13,96(%rdi)
	movdqu	%xmm14,128(%rdi)

	movdqa	%xmm0,(%rbx)
	movdqa	96(%rbp),%xmm5
	movdqa	-32(%rbp),%xmm15
	decl	%edx
	jnz	.Loop

	movl	280(%rsp),%edx
	leaq	16(%rdi),%rdi
	leaq	64(%rsi),%rsi
	decl	%edx
	jnz	.Loop_grande

.Ldone:
	movq	272(%rsp),%rax
.cfi_def_cfa	%rax,8
	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha1_multi_block,.-sha1_multi_block
.type	sha1_multi_block_shaext,@function
.align	32
sha1_multi_block_shaext:
.cfi_startproc	
_shaext_shortcut:
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	subq	$288,%rsp
	shll	$1,%edx
	andq	$-256,%rsp
	leaq	64(%rdi),%rdi
	movq	%rax,272(%rsp)
.Lbody_shaext:
	leaq	256(%rsp),%rbx
	movdqa	K_XX_XX+128(%rip),%xmm3

.Loop_grande_shaext:
	movl	%edx,280(%rsp)
	xorl	%edx,%edx

	movq	0(%rsi),%r8

	movl	8(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,0(%rbx)
	cmovleq	%rsp,%r8

	movq	16(%rsi),%r9

	movl	24(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,4(%rbx)
	cmovleq	%rsp,%r9
	testl	%edx,%edx
	jz	.Ldone_shaext

	movq	0-64(%rdi),%xmm0
	movq	32-64(%rdi),%xmm4
	movq	64-64(%rdi),%xmm5
	movq	96-64(%rdi),%xmm6
	movq	128-64(%rdi),%xmm7

	punpckldq	%xmm4,%xmm0
	punpckldq	%xmm6,%xmm5

	movdqa	%xmm0,%xmm8
	punpcklqdq	%xmm5,%xmm0
	punpckhqdq	%xmm5,%xmm8

	pshufd	$63,%xmm7,%xmm1
	pshufd	$127,%xmm7,%xmm9
	pshufd	$27,%xmm0,%xmm0
	pshufd	$27,%xmm8,%xmm8
	jmp	.Loop_shaext

.align	32
.Loop_shaext:
	movdqu	0(%r8),%xmm4
	movdqu	0(%r9),%xmm11
	movdqu	16(%r8),%xmm5
	movdqu	16(%r9),%xmm12
	movdqu	32(%r8),%xmm6
.byte	102,15,56,0,227
	movdqu	32(%r9),%xmm13
.byte	102,68,15,56,0,219
	movdqu	48(%r8),%xmm7
	leaq	64(%r8),%r8
.byte	102,15,56,0,235
	movdqu	48(%r9),%xmm14
	leaq	64(%r9),%r9
.byte	102,68,15,56,0,227

	movdqa	%xmm1,80(%rsp)
	paddd	%xmm4,%xmm1
	movdqa	%xmm9,112(%rsp)
	paddd	%xmm11,%xmm9
	movdqa	%xmm0,64(%rsp)
	movdqa	%xmm0,%xmm2
	movdqa	%xmm8,96(%rsp)
	movdqa	%xmm8,%xmm10
.byte	15,58,204,193,0
.byte	15,56,200,213
.byte	69,15,58,204,193,0
.byte	69,15,56,200,212
.byte	102,15,56,0,243
	prefetcht0	127(%r8)
.byte	15,56,201,229
.byte	102,68,15,56,0,235
	prefetcht0	127(%r9)
.byte	69,15,56,201,220

.byte	102,15,56,0,251
	movdqa	%xmm0,%xmm1
.byte	102,68,15,56,0,243
	movdqa	%xmm8,%xmm9
.byte	15,58,204,194,0
.byte	15,56,200,206
.byte	69,15,58,204,194,0
.byte	69,15,56,200,205
	pxor	%xmm6,%xmm4
.byte	15,56,201,238
	pxor	%xmm13,%xmm11
.byte	69,15,56,201,229
	movdqa	%xmm0,%xmm2
	movdqa	%xmm8,%xmm10
.byte	15,58,204,193,0
.byte	15,56,200,215
.byte	69,15,58,204,193,0
.byte	69,15,56,200,214
.byte	15,56,202,231
.byte	69,15,56,202,222
	pxor	%xmm7,%xmm5
.byte	15,56,201,247
	pxor	%xmm14,%xmm12
.byte	69,15,56,201,238
	movdqa	%xmm0,%xmm1
	movdqa	%xmm8,%xmm9
.byte	15,58,204,194,0
.byte	15,56,200,204
.byte	69,15,58,204,194,0
.byte	69,15,56,200,203
.byte	15,56,202,236
.byte	69,15,56,202,227
	pxor	%xmm4,%xmm6
.byte	15,56,201,252
	pxor	%xmm11,%xmm13
.byte	69,15,56,201,243
	movdqa	%xmm0,%xmm2
	movdqa	%xmm8,%xmm10
.byte	15,58,204,193,0
.byte	15,56,200,213
.byte	69,15,58,204,193,0
.byte	69,15,56,200,212
.byte	15,56,202,245
.byte	69,15,56,202,236
	pxor	%xmm5,%xmm7
.byte	15,56,201,229
	pxor	%xmm12,%xmm14
.byte	69,15,56,201,220
	movdqa	%xmm0,%xmm1
	movdqa	%xmm8,%xmm9
.byte	15,58,204,194,1
.byte	15,56,200,206
.byte	69,15,58,204,194,1
.byte	69,15,56,200,205
.byte	15,56,202,254
.byte	69,15,56,202,245
	pxor	%xmm6,%xmm4
.byte	15,56,201,238
	pxor	%xmm13,%xmm11
.byte	69,15,56,201,229
	movdqa	%xmm0,%xmm2
	movdqa	%xmm8,%xmm10
.byte	15,58,204,193,1
.byte	15,56,200,215
.byte	69,15,58,204,193,1
.byte	69,15,56,200,214
.byte	15,56,202,231
.byte	69,15,56,202,222
	pxor	%xmm7,%xmm5
.byte	15,56,201,247
	pxor	%xmm14,%xmm12
.byte	69,15,56,201,238
	movdqa	%xmm0,%xmm1
	movdqa	%xmm8,%xmm9
.byte	15,58,204,194,1
.byte	15,56,200,204
.byte	69,15,58,204,194,1
.byte	69,15,56,200,203
.byte	15,56,202,236
.byte	69,15,56,202,227
	pxor	%xmm4,%xmm6
.byte	15,56,201,252
	pxor	%xmm11,%xmm13
.byte	69,15,56,201,243
	movdqa	%xmm0,%xmm2
	movdqa	%xmm8,%xmm10
.byte	15,58,204,193,1
.byte	15,56,200,213
.byte	69,15,58,204,193,1
.byte	69,15,56,200,212
.byte	15,56,202,245
.byte	69,15,56,202,236
	pxor	%xmm5,%xmm7
.byte	15,56,201,229
	pxor	%xmm12,%xmm14
.byte	69,15,56,201,220
	movdqa	%xmm0,%xmm1
	movdqa	%xmm8,%xmm9
.byte	15,58,204,194,1
.byte	15,56,200,206
.byte	69,15,58,204,194,1
.byte	69,15,56,200,205
.byte	15,56,202,254
.byte	69,15,56,202,245
	pxor	%xmm6,%xmm4
.byte	15,56,201,238
	pxor	%xmm13,%xmm11
.byte	69,15,56,201,229
	movdqa	%xmm0,%xmm2
	movdqa	%xmm8,%xmm10
.byte	15,58,204,193,2
.byte	15,56,200,215
.byte	69,15,58,204,193,2
.byte	69,15,56,200,214
.byte	15,56,202,231
.byte	69,15,56,202,222
	pxor	%xmm7,%xmm5
.byte	15,56,201,247
	pxor	%xmm14,%xmm12
.byte	69,15,56,201,238
	movdqa	%xmm0,%xmm1
	movdqa	%xmm8,%xmm9
.byte	15,58,204,194,2
.byte	15,56,200,204
.byte	69,15,58,204,194,2
.byte	69,15,56,200,203
.byte	15,56,202,236
.byte	69,15,56,202,227
	pxor	%xmm4,%xmm6
.byte	15,56,201,252
	pxor	%xmm11,%xmm13
.byte	69,15,56,201,243
	movdqa	%xmm0,%xmm2
	movdqa	%xmm8,%xmm10
.byte	15,58,204,193,2
.byte	15,56,200,213
.byte	69,15,58,204,193,2
.byte	69,15,56,200,212
.byte	15,56,202,245
.byte	69,15,56,202,236
	pxor	%xmm5,%xmm7
.byte	15,56,201,229
	pxor	%xmm12,%xmm14
.byte	69,15,56,201,220
	movdqa	%xmm0,%xmm1
	movdqa	%xmm8,%xmm9
.byte	15,58,204,194,2
.byte	15,56,200,206
.byte	69,15,58,204,194,2
.byte	69,15,56,200,205
.byte	15,56,202,254
.byte	69,15,56,202,245
	pxor	%xmm6,%xmm4
.byte	15,56,201,238
	pxor	%xmm13,%xmm11
.byte	69,15,56,201,229
	movdqa	%xmm0,%xmm2
	movdqa	%xmm8,%xmm10
.byte	15,58,204,193,2
.byte	15,56,200,215
.byte	69,15,58,204,193,2
.byte	69,15,56,200,214
.byte	15,56,202,231
.byte	69,15,56,202,222
	pxor	%xmm7,%xmm5
.byte	15,56,201,247
	pxor	%xmm14,%xmm12
.byte	69,15,56,201,238
	movdqa	%xmm0,%xmm1
	movdqa	%xmm8,%xmm9
.byte	15,58,204,194,3
.byte	15,56,200,204
.byte	69,15,58,204,194,3
.byte	69,15,56,200,203
.byte	15,56,202,236
.byte	69,15,56,202,227
	pxor	%xmm4,%xmm6
.byte	15,56,201,252
	pxor	%xmm11,%xmm13
.byte	69,15,56,201,243
	movdqa	%xmm0,%xmm2
	movdqa	%xmm8,%xmm10
.byte	15,58,204,193,3
.byte	15,56,200,213
.byte	69,15,58,204,193,3
.byte	69,15,56,200,212
.byte	15,56,202,245
.byte	69,15,56,202,236
	pxor	%xmm5,%xmm7
	pxor	%xmm12,%xmm14

	movl	$1,%ecx
	pxor	%xmm4,%xmm4
	cmpl	0(%rbx),%ecx
	cmovgeq	%rsp,%r8

	movdqa	%xmm0,%xmm1
	movdqa	%xmm8,%xmm9
.byte	15,58,204,194,3
.byte	15,56,200,206
.byte	69,15,58,204,194,3
.byte	69,15,56,200,205
.byte	15,56,202,254
.byte	69,15,56,202,245

	cmpl	4(%rbx),%ecx
	cmovgeq	%rsp,%r9
	movq	(%rbx),%xmm6

	movdqa	%xmm0,%xmm2
	movdqa	%xmm8,%xmm10
.byte	15,58,204,193,3
.byte	15,56,200,215
.byte	69,15,58,204,193,3
.byte	69,15,56,200,214

	pshufd	$0x00,%xmm6,%xmm11
	pshufd	$0x55,%xmm6,%xmm12
	movdqa	%xmm6,%xmm7
	pcmpgtd	%xmm4,%xmm11
	pcmpgtd	%xmm4,%xmm12

	movdqa	%xmm0,%xmm1
	movdqa	%xmm8,%xmm9
.byte	15,58,204,194,3
.byte	15,56,200,204
.byte	69,15,58,204,194,3
.byte	68,15,56,200,204

	pcmpgtd	%xmm4,%xmm7
	pand	%xmm11,%xmm0
	pand	%xmm11,%xmm1
	pand	%xmm12,%xmm8
	pand	%xmm12,%xmm9
	paddd	%xmm7,%xmm6

	paddd	64(%rsp),%xmm0
	paddd	80(%rsp),%xmm1
	paddd	96(%rsp),%xmm8
	paddd	112(%rsp),%xmm9

	movq	%xmm6,(%rbx)
	decl	%edx
	jnz	.Loop_shaext

	movl	280(%rsp),%edx

	pshufd	$27,%xmm0,%xmm0
	pshufd	$27,%xmm8,%xmm8

	movdqa	%xmm0,%xmm6
	punpckldq	%xmm8,%xmm0
	punpckhdq	%xmm8,%xmm6
	punpckhdq	%xmm9,%xmm1
	movq	%xmm0,0-64(%rdi)
	psrldq	$8,%xmm0
	movq	%xmm6,64-64(%rdi)
	psrldq	$8,%xmm6
	movq	%xmm0,32-64(%rdi)
	psrldq	$8,%xmm1
	movq	%xmm6,96-64(%rdi)
	movq	%xmm1,128-64(%rdi)

	leaq	8(%rdi),%rdi
	leaq	32(%rsi),%rsi
	decl	%edx
	jnz	.Loop_grande_shaext

.Ldone_shaext:

	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue_shaext:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha1_multi_block_shaext,.-sha1_multi_block_shaext
.type	sha1_multi_block_avx,@function
.align	32
sha1_multi_block_avx:
.cfi_startproc	
_avx_shortcut:
	shrq	$32,%rcx
	cmpl	$2,%edx
	jb	.Lavx
	testl	$32,%ecx
	jnz	_avx2_shortcut
	jmp	.Lavx
.align	32
.Lavx:
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	subq	$288,%rsp
	andq	$-256,%rsp
	movq	%rax,272(%rsp)
.cfi_escape	0x0f,0x06,0x77,0x90,0x02,0x06,0x23,0x08
.Lbody_avx:
	leaq	K_XX_XX(%rip),%rbp
	leaq	256(%rsp),%rbx

	vzeroupper
.Loop_grande_avx:
	movl	%edx,280(%rsp)
	xorl	%edx,%edx

	movq	0(%rsi),%r8

	movl	8(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,0(%rbx)
	cmovleq	%rbp,%r8

	movq	16(%rsi),%r9

	movl	24(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,4(%rbx)
	cmovleq	%rbp,%r9

	movq	32(%rsi),%r10

	movl	40(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,8(%rbx)
	cmovleq	%rbp,%r10

	movq	48(%rsi),%r11

	movl	56(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,12(%rbx)
	cmovleq	%rbp,%r11
	testl	%edx,%edx
	jz	.Ldone_avx

	vmovdqu	0(%rdi),%xmm10
	leaq	128(%rsp),%rax
	vmovdqu	32(%rdi),%xmm11
	vmovdqu	64(%rdi),%xmm12
	vmovdqu	96(%rdi),%xmm13
	vmovdqu	128(%rdi),%xmm14
	vmovdqu	96(%rbp),%xmm5
	jmp	.Loop_avx

.align	32
.Loop_avx:
	vmovdqa	-32(%rbp),%xmm15
	vmovd	(%r8),%xmm0
	leaq	64(%r8),%r8
	vmovd	(%r9),%xmm2
	leaq	64(%r9),%r9
	vpinsrd	$1,(%r10),%xmm0,%xmm0
	leaq	64(%r10),%r10
	vpinsrd	$1,(%r11),%xmm2,%xmm2
	leaq	64(%r11),%r11
	vmovd	-60(%r8),%xmm1
	vpunpckldq	%xmm2,%xmm0,%xmm0
	vmovd	-60(%r9),%xmm9
	vpshufb	%xmm5,%xmm0,%xmm0
	vpinsrd	$1,-60(%r10),%xmm1,%xmm1
	vpinsrd	$1,-60(%r11),%xmm9,%xmm9
	vpaddd	%xmm15,%xmm14,%xmm14
	vpslld	$5,%xmm10,%xmm8
	vpandn	%xmm13,%xmm11,%xmm7
	vpand	%xmm12,%xmm11,%xmm6

	vmovdqa	%xmm0,0-128(%rax)
	vpaddd	%xmm0,%xmm14,%xmm14
	vpunpckldq	%xmm9,%xmm1,%xmm1
	vpsrld	$27,%xmm10,%xmm9
	vpxor	%xmm7,%xmm6,%xmm6
	vmovd	-56(%r8),%xmm2

	vpslld	$30,%xmm11,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vmovd	-56(%r9),%xmm9
	vpaddd	%xmm6,%xmm14,%xmm14

	vpsrld	$2,%xmm11,%xmm11
	vpaddd	%xmm8,%xmm14,%xmm14
	vpshufb	%xmm5,%xmm1,%xmm1
	vpor	%xmm7,%xmm11,%xmm11
	vpinsrd	$1,-56(%r10),%xmm2,%xmm2
	vpinsrd	$1,-56(%r11),%xmm9,%xmm9
	vpaddd	%xmm15,%xmm13,%xmm13
	vpslld	$5,%xmm14,%xmm8
	vpandn	%xmm12,%xmm10,%xmm7
	vpand	%xmm11,%xmm10,%xmm6

	vmovdqa	%xmm1,16-128(%rax)
	vpaddd	%xmm1,%xmm13,%xmm13
	vpunpckldq	%xmm9,%xmm2,%xmm2
	vpsrld	$27,%xmm14,%xmm9
	vpxor	%xmm7,%xmm6,%xmm6
	vmovd	-52(%r8),%xmm3

	vpslld	$30,%xmm10,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vmovd	-52(%r9),%xmm9
	vpaddd	%xmm6,%xmm13,%xmm13

	vpsrld	$2,%xmm10,%xmm10
	vpaddd	%xmm8,%xmm13,%xmm13
	vpshufb	%xmm5,%xmm2,%xmm2
	vpor	%xmm7,%xmm10,%xmm10
	vpinsrd	$1,-52(%r10),%xmm3,%xmm3
	vpinsrd	$1,-52(%r11),%xmm9,%xmm9
	vpaddd	%xmm15,%xmm12,%xmm12
	vpslld	$5,%xmm13,%xmm8
	vpandn	%xmm11,%xmm14,%xmm7
	vpand	%xmm10,%xmm14,%xmm6

	vmovdqa	%xmm2,32-128(%rax)
	vpaddd	%xmm2,%xmm12,%xmm12
	vpunpckldq	%xmm9,%xmm3,%xmm3
	vpsrld	$27,%xmm13,%xmm9
	vpxor	%xmm7,%xmm6,%xmm6
	vmovd	-48(%r8),%xmm4

	vpslld	$30,%xmm14,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vmovd	-48(%r9),%xmm9
	vpaddd	%xmm6,%xmm12,%xmm12

	vpsrld	$2,%xmm14,%xmm14
	vpaddd	%xmm8,%xmm12,%xmm12
	vpshufb	%xmm5,%xmm3,%xmm3
	vpor	%xmm7,%xmm14,%xmm14
	vpinsrd	$1,-48(%r10),%xmm4,%xmm4
	vpinsrd	$1,-48(%r11),%xmm9,%xmm9
	vpaddd	%xmm15,%xmm11,%xmm11
	vpslld	$5,%xmm12,%xmm8
	vpandn	%xmm10,%xmm13,%xmm7
	vpand	%xmm14,%xmm13,%xmm6

	vmovdqa	%xmm3,48-128(%rax)
	vpaddd	%xmm3,%xmm11,%xmm11
	vpunpckldq	%xmm9,%xmm4,%xmm4
	vpsrld	$27,%xmm12,%xmm9
	vpxor	%xmm7,%xmm6,%xmm6
	vmovd	-44(%r8),%xmm0

	vpslld	$30,%xmm13,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vmovd	-44(%r9),%xmm9
	vpaddd	%xmm6,%xmm11,%xmm11

	vpsrld	$2,%xmm13,%xmm13
	vpaddd	%xmm8,%xmm11,%xmm11
	vpshufb	%xmm5,%xmm4,%xmm4
	vpor	%xmm7,%xmm13,%xmm13
	vpinsrd	$1,-44(%r10),%xmm0,%xmm0
	vpinsrd	$1,-44(%r11),%xmm9,%xmm9
	vpaddd	%xmm15,%xmm10,%xmm10
	vpslld	$5,%xmm11,%xmm8
	vpandn	%xmm14,%xmm12,%xmm7
	vpand	%xmm13,%xmm12,%xmm6

	vmovdqa	%xmm4,64-128(%rax)
	vpaddd	%xmm4,%xmm10,%xmm10
	vpunpckldq	%xmm9,%xmm0,%xmm0
	vpsrld	$27,%xmm11,%xmm9
	vpxor	%xmm7,%xmm6,%xmm6
	vmovd	-40(%r8),%xmm1

	vpslld	$30,%xmm12,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vmovd	-40(%r9),%xmm9
	vpaddd	%xmm6,%xmm10,%xmm10

	vpsrld	$2,%xmm12,%xmm12
	vpaddd	%xmm8,%xmm10,%xmm10
	vpshufb	%xmm5,%xmm0,%xmm0
	vpor	%xmm7,%xmm12,%xmm12
	vpinsrd	$1,-40(%r10),%xmm1,%xmm1
	vpinsrd	$1,-40(%r11),%xmm9,%xmm9
	vpaddd	%xmm15,%xmm14,%xmm14
	vpslld	$5,%xmm10,%xmm8
	vpandn	%xmm13,%xmm11,%xmm7
	vpand	%xmm12,%xmm11,%xmm6

	vmovdqa	%xmm0,80-128(%rax)
	vpaddd	%xmm0,%xmm14,%xmm14
	vpunpckldq	%xmm9,%xmm1,%xmm1
	vpsrld	$27,%xmm10,%xmm9
	vpxor	%xmm7,%xmm6,%xmm6
	vmovd	-36(%r8),%xmm2

	vpslld	$30,%xmm11,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vmovd	-36(%r9),%xmm9
	vpaddd	%xmm6,%xmm14,%xmm14

	vpsrld	$2,%xmm11,%xmm11
	vpaddd	%xmm8,%xmm14,%xmm14
	vpshufb	%xmm5,%xmm1,%xmm1
	vpor	%xmm7,%xmm11,%xmm11
	vpinsrd	$1,-36(%r10),%xmm2,%xmm2
	vpinsrd	$1,-36(%r11),%xmm9,%xmm9
	vpaddd	%xmm15,%xmm13,%xmm13
	vpslld	$5,%xmm14,%xmm8
	vpandn	%xmm12,%xmm10,%xmm7
	vpand	%xmm11,%xmm10,%xmm6

	vmovdqa	%xmm1,96-128(%rax)
	vpaddd	%xmm1,%xmm13,%xmm13
	vpunpckldq	%xmm9,%xmm2,%xmm2
	vpsrld	$27,%xmm14,%xmm9
	vpxor	%xmm7,%xmm6,%xmm6
	vmovd	-32(%r8),%xmm3

	vpslld	$30,%xmm10,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vmovd	-32(%r9),%xmm9
	vpaddd	%xmm6,%xmm13,%xmm13

	vpsrld	$2,%xmm10,%xmm10
	vpaddd	%xmm8,%xmm13,%xmm13
	vpshufb	%xmm5,%xmm2,%xmm2
	vpor	%xmm7,%xmm10,%xmm10
	vpinsrd	$1,-32(%r10),%xmm3,%xmm3
	vpinsrd	$1,-32(%r11),%xmm9,%xmm9
	vpaddd	%xmm15,%xmm12,%xmm12
	vpslld	$5,%xmm13,%xmm8
	vpandn	%xmm11,%xmm14,%xmm7
	vpand	%xmm10,%xmm14,%xmm6

	vmovdqa	%xmm2,112-128(%rax)
	vpaddd	%xmm2,%xmm12,%xmm12
	vpunpckldq	%xmm9,%xmm3,%xmm3
	vpsrld	$27,%xmm13,%xmm9
	vpxor	%xmm7,%xmm6,%xmm6
	vmovd	-28(%r8),%xmm4

	vpslld	$30,%xmm14,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vmovd	-28(%r9),%xmm9
	vpaddd	%xmm6,%xmm12,%xmm12

	vpsrld	$2,%xmm14,%xmm14
	vpaddd	%xmm8,%xmm12,%xmm12
	vpshufb	%xmm5,%xmm3,%xmm3
	vpor	%xmm7,%xmm14,%xmm14
	vpinsrd	$1,-28(%r10),%xmm4,%xmm4
	vpinsrd	$1,-28(%r11),%xmm9,%xmm9
	vpaddd	%xmm15,%xmm11,%xmm11
	vpslld	$5,%xmm12,%xmm8
	vpandn	%xmm10,%xmm13,%xmm7
	vpand	%xmm14,%xmm13,%xmm6

	vmovdqa	%xmm3,128-128(%rax)
	vpaddd	%xmm3,%xmm11,%xmm11
	vpunpckldq	%xmm9,%xmm4,%xmm4
	vpsrld	$27,%xmm12,%xmm9
	vpxor	%xmm7,%xmm6,%xmm6
	vmovd	-24(%r8),%xmm0

	vpslld	$30,%xmm13,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vmovd	-24(%r9),%xmm9
	vpaddd	%xmm6,%xmm11,%xmm11

	vpsrld	$2,%xmm13,%xmm13
	vpaddd	%xmm8,%xmm11,%xmm11
	vpshufb	%xmm5,%xmm4,%xmm4
	vpor	%xmm7,%xmm13,%xmm13
	vpinsrd	$1,-24(%r10),%xmm0,%xmm0
	vpinsrd	$1,-24(%r11),%xmm9,%xmm9
	vpaddd	%xmm15,%xmm10,%xmm10
	vpslld	$5,%xmm11,%xmm8
	vpandn	%xmm14,%xmm12,%xmm7
	vpand	%xmm13,%xmm12,%xmm6

	vmovdqa	%xmm4,144-128(%rax)
	vpaddd	%xmm4,%xmm10,%xmm10
	vpunpckldq	%xmm9,%xmm0,%xmm0
	vpsrld	$27,%xmm11,%xmm9
	vpxor	%xmm7,%xmm6,%xmm6
	vmovd	-20(%r8),%xmm1

	vpslld	$30,%xmm12,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vmovd	-20(%r9),%xmm9
	vpaddd	%xmm6,%xmm10,%xmm10

	vpsrld	$2,%xmm12,%xmm12
	vpaddd	%xmm8,%xmm10,%xmm10
	vpshufb	%xmm5,%xmm0,%xmm0
	vpor	%xmm7,%xmm12,%xmm12
	vpinsrd	$1,-20(%r10),%xmm1,%xmm1
	vpinsrd	$1,-20(%r11),%xmm9,%xmm9
	vpaddd	%xmm15,%xmm14,%xmm14
	vpslld	$5,%xmm10,%xmm8
	vpandn	%xmm13,%xmm11,%xmm7
	vpand	%xmm12,%xmm11,%xmm6

	vmovdqa	%xmm0,160-128(%rax)
	vpaddd	%xmm0,%xmm14,%xmm14
	vpunpckldq	%xmm9,%xmm1,%xmm1
	vpsrld	$27,%xmm10,%xmm9
	vpxor	%xmm7,%xmm6,%xmm6
	vmovd	-16(%r8),%xmm2

	vpslld	$30,%xmm11,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vmovd	-16(%r9),%xmm9
	vpaddd	%xmm6,%xmm14,%xmm14

	vpsrld	$2,%xmm11,%xmm11
	vpaddd	%xmm8,%xmm14,%xmm14
	vpshufb	%xmm5,%xmm1,%xmm1
	vpor	%xmm7,%xmm11,%xmm11
	vpinsrd	$1,-16(%r10),%xmm2,%xmm2
	vpinsrd	$1,-16(%r11),%xmm9,%xmm9
	vpaddd	%xmm15,%xmm13,%xmm13
	vpslld	$5,%xmm14,%xmm8
	vpandn	%xmm12,%xmm10,%xmm7
	vpand	%xmm11,%xmm10,%xmm6

	vmovdqa	%xmm1,176-128(%rax)
	vpaddd	%xmm1,%xmm13,%xmm13
	vpunpckldq	%xmm9,%xmm2,%xmm2
	vpsrld	$27,%xmm14,%xmm9
	vpxor	%xmm7,%xmm6,%xmm6
	vmovd	-12(%r8),%xmm3

	vpslld	$30,%xmm10,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vmovd	-12(%r9),%xmm9
	vpaddd	%xmm6,%xmm13,%xmm13

	vpsrld	$2,%xmm10,%xmm10
	vpaddd	%xmm8,%xmm13,%xmm13
	vpshufb	%xmm5,%xmm2,%xmm2
	vpor	%xmm7,%xmm10,%xmm10
	vpinsrd	$1,-12(%r10),%xmm3,%xmm3
	vpinsrd	$1,-12(%r11),%xmm9,%xmm9
	vpaddd	%xmm15,%xmm12,%xmm12
	vpslld	$5,%xmm13,%xmm8
	vpandn	%xmm11,%xmm14,%xmm7
	vpand	%xmm10,%xmm14,%xmm6

	vmovdqa	%xmm2,192-128(%rax)
	vpaddd	%xmm2,%xmm12,%xmm12
	vpunpckldq	%xmm9,%xmm3,%xmm3
	vpsrld	$27,%xmm13,%xmm9
	vpxor	%xmm7,%xmm6,%xmm6
	vmovd	-8(%r8),%xmm4

	vpslld	$30,%xmm14,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vmovd	-8(%r9),%xmm9
	vpaddd	%xmm6,%xmm12,%xmm12

	vpsrld	$2,%xmm14,%xmm14
	vpaddd	%xmm8,%xmm12,%xmm12
	vpshufb	%xmm5,%xmm3,%xmm3
	vpor	%xmm7,%xmm14,%xmm14
	vpinsrd	$1,-8(%r10),%xmm4,%xmm4
	vpinsrd	$1,-8(%r11),%xmm9,%xmm9
	vpaddd	%xmm15,%xmm11,%xmm11
	vpslld	$5,%xmm12,%xmm8
	vpandn	%xmm10,%xmm13,%xmm7
	vpand	%xmm14,%xmm13,%xmm6

	vmovdqa	%xmm3,208-128(%rax)
	vpaddd	%xmm3,%xmm11,%xmm11
	vpunpckldq	%xmm9,%xmm4,%xmm4
	vpsrld	$27,%xmm12,%xmm9
	vpxor	%xmm7,%xmm6,%xmm6
	vmovd	-4(%r8),%xmm0

	vpslld	$30,%xmm13,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vmovd	-4(%r9),%xmm9
	vpaddd	%xmm6,%xmm11,%xmm11

	vpsrld	$2,%xmm13,%xmm13
	vpaddd	%xmm8,%xmm11,%xmm11
	vpshufb	%xmm5,%xmm4,%xmm4
	vpor	%xmm7,%xmm13,%xmm13
	vmovdqa	0-128(%rax),%xmm1
	vpinsrd	$1,-4(%r10),%xmm0,%xmm0
	vpinsrd	$1,-4(%r11),%xmm9,%xmm9
	vpaddd	%xmm15,%xmm10,%xmm10
	prefetcht0	63(%r8)
	vpslld	$5,%xmm11,%xmm8
	vpandn	%xmm14,%xmm12,%xmm7
	vpand	%xmm13,%xmm12,%xmm6

	vmovdqa	%xmm4,224-128(%rax)
	vpaddd	%xmm4,%xmm10,%xmm10
	vpunpckldq	%xmm9,%xmm0,%xmm0
	vpsrld	$27,%xmm11,%xmm9
	prefetcht0	63(%r9)
	vpxor	%xmm7,%xmm6,%xmm6

	vpslld	$30,%xmm12,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	prefetcht0	63(%r10)
	vpaddd	%xmm6,%xmm10,%xmm10

	vpsrld	$2,%xmm12,%xmm12
	vpaddd	%xmm8,%xmm10,%xmm10
	prefetcht0	63(%r11)
	vpshufb	%xmm5,%xmm0,%xmm0
	vpor	%xmm7,%xmm12,%xmm12
	vmovdqa	16-128(%rax),%xmm2
	vpxor	%xmm3,%xmm1,%xmm1
	vmovdqa	32-128(%rax),%xmm3

	vpaddd	%xmm15,%xmm14,%xmm14
	vpslld	$5,%xmm10,%xmm8
	vpandn	%xmm13,%xmm11,%xmm7

	vpand	%xmm12,%xmm11,%xmm6

	vmovdqa	%xmm0,240-128(%rax)
	vpaddd	%xmm0,%xmm14,%xmm14
	vpxor	128-128(%rax),%xmm1,%xmm1
	vpsrld	$27,%xmm10,%xmm9
	vpxor	%xmm7,%xmm6,%xmm6
	vpxor	%xmm3,%xmm1,%xmm1


	vpslld	$30,%xmm11,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm14,%xmm14

	vpsrld	$31,%xmm1,%xmm5
	vpaddd	%xmm1,%xmm1,%xmm1

	vpsrld	$2,%xmm11,%xmm11

	vpaddd	%xmm8,%xmm14,%xmm14
	vpor	%xmm5,%xmm1,%xmm1
	vpor	%xmm7,%xmm11,%xmm11
	vpxor	%xmm4,%xmm2,%xmm2
	vmovdqa	48-128(%rax),%xmm4

	vpaddd	%xmm15,%xmm13,%xmm13
	vpslld	$5,%xmm14,%xmm8
	vpandn	%xmm12,%xmm10,%xmm7

	vpand	%xmm11,%xmm10,%xmm6

	vmovdqa	%xmm1,0-128(%rax)
	vpaddd	%xmm1,%xmm13,%xmm13
	vpxor	144-128(%rax),%xmm2,%xmm2
	vpsrld	$27,%xmm14,%xmm9
	vpxor	%xmm7,%xmm6,%xmm6
	vpxor	%xmm4,%xmm2,%xmm2


	vpslld	$30,%xmm10,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm13,%xmm13

	vpsrld	$31,%xmm2,%xmm5
	vpaddd	%xmm2,%xmm2,%xmm2

	vpsrld	$2,%xmm10,%xmm10

	vpaddd	%xmm8,%xmm13,%xmm13
	vpor	%xmm5,%xmm2,%xmm2
	vpor	%xmm7,%xmm10,%xmm10
	vpxor	%xmm0,%xmm3,%xmm3
	vmovdqa	64-128(%rax),%xmm0

	vpaddd	%xmm15,%xmm12,%xmm12
	vpslld	$5,%xmm13,%xmm8
	vpandn	%xmm11,%xmm14,%xmm7

	vpand	%xmm10,%xmm14,%xmm6

	vmovdqa	%xmm2,16-128(%rax)
	vpaddd	%xmm2,%xmm12,%xmm12
	vpxor	160-128(%rax),%xmm3,%xmm3
	vpsrld	$27,%xmm13,%xmm9
	vpxor	%xmm7,%xmm6,%xmm6
	vpxor	%xmm0,%xmm3,%xmm3


	vpslld	$30,%xmm14,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm12,%xmm12

	vpsrld	$31,%xmm3,%xmm5
	vpaddd	%xmm3,%xmm3,%xmm3

	vpsrld	$2,%xmm14,%xmm14

	vpaddd	%xmm8,%xmm12,%xmm12
	vpor	%xmm5,%xmm3,%xmm3
	vpor	%xmm7,%xmm14,%xmm14
	vpxor	%xmm1,%xmm4,%xmm4
	vmovdqa	80-128(%rax),%xmm1

	vpaddd	%xmm15,%xmm11,%xmm11
	vpslld	$5,%xmm12,%xmm8
	vpandn	%xmm10,%xmm13,%xmm7

	vpand	%xmm14,%xmm13,%xmm6

	vmovdqa	%xmm3,32-128(%rax)
	vpaddd	%xmm3,%xmm11,%xmm11
	vpxor	176-128(%rax),%xmm4,%xmm4
	vpsrld	$27,%xmm12,%xmm9
	vpxor	%xmm7,%xmm6,%xmm6
	vpxor	%xmm1,%xmm4,%xmm4


	vpslld	$30,%xmm13,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm11,%xmm11

	vpsrld	$31,%xmm4,%xmm5
	vpaddd	%xmm4,%xmm4,%xmm4

	vpsrld	$2,%xmm13,%xmm13

	vpaddd	%xmm8,%xmm11,%xmm11
	vpor	%xmm5,%xmm4,%xmm4
	vpor	%xmm7,%xmm13,%xmm13
	vpxor	%xmm2,%xmm0,%xmm0
	vmovdqa	96-128(%rax),%xmm2

	vpaddd	%xmm15,%xmm10,%xmm10
	vpslld	$5,%xmm11,%xmm8
	vpandn	%xmm14,%xmm12,%xmm7

	vpand	%xmm13,%xmm12,%xmm6

	vmovdqa	%xmm4,48-128(%rax)
	vpaddd	%xmm4,%xmm10,%xmm10
	vpxor	192-128(%rax),%xmm0,%xmm0
	vpsrld	$27,%xmm11,%xmm9
	vpxor	%xmm7,%xmm6,%xmm6
	vpxor	%xmm2,%xmm0,%xmm0


	vpslld	$30,%xmm12,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm10,%xmm10

	vpsrld	$31,%xmm0,%xmm5
	vpaddd	%xmm0,%xmm0,%xmm0

	vpsrld	$2,%xmm12,%xmm12

	vpaddd	%xmm8,%xmm10,%xmm10
	vpor	%xmm5,%xmm0,%xmm0
	vpor	%xmm7,%xmm12,%xmm12
	vmovdqa	0(%rbp),%xmm15
	vpxor	%xmm3,%xmm1,%xmm1
	vmovdqa	112-128(%rax),%xmm3

	vpslld	$5,%xmm10,%xmm8
	vpaddd	%xmm15,%xmm14,%xmm14
	vpxor	%xmm11,%xmm13,%xmm6
	vmovdqa	%xmm0,64-128(%rax)
	vpaddd	%xmm0,%xmm14,%xmm14
	vpxor	208-128(%rax),%xmm1,%xmm1
	vpsrld	$27,%xmm10,%xmm9
	vpxor	%xmm12,%xmm6,%xmm6
	vpxor	%xmm3,%xmm1,%xmm1

	vpslld	$30,%xmm11,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm14,%xmm14
	vpsrld	$31,%xmm1,%xmm5
	vpaddd	%xmm1,%xmm1,%xmm1

	vpsrld	$2,%xmm11,%xmm11
	vpaddd	%xmm8,%xmm14,%xmm14
	vpor	%xmm5,%xmm1,%xmm1
	vpor	%xmm7,%xmm11,%xmm11
	vpxor	%xmm4,%xmm2,%xmm2
	vmovdqa	128-128(%rax),%xmm4

	vpslld	$5,%xmm14,%xmm8
	vpaddd	%xmm15,%xmm13,%xmm13
	vpxor	%xmm10,%xmm12,%xmm6
	vmovdqa	%xmm1,80-128(%rax)
	vpaddd	%xmm1,%xmm13,%xmm13
	vpxor	224-128(%rax),%xmm2,%xmm2
	vpsrld	$27,%xmm14,%xmm9
	vpxor	%xmm11,%xmm6,%xmm6
	vpxor	%xmm4,%xmm2,%xmm2

	vpslld	$30,%xmm10,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm13,%xmm13
	vpsrld	$31,%xmm2,%xmm5
	vpaddd	%xmm2,%xmm2,%xmm2

	vpsrld	$2,%xmm10,%xmm10
	vpaddd	%xmm8,%xmm13,%xmm13
	vpor	%xmm5,%xmm2,%xmm2
	vpor	%xmm7,%xmm10,%xmm10
	vpxor	%xmm0,%xmm3,%xmm3
	vmovdqa	144-128(%rax),%xmm0

	vpslld	$5,%xmm13,%xmm8
	vpaddd	%xmm15,%xmm12,%xmm12
	vpxor	%xmm14,%xmm11,%xmm6
	vmovdqa	%xmm2,96-128(%rax)
	vpaddd	%xmm2,%xmm12,%xmm12
	vpxor	240-128(%rax),%xmm3,%xmm3
	vpsrld	$27,%xmm13,%xmm9
	vpxor	%xmm10,%xmm6,%xmm6
	vpxor	%xmm0,%xmm3,%xmm3

	vpslld	$30,%xmm14,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm12,%xmm12
	vpsrld	$31,%xmm3,%xmm5
	vpaddd	%xmm3,%xmm3,%xmm3

	vpsrld	$2,%xmm14,%xmm14
	vpaddd	%xmm8,%xmm12,%xmm12
	vpor	%xmm5,%xmm3,%xmm3
	vpor	%xmm7,%xmm14,%xmm14
	vpxor	%xmm1,%xmm4,%xmm4
	vmovdqa	160-128(%rax),%xmm1

	vpslld	$5,%xmm12,%xmm8
	vpaddd	%xmm15,%xmm11,%xmm11
	vpxor	%xmm13,%xmm10,%xmm6
	vmovdqa	%xmm3,112-128(%rax)
	vpaddd	%xmm3,%xmm11,%xmm11
	vpxor	0-128(%rax),%xmm4,%xmm4
	vpsrld	$27,%xmm12,%xmm9
	vpxor	%xmm14,%xmm6,%xmm6
	vpxor	%xmm1,%xmm4,%xmm4

	vpslld	$30,%xmm13,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm11,%xmm11
	vpsrld	$31,%xmm4,%xmm5
	vpaddd	%xmm4,%xmm4,%xmm4

	vpsrld	$2,%xmm13,%xmm13
	vpaddd	%xmm8,%xmm11,%xmm11
	vpor	%xmm5,%xmm4,%xmm4
	vpor	%xmm7,%xmm13,%xmm13
	vpxor	%xmm2,%xmm0,%xmm0
	vmovdqa	176-128(%rax),%xmm2

	vpslld	$5,%xmm11,%xmm8
	vpaddd	%xmm15,%xmm10,%xmm10
	vpxor	%xmm12,%xmm14,%xmm6
	vmovdqa	%xmm4,128-128(%rax)
	vpaddd	%xmm4,%xmm10,%xmm10
	vpxor	16-128(%rax),%xmm0,%xmm0
	vpsrld	$27,%xmm11,%xmm9
	vpxor	%xmm13,%xmm6,%xmm6
	vpxor	%xmm2,%xmm0,%xmm0

	vpslld	$30,%xmm12,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm10,%xmm10
	vpsrld	$31,%xmm0,%xmm5
	vpaddd	%xmm0,%xmm0,%xmm0

	vpsrld	$2,%xmm12,%xmm12
	vpaddd	%xmm8,%xmm10,%xmm10
	vpor	%xmm5,%xmm0,%xmm0
	vpor	%xmm7,%xmm12,%xmm12
	vpxor	%xmm3,%xmm1,%xmm1
	vmovdqa	192-128(%rax),%xmm3

	vpslld	$5,%xmm10,%xmm8
	vpaddd	%xmm15,%xmm14,%xmm14
	vpxor	%xmm11,%xmm13,%xmm6
	vmovdqa	%xmm0,144-128(%rax)
	vpaddd	%xmm0,%xmm14,%xmm14
	vpxor	32-128(%rax),%xmm1,%xmm1
	vpsrld	$27,%xmm10,%xmm9
	vpxor	%xmm12,%xmm6,%xmm6
	vpxor	%xmm3,%xmm1,%xmm1

	vpslld	$30,%xmm11,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm14,%xmm14
	vpsrld	$31,%xmm1,%xmm5
	vpaddd	%xmm1,%xmm1,%xmm1

	vpsrld	$2,%xmm11,%xmm11
	vpaddd	%xmm8,%xmm14,%xmm14
	vpor	%xmm5,%xmm1,%xmm1
	vpor	%xmm7,%xmm11,%xmm11
	vpxor	%xmm4,%xmm2,%xmm2
	vmovdqa	208-128(%rax),%xmm4

	vpslld	$5,%xmm14,%xmm8
	vpaddd	%xmm15,%xmm13,%xmm13
	vpxor	%xmm10,%xmm12,%xmm6
	vmovdqa	%xmm1,160-128(%rax)
	vpaddd	%xmm1,%xmm13,%xmm13
	vpxor	48-128(%rax),%xmm2,%xmm2
	vpsrld	$27,%xmm14,%xmm9
	vpxor	%xmm11,%xmm6,%xmm6
	vpxor	%xmm4,%xmm2,%xmm2

	vpslld	$30,%xmm10,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm13,%xmm13
	vpsrld	$31,%xmm2,%xmm5
	vpaddd	%xmm2,%xmm2,%xmm2

	vpsrld	$2,%xmm10,%xmm10
	vpaddd	%xmm8,%xmm13,%xmm13
	vpor	%xmm5,%xmm2,%xmm2
	vpor	%xmm7,%xmm10,%xmm10
	vpxor	%xmm0,%xmm3,%xmm3
	vmovdqa	224-128(%rax),%xmm0

	vpslld	$5,%xmm13,%xmm8
	vpaddd	%xmm15,%xmm12,%xmm12
	vpxor	%xmm14,%xmm11,%xmm6
	vmovdqa	%xmm2,176-128(%rax)
	vpaddd	%xmm2,%xmm12,%xmm12
	vpxor	64-128(%rax),%xmm3,%xmm3
	vpsrld	$27,%xmm13,%xmm9
	vpxor	%xmm10,%xmm6,%xmm6
	vpxor	%xmm0,%xmm3,%xmm3

	vpslld	$30,%xmm14,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm12,%xmm12
	vpsrld	$31,%xmm3,%xmm5
	vpaddd	%xmm3,%xmm3,%xmm3

	vpsrld	$2,%xmm14,%xmm14
	vpaddd	%xmm8,%xmm12,%xmm12
	vpor	%xmm5,%xmm3,%xmm3
	vpor	%xmm7,%xmm14,%xmm14
	vpxor	%xmm1,%xmm4,%xmm4
	vmovdqa	240-128(%rax),%xmm1

	vpslld	$5,%xmm12,%xmm8
	vpaddd	%xmm15,%xmm11,%xmm11
	vpxor	%xmm13,%xmm10,%xmm6
	vmovdqa	%xmm3,192-128(%rax)
	vpaddd	%xmm3,%xmm11,%xmm11
	vpxor	80-128(%rax),%xmm4,%xmm4
	vpsrld	$27,%xmm12,%xmm9
	vpxor	%xmm14,%xmm6,%xmm6
	vpxor	%xmm1,%xmm4,%xmm4

	vpslld	$30,%xmm13,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm11,%xmm11
	vpsrld	$31,%xmm4,%xmm5
	vpaddd	%xmm4,%xmm4,%xmm4

	vpsrld	$2,%xmm13,%xmm13
	vpaddd	%xmm8,%xmm11,%xmm11
	vpor	%xmm5,%xmm4,%xmm4
	vpor	%xmm7,%xmm13,%xmm13
	vpxor	%xmm2,%xmm0,%xmm0
	vmovdqa	0-128(%rax),%xmm2

	vpslld	$5,%xmm11,%xmm8
	vpaddd	%xmm15,%xmm10,%xmm10
	vpxor	%xmm12,%xmm14,%xmm6
	vmovdqa	%xmm4,208-128(%rax)
	vpaddd	%xmm4,%xmm10,%xmm10
	vpxor	96-128(%rax),%xmm0,%xmm0
	vpsrld	$27,%xmm11,%xmm9
	vpxor	%xmm13,%xmm6,%xmm6
	vpxor	%xmm2,%xmm0,%xmm0

	vpslld	$30,%xmm12,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm10,%xmm10
	vpsrld	$31,%xmm0,%xmm5
	vpaddd	%xmm0,%xmm0,%xmm0

	vpsrld	$2,%xmm12,%xmm12
	vpaddd	%xmm8,%xmm10,%xmm10
	vpor	%xmm5,%xmm0,%xmm0
	vpor	%xmm7,%xmm12,%xmm12
	vpxor	%xmm3,%xmm1,%xmm1
	vmovdqa	16-128(%rax),%xmm3

	vpslld	$5,%xmm10,%xmm8
	vpaddd	%xmm15,%xmm14,%xmm14
	vpxor	%xmm11,%xmm13,%xmm6
	vmovdqa	%xmm0,224-128(%rax)
	vpaddd	%xmm0,%xmm14,%xmm14
	vpxor	112-128(%rax),%xmm1,%xmm1
	vpsrld	$27,%xmm10,%xmm9
	vpxor	%xmm12,%xmm6,%xmm6
	vpxor	%xmm3,%xmm1,%xmm1

	vpslld	$30,%xmm11,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm14,%xmm14
	vpsrld	$31,%xmm1,%xmm5
	vpaddd	%xmm1,%xmm1,%xmm1

	vpsrld	$2,%xmm11,%xmm11
	vpaddd	%xmm8,%xmm14,%xmm14
	vpor	%xmm5,%xmm1,%xmm1
	vpor	%xmm7,%xmm11,%xmm11
	vpxor	%xmm4,%xmm2,%xmm2
	vmovdqa	32-128(%rax),%xmm4

	vpslld	$5,%xmm14,%xmm8
	vpaddd	%xmm15,%xmm13,%xmm13
	vpxor	%xmm10,%xmm12,%xmm6
	vmovdqa	%xmm1,240-128(%rax)
	vpaddd	%xmm1,%xmm13,%xmm13
	vpxor	128-128(%rax),%xmm2,%xmm2
	vpsrld	$27,%xmm14,%xmm9
	vpxor	%xmm11,%xmm6,%xmm6
	vpxor	%xmm4,%xmm2,%xmm2

	vpslld	$30,%xmm10,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm13,%xmm13
	vpsrld	$31,%xmm2,%xmm5
	vpaddd	%xmm2,%xmm2,%xmm2

	vpsrld	$2,%xmm10,%xmm10
	vpaddd	%xmm8,%xmm13,%xmm13
	vpor	%xmm5,%xmm2,%xmm2
	vpor	%xmm7,%xmm10,%xmm10
	vpxor	%xmm0,%xmm3,%xmm3
	vmovdqa	48-128(%rax),%xmm0

	vpslld	$5,%xmm13,%xmm8
	vpaddd	%xmm15,%xmm12,%xmm12
	vpxor	%xmm14,%xmm11,%xmm6
	vmovdqa	%xmm2,0-128(%rax)
	vpaddd	%xmm2,%xmm12,%xmm12
	vpxor	144-128(%rax),%xmm3,%xmm3
	vpsrld	$27,%xmm13,%xmm9
	vpxor	%xmm10,%xmm6,%xmm6
	vpxor	%xmm0,%xmm3,%xmm3

	vpslld	$30,%xmm14,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm12,%xmm12
	vpsrld	$31,%xmm3,%xmm5
	vpaddd	%xmm3,%xmm3,%xmm3

	vpsrld	$2,%xmm14,%xmm14
	vpaddd	%xmm8,%xmm12,%xmm12
	vpor	%xmm5,%xmm3,%xmm3
	vpor	%xmm7,%xmm14,%xmm14
	vpxor	%xmm1,%xmm4,%xmm4
	vmovdqa	64-128(%rax),%xmm1

	vpslld	$5,%xmm12,%xmm8
	vpaddd	%xmm15,%xmm11,%xmm11
	vpxor	%xmm13,%xmm10,%xmm6
	vmovdqa	%xmm3,16-128(%rax)
	vpaddd	%xmm3,%xmm11,%xmm11
	vpxor	160-128(%rax),%xmm4,%xmm4
	vpsrld	$27,%xmm12,%xmm9
	vpxor	%xmm14,%xmm6,%xmm6
	vpxor	%xmm1,%xmm4,%xmm4

	vpslld	$30,%xmm13,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm11,%xmm11
	vpsrld	$31,%xmm4,%xmm5
	vpaddd	%xmm4,%xmm4,%xmm4

	vpsrld	$2,%xmm13,%xmm13
	vpaddd	%xmm8,%xmm11,%xmm11
	vpor	%xmm5,%xmm4,%xmm4
	vpor	%xmm7,%xmm13,%xmm13
	vpxor	%xmm2,%xmm0,%xmm0
	vmovdqa	80-128(%rax),%xmm2

	vpslld	$5,%xmm11,%xmm8
	vpaddd	%xmm15,%xmm10,%xmm10
	vpxor	%xmm12,%xmm14,%xmm6
	vmovdqa	%xmm4,32-128(%rax)
	vpaddd	%xmm4,%xmm10,%xmm10
	vpxor	176-128(%rax),%xmm0,%xmm0
	vpsrld	$27,%xmm11,%xmm9
	vpxor	%xmm13,%xmm6,%xmm6
	vpxor	%xmm2,%xmm0,%xmm0

	vpslld	$30,%xmm12,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm10,%xmm10
	vpsrld	$31,%xmm0,%xmm5
	vpaddd	%xmm0,%xmm0,%xmm0

	vpsrld	$2,%xmm12,%xmm12
	vpaddd	%xmm8,%xmm10,%xmm10
	vpor	%xmm5,%xmm0,%xmm0
	vpor	%xmm7,%xmm12,%xmm12
	vpxor	%xmm3,%xmm1,%xmm1
	vmovdqa	96-128(%rax),%xmm3

	vpslld	$5,%xmm10,%xmm8
	vpaddd	%xmm15,%xmm14,%xmm14
	vpxor	%xmm11,%xmm13,%xmm6
	vmovdqa	%xmm0,48-128(%rax)
	vpaddd	%xmm0,%xmm14,%xmm14
	vpxor	192-128(%rax),%xmm1,%xmm1
	vpsrld	$27,%xmm10,%xmm9
	vpxor	%xmm12,%xmm6,%xmm6
	vpxor	%xmm3,%xmm1,%xmm1

	vpslld	$30,%xmm11,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm14,%xmm14
	vpsrld	$31,%xmm1,%xmm5
	vpaddd	%xmm1,%xmm1,%xmm1

	vpsrld	$2,%xmm11,%xmm11
	vpaddd	%xmm8,%xmm14,%xmm14
	vpor	%xmm5,%xmm1,%xmm1
	vpor	%xmm7,%xmm11,%xmm11
	vpxor	%xmm4,%xmm2,%xmm2
	vmovdqa	112-128(%rax),%xmm4

	vpslld	$5,%xmm14,%xmm8
	vpaddd	%xmm15,%xmm13,%xmm13
	vpxor	%xmm10,%xmm12,%xmm6
	vmovdqa	%xmm1,64-128(%rax)
	vpaddd	%xmm1,%xmm13,%xmm13
	vpxor	208-128(%rax),%xmm2,%xmm2
	vpsrld	$27,%xmm14,%xmm9
	vpxor	%xmm11,%xmm6,%xmm6
	vpxor	%xmm4,%xmm2,%xmm2

	vpslld	$30,%xmm10,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm13,%xmm13
	vpsrld	$31,%xmm2,%xmm5
	vpaddd	%xmm2,%xmm2,%xmm2

	vpsrld	$2,%xmm10,%xmm10
	vpaddd	%xmm8,%xmm13,%xmm13
	vpor	%xmm5,%xmm2,%xmm2
	vpor	%xmm7,%xmm10,%xmm10
	vpxor	%xmm0,%xmm3,%xmm3
	vmovdqa	128-128(%rax),%xmm0

	vpslld	$5,%xmm13,%xmm8
	vpaddd	%xmm15,%xmm12,%xmm12
	vpxor	%xmm14,%xmm11,%xmm6
	vmovdqa	%xmm2,80-128(%rax)
	vpaddd	%xmm2,%xmm12,%xmm12
	vpxor	224-128(%rax),%xmm3,%xmm3
	vpsrld	$27,%xmm13,%xmm9
	vpxor	%xmm10,%xmm6,%xmm6
	vpxor	%xmm0,%xmm3,%xmm3

	vpslld	$30,%xmm14,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm12,%xmm12
	vpsrld	$31,%xmm3,%xmm5
	vpaddd	%xmm3,%xmm3,%xmm3

	vpsrld	$2,%xmm14,%xmm14
	vpaddd	%xmm8,%xmm12,%xmm12
	vpor	%xmm5,%xmm3,%xmm3
	vpor	%xmm7,%xmm14,%xmm14
	vpxor	%xmm1,%xmm4,%xmm4
	vmovdqa	144-128(%rax),%xmm1

	vpslld	$5,%xmm12,%xmm8
	vpaddd	%xmm15,%xmm11,%xmm11
	vpxor	%xmm13,%xmm10,%xmm6
	vmovdqa	%xmm3,96-128(%rax)
	vpaddd	%xmm3,%xmm11,%xmm11
	vpxor	240-128(%rax),%xmm4,%xmm4
	vpsrld	$27,%xmm12,%xmm9
	vpxor	%xmm14,%xmm6,%xmm6
	vpxor	%xmm1,%xmm4,%xmm4

	vpslld	$30,%xmm13,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm11,%xmm11
	vpsrld	$31,%xmm4,%xmm5
	vpaddd	%xmm4,%xmm4,%xmm4

	vpsrld	$2,%xmm13,%xmm13
	vpaddd	%xmm8,%xmm11,%xmm11
	vpor	%xmm5,%xmm4,%xmm4
	vpor	%xmm7,%xmm13,%xmm13
	vpxor	%xmm2,%xmm0,%xmm0
	vmovdqa	160-128(%rax),%xmm2

	vpslld	$5,%xmm11,%xmm8
	vpaddd	%xmm15,%xmm10,%xmm10
	vpxor	%xmm12,%xmm14,%xmm6
	vmovdqa	%xmm4,112-128(%rax)
	vpaddd	%xmm4,%xmm10,%xmm10
	vpxor	0-128(%rax),%xmm0,%xmm0
	vpsrld	$27,%xmm11,%xmm9
	vpxor	%xmm13,%xmm6,%xmm6
	vpxor	%xmm2,%xmm0,%xmm0

	vpslld	$30,%xmm12,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm10,%xmm10
	vpsrld	$31,%xmm0,%xmm5
	vpaddd	%xmm0,%xmm0,%xmm0

	vpsrld	$2,%xmm12,%xmm12
	vpaddd	%xmm8,%xmm10,%xmm10
	vpor	%xmm5,%xmm0,%xmm0
	vpor	%xmm7,%xmm12,%xmm12
	vmovdqa	32(%rbp),%xmm15
	vpxor	%xmm3,%xmm1,%xmm1
	vmovdqa	176-128(%rax),%xmm3

	vpaddd	%xmm15,%xmm14,%xmm14
	vpslld	$5,%xmm10,%xmm8
	vpand	%xmm12,%xmm13,%xmm7
	vpxor	16-128(%rax),%xmm1,%xmm1

	vpaddd	%xmm7,%xmm14,%xmm14
	vpsrld	$27,%xmm10,%xmm9
	vpxor	%xmm12,%xmm13,%xmm6
	vpxor	%xmm3,%xmm1,%xmm1

	vmovdqu	%xmm0,128-128(%rax)
	vpaddd	%xmm0,%xmm14,%xmm14
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm1,%xmm5
	vpand	%xmm11,%xmm6,%xmm6
	vpaddd	%xmm1,%xmm1,%xmm1

	vpslld	$30,%xmm11,%xmm7
	vpaddd	%xmm6,%xmm14,%xmm14

	vpsrld	$2,%xmm11,%xmm11
	vpaddd	%xmm8,%xmm14,%xmm14
	vpor	%xmm5,%xmm1,%xmm1
	vpor	%xmm7,%xmm11,%xmm11
	vpxor	%xmm4,%xmm2,%xmm2
	vmovdqa	192-128(%rax),%xmm4

	vpaddd	%xmm15,%xmm13,%xmm13
	vpslld	$5,%xmm14,%xmm8
	vpand	%xmm11,%xmm12,%xmm7
	vpxor	32-128(%rax),%xmm2,%xmm2

	vpaddd	%xmm7,%xmm13,%xmm13
	vpsrld	$27,%xmm14,%xmm9
	vpxor	%xmm11,%xmm12,%xmm6
	vpxor	%xmm4,%xmm2,%xmm2

	vmovdqu	%xmm1,144-128(%rax)
	vpaddd	%xmm1,%xmm13,%xmm13
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm2,%xmm5
	vpand	%xmm10,%xmm6,%xmm6
	vpaddd	%xmm2,%xmm2,%xmm2

	vpslld	$30,%xmm10,%xmm7
	vpaddd	%xmm6,%xmm13,%xmm13

	vpsrld	$2,%xmm10,%xmm10
	vpaddd	%xmm8,%xmm13,%xmm13
	vpor	%xmm5,%xmm2,%xmm2
	vpor	%xmm7,%xmm10,%xmm10
	vpxor	%xmm0,%xmm3,%xmm3
	vmovdqa	208-128(%rax),%xmm0

	vpaddd	%xmm15,%xmm12,%xmm12
	vpslld	$5,%xmm13,%xmm8
	vpand	%xmm10,%xmm11,%xmm7
	vpxor	48-128(%rax),%xmm3,%xmm3

	vpaddd	%xmm7,%xmm12,%xmm12
	vpsrld	$27,%xmm13,%xmm9
	vpxor	%xmm10,%xmm11,%xmm6
	vpxor	%xmm0,%xmm3,%xmm3

	vmovdqu	%xmm2,160-128(%rax)
	vpaddd	%xmm2,%xmm12,%xmm12
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm3,%xmm5
	vpand	%xmm14,%xmm6,%xmm6
	vpaddd	%xmm3,%xmm3,%xmm3

	vpslld	$30,%xmm14,%xmm7
	vpaddd	%xmm6,%xmm12,%xmm12

	vpsrld	$2,%xmm14,%xmm14
	vpaddd	%xmm8,%xmm12,%xmm12
	vpor	%xmm5,%xmm3,%xmm3
	vpor	%xmm7,%xmm14,%xmm14
	vpxor	%xmm1,%xmm4,%xmm4
	vmovdqa	224-128(%rax),%xmm1

	vpaddd	%xmm15,%xmm11,%xmm11
	vpslld	$5,%xmm12,%xmm8
	vpand	%xmm14,%xmm10,%xmm7
	vpxor	64-128(%rax),%xmm4,%xmm4

	vpaddd	%xmm7,%xmm11,%xmm11
	vpsrld	$27,%xmm12,%xmm9
	vpxor	%xmm14,%xmm10,%xmm6
	vpxor	%xmm1,%xmm4,%xmm4

	vmovdqu	%xmm3,176-128(%rax)
	vpaddd	%xmm3,%xmm11,%xmm11
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm4,%xmm5
	vpand	%xmm13,%xmm6,%xmm6
	vpaddd	%xmm4,%xmm4,%xmm4

	vpslld	$30,%xmm13,%xmm7
	vpaddd	%xmm6,%xmm11,%xmm11

	vpsrld	$2,%xmm13,%xmm13
	vpaddd	%xmm8,%xmm11,%xmm11
	vpor	%xmm5,%xmm4,%xmm4
	vpor	%xmm7,%xmm13,%xmm13
	vpxor	%xmm2,%xmm0,%xmm0
	vmovdqa	240-128(%rax),%xmm2

	vpaddd	%xmm15,%xmm10,%xmm10
	vpslld	$5,%xmm11,%xmm8
	vpand	%xmm13,%xmm14,%xmm7
	vpxor	80-128(%rax),%xmm0,%xmm0

	vpaddd	%xmm7,%xmm10,%xmm10
	vpsrld	$27,%xmm11,%xmm9
	vpxor	%xmm13,%xmm14,%xmm6
	vpxor	%xmm2,%xmm0,%xmm0

	vmovdqu	%xmm4,192-128(%rax)
	vpaddd	%xmm4,%xmm10,%xmm10
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm0,%xmm5
	vpand	%xmm12,%xmm6,%xmm6
	vpaddd	%xmm0,%xmm0,%xmm0

	vpslld	$30,%xmm12,%xmm7
	vpaddd	%xmm6,%xmm10,%xmm10

	vpsrld	$2,%xmm12,%xmm12
	vpaddd	%xmm8,%xmm10,%xmm10
	vpor	%xmm5,%xmm0,%xmm0
	vpor	%xmm7,%xmm12,%xmm12
	vpxor	%xmm3,%xmm1,%xmm1
	vmovdqa	0-128(%rax),%xmm3

	vpaddd	%xmm15,%xmm14,%xmm14
	vpslld	$5,%xmm10,%xmm8
	vpand	%xmm12,%xmm13,%xmm7
	vpxor	96-128(%rax),%xmm1,%xmm1

	vpaddd	%xmm7,%xmm14,%xmm14
	vpsrld	$27,%xmm10,%xmm9
	vpxor	%xmm12,%xmm13,%xmm6
	vpxor	%xmm3,%xmm1,%xmm1

	vmovdqu	%xmm0,208-128(%rax)
	vpaddd	%xmm0,%xmm14,%xmm14
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm1,%xmm5
	vpand	%xmm11,%xmm6,%xmm6
	vpaddd	%xmm1,%xmm1,%xmm1

	vpslld	$30,%xmm11,%xmm7
	vpaddd	%xmm6,%xmm14,%xmm14

	vpsrld	$2,%xmm11,%xmm11
	vpaddd	%xmm8,%xmm14,%xmm14
	vpor	%xmm5,%xmm1,%xmm1
	vpor	%xmm7,%xmm11,%xmm11
	vpxor	%xmm4,%xmm2,%xmm2
	vmovdqa	16-128(%rax),%xmm4

	vpaddd	%xmm15,%xmm13,%xmm13
	vpslld	$5,%xmm14,%xmm8
	vpand	%xmm11,%xmm12,%xmm7
	vpxor	112-128(%rax),%xmm2,%xmm2

	vpaddd	%xmm7,%xmm13,%xmm13
	vpsrld	$27,%xmm14,%xmm9
	vpxor	%xmm11,%xmm12,%xmm6
	vpxor	%xmm4,%xmm2,%xmm2

	vmovdqu	%xmm1,224-128(%rax)
	vpaddd	%xmm1,%xmm13,%xmm13
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm2,%xmm5
	vpand	%xmm10,%xmm6,%xmm6
	vpaddd	%xmm2,%xmm2,%xmm2

	vpslld	$30,%xmm10,%xmm7
	vpaddd	%xmm6,%xmm13,%xmm13

	vpsrld	$2,%xmm10,%xmm10
	vpaddd	%xmm8,%xmm13,%xmm13
	vpor	%xmm5,%xmm2,%xmm2
	vpor	%xmm7,%xmm10,%xmm10
	vpxor	%xmm0,%xmm3,%xmm3
	vmovdqa	32-128(%rax),%xmm0

	vpaddd	%xmm15,%xmm12,%xmm12
	vpslld	$5,%xmm13,%xmm8
	vpand	%xmm10,%xmm11,%xmm7
	vpxor	128-128(%rax),%xmm3,%xmm3

	vpaddd	%xmm7,%xmm12,%xmm12
	vpsrld	$27,%xmm13,%xmm9
	vpxor	%xmm10,%xmm11,%xmm6
	vpxor	%xmm0,%xmm3,%xmm3

	vmovdqu	%xmm2,240-128(%rax)
	vpaddd	%xmm2,%xmm12,%xmm12
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm3,%xmm5
	vpand	%xmm14,%xmm6,%xmm6
	vpaddd	%xmm3,%xmm3,%xmm3

	vpslld	$30,%xmm14,%xmm7
	vpaddd	%xmm6,%xmm12,%xmm12

	vpsrld	$2,%xmm14,%xmm14
	vpaddd	%xmm8,%xmm12,%xmm12
	vpor	%xmm5,%xmm3,%xmm3
	vpor	%xmm7,%xmm14,%xmm14
	vpxor	%xmm1,%xmm4,%xmm4
	vmovdqa	48-128(%rax),%xmm1

	vpaddd	%xmm15,%xmm11,%xmm11
	vpslld	$5,%xmm12,%xmm8
	vpand	%xmm14,%xmm10,%xmm7
	vpxor	144-128(%rax),%xmm4,%xmm4

	vpaddd	%xmm7,%xmm11,%xmm11
	vpsrld	$27,%xmm12,%xmm9
	vpxor	%xmm14,%xmm10,%xmm6
	vpxor	%xmm1,%xmm4,%xmm4

	vmovdqu	%xmm3,0-128(%rax)
	vpaddd	%xmm3,%xmm11,%xmm11
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm4,%xmm5
	vpand	%xmm13,%xmm6,%xmm6
	vpaddd	%xmm4,%xmm4,%xmm4

	vpslld	$30,%xmm13,%xmm7
	vpaddd	%xmm6,%xmm11,%xmm11

	vpsrld	$2,%xmm13,%xmm13
	vpaddd	%xmm8,%xmm11,%xmm11
	vpor	%xmm5,%xmm4,%xmm4
	vpor	%xmm7,%xmm13,%xmm13
	vpxor	%xmm2,%xmm0,%xmm0
	vmovdqa	64-128(%rax),%xmm2

	vpaddd	%xmm15,%xmm10,%xmm10
	vpslld	$5,%xmm11,%xmm8
	vpand	%xmm13,%xmm14,%xmm7
	vpxor	160-128(%rax),%xmm0,%xmm0

	vpaddd	%xmm7,%xmm10,%xmm10
	vpsrld	$27,%xmm11,%xmm9
	vpxor	%xmm13,%xmm14,%xmm6
	vpxor	%xmm2,%xmm0,%xmm0

	vmovdqu	%xmm4,16-128(%rax)
	vpaddd	%xmm4,%xmm10,%xmm10
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm0,%xmm5
	vpand	%xmm12,%xmm6,%xmm6
	vpaddd	%xmm0,%xmm0,%xmm0

	vpslld	$30,%xmm12,%xmm7
	vpaddd	%xmm6,%xmm10,%xmm10

	vpsrld	$2,%xmm12,%xmm12
	vpaddd	%xmm8,%xmm10,%xmm10
	vpor	%xmm5,%xmm0,%xmm0
	vpor	%xmm7,%xmm12,%xmm12
	vpxor	%xmm3,%xmm1,%xmm1
	vmovdqa	80-128(%rax),%xmm3

	vpaddd	%xmm15,%xmm14,%xmm14
	vpslld	$5,%xmm10,%xmm8
	vpand	%xmm12,%xmm13,%xmm7
	vpxor	176-128(%rax),%xmm1,%xmm1

	vpaddd	%xmm7,%xmm14,%xmm14
	vpsrld	$27,%xmm10,%xmm9
	vpxor	%xmm12,%xmm13,%xmm6
	vpxor	%xmm3,%xmm1,%xmm1

	vmovdqu	%xmm0,32-128(%rax)
	vpaddd	%xmm0,%xmm14,%xmm14
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm1,%xmm5
	vpand	%xmm11,%xmm6,%xmm6
	vpaddd	%xmm1,%xmm1,%xmm1

	vpslld	$30,%xmm11,%xmm7
	vpaddd	%xmm6,%xmm14,%xmm14

	vpsrld	$2,%xmm11,%xmm11
	vpaddd	%xmm8,%xmm14,%xmm14
	vpor	%xmm5,%xmm1,%xmm1
	vpor	%xmm7,%xmm11,%xmm11
	vpxor	%xmm4,%xmm2,%xmm2
	vmovdqa	96-128(%rax),%xmm4

	vpaddd	%xmm15,%xmm13,%xmm13
	vpslld	$5,%xmm14,%xmm8
	vpand	%xmm11,%xmm12,%xmm7
	vpxor	192-128(%rax),%xmm2,%xmm2

	vpaddd	%xmm7,%xmm13,%xmm13
	vpsrld	$27,%xmm14,%xmm9
	vpxor	%xmm11,%xmm12,%xmm6
	vpxor	%xmm4,%xmm2,%xmm2

	vmovdqu	%xmm1,48-128(%rax)
	vpaddd	%xmm1,%xmm13,%xmm13
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm2,%xmm5
	vpand	%xmm10,%xmm6,%xmm6
	vpaddd	%xmm2,%xmm2,%xmm2

	vpslld	$30,%xmm10,%xmm7
	vpaddd	%xmm6,%xmm13,%xmm13

	vpsrld	$2,%xmm10,%xmm10
	vpaddd	%xmm8,%xmm13,%xmm13
	vpor	%xmm5,%xmm2,%xmm2
	vpor	%xmm7,%xmm10,%xmm10
	vpxor	%xmm0,%xmm3,%xmm3
	vmovdqa	112-128(%rax),%xmm0

	vpaddd	%xmm15,%xmm12,%xmm12
	vpslld	$5,%xmm13,%xmm8
	vpand	%xmm10,%xmm11,%xmm7
	vpxor	208-128(%rax),%xmm3,%xmm3

	vpaddd	%xmm7,%xmm12,%xmm12
	vpsrld	$27,%xmm13,%xmm9
	vpxor	%xmm10,%xmm11,%xmm6
	vpxor	%xmm0,%xmm3,%xmm3

	vmovdqu	%xmm2,64-128(%rax)
	vpaddd	%xmm2,%xmm12,%xmm12
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm3,%xmm5
	vpand	%xmm14,%xmm6,%xmm6
	vpaddd	%xmm3,%xmm3,%xmm3

	vpslld	$30,%xmm14,%xmm7
	vpaddd	%xmm6,%xmm12,%xmm12

	vpsrld	$2,%xmm14,%xmm14
	vpaddd	%xmm8,%xmm12,%xmm12
	vpor	%xmm5,%xmm3,%xmm3
	vpor	%xmm7,%xmm14,%xmm14
	vpxor	%xmm1,%xmm4,%xmm4
	vmovdqa	128-128(%rax),%xmm1

	vpaddd	%xmm15,%xmm11,%xmm11
	vpslld	$5,%xmm12,%xmm8
	vpand	%xmm14,%xmm10,%xmm7
	vpxor	224-128(%rax),%xmm4,%xmm4

	vpaddd	%xmm7,%xmm11,%xmm11
	vpsrld	$27,%xmm12,%xmm9
	vpxor	%xmm14,%xmm10,%xmm6
	vpxor	%xmm1,%xmm4,%xmm4

	vmovdqu	%xmm3,80-128(%rax)
	vpaddd	%xmm3,%xmm11,%xmm11
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm4,%xmm5
	vpand	%xmm13,%xmm6,%xmm6
	vpaddd	%xmm4,%xmm4,%xmm4

	vpslld	$30,%xmm13,%xmm7
	vpaddd	%xmm6,%xmm11,%xmm11

	vpsrld	$2,%xmm13,%xmm13
	vpaddd	%xmm8,%xmm11,%xmm11
	vpor	%xmm5,%xmm4,%xmm4
	vpor	%xmm7,%xmm13,%xmm13
	vpxor	%xmm2,%xmm0,%xmm0
	vmovdqa	144-128(%rax),%xmm2

	vpaddd	%xmm15,%xmm10,%xmm10
	vpslld	$5,%xmm11,%xmm8
	vpand	%xmm13,%xmm14,%xmm7
	vpxor	240-128(%rax),%xmm0,%xmm0

	vpaddd	%xmm7,%xmm10,%xmm10
	vpsrld	$27,%xmm11,%xmm9
	vpxor	%xmm13,%xmm14,%xmm6
	vpxor	%xmm2,%xmm0,%xmm0

	vmovdqu	%xmm4,96-128(%rax)
	vpaddd	%xmm4,%xmm10,%xmm10
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm0,%xmm5
	vpand	%xmm12,%xmm6,%xmm6
	vpaddd	%xmm0,%xmm0,%xmm0

	vpslld	$30,%xmm12,%xmm7
	vpaddd	%xmm6,%xmm10,%xmm10

	vpsrld	$2,%xmm12,%xmm12
	vpaddd	%xmm8,%xmm10,%xmm10
	vpor	%xmm5,%xmm0,%xmm0
	vpor	%xmm7,%xmm12,%xmm12
	vpxor	%xmm3,%xmm1,%xmm1
	vmovdqa	160-128(%rax),%xmm3

	vpaddd	%xmm15,%xmm14,%xmm14
	vpslld	$5,%xmm10,%xmm8
	vpand	%xmm12,%xmm13,%xmm7
	vpxor	0-128(%rax),%xmm1,%xmm1

	vpaddd	%xmm7,%xmm14,%xmm14
	vpsrld	$27,%xmm10,%xmm9
	vpxor	%xmm12,%xmm13,%xmm6
	vpxor	%xmm3,%xmm1,%xmm1

	vmovdqu	%xmm0,112-128(%rax)
	vpaddd	%xmm0,%xmm14,%xmm14
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm1,%xmm5
	vpand	%xmm11,%xmm6,%xmm6
	vpaddd	%xmm1,%xmm1,%xmm1

	vpslld	$30,%xmm11,%xmm7
	vpaddd	%xmm6,%xmm14,%xmm14

	vpsrld	$2,%xmm11,%xmm11
	vpaddd	%xmm8,%xmm14,%xmm14
	vpor	%xmm5,%xmm1,%xmm1
	vpor	%xmm7,%xmm11,%xmm11
	vpxor	%xmm4,%xmm2,%xmm2
	vmovdqa	176-128(%rax),%xmm4

	vpaddd	%xmm15,%xmm13,%xmm13
	vpslld	$5,%xmm14,%xmm8
	vpand	%xmm11,%xmm12,%xmm7
	vpxor	16-128(%rax),%xmm2,%xmm2

	vpaddd	%xmm7,%xmm13,%xmm13
	vpsrld	$27,%xmm14,%xmm9
	vpxor	%xmm11,%xmm12,%xmm6
	vpxor	%xmm4,%xmm2,%xmm2

	vmovdqu	%xmm1,128-128(%rax)
	vpaddd	%xmm1,%xmm13,%xmm13
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm2,%xmm5
	vpand	%xmm10,%xmm6,%xmm6
	vpaddd	%xmm2,%xmm2,%xmm2

	vpslld	$30,%xmm10,%xmm7
	vpaddd	%xmm6,%xmm13,%xmm13

	vpsrld	$2,%xmm10,%xmm10
	vpaddd	%xmm8,%xmm13,%xmm13
	vpor	%xmm5,%xmm2,%xmm2
	vpor	%xmm7,%xmm10,%xmm10
	vpxor	%xmm0,%xmm3,%xmm3
	vmovdqa	192-128(%rax),%xmm0

	vpaddd	%xmm15,%xmm12,%xmm12
	vpslld	$5,%xmm13,%xmm8
	vpand	%xmm10,%xmm11,%xmm7
	vpxor	32-128(%rax),%xmm3,%xmm3

	vpaddd	%xmm7,%xmm12,%xmm12
	vpsrld	$27,%xmm13,%xmm9
	vpxor	%xmm10,%xmm11,%xmm6
	vpxor	%xmm0,%xmm3,%xmm3

	vmovdqu	%xmm2,144-128(%rax)
	vpaddd	%xmm2,%xmm12,%xmm12
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm3,%xmm5
	vpand	%xmm14,%xmm6,%xmm6
	vpaddd	%xmm3,%xmm3,%xmm3

	vpslld	$30,%xmm14,%xmm7
	vpaddd	%xmm6,%xmm12,%xmm12

	vpsrld	$2,%xmm14,%xmm14
	vpaddd	%xmm8,%xmm12,%xmm12
	vpor	%xmm5,%xmm3,%xmm3
	vpor	%xmm7,%xmm14,%xmm14
	vpxor	%xmm1,%xmm4,%xmm4
	vmovdqa	208-128(%rax),%xmm1

	vpaddd	%xmm15,%xmm11,%xmm11
	vpslld	$5,%xmm12,%xmm8
	vpand	%xmm14,%xmm10,%xmm7
	vpxor	48-128(%rax),%xmm4,%xmm4

	vpaddd	%xmm7,%xmm11,%xmm11
	vpsrld	$27,%xmm12,%xmm9
	vpxor	%xmm14,%xmm10,%xmm6
	vpxor	%xmm1,%xmm4,%xmm4

	vmovdqu	%xmm3,160-128(%rax)
	vpaddd	%xmm3,%xmm11,%xmm11
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm4,%xmm5
	vpand	%xmm13,%xmm6,%xmm6
	vpaddd	%xmm4,%xmm4,%xmm4

	vpslld	$30,%xmm13,%xmm7
	vpaddd	%xmm6,%xmm11,%xmm11

	vpsrld	$2,%xmm13,%xmm13
	vpaddd	%xmm8,%xmm11,%xmm11
	vpor	%xmm5,%xmm4,%xmm4
	vpor	%xmm7,%xmm13,%xmm13
	vpxor	%xmm2,%xmm0,%xmm0
	vmovdqa	224-128(%rax),%xmm2

	vpaddd	%xmm15,%xmm10,%xmm10
	vpslld	$5,%xmm11,%xmm8
	vpand	%xmm13,%xmm14,%xmm7
	vpxor	64-128(%rax),%xmm0,%xmm0

	vpaddd	%xmm7,%xmm10,%xmm10
	vpsrld	$27,%xmm11,%xmm9
	vpxor	%xmm13,%xmm14,%xmm6
	vpxor	%xmm2,%xmm0,%xmm0

	vmovdqu	%xmm4,176-128(%rax)
	vpaddd	%xmm4,%xmm10,%xmm10
	vpor	%xmm9,%xmm8,%xmm8
	vpsrld	$31,%xmm0,%xmm5
	vpand	%xmm12,%xmm6,%xmm6
	vpaddd	%xmm0,%xmm0,%xmm0

	vpslld	$30,%xmm12,%xmm7
	vpaddd	%xmm6,%xmm10,%xmm10

	vpsrld	$2,%xmm12,%xmm12
	vpaddd	%xmm8,%xmm10,%xmm10
	vpor	%xmm5,%xmm0,%xmm0
	vpor	%xmm7,%xmm12,%xmm12
	vmovdqa	64(%rbp),%xmm15
	vpxor	%xmm3,%xmm1,%xmm1
	vmovdqa	240-128(%rax),%xmm3

	vpslld	$5,%xmm10,%xmm8
	vpaddd	%xmm15,%xmm14,%xmm14
	vpxor	%xmm11,%xmm13,%xmm6
	vmovdqa	%xmm0,192-128(%rax)
	vpaddd	%xmm0,%xmm14,%xmm14
	vpxor	80-128(%rax),%xmm1,%xmm1
	vpsrld	$27,%xmm10,%xmm9
	vpxor	%xmm12,%xmm6,%xmm6
	vpxor	%xmm3,%xmm1,%xmm1

	vpslld	$30,%xmm11,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm14,%xmm14
	vpsrld	$31,%xmm1,%xmm5
	vpaddd	%xmm1,%xmm1,%xmm1

	vpsrld	$2,%xmm11,%xmm11
	vpaddd	%xmm8,%xmm14,%xmm14
	vpor	%xmm5,%xmm1,%xmm1
	vpor	%xmm7,%xmm11,%xmm11
	vpxor	%xmm4,%xmm2,%xmm2
	vmovdqa	0-128(%rax),%xmm4

	vpslld	$5,%xmm14,%xmm8
	vpaddd	%xmm15,%xmm13,%xmm13
	vpxor	%xmm10,%xmm12,%xmm6
	vmovdqa	%xmm1,208-128(%rax)
	vpaddd	%xmm1,%xmm13,%xmm13
	vpxor	96-128(%rax),%xmm2,%xmm2
	vpsrld	$27,%xmm14,%xmm9
	vpxor	%xmm11,%xmm6,%xmm6
	vpxor	%xmm4,%xmm2,%xmm2

	vpslld	$30,%xmm10,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm13,%xmm13
	vpsrld	$31,%xmm2,%xmm5
	vpaddd	%xmm2,%xmm2,%xmm2

	vpsrld	$2,%xmm10,%xmm10
	vpaddd	%xmm8,%xmm13,%xmm13
	vpor	%xmm5,%xmm2,%xmm2
	vpor	%xmm7,%xmm10,%xmm10
	vpxor	%xmm0,%xmm3,%xmm3
	vmovdqa	16-128(%rax),%xmm0

	vpslld	$5,%xmm13,%xmm8
	vpaddd	%xmm15,%xmm12,%xmm12
	vpxor	%xmm14,%xmm11,%xmm6
	vmovdqa	%xmm2,224-128(%rax)
	vpaddd	%xmm2,%xmm12,%xmm12
	vpxor	112-128(%rax),%xmm3,%xmm3
	vpsrld	$27,%xmm13,%xmm9
	vpxor	%xmm10,%xmm6,%xmm6
	vpxor	%xmm0,%xmm3,%xmm3

	vpslld	$30,%xmm14,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm12,%xmm12
	vpsrld	$31,%xmm3,%xmm5
	vpaddd	%xmm3,%xmm3,%xmm3

	vpsrld	$2,%xmm14,%xmm14
	vpaddd	%xmm8,%xmm12,%xmm12
	vpor	%xmm5,%xmm3,%xmm3
	vpor	%xmm7,%xmm14,%xmm14
	vpxor	%xmm1,%xmm4,%xmm4
	vmovdqa	32-128(%rax),%xmm1

	vpslld	$5,%xmm12,%xmm8
	vpaddd	%xmm15,%xmm11,%xmm11
	vpxor	%xmm13,%xmm10,%xmm6
	vmovdqa	%xmm3,240-128(%rax)
	vpaddd	%xmm3,%xmm11,%xmm11
	vpxor	128-128(%rax),%xmm4,%xmm4
	vpsrld	$27,%xmm12,%xmm9
	vpxor	%xmm14,%xmm6,%xmm6
	vpxor	%xmm1,%xmm4,%xmm4

	vpslld	$30,%xmm13,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm11,%xmm11
	vpsrld	$31,%xmm4,%xmm5
	vpaddd	%xmm4,%xmm4,%xmm4

	vpsrld	$2,%xmm13,%xmm13
	vpaddd	%xmm8,%xmm11,%xmm11
	vpor	%xmm5,%xmm4,%xmm4
	vpor	%xmm7,%xmm13,%xmm13
	vpxor	%xmm2,%xmm0,%xmm0
	vmovdqa	48-128(%rax),%xmm2

	vpslld	$5,%xmm11,%xmm8
	vpaddd	%xmm15,%xmm10,%xmm10
	vpxor	%xmm12,%xmm14,%xmm6
	vmovdqa	%xmm4,0-128(%rax)
	vpaddd	%xmm4,%xmm10,%xmm10
	vpxor	144-128(%rax),%xmm0,%xmm0
	vpsrld	$27,%xmm11,%xmm9
	vpxor	%xmm13,%xmm6,%xmm6
	vpxor	%xmm2,%xmm0,%xmm0

	vpslld	$30,%xmm12,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm10,%xmm10
	vpsrld	$31,%xmm0,%xmm5
	vpaddd	%xmm0,%xmm0,%xmm0

	vpsrld	$2,%xmm12,%xmm12
	vpaddd	%xmm8,%xmm10,%xmm10
	vpor	%xmm5,%xmm0,%xmm0
	vpor	%xmm7,%xmm12,%xmm12
	vpxor	%xmm3,%xmm1,%xmm1
	vmovdqa	64-128(%rax),%xmm3

	vpslld	$5,%xmm10,%xmm8
	vpaddd	%xmm15,%xmm14,%xmm14
	vpxor	%xmm11,%xmm13,%xmm6
	vmovdqa	%xmm0,16-128(%rax)
	vpaddd	%xmm0,%xmm14,%xmm14
	vpxor	160-128(%rax),%xmm1,%xmm1
	vpsrld	$27,%xmm10,%xmm9
	vpxor	%xmm12,%xmm6,%xmm6
	vpxor	%xmm3,%xmm1,%xmm1

	vpslld	$30,%xmm11,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm14,%xmm14
	vpsrld	$31,%xmm1,%xmm5
	vpaddd	%xmm1,%xmm1,%xmm1

	vpsrld	$2,%xmm11,%xmm11
	vpaddd	%xmm8,%xmm14,%xmm14
	vpor	%xmm5,%xmm1,%xmm1
	vpor	%xmm7,%xmm11,%xmm11
	vpxor	%xmm4,%xmm2,%xmm2
	vmovdqa	80-128(%rax),%xmm4

	vpslld	$5,%xmm14,%xmm8
	vpaddd	%xmm15,%xmm13,%xmm13
	vpxor	%xmm10,%xmm12,%xmm6
	vmovdqa	%xmm1,32-128(%rax)
	vpaddd	%xmm1,%xmm13,%xmm13
	vpxor	176-128(%rax),%xmm2,%xmm2
	vpsrld	$27,%xmm14,%xmm9
	vpxor	%xmm11,%xmm6,%xmm6
	vpxor	%xmm4,%xmm2,%xmm2

	vpslld	$30,%xmm10,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm13,%xmm13
	vpsrld	$31,%xmm2,%xmm5
	vpaddd	%xmm2,%xmm2,%xmm2

	vpsrld	$2,%xmm10,%xmm10
	vpaddd	%xmm8,%xmm13,%xmm13
	vpor	%xmm5,%xmm2,%xmm2
	vpor	%xmm7,%xmm10,%xmm10
	vpxor	%xmm0,%xmm3,%xmm3
	vmovdqa	96-128(%rax),%xmm0

	vpslld	$5,%xmm13,%xmm8
	vpaddd	%xmm15,%xmm12,%xmm12
	vpxor	%xmm14,%xmm11,%xmm6
	vmovdqa	%xmm2,48-128(%rax)
	vpaddd	%xmm2,%xmm12,%xmm12
	vpxor	192-128(%rax),%xmm3,%xmm3
	vpsrld	$27,%xmm13,%xmm9
	vpxor	%xmm10,%xmm6,%xmm6
	vpxor	%xmm0,%xmm3,%xmm3

	vpslld	$30,%xmm14,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm12,%xmm12
	vpsrld	$31,%xmm3,%xmm5
	vpaddd	%xmm3,%xmm3,%xmm3

	vpsrld	$2,%xmm14,%xmm14
	vpaddd	%xmm8,%xmm12,%xmm12
	vpor	%xmm5,%xmm3,%xmm3
	vpor	%xmm7,%xmm14,%xmm14
	vpxor	%xmm1,%xmm4,%xmm4
	vmovdqa	112-128(%rax),%xmm1

	vpslld	$5,%xmm12,%xmm8
	vpaddd	%xmm15,%xmm11,%xmm11
	vpxor	%xmm13,%xmm10,%xmm6
	vmovdqa	%xmm3,64-128(%rax)
	vpaddd	%xmm3,%xmm11,%xmm11
	vpxor	208-128(%rax),%xmm4,%xmm4
	vpsrld	$27,%xmm12,%xmm9
	vpxor	%xmm14,%xmm6,%xmm6
	vpxor	%xmm1,%xmm4,%xmm4

	vpslld	$30,%xmm13,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm11,%xmm11
	vpsrld	$31,%xmm4,%xmm5
	vpaddd	%xmm4,%xmm4,%xmm4

	vpsrld	$2,%xmm13,%xmm13
	vpaddd	%xmm8,%xmm11,%xmm11
	vpor	%xmm5,%xmm4,%xmm4
	vpor	%xmm7,%xmm13,%xmm13
	vpxor	%xmm2,%xmm0,%xmm0
	vmovdqa	128-128(%rax),%xmm2

	vpslld	$5,%xmm11,%xmm8
	vpaddd	%xmm15,%xmm10,%xmm10
	vpxor	%xmm12,%xmm14,%xmm6
	vmovdqa	%xmm4,80-128(%rax)
	vpaddd	%xmm4,%xmm10,%xmm10
	vpxor	224-128(%rax),%xmm0,%xmm0
	vpsrld	$27,%xmm11,%xmm9
	vpxor	%xmm13,%xmm6,%xmm6
	vpxor	%xmm2,%xmm0,%xmm0

	vpslld	$30,%xmm12,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm10,%xmm10
	vpsrld	$31,%xmm0,%xmm5
	vpaddd	%xmm0,%xmm0,%xmm0

	vpsrld	$2,%xmm12,%xmm12
	vpaddd	%xmm8,%xmm10,%xmm10
	vpor	%xmm5,%xmm0,%xmm0
	vpor	%xmm7,%xmm12,%xmm12
	vpxor	%xmm3,%xmm1,%xmm1
	vmovdqa	144-128(%rax),%xmm3

	vpslld	$5,%xmm10,%xmm8
	vpaddd	%xmm15,%xmm14,%xmm14
	vpxor	%xmm11,%xmm13,%xmm6
	vmovdqa	%xmm0,96-128(%rax)
	vpaddd	%xmm0,%xmm14,%xmm14
	vpxor	240-128(%rax),%xmm1,%xmm1
	vpsrld	$27,%xmm10,%xmm9
	vpxor	%xmm12,%xmm6,%xmm6
	vpxor	%xmm3,%xmm1,%xmm1

	vpslld	$30,%xmm11,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm14,%xmm14
	vpsrld	$31,%xmm1,%xmm5
	vpaddd	%xmm1,%xmm1,%xmm1

	vpsrld	$2,%xmm11,%xmm11
	vpaddd	%xmm8,%xmm14,%xmm14
	vpor	%xmm5,%xmm1,%xmm1
	vpor	%xmm7,%xmm11,%xmm11
	vpxor	%xmm4,%xmm2,%xmm2
	vmovdqa	160-128(%rax),%xmm4

	vpslld	$5,%xmm14,%xmm8
	vpaddd	%xmm15,%xmm13,%xmm13
	vpxor	%xmm10,%xmm12,%xmm6
	vmovdqa	%xmm1,112-128(%rax)
	vpaddd	%xmm1,%xmm13,%xmm13
	vpxor	0-128(%rax),%xmm2,%xmm2
	vpsrld	$27,%xmm14,%xmm9
	vpxor	%xmm11,%xmm6,%xmm6
	vpxor	%xmm4,%xmm2,%xmm2

	vpslld	$30,%xmm10,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm13,%xmm13
	vpsrld	$31,%xmm2,%xmm5
	vpaddd	%xmm2,%xmm2,%xmm2

	vpsrld	$2,%xmm10,%xmm10
	vpaddd	%xmm8,%xmm13,%xmm13
	vpor	%xmm5,%xmm2,%xmm2
	vpor	%xmm7,%xmm10,%xmm10
	vpxor	%xmm0,%xmm3,%xmm3
	vmovdqa	176-128(%rax),%xmm0

	vpslld	$5,%xmm13,%xmm8
	vpaddd	%xmm15,%xmm12,%xmm12
	vpxor	%xmm14,%xmm11,%xmm6
	vpaddd	%xmm2,%xmm12,%xmm12
	vpxor	16-128(%rax),%xmm3,%xmm3
	vpsrld	$27,%xmm13,%xmm9
	vpxor	%xmm10,%xmm6,%xmm6
	vpxor	%xmm0,%xmm3,%xmm3

	vpslld	$30,%xmm14,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm12,%xmm12
	vpsrld	$31,%xmm3,%xmm5
	vpaddd	%xmm3,%xmm3,%xmm3

	vpsrld	$2,%xmm14,%xmm14
	vpaddd	%xmm8,%xmm12,%xmm12
	vpor	%xmm5,%xmm3,%xmm3
	vpor	%xmm7,%xmm14,%xmm14
	vpxor	%xmm1,%xmm4,%xmm4
	vmovdqa	192-128(%rax),%xmm1

	vpslld	$5,%xmm12,%xmm8
	vpaddd	%xmm15,%xmm11,%xmm11
	vpxor	%xmm13,%xmm10,%xmm6
	vpaddd	%xmm3,%xmm11,%xmm11
	vpxor	32-128(%rax),%xmm4,%xmm4
	vpsrld	$27,%xmm12,%xmm9
	vpxor	%xmm14,%xmm6,%xmm6
	vpxor	%xmm1,%xmm4,%xmm4

	vpslld	$30,%xmm13,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm11,%xmm11
	vpsrld	$31,%xmm4,%xmm5
	vpaddd	%xmm4,%xmm4,%xmm4

	vpsrld	$2,%xmm13,%xmm13
	vpaddd	%xmm8,%xmm11,%xmm11
	vpor	%xmm5,%xmm4,%xmm4
	vpor	%xmm7,%xmm13,%xmm13
	vpxor	%xmm2,%xmm0,%xmm0
	vmovdqa	208-128(%rax),%xmm2

	vpslld	$5,%xmm11,%xmm8
	vpaddd	%xmm15,%xmm10,%xmm10
	vpxor	%xmm12,%xmm14,%xmm6
	vpaddd	%xmm4,%xmm10,%xmm10
	vpxor	48-128(%rax),%xmm0,%xmm0
	vpsrld	$27,%xmm11,%xmm9
	vpxor	%xmm13,%xmm6,%xmm6
	vpxor	%xmm2,%xmm0,%xmm0

	vpslld	$30,%xmm12,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm10,%xmm10
	vpsrld	$31,%xmm0,%xmm5
	vpaddd	%xmm0,%xmm0,%xmm0

	vpsrld	$2,%xmm12,%xmm12
	vpaddd	%xmm8,%xmm10,%xmm10
	vpor	%xmm5,%xmm0,%xmm0
	vpor	%xmm7,%xmm12,%xmm12
	vpxor	%xmm3,%xmm1,%xmm1
	vmovdqa	224-128(%rax),%xmm3

	vpslld	$5,%xmm10,%xmm8
	vpaddd	%xmm15,%xmm14,%xmm14
	vpxor	%xmm11,%xmm13,%xmm6
	vpaddd	%xmm0,%xmm14,%xmm14
	vpxor	64-128(%rax),%xmm1,%xmm1
	vpsrld	$27,%xmm10,%xmm9
	vpxor	%xmm12,%xmm6,%xmm6
	vpxor	%xmm3,%xmm1,%xmm1

	vpslld	$30,%xmm11,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm14,%xmm14
	vpsrld	$31,%xmm1,%xmm5
	vpaddd	%xmm1,%xmm1,%xmm1

	vpsrld	$2,%xmm11,%xmm11
	vpaddd	%xmm8,%xmm14,%xmm14
	vpor	%xmm5,%xmm1,%xmm1
	vpor	%xmm7,%xmm11,%xmm11
	vpxor	%xmm4,%xmm2,%xmm2
	vmovdqa	240-128(%rax),%xmm4

	vpslld	$5,%xmm14,%xmm8
	vpaddd	%xmm15,%xmm13,%xmm13
	vpxor	%xmm10,%xmm12,%xmm6
	vpaddd	%xmm1,%xmm13,%xmm13
	vpxor	80-128(%rax),%xmm2,%xmm2
	vpsrld	$27,%xmm14,%xmm9
	vpxor	%xmm11,%xmm6,%xmm6
	vpxor	%xmm4,%xmm2,%xmm2

	vpslld	$30,%xmm10,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm13,%xmm13
	vpsrld	$31,%xmm2,%xmm5
	vpaddd	%xmm2,%xmm2,%xmm2

	vpsrld	$2,%xmm10,%xmm10
	vpaddd	%xmm8,%xmm13,%xmm13
	vpor	%xmm5,%xmm2,%xmm2
	vpor	%xmm7,%xmm10,%xmm10
	vpxor	%xmm0,%xmm3,%xmm3
	vmovdqa	0-128(%rax),%xmm0

	vpslld	$5,%xmm13,%xmm8
	vpaddd	%xmm15,%xmm12,%xmm12
	vpxor	%xmm14,%xmm11,%xmm6
	vpaddd	%xmm2,%xmm12,%xmm12
	vpxor	96-128(%rax),%xmm3,%xmm3
	vpsrld	$27,%xmm13,%xmm9
	vpxor	%xmm10,%xmm6,%xmm6
	vpxor	%xmm0,%xmm3,%xmm3

	vpslld	$30,%xmm14,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm12,%xmm12
	vpsrld	$31,%xmm3,%xmm5
	vpaddd	%xmm3,%xmm3,%xmm3

	vpsrld	$2,%xmm14,%xmm14
	vpaddd	%xmm8,%xmm12,%xmm12
	vpor	%xmm5,%xmm3,%xmm3
	vpor	%xmm7,%xmm14,%xmm14
	vpxor	%xmm1,%xmm4,%xmm4
	vmovdqa	16-128(%rax),%xmm1

	vpslld	$5,%xmm12,%xmm8
	vpaddd	%xmm15,%xmm11,%xmm11
	vpxor	%xmm13,%xmm10,%xmm6
	vpaddd	%xmm3,%xmm11,%xmm11
	vpxor	112-128(%rax),%xmm4,%xmm4
	vpsrld	$27,%xmm12,%xmm9
	vpxor	%xmm14,%xmm6,%xmm6
	vpxor	%xmm1,%xmm4,%xmm4

	vpslld	$30,%xmm13,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm11,%xmm11
	vpsrld	$31,%xmm4,%xmm5
	vpaddd	%xmm4,%xmm4,%xmm4

	vpsrld	$2,%xmm13,%xmm13
	vpaddd	%xmm8,%xmm11,%xmm11
	vpor	%xmm5,%xmm4,%xmm4
	vpor	%xmm7,%xmm13,%xmm13
	vpslld	$5,%xmm11,%xmm8
	vpaddd	%xmm15,%xmm10,%xmm10
	vpxor	%xmm12,%xmm14,%xmm6

	vpsrld	$27,%xmm11,%xmm9
	vpaddd	%xmm4,%xmm10,%xmm10
	vpxor	%xmm13,%xmm6,%xmm6

	vpslld	$30,%xmm12,%xmm7
	vpor	%xmm9,%xmm8,%xmm8
	vpaddd	%xmm6,%xmm10,%xmm10

	vpsrld	$2,%xmm12,%xmm12
	vpaddd	%xmm8,%xmm10,%xmm10
	vpor	%xmm7,%xmm12,%xmm12
	movl	$1,%ecx
	cmpl	0(%rbx),%ecx
	cmovgeq	%rbp,%r8
	cmpl	4(%rbx),%ecx
	cmovgeq	%rbp,%r9
	cmpl	8(%rbx),%ecx
	cmovgeq	%rbp,%r10
	cmpl	12(%rbx),%ecx
	cmovgeq	%rbp,%r11
	vmovdqu	(%rbx),%xmm6
	vpxor	%xmm8,%xmm8,%xmm8
	vmovdqa	%xmm6,%xmm7
	vpcmpgtd	%xmm8,%xmm7,%xmm7
	vpaddd	%xmm7,%xmm6,%xmm6

	vpand	%xmm7,%xmm10,%xmm10
	vpand	%xmm7,%xmm11,%xmm11
	vpaddd	0(%rdi),%xmm10,%xmm10
	vpand	%xmm7,%xmm12,%xmm12
	vpaddd	32(%rdi),%xmm11,%xmm11
	vpand	%xmm7,%xmm13,%xmm13
	vpaddd	64(%rdi),%xmm12,%xmm12
	vpand	%xmm7,%xmm14,%xmm14
	vpaddd	96(%rdi),%xmm13,%xmm13
	vpaddd	128(%rdi),%xmm14,%xmm14
	vmovdqu	%xmm10,0(%rdi)
	vmovdqu	%xmm11,32(%rdi)
	vmovdqu	%xmm12,64(%rdi)
	vmovdqu	%xmm13,96(%rdi)
	vmovdqu	%xmm14,128(%rdi)

	vmovdqu	%xmm6,(%rbx)
	vmovdqu	96(%rbp),%xmm5
	decl	%edx
	jnz	.Loop_avx

	movl	280(%rsp),%edx
	leaq	16(%rdi),%rdi
	leaq	64(%rsi),%rsi
	decl	%edx
	jnz	.Loop_grande_avx

.Ldone_avx:
	movq	272(%rsp),%rax
.cfi_def_cfa	%rax,8
	vzeroupper
	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue_avx:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha1_multi_block_avx,.-sha1_multi_block_avx
.type	sha1_multi_block_avx2,@function
.align	32
sha1_multi_block_avx2:
.cfi_startproc	
_avx2_shortcut:
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
	subq	$576,%rsp
	andq	$-256,%rsp
	movq	%rax,544(%rsp)
.cfi_escape	0x0f,0x06,0x77,0xa0,0x04,0x06,0x23,0x08
.Lbody_avx2:
	leaq	K_XX_XX(%rip),%rbp
	shrl	$1,%edx

	vzeroupper
.Loop_grande_avx2:
	movl	%edx,552(%rsp)
	xorl	%edx,%edx
	leaq	512(%rsp),%rbx

	movq	0(%rsi),%r12

	movl	8(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,0(%rbx)
	cmovleq	%rbp,%r12

	movq	16(%rsi),%r13

	movl	24(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,4(%rbx)
	cmovleq	%rbp,%r13

	movq	32(%rsi),%r14

	movl	40(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,8(%rbx)
	cmovleq	%rbp,%r14

	movq	48(%rsi),%r15

	movl	56(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,12(%rbx)
	cmovleq	%rbp,%r15

	movq	64(%rsi),%r8

	movl	72(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,16(%rbx)
	cmovleq	%rbp,%r8

	movq	80(%rsi),%r9

	movl	88(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,20(%rbx)
	cmovleq	%rbp,%r9

	movq	96(%rsi),%r10

	movl	104(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,24(%rbx)
	cmovleq	%rbp,%r10

	movq	112(%rsi),%r11

	movl	120(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,28(%rbx)
	cmovleq	%rbp,%r11
	vmovdqu	0(%rdi),%ymm0
	leaq	128(%rsp),%rax
	vmovdqu	32(%rdi),%ymm1
	leaq	256+128(%rsp),%rbx
	vmovdqu	64(%rdi),%ymm2
	vmovdqu	96(%rdi),%ymm3
	vmovdqu	128(%rdi),%ymm4
	vmovdqu	96(%rbp),%ymm9
	jmp	.Loop_avx2

.align	32
.Loop_avx2:
	vmovdqa	-32(%rbp),%ymm15
	vmovd	(%r12),%xmm10
	leaq	64(%r12),%r12
	vmovd	(%r8),%xmm12
	leaq	64(%r8),%r8
	vmovd	(%r13),%xmm7
	leaq	64(%r13),%r13
	vmovd	(%r9),%xmm6
	leaq	64(%r9),%r9
	vpinsrd	$1,(%r14),%xmm10,%xmm10
	leaq	64(%r14),%r14
	vpinsrd	$1,(%r10),%xmm12,%xmm12
	leaq	64(%r10),%r10
	vpinsrd	$1,(%r15),%xmm7,%xmm7
	leaq	64(%r15),%r15
	vpunpckldq	%ymm7,%ymm10,%ymm10
	vpinsrd	$1,(%r11),%xmm6,%xmm6
	leaq	64(%r11),%r11
	vpunpckldq	%ymm6,%ymm12,%ymm12
	vmovd	-60(%r12),%xmm11
	vinserti128	$1,%xmm12,%ymm10,%ymm10
	vmovd	-60(%r8),%xmm8
	vpshufb	%ymm9,%ymm10,%ymm10
	vmovd	-60(%r13),%xmm7
	vmovd	-60(%r9),%xmm6
	vpinsrd	$1,-60(%r14),%xmm11,%xmm11
	vpinsrd	$1,-60(%r10),%xmm8,%xmm8
	vpinsrd	$1,-60(%r15),%xmm7,%xmm7
	vpunpckldq	%ymm7,%ymm11,%ymm11
	vpinsrd	$1,-60(%r11),%xmm6,%xmm6
	vpunpckldq	%ymm6,%ymm8,%ymm8
	vpaddd	%ymm15,%ymm4,%ymm4
	vpslld	$5,%ymm0,%ymm7
	vpandn	%ymm3,%ymm1,%ymm6
	vpand	%ymm2,%ymm1,%ymm5

	vmovdqa	%ymm10,0-128(%rax)
	vpaddd	%ymm10,%ymm4,%ymm4
	vinserti128	$1,%xmm8,%ymm11,%ymm11
	vpsrld	$27,%ymm0,%ymm8
	vpxor	%ymm6,%ymm5,%ymm5
	vmovd	-56(%r12),%xmm12

	vpslld	$30,%ymm1,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vmovd	-56(%r8),%xmm8
	vpaddd	%ymm5,%ymm4,%ymm4

	vpsrld	$2,%ymm1,%ymm1
	vpaddd	%ymm7,%ymm4,%ymm4
	vpshufb	%ymm9,%ymm11,%ymm11
	vpor	%ymm6,%ymm1,%ymm1
	vmovd	-56(%r13),%xmm7
	vmovd	-56(%r9),%xmm6
	vpinsrd	$1,-56(%r14),%xmm12,%xmm12
	vpinsrd	$1,-56(%r10),%xmm8,%xmm8
	vpinsrd	$1,-56(%r15),%xmm7,%xmm7
	vpunpckldq	%ymm7,%ymm12,%ymm12
	vpinsrd	$1,-56(%r11),%xmm6,%xmm6
	vpunpckldq	%ymm6,%ymm8,%ymm8
	vpaddd	%ymm15,%ymm3,%ymm3
	vpslld	$5,%ymm4,%ymm7
	vpandn	%ymm2,%ymm0,%ymm6
	vpand	%ymm1,%ymm0,%ymm5

	vmovdqa	%ymm11,32-128(%rax)
	vpaddd	%ymm11,%ymm3,%ymm3
	vinserti128	$1,%xmm8,%ymm12,%ymm12
	vpsrld	$27,%ymm4,%ymm8
	vpxor	%ymm6,%ymm5,%ymm5
	vmovd	-52(%r12),%xmm13

	vpslld	$30,%ymm0,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vmovd	-52(%r8),%xmm8
	vpaddd	%ymm5,%ymm3,%ymm3

	vpsrld	$2,%ymm0,%ymm0
	vpaddd	%ymm7,%ymm3,%ymm3
	vpshufb	%ymm9,%ymm12,%ymm12
	vpor	%ymm6,%ymm0,%ymm0
	vmovd	-52(%r13),%xmm7
	vmovd	-52(%r9),%xmm6
	vpinsrd	$1,-52(%r14),%xmm13,%xmm13
	vpinsrd	$1,-52(%r10),%xmm8,%xmm8
	vpinsrd	$1,-52(%r15),%xmm7,%xmm7
	vpunpckldq	%ymm7,%ymm13,%ymm13
	vpinsrd	$1,-52(%r11),%xmm6,%xmm6
	vpunpckldq	%ymm6,%ymm8,%ymm8
	vpaddd	%ymm15,%ymm2,%ymm2
	vpslld	$5,%ymm3,%ymm7
	vpandn	%ymm1,%ymm4,%ymm6
	vpand	%ymm0,%ymm4,%ymm5

	vmovdqa	%ymm12,64-128(%rax)
	vpaddd	%ymm12,%ymm2,%ymm2
	vinserti128	$1,%xmm8,%ymm13,%ymm13
	vpsrld	$27,%ymm3,%ymm8
	vpxor	%ymm6,%ymm5,%ymm5
	vmovd	-48(%r12),%xmm14

	vpslld	$30,%ymm4,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vmovd	-48(%r8),%xmm8
	vpaddd	%ymm5,%ymm2,%ymm2

	vpsrld	$2,%ymm4,%ymm4
	vpaddd	%ymm7,%ymm2,%ymm2
	vpshufb	%ymm9,%ymm13,%ymm13
	vpor	%ymm6,%ymm4,%ymm4
	vmovd	-48(%r13),%xmm7
	vmovd	-48(%r9),%xmm6
	vpinsrd	$1,-48(%r14),%xmm14,%xmm14
	vpinsrd	$1,-48(%r10),%xmm8,%xmm8
	vpinsrd	$1,-48(%r15),%xmm7,%xmm7
	vpunpckldq	%ymm7,%ymm14,%ymm14
	vpinsrd	$1,-48(%r11),%xmm6,%xmm6
	vpunpckldq	%ymm6,%ymm8,%ymm8
	vpaddd	%ymm15,%ymm1,%ymm1
	vpslld	$5,%ymm2,%ymm7
	vpandn	%ymm0,%ymm3,%ymm6
	vpand	%ymm4,%ymm3,%ymm5

	vmovdqa	%ymm13,96-128(%rax)
	vpaddd	%ymm13,%ymm1,%ymm1
	vinserti128	$1,%xmm8,%ymm14,%ymm14
	vpsrld	$27,%ymm2,%ymm8
	vpxor	%ymm6,%ymm5,%ymm5
	vmovd	-44(%r12),%xmm10

	vpslld	$30,%ymm3,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vmovd	-44(%r8),%xmm8
	vpaddd	%ymm5,%ymm1,%ymm1

	vpsrld	$2,%ymm3,%ymm3
	vpaddd	%ymm7,%ymm1,%ymm1
	vpshufb	%ymm9,%ymm14,%ymm14
	vpor	%ymm6,%ymm3,%ymm3
	vmovd	-44(%r13),%xmm7
	vmovd	-44(%r9),%xmm6
	vpinsrd	$1,-44(%r14),%xmm10,%xmm10
	vpinsrd	$1,-44(%r10),%xmm8,%xmm8
	vpinsrd	$1,-44(%r15),%xmm7,%xmm7
	vpunpckldq	%ymm7,%ymm10,%ymm10
	vpinsrd	$1,-44(%r11),%xmm6,%xmm6
	vpunpckldq	%ymm6,%ymm8,%ymm8
	vpaddd	%ymm15,%ymm0,%ymm0
	vpslld	$5,%ymm1,%ymm7
	vpandn	%ymm4,%ymm2,%ymm6
	vpand	%ymm3,%ymm2,%ymm5

	vmovdqa	%ymm14,128-128(%rax)
	vpaddd	%ymm14,%ymm0,%ymm0
	vinserti128	$1,%xmm8,%ymm10,%ymm10
	vpsrld	$27,%ymm1,%ymm8
	vpxor	%ymm6,%ymm5,%ymm5
	vmovd	-40(%r12),%xmm11

	vpslld	$30,%ymm2,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vmovd	-40(%r8),%xmm8
	vpaddd	%ymm5,%ymm0,%ymm0

	vpsrld	$2,%ymm2,%ymm2
	vpaddd	%ymm7,%ymm0,%ymm0
	vpshufb	%ymm9,%ymm10,%ymm10
	vpor	%ymm6,%ymm2,%ymm2
	vmovd	-40(%r13),%xmm7
	vmovd	-40(%r9),%xmm6
	vpinsrd	$1,-40(%r14),%xmm11,%xmm11
	vpinsrd	$1,-40(%r10),%xmm8,%xmm8
	vpinsrd	$1,-40(%r15),%xmm7,%xmm7
	vpunpckldq	%ymm7,%ymm11,%ymm11
	vpinsrd	$1,-40(%r11),%xmm6,%xmm6
	vpunpckldq	%ymm6,%ymm8,%ymm8
	vpaddd	%ymm15,%ymm4,%ymm4
	vpslld	$5,%ymm0,%ymm7
	vpandn	%ymm3,%ymm1,%ymm6
	vpand	%ymm2,%ymm1,%ymm5

	vmovdqa	%ymm10,160-128(%rax)
	vpaddd	%ymm10,%ymm4,%ymm4
	vinserti128	$1,%xmm8,%ymm11,%ymm11
	vpsrld	$27,%ymm0,%ymm8
	vpxor	%ymm6,%ymm5,%ymm5
	vmovd	-36(%r12),%xmm12

	vpslld	$30,%ymm1,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vmovd	-36(%r8),%xmm8
	vpaddd	%ymm5,%ymm4,%ymm4

	vpsrld	$2,%ymm1,%ymm1
	vpaddd	%ymm7,%ymm4,%ymm4
	vpshufb	%ymm9,%ymm11,%ymm11
	vpor	%ymm6,%ymm1,%ymm1
	vmovd	-36(%r13),%xmm7
	vmovd	-36(%r9),%xmm6
	vpinsrd	$1,-36(%r14),%xmm12,%xmm12
	vpinsrd	$1,-36(%r10),%xmm8,%xmm8
	vpinsrd	$1,-36(%r15),%xmm7,%xmm7
	vpunpckldq	%ymm7,%ymm12,%ymm12
	vpinsrd	$1,-36(%r11),%xmm6,%xmm6
	vpunpckldq	%ymm6,%ymm8,%ymm8
	vpaddd	%ymm15,%ymm3,%ymm3
	vpslld	$5,%ymm4,%ymm7
	vpandn	%ymm2,%ymm0,%ymm6
	vpand	%ymm1,%ymm0,%ymm5

	vmovdqa	%ymm11,192-128(%rax)
	vpaddd	%ymm11,%ymm3,%ymm3
	vinserti128	$1,%xmm8,%ymm12,%ymm12
	vpsrld	$27,%ymm4,%ymm8
	vpxor	%ymm6,%ymm5,%ymm5
	vmovd	-32(%r12),%xmm13

	vpslld	$30,%ymm0,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vmovd	-32(%r8),%xmm8
	vpaddd	%ymm5,%ymm3,%ymm3

	vpsrld	$2,%ymm0,%ymm0
	vpaddd	%ymm7,%ymm3,%ymm3
	vpshufb	%ymm9,%ymm12,%ymm12
	vpor	%ymm6,%ymm0,%ymm0
	vmovd	-32(%r13),%xmm7
	vmovd	-32(%r9),%xmm6
	vpinsrd	$1,-32(%r14),%xmm13,%xmm13
	vpinsrd	$1,-32(%r10),%xmm8,%xmm8
	vpinsrd	$1,-32(%r15),%xmm7,%xmm7
	vpunpckldq	%ymm7,%ymm13,%ymm13
	vpinsrd	$1,-32(%r11),%xmm6,%xmm6
	vpunpckldq	%ymm6,%ymm8,%ymm8
	vpaddd	%ymm15,%ymm2,%ymm2
	vpslld	$5,%ymm3,%ymm7
	vpandn	%ymm1,%ymm4,%ymm6
	vpand	%ymm0,%ymm4,%ymm5

	vmovdqa	%ymm12,224-128(%rax)
	vpaddd	%ymm12,%ymm2,%ymm2
	vinserti128	$1,%xmm8,%ymm13,%ymm13
	vpsrld	$27,%ymm3,%ymm8
	vpxor	%ymm6,%ymm5,%ymm5
	vmovd	-28(%r12),%xmm14

	vpslld	$30,%ymm4,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vmovd	-28(%r8),%xmm8
	vpaddd	%ymm5,%ymm2,%ymm2

	vpsrld	$2,%ymm4,%ymm4
	vpaddd	%ymm7,%ymm2,%ymm2
	vpshufb	%ymm9,%ymm13,%ymm13
	vpor	%ymm6,%ymm4,%ymm4
	vmovd	-28(%r13),%xmm7
	vmovd	-28(%r9),%xmm6
	vpinsrd	$1,-28(%r14),%xmm14,%xmm14
	vpinsrd	$1,-28(%r10),%xmm8,%xmm8
	vpinsrd	$1,-28(%r15),%xmm7,%xmm7
	vpunpckldq	%ymm7,%ymm14,%ymm14
	vpinsrd	$1,-28(%r11),%xmm6,%xmm6
	vpunpckldq	%ymm6,%ymm8,%ymm8
	vpaddd	%ymm15,%ymm1,%ymm1
	vpslld	$5,%ymm2,%ymm7
	vpandn	%ymm0,%ymm3,%ymm6
	vpand	%ymm4,%ymm3,%ymm5

	vmovdqa	%ymm13,256-256-128(%rbx)
	vpaddd	%ymm13,%ymm1,%ymm1
	vinserti128	$1,%xmm8,%ymm14,%ymm14
	vpsrld	$27,%ymm2,%ymm8
	vpxor	%ymm6,%ymm5,%ymm5
	vmovd	-24(%r12),%xmm10

	vpslld	$30,%ymm3,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vmovd	-24(%r8),%xmm8
	vpaddd	%ymm5,%ymm1,%ymm1

	vpsrld	$2,%ymm3,%ymm3
	vpaddd	%ymm7,%ymm1,%ymm1
	vpshufb	%ymm9,%ymm14,%ymm14
	vpor	%ymm6,%ymm3,%ymm3
	vmovd	-24(%r13),%xmm7
	vmovd	-24(%r9),%xmm6
	vpinsrd	$1,-24(%r14),%xmm10,%xmm10
	vpinsrd	$1,-24(%r10),%xmm8,%xmm8
	vpinsrd	$1,-24(%r15),%xmm7,%xmm7
	vpunpckldq	%ymm7,%ymm10,%ymm10
	vpinsrd	$1,-24(%r11),%xmm6,%xmm6
	vpunpckldq	%ymm6,%ymm8,%ymm8
	vpaddd	%ymm15,%ymm0,%ymm0
	vpslld	$5,%ymm1,%ymm7
	vpandn	%ymm4,%ymm2,%ymm6
	vpand	%ymm3,%ymm2,%ymm5

	vmovdqa	%ymm14,288-256-128(%rbx)
	vpaddd	%ymm14,%ymm0,%ymm0
	vinserti128	$1,%xmm8,%ymm10,%ymm10
	vpsrld	$27,%ymm1,%ymm8
	vpxor	%ymm6,%ymm5,%ymm5
	vmovd	-20(%r12),%xmm11

	vpslld	$30,%ymm2,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vmovd	-20(%r8),%xmm8
	vpaddd	%ymm5,%ymm0,%ymm0

	vpsrld	$2,%ymm2,%ymm2
	vpaddd	%ymm7,%ymm0,%ymm0
	vpshufb	%ymm9,%ymm10,%ymm10
	vpor	%ymm6,%ymm2,%ymm2
	vmovd	-20(%r13),%xmm7
	vmovd	-20(%r9),%xmm6
	vpinsrd	$1,-20(%r14),%xmm11,%xmm11
	vpinsrd	$1,-20(%r10),%xmm8,%xmm8
	vpinsrd	$1,-20(%r15),%xmm7,%xmm7
	vpunpckldq	%ymm7,%ymm11,%ymm11
	vpinsrd	$1,-20(%r11),%xmm6,%xmm6
	vpunpckldq	%ymm6,%ymm8,%ymm8
	vpaddd	%ymm15,%ymm4,%ymm4
	vpslld	$5,%ymm0,%ymm7
	vpandn	%ymm3,%ymm1,%ymm6
	vpand	%ymm2,%ymm1,%ymm5

	vmovdqa	%ymm10,320-256-128(%rbx)
	vpaddd	%ymm10,%ymm4,%ymm4
	vinserti128	$1,%xmm8,%ymm11,%ymm11
	vpsrld	$27,%ymm0,%ymm8
	vpxor	%ymm6,%ymm5,%ymm5
	vmovd	-16(%r12),%xmm12

	vpslld	$30,%ymm1,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vmovd	-16(%r8),%xmm8
	vpaddd	%ymm5,%ymm4,%ymm4

	vpsrld	$2,%ymm1,%ymm1
	vpaddd	%ymm7,%ymm4,%ymm4
	vpshufb	%ymm9,%ymm11,%ymm11
	vpor	%ymm6,%ymm1,%ymm1
	vmovd	-16(%r13),%xmm7
	vmovd	-16(%r9),%xmm6
	vpinsrd	$1,-16(%r14),%xmm12,%xmm12
	vpinsrd	$1,-16(%r10),%xmm8,%xmm8
	vpinsrd	$1,-16(%r15),%xmm7,%xmm7
	vpunpckldq	%ymm7,%ymm12,%ymm12
	vpinsrd	$1,-16(%r11),%xmm6,%xmm6
	vpunpckldq	%ymm6,%ymm8,%ymm8
	vpaddd	%ymm15,%ymm3,%ymm3
	vpslld	$5,%ymm4,%ymm7
	vpandn	%ymm2,%ymm0,%ymm6
	vpand	%ymm1,%ymm0,%ymm5

	vmovdqa	%ymm11,352-256-128(%rbx)
	vpaddd	%ymm11,%ymm3,%ymm3
	vinserti128	$1,%xmm8,%ymm12,%ymm12
	vpsrld	$27,%ymm4,%ymm8
	vpxor	%ymm6,%ymm5,%ymm5
	vmovd	-12(%r12),%xmm13

	vpslld	$30,%ymm0,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vmovd	-12(%r8),%xmm8
	vpaddd	%ymm5,%ymm3,%ymm3

	vpsrld	$2,%ymm0,%ymm0
	vpaddd	%ymm7,%ymm3,%ymm3
	vpshufb	%ymm9,%ymm12,%ymm12
	vpor	%ymm6,%ymm0,%ymm0
	vmovd	-12(%r13),%xmm7
	vmovd	-12(%r9),%xmm6
	vpinsrd	$1,-12(%r14),%xmm13,%xmm13
	vpinsrd	$1,-12(%r10),%xmm8,%xmm8
	vpinsrd	$1,-12(%r15),%xmm7,%xmm7
	vpunpckldq	%ymm7,%ymm13,%ymm13
	vpinsrd	$1,-12(%r11),%xmm6,%xmm6
	vpunpckldq	%ymm6,%ymm8,%ymm8
	vpaddd	%ymm15,%ymm2,%ymm2
	vpslld	$5,%ymm3,%ymm7
	vpandn	%ymm1,%ymm4,%ymm6
	vpand	%ymm0,%ymm4,%ymm5

	vmovdqa	%ymm12,384-256-128(%rbx)
	vpaddd	%ymm12,%ymm2,%ymm2
	vinserti128	$1,%xmm8,%ymm13,%ymm13
	vpsrld	$27,%ymm3,%ymm8
	vpxor	%ymm6,%ymm5,%ymm5
	vmovd	-8(%r12),%xmm14

	vpslld	$30,%ymm4,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vmovd	-8(%r8),%xmm8
	vpaddd	%ymm5,%ymm2,%ymm2

	vpsrld	$2,%ymm4,%ymm4
	vpaddd	%ymm7,%ymm2,%ymm2
	vpshufb	%ymm9,%ymm13,%ymm13
	vpor	%ymm6,%ymm4,%ymm4
	vmovd	-8(%r13),%xmm7
	vmovd	-8(%r9),%xmm6
	vpinsrd	$1,-8(%r14),%xmm14,%xmm14
	vpinsrd	$1,-8(%r10),%xmm8,%xmm8
	vpinsrd	$1,-8(%r15),%xmm7,%xmm7
	vpunpckldq	%ymm7,%ymm14,%ymm14
	vpinsrd	$1,-8(%r11),%xmm6,%xmm6
	vpunpckldq	%ymm6,%ymm8,%ymm8
	vpaddd	%ymm15,%ymm1,%ymm1
	vpslld	$5,%ymm2,%ymm7
	vpandn	%ymm0,%ymm3,%ymm6
	vpand	%ymm4,%ymm3,%ymm5

	vmovdqa	%ymm13,416-256-128(%rbx)
	vpaddd	%ymm13,%ymm1,%ymm1
	vinserti128	$1,%xmm8,%ymm14,%ymm14
	vpsrld	$27,%ymm2,%ymm8
	vpxor	%ymm6,%ymm5,%ymm5
	vmovd	-4(%r12),%xmm10

	vpslld	$30,%ymm3,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vmovd	-4(%r8),%xmm8
	vpaddd	%ymm5,%ymm1,%ymm1

	vpsrld	$2,%ymm3,%ymm3
	vpaddd	%ymm7,%ymm1,%ymm1
	vpshufb	%ymm9,%ymm14,%ymm14
	vpor	%ymm6,%ymm3,%ymm3
	vmovdqa	0-128(%rax),%ymm11
	vmovd	-4(%r13),%xmm7
	vmovd	-4(%r9),%xmm6
	vpinsrd	$1,-4(%r14),%xmm10,%xmm10
	vpinsrd	$1,-4(%r10),%xmm8,%xmm8
	vpinsrd	$1,-4(%r15),%xmm7,%xmm7
	vpunpckldq	%ymm7,%ymm10,%ymm10
	vpinsrd	$1,-4(%r11),%xmm6,%xmm6
	vpunpckldq	%ymm6,%ymm8,%ymm8
	vpaddd	%ymm15,%ymm0,%ymm0
	prefetcht0	63(%r12)
	vpslld	$5,%ymm1,%ymm7
	vpandn	%ymm4,%ymm2,%ymm6
	vpand	%ymm3,%ymm2,%ymm5

	vmovdqa	%ymm14,448-256-128(%rbx)
	vpaddd	%ymm14,%ymm0,%ymm0
	vinserti128	$1,%xmm8,%ymm10,%ymm10
	vpsrld	$27,%ymm1,%ymm8
	prefetcht0	63(%r13)
	vpxor	%ymm6,%ymm5,%ymm5

	vpslld	$30,%ymm2,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	prefetcht0	63(%r14)
	vpaddd	%ymm5,%ymm0,%ymm0

	vpsrld	$2,%ymm2,%ymm2
	vpaddd	%ymm7,%ymm0,%ymm0
	prefetcht0	63(%r15)
	vpshufb	%ymm9,%ymm10,%ymm10
	vpor	%ymm6,%ymm2,%ymm2
	vmovdqa	32-128(%rax),%ymm12
	vpxor	%ymm13,%ymm11,%ymm11
	vmovdqa	64-128(%rax),%ymm13

	vpaddd	%ymm15,%ymm4,%ymm4
	vpslld	$5,%ymm0,%ymm7
	vpandn	%ymm3,%ymm1,%ymm6
	prefetcht0	63(%r8)
	vpand	%ymm2,%ymm1,%ymm5

	vmovdqa	%ymm10,480-256-128(%rbx)
	vpaddd	%ymm10,%ymm4,%ymm4
	vpxor	256-256-128(%rbx),%ymm11,%ymm11
	vpsrld	$27,%ymm0,%ymm8
	vpxor	%ymm6,%ymm5,%ymm5
	vpxor	%ymm13,%ymm11,%ymm11
	prefetcht0	63(%r9)

	vpslld	$30,%ymm1,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm4,%ymm4
	prefetcht0	63(%r10)
	vpsrld	$31,%ymm11,%ymm9
	vpaddd	%ymm11,%ymm11,%ymm11

	vpsrld	$2,%ymm1,%ymm1
	prefetcht0	63(%r11)
	vpaddd	%ymm7,%ymm4,%ymm4
	vpor	%ymm9,%ymm11,%ymm11
	vpor	%ymm6,%ymm1,%ymm1
	vpxor	%ymm14,%ymm12,%ymm12
	vmovdqa	96-128(%rax),%ymm14

	vpaddd	%ymm15,%ymm3,%ymm3
	vpslld	$5,%ymm4,%ymm7
	vpandn	%ymm2,%ymm0,%ymm6

	vpand	%ymm1,%ymm0,%ymm5

	vmovdqa	%ymm11,0-128(%rax)
	vpaddd	%ymm11,%ymm3,%ymm3
	vpxor	288-256-128(%rbx),%ymm12,%ymm12
	vpsrld	$27,%ymm4,%ymm8
	vpxor	%ymm6,%ymm5,%ymm5
	vpxor	%ymm14,%ymm12,%ymm12


	vpslld	$30,%ymm0,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm3,%ymm3

	vpsrld	$31,%ymm12,%ymm9
	vpaddd	%ymm12,%ymm12,%ymm12

	vpsrld	$2,%ymm0,%ymm0

	vpaddd	%ymm7,%ymm3,%ymm3
	vpor	%ymm9,%ymm12,%ymm12
	vpor	%ymm6,%ymm0,%ymm0
	vpxor	%ymm10,%ymm13,%ymm13
	vmovdqa	128-128(%rax),%ymm10

	vpaddd	%ymm15,%ymm2,%ymm2
	vpslld	$5,%ymm3,%ymm7
	vpandn	%ymm1,%ymm4,%ymm6

	vpand	%ymm0,%ymm4,%ymm5

	vmovdqa	%ymm12,32-128(%rax)
	vpaddd	%ymm12,%ymm2,%ymm2
	vpxor	320-256-128(%rbx),%ymm13,%ymm13
	vpsrld	$27,%ymm3,%ymm8
	vpxor	%ymm6,%ymm5,%ymm5
	vpxor	%ymm10,%ymm13,%ymm13


	vpslld	$30,%ymm4,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm2,%ymm2

	vpsrld	$31,%ymm13,%ymm9
	vpaddd	%ymm13,%ymm13,%ymm13

	vpsrld	$2,%ymm4,%ymm4

	vpaddd	%ymm7,%ymm2,%ymm2
	vpor	%ymm9,%ymm13,%ymm13
	vpor	%ymm6,%ymm4,%ymm4
	vpxor	%ymm11,%ymm14,%ymm14
	vmovdqa	160-128(%rax),%ymm11

	vpaddd	%ymm15,%ymm1,%ymm1
	vpslld	$5,%ymm2,%ymm7
	vpandn	%ymm0,%ymm3,%ymm6

	vpand	%ymm4,%ymm3,%ymm5

	vmovdqa	%ymm13,64-128(%rax)
	vpaddd	%ymm13,%ymm1,%ymm1
	vpxor	352-256-128(%rbx),%ymm14,%ymm14
	vpsrld	$27,%ymm2,%ymm8
	vpxor	%ymm6,%ymm5,%ymm5
	vpxor	%ymm11,%ymm14,%ymm14


	vpslld	$30,%ymm3,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm1,%ymm1

	vpsrld	$31,%ymm14,%ymm9
	vpaddd	%ymm14,%ymm14,%ymm14

	vpsrld	$2,%ymm3,%ymm3

	vpaddd	%ymm7,%ymm1,%ymm1
	vpor	%ymm9,%ymm14,%ymm14
	vpor	%ymm6,%ymm3,%ymm3
	vpxor	%ymm12,%ymm10,%ymm10
	vmovdqa	192-128(%rax),%ymm12

	vpaddd	%ymm15,%ymm0,%ymm0
	vpslld	$5,%ymm1,%ymm7
	vpandn	%ymm4,%ymm2,%ymm6

	vpand	%ymm3,%ymm2,%ymm5

	vmovdqa	%ymm14,96-128(%rax)
	vpaddd	%ymm14,%ymm0,%ymm0
	vpxor	384-256-128(%rbx),%ymm10,%ymm10
	vpsrld	$27,%ymm1,%ymm8
	vpxor	%ymm6,%ymm5,%ymm5
	vpxor	%ymm12,%ymm10,%ymm10


	vpslld	$30,%ymm2,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm0,%ymm0

	vpsrld	$31,%ymm10,%ymm9
	vpaddd	%ymm10,%ymm10,%ymm10

	vpsrld	$2,%ymm2,%ymm2

	vpaddd	%ymm7,%ymm0,%ymm0
	vpor	%ymm9,%ymm10,%ymm10
	vpor	%ymm6,%ymm2,%ymm2
	vmovdqa	0(%rbp),%ymm15
	vpxor	%ymm13,%ymm11,%ymm11
	vmovdqa	224-128(%rax),%ymm13

	vpslld	$5,%ymm0,%ymm7
	vpaddd	%ymm15,%ymm4,%ymm4
	vpxor	%ymm1,%ymm3,%ymm5
	vmovdqa	%ymm10,128-128(%rax)
	vpaddd	%ymm10,%ymm4,%ymm4
	vpxor	416-256-128(%rbx),%ymm11,%ymm11
	vpsrld	$27,%ymm0,%ymm8
	vpxor	%ymm2,%ymm5,%ymm5
	vpxor	%ymm13,%ymm11,%ymm11

	vpslld	$30,%ymm1,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm4,%ymm4
	vpsrld	$31,%ymm11,%ymm9
	vpaddd	%ymm11,%ymm11,%ymm11

	vpsrld	$2,%ymm1,%ymm1
	vpaddd	%ymm7,%ymm4,%ymm4
	vpor	%ymm9,%ymm11,%ymm11
	vpor	%ymm6,%ymm1,%ymm1
	vpxor	%ymm14,%ymm12,%ymm12
	vmovdqa	256-256-128(%rbx),%ymm14

	vpslld	$5,%ymm4,%ymm7
	vpaddd	%ymm15,%ymm3,%ymm3
	vpxor	%ymm0,%ymm2,%ymm5
	vmovdqa	%ymm11,160-128(%rax)
	vpaddd	%ymm11,%ymm3,%ymm3
	vpxor	448-256-128(%rbx),%ymm12,%ymm12
	vpsrld	$27,%ymm4,%ymm8
	vpxor	%ymm1,%ymm5,%ymm5
	vpxor	%ymm14,%ymm12,%ymm12

	vpslld	$30,%ymm0,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm3,%ymm3
	vpsrld	$31,%ymm12,%ymm9
	vpaddd	%ymm12,%ymm12,%ymm12

	vpsrld	$2,%ymm0,%ymm0
	vpaddd	%ymm7,%ymm3,%ymm3
	vpor	%ymm9,%ymm12,%ymm12
	vpor	%ymm6,%ymm0,%ymm0
	vpxor	%ymm10,%ymm13,%ymm13
	vmovdqa	288-256-128(%rbx),%ymm10

	vpslld	$5,%ymm3,%ymm7
	vpaddd	%ymm15,%ymm2,%ymm2
	vpxor	%ymm4,%ymm1,%ymm5
	vmovdqa	%ymm12,192-128(%rax)
	vpaddd	%ymm12,%ymm2,%ymm2
	vpxor	480-256-128(%rbx),%ymm13,%ymm13
	vpsrld	$27,%ymm3,%ymm8
	vpxor	%ymm0,%ymm5,%ymm5
	vpxor	%ymm10,%ymm13,%ymm13

	vpslld	$30,%ymm4,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm2,%ymm2
	vpsrld	$31,%ymm13,%ymm9
	vpaddd	%ymm13,%ymm13,%ymm13

	vpsrld	$2,%ymm4,%ymm4
	vpaddd	%ymm7,%ymm2,%ymm2
	vpor	%ymm9,%ymm13,%ymm13
	vpor	%ymm6,%ymm4,%ymm4
	vpxor	%ymm11,%ymm14,%ymm14
	vmovdqa	320-256-128(%rbx),%ymm11

	vpslld	$5,%ymm2,%ymm7
	vpaddd	%ymm15,%ymm1,%ymm1
	vpxor	%ymm3,%ymm0,%ymm5
	vmovdqa	%ymm13,224-128(%rax)
	vpaddd	%ymm13,%ymm1,%ymm1
	vpxor	0-128(%rax),%ymm14,%ymm14
	vpsrld	$27,%ymm2,%ymm8
	vpxor	%ymm4,%ymm5,%ymm5
	vpxor	%ymm11,%ymm14,%ymm14

	vpslld	$30,%ymm3,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm1,%ymm1
	vpsrld	$31,%ymm14,%ymm9
	vpaddd	%ymm14,%ymm14,%ymm14

	vpsrld	$2,%ymm3,%ymm3
	vpaddd	%ymm7,%ymm1,%ymm1
	vpor	%ymm9,%ymm14,%ymm14
	vpor	%ymm6,%ymm3,%ymm3
	vpxor	%ymm12,%ymm10,%ymm10
	vmovdqa	352-256-128(%rbx),%ymm12

	vpslld	$5,%ymm1,%ymm7
	vpaddd	%ymm15,%ymm0,%ymm0
	vpxor	%ymm2,%ymm4,%ymm5
	vmovdqa	%ymm14,256-256-128(%rbx)
	vpaddd	%ymm14,%ymm0,%ymm0
	vpxor	32-128(%rax),%ymm10,%ymm10
	vpsrld	$27,%ymm1,%ymm8
	vpxor	%ymm3,%ymm5,%ymm5
	vpxor	%ymm12,%ymm10,%ymm10

	vpslld	$30,%ymm2,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm0,%ymm0
	vpsrld	$31,%ymm10,%ymm9
	vpaddd	%ymm10,%ymm10,%ymm10

	vpsrld	$2,%ymm2,%ymm2
	vpaddd	%ymm7,%ymm0,%ymm0
	vpor	%ymm9,%ymm10,%ymm10
	vpor	%ymm6,%ymm2,%ymm2
	vpxor	%ymm13,%ymm11,%ymm11
	vmovdqa	384-256-128(%rbx),%ymm13

	vpslld	$5,%ymm0,%ymm7
	vpaddd	%ymm15,%ymm4,%ymm4
	vpxor	%ymm1,%ymm3,%ymm5
	vmovdqa	%ymm10,288-256-128(%rbx)
	vpaddd	%ymm10,%ymm4,%ymm4
	vpxor	64-128(%rax),%ymm11,%ymm11
	vpsrld	$27,%ymm0,%ymm8
	vpxor	%ymm2,%ymm5,%ymm5
	vpxor	%ymm13,%ymm11,%ymm11

	vpslld	$30,%ymm1,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm4,%ymm4
	vpsrld	$31,%ymm11,%ymm9
	vpaddd	%ymm11,%ymm11,%ymm11

	vpsrld	$2,%ymm1,%ymm1
	vpaddd	%ymm7,%ymm4,%ymm4
	vpor	%ymm9,%ymm11,%ymm11
	vpor	%ymm6,%ymm1,%ymm1
	vpxor	%ymm14,%ymm12,%ymm12
	vmovdqa	416-256-128(%rbx),%ymm14

	vpslld	$5,%ymm4,%ymm7
	vpaddd	%ymm15,%ymm3,%ymm3
	vpxor	%ymm0,%ymm2,%ymm5
	vmovdqa	%ymm11,320-256-128(%rbx)
	vpaddd	%ymm11,%ymm3,%ymm3
	vpxor	96-128(%rax),%ymm12,%ymm12
	vpsrld	$27,%ymm4,%ymm8
	vpxor	%ymm1,%ymm5,%ymm5
	vpxor	%ymm14,%ymm12,%ymm12

	vpslld	$30,%ymm0,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm3,%ymm3
	vpsrld	$31,%ymm12,%ymm9
	vpaddd	%ymm12,%ymm12,%ymm12

	vpsrld	$2,%ymm0,%ymm0
	vpaddd	%ymm7,%ymm3,%ymm3
	vpor	%ymm9,%ymm12,%ymm12
	vpor	%ymm6,%ymm0,%ymm0
	vpxor	%ymm10,%ymm13,%ymm13
	vmovdqa	448-256-128(%rbx),%ymm10

	vpslld	$5,%ymm3,%ymm7
	vpaddd	%ymm15,%ymm2,%ymm2
	vpxor	%ymm4,%ymm1,%ymm5
	vmovdqa	%ymm12,352-256-128(%rbx)
	vpaddd	%ymm12,%ymm2,%ymm2
	vpxor	128-128(%rax),%ymm13,%ymm13
	vpsrld	$27,%ymm3,%ymm8
	vpxor	%ymm0,%ymm5,%ymm5
	vpxor	%ymm10,%ymm13,%ymm13

	vpslld	$30,%ymm4,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm2,%ymm2
	vpsrld	$31,%ymm13,%ymm9
	vpaddd	%ymm13,%ymm13,%ymm13

	vpsrld	$2,%ymm4,%ymm4
	vpaddd	%ymm7,%ymm2,%ymm2
	vpor	%ymm9,%ymm13,%ymm13
	vpor	%ymm6,%ymm4,%ymm4
	vpxor	%ymm11,%ymm14,%ymm14
	vmovdqa	480-256-128(%rbx),%ymm11

	vpslld	$5,%ymm2,%ymm7
	vpaddd	%ymm15,%ymm1,%ymm1
	vpxor	%ymm3,%ymm0,%ymm5
	vmovdqa	%ymm13,384-256-128(%rbx)
	vpaddd	%ymm13,%ymm1,%ymm1
	vpxor	160-128(%rax),%ymm14,%ymm14
	vpsrld	$27,%ymm2,%ymm8
	vpxor	%ymm4,%ymm5,%ymm5
	vpxor	%ymm11,%ymm14,%ymm14

	vpslld	$30,%ymm3,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm1,%ymm1
	vpsrld	$31,%ymm14,%ymm9
	vpaddd	%ymm14,%ymm14,%ymm14

	vpsrld	$2,%ymm3,%ymm3
	vpaddd	%ymm7,%ymm1,%ymm1
	vpor	%ymm9,%ymm14,%ymm14
	vpor	%ymm6,%ymm3,%ymm3
	vpxor	%ymm12,%ymm10,%ymm10
	vmovdqa	0-128(%rax),%ymm12

	vpslld	$5,%ymm1,%ymm7
	vpaddd	%ymm15,%ymm0,%ymm0
	vpxor	%ymm2,%ymm4,%ymm5
	vmovdqa	%ymm14,416-256-128(%rbx)
	vpaddd	%ymm14,%ymm0,%ymm0
	vpxor	192-128(%rax),%ymm10,%ymm10
	vpsrld	$27,%ymm1,%ymm8
	vpxor	%ymm3,%ymm5,%ymm5
	vpxor	%ymm12,%ymm10,%ymm10

	vpslld	$30,%ymm2,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm0,%ymm0
	vpsrld	$31,%ymm10,%ymm9
	vpaddd	%ymm10,%ymm10,%ymm10

	vpsrld	$2,%ymm2,%ymm2
	vpaddd	%ymm7,%ymm0,%ymm0
	vpor	%ymm9,%ymm10,%ymm10
	vpor	%ymm6,%ymm2,%ymm2
	vpxor	%ymm13,%ymm11,%ymm11
	vmovdqa	32-128(%rax),%ymm13

	vpslld	$5,%ymm0,%ymm7
	vpaddd	%ymm15,%ymm4,%ymm4
	vpxor	%ymm1,%ymm3,%ymm5
	vmovdqa	%ymm10,448-256-128(%rbx)
	vpaddd	%ymm10,%ymm4,%ymm4
	vpxor	224-128(%rax),%ymm11,%ymm11
	vpsrld	$27,%ymm0,%ymm8
	vpxor	%ymm2,%ymm5,%ymm5
	vpxor	%ymm13,%ymm11,%ymm11

	vpslld	$30,%ymm1,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm4,%ymm4
	vpsrld	$31,%ymm11,%ymm9
	vpaddd	%ymm11,%ymm11,%ymm11

	vpsrld	$2,%ymm1,%ymm1
	vpaddd	%ymm7,%ymm4,%ymm4
	vpor	%ymm9,%ymm11,%ymm11
	vpor	%ymm6,%ymm1,%ymm1
	vpxor	%ymm14,%ymm12,%ymm12
	vmovdqa	64-128(%rax),%ymm14

	vpslld	$5,%ymm4,%ymm7
	vpaddd	%ymm15,%ymm3,%ymm3
	vpxor	%ymm0,%ymm2,%ymm5
	vmovdqa	%ymm11,480-256-128(%rbx)
	vpaddd	%ymm11,%ymm3,%ymm3
	vpxor	256-256-128(%rbx),%ymm12,%ymm12
	vpsrld	$27,%ymm4,%ymm8
	vpxor	%ymm1,%ymm5,%ymm5
	vpxor	%ymm14,%ymm12,%ymm12

	vpslld	$30,%ymm0,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm3,%ymm3
	vpsrld	$31,%ymm12,%ymm9
	vpaddd	%ymm12,%ymm12,%ymm12

	vpsrld	$2,%ymm0,%ymm0
	vpaddd	%ymm7,%ymm3,%ymm3
	vpor	%ymm9,%ymm12,%ymm12
	vpor	%ymm6,%ymm0,%ymm0
	vpxor	%ymm10,%ymm13,%ymm13
	vmovdqa	96-128(%rax),%ymm10

	vpslld	$5,%ymm3,%ymm7
	vpaddd	%ymm15,%ymm2,%ymm2
	vpxor	%ymm4,%ymm1,%ymm5
	vmovdqa	%ymm12,0-128(%rax)
	vpaddd	%ymm12,%ymm2,%ymm2
	vpxor	288-256-128(%rbx),%ymm13,%ymm13
	vpsrld	$27,%ymm3,%ymm8
	vpxor	%ymm0,%ymm5,%ymm5
	vpxor	%ymm10,%ymm13,%ymm13

	vpslld	$30,%ymm4,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm2,%ymm2
	vpsrld	$31,%ymm13,%ymm9
	vpaddd	%ymm13,%ymm13,%ymm13

	vpsrld	$2,%ymm4,%ymm4
	vpaddd	%ymm7,%ymm2,%ymm2
	vpor	%ymm9,%ymm13,%ymm13
	vpor	%ymm6,%ymm4,%ymm4
	vpxor	%ymm11,%ymm14,%ymm14
	vmovdqa	128-128(%rax),%ymm11

	vpslld	$5,%ymm2,%ymm7
	vpaddd	%ymm15,%ymm1,%ymm1
	vpxor	%ymm3,%ymm0,%ymm5
	vmovdqa	%ymm13,32-128(%rax)
	vpaddd	%ymm13,%ymm1,%ymm1
	vpxor	320-256-128(%rbx),%ymm14,%ymm14
	vpsrld	$27,%ymm2,%ymm8
	vpxor	%ymm4,%ymm5,%ymm5
	vpxor	%ymm11,%ymm14,%ymm14

	vpslld	$30,%ymm3,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm1,%ymm1
	vpsrld	$31,%ymm14,%ymm9
	vpaddd	%ymm14,%ymm14,%ymm14

	vpsrld	$2,%ymm3,%ymm3
	vpaddd	%ymm7,%ymm1,%ymm1
	vpor	%ymm9,%ymm14,%ymm14
	vpor	%ymm6,%ymm3,%ymm3
	vpxor	%ymm12,%ymm10,%ymm10
	vmovdqa	160-128(%rax),%ymm12

	vpslld	$5,%ymm1,%ymm7
	vpaddd	%ymm15,%ymm0,%ymm0
	vpxor	%ymm2,%ymm4,%ymm5
	vmovdqa	%ymm14,64-128(%rax)
	vpaddd	%ymm14,%ymm0,%ymm0
	vpxor	352-256-128(%rbx),%ymm10,%ymm10
	vpsrld	$27,%ymm1,%ymm8
	vpxor	%ymm3,%ymm5,%ymm5
	vpxor	%ymm12,%ymm10,%ymm10

	vpslld	$30,%ymm2,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm0,%ymm0
	vpsrld	$31,%ymm10,%ymm9
	vpaddd	%ymm10,%ymm10,%ymm10

	vpsrld	$2,%ymm2,%ymm2
	vpaddd	%ymm7,%ymm0,%ymm0
	vpor	%ymm9,%ymm10,%ymm10
	vpor	%ymm6,%ymm2,%ymm2
	vpxor	%ymm13,%ymm11,%ymm11
	vmovdqa	192-128(%rax),%ymm13

	vpslld	$5,%ymm0,%ymm7
	vpaddd	%ymm15,%ymm4,%ymm4
	vpxor	%ymm1,%ymm3,%ymm5
	vmovdqa	%ymm10,96-128(%rax)
	vpaddd	%ymm10,%ymm4,%ymm4
	vpxor	384-256-128(%rbx),%ymm11,%ymm11
	vpsrld	$27,%ymm0,%ymm8
	vpxor	%ymm2,%ymm5,%ymm5
	vpxor	%ymm13,%ymm11,%ymm11

	vpslld	$30,%ymm1,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm4,%ymm4
	vpsrld	$31,%ymm11,%ymm9
	vpaddd	%ymm11,%ymm11,%ymm11

	vpsrld	$2,%ymm1,%ymm1
	vpaddd	%ymm7,%ymm4,%ymm4
	vpor	%ymm9,%ymm11,%ymm11
	vpor	%ymm6,%ymm1,%ymm1
	vpxor	%ymm14,%ymm12,%ymm12
	vmovdqa	224-128(%rax),%ymm14

	vpslld	$5,%ymm4,%ymm7
	vpaddd	%ymm15,%ymm3,%ymm3
	vpxor	%ymm0,%ymm2,%ymm5
	vmovdqa	%ymm11,128-128(%rax)
	vpaddd	%ymm11,%ymm3,%ymm3
	vpxor	416-256-128(%rbx),%ymm12,%ymm12
	vpsrld	$27,%ymm4,%ymm8
	vpxor	%ymm1,%ymm5,%ymm5
	vpxor	%ymm14,%ymm12,%ymm12

	vpslld	$30,%ymm0,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm3,%ymm3
	vpsrld	$31,%ymm12,%ymm9
	vpaddd	%ymm12,%ymm12,%ymm12

	vpsrld	$2,%ymm0,%ymm0
	vpaddd	%ymm7,%ymm3,%ymm3
	vpor	%ymm9,%ymm12,%ymm12
	vpor	%ymm6,%ymm0,%ymm0
	vpxor	%ymm10,%ymm13,%ymm13
	vmovdqa	256-256-128(%rbx),%ymm10

	vpslld	$5,%ymm3,%ymm7
	vpaddd	%ymm15,%ymm2,%ymm2
	vpxor	%ymm4,%ymm1,%ymm5
	vmovdqa	%ymm12,160-128(%rax)
	vpaddd	%ymm12,%ymm2,%ymm2
	vpxor	448-256-128(%rbx),%ymm13,%ymm13
	vpsrld	$27,%ymm3,%ymm8
	vpxor	%ymm0,%ymm5,%ymm5
	vpxor	%ymm10,%ymm13,%ymm13

	vpslld	$30,%ymm4,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm2,%ymm2
	vpsrld	$31,%ymm13,%ymm9
	vpaddd	%ymm13,%ymm13,%ymm13

	vpsrld	$2,%ymm4,%ymm4
	vpaddd	%ymm7,%ymm2,%ymm2
	vpor	%ymm9,%ymm13,%ymm13
	vpor	%ymm6,%ymm4,%ymm4
	vpxor	%ymm11,%ymm14,%ymm14
	vmovdqa	288-256-128(%rbx),%ymm11

	vpslld	$5,%ymm2,%ymm7
	vpaddd	%ymm15,%ymm1,%ymm1
	vpxor	%ymm3,%ymm0,%ymm5
	vmovdqa	%ymm13,192-128(%rax)
	vpaddd	%ymm13,%ymm1,%ymm1
	vpxor	480-256-128(%rbx),%ymm14,%ymm14
	vpsrld	$27,%ymm2,%ymm8
	vpxor	%ymm4,%ymm5,%ymm5
	vpxor	%ymm11,%ymm14,%ymm14

	vpslld	$30,%ymm3,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm1,%ymm1
	vpsrld	$31,%ymm14,%ymm9
	vpaddd	%ymm14,%ymm14,%ymm14

	vpsrld	$2,%ymm3,%ymm3
	vpaddd	%ymm7,%ymm1,%ymm1
	vpor	%ymm9,%ymm14,%ymm14
	vpor	%ymm6,%ymm3,%ymm3
	vpxor	%ymm12,%ymm10,%ymm10
	vmovdqa	320-256-128(%rbx),%ymm12

	vpslld	$5,%ymm1,%ymm7
	vpaddd	%ymm15,%ymm0,%ymm0
	vpxor	%ymm2,%ymm4,%ymm5
	vmovdqa	%ymm14,224-128(%rax)
	vpaddd	%ymm14,%ymm0,%ymm0
	vpxor	0-128(%rax),%ymm10,%ymm10
	vpsrld	$27,%ymm1,%ymm8
	vpxor	%ymm3,%ymm5,%ymm5
	vpxor	%ymm12,%ymm10,%ymm10

	vpslld	$30,%ymm2,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm0,%ymm0
	vpsrld	$31,%ymm10,%ymm9
	vpaddd	%ymm10,%ymm10,%ymm10

	vpsrld	$2,%ymm2,%ymm2
	vpaddd	%ymm7,%ymm0,%ymm0
	vpor	%ymm9,%ymm10,%ymm10
	vpor	%ymm6,%ymm2,%ymm2
	vmovdqa	32(%rbp),%ymm15
	vpxor	%ymm13,%ymm11,%ymm11
	vmovdqa	352-256-128(%rbx),%ymm13

	vpaddd	%ymm15,%ymm4,%ymm4
	vpslld	$5,%ymm0,%ymm7
	vpand	%ymm2,%ymm3,%ymm6
	vpxor	32-128(%rax),%ymm11,%ymm11

	vpaddd	%ymm6,%ymm4,%ymm4
	vpsrld	$27,%ymm0,%ymm8
	vpxor	%ymm2,%ymm3,%ymm5
	vpxor	%ymm13,%ymm11,%ymm11

	vmovdqu	%ymm10,256-256-128(%rbx)
	vpaddd	%ymm10,%ymm4,%ymm4
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm11,%ymm9
	vpand	%ymm1,%ymm5,%ymm5
	vpaddd	%ymm11,%ymm11,%ymm11

	vpslld	$30,%ymm1,%ymm6
	vpaddd	%ymm5,%ymm4,%ymm4

	vpsrld	$2,%ymm1,%ymm1
	vpaddd	%ymm7,%ymm4,%ymm4
	vpor	%ymm9,%ymm11,%ymm11
	vpor	%ymm6,%ymm1,%ymm1
	vpxor	%ymm14,%ymm12,%ymm12
	vmovdqa	384-256-128(%rbx),%ymm14

	vpaddd	%ymm15,%ymm3,%ymm3
	vpslld	$5,%ymm4,%ymm7
	vpand	%ymm1,%ymm2,%ymm6
	vpxor	64-128(%rax),%ymm12,%ymm12

	vpaddd	%ymm6,%ymm3,%ymm3
	vpsrld	$27,%ymm4,%ymm8
	vpxor	%ymm1,%ymm2,%ymm5
	vpxor	%ymm14,%ymm12,%ymm12

	vmovdqu	%ymm11,288-256-128(%rbx)
	vpaddd	%ymm11,%ymm3,%ymm3
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm12,%ymm9
	vpand	%ymm0,%ymm5,%ymm5
	vpaddd	%ymm12,%ymm12,%ymm12

	vpslld	$30,%ymm0,%ymm6
	vpaddd	%ymm5,%ymm3,%ymm3

	vpsrld	$2,%ymm0,%ymm0
	vpaddd	%ymm7,%ymm3,%ymm3
	vpor	%ymm9,%ymm12,%ymm12
	vpor	%ymm6,%ymm0,%ymm0
	vpxor	%ymm10,%ymm13,%ymm13
	vmovdqa	416-256-128(%rbx),%ymm10

	vpaddd	%ymm15,%ymm2,%ymm2
	vpslld	$5,%ymm3,%ymm7
	vpand	%ymm0,%ymm1,%ymm6
	vpxor	96-128(%rax),%ymm13,%ymm13

	vpaddd	%ymm6,%ymm2,%ymm2
	vpsrld	$27,%ymm3,%ymm8
	vpxor	%ymm0,%ymm1,%ymm5
	vpxor	%ymm10,%ymm13,%ymm13

	vmovdqu	%ymm12,320-256-128(%rbx)
	vpaddd	%ymm12,%ymm2,%ymm2
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm13,%ymm9
	vpand	%ymm4,%ymm5,%ymm5
	vpaddd	%ymm13,%ymm13,%ymm13

	vpslld	$30,%ymm4,%ymm6
	vpaddd	%ymm5,%ymm2,%ymm2

	vpsrld	$2,%ymm4,%ymm4
	vpaddd	%ymm7,%ymm2,%ymm2
	vpor	%ymm9,%ymm13,%ymm13
	vpor	%ymm6,%ymm4,%ymm4
	vpxor	%ymm11,%ymm14,%ymm14
	vmovdqa	448-256-128(%rbx),%ymm11

	vpaddd	%ymm15,%ymm1,%ymm1
	vpslld	$5,%ymm2,%ymm7
	vpand	%ymm4,%ymm0,%ymm6
	vpxor	128-128(%rax),%ymm14,%ymm14

	vpaddd	%ymm6,%ymm1,%ymm1
	vpsrld	$27,%ymm2,%ymm8
	vpxor	%ymm4,%ymm0,%ymm5
	vpxor	%ymm11,%ymm14,%ymm14

	vmovdqu	%ymm13,352-256-128(%rbx)
	vpaddd	%ymm13,%ymm1,%ymm1
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm14,%ymm9
	vpand	%ymm3,%ymm5,%ymm5
	vpaddd	%ymm14,%ymm14,%ymm14

	vpslld	$30,%ymm3,%ymm6
	vpaddd	%ymm5,%ymm1,%ymm1

	vpsrld	$2,%ymm3,%ymm3
	vpaddd	%ymm7,%ymm1,%ymm1
	vpor	%ymm9,%ymm14,%ymm14
	vpor	%ymm6,%ymm3,%ymm3
	vpxor	%ymm12,%ymm10,%ymm10
	vmovdqa	480-256-128(%rbx),%ymm12

	vpaddd	%ymm15,%ymm0,%ymm0
	vpslld	$5,%ymm1,%ymm7
	vpand	%ymm3,%ymm4,%ymm6
	vpxor	160-128(%rax),%ymm10,%ymm10

	vpaddd	%ymm6,%ymm0,%ymm0
	vpsrld	$27,%ymm1,%ymm8
	vpxor	%ymm3,%ymm4,%ymm5
	vpxor	%ymm12,%ymm10,%ymm10

	vmovdqu	%ymm14,384-256-128(%rbx)
	vpaddd	%ymm14,%ymm0,%ymm0
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm10,%ymm9
	vpand	%ymm2,%ymm5,%ymm5
	vpaddd	%ymm10,%ymm10,%ymm10

	vpslld	$30,%ymm2,%ymm6
	vpaddd	%ymm5,%ymm0,%ymm0

	vpsrld	$2,%ymm2,%ymm2
	vpaddd	%ymm7,%ymm0,%ymm0
	vpor	%ymm9,%ymm10,%ymm10
	vpor	%ymm6,%ymm2,%ymm2
	vpxor	%ymm13,%ymm11,%ymm11
	vmovdqa	0-128(%rax),%ymm13

	vpaddd	%ymm15,%ymm4,%ymm4
	vpslld	$5,%ymm0,%ymm7
	vpand	%ymm2,%ymm3,%ymm6
	vpxor	192-128(%rax),%ymm11,%ymm11

	vpaddd	%ymm6,%ymm4,%ymm4
	vpsrld	$27,%ymm0,%ymm8
	vpxor	%ymm2,%ymm3,%ymm5
	vpxor	%ymm13,%ymm11,%ymm11

	vmovdqu	%ymm10,416-256-128(%rbx)
	vpaddd	%ymm10,%ymm4,%ymm4
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm11,%ymm9
	vpand	%ymm1,%ymm5,%ymm5
	vpaddd	%ymm11,%ymm11,%ymm11

	vpslld	$30,%ymm1,%ymm6
	vpaddd	%ymm5,%ymm4,%ymm4

	vpsrld	$2,%ymm1,%ymm1
	vpaddd	%ymm7,%ymm4,%ymm4
	vpor	%ymm9,%ymm11,%ymm11
	vpor	%ymm6,%ymm1,%ymm1
	vpxor	%ymm14,%ymm12,%ymm12
	vmovdqa	32-128(%rax),%ymm14

	vpaddd	%ymm15,%ymm3,%ymm3
	vpslld	$5,%ymm4,%ymm7
	vpand	%ymm1,%ymm2,%ymm6
	vpxor	224-128(%rax),%ymm12,%ymm12

	vpaddd	%ymm6,%ymm3,%ymm3
	vpsrld	$27,%ymm4,%ymm8
	vpxor	%ymm1,%ymm2,%ymm5
	vpxor	%ymm14,%ymm12,%ymm12

	vmovdqu	%ymm11,448-256-128(%rbx)
	vpaddd	%ymm11,%ymm3,%ymm3
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm12,%ymm9
	vpand	%ymm0,%ymm5,%ymm5
	vpaddd	%ymm12,%ymm12,%ymm12

	vpslld	$30,%ymm0,%ymm6
	vpaddd	%ymm5,%ymm3,%ymm3

	vpsrld	$2,%ymm0,%ymm0
	vpaddd	%ymm7,%ymm3,%ymm3
	vpor	%ymm9,%ymm12,%ymm12
	vpor	%ymm6,%ymm0,%ymm0
	vpxor	%ymm10,%ymm13,%ymm13
	vmovdqa	64-128(%rax),%ymm10

	vpaddd	%ymm15,%ymm2,%ymm2
	vpslld	$5,%ymm3,%ymm7
	vpand	%ymm0,%ymm1,%ymm6
	vpxor	256-256-128(%rbx),%ymm13,%ymm13

	vpaddd	%ymm6,%ymm2,%ymm2
	vpsrld	$27,%ymm3,%ymm8
	vpxor	%ymm0,%ymm1,%ymm5
	vpxor	%ymm10,%ymm13,%ymm13

	vmovdqu	%ymm12,480-256-128(%rbx)
	vpaddd	%ymm12,%ymm2,%ymm2
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm13,%ymm9
	vpand	%ymm4,%ymm5,%ymm5
	vpaddd	%ymm13,%ymm13,%ymm13

	vpslld	$30,%ymm4,%ymm6
	vpaddd	%ymm5,%ymm2,%ymm2

	vpsrld	$2,%ymm4,%ymm4
	vpaddd	%ymm7,%ymm2,%ymm2
	vpor	%ymm9,%ymm13,%ymm13
	vpor	%ymm6,%ymm4,%ymm4
	vpxor	%ymm11,%ymm14,%ymm14
	vmovdqa	96-128(%rax),%ymm11

	vpaddd	%ymm15,%ymm1,%ymm1
	vpslld	$5,%ymm2,%ymm7
	vpand	%ymm4,%ymm0,%ymm6
	vpxor	288-256-128(%rbx),%ymm14,%ymm14

	vpaddd	%ymm6,%ymm1,%ymm1
	vpsrld	$27,%ymm2,%ymm8
	vpxor	%ymm4,%ymm0,%ymm5
	vpxor	%ymm11,%ymm14,%ymm14

	vmovdqu	%ymm13,0-128(%rax)
	vpaddd	%ymm13,%ymm1,%ymm1
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm14,%ymm9
	vpand	%ymm3,%ymm5,%ymm5
	vpaddd	%ymm14,%ymm14,%ymm14

	vpslld	$30,%ymm3,%ymm6
	vpaddd	%ymm5,%ymm1,%ymm1

	vpsrld	$2,%ymm3,%ymm3
	vpaddd	%ymm7,%ymm1,%ymm1
	vpor	%ymm9,%ymm14,%ymm14
	vpor	%ymm6,%ymm3,%ymm3
	vpxor	%ymm12,%ymm10,%ymm10
	vmovdqa	128-128(%rax),%ymm12

	vpaddd	%ymm15,%ymm0,%ymm0
	vpslld	$5,%ymm1,%ymm7
	vpand	%ymm3,%ymm4,%ymm6
	vpxor	320-256-128(%rbx),%ymm10,%ymm10

	vpaddd	%ymm6,%ymm0,%ymm0
	vpsrld	$27,%ymm1,%ymm8
	vpxor	%ymm3,%ymm4,%ymm5
	vpxor	%ymm12,%ymm10,%ymm10

	vmovdqu	%ymm14,32-128(%rax)
	vpaddd	%ymm14,%ymm0,%ymm0
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm10,%ymm9
	vpand	%ymm2,%ymm5,%ymm5
	vpaddd	%ymm10,%ymm10,%ymm10

	vpslld	$30,%ymm2,%ymm6
	vpaddd	%ymm5,%ymm0,%ymm0

	vpsrld	$2,%ymm2,%ymm2
	vpaddd	%ymm7,%ymm0,%ymm0
	vpor	%ymm9,%ymm10,%ymm10
	vpor	%ymm6,%ymm2,%ymm2
	vpxor	%ymm13,%ymm11,%ymm11
	vmovdqa	160-128(%rax),%ymm13

	vpaddd	%ymm15,%ymm4,%ymm4
	vpslld	$5,%ymm0,%ymm7
	vpand	%ymm2,%ymm3,%ymm6
	vpxor	352-256-128(%rbx),%ymm11,%ymm11

	vpaddd	%ymm6,%ymm4,%ymm4
	vpsrld	$27,%ymm0,%ymm8
	vpxor	%ymm2,%ymm3,%ymm5
	vpxor	%ymm13,%ymm11,%ymm11

	vmovdqu	%ymm10,64-128(%rax)
	vpaddd	%ymm10,%ymm4,%ymm4
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm11,%ymm9
	vpand	%ymm1,%ymm5,%ymm5
	vpaddd	%ymm11,%ymm11,%ymm11

	vpslld	$30,%ymm1,%ymm6
	vpaddd	%ymm5,%ymm4,%ymm4

	vpsrld	$2,%ymm1,%ymm1
	vpaddd	%ymm7,%ymm4,%ymm4
	vpor	%ymm9,%ymm11,%ymm11
	vpor	%ymm6,%ymm1,%ymm1
	vpxor	%ymm14,%ymm12,%ymm12
	vmovdqa	192-128(%rax),%ymm14

	vpaddd	%ymm15,%ymm3,%ymm3
	vpslld	$5,%ymm4,%ymm7
	vpand	%ymm1,%ymm2,%ymm6
	vpxor	384-256-128(%rbx),%ymm12,%ymm12

	vpaddd	%ymm6,%ymm3,%ymm3
	vpsrld	$27,%ymm4,%ymm8
	vpxor	%ymm1,%ymm2,%ymm5
	vpxor	%ymm14,%ymm12,%ymm12

	vmovdqu	%ymm11,96-128(%rax)
	vpaddd	%ymm11,%ymm3,%ymm3
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm12,%ymm9
	vpand	%ymm0,%ymm5,%ymm5
	vpaddd	%ymm12,%ymm12,%ymm12

	vpslld	$30,%ymm0,%ymm6
	vpaddd	%ymm5,%ymm3,%ymm3

	vpsrld	$2,%ymm0,%ymm0
	vpaddd	%ymm7,%ymm3,%ymm3
	vpor	%ymm9,%ymm12,%ymm12
	vpor	%ymm6,%ymm0,%ymm0
	vpxor	%ymm10,%ymm13,%ymm13
	vmovdqa	224-128(%rax),%ymm10

	vpaddd	%ymm15,%ymm2,%ymm2
	vpslld	$5,%ymm3,%ymm7
	vpand	%ymm0,%ymm1,%ymm6
	vpxor	416-256-128(%rbx),%ymm13,%ymm13

	vpaddd	%ymm6,%ymm2,%ymm2
	vpsrld	$27,%ymm3,%ymm8
	vpxor	%ymm0,%ymm1,%ymm5
	vpxor	%ymm10,%ymm13,%ymm13

	vmovdqu	%ymm12,128-128(%rax)
	vpaddd	%ymm12,%ymm2,%ymm2
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm13,%ymm9
	vpand	%ymm4,%ymm5,%ymm5
	vpaddd	%ymm13,%ymm13,%ymm13

	vpslld	$30,%ymm4,%ymm6
	vpaddd	%ymm5,%ymm2,%ymm2

	vpsrld	$2,%ymm4,%ymm4
	vpaddd	%ymm7,%ymm2,%ymm2
	vpor	%ymm9,%ymm13,%ymm13
	vpor	%ymm6,%ymm4,%ymm4
	vpxor	%ymm11,%ymm14,%ymm14
	vmovdqa	256-256-128(%rbx),%ymm11

	vpaddd	%ymm15,%ymm1,%ymm1
	vpslld	$5,%ymm2,%ymm7
	vpand	%ymm4,%ymm0,%ymm6
	vpxor	448-256-128(%rbx),%ymm14,%ymm14

	vpaddd	%ymm6,%ymm1,%ymm1
	vpsrld	$27,%ymm2,%ymm8
	vpxor	%ymm4,%ymm0,%ymm5
	vpxor	%ymm11,%ymm14,%ymm14

	vmovdqu	%ymm13,160-128(%rax)
	vpaddd	%ymm13,%ymm1,%ymm1
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm14,%ymm9
	vpand	%ymm3,%ymm5,%ymm5
	vpaddd	%ymm14,%ymm14,%ymm14

	vpslld	$30,%ymm3,%ymm6
	vpaddd	%ymm5,%ymm1,%ymm1

	vpsrld	$2,%ymm3,%ymm3
	vpaddd	%ymm7,%ymm1,%ymm1
	vpor	%ymm9,%ymm14,%ymm14
	vpor	%ymm6,%ymm3,%ymm3
	vpxor	%ymm12,%ymm10,%ymm10
	vmovdqa	288-256-128(%rbx),%ymm12

	vpaddd	%ymm15,%ymm0,%ymm0
	vpslld	$5,%ymm1,%ymm7
	vpand	%ymm3,%ymm4,%ymm6
	vpxor	480-256-128(%rbx),%ymm10,%ymm10

	vpaddd	%ymm6,%ymm0,%ymm0
	vpsrld	$27,%ymm1,%ymm8
	vpxor	%ymm3,%ymm4,%ymm5
	vpxor	%ymm12,%ymm10,%ymm10

	vmovdqu	%ymm14,192-128(%rax)
	vpaddd	%ymm14,%ymm0,%ymm0
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm10,%ymm9
	vpand	%ymm2,%ymm5,%ymm5
	vpaddd	%ymm10,%ymm10,%ymm10

	vpslld	$30,%ymm2,%ymm6
	vpaddd	%ymm5,%ymm0,%ymm0

	vpsrld	$2,%ymm2,%ymm2
	vpaddd	%ymm7,%ymm0,%ymm0
	vpor	%ymm9,%ymm10,%ymm10
	vpor	%ymm6,%ymm2,%ymm2
	vpxor	%ymm13,%ymm11,%ymm11
	vmovdqa	320-256-128(%rbx),%ymm13

	vpaddd	%ymm15,%ymm4,%ymm4
	vpslld	$5,%ymm0,%ymm7
	vpand	%ymm2,%ymm3,%ymm6
	vpxor	0-128(%rax),%ymm11,%ymm11

	vpaddd	%ymm6,%ymm4,%ymm4
	vpsrld	$27,%ymm0,%ymm8
	vpxor	%ymm2,%ymm3,%ymm5
	vpxor	%ymm13,%ymm11,%ymm11

	vmovdqu	%ymm10,224-128(%rax)
	vpaddd	%ymm10,%ymm4,%ymm4
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm11,%ymm9
	vpand	%ymm1,%ymm5,%ymm5
	vpaddd	%ymm11,%ymm11,%ymm11

	vpslld	$30,%ymm1,%ymm6
	vpaddd	%ymm5,%ymm4,%ymm4

	vpsrld	$2,%ymm1,%ymm1
	vpaddd	%ymm7,%ymm4,%ymm4
	vpor	%ymm9,%ymm11,%ymm11
	vpor	%ymm6,%ymm1,%ymm1
	vpxor	%ymm14,%ymm12,%ymm12
	vmovdqa	352-256-128(%rbx),%ymm14

	vpaddd	%ymm15,%ymm3,%ymm3
	vpslld	$5,%ymm4,%ymm7
	vpand	%ymm1,%ymm2,%ymm6
	vpxor	32-128(%rax),%ymm12,%ymm12

	vpaddd	%ymm6,%ymm3,%ymm3
	vpsrld	$27,%ymm4,%ymm8
	vpxor	%ymm1,%ymm2,%ymm5
	vpxor	%ymm14,%ymm12,%ymm12

	vmovdqu	%ymm11,256-256-128(%rbx)
	vpaddd	%ymm11,%ymm3,%ymm3
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm12,%ymm9
	vpand	%ymm0,%ymm5,%ymm5
	vpaddd	%ymm12,%ymm12,%ymm12

	vpslld	$30,%ymm0,%ymm6
	vpaddd	%ymm5,%ymm3,%ymm3

	vpsrld	$2,%ymm0,%ymm0
	vpaddd	%ymm7,%ymm3,%ymm3
	vpor	%ymm9,%ymm12,%ymm12
	vpor	%ymm6,%ymm0,%ymm0
	vpxor	%ymm10,%ymm13,%ymm13
	vmovdqa	384-256-128(%rbx),%ymm10

	vpaddd	%ymm15,%ymm2,%ymm2
	vpslld	$5,%ymm3,%ymm7
	vpand	%ymm0,%ymm1,%ymm6
	vpxor	64-128(%rax),%ymm13,%ymm13

	vpaddd	%ymm6,%ymm2,%ymm2
	vpsrld	$27,%ymm3,%ymm8
	vpxor	%ymm0,%ymm1,%ymm5
	vpxor	%ymm10,%ymm13,%ymm13

	vmovdqu	%ymm12,288-256-128(%rbx)
	vpaddd	%ymm12,%ymm2,%ymm2
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm13,%ymm9
	vpand	%ymm4,%ymm5,%ymm5
	vpaddd	%ymm13,%ymm13,%ymm13

	vpslld	$30,%ymm4,%ymm6
	vpaddd	%ymm5,%ymm2,%ymm2

	vpsrld	$2,%ymm4,%ymm4
	vpaddd	%ymm7,%ymm2,%ymm2
	vpor	%ymm9,%ymm13,%ymm13
	vpor	%ymm6,%ymm4,%ymm4
	vpxor	%ymm11,%ymm14,%ymm14
	vmovdqa	416-256-128(%rbx),%ymm11

	vpaddd	%ymm15,%ymm1,%ymm1
	vpslld	$5,%ymm2,%ymm7
	vpand	%ymm4,%ymm0,%ymm6
	vpxor	96-128(%rax),%ymm14,%ymm14

	vpaddd	%ymm6,%ymm1,%ymm1
	vpsrld	$27,%ymm2,%ymm8
	vpxor	%ymm4,%ymm0,%ymm5
	vpxor	%ymm11,%ymm14,%ymm14

	vmovdqu	%ymm13,320-256-128(%rbx)
	vpaddd	%ymm13,%ymm1,%ymm1
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm14,%ymm9
	vpand	%ymm3,%ymm5,%ymm5
	vpaddd	%ymm14,%ymm14,%ymm14

	vpslld	$30,%ymm3,%ymm6
	vpaddd	%ymm5,%ymm1,%ymm1

	vpsrld	$2,%ymm3,%ymm3
	vpaddd	%ymm7,%ymm1,%ymm1
	vpor	%ymm9,%ymm14,%ymm14
	vpor	%ymm6,%ymm3,%ymm3
	vpxor	%ymm12,%ymm10,%ymm10
	vmovdqa	448-256-128(%rbx),%ymm12

	vpaddd	%ymm15,%ymm0,%ymm0
	vpslld	$5,%ymm1,%ymm7
	vpand	%ymm3,%ymm4,%ymm6
	vpxor	128-128(%rax),%ymm10,%ymm10

	vpaddd	%ymm6,%ymm0,%ymm0
	vpsrld	$27,%ymm1,%ymm8
	vpxor	%ymm3,%ymm4,%ymm5
	vpxor	%ymm12,%ymm10,%ymm10

	vmovdqu	%ymm14,352-256-128(%rbx)
	vpaddd	%ymm14,%ymm0,%ymm0
	vpor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm10,%ymm9
	vpand	%ymm2,%ymm5,%ymm5
	vpaddd	%ymm10,%ymm10,%ymm10

	vpslld	$30,%ymm2,%ymm6
	vpaddd	%ymm5,%ymm0,%ymm0

	vpsrld	$2,%ymm2,%ymm2
	vpaddd	%ymm7,%ymm0,%ymm0
	vpor	%ymm9,%ymm10,%ymm10
	vpor	%ymm6,%ymm2,%ymm2
	vmovdqa	64(%rbp),%ymm15
	vpxor	%ymm13,%ymm11,%ymm11
	vmovdqa	480-256-128(%rbx),%ymm13

	vpslld	$5,%ymm0,%ymm7
	vpaddd	%ymm15,%ymm4,%ymm4
	vpxor	%ymm1,%ymm3,%ymm5
	vmovdqa	%ymm10,384-256-128(%rbx)
	vpaddd	%ymm10,%ymm4,%ymm4
	vpxor	160-128(%rax),%ymm11,%ymm11
	vpsrld	$27,%ymm0,%ymm8
	vpxor	%ymm2,%ymm5,%ymm5
	vpxor	%ymm13,%ymm11,%ymm11

	vpslld	$30,%ymm1,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm4,%ymm4
	vpsrld	$31,%ymm11,%ymm9
	vpaddd	%ymm11,%ymm11,%ymm11

	vpsrld	$2,%ymm1,%ymm1
	vpaddd	%ymm7,%ymm4,%ymm4
	vpor	%ymm9,%ymm11,%ymm11
	vpor	%ymm6,%ymm1,%ymm1
	vpxor	%ymm14,%ymm12,%ymm12
	vmovdqa	0-128(%rax),%ymm14

	vpslld	$5,%ymm4,%ymm7
	vpaddd	%ymm15,%ymm3,%ymm3
	vpxor	%ymm0,%ymm2,%ymm5
	vmovdqa	%ymm11,416-256-128(%rbx)
	vpaddd	%ymm11,%ymm3,%ymm3
	vpxor	192-128(%rax),%ymm12,%ymm12
	vpsrld	$27,%ymm4,%ymm8
	vpxor	%ymm1,%ymm5,%ymm5
	vpxor	%ymm14,%ymm12,%ymm12

	vpslld	$30,%ymm0,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm3,%ymm3
	vpsrld	$31,%ymm12,%ymm9
	vpaddd	%ymm12,%ymm12,%ymm12

	vpsrld	$2,%ymm0,%ymm0
	vpaddd	%ymm7,%ymm3,%ymm3
	vpor	%ymm9,%ymm12,%ymm12
	vpor	%ymm6,%ymm0,%ymm0
	vpxor	%ymm10,%ymm13,%ymm13
	vmovdqa	32-128(%rax),%ymm10

	vpslld	$5,%ymm3,%ymm7
	vpaddd	%ymm15,%ymm2,%ymm2
	vpxor	%ymm4,%ymm1,%ymm5
	vmovdqa	%ymm12,448-256-128(%rbx)
	vpaddd	%ymm12,%ymm2,%ymm2
	vpxor	224-128(%rax),%ymm13,%ymm13
	vpsrld	$27,%ymm3,%ymm8
	vpxor	%ymm0,%ymm5,%ymm5
	vpxor	%ymm10,%ymm13,%ymm13

	vpslld	$30,%ymm4,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm2,%ymm2
	vpsrld	$31,%ymm13,%ymm9
	vpaddd	%ymm13,%ymm13,%ymm13

	vpsrld	$2,%ymm4,%ymm4
	vpaddd	%ymm7,%ymm2,%ymm2
	vpor	%ymm9,%ymm13,%ymm13
	vpor	%ymm6,%ymm4,%ymm4
	vpxor	%ymm11,%ymm14,%ymm14
	vmovdqa	64-128(%rax),%ymm11

	vpslld	$5,%ymm2,%ymm7
	vpaddd	%ymm15,%ymm1,%ymm1
	vpxor	%ymm3,%ymm0,%ymm5
	vmovdqa	%ymm13,480-256-128(%rbx)
	vpaddd	%ymm13,%ymm1,%ymm1
	vpxor	256-256-128(%rbx),%ymm14,%ymm14
	vpsrld	$27,%ymm2,%ymm8
	vpxor	%ymm4,%ymm5,%ymm5
	vpxor	%ymm11,%ymm14,%ymm14

	vpslld	$30,%ymm3,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm1,%ymm1
	vpsrld	$31,%ymm14,%ymm9
	vpaddd	%ymm14,%ymm14,%ymm14

	vpsrld	$2,%ymm3,%ymm3
	vpaddd	%ymm7,%ymm1,%ymm1
	vpor	%ymm9,%ymm14,%ymm14
	vpor	%ymm6,%ymm3,%ymm3
	vpxor	%ymm12,%ymm10,%ymm10
	vmovdqa	96-128(%rax),%ymm12

	vpslld	$5,%ymm1,%ymm7
	vpaddd	%ymm15,%ymm0,%ymm0
	vpxor	%ymm2,%ymm4,%ymm5
	vmovdqa	%ymm14,0-128(%rax)
	vpaddd	%ymm14,%ymm0,%ymm0
	vpxor	288-256-128(%rbx),%ymm10,%ymm10
	vpsrld	$27,%ymm1,%ymm8
	vpxor	%ymm3,%ymm5,%ymm5
	vpxor	%ymm12,%ymm10,%ymm10

	vpslld	$30,%ymm2,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm0,%ymm0
	vpsrld	$31,%ymm10,%ymm9
	vpaddd	%ymm10,%ymm10,%ymm10

	vpsrld	$2,%ymm2,%ymm2
	vpaddd	%ymm7,%ymm0,%ymm0
	vpor	%ymm9,%ymm10,%ymm10
	vpor	%ymm6,%ymm2,%ymm2
	vpxor	%ymm13,%ymm11,%ymm11
	vmovdqa	128-128(%rax),%ymm13

	vpslld	$5,%ymm0,%ymm7
	vpaddd	%ymm15,%ymm4,%ymm4
	vpxor	%ymm1,%ymm3,%ymm5
	vmovdqa	%ymm10,32-128(%rax)
	vpaddd	%ymm10,%ymm4,%ymm4
	vpxor	320-256-128(%rbx),%ymm11,%ymm11
	vpsrld	$27,%ymm0,%ymm8
	vpxor	%ymm2,%ymm5,%ymm5
	vpxor	%ymm13,%ymm11,%ymm11

	vpslld	$30,%ymm1,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm4,%ymm4
	vpsrld	$31,%ymm11,%ymm9
	vpaddd	%ymm11,%ymm11,%ymm11

	vpsrld	$2,%ymm1,%ymm1
	vpaddd	%ymm7,%ymm4,%ymm4
	vpor	%ymm9,%ymm11,%ymm11
	vpor	%ymm6,%ymm1,%ymm1
	vpxor	%ymm14,%ymm12,%ymm12
	vmovdqa	160-128(%rax),%ymm14

	vpslld	$5,%ymm4,%ymm7
	vpaddd	%ymm15,%ymm3,%ymm3
	vpxor	%ymm0,%ymm2,%ymm5
	vmovdqa	%ymm11,64-128(%rax)
	vpaddd	%ymm11,%ymm3,%ymm3
	vpxor	352-256-128(%rbx),%ymm12,%ymm12
	vpsrld	$27,%ymm4,%ymm8
	vpxor	%ymm1,%ymm5,%ymm5
	vpxor	%ymm14,%ymm12,%ymm12

	vpslld	$30,%ymm0,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm3,%ymm3
	vpsrld	$31,%ymm12,%ymm9
	vpaddd	%ymm12,%ymm12,%ymm12

	vpsrld	$2,%ymm0,%ymm0
	vpaddd	%ymm7,%ymm3,%ymm3
	vpor	%ymm9,%ymm12,%ymm12
	vpor	%ymm6,%ymm0,%ymm0
	vpxor	%ymm10,%ymm13,%ymm13
	vmovdqa	192-128(%rax),%ymm10

	vpslld	$5,%ymm3,%ymm7
	vpaddd	%ymm15,%ymm2,%ymm2
	vpxor	%ymm4,%ymm1,%ymm5
	vmovdqa	%ymm12,96-128(%rax)
	vpaddd	%ymm12,%ymm2,%ymm2
	vpxor	384-256-128(%rbx),%ymm13,%ymm13
	vpsrld	$27,%ymm3,%ymm8
	vpxor	%ymm0,%ymm5,%ymm5
	vpxor	%ymm10,%ymm13,%ymm13

	vpslld	$30,%ymm4,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm2,%ymm2
	vpsrld	$31,%ymm13,%ymm9
	vpaddd	%ymm13,%ymm13,%ymm13

	vpsrld	$2,%ymm4,%ymm4
	vpaddd	%ymm7,%ymm2,%ymm2
	vpor	%ymm9,%ymm13,%ymm13
	vpor	%ymm6,%ymm4,%ymm4
	vpxor	%ymm11,%ymm14,%ymm14
	vmovdqa	224-128(%rax),%ymm11

	vpslld	$5,%ymm2,%ymm7
	vpaddd	%ymm15,%ymm1,%ymm1
	vpxor	%ymm3,%ymm0,%ymm5
	vmovdqa	%ymm13,128-128(%rax)
	vpaddd	%ymm13,%ymm1,%ymm1
	vpxor	416-256-128(%rbx),%ymm14,%ymm14
	vpsrld	$27,%ymm2,%ymm8
	vpxor	%ymm4,%ymm5,%ymm5
	vpxor	%ymm11,%ymm14,%ymm14

	vpslld	$30,%ymm3,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm1,%ymm1
	vpsrld	$31,%ymm14,%ymm9
	vpaddd	%ymm14,%ymm14,%ymm14

	vpsrld	$2,%ymm3,%ymm3
	vpaddd	%ymm7,%ymm1,%ymm1
	vpor	%ymm9,%ymm14,%ymm14
	vpor	%ymm6,%ymm3,%ymm3
	vpxor	%ymm12,%ymm10,%ymm10
	vmovdqa	256-256-128(%rbx),%ymm12

	vpslld	$5,%ymm1,%ymm7
	vpaddd	%ymm15,%ymm0,%ymm0
	vpxor	%ymm2,%ymm4,%ymm5
	vmovdqa	%ymm14,160-128(%rax)
	vpaddd	%ymm14,%ymm0,%ymm0
	vpxor	448-256-128(%rbx),%ymm10,%ymm10
	vpsrld	$27,%ymm1,%ymm8
	vpxor	%ymm3,%ymm5,%ymm5
	vpxor	%ymm12,%ymm10,%ymm10

	vpslld	$30,%ymm2,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm0,%ymm0
	vpsrld	$31,%ymm10,%ymm9
	vpaddd	%ymm10,%ymm10,%ymm10

	vpsrld	$2,%ymm2,%ymm2
	vpaddd	%ymm7,%ymm0,%ymm0
	vpor	%ymm9,%ymm10,%ymm10
	vpor	%ymm6,%ymm2,%ymm2
	vpxor	%ymm13,%ymm11,%ymm11
	vmovdqa	288-256-128(%rbx),%ymm13

	vpslld	$5,%ymm0,%ymm7
	vpaddd	%ymm15,%ymm4,%ymm4
	vpxor	%ymm1,%ymm3,%ymm5
	vmovdqa	%ymm10,192-128(%rax)
	vpaddd	%ymm10,%ymm4,%ymm4
	vpxor	480-256-128(%rbx),%ymm11,%ymm11
	vpsrld	$27,%ymm0,%ymm8
	vpxor	%ymm2,%ymm5,%ymm5
	vpxor	%ymm13,%ymm11,%ymm11

	vpslld	$30,%ymm1,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm4,%ymm4
	vpsrld	$31,%ymm11,%ymm9
	vpaddd	%ymm11,%ymm11,%ymm11

	vpsrld	$2,%ymm1,%ymm1
	vpaddd	%ymm7,%ymm4,%ymm4
	vpor	%ymm9,%ymm11,%ymm11
	vpor	%ymm6,%ymm1,%ymm1
	vpxor	%ymm14,%ymm12,%ymm12
	vmovdqa	320-256-128(%rbx),%ymm14

	vpslld	$5,%ymm4,%ymm7
	vpaddd	%ymm15,%ymm3,%ymm3
	vpxor	%ymm0,%ymm2,%ymm5
	vmovdqa	%ymm11,224-128(%rax)
	vpaddd	%ymm11,%ymm3,%ymm3
	vpxor	0-128(%rax),%ymm12,%ymm12
	vpsrld	$27,%ymm4,%ymm8
	vpxor	%ymm1,%ymm5,%ymm5
	vpxor	%ymm14,%ymm12,%ymm12

	vpslld	$30,%ymm0,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm3,%ymm3
	vpsrld	$31,%ymm12,%ymm9
	vpaddd	%ymm12,%ymm12,%ymm12

	vpsrld	$2,%ymm0,%ymm0
	vpaddd	%ymm7,%ymm3,%ymm3
	vpor	%ymm9,%ymm12,%ymm12
	vpor	%ymm6,%ymm0,%ymm0
	vpxor	%ymm10,%ymm13,%ymm13
	vmovdqa	352-256-128(%rbx),%ymm10

	vpslld	$5,%ymm3,%ymm7
	vpaddd	%ymm15,%ymm2,%ymm2
	vpxor	%ymm4,%ymm1,%ymm5
	vpaddd	%ymm12,%ymm2,%ymm2
	vpxor	32-128(%rax),%ymm13,%ymm13
	vpsrld	$27,%ymm3,%ymm8
	vpxor	%ymm0,%ymm5,%ymm5
	vpxor	%ymm10,%ymm13,%ymm13

	vpslld	$30,%ymm4,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm2,%ymm2
	vpsrld	$31,%ymm13,%ymm9
	vpaddd	%ymm13,%ymm13,%ymm13

	vpsrld	$2,%ymm4,%ymm4
	vpaddd	%ymm7,%ymm2,%ymm2
	vpor	%ymm9,%ymm13,%ymm13
	vpor	%ymm6,%ymm4,%ymm4
	vpxor	%ymm11,%ymm14,%ymm14
	vmovdqa	384-256-128(%rbx),%ymm11

	vpslld	$5,%ymm2,%ymm7
	vpaddd	%ymm15,%ymm1,%ymm1
	vpxor	%ymm3,%ymm0,%ymm5
	vpaddd	%ymm13,%ymm1,%ymm1
	vpxor	64-128(%rax),%ymm14,%ymm14
	vpsrld	$27,%ymm2,%ymm8
	vpxor	%ymm4,%ymm5,%ymm5
	vpxor	%ymm11,%ymm14,%ymm14

	vpslld	$30,%ymm3,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm1,%ymm1
	vpsrld	$31,%ymm14,%ymm9
	vpaddd	%ymm14,%ymm14,%ymm14

	vpsrld	$2,%ymm3,%ymm3
	vpaddd	%ymm7,%ymm1,%ymm1
	vpor	%ymm9,%ymm14,%ymm14
	vpor	%ymm6,%ymm3,%ymm3
	vpxor	%ymm12,%ymm10,%ymm10
	vmovdqa	416-256-128(%rbx),%ymm12

	vpslld	$5,%ymm1,%ymm7
	vpaddd	%ymm15,%ymm0,%ymm0
	vpxor	%ymm2,%ymm4,%ymm5
	vpaddd	%ymm14,%ymm0,%ymm0
	vpxor	96-128(%rax),%ymm10,%ymm10
	vpsrld	$27,%ymm1,%ymm8
	vpxor	%ymm3,%ymm5,%ymm5
	vpxor	%ymm12,%ymm10,%ymm10

	vpslld	$30,%ymm2,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm0,%ymm0
	vpsrld	$31,%ymm10,%ymm9
	vpaddd	%ymm10,%ymm10,%ymm10

	vpsrld	$2,%ymm2,%ymm2
	vpaddd	%ymm7,%ymm0,%ymm0
	vpor	%ymm9,%ymm10,%ymm10
	vpor	%ymm6,%ymm2,%ymm2
	vpxor	%ymm13,%ymm11,%ymm11
	vmovdqa	448-256-128(%rbx),%ymm13

	vpslld	$5,%ymm0,%ymm7
	vpaddd	%ymm15,%ymm4,%ymm4
	vpxor	%ymm1,%ymm3,%ymm5
	vpaddd	%ymm10,%ymm4,%ymm4
	vpxor	128-128(%rax),%ymm11,%ymm11
	vpsrld	$27,%ymm0,%ymm8
	vpxor	%ymm2,%ymm5,%ymm5
	vpxor	%ymm13,%ymm11,%ymm11

	vpslld	$30,%ymm1,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm4,%ymm4
	vpsrld	$31,%ymm11,%ymm9
	vpaddd	%ymm11,%ymm11,%ymm11

	vpsrld	$2,%ymm1,%ymm1
	vpaddd	%ymm7,%ymm4,%ymm4
	vpor	%ymm9,%ymm11,%ymm11
	vpor	%ymm6,%ymm1,%ymm1
	vpxor	%ymm14,%ymm12,%ymm12
	vmovdqa	480-256-128(%rbx),%ymm14

	vpslld	$5,%ymm4,%ymm7
	vpaddd	%ymm15,%ymm3,%ymm3
	vpxor	%ymm0,%ymm2,%ymm5
	vpaddd	%ymm11,%ymm3,%ymm3
	vpxor	160-128(%rax),%ymm12,%ymm12
	vpsrld	$27,%ymm4,%ymm8
	vpxor	%ymm1,%ymm5,%ymm5
	vpxor	%ymm14,%ymm12,%ymm12

	vpslld	$30,%ymm0,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm3,%ymm3
	vpsrld	$31,%ymm12,%ymm9
	vpaddd	%ymm12,%ymm12,%ymm12

	vpsrld	$2,%ymm0,%ymm0
	vpaddd	%ymm7,%ymm3,%ymm3
	vpor	%ymm9,%ymm12,%ymm12
	vpor	%ymm6,%ymm0,%ymm0
	vpxor	%ymm10,%ymm13,%ymm13
	vmovdqa	0-128(%rax),%ymm10

	vpslld	$5,%ymm3,%ymm7
	vpaddd	%ymm15,%ymm2,%ymm2
	vpxor	%ymm4,%ymm1,%ymm5
	vpaddd	%ymm12,%ymm2,%ymm2
	vpxor	192-128(%rax),%ymm13,%ymm13
	vpsrld	$27,%ymm3,%ymm8
	vpxor	%ymm0,%ymm5,%ymm5
	vpxor	%ymm10,%ymm13,%ymm13

	vpslld	$30,%ymm4,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm2,%ymm2
	vpsrld	$31,%ymm13,%ymm9
	vpaddd	%ymm13,%ymm13,%ymm13

	vpsrld	$2,%ymm4,%ymm4
	vpaddd	%ymm7,%ymm2,%ymm2
	vpor	%ymm9,%ymm13,%ymm13
	vpor	%ymm6,%ymm4,%ymm4
	vpxor	%ymm11,%ymm14,%ymm14
	vmovdqa	32-128(%rax),%ymm11

	vpslld	$5,%ymm2,%ymm7
	vpaddd	%ymm15,%ymm1,%ymm1
	vpxor	%ymm3,%ymm0,%ymm5
	vpaddd	%ymm13,%ymm1,%ymm1
	vpxor	224-128(%rax),%ymm14,%ymm14
	vpsrld	$27,%ymm2,%ymm8
	vpxor	%ymm4,%ymm5,%ymm5
	vpxor	%ymm11,%ymm14,%ymm14

	vpslld	$30,%ymm3,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm1,%ymm1
	vpsrld	$31,%ymm14,%ymm9
	vpaddd	%ymm14,%ymm14,%ymm14

	vpsrld	$2,%ymm3,%ymm3
	vpaddd	%ymm7,%ymm1,%ymm1
	vpor	%ymm9,%ymm14,%ymm14
	vpor	%ymm6,%ymm3,%ymm3
	vpslld	$5,%ymm1,%ymm7
	vpaddd	%ymm15,%ymm0,%ymm0
	vpxor	%ymm2,%ymm4,%ymm5

	vpsrld	$27,%ymm1,%ymm8
	vpaddd	%ymm14,%ymm0,%ymm0
	vpxor	%ymm3,%ymm5,%ymm5

	vpslld	$30,%ymm2,%ymm6
	vpor	%ymm8,%ymm7,%ymm7
	vpaddd	%ymm5,%ymm0,%ymm0

	vpsrld	$2,%ymm2,%ymm2
	vpaddd	%ymm7,%ymm0,%ymm0
	vpor	%ymm6,%ymm2,%ymm2
	movl	$1,%ecx
	leaq	512(%rsp),%rbx
	cmpl	0(%rbx),%ecx
	cmovgeq	%rbp,%r12
	cmpl	4(%rbx),%ecx
	cmovgeq	%rbp,%r13
	cmpl	8(%rbx),%ecx
	cmovgeq	%rbp,%r14
	cmpl	12(%rbx),%ecx
	cmovgeq	%rbp,%r15
	cmpl	16(%rbx),%ecx
	cmovgeq	%rbp,%r8
	cmpl	20(%rbx),%ecx
	cmovgeq	%rbp,%r9
	cmpl	24(%rbx),%ecx
	cmovgeq	%rbp,%r10
	cmpl	28(%rbx),%ecx
	cmovgeq	%rbp,%r11
	vmovdqu	(%rbx),%ymm5
	vpxor	%ymm7,%ymm7,%ymm7
	vmovdqa	%ymm5,%ymm6
	vpcmpgtd	%ymm7,%ymm6,%ymm6
	vpaddd	%ymm6,%ymm5,%ymm5

	vpand	%ymm6,%ymm0,%ymm0
	vpand	%ymm6,%ymm1,%ymm1
	vpaddd	0(%rdi),%ymm0,%ymm0
	vpand	%ymm6,%ymm2,%ymm2
	vpaddd	32(%rdi),%ymm1,%ymm1
	vpand	%ymm6,%ymm3,%ymm3
	vpaddd	64(%rdi),%ymm2,%ymm2
	vpand	%ymm6,%ymm4,%ymm4
	vpaddd	96(%rdi),%ymm3,%ymm3
	vpaddd	128(%rdi),%ymm4,%ymm4
	vmovdqu	%ymm0,0(%rdi)
	vmovdqu	%ymm1,32(%rdi)
	vmovdqu	%ymm2,64(%rdi)
	vmovdqu	%ymm3,96(%rdi)
	vmovdqu	%ymm4,128(%rdi)

	vmovdqu	%ymm5,(%rbx)
	leaq	256+128(%rsp),%rbx
	vmovdqu	96(%rbp),%ymm9
	decl	%edx
	jnz	.Loop_avx2







.Ldone_avx2:
	movq	544(%rsp),%rax
.cfi_def_cfa	%rax,8
	vzeroupper
	movq	-48(%rax),%r15
.cfi_restore	%r15
	movq	-40(%rax),%r14
.cfi_restore	%r14
	movq	-32(%rax),%r13
.cfi_restore	%r13
	movq	-24(%rax),%r12
.cfi_restore	%r12
	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue_avx2:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha1_multi_block_avx2,.-sha1_multi_block_avx2

.align	256
.long	0x5a827999,0x5a827999,0x5a827999,0x5a827999
.long	0x5a827999,0x5a827999,0x5a827999,0x5a827999
K_XX_XX:
.long	0x6ed9eba1,0x6ed9eba1,0x6ed9eba1,0x6ed9eba1
.long	0x6ed9eba1,0x6ed9eba1,0x6ed9eba1,0x6ed9eba1
.long	0x8f1bbcdc,0x8f1bbcdc,0x8f1bbcdc,0x8f1bbcdc
.long	0x8f1bbcdc,0x8f1bbcdc,0x8f1bbcdc,0x8f1bbcdc
.long	0xca62c1d6,0xca62c1d6,0xca62c1d6,0xca62c1d6
.long	0xca62c1d6,0xca62c1d6,0xca62c1d6,0xca62c1d6
.long	0x00010203,0x04050607,0x08090a0b,0x0c0d0e0f
.long	0x00010203,0x04050607,0x08090a0b,0x0c0d0e0f
.byte	0xf,0xe,0xd,0xc,0xb,0xa,0x9,0x8,0x7,0x6,0x5,0x4,0x3,0x2,0x1,0x0
.byte	83,72,65,49,32,109,117,108,116,105,45,98,108,111,99,107,32,116,114,97,110,115,102,111,114,109,32,102,111,114,32,120,56,54,95,54,52,44,32,67,82,89,80,84,79,71,65,77,83,32,98,121,32,60,97,112,112,114,111,64,111,112,101,110,115,115,108,46,111,114,103,62,0
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                                                                                                                                                                                                                                                                                     node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/crypto/sha/sha1-x86_64.s        0000664 0000000 0000000 00000307360 14746647661 0030654 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	


.globl	sha1_block_data_order
.type	sha1_block_data_order,@function
.align	16
sha1_block_data_order:
.cfi_startproc	
	movl	OPENSSL_ia32cap_P+0(%rip),%r9d
	movl	OPENSSL_ia32cap_P+4(%rip),%r8d
	movl	OPENSSL_ia32cap_P+8(%rip),%r10d
	testl	$512,%r8d
	jz	.Lialu
	testl	$536870912,%r10d
	jnz	_shaext_shortcut
	andl	$296,%r10d
	cmpl	$296,%r10d
	je	_avx2_shortcut
	andl	$268435456,%r8d
	andl	$1073741824,%r9d
	orl	%r9d,%r8d
	cmpl	$1342177280,%r8d
	je	_avx_shortcut
	jmp	_ssse3_shortcut

.align	16
.Lialu:
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	movq	%rdi,%r8
	subq	$72,%rsp
	movq	%rsi,%r9
	andq	$-64,%rsp
	movq	%rdx,%r10
	movq	%rax,64(%rsp)
.cfi_escape	0x0f,0x06,0x77,0xc0,0x00,0x06,0x23,0x08
.Lprologue:

	movl	0(%r8),%esi
	movl	4(%r8),%edi
	movl	8(%r8),%r11d
	movl	12(%r8),%r12d
	movl	16(%r8),%r13d
	jmp	.Lloop

.align	16
.Lloop:
	movl	0(%r9),%edx
	bswapl	%edx
	movl	4(%r9),%ebp
	movl	%r12d,%eax
	movl	%edx,0(%rsp)
	movl	%esi,%ecx
	bswapl	%ebp
	xorl	%r11d,%eax
	roll	$5,%ecx
	andl	%edi,%eax
	leal	1518500249(%rdx,%r13,1),%r13d
	addl	%ecx,%r13d
	xorl	%r12d,%eax
	roll	$30,%edi
	addl	%eax,%r13d
	movl	8(%r9),%r14d
	movl	%r11d,%eax
	movl	%ebp,4(%rsp)
	movl	%r13d,%ecx
	bswapl	%r14d
	xorl	%edi,%eax
	roll	$5,%ecx
	andl	%esi,%eax
	leal	1518500249(%rbp,%r12,1),%r12d
	addl	%ecx,%r12d
	xorl	%r11d,%eax
	roll	$30,%esi
	addl	%eax,%r12d
	movl	12(%r9),%edx
	movl	%edi,%eax
	movl	%r14d,8(%rsp)
	movl	%r12d,%ecx
	bswapl	%edx
	xorl	%esi,%eax
	roll	$5,%ecx
	andl	%r13d,%eax
	leal	1518500249(%r14,%r11,1),%r11d
	addl	%ecx,%r11d
	xorl	%edi,%eax
	roll	$30,%r13d
	addl	%eax,%r11d
	movl	16(%r9),%ebp
	movl	%esi,%eax
	movl	%edx,12(%rsp)
	movl	%r11d,%ecx
	bswapl	%ebp
	xorl	%r13d,%eax
	roll	$5,%ecx
	andl	%r12d,%eax
	leal	1518500249(%rdx,%rdi,1),%edi
	addl	%ecx,%edi
	xorl	%esi,%eax
	roll	$30,%r12d
	addl	%eax,%edi
	movl	20(%r9),%r14d
	movl	%r13d,%eax
	movl	%ebp,16(%rsp)
	movl	%edi,%ecx
	bswapl	%r14d
	xorl	%r12d,%eax
	roll	$5,%ecx
	andl	%r11d,%eax
	leal	1518500249(%rbp,%rsi,1),%esi
	addl	%ecx,%esi
	xorl	%r13d,%eax
	roll	$30,%r11d
	addl	%eax,%esi
	movl	24(%r9),%edx
	movl	%r12d,%eax
	movl	%r14d,20(%rsp)
	movl	%esi,%ecx
	bswapl	%edx
	xorl	%r11d,%eax
	roll	$5,%ecx
	andl	%edi,%eax
	leal	1518500249(%r14,%r13,1),%r13d
	addl	%ecx,%r13d
	xorl	%r12d,%eax
	roll	$30,%edi
	addl	%eax,%r13d
	movl	28(%r9),%ebp
	movl	%r11d,%eax
	movl	%edx,24(%rsp)
	movl	%r13d,%ecx
	bswapl	%ebp
	xorl	%edi,%eax
	roll	$5,%ecx
	andl	%esi,%eax
	leal	1518500249(%rdx,%r12,1),%r12d
	addl	%ecx,%r12d
	xorl	%r11d,%eax
	roll	$30,%esi
	addl	%eax,%r12d
	movl	32(%r9),%r14d
	movl	%edi,%eax
	movl	%ebp,28(%rsp)
	movl	%r12d,%ecx
	bswapl	%r14d
	xorl	%esi,%eax
	roll	$5,%ecx
	andl	%r13d,%eax
	leal	1518500249(%rbp,%r11,1),%r11d
	addl	%ecx,%r11d
	xorl	%edi,%eax
	roll	$30,%r13d
	addl	%eax,%r11d
	movl	36(%r9),%edx
	movl	%esi,%eax
	movl	%r14d,32(%rsp)
	movl	%r11d,%ecx
	bswapl	%edx
	xorl	%r13d,%eax
	roll	$5,%ecx
	andl	%r12d,%eax
	leal	1518500249(%r14,%rdi,1),%edi
	addl	%ecx,%edi
	xorl	%esi,%eax
	roll	$30,%r12d
	addl	%eax,%edi
	movl	40(%r9),%ebp
	movl	%r13d,%eax
	movl	%edx,36(%rsp)
	movl	%edi,%ecx
	bswapl	%ebp
	xorl	%r12d,%eax
	roll	$5,%ecx
	andl	%r11d,%eax
	leal	1518500249(%rdx,%rsi,1),%esi
	addl	%ecx,%esi
	xorl	%r13d,%eax
	roll	$30,%r11d
	addl	%eax,%esi
	movl	44(%r9),%r14d
	movl	%r12d,%eax
	movl	%ebp,40(%rsp)
	movl	%esi,%ecx
	bswapl	%r14d
	xorl	%r11d,%eax
	roll	$5,%ecx
	andl	%edi,%eax
	leal	1518500249(%rbp,%r13,1),%r13d
	addl	%ecx,%r13d
	xorl	%r12d,%eax
	roll	$30,%edi
	addl	%eax,%r13d
	movl	48(%r9),%edx
	movl	%r11d,%eax
	movl	%r14d,44(%rsp)
	movl	%r13d,%ecx
	bswapl	%edx
	xorl	%edi,%eax
	roll	$5,%ecx
	andl	%esi,%eax
	leal	1518500249(%r14,%r12,1),%r12d
	addl	%ecx,%r12d
	xorl	%r11d,%eax
	roll	$30,%esi
	addl	%eax,%r12d
	movl	52(%r9),%ebp
	movl	%edi,%eax
	movl	%edx,48(%rsp)
	movl	%r12d,%ecx
	bswapl	%ebp
	xorl	%esi,%eax
	roll	$5,%ecx
	andl	%r13d,%eax
	leal	1518500249(%rdx,%r11,1),%r11d
	addl	%ecx,%r11d
	xorl	%edi,%eax
	roll	$30,%r13d
	addl	%eax,%r11d
	movl	56(%r9),%r14d
	movl	%esi,%eax
	movl	%ebp,52(%rsp)
	movl	%r11d,%ecx
	bswapl	%r14d
	xorl	%r13d,%eax
	roll	$5,%ecx
	andl	%r12d,%eax
	leal	1518500249(%rbp,%rdi,1),%edi
	addl	%ecx,%edi
	xorl	%esi,%eax
	roll	$30,%r12d
	addl	%eax,%edi
	movl	60(%r9),%edx
	movl	%r13d,%eax
	movl	%r14d,56(%rsp)
	movl	%edi,%ecx
	bswapl	%edx
	xorl	%r12d,%eax
	roll	$5,%ecx
	andl	%r11d,%eax
	leal	1518500249(%r14,%rsi,1),%esi
	addl	%ecx,%esi
	xorl	%r13d,%eax
	roll	$30,%r11d
	addl	%eax,%esi
	xorl	0(%rsp),%ebp
	movl	%r12d,%eax
	movl	%edx,60(%rsp)
	movl	%esi,%ecx
	xorl	8(%rsp),%ebp
	xorl	%r11d,%eax
	roll	$5,%ecx
	xorl	32(%rsp),%ebp
	andl	%edi,%eax
	leal	1518500249(%rdx,%r13,1),%r13d
	roll	$30,%edi
	xorl	%r12d,%eax
	addl	%ecx,%r13d
	roll	$1,%ebp
	addl	%eax,%r13d
	xorl	4(%rsp),%r14d
	movl	%r11d,%eax
	movl	%ebp,0(%rsp)
	movl	%r13d,%ecx
	xorl	12(%rsp),%r14d
	xorl	%edi,%eax
	roll	$5,%ecx
	xorl	36(%rsp),%r14d
	andl	%esi,%eax
	leal	1518500249(%rbp,%r12,1),%r12d
	roll	$30,%esi
	xorl	%r11d,%eax
	addl	%ecx,%r12d
	roll	$1,%r14d
	addl	%eax,%r12d
	xorl	8(%rsp),%edx
	movl	%edi,%eax
	movl	%r14d,4(%rsp)
	movl	%r12d,%ecx
	xorl	16(%rsp),%edx
	xorl	%esi,%eax
	roll	$5,%ecx
	xorl	40(%rsp),%edx
	andl	%r13d,%eax
	leal	1518500249(%r14,%r11,1),%r11d
	roll	$30,%r13d
	xorl	%edi,%eax
	addl	%ecx,%r11d
	roll	$1,%edx
	addl	%eax,%r11d
	xorl	12(%rsp),%ebp
	movl	%esi,%eax
	movl	%edx,8(%rsp)
	movl	%r11d,%ecx
	xorl	20(%rsp),%ebp
	xorl	%r13d,%eax
	roll	$5,%ecx
	xorl	44(%rsp),%ebp
	andl	%r12d,%eax
	leal	1518500249(%rdx,%rdi,1),%edi
	roll	$30,%r12d
	xorl	%esi,%eax
	addl	%ecx,%edi
	roll	$1,%ebp
	addl	%eax,%edi
	xorl	16(%rsp),%r14d
	movl	%r13d,%eax
	movl	%ebp,12(%rsp)
	movl	%edi,%ecx
	xorl	24(%rsp),%r14d
	xorl	%r12d,%eax
	roll	$5,%ecx
	xorl	48(%rsp),%r14d
	andl	%r11d,%eax
	leal	1518500249(%rbp,%rsi,1),%esi
	roll	$30,%r11d
	xorl	%r13d,%eax
	addl	%ecx,%esi
	roll	$1,%r14d
	addl	%eax,%esi
	xorl	20(%rsp),%edx
	movl	%edi,%eax
	movl	%r14d,16(%rsp)
	movl	%esi,%ecx
	xorl	28(%rsp),%edx
	xorl	%r12d,%eax
	roll	$5,%ecx
	xorl	52(%rsp),%edx
	leal	1859775393(%r14,%r13,1),%r13d
	xorl	%r11d,%eax
	addl	%ecx,%r13d
	roll	$30,%edi
	addl	%eax,%r13d
	roll	$1,%edx
	xorl	24(%rsp),%ebp
	movl	%esi,%eax
	movl	%edx,20(%rsp)
	movl	%r13d,%ecx
	xorl	32(%rsp),%ebp
	xorl	%r11d,%eax
	roll	$5,%ecx
	xorl	56(%rsp),%ebp
	leal	1859775393(%rdx,%r12,1),%r12d
	xorl	%edi,%eax
	addl	%ecx,%r12d
	roll	$30,%esi
	addl	%eax,%r12d
	roll	$1,%ebp
	xorl	28(%rsp),%r14d
	movl	%r13d,%eax
	movl	%ebp,24(%rsp)
	movl	%r12d,%ecx
	xorl	36(%rsp),%r14d
	xorl	%edi,%eax
	roll	$5,%ecx
	xorl	60(%rsp),%r14d
	leal	1859775393(%rbp,%r11,1),%r11d
	xorl	%esi,%eax
	addl	%ecx,%r11d
	roll	$30,%r13d
	addl	%eax,%r11d
	roll	$1,%r14d
	xorl	32(%rsp),%edx
	movl	%r12d,%eax
	movl	%r14d,28(%rsp)
	movl	%r11d,%ecx
	xorl	40(%rsp),%edx
	xorl	%esi,%eax
	roll	$5,%ecx
	xorl	0(%rsp),%edx
	leal	1859775393(%r14,%rdi,1),%edi
	xorl	%r13d,%eax
	addl	%ecx,%edi
	roll	$30,%r12d
	addl	%eax,%edi
	roll	$1,%edx
	xorl	36(%rsp),%ebp
	movl	%r11d,%eax
	movl	%edx,32(%rsp)
	movl	%edi,%ecx
	xorl	44(%rsp),%ebp
	xorl	%r13d,%eax
	roll	$5,%ecx
	xorl	4(%rsp),%ebp
	leal	1859775393(%rdx,%rsi,1),%esi
	xorl	%r12d,%eax
	addl	%ecx,%esi
	roll	$30,%r11d
	addl	%eax,%esi
	roll	$1,%ebp
	xorl	40(%rsp),%r14d
	movl	%edi,%eax
	movl	%ebp,36(%rsp)
	movl	%esi,%ecx
	xorl	48(%rsp),%r14d
	xorl	%r12d,%eax
	roll	$5,%ecx
	xorl	8(%rsp),%r14d
	leal	1859775393(%rbp,%r13,1),%r13d
	xorl	%r11d,%eax
	addl	%ecx,%r13d
	roll	$30,%edi
	addl	%eax,%r13d
	roll	$1,%r14d
	xorl	44(%rsp),%edx
	movl	%esi,%eax
	movl	%r14d,40(%rsp)
	movl	%r13d,%ecx
	xorl	52(%rsp),%edx
	xorl	%r11d,%eax
	roll	$5,%ecx
	xorl	12(%rsp),%edx
	leal	1859775393(%r14,%r12,1),%r12d
	xorl	%edi,%eax
	addl	%ecx,%r12d
	roll	$30,%esi
	addl	%eax,%r12d
	roll	$1,%edx
	xorl	48(%rsp),%ebp
	movl	%r13d,%eax
	movl	%edx,44(%rsp)
	movl	%r12d,%ecx
	xorl	56(%rsp),%ebp
	xorl	%edi,%eax
	roll	$5,%ecx
	xorl	16(%rsp),%ebp
	leal	1859775393(%rdx,%r11,1),%r11d
	xorl	%esi,%eax
	addl	%ecx,%r11d
	roll	$30,%r13d
	addl	%eax,%r11d
	roll	$1,%ebp
	xorl	52(%rsp),%r14d
	movl	%r12d,%eax
	movl	%ebp,48(%rsp)
	movl	%r11d,%ecx
	xorl	60(%rsp),%r14d
	xorl	%esi,%eax
	roll	$5,%ecx
	xorl	20(%rsp),%r14d
	leal	1859775393(%rbp,%rdi,1),%edi
	xorl	%r13d,%eax
	addl	%ecx,%edi
	roll	$30,%r12d
	addl	%eax,%edi
	roll	$1,%r14d
	xorl	56(%rsp),%edx
	movl	%r11d,%eax
	movl	%r14d,52(%rsp)
	movl	%edi,%ecx
	xorl	0(%rsp),%edx
	xorl	%r13d,%eax
	roll	$5,%ecx
	xorl	24(%rsp),%edx
	leal	1859775393(%r14,%rsi,1),%esi
	xorl	%r12d,%eax
	addl	%ecx,%esi
	roll	$30,%r11d
	addl	%eax,%esi
	roll	$1,%edx
	xorl	60(%rsp),%ebp
	movl	%edi,%eax
	movl	%edx,56(%rsp)
	movl	%esi,%ecx
	xorl	4(%rsp),%ebp
	xorl	%r12d,%eax
	roll	$5,%ecx
	xorl	28(%rsp),%ebp
	leal	1859775393(%rdx,%r13,1),%r13d
	xorl	%r11d,%eax
	addl	%ecx,%r13d
	roll	$30,%edi
	addl	%eax,%r13d
	roll	$1,%ebp
	xorl	0(%rsp),%r14d
	movl	%esi,%eax
	movl	%ebp,60(%rsp)
	movl	%r13d,%ecx
	xorl	8(%rsp),%r14d
	xorl	%r11d,%eax
	roll	$5,%ecx
	xorl	32(%rsp),%r14d
	leal	1859775393(%rbp,%r12,1),%r12d
	xorl	%edi,%eax
	addl	%ecx,%r12d
	roll	$30,%esi
	addl	%eax,%r12d
	roll	$1,%r14d
	xorl	4(%rsp),%edx
	movl	%r13d,%eax
	movl	%r14d,0(%rsp)
	movl	%r12d,%ecx
	xorl	12(%rsp),%edx
	xorl	%edi,%eax
	roll	$5,%ecx
	xorl	36(%rsp),%edx
	leal	1859775393(%r14,%r11,1),%r11d
	xorl	%esi,%eax
	addl	%ecx,%r11d
	roll	$30,%r13d
	addl	%eax,%r11d
	roll	$1,%edx
	xorl	8(%rsp),%ebp
	movl	%r12d,%eax
	movl	%edx,4(%rsp)
	movl	%r11d,%ecx
	xorl	16(%rsp),%ebp
	xorl	%esi,%eax
	roll	$5,%ecx
	xorl	40(%rsp),%ebp
	leal	1859775393(%rdx,%rdi,1),%edi
	xorl	%r13d,%eax
	addl	%ecx,%edi
	roll	$30,%r12d
	addl	%eax,%edi
	roll	$1,%ebp
	xorl	12(%rsp),%r14d
	movl	%r11d,%eax
	movl	%ebp,8(%rsp)
	movl	%edi,%ecx
	xorl	20(%rsp),%r14d
	xorl	%r13d,%eax
	roll	$5,%ecx
	xorl	44(%rsp),%r14d
	leal	1859775393(%rbp,%rsi,1),%esi
	xorl	%r12d,%eax
	addl	%ecx,%esi
	roll	$30,%r11d
	addl	%eax,%esi
	roll	$1,%r14d
	xorl	16(%rsp),%edx
	movl	%edi,%eax
	movl	%r14d,12(%rsp)
	movl	%esi,%ecx
	xorl	24(%rsp),%edx
	xorl	%r12d,%eax
	roll	$5,%ecx
	xorl	48(%rsp),%edx
	leal	1859775393(%r14,%r13,1),%r13d
	xorl	%r11d,%eax
	addl	%ecx,%r13d
	roll	$30,%edi
	addl	%eax,%r13d
	roll	$1,%edx
	xorl	20(%rsp),%ebp
	movl	%esi,%eax
	movl	%edx,16(%rsp)
	movl	%r13d,%ecx
	xorl	28(%rsp),%ebp
	xorl	%r11d,%eax
	roll	$5,%ecx
	xorl	52(%rsp),%ebp
	leal	1859775393(%rdx,%r12,1),%r12d
	xorl	%edi,%eax
	addl	%ecx,%r12d
	roll	$30,%esi
	addl	%eax,%r12d
	roll	$1,%ebp
	xorl	24(%rsp),%r14d
	movl	%r13d,%eax
	movl	%ebp,20(%rsp)
	movl	%r12d,%ecx
	xorl	32(%rsp),%r14d
	xorl	%edi,%eax
	roll	$5,%ecx
	xorl	56(%rsp),%r14d
	leal	1859775393(%rbp,%r11,1),%r11d
	xorl	%esi,%eax
	addl	%ecx,%r11d
	roll	$30,%r13d
	addl	%eax,%r11d
	roll	$1,%r14d
	xorl	28(%rsp),%edx
	movl	%r12d,%eax
	movl	%r14d,24(%rsp)
	movl	%r11d,%ecx
	xorl	36(%rsp),%edx
	xorl	%esi,%eax
	roll	$5,%ecx
	xorl	60(%rsp),%edx
	leal	1859775393(%r14,%rdi,1),%edi
	xorl	%r13d,%eax
	addl	%ecx,%edi
	roll	$30,%r12d
	addl	%eax,%edi
	roll	$1,%edx
	xorl	32(%rsp),%ebp
	movl	%r11d,%eax
	movl	%edx,28(%rsp)
	movl	%edi,%ecx
	xorl	40(%rsp),%ebp
	xorl	%r13d,%eax
	roll	$5,%ecx
	xorl	0(%rsp),%ebp
	leal	1859775393(%rdx,%rsi,1),%esi
	xorl	%r12d,%eax
	addl	%ecx,%esi
	roll	$30,%r11d
	addl	%eax,%esi
	roll	$1,%ebp
	xorl	36(%rsp),%r14d
	movl	%r12d,%eax
	movl	%ebp,32(%rsp)
	movl	%r12d,%ebx
	xorl	44(%rsp),%r14d
	andl	%r11d,%eax
	movl	%esi,%ecx
	xorl	4(%rsp),%r14d
	leal	-1894007588(%rbp,%r13,1),%r13d
	xorl	%r11d,%ebx
	roll	$5,%ecx
	addl	%eax,%r13d
	roll	$1,%r14d
	andl	%edi,%ebx
	addl	%ecx,%r13d
	roll	$30,%edi
	addl	%ebx,%r13d
	xorl	40(%rsp),%edx
	movl	%r11d,%eax
	movl	%r14d,36(%rsp)
	movl	%r11d,%ebx
	xorl	48(%rsp),%edx
	andl	%edi,%eax
	movl	%r13d,%ecx
	xorl	8(%rsp),%edx
	leal	-1894007588(%r14,%r12,1),%r12d
	xorl	%edi,%ebx
	roll	$5,%ecx
	addl	%eax,%r12d
	roll	$1,%edx
	andl	%esi,%ebx
	addl	%ecx,%r12d
	roll	$30,%esi
	addl	%ebx,%r12d
	xorl	44(%rsp),%ebp
	movl	%edi,%eax
	movl	%edx,40(%rsp)
	movl	%edi,%ebx
	xorl	52(%rsp),%ebp
	andl	%esi,%eax
	movl	%r12d,%ecx
	xorl	12(%rsp),%ebp
	leal	-1894007588(%rdx,%r11,1),%r11d
	xorl	%esi,%ebx
	roll	$5,%ecx
	addl	%eax,%r11d
	roll	$1,%ebp
	andl	%r13d,%ebx
	addl	%ecx,%r11d
	roll	$30,%r13d
	addl	%ebx,%r11d
	xorl	48(%rsp),%r14d
	movl	%esi,%eax
	movl	%ebp,44(%rsp)
	movl	%esi,%ebx
	xorl	56(%rsp),%r14d
	andl	%r13d,%eax
	movl	%r11d,%ecx
	xorl	16(%rsp),%r14d
	leal	-1894007588(%rbp,%rdi,1),%edi
	xorl	%r13d,%ebx
	roll	$5,%ecx
	addl	%eax,%edi
	roll	$1,%r14d
	andl	%r12d,%ebx
	addl	%ecx,%edi
	roll	$30,%r12d
	addl	%ebx,%edi
	xorl	52(%rsp),%edx
	movl	%r13d,%eax
	movl	%r14d,48(%rsp)
	movl	%r13d,%ebx
	xorl	60(%rsp),%edx
	andl	%r12d,%eax
	movl	%edi,%ecx
	xorl	20(%rsp),%edx
	leal	-1894007588(%r14,%rsi,1),%esi
	xorl	%r12d,%ebx
	roll	$5,%ecx
	addl	%eax,%esi
	roll	$1,%edx
	andl	%r11d,%ebx
	addl	%ecx,%esi
	roll	$30,%r11d
	addl	%ebx,%esi
	xorl	56(%rsp),%ebp
	movl	%r12d,%eax
	movl	%edx,52(%rsp)
	movl	%r12d,%ebx
	xorl	0(%rsp),%ebp
	andl	%r11d,%eax
	movl	%esi,%ecx
	xorl	24(%rsp),%ebp
	leal	-1894007588(%rdx,%r13,1),%r13d
	xorl	%r11d,%ebx
	roll	$5,%ecx
	addl	%eax,%r13d
	roll	$1,%ebp
	andl	%edi,%ebx
	addl	%ecx,%r13d
	roll	$30,%edi
	addl	%ebx,%r13d
	xorl	60(%rsp),%r14d
	movl	%r11d,%eax
	movl	%ebp,56(%rsp)
	movl	%r11d,%ebx
	xorl	4(%rsp),%r14d
	andl	%edi,%eax
	movl	%r13d,%ecx
	xorl	28(%rsp),%r14d
	leal	-1894007588(%rbp,%r12,1),%r12d
	xorl	%edi,%ebx
	roll	$5,%ecx
	addl	%eax,%r12d
	roll	$1,%r14d
	andl	%esi,%ebx
	addl	%ecx,%r12d
	roll	$30,%esi
	addl	%ebx,%r12d
	xorl	0(%rsp),%edx
	movl	%edi,%eax
	movl	%r14d,60(%rsp)
	movl	%edi,%ebx
	xorl	8(%rsp),%edx
	andl	%esi,%eax
	movl	%r12d,%ecx
	xorl	32(%rsp),%edx
	leal	-1894007588(%r14,%r11,1),%r11d
	xorl	%esi,%ebx
	roll	$5,%ecx
	addl	%eax,%r11d
	roll	$1,%edx
	andl	%r13d,%ebx
	addl	%ecx,%r11d
	roll	$30,%r13d
	addl	%ebx,%r11d
	xorl	4(%rsp),%ebp
	movl	%esi,%eax
	movl	%edx,0(%rsp)
	movl	%esi,%ebx
	xorl	12(%rsp),%ebp
	andl	%r13d,%eax
	movl	%r11d,%ecx
	xorl	36(%rsp),%ebp
	leal	-1894007588(%rdx,%rdi,1),%edi
	xorl	%r13d,%ebx
	roll	$5,%ecx
	addl	%eax,%edi
	roll	$1,%ebp
	andl	%r12d,%ebx
	addl	%ecx,%edi
	roll	$30,%r12d
	addl	%ebx,%edi
	xorl	8(%rsp),%r14d
	movl	%r13d,%eax
	movl	%ebp,4(%rsp)
	movl	%r13d,%ebx
	xorl	16(%rsp),%r14d
	andl	%r12d,%eax
	movl	%edi,%ecx
	xorl	40(%rsp),%r14d
	leal	-1894007588(%rbp,%rsi,1),%esi
	xorl	%r12d,%ebx
	roll	$5,%ecx
	addl	%eax,%esi
	roll	$1,%r14d
	andl	%r11d,%ebx
	addl	%ecx,%esi
	roll	$30,%r11d
	addl	%ebx,%esi
	xorl	12(%rsp),%edx
	movl	%r12d,%eax
	movl	%r14d,8(%rsp)
	movl	%r12d,%ebx
	xorl	20(%rsp),%edx
	andl	%r11d,%eax
	movl	%esi,%ecx
	xorl	44(%rsp),%edx
	leal	-1894007588(%r14,%r13,1),%r13d
	xorl	%r11d,%ebx
	roll	$5,%ecx
	addl	%eax,%r13d
	roll	$1,%edx
	andl	%edi,%ebx
	addl	%ecx,%r13d
	roll	$30,%edi
	addl	%ebx,%r13d
	xorl	16(%rsp),%ebp
	movl	%r11d,%eax
	movl	%edx,12(%rsp)
	movl	%r11d,%ebx
	xorl	24(%rsp),%ebp
	andl	%edi,%eax
	movl	%r13d,%ecx
	xorl	48(%rsp),%ebp
	leal	-1894007588(%rdx,%r12,1),%r12d
	xorl	%edi,%ebx
	roll	$5,%ecx
	addl	%eax,%r12d
	roll	$1,%ebp
	andl	%esi,%ebx
	addl	%ecx,%r12d
	roll	$30,%esi
	addl	%ebx,%r12d
	xorl	20(%rsp),%r14d
	movl	%edi,%eax
	movl	%ebp,16(%rsp)
	movl	%edi,%ebx
	xorl	28(%rsp),%r14d
	andl	%esi,%eax
	movl	%r12d,%ecx
	xorl	52(%rsp),%r14d
	leal	-1894007588(%rbp,%r11,1),%r11d
	xorl	%esi,%ebx
	roll	$5,%ecx
	addl	%eax,%r11d
	roll	$1,%r14d
	andl	%r13d,%ebx
	addl	%ecx,%r11d
	roll	$30,%r13d
	addl	%ebx,%r11d
	xorl	24(%rsp),%edx
	movl	%esi,%eax
	movl	%r14d,20(%rsp)
	movl	%esi,%ebx
	xorl	32(%rsp),%edx
	andl	%r13d,%eax
	movl	%r11d,%ecx
	xorl	56(%rsp),%edx
	leal	-1894007588(%r14,%rdi,1),%edi
	xorl	%r13d,%ebx
	roll	$5,%ecx
	addl	%eax,%edi
	roll	$1,%edx
	andl	%r12d,%ebx
	addl	%ecx,%edi
	roll	$30,%r12d
	addl	%ebx,%edi
	xorl	28(%rsp),%ebp
	movl	%r13d,%eax
	movl	%edx,24(%rsp)
	movl	%r13d,%ebx
	xorl	36(%rsp),%ebp
	andl	%r12d,%eax
	movl	%edi,%ecx
	xorl	60(%rsp),%ebp
	leal	-1894007588(%rdx,%rsi,1),%esi
	xorl	%r12d,%ebx
	roll	$5,%ecx
	addl	%eax,%esi
	roll	$1,%ebp
	andl	%r11d,%ebx
	addl	%ecx,%esi
	roll	$30,%r11d
	addl	%ebx,%esi
	xorl	32(%rsp),%r14d
	movl	%r12d,%eax
	movl	%ebp,28(%rsp)
	movl	%r12d,%ebx
	xorl	40(%rsp),%r14d
	andl	%r11d,%eax
	movl	%esi,%ecx
	xorl	0(%rsp),%r14d
	leal	-1894007588(%rbp,%r13,1),%r13d
	xorl	%r11d,%ebx
	roll	$5,%ecx
	addl	%eax,%r13d
	roll	$1,%r14d
	andl	%edi,%ebx
	addl	%ecx,%r13d
	roll	$30,%edi
	addl	%ebx,%r13d
	xorl	36(%rsp),%edx
	movl	%r11d,%eax
	movl	%r14d,32(%rsp)
	movl	%r11d,%ebx
	xorl	44(%rsp),%edx
	andl	%edi,%eax
	movl	%r13d,%ecx
	xorl	4(%rsp),%edx
	leal	-1894007588(%r14,%r12,1),%r12d
	xorl	%edi,%ebx
	roll	$5,%ecx
	addl	%eax,%r12d
	roll	$1,%edx
	andl	%esi,%ebx
	addl	%ecx,%r12d
	roll	$30,%esi
	addl	%ebx,%r12d
	xorl	40(%rsp),%ebp
	movl	%edi,%eax
	movl	%edx,36(%rsp)
	movl	%edi,%ebx
	xorl	48(%rsp),%ebp
	andl	%esi,%eax
	movl	%r12d,%ecx
	xorl	8(%rsp),%ebp
	leal	-1894007588(%rdx,%r11,1),%r11d
	xorl	%esi,%ebx
	roll	$5,%ecx
	addl	%eax,%r11d
	roll	$1,%ebp
	andl	%r13d,%ebx
	addl	%ecx,%r11d
	roll	$30,%r13d
	addl	%ebx,%r11d
	xorl	44(%rsp),%r14d
	movl	%esi,%eax
	movl	%ebp,40(%rsp)
	movl	%esi,%ebx
	xorl	52(%rsp),%r14d
	andl	%r13d,%eax
	movl	%r11d,%ecx
	xorl	12(%rsp),%r14d
	leal	-1894007588(%rbp,%rdi,1),%edi
	xorl	%r13d,%ebx
	roll	$5,%ecx
	addl	%eax,%edi
	roll	$1,%r14d
	andl	%r12d,%ebx
	addl	%ecx,%edi
	roll	$30,%r12d
	addl	%ebx,%edi
	xorl	48(%rsp),%edx
	movl	%r13d,%eax
	movl	%r14d,44(%rsp)
	movl	%r13d,%ebx
	xorl	56(%rsp),%edx
	andl	%r12d,%eax
	movl	%edi,%ecx
	xorl	16(%rsp),%edx
	leal	-1894007588(%r14,%rsi,1),%esi
	xorl	%r12d,%ebx
	roll	$5,%ecx
	addl	%eax,%esi
	roll	$1,%edx
	andl	%r11d,%ebx
	addl	%ecx,%esi
	roll	$30,%r11d
	addl	%ebx,%esi
	xorl	52(%rsp),%ebp
	movl	%edi,%eax
	movl	%edx,48(%rsp)
	movl	%esi,%ecx
	xorl	60(%rsp),%ebp
	xorl	%r12d,%eax
	roll	$5,%ecx
	xorl	20(%rsp),%ebp
	leal	-899497514(%rdx,%r13,1),%r13d
	xorl	%r11d,%eax
	addl	%ecx,%r13d
	roll	$30,%edi
	addl	%eax,%r13d
	roll	$1,%ebp
	xorl	56(%rsp),%r14d
	movl	%esi,%eax
	movl	%ebp,52(%rsp)
	movl	%r13d,%ecx
	xorl	0(%rsp),%r14d
	xorl	%r11d,%eax
	roll	$5,%ecx
	xorl	24(%rsp),%r14d
	leal	-899497514(%rbp,%r12,1),%r12d
	xorl	%edi,%eax
	addl	%ecx,%r12d
	roll	$30,%esi
	addl	%eax,%r12d
	roll	$1,%r14d
	xorl	60(%rsp),%edx
	movl	%r13d,%eax
	movl	%r14d,56(%rsp)
	movl	%r12d,%ecx
	xorl	4(%rsp),%edx
	xorl	%edi,%eax
	roll	$5,%ecx
	xorl	28(%rsp),%edx
	leal	-899497514(%r14,%r11,1),%r11d
	xorl	%esi,%eax
	addl	%ecx,%r11d
	roll	$30,%r13d
	addl	%eax,%r11d
	roll	$1,%edx
	xorl	0(%rsp),%ebp
	movl	%r12d,%eax
	movl	%edx,60(%rsp)
	movl	%r11d,%ecx
	xorl	8(%rsp),%ebp
	xorl	%esi,%eax
	roll	$5,%ecx
	xorl	32(%rsp),%ebp
	leal	-899497514(%rdx,%rdi,1),%edi
	xorl	%r13d,%eax
	addl	%ecx,%edi
	roll	$30,%r12d
	addl	%eax,%edi
	roll	$1,%ebp
	xorl	4(%rsp),%r14d
	movl	%r11d,%eax
	movl	%ebp,0(%rsp)
	movl	%edi,%ecx
	xorl	12(%rsp),%r14d
	xorl	%r13d,%eax
	roll	$5,%ecx
	xorl	36(%rsp),%r14d
	leal	-899497514(%rbp,%rsi,1),%esi
	xorl	%r12d,%eax
	addl	%ecx,%esi
	roll	$30,%r11d
	addl	%eax,%esi
	roll	$1,%r14d
	xorl	8(%rsp),%edx
	movl	%edi,%eax
	movl	%r14d,4(%rsp)
	movl	%esi,%ecx
	xorl	16(%rsp),%edx
	xorl	%r12d,%eax
	roll	$5,%ecx
	xorl	40(%rsp),%edx
	leal	-899497514(%r14,%r13,1),%r13d
	xorl	%r11d,%eax
	addl	%ecx,%r13d
	roll	$30,%edi
	addl	%eax,%r13d
	roll	$1,%edx
	xorl	12(%rsp),%ebp
	movl	%esi,%eax
	movl	%edx,8(%rsp)
	movl	%r13d,%ecx
	xorl	20(%rsp),%ebp
	xorl	%r11d,%eax
	roll	$5,%ecx
	xorl	44(%rsp),%ebp
	leal	-899497514(%rdx,%r12,1),%r12d
	xorl	%edi,%eax
	addl	%ecx,%r12d
	roll	$30,%esi
	addl	%eax,%r12d
	roll	$1,%ebp
	xorl	16(%rsp),%r14d
	movl	%r13d,%eax
	movl	%ebp,12(%rsp)
	movl	%r12d,%ecx
	xorl	24(%rsp),%r14d
	xorl	%edi,%eax
	roll	$5,%ecx
	xorl	48(%rsp),%r14d
	leal	-899497514(%rbp,%r11,1),%r11d
	xorl	%esi,%eax
	addl	%ecx,%r11d
	roll	$30,%r13d
	addl	%eax,%r11d
	roll	$1,%r14d
	xorl	20(%rsp),%edx
	movl	%r12d,%eax
	movl	%r14d,16(%rsp)
	movl	%r11d,%ecx
	xorl	28(%rsp),%edx
	xorl	%esi,%eax
	roll	$5,%ecx
	xorl	52(%rsp),%edx
	leal	-899497514(%r14,%rdi,1),%edi
	xorl	%r13d,%eax
	addl	%ecx,%edi
	roll	$30,%r12d
	addl	%eax,%edi
	roll	$1,%edx
	xorl	24(%rsp),%ebp
	movl	%r11d,%eax
	movl	%edx,20(%rsp)
	movl	%edi,%ecx
	xorl	32(%rsp),%ebp
	xorl	%r13d,%eax
	roll	$5,%ecx
	xorl	56(%rsp),%ebp
	leal	-899497514(%rdx,%rsi,1),%esi
	xorl	%r12d,%eax
	addl	%ecx,%esi
	roll	$30,%r11d
	addl	%eax,%esi
	roll	$1,%ebp
	xorl	28(%rsp),%r14d
	movl	%edi,%eax
	movl	%ebp,24(%rsp)
	movl	%esi,%ecx
	xorl	36(%rsp),%r14d
	xorl	%r12d,%eax
	roll	$5,%ecx
	xorl	60(%rsp),%r14d
	leal	-899497514(%rbp,%r13,1),%r13d
	xorl	%r11d,%eax
	addl	%ecx,%r13d
	roll	$30,%edi
	addl	%eax,%r13d
	roll	$1,%r14d
	xorl	32(%rsp),%edx
	movl	%esi,%eax
	movl	%r14d,28(%rsp)
	movl	%r13d,%ecx
	xorl	40(%rsp),%edx
	xorl	%r11d,%eax
	roll	$5,%ecx
	xorl	0(%rsp),%edx
	leal	-899497514(%r14,%r12,1),%r12d
	xorl	%edi,%eax
	addl	%ecx,%r12d
	roll	$30,%esi
	addl	%eax,%r12d
	roll	$1,%edx
	xorl	36(%rsp),%ebp
	movl	%r13d,%eax

	movl	%r12d,%ecx
	xorl	44(%rsp),%ebp
	xorl	%edi,%eax
	roll	$5,%ecx
	xorl	4(%rsp),%ebp
	leal	-899497514(%rdx,%r11,1),%r11d
	xorl	%esi,%eax
	addl	%ecx,%r11d
	roll	$30,%r13d
	addl	%eax,%r11d
	roll	$1,%ebp
	xorl	40(%rsp),%r14d
	movl	%r12d,%eax

	movl	%r11d,%ecx
	xorl	48(%rsp),%r14d
	xorl	%esi,%eax
	roll	$5,%ecx
	xorl	8(%rsp),%r14d
	leal	-899497514(%rbp,%rdi,1),%edi
	xorl	%r13d,%eax
	addl	%ecx,%edi
	roll	$30,%r12d
	addl	%eax,%edi
	roll	$1,%r14d
	xorl	44(%rsp),%edx
	movl	%r11d,%eax

	movl	%edi,%ecx
	xorl	52(%rsp),%edx
	xorl	%r13d,%eax
	roll	$5,%ecx
	xorl	12(%rsp),%edx
	leal	-899497514(%r14,%rsi,1),%esi
	xorl	%r12d,%eax
	addl	%ecx,%esi
	roll	$30,%r11d
	addl	%eax,%esi
	roll	$1,%edx
	xorl	48(%rsp),%ebp
	movl	%edi,%eax

	movl	%esi,%ecx
	xorl	56(%rsp),%ebp
	xorl	%r12d,%eax
	roll	$5,%ecx
	xorl	16(%rsp),%ebp
	leal	-899497514(%rdx,%r13,1),%r13d
	xorl	%r11d,%eax
	addl	%ecx,%r13d
	roll	$30,%edi
	addl	%eax,%r13d
	roll	$1,%ebp
	xorl	52(%rsp),%r14d
	movl	%esi,%eax

	movl	%r13d,%ecx
	xorl	60(%rsp),%r14d
	xorl	%r11d,%eax
	roll	$5,%ecx
	xorl	20(%rsp),%r14d
	leal	-899497514(%rbp,%r12,1),%r12d
	xorl	%edi,%eax
	addl	%ecx,%r12d
	roll	$30,%esi
	addl	%eax,%r12d
	roll	$1,%r14d
	xorl	56(%rsp),%edx
	movl	%r13d,%eax

	movl	%r12d,%ecx
	xorl	0(%rsp),%edx
	xorl	%edi,%eax
	roll	$5,%ecx
	xorl	24(%rsp),%edx
	leal	-899497514(%r14,%r11,1),%r11d
	xorl	%esi,%eax
	addl	%ecx,%r11d
	roll	$30,%r13d
	addl	%eax,%r11d
	roll	$1,%edx
	xorl	60(%rsp),%ebp
	movl	%r12d,%eax

	movl	%r11d,%ecx
	xorl	4(%rsp),%ebp
	xorl	%esi,%eax
	roll	$5,%ecx
	xorl	28(%rsp),%ebp
	leal	-899497514(%rdx,%rdi,1),%edi
	xorl	%r13d,%eax
	addl	%ecx,%edi
	roll	$30,%r12d
	addl	%eax,%edi
	roll	$1,%ebp
	movl	%r11d,%eax
	movl	%edi,%ecx
	xorl	%r13d,%eax
	leal	-899497514(%rbp,%rsi,1),%esi
	roll	$5,%ecx
	xorl	%r12d,%eax
	addl	%ecx,%esi
	roll	$30,%r11d
	addl	%eax,%esi
	addl	0(%r8),%esi
	addl	4(%r8),%edi
	addl	8(%r8),%r11d
	addl	12(%r8),%r12d
	addl	16(%r8),%r13d
	movl	%esi,0(%r8)
	movl	%edi,4(%r8)
	movl	%r11d,8(%r8)
	movl	%r12d,12(%r8)
	movl	%r13d,16(%r8)

	subq	$1,%r10
	leaq	64(%r9),%r9
	jnz	.Lloop

	movq	64(%rsp),%rsi
.cfi_def_cfa	%rsi,8
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha1_block_data_order,.-sha1_block_data_order
.type	sha1_block_data_order_shaext,@function
.align	32
sha1_block_data_order_shaext:
_shaext_shortcut:
.cfi_startproc	
	movdqu	(%rdi),%xmm0
	movd	16(%rdi),%xmm1
	movdqa	K_XX_XX+160(%rip),%xmm3

	movdqu	(%rsi),%xmm4
	pshufd	$27,%xmm0,%xmm0
	movdqu	16(%rsi),%xmm5
	pshufd	$27,%xmm1,%xmm1
	movdqu	32(%rsi),%xmm6
.byte	102,15,56,0,227
	movdqu	48(%rsi),%xmm7
.byte	102,15,56,0,235
.byte	102,15,56,0,243
	movdqa	%xmm1,%xmm9
.byte	102,15,56,0,251
	jmp	.Loop_shaext

.align	16
.Loop_shaext:
	decq	%rdx
	leaq	64(%rsi),%r8
	paddd	%xmm4,%xmm1
	cmovneq	%r8,%rsi
	movdqa	%xmm0,%xmm8
.byte	15,56,201,229
	movdqa	%xmm0,%xmm2
.byte	15,58,204,193,0
.byte	15,56,200,213
	pxor	%xmm6,%xmm4
.byte	15,56,201,238
.byte	15,56,202,231

	movdqa	%xmm0,%xmm1
.byte	15,58,204,194,0
.byte	15,56,200,206
	pxor	%xmm7,%xmm5
.byte	15,56,202,236
.byte	15,56,201,247
	movdqa	%xmm0,%xmm2
.byte	15,58,204,193,0
.byte	15,56,200,215
	pxor	%xmm4,%xmm6
.byte	15,56,201,252
.byte	15,56,202,245

	movdqa	%xmm0,%xmm1
.byte	15,58,204,194,0
.byte	15,56,200,204
	pxor	%xmm5,%xmm7
.byte	15,56,202,254
.byte	15,56,201,229
	movdqa	%xmm0,%xmm2
.byte	15,58,204,193,0
.byte	15,56,200,213
	pxor	%xmm6,%xmm4
.byte	15,56,201,238
.byte	15,56,202,231

	movdqa	%xmm0,%xmm1
.byte	15,58,204,194,1
.byte	15,56,200,206
	pxor	%xmm7,%xmm5
.byte	15,56,202,236
.byte	15,56,201,247
	movdqa	%xmm0,%xmm2
.byte	15,58,204,193,1
.byte	15,56,200,215
	pxor	%xmm4,%xmm6
.byte	15,56,201,252
.byte	15,56,202,245

	movdqa	%xmm0,%xmm1
.byte	15,58,204,194,1
.byte	15,56,200,204
	pxor	%xmm5,%xmm7
.byte	15,56,202,254
.byte	15,56,201,229
	movdqa	%xmm0,%xmm2
.byte	15,58,204,193,1
.byte	15,56,200,213
	pxor	%xmm6,%xmm4
.byte	15,56,201,238
.byte	15,56,202,231

	movdqa	%xmm0,%xmm1
.byte	15,58,204,194,1
.byte	15,56,200,206
	pxor	%xmm7,%xmm5
.byte	15,56,202,236
.byte	15,56,201,247
	movdqa	%xmm0,%xmm2
.byte	15,58,204,193,2
.byte	15,56,200,215
	pxor	%xmm4,%xmm6
.byte	15,56,201,252
.byte	15,56,202,245

	movdqa	%xmm0,%xmm1
.byte	15,58,204,194,2
.byte	15,56,200,204
	pxor	%xmm5,%xmm7
.byte	15,56,202,254
.byte	15,56,201,229
	movdqa	%xmm0,%xmm2
.byte	15,58,204,193,2
.byte	15,56,200,213
	pxor	%xmm6,%xmm4
.byte	15,56,201,238
.byte	15,56,202,231

	movdqa	%xmm0,%xmm1
.byte	15,58,204,194,2
.byte	15,56,200,206
	pxor	%xmm7,%xmm5
.byte	15,56,202,236
.byte	15,56,201,247
	movdqa	%xmm0,%xmm2
.byte	15,58,204,193,2
.byte	15,56,200,215
	pxor	%xmm4,%xmm6
.byte	15,56,201,252
.byte	15,56,202,245

	movdqa	%xmm0,%xmm1
.byte	15,58,204,194,3
.byte	15,56,200,204
	pxor	%xmm5,%xmm7
.byte	15,56,202,254
	movdqu	(%rsi),%xmm4
	movdqa	%xmm0,%xmm2
.byte	15,58,204,193,3
.byte	15,56,200,213
	movdqu	16(%rsi),%xmm5
.byte	102,15,56,0,227

	movdqa	%xmm0,%xmm1
.byte	15,58,204,194,3
.byte	15,56,200,206
	movdqu	32(%rsi),%xmm6
.byte	102,15,56,0,235

	movdqa	%xmm0,%xmm2
.byte	15,58,204,193,3
.byte	15,56,200,215
	movdqu	48(%rsi),%xmm7
.byte	102,15,56,0,243

	movdqa	%xmm0,%xmm1
.byte	15,58,204,194,3
.byte	65,15,56,200,201
.byte	102,15,56,0,251

	paddd	%xmm8,%xmm0
	movdqa	%xmm1,%xmm9

	jnz	.Loop_shaext

	pshufd	$27,%xmm0,%xmm0
	pshufd	$27,%xmm1,%xmm1
	movdqu	%xmm0,(%rdi)
	movd	%xmm1,16(%rdi)
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha1_block_data_order_shaext,.-sha1_block_data_order_shaext
.type	sha1_block_data_order_ssse3,@function
.align	16
sha1_block_data_order_ssse3:
_ssse3_shortcut:
.cfi_startproc	
	movq	%rsp,%r11
.cfi_def_cfa_register	%r11
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	leaq	-64(%rsp),%rsp
	andq	$-64,%rsp
	movq	%rdi,%r8
	movq	%rsi,%r9
	movq	%rdx,%r10

	shlq	$6,%r10
	addq	%r9,%r10
	leaq	K_XX_XX+64(%rip),%r14

	movl	0(%r8),%eax
	movl	4(%r8),%ebx
	movl	8(%r8),%ecx
	movl	12(%r8),%edx
	movl	%ebx,%esi
	movl	16(%r8),%ebp
	movl	%ecx,%edi
	xorl	%edx,%edi
	andl	%edi,%esi

	movdqa	64(%r14),%xmm6
	movdqa	-64(%r14),%xmm9
	movdqu	0(%r9),%xmm0
	movdqu	16(%r9),%xmm1
	movdqu	32(%r9),%xmm2
	movdqu	48(%r9),%xmm3
.byte	102,15,56,0,198
.byte	102,15,56,0,206
.byte	102,15,56,0,214
	addq	$64,%r9
	paddd	%xmm9,%xmm0
.byte	102,15,56,0,222
	paddd	%xmm9,%xmm1
	paddd	%xmm9,%xmm2
	movdqa	%xmm0,0(%rsp)
	psubd	%xmm9,%xmm0
	movdqa	%xmm1,16(%rsp)
	psubd	%xmm9,%xmm1
	movdqa	%xmm2,32(%rsp)
	psubd	%xmm9,%xmm2
	jmp	.Loop_ssse3
.align	16
.Loop_ssse3:
	rorl	$2,%ebx
	pshufd	$238,%xmm0,%xmm4
	xorl	%edx,%esi
	movdqa	%xmm3,%xmm8
	paddd	%xmm3,%xmm9
	movl	%eax,%edi
	addl	0(%rsp),%ebp
	punpcklqdq	%xmm1,%xmm4
	xorl	%ecx,%ebx
	roll	$5,%eax
	addl	%esi,%ebp
	psrldq	$4,%xmm8
	andl	%ebx,%edi
	xorl	%ecx,%ebx
	pxor	%xmm0,%xmm4
	addl	%eax,%ebp
	rorl	$7,%eax
	pxor	%xmm2,%xmm8
	xorl	%ecx,%edi
	movl	%ebp,%esi
	addl	4(%rsp),%edx
	pxor	%xmm8,%xmm4
	xorl	%ebx,%eax
	roll	$5,%ebp
	movdqa	%xmm9,48(%rsp)
	addl	%edi,%edx
	andl	%eax,%esi
	movdqa	%xmm4,%xmm10
	xorl	%ebx,%eax
	addl	%ebp,%edx
	rorl	$7,%ebp
	movdqa	%xmm4,%xmm8
	xorl	%ebx,%esi
	pslldq	$12,%xmm10
	paddd	%xmm4,%xmm4
	movl	%edx,%edi
	addl	8(%rsp),%ecx
	psrld	$31,%xmm8
	xorl	%eax,%ebp
	roll	$5,%edx
	addl	%esi,%ecx
	movdqa	%xmm10,%xmm9
	andl	%ebp,%edi
	xorl	%eax,%ebp
	psrld	$30,%xmm10
	addl	%edx,%ecx
	rorl	$7,%edx
	por	%xmm8,%xmm4
	xorl	%eax,%edi
	movl	%ecx,%esi
	addl	12(%rsp),%ebx
	pslld	$2,%xmm9
	pxor	%xmm10,%xmm4
	xorl	%ebp,%edx
	movdqa	-64(%r14),%xmm10
	roll	$5,%ecx
	addl	%edi,%ebx
	andl	%edx,%esi
	pxor	%xmm9,%xmm4
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	rorl	$7,%ecx
	pshufd	$238,%xmm1,%xmm5
	xorl	%ebp,%esi
	movdqa	%xmm4,%xmm9
	paddd	%xmm4,%xmm10
	movl	%ebx,%edi
	addl	16(%rsp),%eax
	punpcklqdq	%xmm2,%xmm5
	xorl	%edx,%ecx
	roll	$5,%ebx
	addl	%esi,%eax
	psrldq	$4,%xmm9
	andl	%ecx,%edi
	xorl	%edx,%ecx
	pxor	%xmm1,%xmm5
	addl	%ebx,%eax
	rorl	$7,%ebx
	pxor	%xmm3,%xmm9
	xorl	%edx,%edi
	movl	%eax,%esi
	addl	20(%rsp),%ebp
	pxor	%xmm9,%xmm5
	xorl	%ecx,%ebx
	roll	$5,%eax
	movdqa	%xmm10,0(%rsp)
	addl	%edi,%ebp
	andl	%ebx,%esi
	movdqa	%xmm5,%xmm8
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	rorl	$7,%eax
	movdqa	%xmm5,%xmm9
	xorl	%ecx,%esi
	pslldq	$12,%xmm8
	paddd	%xmm5,%xmm5
	movl	%ebp,%edi
	addl	24(%rsp),%edx
	psrld	$31,%xmm9
	xorl	%ebx,%eax
	roll	$5,%ebp
	addl	%esi,%edx
	movdqa	%xmm8,%xmm10
	andl	%eax,%edi
	xorl	%ebx,%eax
	psrld	$30,%xmm8
	addl	%ebp,%edx
	rorl	$7,%ebp
	por	%xmm9,%xmm5
	xorl	%ebx,%edi
	movl	%edx,%esi
	addl	28(%rsp),%ecx
	pslld	$2,%xmm10
	pxor	%xmm8,%xmm5
	xorl	%eax,%ebp
	movdqa	-32(%r14),%xmm8
	roll	$5,%edx
	addl	%edi,%ecx
	andl	%ebp,%esi
	pxor	%xmm10,%xmm5
	xorl	%eax,%ebp
	addl	%edx,%ecx
	rorl	$7,%edx
	pshufd	$238,%xmm2,%xmm6
	xorl	%eax,%esi
	movdqa	%xmm5,%xmm10
	paddd	%xmm5,%xmm8
	movl	%ecx,%edi
	addl	32(%rsp),%ebx
	punpcklqdq	%xmm3,%xmm6
	xorl	%ebp,%edx
	roll	$5,%ecx
	addl	%esi,%ebx
	psrldq	$4,%xmm10
	andl	%edx,%edi
	xorl	%ebp,%edx
	pxor	%xmm2,%xmm6
	addl	%ecx,%ebx
	rorl	$7,%ecx
	pxor	%xmm4,%xmm10
	xorl	%ebp,%edi
	movl	%ebx,%esi
	addl	36(%rsp),%eax
	pxor	%xmm10,%xmm6
	xorl	%edx,%ecx
	roll	$5,%ebx
	movdqa	%xmm8,16(%rsp)
	addl	%edi,%eax
	andl	%ecx,%esi
	movdqa	%xmm6,%xmm9
	xorl	%edx,%ecx
	addl	%ebx,%eax
	rorl	$7,%ebx
	movdqa	%xmm6,%xmm10
	xorl	%edx,%esi
	pslldq	$12,%xmm9
	paddd	%xmm6,%xmm6
	movl	%eax,%edi
	addl	40(%rsp),%ebp
	psrld	$31,%xmm10
	xorl	%ecx,%ebx
	roll	$5,%eax
	addl	%esi,%ebp
	movdqa	%xmm9,%xmm8
	andl	%ebx,%edi
	xorl	%ecx,%ebx
	psrld	$30,%xmm9
	addl	%eax,%ebp
	rorl	$7,%eax
	por	%xmm10,%xmm6
	xorl	%ecx,%edi
	movl	%ebp,%esi
	addl	44(%rsp),%edx
	pslld	$2,%xmm8
	pxor	%xmm9,%xmm6
	xorl	%ebx,%eax
	movdqa	-32(%r14),%xmm9
	roll	$5,%ebp
	addl	%edi,%edx
	andl	%eax,%esi
	pxor	%xmm8,%xmm6
	xorl	%ebx,%eax
	addl	%ebp,%edx
	rorl	$7,%ebp
	pshufd	$238,%xmm3,%xmm7
	xorl	%ebx,%esi
	movdqa	%xmm6,%xmm8
	paddd	%xmm6,%xmm9
	movl	%edx,%edi
	addl	48(%rsp),%ecx
	punpcklqdq	%xmm4,%xmm7
	xorl	%eax,%ebp
	roll	$5,%edx
	addl	%esi,%ecx
	psrldq	$4,%xmm8
	andl	%ebp,%edi
	xorl	%eax,%ebp
	pxor	%xmm3,%xmm7
	addl	%edx,%ecx
	rorl	$7,%edx
	pxor	%xmm5,%xmm8
	xorl	%eax,%edi
	movl	%ecx,%esi
	addl	52(%rsp),%ebx
	pxor	%xmm8,%xmm7
	xorl	%ebp,%edx
	roll	$5,%ecx
	movdqa	%xmm9,32(%rsp)
	addl	%edi,%ebx
	andl	%edx,%esi
	movdqa	%xmm7,%xmm10
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	rorl	$7,%ecx
	movdqa	%xmm7,%xmm8
	xorl	%ebp,%esi
	pslldq	$12,%xmm10
	paddd	%xmm7,%xmm7
	movl	%ebx,%edi
	addl	56(%rsp),%eax
	psrld	$31,%xmm8
	xorl	%edx,%ecx
	roll	$5,%ebx
	addl	%esi,%eax
	movdqa	%xmm10,%xmm9
	andl	%ecx,%edi
	xorl	%edx,%ecx
	psrld	$30,%xmm10
	addl	%ebx,%eax
	rorl	$7,%ebx
	por	%xmm8,%xmm7
	xorl	%edx,%edi
	movl	%eax,%esi
	addl	60(%rsp),%ebp
	pslld	$2,%xmm9
	pxor	%xmm10,%xmm7
	xorl	%ecx,%ebx
	movdqa	-32(%r14),%xmm10
	roll	$5,%eax
	addl	%edi,%ebp
	andl	%ebx,%esi
	pxor	%xmm9,%xmm7
	pshufd	$238,%xmm6,%xmm9
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	rorl	$7,%eax
	pxor	%xmm4,%xmm0
	xorl	%ecx,%esi
	movl	%ebp,%edi
	addl	0(%rsp),%edx
	punpcklqdq	%xmm7,%xmm9
	xorl	%ebx,%eax
	roll	$5,%ebp
	pxor	%xmm1,%xmm0
	addl	%esi,%edx
	andl	%eax,%edi
	movdqa	%xmm10,%xmm8
	xorl	%ebx,%eax
	paddd	%xmm7,%xmm10
	addl	%ebp,%edx
	pxor	%xmm9,%xmm0
	rorl	$7,%ebp
	xorl	%ebx,%edi
	movl	%edx,%esi
	addl	4(%rsp),%ecx
	movdqa	%xmm0,%xmm9
	xorl	%eax,%ebp
	roll	$5,%edx
	movdqa	%xmm10,48(%rsp)
	addl	%edi,%ecx
	andl	%ebp,%esi
	xorl	%eax,%ebp
	pslld	$2,%xmm0
	addl	%edx,%ecx
	rorl	$7,%edx
	psrld	$30,%xmm9
	xorl	%eax,%esi
	movl	%ecx,%edi
	addl	8(%rsp),%ebx
	por	%xmm9,%xmm0
	xorl	%ebp,%edx
	roll	$5,%ecx
	pshufd	$238,%xmm7,%xmm10
	addl	%esi,%ebx
	andl	%edx,%edi
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	addl	12(%rsp),%eax
	xorl	%ebp,%edi
	movl	%ebx,%esi
	roll	$5,%ebx
	addl	%edi,%eax
	xorl	%edx,%esi
	rorl	$7,%ecx
	addl	%ebx,%eax
	pxor	%xmm5,%xmm1
	addl	16(%rsp),%ebp
	xorl	%ecx,%esi
	punpcklqdq	%xmm0,%xmm10
	movl	%eax,%edi
	roll	$5,%eax
	pxor	%xmm2,%xmm1
	addl	%esi,%ebp
	xorl	%ecx,%edi
	movdqa	%xmm8,%xmm9
	rorl	$7,%ebx
	paddd	%xmm0,%xmm8
	addl	%eax,%ebp
	pxor	%xmm10,%xmm1
	addl	20(%rsp),%edx
	xorl	%ebx,%edi
	movl	%ebp,%esi
	roll	$5,%ebp
	movdqa	%xmm1,%xmm10
	addl	%edi,%edx
	xorl	%ebx,%esi
	movdqa	%xmm8,0(%rsp)
	rorl	$7,%eax
	addl	%ebp,%edx
	addl	24(%rsp),%ecx
	pslld	$2,%xmm1
	xorl	%eax,%esi
	movl	%edx,%edi
	psrld	$30,%xmm10
	roll	$5,%edx
	addl	%esi,%ecx
	xorl	%eax,%edi
	rorl	$7,%ebp
	por	%xmm10,%xmm1
	addl	%edx,%ecx
	addl	28(%rsp),%ebx
	pshufd	$238,%xmm0,%xmm8
	xorl	%ebp,%edi
	movl	%ecx,%esi
	roll	$5,%ecx
	addl	%edi,%ebx
	xorl	%ebp,%esi
	rorl	$7,%edx
	addl	%ecx,%ebx
	pxor	%xmm6,%xmm2
	addl	32(%rsp),%eax
	xorl	%edx,%esi
	punpcklqdq	%xmm1,%xmm8
	movl	%ebx,%edi
	roll	$5,%ebx
	pxor	%xmm3,%xmm2
	addl	%esi,%eax
	xorl	%edx,%edi
	movdqa	0(%r14),%xmm10
	rorl	$7,%ecx
	paddd	%xmm1,%xmm9
	addl	%ebx,%eax
	pxor	%xmm8,%xmm2
	addl	36(%rsp),%ebp
	xorl	%ecx,%edi
	movl	%eax,%esi
	roll	$5,%eax
	movdqa	%xmm2,%xmm8
	addl	%edi,%ebp
	xorl	%ecx,%esi
	movdqa	%xmm9,16(%rsp)
	rorl	$7,%ebx
	addl	%eax,%ebp
	addl	40(%rsp),%edx
	pslld	$2,%xmm2
	xorl	%ebx,%esi
	movl	%ebp,%edi
	psrld	$30,%xmm8
	roll	$5,%ebp
	addl	%esi,%edx
	xorl	%ebx,%edi
	rorl	$7,%eax
	por	%xmm8,%xmm2
	addl	%ebp,%edx
	addl	44(%rsp),%ecx
	pshufd	$238,%xmm1,%xmm9
	xorl	%eax,%edi
	movl	%edx,%esi
	roll	$5,%edx
	addl	%edi,%ecx
	xorl	%eax,%esi
	rorl	$7,%ebp
	addl	%edx,%ecx
	pxor	%xmm7,%xmm3
	addl	48(%rsp),%ebx
	xorl	%ebp,%esi
	punpcklqdq	%xmm2,%xmm9
	movl	%ecx,%edi
	roll	$5,%ecx
	pxor	%xmm4,%xmm3
	addl	%esi,%ebx
	xorl	%ebp,%edi
	movdqa	%xmm10,%xmm8
	rorl	$7,%edx
	paddd	%xmm2,%xmm10
	addl	%ecx,%ebx
	pxor	%xmm9,%xmm3
	addl	52(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	roll	$5,%ebx
	movdqa	%xmm3,%xmm9
	addl	%edi,%eax
	xorl	%edx,%esi
	movdqa	%xmm10,32(%rsp)
	rorl	$7,%ecx
	addl	%ebx,%eax
	addl	56(%rsp),%ebp
	pslld	$2,%xmm3
	xorl	%ecx,%esi
	movl	%eax,%edi
	psrld	$30,%xmm9
	roll	$5,%eax
	addl	%esi,%ebp
	xorl	%ecx,%edi
	rorl	$7,%ebx
	por	%xmm9,%xmm3
	addl	%eax,%ebp
	addl	60(%rsp),%edx
	pshufd	$238,%xmm2,%xmm10
	xorl	%ebx,%edi
	movl	%ebp,%esi
	roll	$5,%ebp
	addl	%edi,%edx
	xorl	%ebx,%esi
	rorl	$7,%eax
	addl	%ebp,%edx
	pxor	%xmm0,%xmm4
	addl	0(%rsp),%ecx
	xorl	%eax,%esi
	punpcklqdq	%xmm3,%xmm10
	movl	%edx,%edi
	roll	$5,%edx
	pxor	%xmm5,%xmm4
	addl	%esi,%ecx
	xorl	%eax,%edi
	movdqa	%xmm8,%xmm9
	rorl	$7,%ebp
	paddd	%xmm3,%xmm8
	addl	%edx,%ecx
	pxor	%xmm10,%xmm4
	addl	4(%rsp),%ebx
	xorl	%ebp,%edi
	movl	%ecx,%esi
	roll	$5,%ecx
	movdqa	%xmm4,%xmm10
	addl	%edi,%ebx
	xorl	%ebp,%esi
	movdqa	%xmm8,48(%rsp)
	rorl	$7,%edx
	addl	%ecx,%ebx
	addl	8(%rsp),%eax
	pslld	$2,%xmm4
	xorl	%edx,%esi
	movl	%ebx,%edi
	psrld	$30,%xmm10
	roll	$5,%ebx
	addl	%esi,%eax
	xorl	%edx,%edi
	rorl	$7,%ecx
	por	%xmm10,%xmm4
	addl	%ebx,%eax
	addl	12(%rsp),%ebp
	pshufd	$238,%xmm3,%xmm8
	xorl	%ecx,%edi
	movl	%eax,%esi
	roll	$5,%eax
	addl	%edi,%ebp
	xorl	%ecx,%esi
	rorl	$7,%ebx
	addl	%eax,%ebp
	pxor	%xmm1,%xmm5
	addl	16(%rsp),%edx
	xorl	%ebx,%esi
	punpcklqdq	%xmm4,%xmm8
	movl	%ebp,%edi
	roll	$5,%ebp
	pxor	%xmm6,%xmm5
	addl	%esi,%edx
	xorl	%ebx,%edi
	movdqa	%xmm9,%xmm10
	rorl	$7,%eax
	paddd	%xmm4,%xmm9
	addl	%ebp,%edx
	pxor	%xmm8,%xmm5
	addl	20(%rsp),%ecx
	xorl	%eax,%edi
	movl	%edx,%esi
	roll	$5,%edx
	movdqa	%xmm5,%xmm8
	addl	%edi,%ecx
	xorl	%eax,%esi
	movdqa	%xmm9,0(%rsp)
	rorl	$7,%ebp
	addl	%edx,%ecx
	addl	24(%rsp),%ebx
	pslld	$2,%xmm5
	xorl	%ebp,%esi
	movl	%ecx,%edi
	psrld	$30,%xmm8
	roll	$5,%ecx
	addl	%esi,%ebx
	xorl	%ebp,%edi
	rorl	$7,%edx
	por	%xmm8,%xmm5
	addl	%ecx,%ebx
	addl	28(%rsp),%eax
	pshufd	$238,%xmm4,%xmm9
	rorl	$7,%ecx
	movl	%ebx,%esi
	xorl	%edx,%edi
	roll	$5,%ebx
	addl	%edi,%eax
	xorl	%ecx,%esi
	xorl	%edx,%ecx
	addl	%ebx,%eax
	pxor	%xmm2,%xmm6
	addl	32(%rsp),%ebp
	andl	%ecx,%esi
	xorl	%edx,%ecx
	rorl	$7,%ebx
	punpcklqdq	%xmm5,%xmm9
	movl	%eax,%edi
	xorl	%ecx,%esi
	pxor	%xmm7,%xmm6
	roll	$5,%eax
	addl	%esi,%ebp
	movdqa	%xmm10,%xmm8
	xorl	%ebx,%edi
	paddd	%xmm5,%xmm10
	xorl	%ecx,%ebx
	pxor	%xmm9,%xmm6
	addl	%eax,%ebp
	addl	36(%rsp),%edx
	andl	%ebx,%edi
	xorl	%ecx,%ebx
	rorl	$7,%eax
	movdqa	%xmm6,%xmm9
	movl	%ebp,%esi
	xorl	%ebx,%edi
	movdqa	%xmm10,16(%rsp)
	roll	$5,%ebp
	addl	%edi,%edx
	xorl	%eax,%esi
	pslld	$2,%xmm6
	xorl	%ebx,%eax
	addl	%ebp,%edx
	psrld	$30,%xmm9
	addl	40(%rsp),%ecx
	andl	%eax,%esi
	xorl	%ebx,%eax
	por	%xmm9,%xmm6
	rorl	$7,%ebp
	movl	%edx,%edi
	xorl	%eax,%esi
	roll	$5,%edx
	pshufd	$238,%xmm5,%xmm10
	addl	%esi,%ecx
	xorl	%ebp,%edi
	xorl	%eax,%ebp
	addl	%edx,%ecx
	addl	44(%rsp),%ebx
	andl	%ebp,%edi
	xorl	%eax,%ebp
	rorl	$7,%edx
	movl	%ecx,%esi
	xorl	%ebp,%edi
	roll	$5,%ecx
	addl	%edi,%ebx
	xorl	%edx,%esi
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	pxor	%xmm3,%xmm7
	addl	48(%rsp),%eax
	andl	%edx,%esi
	xorl	%ebp,%edx
	rorl	$7,%ecx
	punpcklqdq	%xmm6,%xmm10
	movl	%ebx,%edi
	xorl	%edx,%esi
	pxor	%xmm0,%xmm7
	roll	$5,%ebx
	addl	%esi,%eax
	movdqa	32(%r14),%xmm9
	xorl	%ecx,%edi
	paddd	%xmm6,%xmm8
	xorl	%edx,%ecx
	pxor	%xmm10,%xmm7
	addl	%ebx,%eax
	addl	52(%rsp),%ebp
	andl	%ecx,%edi
	xorl	%edx,%ecx
	rorl	$7,%ebx
	movdqa	%xmm7,%xmm10
	movl	%eax,%esi
	xorl	%ecx,%edi
	movdqa	%xmm8,32(%rsp)
	roll	$5,%eax
	addl	%edi,%ebp
	xorl	%ebx,%esi
	pslld	$2,%xmm7
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	psrld	$30,%xmm10
	addl	56(%rsp),%edx
	andl	%ebx,%esi
	xorl	%ecx,%ebx
	por	%xmm10,%xmm7
	rorl	$7,%eax
	movl	%ebp,%edi
	xorl	%ebx,%esi
	roll	$5,%ebp
	pshufd	$238,%xmm6,%xmm8
	addl	%esi,%edx
	xorl	%eax,%edi
	xorl	%ebx,%eax
	addl	%ebp,%edx
	addl	60(%rsp),%ecx
	andl	%eax,%edi
	xorl	%ebx,%eax
	rorl	$7,%ebp
	movl	%edx,%esi
	xorl	%eax,%edi
	roll	$5,%edx
	addl	%edi,%ecx
	xorl	%ebp,%esi
	xorl	%eax,%ebp
	addl	%edx,%ecx
	pxor	%xmm4,%xmm0
	addl	0(%rsp),%ebx
	andl	%ebp,%esi
	xorl	%eax,%ebp
	rorl	$7,%edx
	punpcklqdq	%xmm7,%xmm8
	movl	%ecx,%edi
	xorl	%ebp,%esi
	pxor	%xmm1,%xmm0
	roll	$5,%ecx
	addl	%esi,%ebx
	movdqa	%xmm9,%xmm10
	xorl	%edx,%edi
	paddd	%xmm7,%xmm9
	xorl	%ebp,%edx
	pxor	%xmm8,%xmm0
	addl	%ecx,%ebx
	addl	4(%rsp),%eax
	andl	%edx,%edi
	xorl	%ebp,%edx
	rorl	$7,%ecx
	movdqa	%xmm0,%xmm8
	movl	%ebx,%esi
	xorl	%edx,%edi
	movdqa	%xmm9,48(%rsp)
	roll	$5,%ebx
	addl	%edi,%eax
	xorl	%ecx,%esi
	pslld	$2,%xmm0
	xorl	%edx,%ecx
	addl	%ebx,%eax
	psrld	$30,%xmm8
	addl	8(%rsp),%ebp
	andl	%ecx,%esi
	xorl	%edx,%ecx
	por	%xmm8,%xmm0
	rorl	$7,%ebx
	movl	%eax,%edi
	xorl	%ecx,%esi
	roll	$5,%eax
	pshufd	$238,%xmm7,%xmm9
	addl	%esi,%ebp
	xorl	%ebx,%edi
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	addl	12(%rsp),%edx
	andl	%ebx,%edi
	xorl	%ecx,%ebx
	rorl	$7,%eax
	movl	%ebp,%esi
	xorl	%ebx,%edi
	roll	$5,%ebp
	addl	%edi,%edx
	xorl	%eax,%esi
	xorl	%ebx,%eax
	addl	%ebp,%edx
	pxor	%xmm5,%xmm1
	addl	16(%rsp),%ecx
	andl	%eax,%esi
	xorl	%ebx,%eax
	rorl	$7,%ebp
	punpcklqdq	%xmm0,%xmm9
	movl	%edx,%edi
	xorl	%eax,%esi
	pxor	%xmm2,%xmm1
	roll	$5,%edx
	addl	%esi,%ecx
	movdqa	%xmm10,%xmm8
	xorl	%ebp,%edi
	paddd	%xmm0,%xmm10
	xorl	%eax,%ebp
	pxor	%xmm9,%xmm1
	addl	%edx,%ecx
	addl	20(%rsp),%ebx
	andl	%ebp,%edi
	xorl	%eax,%ebp
	rorl	$7,%edx
	movdqa	%xmm1,%xmm9
	movl	%ecx,%esi
	xorl	%ebp,%edi
	movdqa	%xmm10,0(%rsp)
	roll	$5,%ecx
	addl	%edi,%ebx
	xorl	%edx,%esi
	pslld	$2,%xmm1
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	psrld	$30,%xmm9
	addl	24(%rsp),%eax
	andl	%edx,%esi
	xorl	%ebp,%edx
	por	%xmm9,%xmm1
	rorl	$7,%ecx
	movl	%ebx,%edi
	xorl	%edx,%esi
	roll	$5,%ebx
	pshufd	$238,%xmm0,%xmm10
	addl	%esi,%eax
	xorl	%ecx,%edi
	xorl	%edx,%ecx
	addl	%ebx,%eax
	addl	28(%rsp),%ebp
	andl	%ecx,%edi
	xorl	%edx,%ecx
	rorl	$7,%ebx
	movl	%eax,%esi
	xorl	%ecx,%edi
	roll	$5,%eax
	addl	%edi,%ebp
	xorl	%ebx,%esi
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	pxor	%xmm6,%xmm2
	addl	32(%rsp),%edx
	andl	%ebx,%esi
	xorl	%ecx,%ebx
	rorl	$7,%eax
	punpcklqdq	%xmm1,%xmm10
	movl	%ebp,%edi
	xorl	%ebx,%esi
	pxor	%xmm3,%xmm2
	roll	$5,%ebp
	addl	%esi,%edx
	movdqa	%xmm8,%xmm9
	xorl	%eax,%edi
	paddd	%xmm1,%xmm8
	xorl	%ebx,%eax
	pxor	%xmm10,%xmm2
	addl	%ebp,%edx
	addl	36(%rsp),%ecx
	andl	%eax,%edi
	xorl	%ebx,%eax
	rorl	$7,%ebp
	movdqa	%xmm2,%xmm10
	movl	%edx,%esi
	xorl	%eax,%edi
	movdqa	%xmm8,16(%rsp)
	roll	$5,%edx
	addl	%edi,%ecx
	xorl	%ebp,%esi
	pslld	$2,%xmm2
	xorl	%eax,%ebp
	addl	%edx,%ecx
	psrld	$30,%xmm10
	addl	40(%rsp),%ebx
	andl	%ebp,%esi
	xorl	%eax,%ebp
	por	%xmm10,%xmm2
	rorl	$7,%edx
	movl	%ecx,%edi
	xorl	%ebp,%esi
	roll	$5,%ecx
	pshufd	$238,%xmm1,%xmm8
	addl	%esi,%ebx
	xorl	%edx,%edi
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	addl	44(%rsp),%eax
	andl	%edx,%edi
	xorl	%ebp,%edx
	rorl	$7,%ecx
	movl	%ebx,%esi
	xorl	%edx,%edi
	roll	$5,%ebx
	addl	%edi,%eax
	xorl	%edx,%esi
	addl	%ebx,%eax
	pxor	%xmm7,%xmm3
	addl	48(%rsp),%ebp
	xorl	%ecx,%esi
	punpcklqdq	%xmm2,%xmm8
	movl	%eax,%edi
	roll	$5,%eax
	pxor	%xmm4,%xmm3
	addl	%esi,%ebp
	xorl	%ecx,%edi
	movdqa	%xmm9,%xmm10
	rorl	$7,%ebx
	paddd	%xmm2,%xmm9
	addl	%eax,%ebp
	pxor	%xmm8,%xmm3
	addl	52(%rsp),%edx
	xorl	%ebx,%edi
	movl	%ebp,%esi
	roll	$5,%ebp
	movdqa	%xmm3,%xmm8
	addl	%edi,%edx
	xorl	%ebx,%esi
	movdqa	%xmm9,32(%rsp)
	rorl	$7,%eax
	addl	%ebp,%edx
	addl	56(%rsp),%ecx
	pslld	$2,%xmm3
	xorl	%eax,%esi
	movl	%edx,%edi
	psrld	$30,%xmm8
	roll	$5,%edx
	addl	%esi,%ecx
	xorl	%eax,%edi
	rorl	$7,%ebp
	por	%xmm8,%xmm3
	addl	%edx,%ecx
	addl	60(%rsp),%ebx
	xorl	%ebp,%edi
	movl	%ecx,%esi
	roll	$5,%ecx
	addl	%edi,%ebx
	xorl	%ebp,%esi
	rorl	$7,%edx
	addl	%ecx,%ebx
	addl	0(%rsp),%eax
	xorl	%edx,%esi
	movl	%ebx,%edi
	roll	$5,%ebx
	paddd	%xmm3,%xmm10
	addl	%esi,%eax
	xorl	%edx,%edi
	movdqa	%xmm10,48(%rsp)
	rorl	$7,%ecx
	addl	%ebx,%eax
	addl	4(%rsp),%ebp
	xorl	%ecx,%edi
	movl	%eax,%esi
	roll	$5,%eax
	addl	%edi,%ebp
	xorl	%ecx,%esi
	rorl	$7,%ebx
	addl	%eax,%ebp
	addl	8(%rsp),%edx
	xorl	%ebx,%esi
	movl	%ebp,%edi
	roll	$5,%ebp
	addl	%esi,%edx
	xorl	%ebx,%edi
	rorl	$7,%eax
	addl	%ebp,%edx
	addl	12(%rsp),%ecx
	xorl	%eax,%edi
	movl	%edx,%esi
	roll	$5,%edx
	addl	%edi,%ecx
	xorl	%eax,%esi
	rorl	$7,%ebp
	addl	%edx,%ecx
	cmpq	%r10,%r9
	je	.Ldone_ssse3
	movdqa	64(%r14),%xmm6
	movdqa	-64(%r14),%xmm9
	movdqu	0(%r9),%xmm0
	movdqu	16(%r9),%xmm1
	movdqu	32(%r9),%xmm2
	movdqu	48(%r9),%xmm3
.byte	102,15,56,0,198
	addq	$64,%r9
	addl	16(%rsp),%ebx
	xorl	%ebp,%esi
	movl	%ecx,%edi
.byte	102,15,56,0,206
	roll	$5,%ecx
	addl	%esi,%ebx
	xorl	%ebp,%edi
	rorl	$7,%edx
	paddd	%xmm9,%xmm0
	addl	%ecx,%ebx
	addl	20(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	movdqa	%xmm0,0(%rsp)
	roll	$5,%ebx
	addl	%edi,%eax
	xorl	%edx,%esi
	rorl	$7,%ecx
	psubd	%xmm9,%xmm0
	addl	%ebx,%eax
	addl	24(%rsp),%ebp
	xorl	%ecx,%esi
	movl	%eax,%edi
	roll	$5,%eax
	addl	%esi,%ebp
	xorl	%ecx,%edi
	rorl	$7,%ebx
	addl	%eax,%ebp
	addl	28(%rsp),%edx
	xorl	%ebx,%edi
	movl	%ebp,%esi
	roll	$5,%ebp
	addl	%edi,%edx
	xorl	%ebx,%esi
	rorl	$7,%eax
	addl	%ebp,%edx
	addl	32(%rsp),%ecx
	xorl	%eax,%esi
	movl	%edx,%edi
.byte	102,15,56,0,214
	roll	$5,%edx
	addl	%esi,%ecx
	xorl	%eax,%edi
	rorl	$7,%ebp
	paddd	%xmm9,%xmm1
	addl	%edx,%ecx
	addl	36(%rsp),%ebx
	xorl	%ebp,%edi
	movl	%ecx,%esi
	movdqa	%xmm1,16(%rsp)
	roll	$5,%ecx
	addl	%edi,%ebx
	xorl	%ebp,%esi
	rorl	$7,%edx
	psubd	%xmm9,%xmm1
	addl	%ecx,%ebx
	addl	40(%rsp),%eax
	xorl	%edx,%esi
	movl	%ebx,%edi
	roll	$5,%ebx
	addl	%esi,%eax
	xorl	%edx,%edi
	rorl	$7,%ecx
	addl	%ebx,%eax
	addl	44(%rsp),%ebp
	xorl	%ecx,%edi
	movl	%eax,%esi
	roll	$5,%eax
	addl	%edi,%ebp
	xorl	%ecx,%esi
	rorl	$7,%ebx
	addl	%eax,%ebp
	addl	48(%rsp),%edx
	xorl	%ebx,%esi
	movl	%ebp,%edi
.byte	102,15,56,0,222
	roll	$5,%ebp
	addl	%esi,%edx
	xorl	%ebx,%edi
	rorl	$7,%eax
	paddd	%xmm9,%xmm2
	addl	%ebp,%edx
	addl	52(%rsp),%ecx
	xorl	%eax,%edi
	movl	%edx,%esi
	movdqa	%xmm2,32(%rsp)
	roll	$5,%edx
	addl	%edi,%ecx
	xorl	%eax,%esi
	rorl	$7,%ebp
	psubd	%xmm9,%xmm2
	addl	%edx,%ecx
	addl	56(%rsp),%ebx
	xorl	%ebp,%esi
	movl	%ecx,%edi
	roll	$5,%ecx
	addl	%esi,%ebx
	xorl	%ebp,%edi
	rorl	$7,%edx
	addl	%ecx,%ebx
	addl	60(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	roll	$5,%ebx
	addl	%edi,%eax
	rorl	$7,%ecx
	addl	%ebx,%eax
	addl	0(%r8),%eax
	addl	4(%r8),%esi
	addl	8(%r8),%ecx
	addl	12(%r8),%edx
	movl	%eax,0(%r8)
	addl	16(%r8),%ebp
	movl	%esi,4(%r8)
	movl	%esi,%ebx
	movl	%ecx,8(%r8)
	movl	%ecx,%edi
	movl	%edx,12(%r8)
	xorl	%edx,%edi
	movl	%ebp,16(%r8)
	andl	%edi,%esi
	jmp	.Loop_ssse3

.align	16
.Ldone_ssse3:
	addl	16(%rsp),%ebx
	xorl	%ebp,%esi
	movl	%ecx,%edi
	roll	$5,%ecx
	addl	%esi,%ebx
	xorl	%ebp,%edi
	rorl	$7,%edx
	addl	%ecx,%ebx
	addl	20(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	roll	$5,%ebx
	addl	%edi,%eax
	xorl	%edx,%esi
	rorl	$7,%ecx
	addl	%ebx,%eax
	addl	24(%rsp),%ebp
	xorl	%ecx,%esi
	movl	%eax,%edi
	roll	$5,%eax
	addl	%esi,%ebp
	xorl	%ecx,%edi
	rorl	$7,%ebx
	addl	%eax,%ebp
	addl	28(%rsp),%edx
	xorl	%ebx,%edi
	movl	%ebp,%esi
	roll	$5,%ebp
	addl	%edi,%edx
	xorl	%ebx,%esi
	rorl	$7,%eax
	addl	%ebp,%edx
	addl	32(%rsp),%ecx
	xorl	%eax,%esi
	movl	%edx,%edi
	roll	$5,%edx
	addl	%esi,%ecx
	xorl	%eax,%edi
	rorl	$7,%ebp
	addl	%edx,%ecx
	addl	36(%rsp),%ebx
	xorl	%ebp,%edi
	movl	%ecx,%esi
	roll	$5,%ecx
	addl	%edi,%ebx
	xorl	%ebp,%esi
	rorl	$7,%edx
	addl	%ecx,%ebx
	addl	40(%rsp),%eax
	xorl	%edx,%esi
	movl	%ebx,%edi
	roll	$5,%ebx
	addl	%esi,%eax
	xorl	%edx,%edi
	rorl	$7,%ecx
	addl	%ebx,%eax
	addl	44(%rsp),%ebp
	xorl	%ecx,%edi
	movl	%eax,%esi
	roll	$5,%eax
	addl	%edi,%ebp
	xorl	%ecx,%esi
	rorl	$7,%ebx
	addl	%eax,%ebp
	addl	48(%rsp),%edx
	xorl	%ebx,%esi
	movl	%ebp,%edi
	roll	$5,%ebp
	addl	%esi,%edx
	xorl	%ebx,%edi
	rorl	$7,%eax
	addl	%ebp,%edx
	addl	52(%rsp),%ecx
	xorl	%eax,%edi
	movl	%edx,%esi
	roll	$5,%edx
	addl	%edi,%ecx
	xorl	%eax,%esi
	rorl	$7,%ebp
	addl	%edx,%ecx
	addl	56(%rsp),%ebx
	xorl	%ebp,%esi
	movl	%ecx,%edi
	roll	$5,%ecx
	addl	%esi,%ebx
	xorl	%ebp,%edi
	rorl	$7,%edx
	addl	%ecx,%ebx
	addl	60(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	roll	$5,%ebx
	addl	%edi,%eax
	rorl	$7,%ecx
	addl	%ebx,%eax
	addl	0(%r8),%eax
	addl	4(%r8),%esi
	addl	8(%r8),%ecx
	movl	%eax,0(%r8)
	addl	12(%r8),%edx
	movl	%esi,4(%r8)
	addl	16(%r8),%ebp
	movl	%ecx,8(%r8)
	movl	%edx,12(%r8)
	movl	%ebp,16(%r8)
	movq	-40(%r11),%r14
.cfi_restore	%r14
	movq	-32(%r11),%r13
.cfi_restore	%r13
	movq	-24(%r11),%r12
.cfi_restore	%r12
	movq	-16(%r11),%rbp
.cfi_restore	%rbp
	movq	-8(%r11),%rbx
.cfi_restore	%rbx
	leaq	(%r11),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue_ssse3:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha1_block_data_order_ssse3,.-sha1_block_data_order_ssse3
.type	sha1_block_data_order_avx,@function
.align	16
sha1_block_data_order_avx:
_avx_shortcut:
.cfi_startproc	
	movq	%rsp,%r11
.cfi_def_cfa_register	%r11
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	leaq	-64(%rsp),%rsp
	vzeroupper
	andq	$-64,%rsp
	movq	%rdi,%r8
	movq	%rsi,%r9
	movq	%rdx,%r10

	shlq	$6,%r10
	addq	%r9,%r10
	leaq	K_XX_XX+64(%rip),%r14

	movl	0(%r8),%eax
	movl	4(%r8),%ebx
	movl	8(%r8),%ecx
	movl	12(%r8),%edx
	movl	%ebx,%esi
	movl	16(%r8),%ebp
	movl	%ecx,%edi
	xorl	%edx,%edi
	andl	%edi,%esi

	vmovdqa	64(%r14),%xmm6
	vmovdqa	-64(%r14),%xmm11
	vmovdqu	0(%r9),%xmm0
	vmovdqu	16(%r9),%xmm1
	vmovdqu	32(%r9),%xmm2
	vmovdqu	48(%r9),%xmm3
	vpshufb	%xmm6,%xmm0,%xmm0
	addq	$64,%r9
	vpshufb	%xmm6,%xmm1,%xmm1
	vpshufb	%xmm6,%xmm2,%xmm2
	vpshufb	%xmm6,%xmm3,%xmm3
	vpaddd	%xmm11,%xmm0,%xmm4
	vpaddd	%xmm11,%xmm1,%xmm5
	vpaddd	%xmm11,%xmm2,%xmm6
	vmovdqa	%xmm4,0(%rsp)
	vmovdqa	%xmm5,16(%rsp)
	vmovdqa	%xmm6,32(%rsp)
	jmp	.Loop_avx
.align	16
.Loop_avx:
	shrdl	$2,%ebx,%ebx
	xorl	%edx,%esi
	vpalignr	$8,%xmm0,%xmm1,%xmm4
	movl	%eax,%edi
	addl	0(%rsp),%ebp
	vpaddd	%xmm3,%xmm11,%xmm9
	xorl	%ecx,%ebx
	shldl	$5,%eax,%eax
	vpsrldq	$4,%xmm3,%xmm8
	addl	%esi,%ebp
	andl	%ebx,%edi
	vpxor	%xmm0,%xmm4,%xmm4
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	vpxor	%xmm2,%xmm8,%xmm8
	shrdl	$7,%eax,%eax
	xorl	%ecx,%edi
	movl	%ebp,%esi
	addl	4(%rsp),%edx
	vpxor	%xmm8,%xmm4,%xmm4
	xorl	%ebx,%eax
	shldl	$5,%ebp,%ebp
	vmovdqa	%xmm9,48(%rsp)
	addl	%edi,%edx
	andl	%eax,%esi
	vpsrld	$31,%xmm4,%xmm8
	xorl	%ebx,%eax
	addl	%ebp,%edx
	shrdl	$7,%ebp,%ebp
	xorl	%ebx,%esi
	vpslldq	$12,%xmm4,%xmm10
	vpaddd	%xmm4,%xmm4,%xmm4
	movl	%edx,%edi
	addl	8(%rsp),%ecx
	xorl	%eax,%ebp
	shldl	$5,%edx,%edx
	vpsrld	$30,%xmm10,%xmm9
	vpor	%xmm8,%xmm4,%xmm4
	addl	%esi,%ecx
	andl	%ebp,%edi
	xorl	%eax,%ebp
	addl	%edx,%ecx
	vpslld	$2,%xmm10,%xmm10
	vpxor	%xmm9,%xmm4,%xmm4
	shrdl	$7,%edx,%edx
	xorl	%eax,%edi
	movl	%ecx,%esi
	addl	12(%rsp),%ebx
	vpxor	%xmm10,%xmm4,%xmm4
	xorl	%ebp,%edx
	shldl	$5,%ecx,%ecx
	addl	%edi,%ebx
	andl	%edx,%esi
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	shrdl	$7,%ecx,%ecx
	xorl	%ebp,%esi
	vpalignr	$8,%xmm1,%xmm2,%xmm5
	movl	%ebx,%edi
	addl	16(%rsp),%eax
	vpaddd	%xmm4,%xmm11,%xmm9
	xorl	%edx,%ecx
	shldl	$5,%ebx,%ebx
	vpsrldq	$4,%xmm4,%xmm8
	addl	%esi,%eax
	andl	%ecx,%edi
	vpxor	%xmm1,%xmm5,%xmm5
	xorl	%edx,%ecx
	addl	%ebx,%eax
	vpxor	%xmm3,%xmm8,%xmm8
	shrdl	$7,%ebx,%ebx
	xorl	%edx,%edi
	movl	%eax,%esi
	addl	20(%rsp),%ebp
	vpxor	%xmm8,%xmm5,%xmm5
	xorl	%ecx,%ebx
	shldl	$5,%eax,%eax
	vmovdqa	%xmm9,0(%rsp)
	addl	%edi,%ebp
	andl	%ebx,%esi
	vpsrld	$31,%xmm5,%xmm8
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	shrdl	$7,%eax,%eax
	xorl	%ecx,%esi
	vpslldq	$12,%xmm5,%xmm10
	vpaddd	%xmm5,%xmm5,%xmm5
	movl	%ebp,%edi
	addl	24(%rsp),%edx
	xorl	%ebx,%eax
	shldl	$5,%ebp,%ebp
	vpsrld	$30,%xmm10,%xmm9
	vpor	%xmm8,%xmm5,%xmm5
	addl	%esi,%edx
	andl	%eax,%edi
	xorl	%ebx,%eax
	addl	%ebp,%edx
	vpslld	$2,%xmm10,%xmm10
	vpxor	%xmm9,%xmm5,%xmm5
	shrdl	$7,%ebp,%ebp
	xorl	%ebx,%edi
	movl	%edx,%esi
	addl	28(%rsp),%ecx
	vpxor	%xmm10,%xmm5,%xmm5
	xorl	%eax,%ebp
	shldl	$5,%edx,%edx
	vmovdqa	-32(%r14),%xmm11
	addl	%edi,%ecx
	andl	%ebp,%esi
	xorl	%eax,%ebp
	addl	%edx,%ecx
	shrdl	$7,%edx,%edx
	xorl	%eax,%esi
	vpalignr	$8,%xmm2,%xmm3,%xmm6
	movl	%ecx,%edi
	addl	32(%rsp),%ebx
	vpaddd	%xmm5,%xmm11,%xmm9
	xorl	%ebp,%edx
	shldl	$5,%ecx,%ecx
	vpsrldq	$4,%xmm5,%xmm8
	addl	%esi,%ebx
	andl	%edx,%edi
	vpxor	%xmm2,%xmm6,%xmm6
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	vpxor	%xmm4,%xmm8,%xmm8
	shrdl	$7,%ecx,%ecx
	xorl	%ebp,%edi
	movl	%ebx,%esi
	addl	36(%rsp),%eax
	vpxor	%xmm8,%xmm6,%xmm6
	xorl	%edx,%ecx
	shldl	$5,%ebx,%ebx
	vmovdqa	%xmm9,16(%rsp)
	addl	%edi,%eax
	andl	%ecx,%esi
	vpsrld	$31,%xmm6,%xmm8
	xorl	%edx,%ecx
	addl	%ebx,%eax
	shrdl	$7,%ebx,%ebx
	xorl	%edx,%esi
	vpslldq	$12,%xmm6,%xmm10
	vpaddd	%xmm6,%xmm6,%xmm6
	movl	%eax,%edi
	addl	40(%rsp),%ebp
	xorl	%ecx,%ebx
	shldl	$5,%eax,%eax
	vpsrld	$30,%xmm10,%xmm9
	vpor	%xmm8,%xmm6,%xmm6
	addl	%esi,%ebp
	andl	%ebx,%edi
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	vpslld	$2,%xmm10,%xmm10
	vpxor	%xmm9,%xmm6,%xmm6
	shrdl	$7,%eax,%eax
	xorl	%ecx,%edi
	movl	%ebp,%esi
	addl	44(%rsp),%edx
	vpxor	%xmm10,%xmm6,%xmm6
	xorl	%ebx,%eax
	shldl	$5,%ebp,%ebp
	addl	%edi,%edx
	andl	%eax,%esi
	xorl	%ebx,%eax
	addl	%ebp,%edx
	shrdl	$7,%ebp,%ebp
	xorl	%ebx,%esi
	vpalignr	$8,%xmm3,%xmm4,%xmm7
	movl	%edx,%edi
	addl	48(%rsp),%ecx
	vpaddd	%xmm6,%xmm11,%xmm9
	xorl	%eax,%ebp
	shldl	$5,%edx,%edx
	vpsrldq	$4,%xmm6,%xmm8
	addl	%esi,%ecx
	andl	%ebp,%edi
	vpxor	%xmm3,%xmm7,%xmm7
	xorl	%eax,%ebp
	addl	%edx,%ecx
	vpxor	%xmm5,%xmm8,%xmm8
	shrdl	$7,%edx,%edx
	xorl	%eax,%edi
	movl	%ecx,%esi
	addl	52(%rsp),%ebx
	vpxor	%xmm8,%xmm7,%xmm7
	xorl	%ebp,%edx
	shldl	$5,%ecx,%ecx
	vmovdqa	%xmm9,32(%rsp)
	addl	%edi,%ebx
	andl	%edx,%esi
	vpsrld	$31,%xmm7,%xmm8
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	shrdl	$7,%ecx,%ecx
	xorl	%ebp,%esi
	vpslldq	$12,%xmm7,%xmm10
	vpaddd	%xmm7,%xmm7,%xmm7
	movl	%ebx,%edi
	addl	56(%rsp),%eax
	xorl	%edx,%ecx
	shldl	$5,%ebx,%ebx
	vpsrld	$30,%xmm10,%xmm9
	vpor	%xmm8,%xmm7,%xmm7
	addl	%esi,%eax
	andl	%ecx,%edi
	xorl	%edx,%ecx
	addl	%ebx,%eax
	vpslld	$2,%xmm10,%xmm10
	vpxor	%xmm9,%xmm7,%xmm7
	shrdl	$7,%ebx,%ebx
	xorl	%edx,%edi
	movl	%eax,%esi
	addl	60(%rsp),%ebp
	vpxor	%xmm10,%xmm7,%xmm7
	xorl	%ecx,%ebx
	shldl	$5,%eax,%eax
	addl	%edi,%ebp
	andl	%ebx,%esi
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	vpalignr	$8,%xmm6,%xmm7,%xmm8
	vpxor	%xmm4,%xmm0,%xmm0
	shrdl	$7,%eax,%eax
	xorl	%ecx,%esi
	movl	%ebp,%edi
	addl	0(%rsp),%edx
	vpxor	%xmm1,%xmm0,%xmm0
	xorl	%ebx,%eax
	shldl	$5,%ebp,%ebp
	vpaddd	%xmm7,%xmm11,%xmm9
	addl	%esi,%edx
	andl	%eax,%edi
	vpxor	%xmm8,%xmm0,%xmm0
	xorl	%ebx,%eax
	addl	%ebp,%edx
	shrdl	$7,%ebp,%ebp
	xorl	%ebx,%edi
	vpsrld	$30,%xmm0,%xmm8
	vmovdqa	%xmm9,48(%rsp)
	movl	%edx,%esi
	addl	4(%rsp),%ecx
	xorl	%eax,%ebp
	shldl	$5,%edx,%edx
	vpslld	$2,%xmm0,%xmm0
	addl	%edi,%ecx
	andl	%ebp,%esi
	xorl	%eax,%ebp
	addl	%edx,%ecx
	shrdl	$7,%edx,%edx
	xorl	%eax,%esi
	movl	%ecx,%edi
	addl	8(%rsp),%ebx
	vpor	%xmm8,%xmm0,%xmm0
	xorl	%ebp,%edx
	shldl	$5,%ecx,%ecx
	addl	%esi,%ebx
	andl	%edx,%edi
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	addl	12(%rsp),%eax
	xorl	%ebp,%edi
	movl	%ebx,%esi
	shldl	$5,%ebx,%ebx
	addl	%edi,%eax
	xorl	%edx,%esi
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	vpalignr	$8,%xmm7,%xmm0,%xmm8
	vpxor	%xmm5,%xmm1,%xmm1
	addl	16(%rsp),%ebp
	xorl	%ecx,%esi
	movl	%eax,%edi
	shldl	$5,%eax,%eax
	vpxor	%xmm2,%xmm1,%xmm1
	addl	%esi,%ebp
	xorl	%ecx,%edi
	vpaddd	%xmm0,%xmm11,%xmm9
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	vpxor	%xmm8,%xmm1,%xmm1
	addl	20(%rsp),%edx
	xorl	%ebx,%edi
	movl	%ebp,%esi
	shldl	$5,%ebp,%ebp
	vpsrld	$30,%xmm1,%xmm8
	vmovdqa	%xmm9,0(%rsp)
	addl	%edi,%edx
	xorl	%ebx,%esi
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	vpslld	$2,%xmm1,%xmm1
	addl	24(%rsp),%ecx
	xorl	%eax,%esi
	movl	%edx,%edi
	shldl	$5,%edx,%edx
	addl	%esi,%ecx
	xorl	%eax,%edi
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	vpor	%xmm8,%xmm1,%xmm1
	addl	28(%rsp),%ebx
	xorl	%ebp,%edi
	movl	%ecx,%esi
	shldl	$5,%ecx,%ecx
	addl	%edi,%ebx
	xorl	%ebp,%esi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	vpalignr	$8,%xmm0,%xmm1,%xmm8
	vpxor	%xmm6,%xmm2,%xmm2
	addl	32(%rsp),%eax
	xorl	%edx,%esi
	movl	%ebx,%edi
	shldl	$5,%ebx,%ebx
	vpxor	%xmm3,%xmm2,%xmm2
	addl	%esi,%eax
	xorl	%edx,%edi
	vpaddd	%xmm1,%xmm11,%xmm9
	vmovdqa	0(%r14),%xmm11
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	vpxor	%xmm8,%xmm2,%xmm2
	addl	36(%rsp),%ebp
	xorl	%ecx,%edi
	movl	%eax,%esi
	shldl	$5,%eax,%eax
	vpsrld	$30,%xmm2,%xmm8
	vmovdqa	%xmm9,16(%rsp)
	addl	%edi,%ebp
	xorl	%ecx,%esi
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	vpslld	$2,%xmm2,%xmm2
	addl	40(%rsp),%edx
	xorl	%ebx,%esi
	movl	%ebp,%edi
	shldl	$5,%ebp,%ebp
	addl	%esi,%edx
	xorl	%ebx,%edi
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	vpor	%xmm8,%xmm2,%xmm2
	addl	44(%rsp),%ecx
	xorl	%eax,%edi
	movl	%edx,%esi
	shldl	$5,%edx,%edx
	addl	%edi,%ecx
	xorl	%eax,%esi
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	vpalignr	$8,%xmm1,%xmm2,%xmm8
	vpxor	%xmm7,%xmm3,%xmm3
	addl	48(%rsp),%ebx
	xorl	%ebp,%esi
	movl	%ecx,%edi
	shldl	$5,%ecx,%ecx
	vpxor	%xmm4,%xmm3,%xmm3
	addl	%esi,%ebx
	xorl	%ebp,%edi
	vpaddd	%xmm2,%xmm11,%xmm9
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	vpxor	%xmm8,%xmm3,%xmm3
	addl	52(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	shldl	$5,%ebx,%ebx
	vpsrld	$30,%xmm3,%xmm8
	vmovdqa	%xmm9,32(%rsp)
	addl	%edi,%eax
	xorl	%edx,%esi
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	vpslld	$2,%xmm3,%xmm3
	addl	56(%rsp),%ebp
	xorl	%ecx,%esi
	movl	%eax,%edi
	shldl	$5,%eax,%eax
	addl	%esi,%ebp
	xorl	%ecx,%edi
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	vpor	%xmm8,%xmm3,%xmm3
	addl	60(%rsp),%edx
	xorl	%ebx,%edi
	movl	%ebp,%esi
	shldl	$5,%ebp,%ebp
	addl	%edi,%edx
	xorl	%ebx,%esi
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	vpalignr	$8,%xmm2,%xmm3,%xmm8
	vpxor	%xmm0,%xmm4,%xmm4
	addl	0(%rsp),%ecx
	xorl	%eax,%esi
	movl	%edx,%edi
	shldl	$5,%edx,%edx
	vpxor	%xmm5,%xmm4,%xmm4
	addl	%esi,%ecx
	xorl	%eax,%edi
	vpaddd	%xmm3,%xmm11,%xmm9
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	vpxor	%xmm8,%xmm4,%xmm4
	addl	4(%rsp),%ebx
	xorl	%ebp,%edi
	movl	%ecx,%esi
	shldl	$5,%ecx,%ecx
	vpsrld	$30,%xmm4,%xmm8
	vmovdqa	%xmm9,48(%rsp)
	addl	%edi,%ebx
	xorl	%ebp,%esi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	vpslld	$2,%xmm4,%xmm4
	addl	8(%rsp),%eax
	xorl	%edx,%esi
	movl	%ebx,%edi
	shldl	$5,%ebx,%ebx
	addl	%esi,%eax
	xorl	%edx,%edi
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	vpor	%xmm8,%xmm4,%xmm4
	addl	12(%rsp),%ebp
	xorl	%ecx,%edi
	movl	%eax,%esi
	shldl	$5,%eax,%eax
	addl	%edi,%ebp
	xorl	%ecx,%esi
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	vpalignr	$8,%xmm3,%xmm4,%xmm8
	vpxor	%xmm1,%xmm5,%xmm5
	addl	16(%rsp),%edx
	xorl	%ebx,%esi
	movl	%ebp,%edi
	shldl	$5,%ebp,%ebp
	vpxor	%xmm6,%xmm5,%xmm5
	addl	%esi,%edx
	xorl	%ebx,%edi
	vpaddd	%xmm4,%xmm11,%xmm9
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	vpxor	%xmm8,%xmm5,%xmm5
	addl	20(%rsp),%ecx
	xorl	%eax,%edi
	movl	%edx,%esi
	shldl	$5,%edx,%edx
	vpsrld	$30,%xmm5,%xmm8
	vmovdqa	%xmm9,0(%rsp)
	addl	%edi,%ecx
	xorl	%eax,%esi
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	vpslld	$2,%xmm5,%xmm5
	addl	24(%rsp),%ebx
	xorl	%ebp,%esi
	movl	%ecx,%edi
	shldl	$5,%ecx,%ecx
	addl	%esi,%ebx
	xorl	%ebp,%edi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	vpor	%xmm8,%xmm5,%xmm5
	addl	28(%rsp),%eax
	shrdl	$7,%ecx,%ecx
	movl	%ebx,%esi
	xorl	%edx,%edi
	shldl	$5,%ebx,%ebx
	addl	%edi,%eax
	xorl	%ecx,%esi
	xorl	%edx,%ecx
	addl	%ebx,%eax
	vpalignr	$8,%xmm4,%xmm5,%xmm8
	vpxor	%xmm2,%xmm6,%xmm6
	addl	32(%rsp),%ebp
	andl	%ecx,%esi
	xorl	%edx,%ecx
	shrdl	$7,%ebx,%ebx
	vpxor	%xmm7,%xmm6,%xmm6
	movl	%eax,%edi
	xorl	%ecx,%esi
	vpaddd	%xmm5,%xmm11,%xmm9
	shldl	$5,%eax,%eax
	addl	%esi,%ebp
	vpxor	%xmm8,%xmm6,%xmm6
	xorl	%ebx,%edi
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	addl	36(%rsp),%edx
	vpsrld	$30,%xmm6,%xmm8
	vmovdqa	%xmm9,16(%rsp)
	andl	%ebx,%edi
	xorl	%ecx,%ebx
	shrdl	$7,%eax,%eax
	movl	%ebp,%esi
	vpslld	$2,%xmm6,%xmm6
	xorl	%ebx,%edi
	shldl	$5,%ebp,%ebp
	addl	%edi,%edx
	xorl	%eax,%esi
	xorl	%ebx,%eax
	addl	%ebp,%edx
	addl	40(%rsp),%ecx
	andl	%eax,%esi
	vpor	%xmm8,%xmm6,%xmm6
	xorl	%ebx,%eax
	shrdl	$7,%ebp,%ebp
	movl	%edx,%edi
	xorl	%eax,%esi
	shldl	$5,%edx,%edx
	addl	%esi,%ecx
	xorl	%ebp,%edi
	xorl	%eax,%ebp
	addl	%edx,%ecx
	addl	44(%rsp),%ebx
	andl	%ebp,%edi
	xorl	%eax,%ebp
	shrdl	$7,%edx,%edx
	movl	%ecx,%esi
	xorl	%ebp,%edi
	shldl	$5,%ecx,%ecx
	addl	%edi,%ebx
	xorl	%edx,%esi
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	vpalignr	$8,%xmm5,%xmm6,%xmm8
	vpxor	%xmm3,%xmm7,%xmm7
	addl	48(%rsp),%eax
	andl	%edx,%esi
	xorl	%ebp,%edx
	shrdl	$7,%ecx,%ecx
	vpxor	%xmm0,%xmm7,%xmm7
	movl	%ebx,%edi
	xorl	%edx,%esi
	vpaddd	%xmm6,%xmm11,%xmm9
	vmovdqa	32(%r14),%xmm11
	shldl	$5,%ebx,%ebx
	addl	%esi,%eax
	vpxor	%xmm8,%xmm7,%xmm7
	xorl	%ecx,%edi
	xorl	%edx,%ecx
	addl	%ebx,%eax
	addl	52(%rsp),%ebp
	vpsrld	$30,%xmm7,%xmm8
	vmovdqa	%xmm9,32(%rsp)
	andl	%ecx,%edi
	xorl	%edx,%ecx
	shrdl	$7,%ebx,%ebx
	movl	%eax,%esi
	vpslld	$2,%xmm7,%xmm7
	xorl	%ecx,%edi
	shldl	$5,%eax,%eax
	addl	%edi,%ebp
	xorl	%ebx,%esi
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	addl	56(%rsp),%edx
	andl	%ebx,%esi
	vpor	%xmm8,%xmm7,%xmm7
	xorl	%ecx,%ebx
	shrdl	$7,%eax,%eax
	movl	%ebp,%edi
	xorl	%ebx,%esi
	shldl	$5,%ebp,%ebp
	addl	%esi,%edx
	xorl	%eax,%edi
	xorl	%ebx,%eax
	addl	%ebp,%edx
	addl	60(%rsp),%ecx
	andl	%eax,%edi
	xorl	%ebx,%eax
	shrdl	$7,%ebp,%ebp
	movl	%edx,%esi
	xorl	%eax,%edi
	shldl	$5,%edx,%edx
	addl	%edi,%ecx
	xorl	%ebp,%esi
	xorl	%eax,%ebp
	addl	%edx,%ecx
	vpalignr	$8,%xmm6,%xmm7,%xmm8
	vpxor	%xmm4,%xmm0,%xmm0
	addl	0(%rsp),%ebx
	andl	%ebp,%esi
	xorl	%eax,%ebp
	shrdl	$7,%edx,%edx
	vpxor	%xmm1,%xmm0,%xmm0
	movl	%ecx,%edi
	xorl	%ebp,%esi
	vpaddd	%xmm7,%xmm11,%xmm9
	shldl	$5,%ecx,%ecx
	addl	%esi,%ebx
	vpxor	%xmm8,%xmm0,%xmm0
	xorl	%edx,%edi
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	addl	4(%rsp),%eax
	vpsrld	$30,%xmm0,%xmm8
	vmovdqa	%xmm9,48(%rsp)
	andl	%edx,%edi
	xorl	%ebp,%edx
	shrdl	$7,%ecx,%ecx
	movl	%ebx,%esi
	vpslld	$2,%xmm0,%xmm0
	xorl	%edx,%edi
	shldl	$5,%ebx,%ebx
	addl	%edi,%eax
	xorl	%ecx,%esi
	xorl	%edx,%ecx
	addl	%ebx,%eax
	addl	8(%rsp),%ebp
	andl	%ecx,%esi
	vpor	%xmm8,%xmm0,%xmm0
	xorl	%edx,%ecx
	shrdl	$7,%ebx,%ebx
	movl	%eax,%edi
	xorl	%ecx,%esi
	shldl	$5,%eax,%eax
	addl	%esi,%ebp
	xorl	%ebx,%edi
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	addl	12(%rsp),%edx
	andl	%ebx,%edi
	xorl	%ecx,%ebx
	shrdl	$7,%eax,%eax
	movl	%ebp,%esi
	xorl	%ebx,%edi
	shldl	$5,%ebp,%ebp
	addl	%edi,%edx
	xorl	%eax,%esi
	xorl	%ebx,%eax
	addl	%ebp,%edx
	vpalignr	$8,%xmm7,%xmm0,%xmm8
	vpxor	%xmm5,%xmm1,%xmm1
	addl	16(%rsp),%ecx
	andl	%eax,%esi
	xorl	%ebx,%eax
	shrdl	$7,%ebp,%ebp
	vpxor	%xmm2,%xmm1,%xmm1
	movl	%edx,%edi
	xorl	%eax,%esi
	vpaddd	%xmm0,%xmm11,%xmm9
	shldl	$5,%edx,%edx
	addl	%esi,%ecx
	vpxor	%xmm8,%xmm1,%xmm1
	xorl	%ebp,%edi
	xorl	%eax,%ebp
	addl	%edx,%ecx
	addl	20(%rsp),%ebx
	vpsrld	$30,%xmm1,%xmm8
	vmovdqa	%xmm9,0(%rsp)
	andl	%ebp,%edi
	xorl	%eax,%ebp
	shrdl	$7,%edx,%edx
	movl	%ecx,%esi
	vpslld	$2,%xmm1,%xmm1
	xorl	%ebp,%edi
	shldl	$5,%ecx,%ecx
	addl	%edi,%ebx
	xorl	%edx,%esi
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	addl	24(%rsp),%eax
	andl	%edx,%esi
	vpor	%xmm8,%xmm1,%xmm1
	xorl	%ebp,%edx
	shrdl	$7,%ecx,%ecx
	movl	%ebx,%edi
	xorl	%edx,%esi
	shldl	$5,%ebx,%ebx
	addl	%esi,%eax
	xorl	%ecx,%edi
	xorl	%edx,%ecx
	addl	%ebx,%eax
	addl	28(%rsp),%ebp
	andl	%ecx,%edi
	xorl	%edx,%ecx
	shrdl	$7,%ebx,%ebx
	movl	%eax,%esi
	xorl	%ecx,%edi
	shldl	$5,%eax,%eax
	addl	%edi,%ebp
	xorl	%ebx,%esi
	xorl	%ecx,%ebx
	addl	%eax,%ebp
	vpalignr	$8,%xmm0,%xmm1,%xmm8
	vpxor	%xmm6,%xmm2,%xmm2
	addl	32(%rsp),%edx
	andl	%ebx,%esi
	xorl	%ecx,%ebx
	shrdl	$7,%eax,%eax
	vpxor	%xmm3,%xmm2,%xmm2
	movl	%ebp,%edi
	xorl	%ebx,%esi
	vpaddd	%xmm1,%xmm11,%xmm9
	shldl	$5,%ebp,%ebp
	addl	%esi,%edx
	vpxor	%xmm8,%xmm2,%xmm2
	xorl	%eax,%edi
	xorl	%ebx,%eax
	addl	%ebp,%edx
	addl	36(%rsp),%ecx
	vpsrld	$30,%xmm2,%xmm8
	vmovdqa	%xmm9,16(%rsp)
	andl	%eax,%edi
	xorl	%ebx,%eax
	shrdl	$7,%ebp,%ebp
	movl	%edx,%esi
	vpslld	$2,%xmm2,%xmm2
	xorl	%eax,%edi
	shldl	$5,%edx,%edx
	addl	%edi,%ecx
	xorl	%ebp,%esi
	xorl	%eax,%ebp
	addl	%edx,%ecx
	addl	40(%rsp),%ebx
	andl	%ebp,%esi
	vpor	%xmm8,%xmm2,%xmm2
	xorl	%eax,%ebp
	shrdl	$7,%edx,%edx
	movl	%ecx,%edi
	xorl	%ebp,%esi
	shldl	$5,%ecx,%ecx
	addl	%esi,%ebx
	xorl	%edx,%edi
	xorl	%ebp,%edx
	addl	%ecx,%ebx
	addl	44(%rsp),%eax
	andl	%edx,%edi
	xorl	%ebp,%edx
	shrdl	$7,%ecx,%ecx
	movl	%ebx,%esi
	xorl	%edx,%edi
	shldl	$5,%ebx,%ebx
	addl	%edi,%eax
	xorl	%edx,%esi
	addl	%ebx,%eax
	vpalignr	$8,%xmm1,%xmm2,%xmm8
	vpxor	%xmm7,%xmm3,%xmm3
	addl	48(%rsp),%ebp
	xorl	%ecx,%esi
	movl	%eax,%edi
	shldl	$5,%eax,%eax
	vpxor	%xmm4,%xmm3,%xmm3
	addl	%esi,%ebp
	xorl	%ecx,%edi
	vpaddd	%xmm2,%xmm11,%xmm9
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	vpxor	%xmm8,%xmm3,%xmm3
	addl	52(%rsp),%edx
	xorl	%ebx,%edi
	movl	%ebp,%esi
	shldl	$5,%ebp,%ebp
	vpsrld	$30,%xmm3,%xmm8
	vmovdqa	%xmm9,32(%rsp)
	addl	%edi,%edx
	xorl	%ebx,%esi
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	vpslld	$2,%xmm3,%xmm3
	addl	56(%rsp),%ecx
	xorl	%eax,%esi
	movl	%edx,%edi
	shldl	$5,%edx,%edx
	addl	%esi,%ecx
	xorl	%eax,%edi
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	vpor	%xmm8,%xmm3,%xmm3
	addl	60(%rsp),%ebx
	xorl	%ebp,%edi
	movl	%ecx,%esi
	shldl	$5,%ecx,%ecx
	addl	%edi,%ebx
	xorl	%ebp,%esi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	addl	0(%rsp),%eax
	vpaddd	%xmm3,%xmm11,%xmm9
	xorl	%edx,%esi
	movl	%ebx,%edi
	shldl	$5,%ebx,%ebx
	addl	%esi,%eax
	vmovdqa	%xmm9,48(%rsp)
	xorl	%edx,%edi
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	addl	4(%rsp),%ebp
	xorl	%ecx,%edi
	movl	%eax,%esi
	shldl	$5,%eax,%eax
	addl	%edi,%ebp
	xorl	%ecx,%esi
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	addl	8(%rsp),%edx
	xorl	%ebx,%esi
	movl	%ebp,%edi
	shldl	$5,%ebp,%ebp
	addl	%esi,%edx
	xorl	%ebx,%edi
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	addl	12(%rsp),%ecx
	xorl	%eax,%edi
	movl	%edx,%esi
	shldl	$5,%edx,%edx
	addl	%edi,%ecx
	xorl	%eax,%esi
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	cmpq	%r10,%r9
	je	.Ldone_avx
	vmovdqa	64(%r14),%xmm6
	vmovdqa	-64(%r14),%xmm11
	vmovdqu	0(%r9),%xmm0
	vmovdqu	16(%r9),%xmm1
	vmovdqu	32(%r9),%xmm2
	vmovdqu	48(%r9),%xmm3
	vpshufb	%xmm6,%xmm0,%xmm0
	addq	$64,%r9
	addl	16(%rsp),%ebx
	xorl	%ebp,%esi
	vpshufb	%xmm6,%xmm1,%xmm1
	movl	%ecx,%edi
	shldl	$5,%ecx,%ecx
	vpaddd	%xmm11,%xmm0,%xmm4
	addl	%esi,%ebx
	xorl	%ebp,%edi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	vmovdqa	%xmm4,0(%rsp)
	addl	20(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	shldl	$5,%ebx,%ebx
	addl	%edi,%eax
	xorl	%edx,%esi
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	addl	24(%rsp),%ebp
	xorl	%ecx,%esi
	movl	%eax,%edi
	shldl	$5,%eax,%eax
	addl	%esi,%ebp
	xorl	%ecx,%edi
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	addl	28(%rsp),%edx
	xorl	%ebx,%edi
	movl	%ebp,%esi
	shldl	$5,%ebp,%ebp
	addl	%edi,%edx
	xorl	%ebx,%esi
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	addl	32(%rsp),%ecx
	xorl	%eax,%esi
	vpshufb	%xmm6,%xmm2,%xmm2
	movl	%edx,%edi
	shldl	$5,%edx,%edx
	vpaddd	%xmm11,%xmm1,%xmm5
	addl	%esi,%ecx
	xorl	%eax,%edi
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	vmovdqa	%xmm5,16(%rsp)
	addl	36(%rsp),%ebx
	xorl	%ebp,%edi
	movl	%ecx,%esi
	shldl	$5,%ecx,%ecx
	addl	%edi,%ebx
	xorl	%ebp,%esi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	addl	40(%rsp),%eax
	xorl	%edx,%esi
	movl	%ebx,%edi
	shldl	$5,%ebx,%ebx
	addl	%esi,%eax
	xorl	%edx,%edi
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	addl	44(%rsp),%ebp
	xorl	%ecx,%edi
	movl	%eax,%esi
	shldl	$5,%eax,%eax
	addl	%edi,%ebp
	xorl	%ecx,%esi
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	addl	48(%rsp),%edx
	xorl	%ebx,%esi
	vpshufb	%xmm6,%xmm3,%xmm3
	movl	%ebp,%edi
	shldl	$5,%ebp,%ebp
	vpaddd	%xmm11,%xmm2,%xmm6
	addl	%esi,%edx
	xorl	%ebx,%edi
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	vmovdqa	%xmm6,32(%rsp)
	addl	52(%rsp),%ecx
	xorl	%eax,%edi
	movl	%edx,%esi
	shldl	$5,%edx,%edx
	addl	%edi,%ecx
	xorl	%eax,%esi
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	addl	56(%rsp),%ebx
	xorl	%ebp,%esi
	movl	%ecx,%edi
	shldl	$5,%ecx,%ecx
	addl	%esi,%ebx
	xorl	%ebp,%edi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	addl	60(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	shldl	$5,%ebx,%ebx
	addl	%edi,%eax
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	addl	0(%r8),%eax
	addl	4(%r8),%esi
	addl	8(%r8),%ecx
	addl	12(%r8),%edx
	movl	%eax,0(%r8)
	addl	16(%r8),%ebp
	movl	%esi,4(%r8)
	movl	%esi,%ebx
	movl	%ecx,8(%r8)
	movl	%ecx,%edi
	movl	%edx,12(%r8)
	xorl	%edx,%edi
	movl	%ebp,16(%r8)
	andl	%edi,%esi
	jmp	.Loop_avx

.align	16
.Ldone_avx:
	addl	16(%rsp),%ebx
	xorl	%ebp,%esi
	movl	%ecx,%edi
	shldl	$5,%ecx,%ecx
	addl	%esi,%ebx
	xorl	%ebp,%edi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	addl	20(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	shldl	$5,%ebx,%ebx
	addl	%edi,%eax
	xorl	%edx,%esi
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	addl	24(%rsp),%ebp
	xorl	%ecx,%esi
	movl	%eax,%edi
	shldl	$5,%eax,%eax
	addl	%esi,%ebp
	xorl	%ecx,%edi
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	addl	28(%rsp),%edx
	xorl	%ebx,%edi
	movl	%ebp,%esi
	shldl	$5,%ebp,%ebp
	addl	%edi,%edx
	xorl	%ebx,%esi
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	addl	32(%rsp),%ecx
	xorl	%eax,%esi
	movl	%edx,%edi
	shldl	$5,%edx,%edx
	addl	%esi,%ecx
	xorl	%eax,%edi
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	addl	36(%rsp),%ebx
	xorl	%ebp,%edi
	movl	%ecx,%esi
	shldl	$5,%ecx,%ecx
	addl	%edi,%ebx
	xorl	%ebp,%esi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	addl	40(%rsp),%eax
	xorl	%edx,%esi
	movl	%ebx,%edi
	shldl	$5,%ebx,%ebx
	addl	%esi,%eax
	xorl	%edx,%edi
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	addl	44(%rsp),%ebp
	xorl	%ecx,%edi
	movl	%eax,%esi
	shldl	$5,%eax,%eax
	addl	%edi,%ebp
	xorl	%ecx,%esi
	shrdl	$7,%ebx,%ebx
	addl	%eax,%ebp
	addl	48(%rsp),%edx
	xorl	%ebx,%esi
	movl	%ebp,%edi
	shldl	$5,%ebp,%ebp
	addl	%esi,%edx
	xorl	%ebx,%edi
	shrdl	$7,%eax,%eax
	addl	%ebp,%edx
	addl	52(%rsp),%ecx
	xorl	%eax,%edi
	movl	%edx,%esi
	shldl	$5,%edx,%edx
	addl	%edi,%ecx
	xorl	%eax,%esi
	shrdl	$7,%ebp,%ebp
	addl	%edx,%ecx
	addl	56(%rsp),%ebx
	xorl	%ebp,%esi
	movl	%ecx,%edi
	shldl	$5,%ecx,%ecx
	addl	%esi,%ebx
	xorl	%ebp,%edi
	shrdl	$7,%edx,%edx
	addl	%ecx,%ebx
	addl	60(%rsp),%eax
	xorl	%edx,%edi
	movl	%ebx,%esi
	shldl	$5,%ebx,%ebx
	addl	%edi,%eax
	shrdl	$7,%ecx,%ecx
	addl	%ebx,%eax
	vzeroupper

	addl	0(%r8),%eax
	addl	4(%r8),%esi
	addl	8(%r8),%ecx
	movl	%eax,0(%r8)
	addl	12(%r8),%edx
	movl	%esi,4(%r8)
	addl	16(%r8),%ebp
	movl	%ecx,8(%r8)
	movl	%edx,12(%r8)
	movl	%ebp,16(%r8)
	movq	-40(%r11),%r14
.cfi_restore	%r14
	movq	-32(%r11),%r13
.cfi_restore	%r13
	movq	-24(%r11),%r12
.cfi_restore	%r12
	movq	-16(%r11),%rbp
.cfi_restore	%rbp
	movq	-8(%r11),%rbx
.cfi_restore	%rbx
	leaq	(%r11),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue_avx:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha1_block_data_order_avx,.-sha1_block_data_order_avx
.type	sha1_block_data_order_avx2,@function
.align	16
sha1_block_data_order_avx2:
_avx2_shortcut:
.cfi_startproc	
	movq	%rsp,%r11
.cfi_def_cfa_register	%r11
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	vzeroupper
	movq	%rdi,%r8
	movq	%rsi,%r9
	movq	%rdx,%r10

	leaq	-640(%rsp),%rsp
	shlq	$6,%r10
	leaq	64(%r9),%r13
	andq	$-128,%rsp
	addq	%r9,%r10
	leaq	K_XX_XX+64(%rip),%r14

	movl	0(%r8),%eax
	cmpq	%r10,%r13
	cmovaeq	%r9,%r13
	movl	4(%r8),%ebp
	movl	8(%r8),%ecx
	movl	12(%r8),%edx
	movl	16(%r8),%esi
	vmovdqu	64(%r14),%ymm6

	vmovdqu	(%r9),%xmm0
	vmovdqu	16(%r9),%xmm1
	vmovdqu	32(%r9),%xmm2
	vmovdqu	48(%r9),%xmm3
	leaq	64(%r9),%r9
	vinserti128	$1,(%r13),%ymm0,%ymm0
	vinserti128	$1,16(%r13),%ymm1,%ymm1
	vpshufb	%ymm6,%ymm0,%ymm0
	vinserti128	$1,32(%r13),%ymm2,%ymm2
	vpshufb	%ymm6,%ymm1,%ymm1
	vinserti128	$1,48(%r13),%ymm3,%ymm3
	vpshufb	%ymm6,%ymm2,%ymm2
	vmovdqu	-64(%r14),%ymm11
	vpshufb	%ymm6,%ymm3,%ymm3

	vpaddd	%ymm11,%ymm0,%ymm4
	vpaddd	%ymm11,%ymm1,%ymm5
	vmovdqu	%ymm4,0(%rsp)
	vpaddd	%ymm11,%ymm2,%ymm6
	vmovdqu	%ymm5,32(%rsp)
	vpaddd	%ymm11,%ymm3,%ymm7
	vmovdqu	%ymm6,64(%rsp)
	vmovdqu	%ymm7,96(%rsp)
	vpalignr	$8,%ymm0,%ymm1,%ymm4
	vpsrldq	$4,%ymm3,%ymm8
	vpxor	%ymm0,%ymm4,%ymm4
	vpxor	%ymm2,%ymm8,%ymm8
	vpxor	%ymm8,%ymm4,%ymm4
	vpsrld	$31,%ymm4,%ymm8
	vpslldq	$12,%ymm4,%ymm10
	vpaddd	%ymm4,%ymm4,%ymm4
	vpsrld	$30,%ymm10,%ymm9
	vpor	%ymm8,%ymm4,%ymm4
	vpslld	$2,%ymm10,%ymm10
	vpxor	%ymm9,%ymm4,%ymm4
	vpxor	%ymm10,%ymm4,%ymm4
	vpaddd	%ymm11,%ymm4,%ymm9
	vmovdqu	%ymm9,128(%rsp)
	vpalignr	$8,%ymm1,%ymm2,%ymm5
	vpsrldq	$4,%ymm4,%ymm8
	vpxor	%ymm1,%ymm5,%ymm5
	vpxor	%ymm3,%ymm8,%ymm8
	vpxor	%ymm8,%ymm5,%ymm5
	vpsrld	$31,%ymm5,%ymm8
	vmovdqu	-32(%r14),%ymm11
	vpslldq	$12,%ymm5,%ymm10
	vpaddd	%ymm5,%ymm5,%ymm5
	vpsrld	$30,%ymm10,%ymm9
	vpor	%ymm8,%ymm5,%ymm5
	vpslld	$2,%ymm10,%ymm10
	vpxor	%ymm9,%ymm5,%ymm5
	vpxor	%ymm10,%ymm5,%ymm5
	vpaddd	%ymm11,%ymm5,%ymm9
	vmovdqu	%ymm9,160(%rsp)
	vpalignr	$8,%ymm2,%ymm3,%ymm6
	vpsrldq	$4,%ymm5,%ymm8
	vpxor	%ymm2,%ymm6,%ymm6
	vpxor	%ymm4,%ymm8,%ymm8
	vpxor	%ymm8,%ymm6,%ymm6
	vpsrld	$31,%ymm6,%ymm8
	vpslldq	$12,%ymm6,%ymm10
	vpaddd	%ymm6,%ymm6,%ymm6
	vpsrld	$30,%ymm10,%ymm9
	vpor	%ymm8,%ymm6,%ymm6
	vpslld	$2,%ymm10,%ymm10
	vpxor	%ymm9,%ymm6,%ymm6
	vpxor	%ymm10,%ymm6,%ymm6
	vpaddd	%ymm11,%ymm6,%ymm9
	vmovdqu	%ymm9,192(%rsp)
	vpalignr	$8,%ymm3,%ymm4,%ymm7
	vpsrldq	$4,%ymm6,%ymm8
	vpxor	%ymm3,%ymm7,%ymm7
	vpxor	%ymm5,%ymm8,%ymm8
	vpxor	%ymm8,%ymm7,%ymm7
	vpsrld	$31,%ymm7,%ymm8
	vpslldq	$12,%ymm7,%ymm10
	vpaddd	%ymm7,%ymm7,%ymm7
	vpsrld	$30,%ymm10,%ymm9
	vpor	%ymm8,%ymm7,%ymm7
	vpslld	$2,%ymm10,%ymm10
	vpxor	%ymm9,%ymm7,%ymm7
	vpxor	%ymm10,%ymm7,%ymm7
	vpaddd	%ymm11,%ymm7,%ymm9
	vmovdqu	%ymm9,224(%rsp)
	leaq	128(%rsp),%r13
	jmp	.Loop_avx2
.align	32
.Loop_avx2:
	rorxl	$2,%ebp,%ebx
	andnl	%edx,%ebp,%edi
	andl	%ecx,%ebp
	xorl	%edi,%ebp
	jmp	.Lalign32_1
.align	32
.Lalign32_1:
	vpalignr	$8,%ymm6,%ymm7,%ymm8
	vpxor	%ymm4,%ymm0,%ymm0
	addl	-128(%r13),%esi
	andnl	%ecx,%eax,%edi
	vpxor	%ymm1,%ymm0,%ymm0
	addl	%ebp,%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	vpxor	%ymm8,%ymm0,%ymm0
	andl	%ebx,%eax
	addl	%r12d,%esi
	xorl	%edi,%eax
	vpsrld	$30,%ymm0,%ymm8
	vpslld	$2,%ymm0,%ymm0
	addl	-124(%r13),%edx
	andnl	%ebx,%esi,%edi
	addl	%eax,%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	andl	%ebp,%esi
	vpor	%ymm8,%ymm0,%ymm0
	addl	%r12d,%edx
	xorl	%edi,%esi
	addl	-120(%r13),%ecx
	andnl	%ebp,%edx,%edi
	vpaddd	%ymm11,%ymm0,%ymm9
	addl	%esi,%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	andl	%eax,%edx
	vmovdqu	%ymm9,256(%rsp)
	addl	%r12d,%ecx
	xorl	%edi,%edx
	addl	-116(%r13),%ebx
	andnl	%eax,%ecx,%edi
	addl	%edx,%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	andl	%esi,%ecx
	addl	%r12d,%ebx
	xorl	%edi,%ecx
	addl	-96(%r13),%ebp
	andnl	%esi,%ebx,%edi
	addl	%ecx,%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	andl	%edx,%ebx
	addl	%r12d,%ebp
	xorl	%edi,%ebx
	vpalignr	$8,%ymm7,%ymm0,%ymm8
	vpxor	%ymm5,%ymm1,%ymm1
	addl	-92(%r13),%eax
	andnl	%edx,%ebp,%edi
	vpxor	%ymm2,%ymm1,%ymm1
	addl	%ebx,%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	vpxor	%ymm8,%ymm1,%ymm1
	andl	%ecx,%ebp
	addl	%r12d,%eax
	xorl	%edi,%ebp
	vpsrld	$30,%ymm1,%ymm8
	vpslld	$2,%ymm1,%ymm1
	addl	-88(%r13),%esi
	andnl	%ecx,%eax,%edi
	addl	%ebp,%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	andl	%ebx,%eax
	vpor	%ymm8,%ymm1,%ymm1
	addl	%r12d,%esi
	xorl	%edi,%eax
	addl	-84(%r13),%edx
	andnl	%ebx,%esi,%edi
	vpaddd	%ymm11,%ymm1,%ymm9
	addl	%eax,%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	andl	%ebp,%esi
	vmovdqu	%ymm9,288(%rsp)
	addl	%r12d,%edx
	xorl	%edi,%esi
	addl	-64(%r13),%ecx
	andnl	%ebp,%edx,%edi
	addl	%esi,%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	andl	%eax,%edx
	addl	%r12d,%ecx
	xorl	%edi,%edx
	addl	-60(%r13),%ebx
	andnl	%eax,%ecx,%edi
	addl	%edx,%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	andl	%esi,%ecx
	addl	%r12d,%ebx
	xorl	%edi,%ecx
	vpalignr	$8,%ymm0,%ymm1,%ymm8
	vpxor	%ymm6,%ymm2,%ymm2
	addl	-56(%r13),%ebp
	andnl	%esi,%ebx,%edi
	vpxor	%ymm3,%ymm2,%ymm2
	vmovdqu	0(%r14),%ymm11
	addl	%ecx,%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	vpxor	%ymm8,%ymm2,%ymm2
	andl	%edx,%ebx
	addl	%r12d,%ebp
	xorl	%edi,%ebx
	vpsrld	$30,%ymm2,%ymm8
	vpslld	$2,%ymm2,%ymm2
	addl	-52(%r13),%eax
	andnl	%edx,%ebp,%edi
	addl	%ebx,%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	andl	%ecx,%ebp
	vpor	%ymm8,%ymm2,%ymm2
	addl	%r12d,%eax
	xorl	%edi,%ebp
	addl	-32(%r13),%esi
	andnl	%ecx,%eax,%edi
	vpaddd	%ymm11,%ymm2,%ymm9
	addl	%ebp,%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	andl	%ebx,%eax
	vmovdqu	%ymm9,320(%rsp)
	addl	%r12d,%esi
	xorl	%edi,%eax
	addl	-28(%r13),%edx
	andnl	%ebx,%esi,%edi
	addl	%eax,%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	andl	%ebp,%esi
	addl	%r12d,%edx
	xorl	%edi,%esi
	addl	-24(%r13),%ecx
	andnl	%ebp,%edx,%edi
	addl	%esi,%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	andl	%eax,%edx
	addl	%r12d,%ecx
	xorl	%edi,%edx
	vpalignr	$8,%ymm1,%ymm2,%ymm8
	vpxor	%ymm7,%ymm3,%ymm3
	addl	-20(%r13),%ebx
	andnl	%eax,%ecx,%edi
	vpxor	%ymm4,%ymm3,%ymm3
	addl	%edx,%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	vpxor	%ymm8,%ymm3,%ymm3
	andl	%esi,%ecx
	addl	%r12d,%ebx
	xorl	%edi,%ecx
	vpsrld	$30,%ymm3,%ymm8
	vpslld	$2,%ymm3,%ymm3
	addl	0(%r13),%ebp
	andnl	%esi,%ebx,%edi
	addl	%ecx,%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	andl	%edx,%ebx
	vpor	%ymm8,%ymm3,%ymm3
	addl	%r12d,%ebp
	xorl	%edi,%ebx
	addl	4(%r13),%eax
	andnl	%edx,%ebp,%edi
	vpaddd	%ymm11,%ymm3,%ymm9
	addl	%ebx,%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	andl	%ecx,%ebp
	vmovdqu	%ymm9,352(%rsp)
	addl	%r12d,%eax
	xorl	%edi,%ebp
	addl	8(%r13),%esi
	andnl	%ecx,%eax,%edi
	addl	%ebp,%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	andl	%ebx,%eax
	addl	%r12d,%esi
	xorl	%edi,%eax
	addl	12(%r13),%edx
	leal	(%rdx,%rax,1),%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	xorl	%ebp,%esi
	addl	%r12d,%edx
	xorl	%ebx,%esi
	vpalignr	$8,%ymm2,%ymm3,%ymm8
	vpxor	%ymm0,%ymm4,%ymm4
	addl	32(%r13),%ecx
	leal	(%rcx,%rsi,1),%ecx
	vpxor	%ymm5,%ymm4,%ymm4
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	xorl	%eax,%edx
	vpxor	%ymm8,%ymm4,%ymm4
	addl	%r12d,%ecx
	xorl	%ebp,%edx
	addl	36(%r13),%ebx
	vpsrld	$30,%ymm4,%ymm8
	vpslld	$2,%ymm4,%ymm4
	leal	(%rbx,%rdx,1),%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	xorl	%esi,%ecx
	addl	%r12d,%ebx
	xorl	%eax,%ecx
	vpor	%ymm8,%ymm4,%ymm4
	addl	40(%r13),%ebp
	leal	(%rcx,%rbp,1),%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	vpaddd	%ymm11,%ymm4,%ymm9
	xorl	%edx,%ebx
	addl	%r12d,%ebp
	xorl	%esi,%ebx
	addl	44(%r13),%eax
	vmovdqu	%ymm9,384(%rsp)
	leal	(%rax,%rbx,1),%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	xorl	%ecx,%ebp
	addl	%r12d,%eax
	xorl	%edx,%ebp
	addl	64(%r13),%esi
	leal	(%rsi,%rbp,1),%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	xorl	%ebx,%eax
	addl	%r12d,%esi
	xorl	%ecx,%eax
	vpalignr	$8,%ymm3,%ymm4,%ymm8
	vpxor	%ymm1,%ymm5,%ymm5
	addl	68(%r13),%edx
	leal	(%rdx,%rax,1),%edx
	vpxor	%ymm6,%ymm5,%ymm5
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	xorl	%ebp,%esi
	vpxor	%ymm8,%ymm5,%ymm5
	addl	%r12d,%edx
	xorl	%ebx,%esi
	addl	72(%r13),%ecx
	vpsrld	$30,%ymm5,%ymm8
	vpslld	$2,%ymm5,%ymm5
	leal	(%rcx,%rsi,1),%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	xorl	%eax,%edx
	addl	%r12d,%ecx
	xorl	%ebp,%edx
	vpor	%ymm8,%ymm5,%ymm5
	addl	76(%r13),%ebx
	leal	(%rbx,%rdx,1),%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	vpaddd	%ymm11,%ymm5,%ymm9
	xorl	%esi,%ecx
	addl	%r12d,%ebx
	xorl	%eax,%ecx
	addl	96(%r13),%ebp
	vmovdqu	%ymm9,416(%rsp)
	leal	(%rcx,%rbp,1),%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	xorl	%edx,%ebx
	addl	%r12d,%ebp
	xorl	%esi,%ebx
	addl	100(%r13),%eax
	leal	(%rax,%rbx,1),%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	xorl	%ecx,%ebp
	addl	%r12d,%eax
	xorl	%edx,%ebp
	vpalignr	$8,%ymm4,%ymm5,%ymm8
	vpxor	%ymm2,%ymm6,%ymm6
	addl	104(%r13),%esi
	leal	(%rsi,%rbp,1),%esi
	vpxor	%ymm7,%ymm6,%ymm6
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	xorl	%ebx,%eax
	vpxor	%ymm8,%ymm6,%ymm6
	addl	%r12d,%esi
	xorl	%ecx,%eax
	addl	108(%r13),%edx
	leaq	256(%r13),%r13
	vpsrld	$30,%ymm6,%ymm8
	vpslld	$2,%ymm6,%ymm6
	leal	(%rdx,%rax,1),%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	xorl	%ebp,%esi
	addl	%r12d,%edx
	xorl	%ebx,%esi
	vpor	%ymm8,%ymm6,%ymm6
	addl	-128(%r13),%ecx
	leal	(%rcx,%rsi,1),%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	vpaddd	%ymm11,%ymm6,%ymm9
	xorl	%eax,%edx
	addl	%r12d,%ecx
	xorl	%ebp,%edx
	addl	-124(%r13),%ebx
	vmovdqu	%ymm9,448(%rsp)
	leal	(%rbx,%rdx,1),%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	xorl	%esi,%ecx
	addl	%r12d,%ebx
	xorl	%eax,%ecx
	addl	-120(%r13),%ebp
	leal	(%rcx,%rbp,1),%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	xorl	%edx,%ebx
	addl	%r12d,%ebp
	xorl	%esi,%ebx
	vpalignr	$8,%ymm5,%ymm6,%ymm8
	vpxor	%ymm3,%ymm7,%ymm7
	addl	-116(%r13),%eax
	leal	(%rax,%rbx,1),%eax
	vpxor	%ymm0,%ymm7,%ymm7
	vmovdqu	32(%r14),%ymm11
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	xorl	%ecx,%ebp
	vpxor	%ymm8,%ymm7,%ymm7
	addl	%r12d,%eax
	xorl	%edx,%ebp
	addl	-96(%r13),%esi
	vpsrld	$30,%ymm7,%ymm8
	vpslld	$2,%ymm7,%ymm7
	leal	(%rsi,%rbp,1),%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	xorl	%ebx,%eax
	addl	%r12d,%esi
	xorl	%ecx,%eax
	vpor	%ymm8,%ymm7,%ymm7
	addl	-92(%r13),%edx
	leal	(%rdx,%rax,1),%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	vpaddd	%ymm11,%ymm7,%ymm9
	xorl	%ebp,%esi
	addl	%r12d,%edx
	xorl	%ebx,%esi
	addl	-88(%r13),%ecx
	vmovdqu	%ymm9,480(%rsp)
	leal	(%rcx,%rsi,1),%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	xorl	%eax,%edx
	addl	%r12d,%ecx
	xorl	%ebp,%edx
	addl	-84(%r13),%ebx
	movl	%esi,%edi
	xorl	%eax,%edi
	leal	(%rbx,%rdx,1),%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	xorl	%esi,%ecx
	addl	%r12d,%ebx
	andl	%edi,%ecx
	jmp	.Lalign32_2
.align	32
.Lalign32_2:
	vpalignr	$8,%ymm6,%ymm7,%ymm8
	vpxor	%ymm4,%ymm0,%ymm0
	addl	-64(%r13),%ebp
	xorl	%esi,%ecx
	vpxor	%ymm1,%ymm0,%ymm0
	movl	%edx,%edi
	xorl	%esi,%edi
	leal	(%rcx,%rbp,1),%ebp
	vpxor	%ymm8,%ymm0,%ymm0
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	xorl	%edx,%ebx
	vpsrld	$30,%ymm0,%ymm8
	vpslld	$2,%ymm0,%ymm0
	addl	%r12d,%ebp
	andl	%edi,%ebx
	addl	-60(%r13),%eax
	xorl	%edx,%ebx
	movl	%ecx,%edi
	xorl	%edx,%edi
	vpor	%ymm8,%ymm0,%ymm0
	leal	(%rax,%rbx,1),%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	xorl	%ecx,%ebp
	vpaddd	%ymm11,%ymm0,%ymm9
	addl	%r12d,%eax
	andl	%edi,%ebp
	addl	-56(%r13),%esi
	xorl	%ecx,%ebp
	vmovdqu	%ymm9,512(%rsp)
	movl	%ebx,%edi
	xorl	%ecx,%edi
	leal	(%rsi,%rbp,1),%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	xorl	%ebx,%eax
	addl	%r12d,%esi
	andl	%edi,%eax
	addl	-52(%r13),%edx
	xorl	%ebx,%eax
	movl	%ebp,%edi
	xorl	%ebx,%edi
	leal	(%rdx,%rax,1),%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	xorl	%ebp,%esi
	addl	%r12d,%edx
	andl	%edi,%esi
	addl	-32(%r13),%ecx
	xorl	%ebp,%esi
	movl	%eax,%edi
	xorl	%ebp,%edi
	leal	(%rcx,%rsi,1),%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	xorl	%eax,%edx
	addl	%r12d,%ecx
	andl	%edi,%edx
	vpalignr	$8,%ymm7,%ymm0,%ymm8
	vpxor	%ymm5,%ymm1,%ymm1
	addl	-28(%r13),%ebx
	xorl	%eax,%edx
	vpxor	%ymm2,%ymm1,%ymm1
	movl	%esi,%edi
	xorl	%eax,%edi
	leal	(%rbx,%rdx,1),%ebx
	vpxor	%ymm8,%ymm1,%ymm1
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	xorl	%esi,%ecx
	vpsrld	$30,%ymm1,%ymm8
	vpslld	$2,%ymm1,%ymm1
	addl	%r12d,%ebx
	andl	%edi,%ecx
	addl	-24(%r13),%ebp
	xorl	%esi,%ecx
	movl	%edx,%edi
	xorl	%esi,%edi
	vpor	%ymm8,%ymm1,%ymm1
	leal	(%rcx,%rbp,1),%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	xorl	%edx,%ebx
	vpaddd	%ymm11,%ymm1,%ymm9
	addl	%r12d,%ebp
	andl	%edi,%ebx
	addl	-20(%r13),%eax
	xorl	%edx,%ebx
	vmovdqu	%ymm9,544(%rsp)
	movl	%ecx,%edi
	xorl	%edx,%edi
	leal	(%rax,%rbx,1),%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	xorl	%ecx,%ebp
	addl	%r12d,%eax
	andl	%edi,%ebp
	addl	0(%r13),%esi
	xorl	%ecx,%ebp
	movl	%ebx,%edi
	xorl	%ecx,%edi
	leal	(%rsi,%rbp,1),%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	xorl	%ebx,%eax
	addl	%r12d,%esi
	andl	%edi,%eax
	addl	4(%r13),%edx
	xorl	%ebx,%eax
	movl	%ebp,%edi
	xorl	%ebx,%edi
	leal	(%rdx,%rax,1),%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	xorl	%ebp,%esi
	addl	%r12d,%edx
	andl	%edi,%esi
	vpalignr	$8,%ymm0,%ymm1,%ymm8
	vpxor	%ymm6,%ymm2,%ymm2
	addl	8(%r13),%ecx
	xorl	%ebp,%esi
	vpxor	%ymm3,%ymm2,%ymm2
	movl	%eax,%edi
	xorl	%ebp,%edi
	leal	(%rcx,%rsi,1),%ecx
	vpxor	%ymm8,%ymm2,%ymm2
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	xorl	%eax,%edx
	vpsrld	$30,%ymm2,%ymm8
	vpslld	$2,%ymm2,%ymm2
	addl	%r12d,%ecx
	andl	%edi,%edx
	addl	12(%r13),%ebx
	xorl	%eax,%edx
	movl	%esi,%edi
	xorl	%eax,%edi
	vpor	%ymm8,%ymm2,%ymm2
	leal	(%rbx,%rdx,1),%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	xorl	%esi,%ecx
	vpaddd	%ymm11,%ymm2,%ymm9
	addl	%r12d,%ebx
	andl	%edi,%ecx
	addl	32(%r13),%ebp
	xorl	%esi,%ecx
	vmovdqu	%ymm9,576(%rsp)
	movl	%edx,%edi
	xorl	%esi,%edi
	leal	(%rcx,%rbp,1),%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	xorl	%edx,%ebx
	addl	%r12d,%ebp
	andl	%edi,%ebx
	addl	36(%r13),%eax
	xorl	%edx,%ebx
	movl	%ecx,%edi
	xorl	%edx,%edi
	leal	(%rax,%rbx,1),%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	xorl	%ecx,%ebp
	addl	%r12d,%eax
	andl	%edi,%ebp
	addl	40(%r13),%esi
	xorl	%ecx,%ebp
	movl	%ebx,%edi
	xorl	%ecx,%edi
	leal	(%rsi,%rbp,1),%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	xorl	%ebx,%eax
	addl	%r12d,%esi
	andl	%edi,%eax
	vpalignr	$8,%ymm1,%ymm2,%ymm8
	vpxor	%ymm7,%ymm3,%ymm3
	addl	44(%r13),%edx
	xorl	%ebx,%eax
	vpxor	%ymm4,%ymm3,%ymm3
	movl	%ebp,%edi
	xorl	%ebx,%edi
	leal	(%rdx,%rax,1),%edx
	vpxor	%ymm8,%ymm3,%ymm3
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	xorl	%ebp,%esi
	vpsrld	$30,%ymm3,%ymm8
	vpslld	$2,%ymm3,%ymm3
	addl	%r12d,%edx
	andl	%edi,%esi
	addl	64(%r13),%ecx
	xorl	%ebp,%esi
	movl	%eax,%edi
	xorl	%ebp,%edi
	vpor	%ymm8,%ymm3,%ymm3
	leal	(%rcx,%rsi,1),%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	xorl	%eax,%edx
	vpaddd	%ymm11,%ymm3,%ymm9
	addl	%r12d,%ecx
	andl	%edi,%edx
	addl	68(%r13),%ebx
	xorl	%eax,%edx
	vmovdqu	%ymm9,608(%rsp)
	movl	%esi,%edi
	xorl	%eax,%edi
	leal	(%rbx,%rdx,1),%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	xorl	%esi,%ecx
	addl	%r12d,%ebx
	andl	%edi,%ecx
	addl	72(%r13),%ebp
	xorl	%esi,%ecx
	movl	%edx,%edi
	xorl	%esi,%edi
	leal	(%rcx,%rbp,1),%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	xorl	%edx,%ebx
	addl	%r12d,%ebp
	andl	%edi,%ebx
	addl	76(%r13),%eax
	xorl	%edx,%ebx
	leal	(%rax,%rbx,1),%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	xorl	%ecx,%ebp
	addl	%r12d,%eax
	xorl	%edx,%ebp
	addl	96(%r13),%esi
	leal	(%rsi,%rbp,1),%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	xorl	%ebx,%eax
	addl	%r12d,%esi
	xorl	%ecx,%eax
	addl	100(%r13),%edx
	leal	(%rdx,%rax,1),%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	xorl	%ebp,%esi
	addl	%r12d,%edx
	xorl	%ebx,%esi
	addl	104(%r13),%ecx
	leal	(%rcx,%rsi,1),%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	xorl	%eax,%edx
	addl	%r12d,%ecx
	xorl	%ebp,%edx
	addl	108(%r13),%ebx
	leaq	256(%r13),%r13
	leal	(%rbx,%rdx,1),%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	xorl	%esi,%ecx
	addl	%r12d,%ebx
	xorl	%eax,%ecx
	addl	-128(%r13),%ebp
	leal	(%rcx,%rbp,1),%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	xorl	%edx,%ebx
	addl	%r12d,%ebp
	xorl	%esi,%ebx
	addl	-124(%r13),%eax
	leal	(%rax,%rbx,1),%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	xorl	%ecx,%ebp
	addl	%r12d,%eax
	xorl	%edx,%ebp
	addl	-120(%r13),%esi
	leal	(%rsi,%rbp,1),%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	xorl	%ebx,%eax
	addl	%r12d,%esi
	xorl	%ecx,%eax
	addl	-116(%r13),%edx
	leal	(%rdx,%rax,1),%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	xorl	%ebp,%esi
	addl	%r12d,%edx
	xorl	%ebx,%esi
	addl	-96(%r13),%ecx
	leal	(%rcx,%rsi,1),%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	xorl	%eax,%edx
	addl	%r12d,%ecx
	xorl	%ebp,%edx
	addl	-92(%r13),%ebx
	leal	(%rbx,%rdx,1),%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	xorl	%esi,%ecx
	addl	%r12d,%ebx
	xorl	%eax,%ecx
	addl	-88(%r13),%ebp
	leal	(%rcx,%rbp,1),%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	xorl	%edx,%ebx
	addl	%r12d,%ebp
	xorl	%esi,%ebx
	addl	-84(%r13),%eax
	leal	(%rax,%rbx,1),%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	xorl	%ecx,%ebp
	addl	%r12d,%eax
	xorl	%edx,%ebp
	addl	-64(%r13),%esi
	leal	(%rsi,%rbp,1),%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	xorl	%ebx,%eax
	addl	%r12d,%esi
	xorl	%ecx,%eax
	addl	-60(%r13),%edx
	leal	(%rdx,%rax,1),%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	xorl	%ebp,%esi
	addl	%r12d,%edx
	xorl	%ebx,%esi
	addl	-56(%r13),%ecx
	leal	(%rcx,%rsi,1),%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	xorl	%eax,%edx
	addl	%r12d,%ecx
	xorl	%ebp,%edx
	addl	-52(%r13),%ebx
	leal	(%rbx,%rdx,1),%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	xorl	%esi,%ecx
	addl	%r12d,%ebx
	xorl	%eax,%ecx
	addl	-32(%r13),%ebp
	leal	(%rcx,%rbp,1),%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	xorl	%edx,%ebx
	addl	%r12d,%ebp
	xorl	%esi,%ebx
	addl	-28(%r13),%eax
	leal	(%rax,%rbx,1),%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	xorl	%ecx,%ebp
	addl	%r12d,%eax
	xorl	%edx,%ebp
	addl	-24(%r13),%esi
	leal	(%rsi,%rbp,1),%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	xorl	%ebx,%eax
	addl	%r12d,%esi
	xorl	%ecx,%eax
	addl	-20(%r13),%edx
	leal	(%rdx,%rax,1),%edx
	rorxl	$27,%esi,%r12d
	addl	%r12d,%edx
	leaq	128(%r9),%r13
	leaq	128(%r9),%rdi
	cmpq	%r10,%r13
	cmovaeq	%r9,%r13


	addl	0(%r8),%edx
	addl	4(%r8),%esi
	addl	8(%r8),%ebp
	movl	%edx,0(%r8)
	addl	12(%r8),%ebx
	movl	%esi,4(%r8)
	movl	%edx,%eax
	addl	16(%r8),%ecx
	movl	%ebp,%r12d
	movl	%ebp,8(%r8)
	movl	%ebx,%edx

	movl	%ebx,12(%r8)
	movl	%esi,%ebp
	movl	%ecx,16(%r8)

	movl	%ecx,%esi
	movl	%r12d,%ecx


	cmpq	%r10,%r9
	je	.Ldone_avx2
	vmovdqu	64(%r14),%ymm6
	cmpq	%r10,%rdi
	ja	.Last_avx2

	vmovdqu	-64(%rdi),%xmm0
	vmovdqu	-48(%rdi),%xmm1
	vmovdqu	-32(%rdi),%xmm2
	vmovdqu	-16(%rdi),%xmm3
	vinserti128	$1,0(%r13),%ymm0,%ymm0
	vinserti128	$1,16(%r13),%ymm1,%ymm1
	vinserti128	$1,32(%r13),%ymm2,%ymm2
	vinserti128	$1,48(%r13),%ymm3,%ymm3
	jmp	.Last_avx2

.align	32
.Last_avx2:
	leaq	128+16(%rsp),%r13
	rorxl	$2,%ebp,%ebx
	andnl	%edx,%ebp,%edi
	andl	%ecx,%ebp
	xorl	%edi,%ebp
	subq	$-128,%r9
	addl	-128(%r13),%esi
	andnl	%ecx,%eax,%edi
	addl	%ebp,%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	andl	%ebx,%eax
	addl	%r12d,%esi
	xorl	%edi,%eax
	addl	-124(%r13),%edx
	andnl	%ebx,%esi,%edi
	addl	%eax,%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	andl	%ebp,%esi
	addl	%r12d,%edx
	xorl	%edi,%esi
	addl	-120(%r13),%ecx
	andnl	%ebp,%edx,%edi
	addl	%esi,%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	andl	%eax,%edx
	addl	%r12d,%ecx
	xorl	%edi,%edx
	addl	-116(%r13),%ebx
	andnl	%eax,%ecx,%edi
	addl	%edx,%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	andl	%esi,%ecx
	addl	%r12d,%ebx
	xorl	%edi,%ecx
	addl	-96(%r13),%ebp
	andnl	%esi,%ebx,%edi
	addl	%ecx,%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	andl	%edx,%ebx
	addl	%r12d,%ebp
	xorl	%edi,%ebx
	addl	-92(%r13),%eax
	andnl	%edx,%ebp,%edi
	addl	%ebx,%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	andl	%ecx,%ebp
	addl	%r12d,%eax
	xorl	%edi,%ebp
	addl	-88(%r13),%esi
	andnl	%ecx,%eax,%edi
	addl	%ebp,%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	andl	%ebx,%eax
	addl	%r12d,%esi
	xorl	%edi,%eax
	addl	-84(%r13),%edx
	andnl	%ebx,%esi,%edi
	addl	%eax,%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	andl	%ebp,%esi
	addl	%r12d,%edx
	xorl	%edi,%esi
	addl	-64(%r13),%ecx
	andnl	%ebp,%edx,%edi
	addl	%esi,%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	andl	%eax,%edx
	addl	%r12d,%ecx
	xorl	%edi,%edx
	addl	-60(%r13),%ebx
	andnl	%eax,%ecx,%edi
	addl	%edx,%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	andl	%esi,%ecx
	addl	%r12d,%ebx
	xorl	%edi,%ecx
	addl	-56(%r13),%ebp
	andnl	%esi,%ebx,%edi
	addl	%ecx,%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	andl	%edx,%ebx
	addl	%r12d,%ebp
	xorl	%edi,%ebx
	addl	-52(%r13),%eax
	andnl	%edx,%ebp,%edi
	addl	%ebx,%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	andl	%ecx,%ebp
	addl	%r12d,%eax
	xorl	%edi,%ebp
	addl	-32(%r13),%esi
	andnl	%ecx,%eax,%edi
	addl	%ebp,%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	andl	%ebx,%eax
	addl	%r12d,%esi
	xorl	%edi,%eax
	addl	-28(%r13),%edx
	andnl	%ebx,%esi,%edi
	addl	%eax,%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	andl	%ebp,%esi
	addl	%r12d,%edx
	xorl	%edi,%esi
	addl	-24(%r13),%ecx
	andnl	%ebp,%edx,%edi
	addl	%esi,%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	andl	%eax,%edx
	addl	%r12d,%ecx
	xorl	%edi,%edx
	addl	-20(%r13),%ebx
	andnl	%eax,%ecx,%edi
	addl	%edx,%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	andl	%esi,%ecx
	addl	%r12d,%ebx
	xorl	%edi,%ecx
	addl	0(%r13),%ebp
	andnl	%esi,%ebx,%edi
	addl	%ecx,%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	andl	%edx,%ebx
	addl	%r12d,%ebp
	xorl	%edi,%ebx
	addl	4(%r13),%eax
	andnl	%edx,%ebp,%edi
	addl	%ebx,%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	andl	%ecx,%ebp
	addl	%r12d,%eax
	xorl	%edi,%ebp
	addl	8(%r13),%esi
	andnl	%ecx,%eax,%edi
	addl	%ebp,%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	andl	%ebx,%eax
	addl	%r12d,%esi
	xorl	%edi,%eax
	addl	12(%r13),%edx
	leal	(%rdx,%rax,1),%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	xorl	%ebp,%esi
	addl	%r12d,%edx
	xorl	%ebx,%esi
	addl	32(%r13),%ecx
	leal	(%rcx,%rsi,1),%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	xorl	%eax,%edx
	addl	%r12d,%ecx
	xorl	%ebp,%edx
	addl	36(%r13),%ebx
	leal	(%rbx,%rdx,1),%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	xorl	%esi,%ecx
	addl	%r12d,%ebx
	xorl	%eax,%ecx
	addl	40(%r13),%ebp
	leal	(%rcx,%rbp,1),%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	xorl	%edx,%ebx
	addl	%r12d,%ebp
	xorl	%esi,%ebx
	addl	44(%r13),%eax
	leal	(%rax,%rbx,1),%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	xorl	%ecx,%ebp
	addl	%r12d,%eax
	xorl	%edx,%ebp
	addl	64(%r13),%esi
	leal	(%rsi,%rbp,1),%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	xorl	%ebx,%eax
	addl	%r12d,%esi
	xorl	%ecx,%eax
	vmovdqu	-64(%r14),%ymm11
	vpshufb	%ymm6,%ymm0,%ymm0
	addl	68(%r13),%edx
	leal	(%rdx,%rax,1),%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	xorl	%ebp,%esi
	addl	%r12d,%edx
	xorl	%ebx,%esi
	addl	72(%r13),%ecx
	leal	(%rcx,%rsi,1),%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	xorl	%eax,%edx
	addl	%r12d,%ecx
	xorl	%ebp,%edx
	addl	76(%r13),%ebx
	leal	(%rbx,%rdx,1),%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	xorl	%esi,%ecx
	addl	%r12d,%ebx
	xorl	%eax,%ecx
	addl	96(%r13),%ebp
	leal	(%rcx,%rbp,1),%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	xorl	%edx,%ebx
	addl	%r12d,%ebp
	xorl	%esi,%ebx
	addl	100(%r13),%eax
	leal	(%rax,%rbx,1),%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	xorl	%ecx,%ebp
	addl	%r12d,%eax
	xorl	%edx,%ebp
	vpshufb	%ymm6,%ymm1,%ymm1
	vpaddd	%ymm11,%ymm0,%ymm8
	addl	104(%r13),%esi
	leal	(%rsi,%rbp,1),%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	xorl	%ebx,%eax
	addl	%r12d,%esi
	xorl	%ecx,%eax
	addl	108(%r13),%edx
	leaq	256(%r13),%r13
	leal	(%rdx,%rax,1),%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	xorl	%ebp,%esi
	addl	%r12d,%edx
	xorl	%ebx,%esi
	addl	-128(%r13),%ecx
	leal	(%rcx,%rsi,1),%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	xorl	%eax,%edx
	addl	%r12d,%ecx
	xorl	%ebp,%edx
	addl	-124(%r13),%ebx
	leal	(%rbx,%rdx,1),%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	xorl	%esi,%ecx
	addl	%r12d,%ebx
	xorl	%eax,%ecx
	addl	-120(%r13),%ebp
	leal	(%rcx,%rbp,1),%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	xorl	%edx,%ebx
	addl	%r12d,%ebp
	xorl	%esi,%ebx
	vmovdqu	%ymm8,0(%rsp)
	vpshufb	%ymm6,%ymm2,%ymm2
	vpaddd	%ymm11,%ymm1,%ymm9
	addl	-116(%r13),%eax
	leal	(%rax,%rbx,1),%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	xorl	%ecx,%ebp
	addl	%r12d,%eax
	xorl	%edx,%ebp
	addl	-96(%r13),%esi
	leal	(%rsi,%rbp,1),%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	xorl	%ebx,%eax
	addl	%r12d,%esi
	xorl	%ecx,%eax
	addl	-92(%r13),%edx
	leal	(%rdx,%rax,1),%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	xorl	%ebp,%esi
	addl	%r12d,%edx
	xorl	%ebx,%esi
	addl	-88(%r13),%ecx
	leal	(%rcx,%rsi,1),%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	xorl	%eax,%edx
	addl	%r12d,%ecx
	xorl	%ebp,%edx
	addl	-84(%r13),%ebx
	movl	%esi,%edi
	xorl	%eax,%edi
	leal	(%rbx,%rdx,1),%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	xorl	%esi,%ecx
	addl	%r12d,%ebx
	andl	%edi,%ecx
	vmovdqu	%ymm9,32(%rsp)
	vpshufb	%ymm6,%ymm3,%ymm3
	vpaddd	%ymm11,%ymm2,%ymm6
	addl	-64(%r13),%ebp
	xorl	%esi,%ecx
	movl	%edx,%edi
	xorl	%esi,%edi
	leal	(%rcx,%rbp,1),%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	xorl	%edx,%ebx
	addl	%r12d,%ebp
	andl	%edi,%ebx
	addl	-60(%r13),%eax
	xorl	%edx,%ebx
	movl	%ecx,%edi
	xorl	%edx,%edi
	leal	(%rax,%rbx,1),%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	xorl	%ecx,%ebp
	addl	%r12d,%eax
	andl	%edi,%ebp
	addl	-56(%r13),%esi
	xorl	%ecx,%ebp
	movl	%ebx,%edi
	xorl	%ecx,%edi
	leal	(%rsi,%rbp,1),%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	xorl	%ebx,%eax
	addl	%r12d,%esi
	andl	%edi,%eax
	addl	-52(%r13),%edx
	xorl	%ebx,%eax
	movl	%ebp,%edi
	xorl	%ebx,%edi
	leal	(%rdx,%rax,1),%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	xorl	%ebp,%esi
	addl	%r12d,%edx
	andl	%edi,%esi
	addl	-32(%r13),%ecx
	xorl	%ebp,%esi
	movl	%eax,%edi
	xorl	%ebp,%edi
	leal	(%rcx,%rsi,1),%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	xorl	%eax,%edx
	addl	%r12d,%ecx
	andl	%edi,%edx
	jmp	.Lalign32_3
.align	32
.Lalign32_3:
	vmovdqu	%ymm6,64(%rsp)
	vpaddd	%ymm11,%ymm3,%ymm7
	addl	-28(%r13),%ebx
	xorl	%eax,%edx
	movl	%esi,%edi
	xorl	%eax,%edi
	leal	(%rbx,%rdx,1),%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	xorl	%esi,%ecx
	addl	%r12d,%ebx
	andl	%edi,%ecx
	addl	-24(%r13),%ebp
	xorl	%esi,%ecx
	movl	%edx,%edi
	xorl	%esi,%edi
	leal	(%rcx,%rbp,1),%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	xorl	%edx,%ebx
	addl	%r12d,%ebp
	andl	%edi,%ebx
	addl	-20(%r13),%eax
	xorl	%edx,%ebx
	movl	%ecx,%edi
	xorl	%edx,%edi
	leal	(%rax,%rbx,1),%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	xorl	%ecx,%ebp
	addl	%r12d,%eax
	andl	%edi,%ebp
	addl	0(%r13),%esi
	xorl	%ecx,%ebp
	movl	%ebx,%edi
	xorl	%ecx,%edi
	leal	(%rsi,%rbp,1),%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	xorl	%ebx,%eax
	addl	%r12d,%esi
	andl	%edi,%eax
	addl	4(%r13),%edx
	xorl	%ebx,%eax
	movl	%ebp,%edi
	xorl	%ebx,%edi
	leal	(%rdx,%rax,1),%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	xorl	%ebp,%esi
	addl	%r12d,%edx
	andl	%edi,%esi
	vmovdqu	%ymm7,96(%rsp)
	addl	8(%r13),%ecx
	xorl	%ebp,%esi
	movl	%eax,%edi
	xorl	%ebp,%edi
	leal	(%rcx,%rsi,1),%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	xorl	%eax,%edx
	addl	%r12d,%ecx
	andl	%edi,%edx
	addl	12(%r13),%ebx
	xorl	%eax,%edx
	movl	%esi,%edi
	xorl	%eax,%edi
	leal	(%rbx,%rdx,1),%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	xorl	%esi,%ecx
	addl	%r12d,%ebx
	andl	%edi,%ecx
	addl	32(%r13),%ebp
	xorl	%esi,%ecx
	movl	%edx,%edi
	xorl	%esi,%edi
	leal	(%rcx,%rbp,1),%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	xorl	%edx,%ebx
	addl	%r12d,%ebp
	andl	%edi,%ebx
	addl	36(%r13),%eax
	xorl	%edx,%ebx
	movl	%ecx,%edi
	xorl	%edx,%edi
	leal	(%rax,%rbx,1),%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	xorl	%ecx,%ebp
	addl	%r12d,%eax
	andl	%edi,%ebp
	addl	40(%r13),%esi
	xorl	%ecx,%ebp
	movl	%ebx,%edi
	xorl	%ecx,%edi
	leal	(%rsi,%rbp,1),%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	xorl	%ebx,%eax
	addl	%r12d,%esi
	andl	%edi,%eax
	vpalignr	$8,%ymm0,%ymm1,%ymm4
	addl	44(%r13),%edx
	xorl	%ebx,%eax
	movl	%ebp,%edi
	xorl	%ebx,%edi
	vpsrldq	$4,%ymm3,%ymm8
	leal	(%rdx,%rax,1),%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	vpxor	%ymm0,%ymm4,%ymm4
	vpxor	%ymm2,%ymm8,%ymm8
	xorl	%ebp,%esi
	addl	%r12d,%edx
	vpxor	%ymm8,%ymm4,%ymm4
	andl	%edi,%esi
	addl	64(%r13),%ecx
	xorl	%ebp,%esi
	movl	%eax,%edi
	vpsrld	$31,%ymm4,%ymm8
	xorl	%ebp,%edi
	leal	(%rcx,%rsi,1),%ecx
	rorxl	$27,%edx,%r12d
	vpslldq	$12,%ymm4,%ymm10
	vpaddd	%ymm4,%ymm4,%ymm4
	rorxl	$2,%edx,%esi
	xorl	%eax,%edx
	vpsrld	$30,%ymm10,%ymm9
	vpor	%ymm8,%ymm4,%ymm4
	addl	%r12d,%ecx
	andl	%edi,%edx
	vpslld	$2,%ymm10,%ymm10
	vpxor	%ymm9,%ymm4,%ymm4
	addl	68(%r13),%ebx
	xorl	%eax,%edx
	vpxor	%ymm10,%ymm4,%ymm4
	movl	%esi,%edi
	xorl	%eax,%edi
	leal	(%rbx,%rdx,1),%ebx
	vpaddd	%ymm11,%ymm4,%ymm9
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	xorl	%esi,%ecx
	vmovdqu	%ymm9,128(%rsp)
	addl	%r12d,%ebx
	andl	%edi,%ecx
	addl	72(%r13),%ebp
	xorl	%esi,%ecx
	movl	%edx,%edi
	xorl	%esi,%edi
	leal	(%rcx,%rbp,1),%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	xorl	%edx,%ebx
	addl	%r12d,%ebp
	andl	%edi,%ebx
	addl	76(%r13),%eax
	xorl	%edx,%ebx
	leal	(%rax,%rbx,1),%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	xorl	%ecx,%ebp
	addl	%r12d,%eax
	xorl	%edx,%ebp
	vpalignr	$8,%ymm1,%ymm2,%ymm5
	addl	96(%r13),%esi
	leal	(%rsi,%rbp,1),%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	vpsrldq	$4,%ymm4,%ymm8
	xorl	%ebx,%eax
	addl	%r12d,%esi
	xorl	%ecx,%eax
	vpxor	%ymm1,%ymm5,%ymm5
	vpxor	%ymm3,%ymm8,%ymm8
	addl	100(%r13),%edx
	leal	(%rdx,%rax,1),%edx
	vpxor	%ymm8,%ymm5,%ymm5
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	xorl	%ebp,%esi
	addl	%r12d,%edx
	vpsrld	$31,%ymm5,%ymm8
	vmovdqu	-32(%r14),%ymm11
	xorl	%ebx,%esi
	addl	104(%r13),%ecx
	leal	(%rcx,%rsi,1),%ecx
	vpslldq	$12,%ymm5,%ymm10
	vpaddd	%ymm5,%ymm5,%ymm5
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	vpsrld	$30,%ymm10,%ymm9
	vpor	%ymm8,%ymm5,%ymm5
	xorl	%eax,%edx
	addl	%r12d,%ecx
	vpslld	$2,%ymm10,%ymm10
	vpxor	%ymm9,%ymm5,%ymm5
	xorl	%ebp,%edx
	addl	108(%r13),%ebx
	leaq	256(%r13),%r13
	vpxor	%ymm10,%ymm5,%ymm5
	leal	(%rbx,%rdx,1),%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	vpaddd	%ymm11,%ymm5,%ymm9
	xorl	%esi,%ecx
	addl	%r12d,%ebx
	xorl	%eax,%ecx
	vmovdqu	%ymm9,160(%rsp)
	addl	-128(%r13),%ebp
	leal	(%rcx,%rbp,1),%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	xorl	%edx,%ebx
	addl	%r12d,%ebp
	xorl	%esi,%ebx
	vpalignr	$8,%ymm2,%ymm3,%ymm6
	addl	-124(%r13),%eax
	leal	(%rax,%rbx,1),%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	vpsrldq	$4,%ymm5,%ymm8
	xorl	%ecx,%ebp
	addl	%r12d,%eax
	xorl	%edx,%ebp
	vpxor	%ymm2,%ymm6,%ymm6
	vpxor	%ymm4,%ymm8,%ymm8
	addl	-120(%r13),%esi
	leal	(%rsi,%rbp,1),%esi
	vpxor	%ymm8,%ymm6,%ymm6
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	xorl	%ebx,%eax
	addl	%r12d,%esi
	vpsrld	$31,%ymm6,%ymm8
	xorl	%ecx,%eax
	addl	-116(%r13),%edx
	leal	(%rdx,%rax,1),%edx
	vpslldq	$12,%ymm6,%ymm10
	vpaddd	%ymm6,%ymm6,%ymm6
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	vpsrld	$30,%ymm10,%ymm9
	vpor	%ymm8,%ymm6,%ymm6
	xorl	%ebp,%esi
	addl	%r12d,%edx
	vpslld	$2,%ymm10,%ymm10
	vpxor	%ymm9,%ymm6,%ymm6
	xorl	%ebx,%esi
	addl	-96(%r13),%ecx
	vpxor	%ymm10,%ymm6,%ymm6
	leal	(%rcx,%rsi,1),%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	vpaddd	%ymm11,%ymm6,%ymm9
	xorl	%eax,%edx
	addl	%r12d,%ecx
	xorl	%ebp,%edx
	vmovdqu	%ymm9,192(%rsp)
	addl	-92(%r13),%ebx
	leal	(%rbx,%rdx,1),%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	xorl	%esi,%ecx
	addl	%r12d,%ebx
	xorl	%eax,%ecx
	vpalignr	$8,%ymm3,%ymm4,%ymm7
	addl	-88(%r13),%ebp
	leal	(%rcx,%rbp,1),%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	vpsrldq	$4,%ymm6,%ymm8
	xorl	%edx,%ebx
	addl	%r12d,%ebp
	xorl	%esi,%ebx
	vpxor	%ymm3,%ymm7,%ymm7
	vpxor	%ymm5,%ymm8,%ymm8
	addl	-84(%r13),%eax
	leal	(%rax,%rbx,1),%eax
	vpxor	%ymm8,%ymm7,%ymm7
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	xorl	%ecx,%ebp
	addl	%r12d,%eax
	vpsrld	$31,%ymm7,%ymm8
	xorl	%edx,%ebp
	addl	-64(%r13),%esi
	leal	(%rsi,%rbp,1),%esi
	vpslldq	$12,%ymm7,%ymm10
	vpaddd	%ymm7,%ymm7,%ymm7
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	vpsrld	$30,%ymm10,%ymm9
	vpor	%ymm8,%ymm7,%ymm7
	xorl	%ebx,%eax
	addl	%r12d,%esi
	vpslld	$2,%ymm10,%ymm10
	vpxor	%ymm9,%ymm7,%ymm7
	xorl	%ecx,%eax
	addl	-60(%r13),%edx
	vpxor	%ymm10,%ymm7,%ymm7
	leal	(%rdx,%rax,1),%edx
	rorxl	$27,%esi,%r12d
	rorxl	$2,%esi,%eax
	vpaddd	%ymm11,%ymm7,%ymm9
	xorl	%ebp,%esi
	addl	%r12d,%edx
	xorl	%ebx,%esi
	vmovdqu	%ymm9,224(%rsp)
	addl	-56(%r13),%ecx
	leal	(%rcx,%rsi,1),%ecx
	rorxl	$27,%edx,%r12d
	rorxl	$2,%edx,%esi
	xorl	%eax,%edx
	addl	%r12d,%ecx
	xorl	%ebp,%edx
	addl	-52(%r13),%ebx
	leal	(%rbx,%rdx,1),%ebx
	rorxl	$27,%ecx,%r12d
	rorxl	$2,%ecx,%edx
	xorl	%esi,%ecx
	addl	%r12d,%ebx
	xorl	%eax,%ecx
	addl	-32(%r13),%ebp
	leal	(%rcx,%rbp,1),%ebp
	rorxl	$27,%ebx,%r12d
	rorxl	$2,%ebx,%ecx
	xorl	%edx,%ebx
	addl	%r12d,%ebp
	xorl	%esi,%ebx
	addl	-28(%r13),%eax
	leal	(%rax,%rbx,1),%eax
	rorxl	$27,%ebp,%r12d
	rorxl	$2,%ebp,%ebx
	xorl	%ecx,%ebp
	addl	%r12d,%eax
	xorl	%edx,%ebp
	addl	-24(%r13),%esi
	leal	(%rsi,%rbp,1),%esi
	rorxl	$27,%eax,%r12d
	rorxl	$2,%eax,%ebp
	xorl	%ebx,%eax
	addl	%r12d,%esi
	xorl	%ecx,%eax
	addl	-20(%r13),%edx
	leal	(%rdx,%rax,1),%edx
	rorxl	$27,%esi,%r12d
	addl	%r12d,%edx
	leaq	128(%rsp),%r13


	addl	0(%r8),%edx
	addl	4(%r8),%esi
	addl	8(%r8),%ebp
	movl	%edx,0(%r8)
	addl	12(%r8),%ebx
	movl	%esi,4(%r8)
	movl	%edx,%eax
	addl	16(%r8),%ecx
	movl	%ebp,%r12d
	movl	%ebp,8(%r8)
	movl	%ebx,%edx

	movl	%ebx,12(%r8)
	movl	%esi,%ebp
	movl	%ecx,16(%r8)

	movl	%ecx,%esi
	movl	%r12d,%ecx


	cmpq	%r10,%r9
	jbe	.Loop_avx2

.Ldone_avx2:
	vzeroupper
	movq	-40(%r11),%r14
.cfi_restore	%r14
	movq	-32(%r11),%r13
.cfi_restore	%r13
	movq	-24(%r11),%r12
.cfi_restore	%r12
	movq	-16(%r11),%rbp
.cfi_restore	%rbp
	movq	-8(%r11),%rbx
.cfi_restore	%rbx
	leaq	(%r11),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue_avx2:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha1_block_data_order_avx2,.-sha1_block_data_order_avx2
.align	64
K_XX_XX:
.long	0x5a827999,0x5a827999,0x5a827999,0x5a827999
.long	0x5a827999,0x5a827999,0x5a827999,0x5a827999
.long	0x6ed9eba1,0x6ed9eba1,0x6ed9eba1,0x6ed9eba1
.long	0x6ed9eba1,0x6ed9eba1,0x6ed9eba1,0x6ed9eba1
.long	0x8f1bbcdc,0x8f1bbcdc,0x8f1bbcdc,0x8f1bbcdc
.long	0x8f1bbcdc,0x8f1bbcdc,0x8f1bbcdc,0x8f1bbcdc
.long	0xca62c1d6,0xca62c1d6,0xca62c1d6,0xca62c1d6
.long	0xca62c1d6,0xca62c1d6,0xca62c1d6,0xca62c1d6
.long	0x00010203,0x04050607,0x08090a0b,0x0c0d0e0f
.long	0x00010203,0x04050607,0x08090a0b,0x0c0d0e0f
.byte	0xf,0xe,0xd,0xc,0xb,0xa,0x9,0x8,0x7,0x6,0x5,0x4,0x3,0x2,0x1,0x0
.byte	83,72,65,49,32,98,108,111,99,107,32,116,114,97,110,115,102,111,114,109,32,102,111,114,32,120,56,54,95,54,52,44,32,67,82,89,80,84,79,71,65,77,83,32,98,121,32,60,97,112,112,114,111,64,111,112,101,110,115,115,108,46,111,114,103,62,0
.align	64
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                                                                                                                                node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/crypto/sha/sha256-mb-x86_64.s   0000664 0000000 0000000 00000461442 14746647661 0031426 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	



.globl	sha256_multi_block
.type	sha256_multi_block,@function
.align	32
sha256_multi_block:
.cfi_startproc	
	movq	OPENSSL_ia32cap_P+4(%rip),%rcx
	btq	$61,%rcx
	jc	_shaext_shortcut
	testl	$268435456,%ecx
	jnz	_avx_shortcut
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	subq	$288,%rsp
	andq	$-256,%rsp
	movq	%rax,272(%rsp)
.cfi_escape	0x0f,0x06,0x77,0x90,0x02,0x06,0x23,0x08
.Lbody:
	leaq	K256+128(%rip),%rbp
	leaq	256(%rsp),%rbx
	leaq	128(%rdi),%rdi

.Loop_grande:
	movl	%edx,280(%rsp)
	xorl	%edx,%edx

	movq	0(%rsi),%r8

	movl	8(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,0(%rbx)
	cmovleq	%rbp,%r8

	movq	16(%rsi),%r9

	movl	24(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,4(%rbx)
	cmovleq	%rbp,%r9

	movq	32(%rsi),%r10

	movl	40(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,8(%rbx)
	cmovleq	%rbp,%r10

	movq	48(%rsi),%r11

	movl	56(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,12(%rbx)
	cmovleq	%rbp,%r11
	testl	%edx,%edx
	jz	.Ldone

	movdqu	0-128(%rdi),%xmm8
	leaq	128(%rsp),%rax
	movdqu	32-128(%rdi),%xmm9
	movdqu	64-128(%rdi),%xmm10
	movdqu	96-128(%rdi),%xmm11
	movdqu	128-128(%rdi),%xmm12
	movdqu	160-128(%rdi),%xmm13
	movdqu	192-128(%rdi),%xmm14
	movdqu	224-128(%rdi),%xmm15
	movdqu	.Lpbswap(%rip),%xmm6
	jmp	.Loop

.align	32
.Loop:
	movdqa	%xmm10,%xmm4
	pxor	%xmm9,%xmm4
	movd	0(%r8),%xmm5
	movd	0(%r9),%xmm0
	movd	0(%r10),%xmm1
	movd	0(%r11),%xmm2
	punpckldq	%xmm1,%xmm5
	punpckldq	%xmm2,%xmm0
	punpckldq	%xmm0,%xmm5
	movdqa	%xmm12,%xmm7
.byte	102,15,56,0,238
	movdqa	%xmm12,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm12,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,0-128(%rax)
	paddd	%xmm15,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	-128(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm12,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm12,%xmm3
	pslld	$26-21,%xmm2
	pandn	%xmm14,%xmm0
	pand	%xmm13,%xmm3
	pxor	%xmm1,%xmm7


	movdqa	%xmm8,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm8,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	movdqa	%xmm9,%xmm3
	movdqa	%xmm8,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm8,%xmm3


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm3,%xmm4
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm9,%xmm15
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm4,%xmm15
	paddd	%xmm5,%xmm11
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm15
	paddd	%xmm7,%xmm15
	movd	4(%r8),%xmm5
	movd	4(%r9),%xmm0
	movd	4(%r10),%xmm1
	movd	4(%r11),%xmm2
	punpckldq	%xmm1,%xmm5
	punpckldq	%xmm2,%xmm0
	punpckldq	%xmm0,%xmm5
	movdqa	%xmm11,%xmm7

	movdqa	%xmm11,%xmm2
.byte	102,15,56,0,238
	psrld	$6,%xmm7
	movdqa	%xmm11,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,16-128(%rax)
	paddd	%xmm14,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	-96(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm11,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm11,%xmm4
	pslld	$26-21,%xmm2
	pandn	%xmm13,%xmm0
	pand	%xmm12,%xmm4
	pxor	%xmm1,%xmm7


	movdqa	%xmm15,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm15,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm4,%xmm0
	movdqa	%xmm8,%xmm4
	movdqa	%xmm15,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm15,%xmm4


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm4,%xmm3
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm8,%xmm14
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm3,%xmm14
	paddd	%xmm5,%xmm10
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm14
	paddd	%xmm7,%xmm14
	movd	8(%r8),%xmm5
	movd	8(%r9),%xmm0
	movd	8(%r10),%xmm1
	movd	8(%r11),%xmm2
	punpckldq	%xmm1,%xmm5
	punpckldq	%xmm2,%xmm0
	punpckldq	%xmm0,%xmm5
	movdqa	%xmm10,%xmm7
.byte	102,15,56,0,238
	movdqa	%xmm10,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm10,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,32-128(%rax)
	paddd	%xmm13,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	-64(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm10,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm10,%xmm3
	pslld	$26-21,%xmm2
	pandn	%xmm12,%xmm0
	pand	%xmm11,%xmm3
	pxor	%xmm1,%xmm7


	movdqa	%xmm14,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm14,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	movdqa	%xmm15,%xmm3
	movdqa	%xmm14,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm14,%xmm3


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm3,%xmm4
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm15,%xmm13
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm4,%xmm13
	paddd	%xmm5,%xmm9
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm13
	paddd	%xmm7,%xmm13
	movd	12(%r8),%xmm5
	movd	12(%r9),%xmm0
	movd	12(%r10),%xmm1
	movd	12(%r11),%xmm2
	punpckldq	%xmm1,%xmm5
	punpckldq	%xmm2,%xmm0
	punpckldq	%xmm0,%xmm5
	movdqa	%xmm9,%xmm7

	movdqa	%xmm9,%xmm2
.byte	102,15,56,0,238
	psrld	$6,%xmm7
	movdqa	%xmm9,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,48-128(%rax)
	paddd	%xmm12,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	-32(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm9,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm9,%xmm4
	pslld	$26-21,%xmm2
	pandn	%xmm11,%xmm0
	pand	%xmm10,%xmm4
	pxor	%xmm1,%xmm7


	movdqa	%xmm13,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm13,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm4,%xmm0
	movdqa	%xmm14,%xmm4
	movdqa	%xmm13,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm13,%xmm4


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm4,%xmm3
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm14,%xmm12
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm3,%xmm12
	paddd	%xmm5,%xmm8
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm12
	paddd	%xmm7,%xmm12
	movd	16(%r8),%xmm5
	movd	16(%r9),%xmm0
	movd	16(%r10),%xmm1
	movd	16(%r11),%xmm2
	punpckldq	%xmm1,%xmm5
	punpckldq	%xmm2,%xmm0
	punpckldq	%xmm0,%xmm5
	movdqa	%xmm8,%xmm7
.byte	102,15,56,0,238
	movdqa	%xmm8,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm8,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,64-128(%rax)
	paddd	%xmm11,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	0(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm8,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm8,%xmm3
	pslld	$26-21,%xmm2
	pandn	%xmm10,%xmm0
	pand	%xmm9,%xmm3
	pxor	%xmm1,%xmm7


	movdqa	%xmm12,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm12,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	movdqa	%xmm13,%xmm3
	movdqa	%xmm12,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm12,%xmm3


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm3,%xmm4
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm13,%xmm11
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm4,%xmm11
	paddd	%xmm5,%xmm15
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm11
	paddd	%xmm7,%xmm11
	movd	20(%r8),%xmm5
	movd	20(%r9),%xmm0
	movd	20(%r10),%xmm1
	movd	20(%r11),%xmm2
	punpckldq	%xmm1,%xmm5
	punpckldq	%xmm2,%xmm0
	punpckldq	%xmm0,%xmm5
	movdqa	%xmm15,%xmm7

	movdqa	%xmm15,%xmm2
.byte	102,15,56,0,238
	psrld	$6,%xmm7
	movdqa	%xmm15,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,80-128(%rax)
	paddd	%xmm10,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	32(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm15,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm15,%xmm4
	pslld	$26-21,%xmm2
	pandn	%xmm9,%xmm0
	pand	%xmm8,%xmm4
	pxor	%xmm1,%xmm7


	movdqa	%xmm11,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm11,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm4,%xmm0
	movdqa	%xmm12,%xmm4
	movdqa	%xmm11,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm11,%xmm4


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm4,%xmm3
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm12,%xmm10
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm3,%xmm10
	paddd	%xmm5,%xmm14
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm10
	paddd	%xmm7,%xmm10
	movd	24(%r8),%xmm5
	movd	24(%r9),%xmm0
	movd	24(%r10),%xmm1
	movd	24(%r11),%xmm2
	punpckldq	%xmm1,%xmm5
	punpckldq	%xmm2,%xmm0
	punpckldq	%xmm0,%xmm5
	movdqa	%xmm14,%xmm7
.byte	102,15,56,0,238
	movdqa	%xmm14,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm14,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,96-128(%rax)
	paddd	%xmm9,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	64(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm14,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm14,%xmm3
	pslld	$26-21,%xmm2
	pandn	%xmm8,%xmm0
	pand	%xmm15,%xmm3
	pxor	%xmm1,%xmm7


	movdqa	%xmm10,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm10,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	movdqa	%xmm11,%xmm3
	movdqa	%xmm10,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm10,%xmm3


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm3,%xmm4
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm11,%xmm9
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm4,%xmm9
	paddd	%xmm5,%xmm13
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm9
	paddd	%xmm7,%xmm9
	movd	28(%r8),%xmm5
	movd	28(%r9),%xmm0
	movd	28(%r10),%xmm1
	movd	28(%r11),%xmm2
	punpckldq	%xmm1,%xmm5
	punpckldq	%xmm2,%xmm0
	punpckldq	%xmm0,%xmm5
	movdqa	%xmm13,%xmm7

	movdqa	%xmm13,%xmm2
.byte	102,15,56,0,238
	psrld	$6,%xmm7
	movdqa	%xmm13,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,112-128(%rax)
	paddd	%xmm8,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	96(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm13,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm13,%xmm4
	pslld	$26-21,%xmm2
	pandn	%xmm15,%xmm0
	pand	%xmm14,%xmm4
	pxor	%xmm1,%xmm7


	movdqa	%xmm9,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm9,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm4,%xmm0
	movdqa	%xmm10,%xmm4
	movdqa	%xmm9,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm9,%xmm4


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm4,%xmm3
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm10,%xmm8
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm3,%xmm8
	paddd	%xmm5,%xmm12
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm8
	paddd	%xmm7,%xmm8
	leaq	256(%rbp),%rbp
	movd	32(%r8),%xmm5
	movd	32(%r9),%xmm0
	movd	32(%r10),%xmm1
	movd	32(%r11),%xmm2
	punpckldq	%xmm1,%xmm5
	punpckldq	%xmm2,%xmm0
	punpckldq	%xmm0,%xmm5
	movdqa	%xmm12,%xmm7
.byte	102,15,56,0,238
	movdqa	%xmm12,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm12,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,128-128(%rax)
	paddd	%xmm15,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	-128(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm12,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm12,%xmm3
	pslld	$26-21,%xmm2
	pandn	%xmm14,%xmm0
	pand	%xmm13,%xmm3
	pxor	%xmm1,%xmm7


	movdqa	%xmm8,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm8,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	movdqa	%xmm9,%xmm3
	movdqa	%xmm8,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm8,%xmm3


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm3,%xmm4
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm9,%xmm15
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm4,%xmm15
	paddd	%xmm5,%xmm11
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm15
	paddd	%xmm7,%xmm15
	movd	36(%r8),%xmm5
	movd	36(%r9),%xmm0
	movd	36(%r10),%xmm1
	movd	36(%r11),%xmm2
	punpckldq	%xmm1,%xmm5
	punpckldq	%xmm2,%xmm0
	punpckldq	%xmm0,%xmm5
	movdqa	%xmm11,%xmm7

	movdqa	%xmm11,%xmm2
.byte	102,15,56,0,238
	psrld	$6,%xmm7
	movdqa	%xmm11,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,144-128(%rax)
	paddd	%xmm14,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	-96(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm11,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm11,%xmm4
	pslld	$26-21,%xmm2
	pandn	%xmm13,%xmm0
	pand	%xmm12,%xmm4
	pxor	%xmm1,%xmm7


	movdqa	%xmm15,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm15,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm4,%xmm0
	movdqa	%xmm8,%xmm4
	movdqa	%xmm15,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm15,%xmm4


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm4,%xmm3
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm8,%xmm14
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm3,%xmm14
	paddd	%xmm5,%xmm10
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm14
	paddd	%xmm7,%xmm14
	movd	40(%r8),%xmm5
	movd	40(%r9),%xmm0
	movd	40(%r10),%xmm1
	movd	40(%r11),%xmm2
	punpckldq	%xmm1,%xmm5
	punpckldq	%xmm2,%xmm0
	punpckldq	%xmm0,%xmm5
	movdqa	%xmm10,%xmm7
.byte	102,15,56,0,238
	movdqa	%xmm10,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm10,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,160-128(%rax)
	paddd	%xmm13,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	-64(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm10,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm10,%xmm3
	pslld	$26-21,%xmm2
	pandn	%xmm12,%xmm0
	pand	%xmm11,%xmm3
	pxor	%xmm1,%xmm7


	movdqa	%xmm14,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm14,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	movdqa	%xmm15,%xmm3
	movdqa	%xmm14,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm14,%xmm3


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm3,%xmm4
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm15,%xmm13
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm4,%xmm13
	paddd	%xmm5,%xmm9
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm13
	paddd	%xmm7,%xmm13
	movd	44(%r8),%xmm5
	movd	44(%r9),%xmm0
	movd	44(%r10),%xmm1
	movd	44(%r11),%xmm2
	punpckldq	%xmm1,%xmm5
	punpckldq	%xmm2,%xmm0
	punpckldq	%xmm0,%xmm5
	movdqa	%xmm9,%xmm7

	movdqa	%xmm9,%xmm2
.byte	102,15,56,0,238
	psrld	$6,%xmm7
	movdqa	%xmm9,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,176-128(%rax)
	paddd	%xmm12,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	-32(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm9,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm9,%xmm4
	pslld	$26-21,%xmm2
	pandn	%xmm11,%xmm0
	pand	%xmm10,%xmm4
	pxor	%xmm1,%xmm7


	movdqa	%xmm13,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm13,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm4,%xmm0
	movdqa	%xmm14,%xmm4
	movdqa	%xmm13,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm13,%xmm4


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm4,%xmm3
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm14,%xmm12
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm3,%xmm12
	paddd	%xmm5,%xmm8
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm12
	paddd	%xmm7,%xmm12
	movd	48(%r8),%xmm5
	movd	48(%r9),%xmm0
	movd	48(%r10),%xmm1
	movd	48(%r11),%xmm2
	punpckldq	%xmm1,%xmm5
	punpckldq	%xmm2,%xmm0
	punpckldq	%xmm0,%xmm5
	movdqa	%xmm8,%xmm7
.byte	102,15,56,0,238
	movdqa	%xmm8,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm8,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,192-128(%rax)
	paddd	%xmm11,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	0(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm8,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm8,%xmm3
	pslld	$26-21,%xmm2
	pandn	%xmm10,%xmm0
	pand	%xmm9,%xmm3
	pxor	%xmm1,%xmm7


	movdqa	%xmm12,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm12,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	movdqa	%xmm13,%xmm3
	movdqa	%xmm12,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm12,%xmm3


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm3,%xmm4
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm13,%xmm11
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm4,%xmm11
	paddd	%xmm5,%xmm15
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm11
	paddd	%xmm7,%xmm11
	movd	52(%r8),%xmm5
	movd	52(%r9),%xmm0
	movd	52(%r10),%xmm1
	movd	52(%r11),%xmm2
	punpckldq	%xmm1,%xmm5
	punpckldq	%xmm2,%xmm0
	punpckldq	%xmm0,%xmm5
	movdqa	%xmm15,%xmm7

	movdqa	%xmm15,%xmm2
.byte	102,15,56,0,238
	psrld	$6,%xmm7
	movdqa	%xmm15,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,208-128(%rax)
	paddd	%xmm10,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	32(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm15,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm15,%xmm4
	pslld	$26-21,%xmm2
	pandn	%xmm9,%xmm0
	pand	%xmm8,%xmm4
	pxor	%xmm1,%xmm7


	movdqa	%xmm11,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm11,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm4,%xmm0
	movdqa	%xmm12,%xmm4
	movdqa	%xmm11,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm11,%xmm4


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm4,%xmm3
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm12,%xmm10
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm3,%xmm10
	paddd	%xmm5,%xmm14
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm10
	paddd	%xmm7,%xmm10
	movd	56(%r8),%xmm5
	movd	56(%r9),%xmm0
	movd	56(%r10),%xmm1
	movd	56(%r11),%xmm2
	punpckldq	%xmm1,%xmm5
	punpckldq	%xmm2,%xmm0
	punpckldq	%xmm0,%xmm5
	movdqa	%xmm14,%xmm7
.byte	102,15,56,0,238
	movdqa	%xmm14,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm14,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,224-128(%rax)
	paddd	%xmm9,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	64(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm14,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm14,%xmm3
	pslld	$26-21,%xmm2
	pandn	%xmm8,%xmm0
	pand	%xmm15,%xmm3
	pxor	%xmm1,%xmm7


	movdqa	%xmm10,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm10,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	movdqa	%xmm11,%xmm3
	movdqa	%xmm10,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm10,%xmm3


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm3,%xmm4
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm11,%xmm9
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm4,%xmm9
	paddd	%xmm5,%xmm13
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm9
	paddd	%xmm7,%xmm9
	movd	60(%r8),%xmm5
	leaq	64(%r8),%r8
	movd	60(%r9),%xmm0
	leaq	64(%r9),%r9
	movd	60(%r10),%xmm1
	leaq	64(%r10),%r10
	movd	60(%r11),%xmm2
	leaq	64(%r11),%r11
	punpckldq	%xmm1,%xmm5
	punpckldq	%xmm2,%xmm0
	punpckldq	%xmm0,%xmm5
	movdqa	%xmm13,%xmm7

	movdqa	%xmm13,%xmm2
.byte	102,15,56,0,238
	psrld	$6,%xmm7
	movdqa	%xmm13,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,240-128(%rax)
	paddd	%xmm8,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	96(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm13,%xmm0
	prefetcht0	63(%r8)
	pxor	%xmm2,%xmm7
	movdqa	%xmm13,%xmm4
	pslld	$26-21,%xmm2
	pandn	%xmm15,%xmm0
	pand	%xmm14,%xmm4
	pxor	%xmm1,%xmm7

	prefetcht0	63(%r9)
	movdqa	%xmm9,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm9,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm4,%xmm0
	movdqa	%xmm10,%xmm4
	movdqa	%xmm9,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm9,%xmm4

	prefetcht0	63(%r10)
	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm4,%xmm3
	pxor	%xmm7,%xmm1

	prefetcht0	63(%r11)
	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm10,%xmm8
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm3,%xmm8
	paddd	%xmm5,%xmm12
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm8
	paddd	%xmm7,%xmm8
	leaq	256(%rbp),%rbp
	movdqu	0-128(%rax),%xmm5
	movl	$3,%ecx
	jmp	.Loop_16_xx
.align	32
.Loop_16_xx:
	movdqa	16-128(%rax),%xmm6
	paddd	144-128(%rax),%xmm5

	movdqa	%xmm6,%xmm7
	movdqa	%xmm6,%xmm1
	psrld	$3,%xmm7
	movdqa	%xmm6,%xmm2

	psrld	$7,%xmm1
	movdqa	224-128(%rax),%xmm0
	pslld	$14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$18-7,%xmm1
	movdqa	%xmm0,%xmm3
	pxor	%xmm2,%xmm7
	pslld	$25-14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$10,%xmm0
	movdqa	%xmm3,%xmm1

	psrld	$17,%xmm3
	pxor	%xmm2,%xmm7
	pslld	$13,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	psrld	$19-17,%xmm3
	pxor	%xmm1,%xmm0
	pslld	$15-13,%xmm1
	pxor	%xmm3,%xmm0
	pxor	%xmm1,%xmm0
	paddd	%xmm0,%xmm5
	movdqa	%xmm12,%xmm7

	movdqa	%xmm12,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm12,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,0-128(%rax)
	paddd	%xmm15,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	-128(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm12,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm12,%xmm3
	pslld	$26-21,%xmm2
	pandn	%xmm14,%xmm0
	pand	%xmm13,%xmm3
	pxor	%xmm1,%xmm7


	movdqa	%xmm8,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm8,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	movdqa	%xmm9,%xmm3
	movdqa	%xmm8,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm8,%xmm3


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm3,%xmm4
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm9,%xmm15
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm4,%xmm15
	paddd	%xmm5,%xmm11
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm15
	paddd	%xmm7,%xmm15
	movdqa	32-128(%rax),%xmm5
	paddd	160-128(%rax),%xmm6

	movdqa	%xmm5,%xmm7
	movdqa	%xmm5,%xmm1
	psrld	$3,%xmm7
	movdqa	%xmm5,%xmm2

	psrld	$7,%xmm1
	movdqa	240-128(%rax),%xmm0
	pslld	$14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$18-7,%xmm1
	movdqa	%xmm0,%xmm4
	pxor	%xmm2,%xmm7
	pslld	$25-14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$10,%xmm0
	movdqa	%xmm4,%xmm1

	psrld	$17,%xmm4
	pxor	%xmm2,%xmm7
	pslld	$13,%xmm1
	paddd	%xmm7,%xmm6
	pxor	%xmm4,%xmm0
	psrld	$19-17,%xmm4
	pxor	%xmm1,%xmm0
	pslld	$15-13,%xmm1
	pxor	%xmm4,%xmm0
	pxor	%xmm1,%xmm0
	paddd	%xmm0,%xmm6
	movdqa	%xmm11,%xmm7

	movdqa	%xmm11,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm11,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm6,16-128(%rax)
	paddd	%xmm14,%xmm6

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	-96(%rbp),%xmm6
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm11,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm11,%xmm4
	pslld	$26-21,%xmm2
	pandn	%xmm13,%xmm0
	pand	%xmm12,%xmm4
	pxor	%xmm1,%xmm7


	movdqa	%xmm15,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm15,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm6
	pxor	%xmm4,%xmm0
	movdqa	%xmm8,%xmm4
	movdqa	%xmm15,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm15,%xmm4


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm6
	pslld	$19-10,%xmm2
	pand	%xmm4,%xmm3
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm8,%xmm14
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm3,%xmm14
	paddd	%xmm6,%xmm10
	pxor	%xmm2,%xmm7

	paddd	%xmm6,%xmm14
	paddd	%xmm7,%xmm14
	movdqa	48-128(%rax),%xmm6
	paddd	176-128(%rax),%xmm5

	movdqa	%xmm6,%xmm7
	movdqa	%xmm6,%xmm1
	psrld	$3,%xmm7
	movdqa	%xmm6,%xmm2

	psrld	$7,%xmm1
	movdqa	0-128(%rax),%xmm0
	pslld	$14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$18-7,%xmm1
	movdqa	%xmm0,%xmm3
	pxor	%xmm2,%xmm7
	pslld	$25-14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$10,%xmm0
	movdqa	%xmm3,%xmm1

	psrld	$17,%xmm3
	pxor	%xmm2,%xmm7
	pslld	$13,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	psrld	$19-17,%xmm3
	pxor	%xmm1,%xmm0
	pslld	$15-13,%xmm1
	pxor	%xmm3,%xmm0
	pxor	%xmm1,%xmm0
	paddd	%xmm0,%xmm5
	movdqa	%xmm10,%xmm7

	movdqa	%xmm10,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm10,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,32-128(%rax)
	paddd	%xmm13,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	-64(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm10,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm10,%xmm3
	pslld	$26-21,%xmm2
	pandn	%xmm12,%xmm0
	pand	%xmm11,%xmm3
	pxor	%xmm1,%xmm7


	movdqa	%xmm14,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm14,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	movdqa	%xmm15,%xmm3
	movdqa	%xmm14,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm14,%xmm3


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm3,%xmm4
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm15,%xmm13
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm4,%xmm13
	paddd	%xmm5,%xmm9
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm13
	paddd	%xmm7,%xmm13
	movdqa	64-128(%rax),%xmm5
	paddd	192-128(%rax),%xmm6

	movdqa	%xmm5,%xmm7
	movdqa	%xmm5,%xmm1
	psrld	$3,%xmm7
	movdqa	%xmm5,%xmm2

	psrld	$7,%xmm1
	movdqa	16-128(%rax),%xmm0
	pslld	$14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$18-7,%xmm1
	movdqa	%xmm0,%xmm4
	pxor	%xmm2,%xmm7
	pslld	$25-14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$10,%xmm0
	movdqa	%xmm4,%xmm1

	psrld	$17,%xmm4
	pxor	%xmm2,%xmm7
	pslld	$13,%xmm1
	paddd	%xmm7,%xmm6
	pxor	%xmm4,%xmm0
	psrld	$19-17,%xmm4
	pxor	%xmm1,%xmm0
	pslld	$15-13,%xmm1
	pxor	%xmm4,%xmm0
	pxor	%xmm1,%xmm0
	paddd	%xmm0,%xmm6
	movdqa	%xmm9,%xmm7

	movdqa	%xmm9,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm9,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm6,48-128(%rax)
	paddd	%xmm12,%xmm6

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	-32(%rbp),%xmm6
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm9,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm9,%xmm4
	pslld	$26-21,%xmm2
	pandn	%xmm11,%xmm0
	pand	%xmm10,%xmm4
	pxor	%xmm1,%xmm7


	movdqa	%xmm13,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm13,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm6
	pxor	%xmm4,%xmm0
	movdqa	%xmm14,%xmm4
	movdqa	%xmm13,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm13,%xmm4


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm6
	pslld	$19-10,%xmm2
	pand	%xmm4,%xmm3
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm14,%xmm12
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm3,%xmm12
	paddd	%xmm6,%xmm8
	pxor	%xmm2,%xmm7

	paddd	%xmm6,%xmm12
	paddd	%xmm7,%xmm12
	movdqa	80-128(%rax),%xmm6
	paddd	208-128(%rax),%xmm5

	movdqa	%xmm6,%xmm7
	movdqa	%xmm6,%xmm1
	psrld	$3,%xmm7
	movdqa	%xmm6,%xmm2

	psrld	$7,%xmm1
	movdqa	32-128(%rax),%xmm0
	pslld	$14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$18-7,%xmm1
	movdqa	%xmm0,%xmm3
	pxor	%xmm2,%xmm7
	pslld	$25-14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$10,%xmm0
	movdqa	%xmm3,%xmm1

	psrld	$17,%xmm3
	pxor	%xmm2,%xmm7
	pslld	$13,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	psrld	$19-17,%xmm3
	pxor	%xmm1,%xmm0
	pslld	$15-13,%xmm1
	pxor	%xmm3,%xmm0
	pxor	%xmm1,%xmm0
	paddd	%xmm0,%xmm5
	movdqa	%xmm8,%xmm7

	movdqa	%xmm8,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm8,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,64-128(%rax)
	paddd	%xmm11,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	0(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm8,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm8,%xmm3
	pslld	$26-21,%xmm2
	pandn	%xmm10,%xmm0
	pand	%xmm9,%xmm3
	pxor	%xmm1,%xmm7


	movdqa	%xmm12,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm12,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	movdqa	%xmm13,%xmm3
	movdqa	%xmm12,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm12,%xmm3


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm3,%xmm4
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm13,%xmm11
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm4,%xmm11
	paddd	%xmm5,%xmm15
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm11
	paddd	%xmm7,%xmm11
	movdqa	96-128(%rax),%xmm5
	paddd	224-128(%rax),%xmm6

	movdqa	%xmm5,%xmm7
	movdqa	%xmm5,%xmm1
	psrld	$3,%xmm7
	movdqa	%xmm5,%xmm2

	psrld	$7,%xmm1
	movdqa	48-128(%rax),%xmm0
	pslld	$14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$18-7,%xmm1
	movdqa	%xmm0,%xmm4
	pxor	%xmm2,%xmm7
	pslld	$25-14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$10,%xmm0
	movdqa	%xmm4,%xmm1

	psrld	$17,%xmm4
	pxor	%xmm2,%xmm7
	pslld	$13,%xmm1
	paddd	%xmm7,%xmm6
	pxor	%xmm4,%xmm0
	psrld	$19-17,%xmm4
	pxor	%xmm1,%xmm0
	pslld	$15-13,%xmm1
	pxor	%xmm4,%xmm0
	pxor	%xmm1,%xmm0
	paddd	%xmm0,%xmm6
	movdqa	%xmm15,%xmm7

	movdqa	%xmm15,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm15,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm6,80-128(%rax)
	paddd	%xmm10,%xmm6

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	32(%rbp),%xmm6
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm15,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm15,%xmm4
	pslld	$26-21,%xmm2
	pandn	%xmm9,%xmm0
	pand	%xmm8,%xmm4
	pxor	%xmm1,%xmm7


	movdqa	%xmm11,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm11,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm6
	pxor	%xmm4,%xmm0
	movdqa	%xmm12,%xmm4
	movdqa	%xmm11,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm11,%xmm4


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm6
	pslld	$19-10,%xmm2
	pand	%xmm4,%xmm3
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm12,%xmm10
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm3,%xmm10
	paddd	%xmm6,%xmm14
	pxor	%xmm2,%xmm7

	paddd	%xmm6,%xmm10
	paddd	%xmm7,%xmm10
	movdqa	112-128(%rax),%xmm6
	paddd	240-128(%rax),%xmm5

	movdqa	%xmm6,%xmm7
	movdqa	%xmm6,%xmm1
	psrld	$3,%xmm7
	movdqa	%xmm6,%xmm2

	psrld	$7,%xmm1
	movdqa	64-128(%rax),%xmm0
	pslld	$14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$18-7,%xmm1
	movdqa	%xmm0,%xmm3
	pxor	%xmm2,%xmm7
	pslld	$25-14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$10,%xmm0
	movdqa	%xmm3,%xmm1

	psrld	$17,%xmm3
	pxor	%xmm2,%xmm7
	pslld	$13,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	psrld	$19-17,%xmm3
	pxor	%xmm1,%xmm0
	pslld	$15-13,%xmm1
	pxor	%xmm3,%xmm0
	pxor	%xmm1,%xmm0
	paddd	%xmm0,%xmm5
	movdqa	%xmm14,%xmm7

	movdqa	%xmm14,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm14,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,96-128(%rax)
	paddd	%xmm9,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	64(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm14,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm14,%xmm3
	pslld	$26-21,%xmm2
	pandn	%xmm8,%xmm0
	pand	%xmm15,%xmm3
	pxor	%xmm1,%xmm7


	movdqa	%xmm10,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm10,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	movdqa	%xmm11,%xmm3
	movdqa	%xmm10,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm10,%xmm3


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm3,%xmm4
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm11,%xmm9
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm4,%xmm9
	paddd	%xmm5,%xmm13
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm9
	paddd	%xmm7,%xmm9
	movdqa	128-128(%rax),%xmm5
	paddd	0-128(%rax),%xmm6

	movdqa	%xmm5,%xmm7
	movdqa	%xmm5,%xmm1
	psrld	$3,%xmm7
	movdqa	%xmm5,%xmm2

	psrld	$7,%xmm1
	movdqa	80-128(%rax),%xmm0
	pslld	$14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$18-7,%xmm1
	movdqa	%xmm0,%xmm4
	pxor	%xmm2,%xmm7
	pslld	$25-14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$10,%xmm0
	movdqa	%xmm4,%xmm1

	psrld	$17,%xmm4
	pxor	%xmm2,%xmm7
	pslld	$13,%xmm1
	paddd	%xmm7,%xmm6
	pxor	%xmm4,%xmm0
	psrld	$19-17,%xmm4
	pxor	%xmm1,%xmm0
	pslld	$15-13,%xmm1
	pxor	%xmm4,%xmm0
	pxor	%xmm1,%xmm0
	paddd	%xmm0,%xmm6
	movdqa	%xmm13,%xmm7

	movdqa	%xmm13,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm13,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm6,112-128(%rax)
	paddd	%xmm8,%xmm6

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	96(%rbp),%xmm6
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm13,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm13,%xmm4
	pslld	$26-21,%xmm2
	pandn	%xmm15,%xmm0
	pand	%xmm14,%xmm4
	pxor	%xmm1,%xmm7


	movdqa	%xmm9,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm9,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm6
	pxor	%xmm4,%xmm0
	movdqa	%xmm10,%xmm4
	movdqa	%xmm9,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm9,%xmm4


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm6
	pslld	$19-10,%xmm2
	pand	%xmm4,%xmm3
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm10,%xmm8
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm3,%xmm8
	paddd	%xmm6,%xmm12
	pxor	%xmm2,%xmm7

	paddd	%xmm6,%xmm8
	paddd	%xmm7,%xmm8
	leaq	256(%rbp),%rbp
	movdqa	144-128(%rax),%xmm6
	paddd	16-128(%rax),%xmm5

	movdqa	%xmm6,%xmm7
	movdqa	%xmm6,%xmm1
	psrld	$3,%xmm7
	movdqa	%xmm6,%xmm2

	psrld	$7,%xmm1
	movdqa	96-128(%rax),%xmm0
	pslld	$14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$18-7,%xmm1
	movdqa	%xmm0,%xmm3
	pxor	%xmm2,%xmm7
	pslld	$25-14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$10,%xmm0
	movdqa	%xmm3,%xmm1

	psrld	$17,%xmm3
	pxor	%xmm2,%xmm7
	pslld	$13,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	psrld	$19-17,%xmm3
	pxor	%xmm1,%xmm0
	pslld	$15-13,%xmm1
	pxor	%xmm3,%xmm0
	pxor	%xmm1,%xmm0
	paddd	%xmm0,%xmm5
	movdqa	%xmm12,%xmm7

	movdqa	%xmm12,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm12,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,128-128(%rax)
	paddd	%xmm15,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	-128(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm12,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm12,%xmm3
	pslld	$26-21,%xmm2
	pandn	%xmm14,%xmm0
	pand	%xmm13,%xmm3
	pxor	%xmm1,%xmm7


	movdqa	%xmm8,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm8,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	movdqa	%xmm9,%xmm3
	movdqa	%xmm8,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm8,%xmm3


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm3,%xmm4
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm9,%xmm15
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm4,%xmm15
	paddd	%xmm5,%xmm11
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm15
	paddd	%xmm7,%xmm15
	movdqa	160-128(%rax),%xmm5
	paddd	32-128(%rax),%xmm6

	movdqa	%xmm5,%xmm7
	movdqa	%xmm5,%xmm1
	psrld	$3,%xmm7
	movdqa	%xmm5,%xmm2

	psrld	$7,%xmm1
	movdqa	112-128(%rax),%xmm0
	pslld	$14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$18-7,%xmm1
	movdqa	%xmm0,%xmm4
	pxor	%xmm2,%xmm7
	pslld	$25-14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$10,%xmm0
	movdqa	%xmm4,%xmm1

	psrld	$17,%xmm4
	pxor	%xmm2,%xmm7
	pslld	$13,%xmm1
	paddd	%xmm7,%xmm6
	pxor	%xmm4,%xmm0
	psrld	$19-17,%xmm4
	pxor	%xmm1,%xmm0
	pslld	$15-13,%xmm1
	pxor	%xmm4,%xmm0
	pxor	%xmm1,%xmm0
	paddd	%xmm0,%xmm6
	movdqa	%xmm11,%xmm7

	movdqa	%xmm11,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm11,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm6,144-128(%rax)
	paddd	%xmm14,%xmm6

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	-96(%rbp),%xmm6
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm11,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm11,%xmm4
	pslld	$26-21,%xmm2
	pandn	%xmm13,%xmm0
	pand	%xmm12,%xmm4
	pxor	%xmm1,%xmm7


	movdqa	%xmm15,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm15,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm6
	pxor	%xmm4,%xmm0
	movdqa	%xmm8,%xmm4
	movdqa	%xmm15,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm15,%xmm4


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm6
	pslld	$19-10,%xmm2
	pand	%xmm4,%xmm3
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm8,%xmm14
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm3,%xmm14
	paddd	%xmm6,%xmm10
	pxor	%xmm2,%xmm7

	paddd	%xmm6,%xmm14
	paddd	%xmm7,%xmm14
	movdqa	176-128(%rax),%xmm6
	paddd	48-128(%rax),%xmm5

	movdqa	%xmm6,%xmm7
	movdqa	%xmm6,%xmm1
	psrld	$3,%xmm7
	movdqa	%xmm6,%xmm2

	psrld	$7,%xmm1
	movdqa	128-128(%rax),%xmm0
	pslld	$14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$18-7,%xmm1
	movdqa	%xmm0,%xmm3
	pxor	%xmm2,%xmm7
	pslld	$25-14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$10,%xmm0
	movdqa	%xmm3,%xmm1

	psrld	$17,%xmm3
	pxor	%xmm2,%xmm7
	pslld	$13,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	psrld	$19-17,%xmm3
	pxor	%xmm1,%xmm0
	pslld	$15-13,%xmm1
	pxor	%xmm3,%xmm0
	pxor	%xmm1,%xmm0
	paddd	%xmm0,%xmm5
	movdqa	%xmm10,%xmm7

	movdqa	%xmm10,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm10,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,160-128(%rax)
	paddd	%xmm13,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	-64(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm10,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm10,%xmm3
	pslld	$26-21,%xmm2
	pandn	%xmm12,%xmm0
	pand	%xmm11,%xmm3
	pxor	%xmm1,%xmm7


	movdqa	%xmm14,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm14,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	movdqa	%xmm15,%xmm3
	movdqa	%xmm14,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm14,%xmm3


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm3,%xmm4
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm15,%xmm13
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm4,%xmm13
	paddd	%xmm5,%xmm9
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm13
	paddd	%xmm7,%xmm13
	movdqa	192-128(%rax),%xmm5
	paddd	64-128(%rax),%xmm6

	movdqa	%xmm5,%xmm7
	movdqa	%xmm5,%xmm1
	psrld	$3,%xmm7
	movdqa	%xmm5,%xmm2

	psrld	$7,%xmm1
	movdqa	144-128(%rax),%xmm0
	pslld	$14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$18-7,%xmm1
	movdqa	%xmm0,%xmm4
	pxor	%xmm2,%xmm7
	pslld	$25-14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$10,%xmm0
	movdqa	%xmm4,%xmm1

	psrld	$17,%xmm4
	pxor	%xmm2,%xmm7
	pslld	$13,%xmm1
	paddd	%xmm7,%xmm6
	pxor	%xmm4,%xmm0
	psrld	$19-17,%xmm4
	pxor	%xmm1,%xmm0
	pslld	$15-13,%xmm1
	pxor	%xmm4,%xmm0
	pxor	%xmm1,%xmm0
	paddd	%xmm0,%xmm6
	movdqa	%xmm9,%xmm7

	movdqa	%xmm9,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm9,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm6,176-128(%rax)
	paddd	%xmm12,%xmm6

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	-32(%rbp),%xmm6
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm9,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm9,%xmm4
	pslld	$26-21,%xmm2
	pandn	%xmm11,%xmm0
	pand	%xmm10,%xmm4
	pxor	%xmm1,%xmm7


	movdqa	%xmm13,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm13,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm6
	pxor	%xmm4,%xmm0
	movdqa	%xmm14,%xmm4
	movdqa	%xmm13,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm13,%xmm4


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm6
	pslld	$19-10,%xmm2
	pand	%xmm4,%xmm3
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm14,%xmm12
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm3,%xmm12
	paddd	%xmm6,%xmm8
	pxor	%xmm2,%xmm7

	paddd	%xmm6,%xmm12
	paddd	%xmm7,%xmm12
	movdqa	208-128(%rax),%xmm6
	paddd	80-128(%rax),%xmm5

	movdqa	%xmm6,%xmm7
	movdqa	%xmm6,%xmm1
	psrld	$3,%xmm7
	movdqa	%xmm6,%xmm2

	psrld	$7,%xmm1
	movdqa	160-128(%rax),%xmm0
	pslld	$14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$18-7,%xmm1
	movdqa	%xmm0,%xmm3
	pxor	%xmm2,%xmm7
	pslld	$25-14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$10,%xmm0
	movdqa	%xmm3,%xmm1

	psrld	$17,%xmm3
	pxor	%xmm2,%xmm7
	pslld	$13,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	psrld	$19-17,%xmm3
	pxor	%xmm1,%xmm0
	pslld	$15-13,%xmm1
	pxor	%xmm3,%xmm0
	pxor	%xmm1,%xmm0
	paddd	%xmm0,%xmm5
	movdqa	%xmm8,%xmm7

	movdqa	%xmm8,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm8,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,192-128(%rax)
	paddd	%xmm11,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	0(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm8,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm8,%xmm3
	pslld	$26-21,%xmm2
	pandn	%xmm10,%xmm0
	pand	%xmm9,%xmm3
	pxor	%xmm1,%xmm7


	movdqa	%xmm12,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm12,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	movdqa	%xmm13,%xmm3
	movdqa	%xmm12,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm12,%xmm3


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm3,%xmm4
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm13,%xmm11
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm4,%xmm11
	paddd	%xmm5,%xmm15
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm11
	paddd	%xmm7,%xmm11
	movdqa	224-128(%rax),%xmm5
	paddd	96-128(%rax),%xmm6

	movdqa	%xmm5,%xmm7
	movdqa	%xmm5,%xmm1
	psrld	$3,%xmm7
	movdqa	%xmm5,%xmm2

	psrld	$7,%xmm1
	movdqa	176-128(%rax),%xmm0
	pslld	$14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$18-7,%xmm1
	movdqa	%xmm0,%xmm4
	pxor	%xmm2,%xmm7
	pslld	$25-14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$10,%xmm0
	movdqa	%xmm4,%xmm1

	psrld	$17,%xmm4
	pxor	%xmm2,%xmm7
	pslld	$13,%xmm1
	paddd	%xmm7,%xmm6
	pxor	%xmm4,%xmm0
	psrld	$19-17,%xmm4
	pxor	%xmm1,%xmm0
	pslld	$15-13,%xmm1
	pxor	%xmm4,%xmm0
	pxor	%xmm1,%xmm0
	paddd	%xmm0,%xmm6
	movdqa	%xmm15,%xmm7

	movdqa	%xmm15,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm15,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm6,208-128(%rax)
	paddd	%xmm10,%xmm6

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	32(%rbp),%xmm6
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm15,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm15,%xmm4
	pslld	$26-21,%xmm2
	pandn	%xmm9,%xmm0
	pand	%xmm8,%xmm4
	pxor	%xmm1,%xmm7


	movdqa	%xmm11,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm11,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm6
	pxor	%xmm4,%xmm0
	movdqa	%xmm12,%xmm4
	movdqa	%xmm11,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm11,%xmm4


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm6
	pslld	$19-10,%xmm2
	pand	%xmm4,%xmm3
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm12,%xmm10
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm3,%xmm10
	paddd	%xmm6,%xmm14
	pxor	%xmm2,%xmm7

	paddd	%xmm6,%xmm10
	paddd	%xmm7,%xmm10
	movdqa	240-128(%rax),%xmm6
	paddd	112-128(%rax),%xmm5

	movdqa	%xmm6,%xmm7
	movdqa	%xmm6,%xmm1
	psrld	$3,%xmm7
	movdqa	%xmm6,%xmm2

	psrld	$7,%xmm1
	movdqa	192-128(%rax),%xmm0
	pslld	$14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$18-7,%xmm1
	movdqa	%xmm0,%xmm3
	pxor	%xmm2,%xmm7
	pslld	$25-14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$10,%xmm0
	movdqa	%xmm3,%xmm1

	psrld	$17,%xmm3
	pxor	%xmm2,%xmm7
	pslld	$13,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	psrld	$19-17,%xmm3
	pxor	%xmm1,%xmm0
	pslld	$15-13,%xmm1
	pxor	%xmm3,%xmm0
	pxor	%xmm1,%xmm0
	paddd	%xmm0,%xmm5
	movdqa	%xmm14,%xmm7

	movdqa	%xmm14,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm14,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm5,224-128(%rax)
	paddd	%xmm9,%xmm5

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	64(%rbp),%xmm5
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm14,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm14,%xmm3
	pslld	$26-21,%xmm2
	pandn	%xmm8,%xmm0
	pand	%xmm15,%xmm3
	pxor	%xmm1,%xmm7


	movdqa	%xmm10,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm10,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm5
	pxor	%xmm3,%xmm0
	movdqa	%xmm11,%xmm3
	movdqa	%xmm10,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm10,%xmm3


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm5
	pslld	$19-10,%xmm2
	pand	%xmm3,%xmm4
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm11,%xmm9
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm4,%xmm9
	paddd	%xmm5,%xmm13
	pxor	%xmm2,%xmm7

	paddd	%xmm5,%xmm9
	paddd	%xmm7,%xmm9
	movdqa	0-128(%rax),%xmm5
	paddd	128-128(%rax),%xmm6

	movdqa	%xmm5,%xmm7
	movdqa	%xmm5,%xmm1
	psrld	$3,%xmm7
	movdqa	%xmm5,%xmm2

	psrld	$7,%xmm1
	movdqa	208-128(%rax),%xmm0
	pslld	$14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$18-7,%xmm1
	movdqa	%xmm0,%xmm4
	pxor	%xmm2,%xmm7
	pslld	$25-14,%xmm2
	pxor	%xmm1,%xmm7
	psrld	$10,%xmm0
	movdqa	%xmm4,%xmm1

	psrld	$17,%xmm4
	pxor	%xmm2,%xmm7
	pslld	$13,%xmm1
	paddd	%xmm7,%xmm6
	pxor	%xmm4,%xmm0
	psrld	$19-17,%xmm4
	pxor	%xmm1,%xmm0
	pslld	$15-13,%xmm1
	pxor	%xmm4,%xmm0
	pxor	%xmm1,%xmm0
	paddd	%xmm0,%xmm6
	movdqa	%xmm13,%xmm7

	movdqa	%xmm13,%xmm2

	psrld	$6,%xmm7
	movdqa	%xmm13,%xmm1
	pslld	$7,%xmm2
	movdqa	%xmm6,240-128(%rax)
	paddd	%xmm8,%xmm6

	psrld	$11,%xmm1
	pxor	%xmm2,%xmm7
	pslld	$21-7,%xmm2
	paddd	96(%rbp),%xmm6
	pxor	%xmm1,%xmm7

	psrld	$25-11,%xmm1
	movdqa	%xmm13,%xmm0

	pxor	%xmm2,%xmm7
	movdqa	%xmm13,%xmm4
	pslld	$26-21,%xmm2
	pandn	%xmm15,%xmm0
	pand	%xmm14,%xmm4
	pxor	%xmm1,%xmm7


	movdqa	%xmm9,%xmm1
	pxor	%xmm2,%xmm7
	movdqa	%xmm9,%xmm2
	psrld	$2,%xmm1
	paddd	%xmm7,%xmm6
	pxor	%xmm4,%xmm0
	movdqa	%xmm10,%xmm4
	movdqa	%xmm9,%xmm7
	pslld	$10,%xmm2
	pxor	%xmm9,%xmm4


	psrld	$13,%xmm7
	pxor	%xmm2,%xmm1
	paddd	%xmm0,%xmm6
	pslld	$19-10,%xmm2
	pand	%xmm4,%xmm3
	pxor	%xmm7,%xmm1


	psrld	$22-13,%xmm7
	pxor	%xmm2,%xmm1
	movdqa	%xmm10,%xmm8
	pslld	$30-19,%xmm2
	pxor	%xmm1,%xmm7
	pxor	%xmm3,%xmm8
	paddd	%xmm6,%xmm12
	pxor	%xmm2,%xmm7

	paddd	%xmm6,%xmm8
	paddd	%xmm7,%xmm8
	leaq	256(%rbp),%rbp
	decl	%ecx
	jnz	.Loop_16_xx

	movl	$1,%ecx
	leaq	K256+128(%rip),%rbp

	movdqa	(%rbx),%xmm7
	cmpl	0(%rbx),%ecx
	pxor	%xmm0,%xmm0
	cmovgeq	%rbp,%r8
	cmpl	4(%rbx),%ecx
	movdqa	%xmm7,%xmm6
	cmovgeq	%rbp,%r9
	cmpl	8(%rbx),%ecx
	pcmpgtd	%xmm0,%xmm6
	cmovgeq	%rbp,%r10
	cmpl	12(%rbx),%ecx
	paddd	%xmm6,%xmm7
	cmovgeq	%rbp,%r11

	movdqu	0-128(%rdi),%xmm0
	pand	%xmm6,%xmm8
	movdqu	32-128(%rdi),%xmm1
	pand	%xmm6,%xmm9
	movdqu	64-128(%rdi),%xmm2
	pand	%xmm6,%xmm10
	movdqu	96-128(%rdi),%xmm5
	pand	%xmm6,%xmm11
	paddd	%xmm0,%xmm8
	movdqu	128-128(%rdi),%xmm0
	pand	%xmm6,%xmm12
	paddd	%xmm1,%xmm9
	movdqu	160-128(%rdi),%xmm1
	pand	%xmm6,%xmm13
	paddd	%xmm2,%xmm10
	movdqu	192-128(%rdi),%xmm2
	pand	%xmm6,%xmm14
	paddd	%xmm5,%xmm11
	movdqu	224-128(%rdi),%xmm5
	pand	%xmm6,%xmm15
	paddd	%xmm0,%xmm12
	paddd	%xmm1,%xmm13
	movdqu	%xmm8,0-128(%rdi)
	paddd	%xmm2,%xmm14
	movdqu	%xmm9,32-128(%rdi)
	paddd	%xmm5,%xmm15
	movdqu	%xmm10,64-128(%rdi)
	movdqu	%xmm11,96-128(%rdi)
	movdqu	%xmm12,128-128(%rdi)
	movdqu	%xmm13,160-128(%rdi)
	movdqu	%xmm14,192-128(%rdi)
	movdqu	%xmm15,224-128(%rdi)

	movdqa	%xmm7,(%rbx)
	movdqa	.Lpbswap(%rip),%xmm6
	decl	%edx
	jnz	.Loop

	movl	280(%rsp),%edx
	leaq	16(%rdi),%rdi
	leaq	64(%rsi),%rsi
	decl	%edx
	jnz	.Loop_grande

.Ldone:
	movq	272(%rsp),%rax
.cfi_def_cfa	%rax,8
	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha256_multi_block,.-sha256_multi_block
.type	sha256_multi_block_shaext,@function
.align	32
sha256_multi_block_shaext:
.cfi_startproc	
_shaext_shortcut:
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	subq	$288,%rsp
	shll	$1,%edx
	andq	$-256,%rsp
	leaq	128(%rdi),%rdi
	movq	%rax,272(%rsp)
.Lbody_shaext:
	leaq	256(%rsp),%rbx
	leaq	K256_shaext+128(%rip),%rbp

.Loop_grande_shaext:
	movl	%edx,280(%rsp)
	xorl	%edx,%edx

	movq	0(%rsi),%r8

	movl	8(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,0(%rbx)
	cmovleq	%rsp,%r8

	movq	16(%rsi),%r9

	movl	24(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,4(%rbx)
	cmovleq	%rsp,%r9
	testl	%edx,%edx
	jz	.Ldone_shaext

	movq	0-128(%rdi),%xmm12
	movq	32-128(%rdi),%xmm4
	movq	64-128(%rdi),%xmm13
	movq	96-128(%rdi),%xmm5
	movq	128-128(%rdi),%xmm8
	movq	160-128(%rdi),%xmm9
	movq	192-128(%rdi),%xmm10
	movq	224-128(%rdi),%xmm11

	punpckldq	%xmm4,%xmm12
	punpckldq	%xmm5,%xmm13
	punpckldq	%xmm9,%xmm8
	punpckldq	%xmm11,%xmm10
	movdqa	K256_shaext-16(%rip),%xmm3

	movdqa	%xmm12,%xmm14
	movdqa	%xmm13,%xmm15
	punpcklqdq	%xmm8,%xmm12
	punpcklqdq	%xmm10,%xmm13
	punpckhqdq	%xmm8,%xmm14
	punpckhqdq	%xmm10,%xmm15

	pshufd	$27,%xmm12,%xmm12
	pshufd	$27,%xmm13,%xmm13
	pshufd	$27,%xmm14,%xmm14
	pshufd	$27,%xmm15,%xmm15
	jmp	.Loop_shaext

.align	32
.Loop_shaext:
	movdqu	0(%r8),%xmm4
	movdqu	0(%r9),%xmm8
	movdqu	16(%r8),%xmm5
	movdqu	16(%r9),%xmm9
	movdqu	32(%r8),%xmm6
.byte	102,15,56,0,227
	movdqu	32(%r9),%xmm10
.byte	102,68,15,56,0,195
	movdqu	48(%r8),%xmm7
	leaq	64(%r8),%r8
	movdqu	48(%r9),%xmm11
	leaq	64(%r9),%r9

	movdqa	0-128(%rbp),%xmm0
.byte	102,15,56,0,235
	paddd	%xmm4,%xmm0
	pxor	%xmm12,%xmm4
	movdqa	%xmm0,%xmm1
	movdqa	0-128(%rbp),%xmm2
.byte	102,68,15,56,0,203
	paddd	%xmm8,%xmm2
	movdqa	%xmm13,80(%rsp)
.byte	69,15,56,203,236
	pxor	%xmm14,%xmm8
	movdqa	%xmm2,%xmm0
	movdqa	%xmm15,112(%rsp)
.byte	69,15,56,203,254
	pshufd	$0x0e,%xmm1,%xmm0
	pxor	%xmm12,%xmm4
	movdqa	%xmm12,64(%rsp)
.byte	69,15,56,203,229
	pshufd	$0x0e,%xmm2,%xmm0
	pxor	%xmm14,%xmm8
	movdqa	%xmm14,96(%rsp)
	movdqa	16-128(%rbp),%xmm1
	paddd	%xmm5,%xmm1
.byte	102,15,56,0,243
.byte	69,15,56,203,247

	movdqa	%xmm1,%xmm0
	movdqa	16-128(%rbp),%xmm2
	paddd	%xmm9,%xmm2
.byte	69,15,56,203,236
	movdqa	%xmm2,%xmm0
	prefetcht0	127(%r8)
.byte	102,15,56,0,251
.byte	102,68,15,56,0,211
	prefetcht0	127(%r9)
.byte	69,15,56,203,254
	pshufd	$0x0e,%xmm1,%xmm0
.byte	102,68,15,56,0,219
.byte	15,56,204,229
.byte	69,15,56,203,229
	pshufd	$0x0e,%xmm2,%xmm0
	movdqa	32-128(%rbp),%xmm1
	paddd	%xmm6,%xmm1
.byte	69,15,56,203,247

	movdqa	%xmm1,%xmm0
	movdqa	32-128(%rbp),%xmm2
	paddd	%xmm10,%xmm2
.byte	69,15,56,203,236
.byte	69,15,56,204,193
	movdqa	%xmm2,%xmm0
	movdqa	%xmm7,%xmm3
.byte	69,15,56,203,254
	pshufd	$0x0e,%xmm1,%xmm0
.byte	102,15,58,15,222,4
	paddd	%xmm3,%xmm4
	movdqa	%xmm11,%xmm3
.byte	102,65,15,58,15,218,4
.byte	15,56,204,238
.byte	69,15,56,203,229
	pshufd	$0x0e,%xmm2,%xmm0
	movdqa	48-128(%rbp),%xmm1
	paddd	%xmm7,%xmm1
.byte	69,15,56,203,247
.byte	69,15,56,204,202

	movdqa	%xmm1,%xmm0
	movdqa	48-128(%rbp),%xmm2
	paddd	%xmm3,%xmm8
	paddd	%xmm11,%xmm2
.byte	15,56,205,231
.byte	69,15,56,203,236
	movdqa	%xmm2,%xmm0
	movdqa	%xmm4,%xmm3
.byte	102,15,58,15,223,4
.byte	69,15,56,203,254
.byte	69,15,56,205,195
	pshufd	$0x0e,%xmm1,%xmm0
	paddd	%xmm3,%xmm5
	movdqa	%xmm8,%xmm3
.byte	102,65,15,58,15,219,4
.byte	15,56,204,247
.byte	69,15,56,203,229
	pshufd	$0x0e,%xmm2,%xmm0
	movdqa	64-128(%rbp),%xmm1
	paddd	%xmm4,%xmm1
.byte	69,15,56,203,247
.byte	69,15,56,204,211
	movdqa	%xmm1,%xmm0
	movdqa	64-128(%rbp),%xmm2
	paddd	%xmm3,%xmm9
	paddd	%xmm8,%xmm2
.byte	15,56,205,236
.byte	69,15,56,203,236
	movdqa	%xmm2,%xmm0
	movdqa	%xmm5,%xmm3
.byte	102,15,58,15,220,4
.byte	69,15,56,203,254
.byte	69,15,56,205,200
	pshufd	$0x0e,%xmm1,%xmm0
	paddd	%xmm3,%xmm6
	movdqa	%xmm9,%xmm3
.byte	102,65,15,58,15,216,4
.byte	15,56,204,252
.byte	69,15,56,203,229
	pshufd	$0x0e,%xmm2,%xmm0
	movdqa	80-128(%rbp),%xmm1
	paddd	%xmm5,%xmm1
.byte	69,15,56,203,247
.byte	69,15,56,204,216
	movdqa	%xmm1,%xmm0
	movdqa	80-128(%rbp),%xmm2
	paddd	%xmm3,%xmm10
	paddd	%xmm9,%xmm2
.byte	15,56,205,245
.byte	69,15,56,203,236
	movdqa	%xmm2,%xmm0
	movdqa	%xmm6,%xmm3
.byte	102,15,58,15,221,4
.byte	69,15,56,203,254
.byte	69,15,56,205,209
	pshufd	$0x0e,%xmm1,%xmm0
	paddd	%xmm3,%xmm7
	movdqa	%xmm10,%xmm3
.byte	102,65,15,58,15,217,4
.byte	15,56,204,229
.byte	69,15,56,203,229
	pshufd	$0x0e,%xmm2,%xmm0
	movdqa	96-128(%rbp),%xmm1
	paddd	%xmm6,%xmm1
.byte	69,15,56,203,247
.byte	69,15,56,204,193
	movdqa	%xmm1,%xmm0
	movdqa	96-128(%rbp),%xmm2
	paddd	%xmm3,%xmm11
	paddd	%xmm10,%xmm2
.byte	15,56,205,254
.byte	69,15,56,203,236
	movdqa	%xmm2,%xmm0
	movdqa	%xmm7,%xmm3
.byte	102,15,58,15,222,4
.byte	69,15,56,203,254
.byte	69,15,56,205,218
	pshufd	$0x0e,%xmm1,%xmm0
	paddd	%xmm3,%xmm4
	movdqa	%xmm11,%xmm3
.byte	102,65,15,58,15,218,4
.byte	15,56,204,238
.byte	69,15,56,203,229
	pshufd	$0x0e,%xmm2,%xmm0
	movdqa	112-128(%rbp),%xmm1
	paddd	%xmm7,%xmm1
.byte	69,15,56,203,247
.byte	69,15,56,204,202
	movdqa	%xmm1,%xmm0
	movdqa	112-128(%rbp),%xmm2
	paddd	%xmm3,%xmm8
	paddd	%xmm11,%xmm2
.byte	15,56,205,231
.byte	69,15,56,203,236
	movdqa	%xmm2,%xmm0
	movdqa	%xmm4,%xmm3
.byte	102,15,58,15,223,4
.byte	69,15,56,203,254
.byte	69,15,56,205,195
	pshufd	$0x0e,%xmm1,%xmm0
	paddd	%xmm3,%xmm5
	movdqa	%xmm8,%xmm3
.byte	102,65,15,58,15,219,4
.byte	15,56,204,247
.byte	69,15,56,203,229
	pshufd	$0x0e,%xmm2,%xmm0
	movdqa	128-128(%rbp),%xmm1
	paddd	%xmm4,%xmm1
.byte	69,15,56,203,247
.byte	69,15,56,204,211
	movdqa	%xmm1,%xmm0
	movdqa	128-128(%rbp),%xmm2
	paddd	%xmm3,%xmm9
	paddd	%xmm8,%xmm2
.byte	15,56,205,236
.byte	69,15,56,203,236
	movdqa	%xmm2,%xmm0
	movdqa	%xmm5,%xmm3
.byte	102,15,58,15,220,4
.byte	69,15,56,203,254
.byte	69,15,56,205,200
	pshufd	$0x0e,%xmm1,%xmm0
	paddd	%xmm3,%xmm6
	movdqa	%xmm9,%xmm3
.byte	102,65,15,58,15,216,4
.byte	15,56,204,252
.byte	69,15,56,203,229
	pshufd	$0x0e,%xmm2,%xmm0
	movdqa	144-128(%rbp),%xmm1
	paddd	%xmm5,%xmm1
.byte	69,15,56,203,247
.byte	69,15,56,204,216
	movdqa	%xmm1,%xmm0
	movdqa	144-128(%rbp),%xmm2
	paddd	%xmm3,%xmm10
	paddd	%xmm9,%xmm2
.byte	15,56,205,245
.byte	69,15,56,203,236
	movdqa	%xmm2,%xmm0
	movdqa	%xmm6,%xmm3
.byte	102,15,58,15,221,4
.byte	69,15,56,203,254
.byte	69,15,56,205,209
	pshufd	$0x0e,%xmm1,%xmm0
	paddd	%xmm3,%xmm7
	movdqa	%xmm10,%xmm3
.byte	102,65,15,58,15,217,4
.byte	15,56,204,229
.byte	69,15,56,203,229
	pshufd	$0x0e,%xmm2,%xmm0
	movdqa	160-128(%rbp),%xmm1
	paddd	%xmm6,%xmm1
.byte	69,15,56,203,247
.byte	69,15,56,204,193
	movdqa	%xmm1,%xmm0
	movdqa	160-128(%rbp),%xmm2
	paddd	%xmm3,%xmm11
	paddd	%xmm10,%xmm2
.byte	15,56,205,254
.byte	69,15,56,203,236
	movdqa	%xmm2,%xmm0
	movdqa	%xmm7,%xmm3
.byte	102,15,58,15,222,4
.byte	69,15,56,203,254
.byte	69,15,56,205,218
	pshufd	$0x0e,%xmm1,%xmm0
	paddd	%xmm3,%xmm4
	movdqa	%xmm11,%xmm3
.byte	102,65,15,58,15,218,4
.byte	15,56,204,238
.byte	69,15,56,203,229
	pshufd	$0x0e,%xmm2,%xmm0
	movdqa	176-128(%rbp),%xmm1
	paddd	%xmm7,%xmm1
.byte	69,15,56,203,247
.byte	69,15,56,204,202
	movdqa	%xmm1,%xmm0
	movdqa	176-128(%rbp),%xmm2
	paddd	%xmm3,%xmm8
	paddd	%xmm11,%xmm2
.byte	15,56,205,231
.byte	69,15,56,203,236
	movdqa	%xmm2,%xmm0
	movdqa	%xmm4,%xmm3
.byte	102,15,58,15,223,4
.byte	69,15,56,203,254
.byte	69,15,56,205,195
	pshufd	$0x0e,%xmm1,%xmm0
	paddd	%xmm3,%xmm5
	movdqa	%xmm8,%xmm3
.byte	102,65,15,58,15,219,4
.byte	15,56,204,247
.byte	69,15,56,203,229
	pshufd	$0x0e,%xmm2,%xmm0
	movdqa	192-128(%rbp),%xmm1
	paddd	%xmm4,%xmm1
.byte	69,15,56,203,247
.byte	69,15,56,204,211
	movdqa	%xmm1,%xmm0
	movdqa	192-128(%rbp),%xmm2
	paddd	%xmm3,%xmm9
	paddd	%xmm8,%xmm2
.byte	15,56,205,236
.byte	69,15,56,203,236
	movdqa	%xmm2,%xmm0
	movdqa	%xmm5,%xmm3
.byte	102,15,58,15,220,4
.byte	69,15,56,203,254
.byte	69,15,56,205,200
	pshufd	$0x0e,%xmm1,%xmm0
	paddd	%xmm3,%xmm6
	movdqa	%xmm9,%xmm3
.byte	102,65,15,58,15,216,4
.byte	15,56,204,252
.byte	69,15,56,203,229
	pshufd	$0x0e,%xmm2,%xmm0
	movdqa	208-128(%rbp),%xmm1
	paddd	%xmm5,%xmm1
.byte	69,15,56,203,247
.byte	69,15,56,204,216
	movdqa	%xmm1,%xmm0
	movdqa	208-128(%rbp),%xmm2
	paddd	%xmm3,%xmm10
	paddd	%xmm9,%xmm2
.byte	15,56,205,245
.byte	69,15,56,203,236
	movdqa	%xmm2,%xmm0
	movdqa	%xmm6,%xmm3
.byte	102,15,58,15,221,4
.byte	69,15,56,203,254
.byte	69,15,56,205,209
	pshufd	$0x0e,%xmm1,%xmm0
	paddd	%xmm3,%xmm7
	movdqa	%xmm10,%xmm3
.byte	102,65,15,58,15,217,4
	nop
.byte	69,15,56,203,229
	pshufd	$0x0e,%xmm2,%xmm0
	movdqa	224-128(%rbp),%xmm1
	paddd	%xmm6,%xmm1
.byte	69,15,56,203,247

	movdqa	%xmm1,%xmm0
	movdqa	224-128(%rbp),%xmm2
	paddd	%xmm3,%xmm11
	paddd	%xmm10,%xmm2
.byte	15,56,205,254
	nop
.byte	69,15,56,203,236
	movdqa	%xmm2,%xmm0
	movl	$1,%ecx
	pxor	%xmm6,%xmm6
.byte	69,15,56,203,254
.byte	69,15,56,205,218
	pshufd	$0x0e,%xmm1,%xmm0
	movdqa	240-128(%rbp),%xmm1
	paddd	%xmm7,%xmm1
	movq	(%rbx),%xmm7
	nop
.byte	69,15,56,203,229
	pshufd	$0x0e,%xmm2,%xmm0
	movdqa	240-128(%rbp),%xmm2
	paddd	%xmm11,%xmm2
.byte	69,15,56,203,247

	movdqa	%xmm1,%xmm0
	cmpl	0(%rbx),%ecx
	cmovgeq	%rsp,%r8
	cmpl	4(%rbx),%ecx
	cmovgeq	%rsp,%r9
	pshufd	$0x00,%xmm7,%xmm9
.byte	69,15,56,203,236
	movdqa	%xmm2,%xmm0
	pshufd	$0x55,%xmm7,%xmm10
	movdqa	%xmm7,%xmm11
.byte	69,15,56,203,254
	pshufd	$0x0e,%xmm1,%xmm0
	pcmpgtd	%xmm6,%xmm9
	pcmpgtd	%xmm6,%xmm10
.byte	69,15,56,203,229
	pshufd	$0x0e,%xmm2,%xmm0
	pcmpgtd	%xmm6,%xmm11
	movdqa	K256_shaext-16(%rip),%xmm3
.byte	69,15,56,203,247

	pand	%xmm9,%xmm13
	pand	%xmm10,%xmm15
	pand	%xmm9,%xmm12
	pand	%xmm10,%xmm14
	paddd	%xmm7,%xmm11

	paddd	80(%rsp),%xmm13
	paddd	112(%rsp),%xmm15
	paddd	64(%rsp),%xmm12
	paddd	96(%rsp),%xmm14

	movq	%xmm11,(%rbx)
	decl	%edx
	jnz	.Loop_shaext

	movl	280(%rsp),%edx

	pshufd	$27,%xmm12,%xmm12
	pshufd	$27,%xmm13,%xmm13
	pshufd	$27,%xmm14,%xmm14
	pshufd	$27,%xmm15,%xmm15

	movdqa	%xmm12,%xmm5
	movdqa	%xmm13,%xmm6
	punpckldq	%xmm14,%xmm12
	punpckhdq	%xmm14,%xmm5
	punpckldq	%xmm15,%xmm13
	punpckhdq	%xmm15,%xmm6

	movq	%xmm12,0-128(%rdi)
	psrldq	$8,%xmm12
	movq	%xmm5,128-128(%rdi)
	psrldq	$8,%xmm5
	movq	%xmm12,32-128(%rdi)
	movq	%xmm5,160-128(%rdi)

	movq	%xmm13,64-128(%rdi)
	psrldq	$8,%xmm13
	movq	%xmm6,192-128(%rdi)
	psrldq	$8,%xmm6
	movq	%xmm13,96-128(%rdi)
	movq	%xmm6,224-128(%rdi)

	leaq	8(%rdi),%rdi
	leaq	32(%rsi),%rsi
	decl	%edx
	jnz	.Loop_grande_shaext

.Ldone_shaext:

	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue_shaext:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha256_multi_block_shaext,.-sha256_multi_block_shaext
.type	sha256_multi_block_avx,@function
.align	32
sha256_multi_block_avx:
.cfi_startproc	
_avx_shortcut:
	shrq	$32,%rcx
	cmpl	$2,%edx
	jb	.Lavx
	testl	$32,%ecx
	jnz	_avx2_shortcut
	jmp	.Lavx
.align	32
.Lavx:
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	subq	$288,%rsp
	andq	$-256,%rsp
	movq	%rax,272(%rsp)
.cfi_escape	0x0f,0x06,0x77,0x90,0x02,0x06,0x23,0x08
.Lbody_avx:
	leaq	K256+128(%rip),%rbp
	leaq	256(%rsp),%rbx
	leaq	128(%rdi),%rdi

.Loop_grande_avx:
	movl	%edx,280(%rsp)
	xorl	%edx,%edx

	movq	0(%rsi),%r8

	movl	8(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,0(%rbx)
	cmovleq	%rbp,%r8

	movq	16(%rsi),%r9

	movl	24(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,4(%rbx)
	cmovleq	%rbp,%r9

	movq	32(%rsi),%r10

	movl	40(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,8(%rbx)
	cmovleq	%rbp,%r10

	movq	48(%rsi),%r11

	movl	56(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,12(%rbx)
	cmovleq	%rbp,%r11
	testl	%edx,%edx
	jz	.Ldone_avx

	vmovdqu	0-128(%rdi),%xmm8
	leaq	128(%rsp),%rax
	vmovdqu	32-128(%rdi),%xmm9
	vmovdqu	64-128(%rdi),%xmm10
	vmovdqu	96-128(%rdi),%xmm11
	vmovdqu	128-128(%rdi),%xmm12
	vmovdqu	160-128(%rdi),%xmm13
	vmovdqu	192-128(%rdi),%xmm14
	vmovdqu	224-128(%rdi),%xmm15
	vmovdqu	.Lpbswap(%rip),%xmm6
	jmp	.Loop_avx

.align	32
.Loop_avx:
	vpxor	%xmm9,%xmm10,%xmm4
	vmovd	0(%r8),%xmm5
	vmovd	0(%r9),%xmm0
	vpinsrd	$1,0(%r10),%xmm5,%xmm5
	vpinsrd	$1,0(%r11),%xmm0,%xmm0
	vpunpckldq	%xmm0,%xmm5,%xmm5
	vpshufb	%xmm6,%xmm5,%xmm5
	vpsrld	$6,%xmm12,%xmm7
	vpslld	$26,%xmm12,%xmm2
	vmovdqu	%xmm5,0-128(%rax)
	vpaddd	%xmm15,%xmm5,%xmm5

	vpsrld	$11,%xmm12,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm12,%xmm2
	vpaddd	-128(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm12,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm12,%xmm2
	vpandn	%xmm14,%xmm12,%xmm0
	vpand	%xmm13,%xmm12,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm8,%xmm15
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm8,%xmm1
	vpxor	%xmm3,%xmm0,%xmm0
	vpxor	%xmm8,%xmm9,%xmm3

	vpxor	%xmm1,%xmm15,%xmm15
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm8,%xmm1

	vpslld	$19,%xmm8,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm3,%xmm4,%xmm4

	vpxor	%xmm1,%xmm15,%xmm7

	vpsrld	$22,%xmm8,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm8,%xmm2
	vpxor	%xmm4,%xmm9,%xmm15
	vpaddd	%xmm5,%xmm11,%xmm11

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm15,%xmm15
	vpaddd	%xmm7,%xmm15,%xmm15
	vmovd	4(%r8),%xmm5
	vmovd	4(%r9),%xmm0
	vpinsrd	$1,4(%r10),%xmm5,%xmm5
	vpinsrd	$1,4(%r11),%xmm0,%xmm0
	vpunpckldq	%xmm0,%xmm5,%xmm5
	vpshufb	%xmm6,%xmm5,%xmm5
	vpsrld	$6,%xmm11,%xmm7
	vpslld	$26,%xmm11,%xmm2
	vmovdqu	%xmm5,16-128(%rax)
	vpaddd	%xmm14,%xmm5,%xmm5

	vpsrld	$11,%xmm11,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm11,%xmm2
	vpaddd	-96(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm11,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm11,%xmm2
	vpandn	%xmm13,%xmm11,%xmm0
	vpand	%xmm12,%xmm11,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm15,%xmm14
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm15,%xmm1
	vpxor	%xmm4,%xmm0,%xmm0
	vpxor	%xmm15,%xmm8,%xmm4

	vpxor	%xmm1,%xmm14,%xmm14
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm15,%xmm1

	vpslld	$19,%xmm15,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm4,%xmm3,%xmm3

	vpxor	%xmm1,%xmm14,%xmm7

	vpsrld	$22,%xmm15,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm15,%xmm2
	vpxor	%xmm3,%xmm8,%xmm14
	vpaddd	%xmm5,%xmm10,%xmm10

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm14,%xmm14
	vpaddd	%xmm7,%xmm14,%xmm14
	vmovd	8(%r8),%xmm5
	vmovd	8(%r9),%xmm0
	vpinsrd	$1,8(%r10),%xmm5,%xmm5
	vpinsrd	$1,8(%r11),%xmm0,%xmm0
	vpunpckldq	%xmm0,%xmm5,%xmm5
	vpshufb	%xmm6,%xmm5,%xmm5
	vpsrld	$6,%xmm10,%xmm7
	vpslld	$26,%xmm10,%xmm2
	vmovdqu	%xmm5,32-128(%rax)
	vpaddd	%xmm13,%xmm5,%xmm5

	vpsrld	$11,%xmm10,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm10,%xmm2
	vpaddd	-64(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm10,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm10,%xmm2
	vpandn	%xmm12,%xmm10,%xmm0
	vpand	%xmm11,%xmm10,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm14,%xmm13
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm14,%xmm1
	vpxor	%xmm3,%xmm0,%xmm0
	vpxor	%xmm14,%xmm15,%xmm3

	vpxor	%xmm1,%xmm13,%xmm13
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm14,%xmm1

	vpslld	$19,%xmm14,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm3,%xmm4,%xmm4

	vpxor	%xmm1,%xmm13,%xmm7

	vpsrld	$22,%xmm14,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm14,%xmm2
	vpxor	%xmm4,%xmm15,%xmm13
	vpaddd	%xmm5,%xmm9,%xmm9

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm13,%xmm13
	vpaddd	%xmm7,%xmm13,%xmm13
	vmovd	12(%r8),%xmm5
	vmovd	12(%r9),%xmm0
	vpinsrd	$1,12(%r10),%xmm5,%xmm5
	vpinsrd	$1,12(%r11),%xmm0,%xmm0
	vpunpckldq	%xmm0,%xmm5,%xmm5
	vpshufb	%xmm6,%xmm5,%xmm5
	vpsrld	$6,%xmm9,%xmm7
	vpslld	$26,%xmm9,%xmm2
	vmovdqu	%xmm5,48-128(%rax)
	vpaddd	%xmm12,%xmm5,%xmm5

	vpsrld	$11,%xmm9,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm9,%xmm2
	vpaddd	-32(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm9,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm9,%xmm2
	vpandn	%xmm11,%xmm9,%xmm0
	vpand	%xmm10,%xmm9,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm13,%xmm12
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm13,%xmm1
	vpxor	%xmm4,%xmm0,%xmm0
	vpxor	%xmm13,%xmm14,%xmm4

	vpxor	%xmm1,%xmm12,%xmm12
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm13,%xmm1

	vpslld	$19,%xmm13,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm4,%xmm3,%xmm3

	vpxor	%xmm1,%xmm12,%xmm7

	vpsrld	$22,%xmm13,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm13,%xmm2
	vpxor	%xmm3,%xmm14,%xmm12
	vpaddd	%xmm5,%xmm8,%xmm8

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm12,%xmm12
	vpaddd	%xmm7,%xmm12,%xmm12
	vmovd	16(%r8),%xmm5
	vmovd	16(%r9),%xmm0
	vpinsrd	$1,16(%r10),%xmm5,%xmm5
	vpinsrd	$1,16(%r11),%xmm0,%xmm0
	vpunpckldq	%xmm0,%xmm5,%xmm5
	vpshufb	%xmm6,%xmm5,%xmm5
	vpsrld	$6,%xmm8,%xmm7
	vpslld	$26,%xmm8,%xmm2
	vmovdqu	%xmm5,64-128(%rax)
	vpaddd	%xmm11,%xmm5,%xmm5

	vpsrld	$11,%xmm8,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm8,%xmm2
	vpaddd	0(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm8,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm8,%xmm2
	vpandn	%xmm10,%xmm8,%xmm0
	vpand	%xmm9,%xmm8,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm12,%xmm11
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm12,%xmm1
	vpxor	%xmm3,%xmm0,%xmm0
	vpxor	%xmm12,%xmm13,%xmm3

	vpxor	%xmm1,%xmm11,%xmm11
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm12,%xmm1

	vpslld	$19,%xmm12,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm3,%xmm4,%xmm4

	vpxor	%xmm1,%xmm11,%xmm7

	vpsrld	$22,%xmm12,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm12,%xmm2
	vpxor	%xmm4,%xmm13,%xmm11
	vpaddd	%xmm5,%xmm15,%xmm15

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm11,%xmm11
	vpaddd	%xmm7,%xmm11,%xmm11
	vmovd	20(%r8),%xmm5
	vmovd	20(%r9),%xmm0
	vpinsrd	$1,20(%r10),%xmm5,%xmm5
	vpinsrd	$1,20(%r11),%xmm0,%xmm0
	vpunpckldq	%xmm0,%xmm5,%xmm5
	vpshufb	%xmm6,%xmm5,%xmm5
	vpsrld	$6,%xmm15,%xmm7
	vpslld	$26,%xmm15,%xmm2
	vmovdqu	%xmm5,80-128(%rax)
	vpaddd	%xmm10,%xmm5,%xmm5

	vpsrld	$11,%xmm15,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm15,%xmm2
	vpaddd	32(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm15,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm15,%xmm2
	vpandn	%xmm9,%xmm15,%xmm0
	vpand	%xmm8,%xmm15,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm11,%xmm10
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm11,%xmm1
	vpxor	%xmm4,%xmm0,%xmm0
	vpxor	%xmm11,%xmm12,%xmm4

	vpxor	%xmm1,%xmm10,%xmm10
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm11,%xmm1

	vpslld	$19,%xmm11,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm4,%xmm3,%xmm3

	vpxor	%xmm1,%xmm10,%xmm7

	vpsrld	$22,%xmm11,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm11,%xmm2
	vpxor	%xmm3,%xmm12,%xmm10
	vpaddd	%xmm5,%xmm14,%xmm14

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm10,%xmm10
	vpaddd	%xmm7,%xmm10,%xmm10
	vmovd	24(%r8),%xmm5
	vmovd	24(%r9),%xmm0
	vpinsrd	$1,24(%r10),%xmm5,%xmm5
	vpinsrd	$1,24(%r11),%xmm0,%xmm0
	vpunpckldq	%xmm0,%xmm5,%xmm5
	vpshufb	%xmm6,%xmm5,%xmm5
	vpsrld	$6,%xmm14,%xmm7
	vpslld	$26,%xmm14,%xmm2
	vmovdqu	%xmm5,96-128(%rax)
	vpaddd	%xmm9,%xmm5,%xmm5

	vpsrld	$11,%xmm14,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm14,%xmm2
	vpaddd	64(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm14,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm14,%xmm2
	vpandn	%xmm8,%xmm14,%xmm0
	vpand	%xmm15,%xmm14,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm10,%xmm9
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm10,%xmm1
	vpxor	%xmm3,%xmm0,%xmm0
	vpxor	%xmm10,%xmm11,%xmm3

	vpxor	%xmm1,%xmm9,%xmm9
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm10,%xmm1

	vpslld	$19,%xmm10,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm3,%xmm4,%xmm4

	vpxor	%xmm1,%xmm9,%xmm7

	vpsrld	$22,%xmm10,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm10,%xmm2
	vpxor	%xmm4,%xmm11,%xmm9
	vpaddd	%xmm5,%xmm13,%xmm13

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm9,%xmm9
	vpaddd	%xmm7,%xmm9,%xmm9
	vmovd	28(%r8),%xmm5
	vmovd	28(%r9),%xmm0
	vpinsrd	$1,28(%r10),%xmm5,%xmm5
	vpinsrd	$1,28(%r11),%xmm0,%xmm0
	vpunpckldq	%xmm0,%xmm5,%xmm5
	vpshufb	%xmm6,%xmm5,%xmm5
	vpsrld	$6,%xmm13,%xmm7
	vpslld	$26,%xmm13,%xmm2
	vmovdqu	%xmm5,112-128(%rax)
	vpaddd	%xmm8,%xmm5,%xmm5

	vpsrld	$11,%xmm13,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm13,%xmm2
	vpaddd	96(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm13,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm13,%xmm2
	vpandn	%xmm15,%xmm13,%xmm0
	vpand	%xmm14,%xmm13,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm9,%xmm8
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm9,%xmm1
	vpxor	%xmm4,%xmm0,%xmm0
	vpxor	%xmm9,%xmm10,%xmm4

	vpxor	%xmm1,%xmm8,%xmm8
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm9,%xmm1

	vpslld	$19,%xmm9,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm4,%xmm3,%xmm3

	vpxor	%xmm1,%xmm8,%xmm7

	vpsrld	$22,%xmm9,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm9,%xmm2
	vpxor	%xmm3,%xmm10,%xmm8
	vpaddd	%xmm5,%xmm12,%xmm12

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm8,%xmm8
	vpaddd	%xmm7,%xmm8,%xmm8
	addq	$256,%rbp
	vmovd	32(%r8),%xmm5
	vmovd	32(%r9),%xmm0
	vpinsrd	$1,32(%r10),%xmm5,%xmm5
	vpinsrd	$1,32(%r11),%xmm0,%xmm0
	vpunpckldq	%xmm0,%xmm5,%xmm5
	vpshufb	%xmm6,%xmm5,%xmm5
	vpsrld	$6,%xmm12,%xmm7
	vpslld	$26,%xmm12,%xmm2
	vmovdqu	%xmm5,128-128(%rax)
	vpaddd	%xmm15,%xmm5,%xmm5

	vpsrld	$11,%xmm12,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm12,%xmm2
	vpaddd	-128(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm12,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm12,%xmm2
	vpandn	%xmm14,%xmm12,%xmm0
	vpand	%xmm13,%xmm12,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm8,%xmm15
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm8,%xmm1
	vpxor	%xmm3,%xmm0,%xmm0
	vpxor	%xmm8,%xmm9,%xmm3

	vpxor	%xmm1,%xmm15,%xmm15
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm8,%xmm1

	vpslld	$19,%xmm8,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm3,%xmm4,%xmm4

	vpxor	%xmm1,%xmm15,%xmm7

	vpsrld	$22,%xmm8,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm8,%xmm2
	vpxor	%xmm4,%xmm9,%xmm15
	vpaddd	%xmm5,%xmm11,%xmm11

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm15,%xmm15
	vpaddd	%xmm7,%xmm15,%xmm15
	vmovd	36(%r8),%xmm5
	vmovd	36(%r9),%xmm0
	vpinsrd	$1,36(%r10),%xmm5,%xmm5
	vpinsrd	$1,36(%r11),%xmm0,%xmm0
	vpunpckldq	%xmm0,%xmm5,%xmm5
	vpshufb	%xmm6,%xmm5,%xmm5
	vpsrld	$6,%xmm11,%xmm7
	vpslld	$26,%xmm11,%xmm2
	vmovdqu	%xmm5,144-128(%rax)
	vpaddd	%xmm14,%xmm5,%xmm5

	vpsrld	$11,%xmm11,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm11,%xmm2
	vpaddd	-96(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm11,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm11,%xmm2
	vpandn	%xmm13,%xmm11,%xmm0
	vpand	%xmm12,%xmm11,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm15,%xmm14
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm15,%xmm1
	vpxor	%xmm4,%xmm0,%xmm0
	vpxor	%xmm15,%xmm8,%xmm4

	vpxor	%xmm1,%xmm14,%xmm14
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm15,%xmm1

	vpslld	$19,%xmm15,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm4,%xmm3,%xmm3

	vpxor	%xmm1,%xmm14,%xmm7

	vpsrld	$22,%xmm15,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm15,%xmm2
	vpxor	%xmm3,%xmm8,%xmm14
	vpaddd	%xmm5,%xmm10,%xmm10

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm14,%xmm14
	vpaddd	%xmm7,%xmm14,%xmm14
	vmovd	40(%r8),%xmm5
	vmovd	40(%r9),%xmm0
	vpinsrd	$1,40(%r10),%xmm5,%xmm5
	vpinsrd	$1,40(%r11),%xmm0,%xmm0
	vpunpckldq	%xmm0,%xmm5,%xmm5
	vpshufb	%xmm6,%xmm5,%xmm5
	vpsrld	$6,%xmm10,%xmm7
	vpslld	$26,%xmm10,%xmm2
	vmovdqu	%xmm5,160-128(%rax)
	vpaddd	%xmm13,%xmm5,%xmm5

	vpsrld	$11,%xmm10,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm10,%xmm2
	vpaddd	-64(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm10,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm10,%xmm2
	vpandn	%xmm12,%xmm10,%xmm0
	vpand	%xmm11,%xmm10,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm14,%xmm13
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm14,%xmm1
	vpxor	%xmm3,%xmm0,%xmm0
	vpxor	%xmm14,%xmm15,%xmm3

	vpxor	%xmm1,%xmm13,%xmm13
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm14,%xmm1

	vpslld	$19,%xmm14,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm3,%xmm4,%xmm4

	vpxor	%xmm1,%xmm13,%xmm7

	vpsrld	$22,%xmm14,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm14,%xmm2
	vpxor	%xmm4,%xmm15,%xmm13
	vpaddd	%xmm5,%xmm9,%xmm9

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm13,%xmm13
	vpaddd	%xmm7,%xmm13,%xmm13
	vmovd	44(%r8),%xmm5
	vmovd	44(%r9),%xmm0
	vpinsrd	$1,44(%r10),%xmm5,%xmm5
	vpinsrd	$1,44(%r11),%xmm0,%xmm0
	vpunpckldq	%xmm0,%xmm5,%xmm5
	vpshufb	%xmm6,%xmm5,%xmm5
	vpsrld	$6,%xmm9,%xmm7
	vpslld	$26,%xmm9,%xmm2
	vmovdqu	%xmm5,176-128(%rax)
	vpaddd	%xmm12,%xmm5,%xmm5

	vpsrld	$11,%xmm9,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm9,%xmm2
	vpaddd	-32(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm9,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm9,%xmm2
	vpandn	%xmm11,%xmm9,%xmm0
	vpand	%xmm10,%xmm9,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm13,%xmm12
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm13,%xmm1
	vpxor	%xmm4,%xmm0,%xmm0
	vpxor	%xmm13,%xmm14,%xmm4

	vpxor	%xmm1,%xmm12,%xmm12
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm13,%xmm1

	vpslld	$19,%xmm13,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm4,%xmm3,%xmm3

	vpxor	%xmm1,%xmm12,%xmm7

	vpsrld	$22,%xmm13,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm13,%xmm2
	vpxor	%xmm3,%xmm14,%xmm12
	vpaddd	%xmm5,%xmm8,%xmm8

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm12,%xmm12
	vpaddd	%xmm7,%xmm12,%xmm12
	vmovd	48(%r8),%xmm5
	vmovd	48(%r9),%xmm0
	vpinsrd	$1,48(%r10),%xmm5,%xmm5
	vpinsrd	$1,48(%r11),%xmm0,%xmm0
	vpunpckldq	%xmm0,%xmm5,%xmm5
	vpshufb	%xmm6,%xmm5,%xmm5
	vpsrld	$6,%xmm8,%xmm7
	vpslld	$26,%xmm8,%xmm2
	vmovdqu	%xmm5,192-128(%rax)
	vpaddd	%xmm11,%xmm5,%xmm5

	vpsrld	$11,%xmm8,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm8,%xmm2
	vpaddd	0(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm8,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm8,%xmm2
	vpandn	%xmm10,%xmm8,%xmm0
	vpand	%xmm9,%xmm8,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm12,%xmm11
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm12,%xmm1
	vpxor	%xmm3,%xmm0,%xmm0
	vpxor	%xmm12,%xmm13,%xmm3

	vpxor	%xmm1,%xmm11,%xmm11
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm12,%xmm1

	vpslld	$19,%xmm12,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm3,%xmm4,%xmm4

	vpxor	%xmm1,%xmm11,%xmm7

	vpsrld	$22,%xmm12,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm12,%xmm2
	vpxor	%xmm4,%xmm13,%xmm11
	vpaddd	%xmm5,%xmm15,%xmm15

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm11,%xmm11
	vpaddd	%xmm7,%xmm11,%xmm11
	vmovd	52(%r8),%xmm5
	vmovd	52(%r9),%xmm0
	vpinsrd	$1,52(%r10),%xmm5,%xmm5
	vpinsrd	$1,52(%r11),%xmm0,%xmm0
	vpunpckldq	%xmm0,%xmm5,%xmm5
	vpshufb	%xmm6,%xmm5,%xmm5
	vpsrld	$6,%xmm15,%xmm7
	vpslld	$26,%xmm15,%xmm2
	vmovdqu	%xmm5,208-128(%rax)
	vpaddd	%xmm10,%xmm5,%xmm5

	vpsrld	$11,%xmm15,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm15,%xmm2
	vpaddd	32(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm15,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm15,%xmm2
	vpandn	%xmm9,%xmm15,%xmm0
	vpand	%xmm8,%xmm15,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm11,%xmm10
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm11,%xmm1
	vpxor	%xmm4,%xmm0,%xmm0
	vpxor	%xmm11,%xmm12,%xmm4

	vpxor	%xmm1,%xmm10,%xmm10
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm11,%xmm1

	vpslld	$19,%xmm11,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm4,%xmm3,%xmm3

	vpxor	%xmm1,%xmm10,%xmm7

	vpsrld	$22,%xmm11,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm11,%xmm2
	vpxor	%xmm3,%xmm12,%xmm10
	vpaddd	%xmm5,%xmm14,%xmm14

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm10,%xmm10
	vpaddd	%xmm7,%xmm10,%xmm10
	vmovd	56(%r8),%xmm5
	vmovd	56(%r9),%xmm0
	vpinsrd	$1,56(%r10),%xmm5,%xmm5
	vpinsrd	$1,56(%r11),%xmm0,%xmm0
	vpunpckldq	%xmm0,%xmm5,%xmm5
	vpshufb	%xmm6,%xmm5,%xmm5
	vpsrld	$6,%xmm14,%xmm7
	vpslld	$26,%xmm14,%xmm2
	vmovdqu	%xmm5,224-128(%rax)
	vpaddd	%xmm9,%xmm5,%xmm5

	vpsrld	$11,%xmm14,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm14,%xmm2
	vpaddd	64(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm14,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm14,%xmm2
	vpandn	%xmm8,%xmm14,%xmm0
	vpand	%xmm15,%xmm14,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm10,%xmm9
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm10,%xmm1
	vpxor	%xmm3,%xmm0,%xmm0
	vpxor	%xmm10,%xmm11,%xmm3

	vpxor	%xmm1,%xmm9,%xmm9
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm10,%xmm1

	vpslld	$19,%xmm10,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm3,%xmm4,%xmm4

	vpxor	%xmm1,%xmm9,%xmm7

	vpsrld	$22,%xmm10,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm10,%xmm2
	vpxor	%xmm4,%xmm11,%xmm9
	vpaddd	%xmm5,%xmm13,%xmm13

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm9,%xmm9
	vpaddd	%xmm7,%xmm9,%xmm9
	vmovd	60(%r8),%xmm5
	leaq	64(%r8),%r8
	vmovd	60(%r9),%xmm0
	leaq	64(%r9),%r9
	vpinsrd	$1,60(%r10),%xmm5,%xmm5
	leaq	64(%r10),%r10
	vpinsrd	$1,60(%r11),%xmm0,%xmm0
	leaq	64(%r11),%r11
	vpunpckldq	%xmm0,%xmm5,%xmm5
	vpshufb	%xmm6,%xmm5,%xmm5
	vpsrld	$6,%xmm13,%xmm7
	vpslld	$26,%xmm13,%xmm2
	vmovdqu	%xmm5,240-128(%rax)
	vpaddd	%xmm8,%xmm5,%xmm5

	vpsrld	$11,%xmm13,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm13,%xmm2
	vpaddd	96(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm13,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	prefetcht0	63(%r8)
	vpslld	$7,%xmm13,%xmm2
	vpandn	%xmm15,%xmm13,%xmm0
	vpand	%xmm14,%xmm13,%xmm4
	prefetcht0	63(%r9)
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm9,%xmm8
	vpxor	%xmm2,%xmm7,%xmm7
	prefetcht0	63(%r10)
	vpslld	$30,%xmm9,%xmm1
	vpxor	%xmm4,%xmm0,%xmm0
	vpxor	%xmm9,%xmm10,%xmm4
	prefetcht0	63(%r11)
	vpxor	%xmm1,%xmm8,%xmm8
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm9,%xmm1

	vpslld	$19,%xmm9,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm4,%xmm3,%xmm3

	vpxor	%xmm1,%xmm8,%xmm7

	vpsrld	$22,%xmm9,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm9,%xmm2
	vpxor	%xmm3,%xmm10,%xmm8
	vpaddd	%xmm5,%xmm12,%xmm12

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm8,%xmm8
	vpaddd	%xmm7,%xmm8,%xmm8
	addq	$256,%rbp
	vmovdqu	0-128(%rax),%xmm5
	movl	$3,%ecx
	jmp	.Loop_16_xx_avx
.align	32
.Loop_16_xx_avx:
	vmovdqu	16-128(%rax),%xmm6
	vpaddd	144-128(%rax),%xmm5,%xmm5

	vpsrld	$3,%xmm6,%xmm7
	vpsrld	$7,%xmm6,%xmm1
	vpslld	$25,%xmm6,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$18,%xmm6,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$14,%xmm6,%xmm2
	vmovdqu	224-128(%rax),%xmm0
	vpsrld	$10,%xmm0,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$17,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$15,%xmm0,%xmm2
	vpaddd	%xmm7,%xmm5,%xmm5
	vpxor	%xmm1,%xmm3,%xmm7
	vpsrld	$19,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$13,%xmm0,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7
	vpaddd	%xmm7,%xmm5,%xmm5
	vpsrld	$6,%xmm12,%xmm7
	vpslld	$26,%xmm12,%xmm2
	vmovdqu	%xmm5,0-128(%rax)
	vpaddd	%xmm15,%xmm5,%xmm5

	vpsrld	$11,%xmm12,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm12,%xmm2
	vpaddd	-128(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm12,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm12,%xmm2
	vpandn	%xmm14,%xmm12,%xmm0
	vpand	%xmm13,%xmm12,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm8,%xmm15
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm8,%xmm1
	vpxor	%xmm3,%xmm0,%xmm0
	vpxor	%xmm8,%xmm9,%xmm3

	vpxor	%xmm1,%xmm15,%xmm15
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm8,%xmm1

	vpslld	$19,%xmm8,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm3,%xmm4,%xmm4

	vpxor	%xmm1,%xmm15,%xmm7

	vpsrld	$22,%xmm8,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm8,%xmm2
	vpxor	%xmm4,%xmm9,%xmm15
	vpaddd	%xmm5,%xmm11,%xmm11

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm15,%xmm15
	vpaddd	%xmm7,%xmm15,%xmm15
	vmovdqu	32-128(%rax),%xmm5
	vpaddd	160-128(%rax),%xmm6,%xmm6

	vpsrld	$3,%xmm5,%xmm7
	vpsrld	$7,%xmm5,%xmm1
	vpslld	$25,%xmm5,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$18,%xmm5,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$14,%xmm5,%xmm2
	vmovdqu	240-128(%rax),%xmm0
	vpsrld	$10,%xmm0,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$17,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$15,%xmm0,%xmm2
	vpaddd	%xmm7,%xmm6,%xmm6
	vpxor	%xmm1,%xmm4,%xmm7
	vpsrld	$19,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$13,%xmm0,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7
	vpaddd	%xmm7,%xmm6,%xmm6
	vpsrld	$6,%xmm11,%xmm7
	vpslld	$26,%xmm11,%xmm2
	vmovdqu	%xmm6,16-128(%rax)
	vpaddd	%xmm14,%xmm6,%xmm6

	vpsrld	$11,%xmm11,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm11,%xmm2
	vpaddd	-96(%rbp),%xmm6,%xmm6
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm11,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm11,%xmm2
	vpandn	%xmm13,%xmm11,%xmm0
	vpand	%xmm12,%xmm11,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm15,%xmm14
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm15,%xmm1
	vpxor	%xmm4,%xmm0,%xmm0
	vpxor	%xmm15,%xmm8,%xmm4

	vpxor	%xmm1,%xmm14,%xmm14
	vpaddd	%xmm7,%xmm6,%xmm6

	vpsrld	$13,%xmm15,%xmm1

	vpslld	$19,%xmm15,%xmm2
	vpaddd	%xmm0,%xmm6,%xmm6
	vpand	%xmm4,%xmm3,%xmm3

	vpxor	%xmm1,%xmm14,%xmm7

	vpsrld	$22,%xmm15,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm15,%xmm2
	vpxor	%xmm3,%xmm8,%xmm14
	vpaddd	%xmm6,%xmm10,%xmm10

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm6,%xmm14,%xmm14
	vpaddd	%xmm7,%xmm14,%xmm14
	vmovdqu	48-128(%rax),%xmm6
	vpaddd	176-128(%rax),%xmm5,%xmm5

	vpsrld	$3,%xmm6,%xmm7
	vpsrld	$7,%xmm6,%xmm1
	vpslld	$25,%xmm6,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$18,%xmm6,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$14,%xmm6,%xmm2
	vmovdqu	0-128(%rax),%xmm0
	vpsrld	$10,%xmm0,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$17,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$15,%xmm0,%xmm2
	vpaddd	%xmm7,%xmm5,%xmm5
	vpxor	%xmm1,%xmm3,%xmm7
	vpsrld	$19,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$13,%xmm0,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7
	vpaddd	%xmm7,%xmm5,%xmm5
	vpsrld	$6,%xmm10,%xmm7
	vpslld	$26,%xmm10,%xmm2
	vmovdqu	%xmm5,32-128(%rax)
	vpaddd	%xmm13,%xmm5,%xmm5

	vpsrld	$11,%xmm10,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm10,%xmm2
	vpaddd	-64(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm10,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm10,%xmm2
	vpandn	%xmm12,%xmm10,%xmm0
	vpand	%xmm11,%xmm10,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm14,%xmm13
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm14,%xmm1
	vpxor	%xmm3,%xmm0,%xmm0
	vpxor	%xmm14,%xmm15,%xmm3

	vpxor	%xmm1,%xmm13,%xmm13
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm14,%xmm1

	vpslld	$19,%xmm14,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm3,%xmm4,%xmm4

	vpxor	%xmm1,%xmm13,%xmm7

	vpsrld	$22,%xmm14,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm14,%xmm2
	vpxor	%xmm4,%xmm15,%xmm13
	vpaddd	%xmm5,%xmm9,%xmm9

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm13,%xmm13
	vpaddd	%xmm7,%xmm13,%xmm13
	vmovdqu	64-128(%rax),%xmm5
	vpaddd	192-128(%rax),%xmm6,%xmm6

	vpsrld	$3,%xmm5,%xmm7
	vpsrld	$7,%xmm5,%xmm1
	vpslld	$25,%xmm5,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$18,%xmm5,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$14,%xmm5,%xmm2
	vmovdqu	16-128(%rax),%xmm0
	vpsrld	$10,%xmm0,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$17,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$15,%xmm0,%xmm2
	vpaddd	%xmm7,%xmm6,%xmm6
	vpxor	%xmm1,%xmm4,%xmm7
	vpsrld	$19,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$13,%xmm0,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7
	vpaddd	%xmm7,%xmm6,%xmm6
	vpsrld	$6,%xmm9,%xmm7
	vpslld	$26,%xmm9,%xmm2
	vmovdqu	%xmm6,48-128(%rax)
	vpaddd	%xmm12,%xmm6,%xmm6

	vpsrld	$11,%xmm9,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm9,%xmm2
	vpaddd	-32(%rbp),%xmm6,%xmm6
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm9,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm9,%xmm2
	vpandn	%xmm11,%xmm9,%xmm0
	vpand	%xmm10,%xmm9,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm13,%xmm12
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm13,%xmm1
	vpxor	%xmm4,%xmm0,%xmm0
	vpxor	%xmm13,%xmm14,%xmm4

	vpxor	%xmm1,%xmm12,%xmm12
	vpaddd	%xmm7,%xmm6,%xmm6

	vpsrld	$13,%xmm13,%xmm1

	vpslld	$19,%xmm13,%xmm2
	vpaddd	%xmm0,%xmm6,%xmm6
	vpand	%xmm4,%xmm3,%xmm3

	vpxor	%xmm1,%xmm12,%xmm7

	vpsrld	$22,%xmm13,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm13,%xmm2
	vpxor	%xmm3,%xmm14,%xmm12
	vpaddd	%xmm6,%xmm8,%xmm8

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm6,%xmm12,%xmm12
	vpaddd	%xmm7,%xmm12,%xmm12
	vmovdqu	80-128(%rax),%xmm6
	vpaddd	208-128(%rax),%xmm5,%xmm5

	vpsrld	$3,%xmm6,%xmm7
	vpsrld	$7,%xmm6,%xmm1
	vpslld	$25,%xmm6,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$18,%xmm6,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$14,%xmm6,%xmm2
	vmovdqu	32-128(%rax),%xmm0
	vpsrld	$10,%xmm0,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$17,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$15,%xmm0,%xmm2
	vpaddd	%xmm7,%xmm5,%xmm5
	vpxor	%xmm1,%xmm3,%xmm7
	vpsrld	$19,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$13,%xmm0,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7
	vpaddd	%xmm7,%xmm5,%xmm5
	vpsrld	$6,%xmm8,%xmm7
	vpslld	$26,%xmm8,%xmm2
	vmovdqu	%xmm5,64-128(%rax)
	vpaddd	%xmm11,%xmm5,%xmm5

	vpsrld	$11,%xmm8,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm8,%xmm2
	vpaddd	0(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm8,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm8,%xmm2
	vpandn	%xmm10,%xmm8,%xmm0
	vpand	%xmm9,%xmm8,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm12,%xmm11
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm12,%xmm1
	vpxor	%xmm3,%xmm0,%xmm0
	vpxor	%xmm12,%xmm13,%xmm3

	vpxor	%xmm1,%xmm11,%xmm11
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm12,%xmm1

	vpslld	$19,%xmm12,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm3,%xmm4,%xmm4

	vpxor	%xmm1,%xmm11,%xmm7

	vpsrld	$22,%xmm12,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm12,%xmm2
	vpxor	%xmm4,%xmm13,%xmm11
	vpaddd	%xmm5,%xmm15,%xmm15

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm11,%xmm11
	vpaddd	%xmm7,%xmm11,%xmm11
	vmovdqu	96-128(%rax),%xmm5
	vpaddd	224-128(%rax),%xmm6,%xmm6

	vpsrld	$3,%xmm5,%xmm7
	vpsrld	$7,%xmm5,%xmm1
	vpslld	$25,%xmm5,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$18,%xmm5,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$14,%xmm5,%xmm2
	vmovdqu	48-128(%rax),%xmm0
	vpsrld	$10,%xmm0,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$17,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$15,%xmm0,%xmm2
	vpaddd	%xmm7,%xmm6,%xmm6
	vpxor	%xmm1,%xmm4,%xmm7
	vpsrld	$19,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$13,%xmm0,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7
	vpaddd	%xmm7,%xmm6,%xmm6
	vpsrld	$6,%xmm15,%xmm7
	vpslld	$26,%xmm15,%xmm2
	vmovdqu	%xmm6,80-128(%rax)
	vpaddd	%xmm10,%xmm6,%xmm6

	vpsrld	$11,%xmm15,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm15,%xmm2
	vpaddd	32(%rbp),%xmm6,%xmm6
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm15,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm15,%xmm2
	vpandn	%xmm9,%xmm15,%xmm0
	vpand	%xmm8,%xmm15,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm11,%xmm10
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm11,%xmm1
	vpxor	%xmm4,%xmm0,%xmm0
	vpxor	%xmm11,%xmm12,%xmm4

	vpxor	%xmm1,%xmm10,%xmm10
	vpaddd	%xmm7,%xmm6,%xmm6

	vpsrld	$13,%xmm11,%xmm1

	vpslld	$19,%xmm11,%xmm2
	vpaddd	%xmm0,%xmm6,%xmm6
	vpand	%xmm4,%xmm3,%xmm3

	vpxor	%xmm1,%xmm10,%xmm7

	vpsrld	$22,%xmm11,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm11,%xmm2
	vpxor	%xmm3,%xmm12,%xmm10
	vpaddd	%xmm6,%xmm14,%xmm14

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm6,%xmm10,%xmm10
	vpaddd	%xmm7,%xmm10,%xmm10
	vmovdqu	112-128(%rax),%xmm6
	vpaddd	240-128(%rax),%xmm5,%xmm5

	vpsrld	$3,%xmm6,%xmm7
	vpsrld	$7,%xmm6,%xmm1
	vpslld	$25,%xmm6,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$18,%xmm6,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$14,%xmm6,%xmm2
	vmovdqu	64-128(%rax),%xmm0
	vpsrld	$10,%xmm0,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$17,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$15,%xmm0,%xmm2
	vpaddd	%xmm7,%xmm5,%xmm5
	vpxor	%xmm1,%xmm3,%xmm7
	vpsrld	$19,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$13,%xmm0,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7
	vpaddd	%xmm7,%xmm5,%xmm5
	vpsrld	$6,%xmm14,%xmm7
	vpslld	$26,%xmm14,%xmm2
	vmovdqu	%xmm5,96-128(%rax)
	vpaddd	%xmm9,%xmm5,%xmm5

	vpsrld	$11,%xmm14,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm14,%xmm2
	vpaddd	64(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm14,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm14,%xmm2
	vpandn	%xmm8,%xmm14,%xmm0
	vpand	%xmm15,%xmm14,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm10,%xmm9
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm10,%xmm1
	vpxor	%xmm3,%xmm0,%xmm0
	vpxor	%xmm10,%xmm11,%xmm3

	vpxor	%xmm1,%xmm9,%xmm9
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm10,%xmm1

	vpslld	$19,%xmm10,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm3,%xmm4,%xmm4

	vpxor	%xmm1,%xmm9,%xmm7

	vpsrld	$22,%xmm10,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm10,%xmm2
	vpxor	%xmm4,%xmm11,%xmm9
	vpaddd	%xmm5,%xmm13,%xmm13

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm9,%xmm9
	vpaddd	%xmm7,%xmm9,%xmm9
	vmovdqu	128-128(%rax),%xmm5
	vpaddd	0-128(%rax),%xmm6,%xmm6

	vpsrld	$3,%xmm5,%xmm7
	vpsrld	$7,%xmm5,%xmm1
	vpslld	$25,%xmm5,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$18,%xmm5,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$14,%xmm5,%xmm2
	vmovdqu	80-128(%rax),%xmm0
	vpsrld	$10,%xmm0,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$17,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$15,%xmm0,%xmm2
	vpaddd	%xmm7,%xmm6,%xmm6
	vpxor	%xmm1,%xmm4,%xmm7
	vpsrld	$19,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$13,%xmm0,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7
	vpaddd	%xmm7,%xmm6,%xmm6
	vpsrld	$6,%xmm13,%xmm7
	vpslld	$26,%xmm13,%xmm2
	vmovdqu	%xmm6,112-128(%rax)
	vpaddd	%xmm8,%xmm6,%xmm6

	vpsrld	$11,%xmm13,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm13,%xmm2
	vpaddd	96(%rbp),%xmm6,%xmm6
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm13,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm13,%xmm2
	vpandn	%xmm15,%xmm13,%xmm0
	vpand	%xmm14,%xmm13,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm9,%xmm8
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm9,%xmm1
	vpxor	%xmm4,%xmm0,%xmm0
	vpxor	%xmm9,%xmm10,%xmm4

	vpxor	%xmm1,%xmm8,%xmm8
	vpaddd	%xmm7,%xmm6,%xmm6

	vpsrld	$13,%xmm9,%xmm1

	vpslld	$19,%xmm9,%xmm2
	vpaddd	%xmm0,%xmm6,%xmm6
	vpand	%xmm4,%xmm3,%xmm3

	vpxor	%xmm1,%xmm8,%xmm7

	vpsrld	$22,%xmm9,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm9,%xmm2
	vpxor	%xmm3,%xmm10,%xmm8
	vpaddd	%xmm6,%xmm12,%xmm12

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm6,%xmm8,%xmm8
	vpaddd	%xmm7,%xmm8,%xmm8
	addq	$256,%rbp
	vmovdqu	144-128(%rax),%xmm6
	vpaddd	16-128(%rax),%xmm5,%xmm5

	vpsrld	$3,%xmm6,%xmm7
	vpsrld	$7,%xmm6,%xmm1
	vpslld	$25,%xmm6,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$18,%xmm6,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$14,%xmm6,%xmm2
	vmovdqu	96-128(%rax),%xmm0
	vpsrld	$10,%xmm0,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$17,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$15,%xmm0,%xmm2
	vpaddd	%xmm7,%xmm5,%xmm5
	vpxor	%xmm1,%xmm3,%xmm7
	vpsrld	$19,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$13,%xmm0,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7
	vpaddd	%xmm7,%xmm5,%xmm5
	vpsrld	$6,%xmm12,%xmm7
	vpslld	$26,%xmm12,%xmm2
	vmovdqu	%xmm5,128-128(%rax)
	vpaddd	%xmm15,%xmm5,%xmm5

	vpsrld	$11,%xmm12,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm12,%xmm2
	vpaddd	-128(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm12,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm12,%xmm2
	vpandn	%xmm14,%xmm12,%xmm0
	vpand	%xmm13,%xmm12,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm8,%xmm15
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm8,%xmm1
	vpxor	%xmm3,%xmm0,%xmm0
	vpxor	%xmm8,%xmm9,%xmm3

	vpxor	%xmm1,%xmm15,%xmm15
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm8,%xmm1

	vpslld	$19,%xmm8,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm3,%xmm4,%xmm4

	vpxor	%xmm1,%xmm15,%xmm7

	vpsrld	$22,%xmm8,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm8,%xmm2
	vpxor	%xmm4,%xmm9,%xmm15
	vpaddd	%xmm5,%xmm11,%xmm11

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm15,%xmm15
	vpaddd	%xmm7,%xmm15,%xmm15
	vmovdqu	160-128(%rax),%xmm5
	vpaddd	32-128(%rax),%xmm6,%xmm6

	vpsrld	$3,%xmm5,%xmm7
	vpsrld	$7,%xmm5,%xmm1
	vpslld	$25,%xmm5,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$18,%xmm5,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$14,%xmm5,%xmm2
	vmovdqu	112-128(%rax),%xmm0
	vpsrld	$10,%xmm0,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$17,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$15,%xmm0,%xmm2
	vpaddd	%xmm7,%xmm6,%xmm6
	vpxor	%xmm1,%xmm4,%xmm7
	vpsrld	$19,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$13,%xmm0,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7
	vpaddd	%xmm7,%xmm6,%xmm6
	vpsrld	$6,%xmm11,%xmm7
	vpslld	$26,%xmm11,%xmm2
	vmovdqu	%xmm6,144-128(%rax)
	vpaddd	%xmm14,%xmm6,%xmm6

	vpsrld	$11,%xmm11,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm11,%xmm2
	vpaddd	-96(%rbp),%xmm6,%xmm6
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm11,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm11,%xmm2
	vpandn	%xmm13,%xmm11,%xmm0
	vpand	%xmm12,%xmm11,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm15,%xmm14
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm15,%xmm1
	vpxor	%xmm4,%xmm0,%xmm0
	vpxor	%xmm15,%xmm8,%xmm4

	vpxor	%xmm1,%xmm14,%xmm14
	vpaddd	%xmm7,%xmm6,%xmm6

	vpsrld	$13,%xmm15,%xmm1

	vpslld	$19,%xmm15,%xmm2
	vpaddd	%xmm0,%xmm6,%xmm6
	vpand	%xmm4,%xmm3,%xmm3

	vpxor	%xmm1,%xmm14,%xmm7

	vpsrld	$22,%xmm15,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm15,%xmm2
	vpxor	%xmm3,%xmm8,%xmm14
	vpaddd	%xmm6,%xmm10,%xmm10

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm6,%xmm14,%xmm14
	vpaddd	%xmm7,%xmm14,%xmm14
	vmovdqu	176-128(%rax),%xmm6
	vpaddd	48-128(%rax),%xmm5,%xmm5

	vpsrld	$3,%xmm6,%xmm7
	vpsrld	$7,%xmm6,%xmm1
	vpslld	$25,%xmm6,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$18,%xmm6,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$14,%xmm6,%xmm2
	vmovdqu	128-128(%rax),%xmm0
	vpsrld	$10,%xmm0,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$17,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$15,%xmm0,%xmm2
	vpaddd	%xmm7,%xmm5,%xmm5
	vpxor	%xmm1,%xmm3,%xmm7
	vpsrld	$19,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$13,%xmm0,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7
	vpaddd	%xmm7,%xmm5,%xmm5
	vpsrld	$6,%xmm10,%xmm7
	vpslld	$26,%xmm10,%xmm2
	vmovdqu	%xmm5,160-128(%rax)
	vpaddd	%xmm13,%xmm5,%xmm5

	vpsrld	$11,%xmm10,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm10,%xmm2
	vpaddd	-64(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm10,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm10,%xmm2
	vpandn	%xmm12,%xmm10,%xmm0
	vpand	%xmm11,%xmm10,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm14,%xmm13
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm14,%xmm1
	vpxor	%xmm3,%xmm0,%xmm0
	vpxor	%xmm14,%xmm15,%xmm3

	vpxor	%xmm1,%xmm13,%xmm13
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm14,%xmm1

	vpslld	$19,%xmm14,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm3,%xmm4,%xmm4

	vpxor	%xmm1,%xmm13,%xmm7

	vpsrld	$22,%xmm14,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm14,%xmm2
	vpxor	%xmm4,%xmm15,%xmm13
	vpaddd	%xmm5,%xmm9,%xmm9

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm13,%xmm13
	vpaddd	%xmm7,%xmm13,%xmm13
	vmovdqu	192-128(%rax),%xmm5
	vpaddd	64-128(%rax),%xmm6,%xmm6

	vpsrld	$3,%xmm5,%xmm7
	vpsrld	$7,%xmm5,%xmm1
	vpslld	$25,%xmm5,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$18,%xmm5,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$14,%xmm5,%xmm2
	vmovdqu	144-128(%rax),%xmm0
	vpsrld	$10,%xmm0,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$17,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$15,%xmm0,%xmm2
	vpaddd	%xmm7,%xmm6,%xmm6
	vpxor	%xmm1,%xmm4,%xmm7
	vpsrld	$19,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$13,%xmm0,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7
	vpaddd	%xmm7,%xmm6,%xmm6
	vpsrld	$6,%xmm9,%xmm7
	vpslld	$26,%xmm9,%xmm2
	vmovdqu	%xmm6,176-128(%rax)
	vpaddd	%xmm12,%xmm6,%xmm6

	vpsrld	$11,%xmm9,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm9,%xmm2
	vpaddd	-32(%rbp),%xmm6,%xmm6
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm9,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm9,%xmm2
	vpandn	%xmm11,%xmm9,%xmm0
	vpand	%xmm10,%xmm9,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm13,%xmm12
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm13,%xmm1
	vpxor	%xmm4,%xmm0,%xmm0
	vpxor	%xmm13,%xmm14,%xmm4

	vpxor	%xmm1,%xmm12,%xmm12
	vpaddd	%xmm7,%xmm6,%xmm6

	vpsrld	$13,%xmm13,%xmm1

	vpslld	$19,%xmm13,%xmm2
	vpaddd	%xmm0,%xmm6,%xmm6
	vpand	%xmm4,%xmm3,%xmm3

	vpxor	%xmm1,%xmm12,%xmm7

	vpsrld	$22,%xmm13,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm13,%xmm2
	vpxor	%xmm3,%xmm14,%xmm12
	vpaddd	%xmm6,%xmm8,%xmm8

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm6,%xmm12,%xmm12
	vpaddd	%xmm7,%xmm12,%xmm12
	vmovdqu	208-128(%rax),%xmm6
	vpaddd	80-128(%rax),%xmm5,%xmm5

	vpsrld	$3,%xmm6,%xmm7
	vpsrld	$7,%xmm6,%xmm1
	vpslld	$25,%xmm6,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$18,%xmm6,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$14,%xmm6,%xmm2
	vmovdqu	160-128(%rax),%xmm0
	vpsrld	$10,%xmm0,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$17,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$15,%xmm0,%xmm2
	vpaddd	%xmm7,%xmm5,%xmm5
	vpxor	%xmm1,%xmm3,%xmm7
	vpsrld	$19,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$13,%xmm0,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7
	vpaddd	%xmm7,%xmm5,%xmm5
	vpsrld	$6,%xmm8,%xmm7
	vpslld	$26,%xmm8,%xmm2
	vmovdqu	%xmm5,192-128(%rax)
	vpaddd	%xmm11,%xmm5,%xmm5

	vpsrld	$11,%xmm8,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm8,%xmm2
	vpaddd	0(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm8,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm8,%xmm2
	vpandn	%xmm10,%xmm8,%xmm0
	vpand	%xmm9,%xmm8,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm12,%xmm11
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm12,%xmm1
	vpxor	%xmm3,%xmm0,%xmm0
	vpxor	%xmm12,%xmm13,%xmm3

	vpxor	%xmm1,%xmm11,%xmm11
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm12,%xmm1

	vpslld	$19,%xmm12,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm3,%xmm4,%xmm4

	vpxor	%xmm1,%xmm11,%xmm7

	vpsrld	$22,%xmm12,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm12,%xmm2
	vpxor	%xmm4,%xmm13,%xmm11
	vpaddd	%xmm5,%xmm15,%xmm15

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm11,%xmm11
	vpaddd	%xmm7,%xmm11,%xmm11
	vmovdqu	224-128(%rax),%xmm5
	vpaddd	96-128(%rax),%xmm6,%xmm6

	vpsrld	$3,%xmm5,%xmm7
	vpsrld	$7,%xmm5,%xmm1
	vpslld	$25,%xmm5,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$18,%xmm5,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$14,%xmm5,%xmm2
	vmovdqu	176-128(%rax),%xmm0
	vpsrld	$10,%xmm0,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$17,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$15,%xmm0,%xmm2
	vpaddd	%xmm7,%xmm6,%xmm6
	vpxor	%xmm1,%xmm4,%xmm7
	vpsrld	$19,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$13,%xmm0,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7
	vpaddd	%xmm7,%xmm6,%xmm6
	vpsrld	$6,%xmm15,%xmm7
	vpslld	$26,%xmm15,%xmm2
	vmovdqu	%xmm6,208-128(%rax)
	vpaddd	%xmm10,%xmm6,%xmm6

	vpsrld	$11,%xmm15,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm15,%xmm2
	vpaddd	32(%rbp),%xmm6,%xmm6
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm15,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm15,%xmm2
	vpandn	%xmm9,%xmm15,%xmm0
	vpand	%xmm8,%xmm15,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm11,%xmm10
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm11,%xmm1
	vpxor	%xmm4,%xmm0,%xmm0
	vpxor	%xmm11,%xmm12,%xmm4

	vpxor	%xmm1,%xmm10,%xmm10
	vpaddd	%xmm7,%xmm6,%xmm6

	vpsrld	$13,%xmm11,%xmm1

	vpslld	$19,%xmm11,%xmm2
	vpaddd	%xmm0,%xmm6,%xmm6
	vpand	%xmm4,%xmm3,%xmm3

	vpxor	%xmm1,%xmm10,%xmm7

	vpsrld	$22,%xmm11,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm11,%xmm2
	vpxor	%xmm3,%xmm12,%xmm10
	vpaddd	%xmm6,%xmm14,%xmm14

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm6,%xmm10,%xmm10
	vpaddd	%xmm7,%xmm10,%xmm10
	vmovdqu	240-128(%rax),%xmm6
	vpaddd	112-128(%rax),%xmm5,%xmm5

	vpsrld	$3,%xmm6,%xmm7
	vpsrld	$7,%xmm6,%xmm1
	vpslld	$25,%xmm6,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$18,%xmm6,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$14,%xmm6,%xmm2
	vmovdqu	192-128(%rax),%xmm0
	vpsrld	$10,%xmm0,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$17,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$15,%xmm0,%xmm2
	vpaddd	%xmm7,%xmm5,%xmm5
	vpxor	%xmm1,%xmm3,%xmm7
	vpsrld	$19,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$13,%xmm0,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7
	vpaddd	%xmm7,%xmm5,%xmm5
	vpsrld	$6,%xmm14,%xmm7
	vpslld	$26,%xmm14,%xmm2
	vmovdqu	%xmm5,224-128(%rax)
	vpaddd	%xmm9,%xmm5,%xmm5

	vpsrld	$11,%xmm14,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm14,%xmm2
	vpaddd	64(%rbp),%xmm5,%xmm5
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm14,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm14,%xmm2
	vpandn	%xmm8,%xmm14,%xmm0
	vpand	%xmm15,%xmm14,%xmm3

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm10,%xmm9
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm10,%xmm1
	vpxor	%xmm3,%xmm0,%xmm0
	vpxor	%xmm10,%xmm11,%xmm3

	vpxor	%xmm1,%xmm9,%xmm9
	vpaddd	%xmm7,%xmm5,%xmm5

	vpsrld	$13,%xmm10,%xmm1

	vpslld	$19,%xmm10,%xmm2
	vpaddd	%xmm0,%xmm5,%xmm5
	vpand	%xmm3,%xmm4,%xmm4

	vpxor	%xmm1,%xmm9,%xmm7

	vpsrld	$22,%xmm10,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm10,%xmm2
	vpxor	%xmm4,%xmm11,%xmm9
	vpaddd	%xmm5,%xmm13,%xmm13

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm5,%xmm9,%xmm9
	vpaddd	%xmm7,%xmm9,%xmm9
	vmovdqu	0-128(%rax),%xmm5
	vpaddd	128-128(%rax),%xmm6,%xmm6

	vpsrld	$3,%xmm5,%xmm7
	vpsrld	$7,%xmm5,%xmm1
	vpslld	$25,%xmm5,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$18,%xmm5,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$14,%xmm5,%xmm2
	vmovdqu	208-128(%rax),%xmm0
	vpsrld	$10,%xmm0,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7
	vpsrld	$17,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$15,%xmm0,%xmm2
	vpaddd	%xmm7,%xmm6,%xmm6
	vpxor	%xmm1,%xmm4,%xmm7
	vpsrld	$19,%xmm0,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$13,%xmm0,%xmm2
	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7
	vpaddd	%xmm7,%xmm6,%xmm6
	vpsrld	$6,%xmm13,%xmm7
	vpslld	$26,%xmm13,%xmm2
	vmovdqu	%xmm6,240-128(%rax)
	vpaddd	%xmm8,%xmm6,%xmm6

	vpsrld	$11,%xmm13,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7
	vpslld	$21,%xmm13,%xmm2
	vpaddd	96(%rbp),%xmm6,%xmm6
	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$25,%xmm13,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$7,%xmm13,%xmm2
	vpandn	%xmm15,%xmm13,%xmm0
	vpand	%xmm14,%xmm13,%xmm4

	vpxor	%xmm1,%xmm7,%xmm7

	vpsrld	$2,%xmm9,%xmm8
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$30,%xmm9,%xmm1
	vpxor	%xmm4,%xmm0,%xmm0
	vpxor	%xmm9,%xmm10,%xmm4

	vpxor	%xmm1,%xmm8,%xmm8
	vpaddd	%xmm7,%xmm6,%xmm6

	vpsrld	$13,%xmm9,%xmm1

	vpslld	$19,%xmm9,%xmm2
	vpaddd	%xmm0,%xmm6,%xmm6
	vpand	%xmm4,%xmm3,%xmm3

	vpxor	%xmm1,%xmm8,%xmm7

	vpsrld	$22,%xmm9,%xmm1
	vpxor	%xmm2,%xmm7,%xmm7

	vpslld	$10,%xmm9,%xmm2
	vpxor	%xmm3,%xmm10,%xmm8
	vpaddd	%xmm6,%xmm12,%xmm12

	vpxor	%xmm1,%xmm7,%xmm7
	vpxor	%xmm2,%xmm7,%xmm7

	vpaddd	%xmm6,%xmm8,%xmm8
	vpaddd	%xmm7,%xmm8,%xmm8
	addq	$256,%rbp
	decl	%ecx
	jnz	.Loop_16_xx_avx

	movl	$1,%ecx
	leaq	K256+128(%rip),%rbp
	cmpl	0(%rbx),%ecx
	cmovgeq	%rbp,%r8
	cmpl	4(%rbx),%ecx
	cmovgeq	%rbp,%r9
	cmpl	8(%rbx),%ecx
	cmovgeq	%rbp,%r10
	cmpl	12(%rbx),%ecx
	cmovgeq	%rbp,%r11
	vmovdqa	(%rbx),%xmm7
	vpxor	%xmm0,%xmm0,%xmm0
	vmovdqa	%xmm7,%xmm6
	vpcmpgtd	%xmm0,%xmm6,%xmm6
	vpaddd	%xmm6,%xmm7,%xmm7

	vmovdqu	0-128(%rdi),%xmm0
	vpand	%xmm6,%xmm8,%xmm8
	vmovdqu	32-128(%rdi),%xmm1
	vpand	%xmm6,%xmm9,%xmm9
	vmovdqu	64-128(%rdi),%xmm2
	vpand	%xmm6,%xmm10,%xmm10
	vmovdqu	96-128(%rdi),%xmm5
	vpand	%xmm6,%xmm11,%xmm11
	vpaddd	%xmm0,%xmm8,%xmm8
	vmovdqu	128-128(%rdi),%xmm0
	vpand	%xmm6,%xmm12,%xmm12
	vpaddd	%xmm1,%xmm9,%xmm9
	vmovdqu	160-128(%rdi),%xmm1
	vpand	%xmm6,%xmm13,%xmm13
	vpaddd	%xmm2,%xmm10,%xmm10
	vmovdqu	192-128(%rdi),%xmm2
	vpand	%xmm6,%xmm14,%xmm14
	vpaddd	%xmm5,%xmm11,%xmm11
	vmovdqu	224-128(%rdi),%xmm5
	vpand	%xmm6,%xmm15,%xmm15
	vpaddd	%xmm0,%xmm12,%xmm12
	vpaddd	%xmm1,%xmm13,%xmm13
	vmovdqu	%xmm8,0-128(%rdi)
	vpaddd	%xmm2,%xmm14,%xmm14
	vmovdqu	%xmm9,32-128(%rdi)
	vpaddd	%xmm5,%xmm15,%xmm15
	vmovdqu	%xmm10,64-128(%rdi)
	vmovdqu	%xmm11,96-128(%rdi)
	vmovdqu	%xmm12,128-128(%rdi)
	vmovdqu	%xmm13,160-128(%rdi)
	vmovdqu	%xmm14,192-128(%rdi)
	vmovdqu	%xmm15,224-128(%rdi)

	vmovdqu	%xmm7,(%rbx)
	vmovdqu	.Lpbswap(%rip),%xmm6
	decl	%edx
	jnz	.Loop_avx

	movl	280(%rsp),%edx
	leaq	16(%rdi),%rdi
	leaq	64(%rsi),%rsi
	decl	%edx
	jnz	.Loop_grande_avx

.Ldone_avx:
	movq	272(%rsp),%rax
.cfi_def_cfa	%rax,8
	vzeroupper
	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue_avx:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha256_multi_block_avx,.-sha256_multi_block_avx
.type	sha256_multi_block_avx2,@function
.align	32
sha256_multi_block_avx2:
.cfi_startproc	
_avx2_shortcut:
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
	subq	$576,%rsp
	andq	$-256,%rsp
	movq	%rax,544(%rsp)
.cfi_escape	0x0f,0x06,0x77,0xa0,0x04,0x06,0x23,0x08
.Lbody_avx2:
	leaq	K256+128(%rip),%rbp
	leaq	128(%rdi),%rdi

.Loop_grande_avx2:
	movl	%edx,552(%rsp)
	xorl	%edx,%edx
	leaq	512(%rsp),%rbx

	movq	0(%rsi),%r12

	movl	8(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,0(%rbx)
	cmovleq	%rbp,%r12

	movq	16(%rsi),%r13

	movl	24(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,4(%rbx)
	cmovleq	%rbp,%r13

	movq	32(%rsi),%r14

	movl	40(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,8(%rbx)
	cmovleq	%rbp,%r14

	movq	48(%rsi),%r15

	movl	56(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,12(%rbx)
	cmovleq	%rbp,%r15

	movq	64(%rsi),%r8

	movl	72(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,16(%rbx)
	cmovleq	%rbp,%r8

	movq	80(%rsi),%r9

	movl	88(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,20(%rbx)
	cmovleq	%rbp,%r9

	movq	96(%rsi),%r10

	movl	104(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,24(%rbx)
	cmovleq	%rbp,%r10

	movq	112(%rsi),%r11

	movl	120(%rsi),%ecx
	cmpl	%edx,%ecx
	cmovgl	%ecx,%edx
	testl	%ecx,%ecx
	movl	%ecx,28(%rbx)
	cmovleq	%rbp,%r11
	vmovdqu	0-128(%rdi),%ymm8
	leaq	128(%rsp),%rax
	vmovdqu	32-128(%rdi),%ymm9
	leaq	256+128(%rsp),%rbx
	vmovdqu	64-128(%rdi),%ymm10
	vmovdqu	96-128(%rdi),%ymm11
	vmovdqu	128-128(%rdi),%ymm12
	vmovdqu	160-128(%rdi),%ymm13
	vmovdqu	192-128(%rdi),%ymm14
	vmovdqu	224-128(%rdi),%ymm15
	vmovdqu	.Lpbswap(%rip),%ymm6
	jmp	.Loop_avx2

.align	32
.Loop_avx2:
	vpxor	%ymm9,%ymm10,%ymm4
	vmovd	0(%r12),%xmm5
	vmovd	0(%r8),%xmm0
	vmovd	0(%r13),%xmm1
	vmovd	0(%r9),%xmm2
	vpinsrd	$1,0(%r14),%xmm5,%xmm5
	vpinsrd	$1,0(%r10),%xmm0,%xmm0
	vpinsrd	$1,0(%r15),%xmm1,%xmm1
	vpunpckldq	%ymm1,%ymm5,%ymm5
	vpinsrd	$1,0(%r11),%xmm2,%xmm2
	vpunpckldq	%ymm2,%ymm0,%ymm0
	vinserti128	$1,%xmm0,%ymm5,%ymm5
	vpshufb	%ymm6,%ymm5,%ymm5
	vpsrld	$6,%ymm12,%ymm7
	vpslld	$26,%ymm12,%ymm2
	vmovdqu	%ymm5,0-128(%rax)
	vpaddd	%ymm15,%ymm5,%ymm5

	vpsrld	$11,%ymm12,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm12,%ymm2
	vpaddd	-128(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm12,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm12,%ymm2
	vpandn	%ymm14,%ymm12,%ymm0
	vpand	%ymm13,%ymm12,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm8,%ymm15
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm8,%ymm1
	vpxor	%ymm3,%ymm0,%ymm0
	vpxor	%ymm8,%ymm9,%ymm3

	vpxor	%ymm1,%ymm15,%ymm15
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm8,%ymm1

	vpslld	$19,%ymm8,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm3,%ymm4,%ymm4

	vpxor	%ymm1,%ymm15,%ymm7

	vpsrld	$22,%ymm8,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm8,%ymm2
	vpxor	%ymm4,%ymm9,%ymm15
	vpaddd	%ymm5,%ymm11,%ymm11

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm15,%ymm15
	vpaddd	%ymm7,%ymm15,%ymm15
	vmovd	4(%r12),%xmm5
	vmovd	4(%r8),%xmm0
	vmovd	4(%r13),%xmm1
	vmovd	4(%r9),%xmm2
	vpinsrd	$1,4(%r14),%xmm5,%xmm5
	vpinsrd	$1,4(%r10),%xmm0,%xmm0
	vpinsrd	$1,4(%r15),%xmm1,%xmm1
	vpunpckldq	%ymm1,%ymm5,%ymm5
	vpinsrd	$1,4(%r11),%xmm2,%xmm2
	vpunpckldq	%ymm2,%ymm0,%ymm0
	vinserti128	$1,%xmm0,%ymm5,%ymm5
	vpshufb	%ymm6,%ymm5,%ymm5
	vpsrld	$6,%ymm11,%ymm7
	vpslld	$26,%ymm11,%ymm2
	vmovdqu	%ymm5,32-128(%rax)
	vpaddd	%ymm14,%ymm5,%ymm5

	vpsrld	$11,%ymm11,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm11,%ymm2
	vpaddd	-96(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm11,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm11,%ymm2
	vpandn	%ymm13,%ymm11,%ymm0
	vpand	%ymm12,%ymm11,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm15,%ymm14
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm15,%ymm1
	vpxor	%ymm4,%ymm0,%ymm0
	vpxor	%ymm15,%ymm8,%ymm4

	vpxor	%ymm1,%ymm14,%ymm14
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm15,%ymm1

	vpslld	$19,%ymm15,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm4,%ymm3,%ymm3

	vpxor	%ymm1,%ymm14,%ymm7

	vpsrld	$22,%ymm15,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm15,%ymm2
	vpxor	%ymm3,%ymm8,%ymm14
	vpaddd	%ymm5,%ymm10,%ymm10

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm14,%ymm14
	vpaddd	%ymm7,%ymm14,%ymm14
	vmovd	8(%r12),%xmm5
	vmovd	8(%r8),%xmm0
	vmovd	8(%r13),%xmm1
	vmovd	8(%r9),%xmm2
	vpinsrd	$1,8(%r14),%xmm5,%xmm5
	vpinsrd	$1,8(%r10),%xmm0,%xmm0
	vpinsrd	$1,8(%r15),%xmm1,%xmm1
	vpunpckldq	%ymm1,%ymm5,%ymm5
	vpinsrd	$1,8(%r11),%xmm2,%xmm2
	vpunpckldq	%ymm2,%ymm0,%ymm0
	vinserti128	$1,%xmm0,%ymm5,%ymm5
	vpshufb	%ymm6,%ymm5,%ymm5
	vpsrld	$6,%ymm10,%ymm7
	vpslld	$26,%ymm10,%ymm2
	vmovdqu	%ymm5,64-128(%rax)
	vpaddd	%ymm13,%ymm5,%ymm5

	vpsrld	$11,%ymm10,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm10,%ymm2
	vpaddd	-64(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm10,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm10,%ymm2
	vpandn	%ymm12,%ymm10,%ymm0
	vpand	%ymm11,%ymm10,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm14,%ymm13
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm14,%ymm1
	vpxor	%ymm3,%ymm0,%ymm0
	vpxor	%ymm14,%ymm15,%ymm3

	vpxor	%ymm1,%ymm13,%ymm13
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm14,%ymm1

	vpslld	$19,%ymm14,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm3,%ymm4,%ymm4

	vpxor	%ymm1,%ymm13,%ymm7

	vpsrld	$22,%ymm14,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm14,%ymm2
	vpxor	%ymm4,%ymm15,%ymm13
	vpaddd	%ymm5,%ymm9,%ymm9

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm13,%ymm13
	vpaddd	%ymm7,%ymm13,%ymm13
	vmovd	12(%r12),%xmm5
	vmovd	12(%r8),%xmm0
	vmovd	12(%r13),%xmm1
	vmovd	12(%r9),%xmm2
	vpinsrd	$1,12(%r14),%xmm5,%xmm5
	vpinsrd	$1,12(%r10),%xmm0,%xmm0
	vpinsrd	$1,12(%r15),%xmm1,%xmm1
	vpunpckldq	%ymm1,%ymm5,%ymm5
	vpinsrd	$1,12(%r11),%xmm2,%xmm2
	vpunpckldq	%ymm2,%ymm0,%ymm0
	vinserti128	$1,%xmm0,%ymm5,%ymm5
	vpshufb	%ymm6,%ymm5,%ymm5
	vpsrld	$6,%ymm9,%ymm7
	vpslld	$26,%ymm9,%ymm2
	vmovdqu	%ymm5,96-128(%rax)
	vpaddd	%ymm12,%ymm5,%ymm5

	vpsrld	$11,%ymm9,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm9,%ymm2
	vpaddd	-32(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm9,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm9,%ymm2
	vpandn	%ymm11,%ymm9,%ymm0
	vpand	%ymm10,%ymm9,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm13,%ymm12
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm13,%ymm1
	vpxor	%ymm4,%ymm0,%ymm0
	vpxor	%ymm13,%ymm14,%ymm4

	vpxor	%ymm1,%ymm12,%ymm12
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm13,%ymm1

	vpslld	$19,%ymm13,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm4,%ymm3,%ymm3

	vpxor	%ymm1,%ymm12,%ymm7

	vpsrld	$22,%ymm13,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm13,%ymm2
	vpxor	%ymm3,%ymm14,%ymm12
	vpaddd	%ymm5,%ymm8,%ymm8

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm12,%ymm12
	vpaddd	%ymm7,%ymm12,%ymm12
	vmovd	16(%r12),%xmm5
	vmovd	16(%r8),%xmm0
	vmovd	16(%r13),%xmm1
	vmovd	16(%r9),%xmm2
	vpinsrd	$1,16(%r14),%xmm5,%xmm5
	vpinsrd	$1,16(%r10),%xmm0,%xmm0
	vpinsrd	$1,16(%r15),%xmm1,%xmm1
	vpunpckldq	%ymm1,%ymm5,%ymm5
	vpinsrd	$1,16(%r11),%xmm2,%xmm2
	vpunpckldq	%ymm2,%ymm0,%ymm0
	vinserti128	$1,%xmm0,%ymm5,%ymm5
	vpshufb	%ymm6,%ymm5,%ymm5
	vpsrld	$6,%ymm8,%ymm7
	vpslld	$26,%ymm8,%ymm2
	vmovdqu	%ymm5,128-128(%rax)
	vpaddd	%ymm11,%ymm5,%ymm5

	vpsrld	$11,%ymm8,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm8,%ymm2
	vpaddd	0(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm8,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm8,%ymm2
	vpandn	%ymm10,%ymm8,%ymm0
	vpand	%ymm9,%ymm8,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm12,%ymm11
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm12,%ymm1
	vpxor	%ymm3,%ymm0,%ymm0
	vpxor	%ymm12,%ymm13,%ymm3

	vpxor	%ymm1,%ymm11,%ymm11
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm12,%ymm1

	vpslld	$19,%ymm12,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm3,%ymm4,%ymm4

	vpxor	%ymm1,%ymm11,%ymm7

	vpsrld	$22,%ymm12,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm12,%ymm2
	vpxor	%ymm4,%ymm13,%ymm11
	vpaddd	%ymm5,%ymm15,%ymm15

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm11,%ymm11
	vpaddd	%ymm7,%ymm11,%ymm11
	vmovd	20(%r12),%xmm5
	vmovd	20(%r8),%xmm0
	vmovd	20(%r13),%xmm1
	vmovd	20(%r9),%xmm2
	vpinsrd	$1,20(%r14),%xmm5,%xmm5
	vpinsrd	$1,20(%r10),%xmm0,%xmm0
	vpinsrd	$1,20(%r15),%xmm1,%xmm1
	vpunpckldq	%ymm1,%ymm5,%ymm5
	vpinsrd	$1,20(%r11),%xmm2,%xmm2
	vpunpckldq	%ymm2,%ymm0,%ymm0
	vinserti128	$1,%xmm0,%ymm5,%ymm5
	vpshufb	%ymm6,%ymm5,%ymm5
	vpsrld	$6,%ymm15,%ymm7
	vpslld	$26,%ymm15,%ymm2
	vmovdqu	%ymm5,160-128(%rax)
	vpaddd	%ymm10,%ymm5,%ymm5

	vpsrld	$11,%ymm15,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm15,%ymm2
	vpaddd	32(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm15,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm15,%ymm2
	vpandn	%ymm9,%ymm15,%ymm0
	vpand	%ymm8,%ymm15,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm11,%ymm10
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm11,%ymm1
	vpxor	%ymm4,%ymm0,%ymm0
	vpxor	%ymm11,%ymm12,%ymm4

	vpxor	%ymm1,%ymm10,%ymm10
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm11,%ymm1

	vpslld	$19,%ymm11,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm4,%ymm3,%ymm3

	vpxor	%ymm1,%ymm10,%ymm7

	vpsrld	$22,%ymm11,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm11,%ymm2
	vpxor	%ymm3,%ymm12,%ymm10
	vpaddd	%ymm5,%ymm14,%ymm14

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm10,%ymm10
	vpaddd	%ymm7,%ymm10,%ymm10
	vmovd	24(%r12),%xmm5
	vmovd	24(%r8),%xmm0
	vmovd	24(%r13),%xmm1
	vmovd	24(%r9),%xmm2
	vpinsrd	$1,24(%r14),%xmm5,%xmm5
	vpinsrd	$1,24(%r10),%xmm0,%xmm0
	vpinsrd	$1,24(%r15),%xmm1,%xmm1
	vpunpckldq	%ymm1,%ymm5,%ymm5
	vpinsrd	$1,24(%r11),%xmm2,%xmm2
	vpunpckldq	%ymm2,%ymm0,%ymm0
	vinserti128	$1,%xmm0,%ymm5,%ymm5
	vpshufb	%ymm6,%ymm5,%ymm5
	vpsrld	$6,%ymm14,%ymm7
	vpslld	$26,%ymm14,%ymm2
	vmovdqu	%ymm5,192-128(%rax)
	vpaddd	%ymm9,%ymm5,%ymm5

	vpsrld	$11,%ymm14,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm14,%ymm2
	vpaddd	64(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm14,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm14,%ymm2
	vpandn	%ymm8,%ymm14,%ymm0
	vpand	%ymm15,%ymm14,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm10,%ymm9
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm10,%ymm1
	vpxor	%ymm3,%ymm0,%ymm0
	vpxor	%ymm10,%ymm11,%ymm3

	vpxor	%ymm1,%ymm9,%ymm9
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm10,%ymm1

	vpslld	$19,%ymm10,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm3,%ymm4,%ymm4

	vpxor	%ymm1,%ymm9,%ymm7

	vpsrld	$22,%ymm10,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm10,%ymm2
	vpxor	%ymm4,%ymm11,%ymm9
	vpaddd	%ymm5,%ymm13,%ymm13

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm9,%ymm9
	vpaddd	%ymm7,%ymm9,%ymm9
	vmovd	28(%r12),%xmm5
	vmovd	28(%r8),%xmm0
	vmovd	28(%r13),%xmm1
	vmovd	28(%r9),%xmm2
	vpinsrd	$1,28(%r14),%xmm5,%xmm5
	vpinsrd	$1,28(%r10),%xmm0,%xmm0
	vpinsrd	$1,28(%r15),%xmm1,%xmm1
	vpunpckldq	%ymm1,%ymm5,%ymm5
	vpinsrd	$1,28(%r11),%xmm2,%xmm2
	vpunpckldq	%ymm2,%ymm0,%ymm0
	vinserti128	$1,%xmm0,%ymm5,%ymm5
	vpshufb	%ymm6,%ymm5,%ymm5
	vpsrld	$6,%ymm13,%ymm7
	vpslld	$26,%ymm13,%ymm2
	vmovdqu	%ymm5,224-128(%rax)
	vpaddd	%ymm8,%ymm5,%ymm5

	vpsrld	$11,%ymm13,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm13,%ymm2
	vpaddd	96(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm13,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm13,%ymm2
	vpandn	%ymm15,%ymm13,%ymm0
	vpand	%ymm14,%ymm13,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm9,%ymm8
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm9,%ymm1
	vpxor	%ymm4,%ymm0,%ymm0
	vpxor	%ymm9,%ymm10,%ymm4

	vpxor	%ymm1,%ymm8,%ymm8
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm9,%ymm1

	vpslld	$19,%ymm9,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm4,%ymm3,%ymm3

	vpxor	%ymm1,%ymm8,%ymm7

	vpsrld	$22,%ymm9,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm9,%ymm2
	vpxor	%ymm3,%ymm10,%ymm8
	vpaddd	%ymm5,%ymm12,%ymm12

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm8,%ymm8
	vpaddd	%ymm7,%ymm8,%ymm8
	addq	$256,%rbp
	vmovd	32(%r12),%xmm5
	vmovd	32(%r8),%xmm0
	vmovd	32(%r13),%xmm1
	vmovd	32(%r9),%xmm2
	vpinsrd	$1,32(%r14),%xmm5,%xmm5
	vpinsrd	$1,32(%r10),%xmm0,%xmm0
	vpinsrd	$1,32(%r15),%xmm1,%xmm1
	vpunpckldq	%ymm1,%ymm5,%ymm5
	vpinsrd	$1,32(%r11),%xmm2,%xmm2
	vpunpckldq	%ymm2,%ymm0,%ymm0
	vinserti128	$1,%xmm0,%ymm5,%ymm5
	vpshufb	%ymm6,%ymm5,%ymm5
	vpsrld	$6,%ymm12,%ymm7
	vpslld	$26,%ymm12,%ymm2
	vmovdqu	%ymm5,256-256-128(%rbx)
	vpaddd	%ymm15,%ymm5,%ymm5

	vpsrld	$11,%ymm12,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm12,%ymm2
	vpaddd	-128(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm12,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm12,%ymm2
	vpandn	%ymm14,%ymm12,%ymm0
	vpand	%ymm13,%ymm12,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm8,%ymm15
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm8,%ymm1
	vpxor	%ymm3,%ymm0,%ymm0
	vpxor	%ymm8,%ymm9,%ymm3

	vpxor	%ymm1,%ymm15,%ymm15
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm8,%ymm1

	vpslld	$19,%ymm8,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm3,%ymm4,%ymm4

	vpxor	%ymm1,%ymm15,%ymm7

	vpsrld	$22,%ymm8,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm8,%ymm2
	vpxor	%ymm4,%ymm9,%ymm15
	vpaddd	%ymm5,%ymm11,%ymm11

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm15,%ymm15
	vpaddd	%ymm7,%ymm15,%ymm15
	vmovd	36(%r12),%xmm5
	vmovd	36(%r8),%xmm0
	vmovd	36(%r13),%xmm1
	vmovd	36(%r9),%xmm2
	vpinsrd	$1,36(%r14),%xmm5,%xmm5
	vpinsrd	$1,36(%r10),%xmm0,%xmm0
	vpinsrd	$1,36(%r15),%xmm1,%xmm1
	vpunpckldq	%ymm1,%ymm5,%ymm5
	vpinsrd	$1,36(%r11),%xmm2,%xmm2
	vpunpckldq	%ymm2,%ymm0,%ymm0
	vinserti128	$1,%xmm0,%ymm5,%ymm5
	vpshufb	%ymm6,%ymm5,%ymm5
	vpsrld	$6,%ymm11,%ymm7
	vpslld	$26,%ymm11,%ymm2
	vmovdqu	%ymm5,288-256-128(%rbx)
	vpaddd	%ymm14,%ymm5,%ymm5

	vpsrld	$11,%ymm11,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm11,%ymm2
	vpaddd	-96(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm11,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm11,%ymm2
	vpandn	%ymm13,%ymm11,%ymm0
	vpand	%ymm12,%ymm11,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm15,%ymm14
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm15,%ymm1
	vpxor	%ymm4,%ymm0,%ymm0
	vpxor	%ymm15,%ymm8,%ymm4

	vpxor	%ymm1,%ymm14,%ymm14
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm15,%ymm1

	vpslld	$19,%ymm15,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm4,%ymm3,%ymm3

	vpxor	%ymm1,%ymm14,%ymm7

	vpsrld	$22,%ymm15,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm15,%ymm2
	vpxor	%ymm3,%ymm8,%ymm14
	vpaddd	%ymm5,%ymm10,%ymm10

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm14,%ymm14
	vpaddd	%ymm7,%ymm14,%ymm14
	vmovd	40(%r12),%xmm5
	vmovd	40(%r8),%xmm0
	vmovd	40(%r13),%xmm1
	vmovd	40(%r9),%xmm2
	vpinsrd	$1,40(%r14),%xmm5,%xmm5
	vpinsrd	$1,40(%r10),%xmm0,%xmm0
	vpinsrd	$1,40(%r15),%xmm1,%xmm1
	vpunpckldq	%ymm1,%ymm5,%ymm5
	vpinsrd	$1,40(%r11),%xmm2,%xmm2
	vpunpckldq	%ymm2,%ymm0,%ymm0
	vinserti128	$1,%xmm0,%ymm5,%ymm5
	vpshufb	%ymm6,%ymm5,%ymm5
	vpsrld	$6,%ymm10,%ymm7
	vpslld	$26,%ymm10,%ymm2
	vmovdqu	%ymm5,320-256-128(%rbx)
	vpaddd	%ymm13,%ymm5,%ymm5

	vpsrld	$11,%ymm10,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm10,%ymm2
	vpaddd	-64(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm10,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm10,%ymm2
	vpandn	%ymm12,%ymm10,%ymm0
	vpand	%ymm11,%ymm10,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm14,%ymm13
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm14,%ymm1
	vpxor	%ymm3,%ymm0,%ymm0
	vpxor	%ymm14,%ymm15,%ymm3

	vpxor	%ymm1,%ymm13,%ymm13
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm14,%ymm1

	vpslld	$19,%ymm14,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm3,%ymm4,%ymm4

	vpxor	%ymm1,%ymm13,%ymm7

	vpsrld	$22,%ymm14,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm14,%ymm2
	vpxor	%ymm4,%ymm15,%ymm13
	vpaddd	%ymm5,%ymm9,%ymm9

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm13,%ymm13
	vpaddd	%ymm7,%ymm13,%ymm13
	vmovd	44(%r12),%xmm5
	vmovd	44(%r8),%xmm0
	vmovd	44(%r13),%xmm1
	vmovd	44(%r9),%xmm2
	vpinsrd	$1,44(%r14),%xmm5,%xmm5
	vpinsrd	$1,44(%r10),%xmm0,%xmm0
	vpinsrd	$1,44(%r15),%xmm1,%xmm1
	vpunpckldq	%ymm1,%ymm5,%ymm5
	vpinsrd	$1,44(%r11),%xmm2,%xmm2
	vpunpckldq	%ymm2,%ymm0,%ymm0
	vinserti128	$1,%xmm0,%ymm5,%ymm5
	vpshufb	%ymm6,%ymm5,%ymm5
	vpsrld	$6,%ymm9,%ymm7
	vpslld	$26,%ymm9,%ymm2
	vmovdqu	%ymm5,352-256-128(%rbx)
	vpaddd	%ymm12,%ymm5,%ymm5

	vpsrld	$11,%ymm9,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm9,%ymm2
	vpaddd	-32(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm9,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm9,%ymm2
	vpandn	%ymm11,%ymm9,%ymm0
	vpand	%ymm10,%ymm9,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm13,%ymm12
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm13,%ymm1
	vpxor	%ymm4,%ymm0,%ymm0
	vpxor	%ymm13,%ymm14,%ymm4

	vpxor	%ymm1,%ymm12,%ymm12
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm13,%ymm1

	vpslld	$19,%ymm13,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm4,%ymm3,%ymm3

	vpxor	%ymm1,%ymm12,%ymm7

	vpsrld	$22,%ymm13,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm13,%ymm2
	vpxor	%ymm3,%ymm14,%ymm12
	vpaddd	%ymm5,%ymm8,%ymm8

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm12,%ymm12
	vpaddd	%ymm7,%ymm12,%ymm12
	vmovd	48(%r12),%xmm5
	vmovd	48(%r8),%xmm0
	vmovd	48(%r13),%xmm1
	vmovd	48(%r9),%xmm2
	vpinsrd	$1,48(%r14),%xmm5,%xmm5
	vpinsrd	$1,48(%r10),%xmm0,%xmm0
	vpinsrd	$1,48(%r15),%xmm1,%xmm1
	vpunpckldq	%ymm1,%ymm5,%ymm5
	vpinsrd	$1,48(%r11),%xmm2,%xmm2
	vpunpckldq	%ymm2,%ymm0,%ymm0
	vinserti128	$1,%xmm0,%ymm5,%ymm5
	vpshufb	%ymm6,%ymm5,%ymm5
	vpsrld	$6,%ymm8,%ymm7
	vpslld	$26,%ymm8,%ymm2
	vmovdqu	%ymm5,384-256-128(%rbx)
	vpaddd	%ymm11,%ymm5,%ymm5

	vpsrld	$11,%ymm8,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm8,%ymm2
	vpaddd	0(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm8,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm8,%ymm2
	vpandn	%ymm10,%ymm8,%ymm0
	vpand	%ymm9,%ymm8,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm12,%ymm11
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm12,%ymm1
	vpxor	%ymm3,%ymm0,%ymm0
	vpxor	%ymm12,%ymm13,%ymm3

	vpxor	%ymm1,%ymm11,%ymm11
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm12,%ymm1

	vpslld	$19,%ymm12,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm3,%ymm4,%ymm4

	vpxor	%ymm1,%ymm11,%ymm7

	vpsrld	$22,%ymm12,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm12,%ymm2
	vpxor	%ymm4,%ymm13,%ymm11
	vpaddd	%ymm5,%ymm15,%ymm15

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm11,%ymm11
	vpaddd	%ymm7,%ymm11,%ymm11
	vmovd	52(%r12),%xmm5
	vmovd	52(%r8),%xmm0
	vmovd	52(%r13),%xmm1
	vmovd	52(%r9),%xmm2
	vpinsrd	$1,52(%r14),%xmm5,%xmm5
	vpinsrd	$1,52(%r10),%xmm0,%xmm0
	vpinsrd	$1,52(%r15),%xmm1,%xmm1
	vpunpckldq	%ymm1,%ymm5,%ymm5
	vpinsrd	$1,52(%r11),%xmm2,%xmm2
	vpunpckldq	%ymm2,%ymm0,%ymm0
	vinserti128	$1,%xmm0,%ymm5,%ymm5
	vpshufb	%ymm6,%ymm5,%ymm5
	vpsrld	$6,%ymm15,%ymm7
	vpslld	$26,%ymm15,%ymm2
	vmovdqu	%ymm5,416-256-128(%rbx)
	vpaddd	%ymm10,%ymm5,%ymm5

	vpsrld	$11,%ymm15,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm15,%ymm2
	vpaddd	32(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm15,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm15,%ymm2
	vpandn	%ymm9,%ymm15,%ymm0
	vpand	%ymm8,%ymm15,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm11,%ymm10
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm11,%ymm1
	vpxor	%ymm4,%ymm0,%ymm0
	vpxor	%ymm11,%ymm12,%ymm4

	vpxor	%ymm1,%ymm10,%ymm10
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm11,%ymm1

	vpslld	$19,%ymm11,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm4,%ymm3,%ymm3

	vpxor	%ymm1,%ymm10,%ymm7

	vpsrld	$22,%ymm11,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm11,%ymm2
	vpxor	%ymm3,%ymm12,%ymm10
	vpaddd	%ymm5,%ymm14,%ymm14

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm10,%ymm10
	vpaddd	%ymm7,%ymm10,%ymm10
	vmovd	56(%r12),%xmm5
	vmovd	56(%r8),%xmm0
	vmovd	56(%r13),%xmm1
	vmovd	56(%r9),%xmm2
	vpinsrd	$1,56(%r14),%xmm5,%xmm5
	vpinsrd	$1,56(%r10),%xmm0,%xmm0
	vpinsrd	$1,56(%r15),%xmm1,%xmm1
	vpunpckldq	%ymm1,%ymm5,%ymm5
	vpinsrd	$1,56(%r11),%xmm2,%xmm2
	vpunpckldq	%ymm2,%ymm0,%ymm0
	vinserti128	$1,%xmm0,%ymm5,%ymm5
	vpshufb	%ymm6,%ymm5,%ymm5
	vpsrld	$6,%ymm14,%ymm7
	vpslld	$26,%ymm14,%ymm2
	vmovdqu	%ymm5,448-256-128(%rbx)
	vpaddd	%ymm9,%ymm5,%ymm5

	vpsrld	$11,%ymm14,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm14,%ymm2
	vpaddd	64(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm14,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm14,%ymm2
	vpandn	%ymm8,%ymm14,%ymm0
	vpand	%ymm15,%ymm14,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm10,%ymm9
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm10,%ymm1
	vpxor	%ymm3,%ymm0,%ymm0
	vpxor	%ymm10,%ymm11,%ymm3

	vpxor	%ymm1,%ymm9,%ymm9
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm10,%ymm1

	vpslld	$19,%ymm10,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm3,%ymm4,%ymm4

	vpxor	%ymm1,%ymm9,%ymm7

	vpsrld	$22,%ymm10,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm10,%ymm2
	vpxor	%ymm4,%ymm11,%ymm9
	vpaddd	%ymm5,%ymm13,%ymm13

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm9,%ymm9
	vpaddd	%ymm7,%ymm9,%ymm9
	vmovd	60(%r12),%xmm5
	leaq	64(%r12),%r12
	vmovd	60(%r8),%xmm0
	leaq	64(%r8),%r8
	vmovd	60(%r13),%xmm1
	leaq	64(%r13),%r13
	vmovd	60(%r9),%xmm2
	leaq	64(%r9),%r9
	vpinsrd	$1,60(%r14),%xmm5,%xmm5
	leaq	64(%r14),%r14
	vpinsrd	$1,60(%r10),%xmm0,%xmm0
	leaq	64(%r10),%r10
	vpinsrd	$1,60(%r15),%xmm1,%xmm1
	leaq	64(%r15),%r15
	vpunpckldq	%ymm1,%ymm5,%ymm5
	vpinsrd	$1,60(%r11),%xmm2,%xmm2
	leaq	64(%r11),%r11
	vpunpckldq	%ymm2,%ymm0,%ymm0
	vinserti128	$1,%xmm0,%ymm5,%ymm5
	vpshufb	%ymm6,%ymm5,%ymm5
	vpsrld	$6,%ymm13,%ymm7
	vpslld	$26,%ymm13,%ymm2
	vmovdqu	%ymm5,480-256-128(%rbx)
	vpaddd	%ymm8,%ymm5,%ymm5

	vpsrld	$11,%ymm13,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm13,%ymm2
	vpaddd	96(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm13,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	prefetcht0	63(%r12)
	vpslld	$7,%ymm13,%ymm2
	vpandn	%ymm15,%ymm13,%ymm0
	vpand	%ymm14,%ymm13,%ymm4
	prefetcht0	63(%r13)
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm9,%ymm8
	vpxor	%ymm2,%ymm7,%ymm7
	prefetcht0	63(%r14)
	vpslld	$30,%ymm9,%ymm1
	vpxor	%ymm4,%ymm0,%ymm0
	vpxor	%ymm9,%ymm10,%ymm4
	prefetcht0	63(%r15)
	vpxor	%ymm1,%ymm8,%ymm8
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm9,%ymm1
	prefetcht0	63(%r8)
	vpslld	$19,%ymm9,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm4,%ymm3,%ymm3
	prefetcht0	63(%r9)
	vpxor	%ymm1,%ymm8,%ymm7

	vpsrld	$22,%ymm9,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	prefetcht0	63(%r10)
	vpslld	$10,%ymm9,%ymm2
	vpxor	%ymm3,%ymm10,%ymm8
	vpaddd	%ymm5,%ymm12,%ymm12
	prefetcht0	63(%r11)
	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm8,%ymm8
	vpaddd	%ymm7,%ymm8,%ymm8
	addq	$256,%rbp
	vmovdqu	0-128(%rax),%ymm5
	movl	$3,%ecx
	jmp	.Loop_16_xx_avx2
.align	32
.Loop_16_xx_avx2:
	vmovdqu	32-128(%rax),%ymm6
	vpaddd	288-256-128(%rbx),%ymm5,%ymm5

	vpsrld	$3,%ymm6,%ymm7
	vpsrld	$7,%ymm6,%ymm1
	vpslld	$25,%ymm6,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$18,%ymm6,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$14,%ymm6,%ymm2
	vmovdqu	448-256-128(%rbx),%ymm0
	vpsrld	$10,%ymm0,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$17,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$15,%ymm0,%ymm2
	vpaddd	%ymm7,%ymm5,%ymm5
	vpxor	%ymm1,%ymm3,%ymm7
	vpsrld	$19,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$13,%ymm0,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7
	vpaddd	%ymm7,%ymm5,%ymm5
	vpsrld	$6,%ymm12,%ymm7
	vpslld	$26,%ymm12,%ymm2
	vmovdqu	%ymm5,0-128(%rax)
	vpaddd	%ymm15,%ymm5,%ymm5

	vpsrld	$11,%ymm12,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm12,%ymm2
	vpaddd	-128(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm12,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm12,%ymm2
	vpandn	%ymm14,%ymm12,%ymm0
	vpand	%ymm13,%ymm12,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm8,%ymm15
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm8,%ymm1
	vpxor	%ymm3,%ymm0,%ymm0
	vpxor	%ymm8,%ymm9,%ymm3

	vpxor	%ymm1,%ymm15,%ymm15
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm8,%ymm1

	vpslld	$19,%ymm8,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm3,%ymm4,%ymm4

	vpxor	%ymm1,%ymm15,%ymm7

	vpsrld	$22,%ymm8,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm8,%ymm2
	vpxor	%ymm4,%ymm9,%ymm15
	vpaddd	%ymm5,%ymm11,%ymm11

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm15,%ymm15
	vpaddd	%ymm7,%ymm15,%ymm15
	vmovdqu	64-128(%rax),%ymm5
	vpaddd	320-256-128(%rbx),%ymm6,%ymm6

	vpsrld	$3,%ymm5,%ymm7
	vpsrld	$7,%ymm5,%ymm1
	vpslld	$25,%ymm5,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$18,%ymm5,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$14,%ymm5,%ymm2
	vmovdqu	480-256-128(%rbx),%ymm0
	vpsrld	$10,%ymm0,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$17,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$15,%ymm0,%ymm2
	vpaddd	%ymm7,%ymm6,%ymm6
	vpxor	%ymm1,%ymm4,%ymm7
	vpsrld	$19,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$13,%ymm0,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7
	vpaddd	%ymm7,%ymm6,%ymm6
	vpsrld	$6,%ymm11,%ymm7
	vpslld	$26,%ymm11,%ymm2
	vmovdqu	%ymm6,32-128(%rax)
	vpaddd	%ymm14,%ymm6,%ymm6

	vpsrld	$11,%ymm11,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm11,%ymm2
	vpaddd	-96(%rbp),%ymm6,%ymm6
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm11,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm11,%ymm2
	vpandn	%ymm13,%ymm11,%ymm0
	vpand	%ymm12,%ymm11,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm15,%ymm14
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm15,%ymm1
	vpxor	%ymm4,%ymm0,%ymm0
	vpxor	%ymm15,%ymm8,%ymm4

	vpxor	%ymm1,%ymm14,%ymm14
	vpaddd	%ymm7,%ymm6,%ymm6

	vpsrld	$13,%ymm15,%ymm1

	vpslld	$19,%ymm15,%ymm2
	vpaddd	%ymm0,%ymm6,%ymm6
	vpand	%ymm4,%ymm3,%ymm3

	vpxor	%ymm1,%ymm14,%ymm7

	vpsrld	$22,%ymm15,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm15,%ymm2
	vpxor	%ymm3,%ymm8,%ymm14
	vpaddd	%ymm6,%ymm10,%ymm10

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm6,%ymm14,%ymm14
	vpaddd	%ymm7,%ymm14,%ymm14
	vmovdqu	96-128(%rax),%ymm6
	vpaddd	352-256-128(%rbx),%ymm5,%ymm5

	vpsrld	$3,%ymm6,%ymm7
	vpsrld	$7,%ymm6,%ymm1
	vpslld	$25,%ymm6,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$18,%ymm6,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$14,%ymm6,%ymm2
	vmovdqu	0-128(%rax),%ymm0
	vpsrld	$10,%ymm0,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$17,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$15,%ymm0,%ymm2
	vpaddd	%ymm7,%ymm5,%ymm5
	vpxor	%ymm1,%ymm3,%ymm7
	vpsrld	$19,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$13,%ymm0,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7
	vpaddd	%ymm7,%ymm5,%ymm5
	vpsrld	$6,%ymm10,%ymm7
	vpslld	$26,%ymm10,%ymm2
	vmovdqu	%ymm5,64-128(%rax)
	vpaddd	%ymm13,%ymm5,%ymm5

	vpsrld	$11,%ymm10,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm10,%ymm2
	vpaddd	-64(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm10,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm10,%ymm2
	vpandn	%ymm12,%ymm10,%ymm0
	vpand	%ymm11,%ymm10,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm14,%ymm13
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm14,%ymm1
	vpxor	%ymm3,%ymm0,%ymm0
	vpxor	%ymm14,%ymm15,%ymm3

	vpxor	%ymm1,%ymm13,%ymm13
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm14,%ymm1

	vpslld	$19,%ymm14,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm3,%ymm4,%ymm4

	vpxor	%ymm1,%ymm13,%ymm7

	vpsrld	$22,%ymm14,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm14,%ymm2
	vpxor	%ymm4,%ymm15,%ymm13
	vpaddd	%ymm5,%ymm9,%ymm9

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm13,%ymm13
	vpaddd	%ymm7,%ymm13,%ymm13
	vmovdqu	128-128(%rax),%ymm5
	vpaddd	384-256-128(%rbx),%ymm6,%ymm6

	vpsrld	$3,%ymm5,%ymm7
	vpsrld	$7,%ymm5,%ymm1
	vpslld	$25,%ymm5,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$18,%ymm5,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$14,%ymm5,%ymm2
	vmovdqu	32-128(%rax),%ymm0
	vpsrld	$10,%ymm0,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$17,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$15,%ymm0,%ymm2
	vpaddd	%ymm7,%ymm6,%ymm6
	vpxor	%ymm1,%ymm4,%ymm7
	vpsrld	$19,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$13,%ymm0,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7
	vpaddd	%ymm7,%ymm6,%ymm6
	vpsrld	$6,%ymm9,%ymm7
	vpslld	$26,%ymm9,%ymm2
	vmovdqu	%ymm6,96-128(%rax)
	vpaddd	%ymm12,%ymm6,%ymm6

	vpsrld	$11,%ymm9,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm9,%ymm2
	vpaddd	-32(%rbp),%ymm6,%ymm6
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm9,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm9,%ymm2
	vpandn	%ymm11,%ymm9,%ymm0
	vpand	%ymm10,%ymm9,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm13,%ymm12
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm13,%ymm1
	vpxor	%ymm4,%ymm0,%ymm0
	vpxor	%ymm13,%ymm14,%ymm4

	vpxor	%ymm1,%ymm12,%ymm12
	vpaddd	%ymm7,%ymm6,%ymm6

	vpsrld	$13,%ymm13,%ymm1

	vpslld	$19,%ymm13,%ymm2
	vpaddd	%ymm0,%ymm6,%ymm6
	vpand	%ymm4,%ymm3,%ymm3

	vpxor	%ymm1,%ymm12,%ymm7

	vpsrld	$22,%ymm13,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm13,%ymm2
	vpxor	%ymm3,%ymm14,%ymm12
	vpaddd	%ymm6,%ymm8,%ymm8

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm6,%ymm12,%ymm12
	vpaddd	%ymm7,%ymm12,%ymm12
	vmovdqu	160-128(%rax),%ymm6
	vpaddd	416-256-128(%rbx),%ymm5,%ymm5

	vpsrld	$3,%ymm6,%ymm7
	vpsrld	$7,%ymm6,%ymm1
	vpslld	$25,%ymm6,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$18,%ymm6,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$14,%ymm6,%ymm2
	vmovdqu	64-128(%rax),%ymm0
	vpsrld	$10,%ymm0,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$17,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$15,%ymm0,%ymm2
	vpaddd	%ymm7,%ymm5,%ymm5
	vpxor	%ymm1,%ymm3,%ymm7
	vpsrld	$19,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$13,%ymm0,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7
	vpaddd	%ymm7,%ymm5,%ymm5
	vpsrld	$6,%ymm8,%ymm7
	vpslld	$26,%ymm8,%ymm2
	vmovdqu	%ymm5,128-128(%rax)
	vpaddd	%ymm11,%ymm5,%ymm5

	vpsrld	$11,%ymm8,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm8,%ymm2
	vpaddd	0(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm8,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm8,%ymm2
	vpandn	%ymm10,%ymm8,%ymm0
	vpand	%ymm9,%ymm8,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm12,%ymm11
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm12,%ymm1
	vpxor	%ymm3,%ymm0,%ymm0
	vpxor	%ymm12,%ymm13,%ymm3

	vpxor	%ymm1,%ymm11,%ymm11
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm12,%ymm1

	vpslld	$19,%ymm12,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm3,%ymm4,%ymm4

	vpxor	%ymm1,%ymm11,%ymm7

	vpsrld	$22,%ymm12,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm12,%ymm2
	vpxor	%ymm4,%ymm13,%ymm11
	vpaddd	%ymm5,%ymm15,%ymm15

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm11,%ymm11
	vpaddd	%ymm7,%ymm11,%ymm11
	vmovdqu	192-128(%rax),%ymm5
	vpaddd	448-256-128(%rbx),%ymm6,%ymm6

	vpsrld	$3,%ymm5,%ymm7
	vpsrld	$7,%ymm5,%ymm1
	vpslld	$25,%ymm5,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$18,%ymm5,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$14,%ymm5,%ymm2
	vmovdqu	96-128(%rax),%ymm0
	vpsrld	$10,%ymm0,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$17,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$15,%ymm0,%ymm2
	vpaddd	%ymm7,%ymm6,%ymm6
	vpxor	%ymm1,%ymm4,%ymm7
	vpsrld	$19,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$13,%ymm0,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7
	vpaddd	%ymm7,%ymm6,%ymm6
	vpsrld	$6,%ymm15,%ymm7
	vpslld	$26,%ymm15,%ymm2
	vmovdqu	%ymm6,160-128(%rax)
	vpaddd	%ymm10,%ymm6,%ymm6

	vpsrld	$11,%ymm15,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm15,%ymm2
	vpaddd	32(%rbp),%ymm6,%ymm6
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm15,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm15,%ymm2
	vpandn	%ymm9,%ymm15,%ymm0
	vpand	%ymm8,%ymm15,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm11,%ymm10
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm11,%ymm1
	vpxor	%ymm4,%ymm0,%ymm0
	vpxor	%ymm11,%ymm12,%ymm4

	vpxor	%ymm1,%ymm10,%ymm10
	vpaddd	%ymm7,%ymm6,%ymm6

	vpsrld	$13,%ymm11,%ymm1

	vpslld	$19,%ymm11,%ymm2
	vpaddd	%ymm0,%ymm6,%ymm6
	vpand	%ymm4,%ymm3,%ymm3

	vpxor	%ymm1,%ymm10,%ymm7

	vpsrld	$22,%ymm11,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm11,%ymm2
	vpxor	%ymm3,%ymm12,%ymm10
	vpaddd	%ymm6,%ymm14,%ymm14

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm6,%ymm10,%ymm10
	vpaddd	%ymm7,%ymm10,%ymm10
	vmovdqu	224-128(%rax),%ymm6
	vpaddd	480-256-128(%rbx),%ymm5,%ymm5

	vpsrld	$3,%ymm6,%ymm7
	vpsrld	$7,%ymm6,%ymm1
	vpslld	$25,%ymm6,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$18,%ymm6,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$14,%ymm6,%ymm2
	vmovdqu	128-128(%rax),%ymm0
	vpsrld	$10,%ymm0,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$17,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$15,%ymm0,%ymm2
	vpaddd	%ymm7,%ymm5,%ymm5
	vpxor	%ymm1,%ymm3,%ymm7
	vpsrld	$19,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$13,%ymm0,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7
	vpaddd	%ymm7,%ymm5,%ymm5
	vpsrld	$6,%ymm14,%ymm7
	vpslld	$26,%ymm14,%ymm2
	vmovdqu	%ymm5,192-128(%rax)
	vpaddd	%ymm9,%ymm5,%ymm5

	vpsrld	$11,%ymm14,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm14,%ymm2
	vpaddd	64(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm14,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm14,%ymm2
	vpandn	%ymm8,%ymm14,%ymm0
	vpand	%ymm15,%ymm14,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm10,%ymm9
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm10,%ymm1
	vpxor	%ymm3,%ymm0,%ymm0
	vpxor	%ymm10,%ymm11,%ymm3

	vpxor	%ymm1,%ymm9,%ymm9
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm10,%ymm1

	vpslld	$19,%ymm10,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm3,%ymm4,%ymm4

	vpxor	%ymm1,%ymm9,%ymm7

	vpsrld	$22,%ymm10,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm10,%ymm2
	vpxor	%ymm4,%ymm11,%ymm9
	vpaddd	%ymm5,%ymm13,%ymm13

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm9,%ymm9
	vpaddd	%ymm7,%ymm9,%ymm9
	vmovdqu	256-256-128(%rbx),%ymm5
	vpaddd	0-128(%rax),%ymm6,%ymm6

	vpsrld	$3,%ymm5,%ymm7
	vpsrld	$7,%ymm5,%ymm1
	vpslld	$25,%ymm5,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$18,%ymm5,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$14,%ymm5,%ymm2
	vmovdqu	160-128(%rax),%ymm0
	vpsrld	$10,%ymm0,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$17,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$15,%ymm0,%ymm2
	vpaddd	%ymm7,%ymm6,%ymm6
	vpxor	%ymm1,%ymm4,%ymm7
	vpsrld	$19,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$13,%ymm0,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7
	vpaddd	%ymm7,%ymm6,%ymm6
	vpsrld	$6,%ymm13,%ymm7
	vpslld	$26,%ymm13,%ymm2
	vmovdqu	%ymm6,224-128(%rax)
	vpaddd	%ymm8,%ymm6,%ymm6

	vpsrld	$11,%ymm13,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm13,%ymm2
	vpaddd	96(%rbp),%ymm6,%ymm6
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm13,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm13,%ymm2
	vpandn	%ymm15,%ymm13,%ymm0
	vpand	%ymm14,%ymm13,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm9,%ymm8
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm9,%ymm1
	vpxor	%ymm4,%ymm0,%ymm0
	vpxor	%ymm9,%ymm10,%ymm4

	vpxor	%ymm1,%ymm8,%ymm8
	vpaddd	%ymm7,%ymm6,%ymm6

	vpsrld	$13,%ymm9,%ymm1

	vpslld	$19,%ymm9,%ymm2
	vpaddd	%ymm0,%ymm6,%ymm6
	vpand	%ymm4,%ymm3,%ymm3

	vpxor	%ymm1,%ymm8,%ymm7

	vpsrld	$22,%ymm9,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm9,%ymm2
	vpxor	%ymm3,%ymm10,%ymm8
	vpaddd	%ymm6,%ymm12,%ymm12

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm6,%ymm8,%ymm8
	vpaddd	%ymm7,%ymm8,%ymm8
	addq	$256,%rbp
	vmovdqu	288-256-128(%rbx),%ymm6
	vpaddd	32-128(%rax),%ymm5,%ymm5

	vpsrld	$3,%ymm6,%ymm7
	vpsrld	$7,%ymm6,%ymm1
	vpslld	$25,%ymm6,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$18,%ymm6,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$14,%ymm6,%ymm2
	vmovdqu	192-128(%rax),%ymm0
	vpsrld	$10,%ymm0,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$17,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$15,%ymm0,%ymm2
	vpaddd	%ymm7,%ymm5,%ymm5
	vpxor	%ymm1,%ymm3,%ymm7
	vpsrld	$19,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$13,%ymm0,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7
	vpaddd	%ymm7,%ymm5,%ymm5
	vpsrld	$6,%ymm12,%ymm7
	vpslld	$26,%ymm12,%ymm2
	vmovdqu	%ymm5,256-256-128(%rbx)
	vpaddd	%ymm15,%ymm5,%ymm5

	vpsrld	$11,%ymm12,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm12,%ymm2
	vpaddd	-128(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm12,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm12,%ymm2
	vpandn	%ymm14,%ymm12,%ymm0
	vpand	%ymm13,%ymm12,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm8,%ymm15
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm8,%ymm1
	vpxor	%ymm3,%ymm0,%ymm0
	vpxor	%ymm8,%ymm9,%ymm3

	vpxor	%ymm1,%ymm15,%ymm15
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm8,%ymm1

	vpslld	$19,%ymm8,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm3,%ymm4,%ymm4

	vpxor	%ymm1,%ymm15,%ymm7

	vpsrld	$22,%ymm8,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm8,%ymm2
	vpxor	%ymm4,%ymm9,%ymm15
	vpaddd	%ymm5,%ymm11,%ymm11

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm15,%ymm15
	vpaddd	%ymm7,%ymm15,%ymm15
	vmovdqu	320-256-128(%rbx),%ymm5
	vpaddd	64-128(%rax),%ymm6,%ymm6

	vpsrld	$3,%ymm5,%ymm7
	vpsrld	$7,%ymm5,%ymm1
	vpslld	$25,%ymm5,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$18,%ymm5,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$14,%ymm5,%ymm2
	vmovdqu	224-128(%rax),%ymm0
	vpsrld	$10,%ymm0,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$17,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$15,%ymm0,%ymm2
	vpaddd	%ymm7,%ymm6,%ymm6
	vpxor	%ymm1,%ymm4,%ymm7
	vpsrld	$19,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$13,%ymm0,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7
	vpaddd	%ymm7,%ymm6,%ymm6
	vpsrld	$6,%ymm11,%ymm7
	vpslld	$26,%ymm11,%ymm2
	vmovdqu	%ymm6,288-256-128(%rbx)
	vpaddd	%ymm14,%ymm6,%ymm6

	vpsrld	$11,%ymm11,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm11,%ymm2
	vpaddd	-96(%rbp),%ymm6,%ymm6
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm11,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm11,%ymm2
	vpandn	%ymm13,%ymm11,%ymm0
	vpand	%ymm12,%ymm11,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm15,%ymm14
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm15,%ymm1
	vpxor	%ymm4,%ymm0,%ymm0
	vpxor	%ymm15,%ymm8,%ymm4

	vpxor	%ymm1,%ymm14,%ymm14
	vpaddd	%ymm7,%ymm6,%ymm6

	vpsrld	$13,%ymm15,%ymm1

	vpslld	$19,%ymm15,%ymm2
	vpaddd	%ymm0,%ymm6,%ymm6
	vpand	%ymm4,%ymm3,%ymm3

	vpxor	%ymm1,%ymm14,%ymm7

	vpsrld	$22,%ymm15,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm15,%ymm2
	vpxor	%ymm3,%ymm8,%ymm14
	vpaddd	%ymm6,%ymm10,%ymm10

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm6,%ymm14,%ymm14
	vpaddd	%ymm7,%ymm14,%ymm14
	vmovdqu	352-256-128(%rbx),%ymm6
	vpaddd	96-128(%rax),%ymm5,%ymm5

	vpsrld	$3,%ymm6,%ymm7
	vpsrld	$7,%ymm6,%ymm1
	vpslld	$25,%ymm6,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$18,%ymm6,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$14,%ymm6,%ymm2
	vmovdqu	256-256-128(%rbx),%ymm0
	vpsrld	$10,%ymm0,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$17,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$15,%ymm0,%ymm2
	vpaddd	%ymm7,%ymm5,%ymm5
	vpxor	%ymm1,%ymm3,%ymm7
	vpsrld	$19,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$13,%ymm0,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7
	vpaddd	%ymm7,%ymm5,%ymm5
	vpsrld	$6,%ymm10,%ymm7
	vpslld	$26,%ymm10,%ymm2
	vmovdqu	%ymm5,320-256-128(%rbx)
	vpaddd	%ymm13,%ymm5,%ymm5

	vpsrld	$11,%ymm10,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm10,%ymm2
	vpaddd	-64(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm10,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm10,%ymm2
	vpandn	%ymm12,%ymm10,%ymm0
	vpand	%ymm11,%ymm10,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm14,%ymm13
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm14,%ymm1
	vpxor	%ymm3,%ymm0,%ymm0
	vpxor	%ymm14,%ymm15,%ymm3

	vpxor	%ymm1,%ymm13,%ymm13
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm14,%ymm1

	vpslld	$19,%ymm14,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm3,%ymm4,%ymm4

	vpxor	%ymm1,%ymm13,%ymm7

	vpsrld	$22,%ymm14,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm14,%ymm2
	vpxor	%ymm4,%ymm15,%ymm13
	vpaddd	%ymm5,%ymm9,%ymm9

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm13,%ymm13
	vpaddd	%ymm7,%ymm13,%ymm13
	vmovdqu	384-256-128(%rbx),%ymm5
	vpaddd	128-128(%rax),%ymm6,%ymm6

	vpsrld	$3,%ymm5,%ymm7
	vpsrld	$7,%ymm5,%ymm1
	vpslld	$25,%ymm5,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$18,%ymm5,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$14,%ymm5,%ymm2
	vmovdqu	288-256-128(%rbx),%ymm0
	vpsrld	$10,%ymm0,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$17,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$15,%ymm0,%ymm2
	vpaddd	%ymm7,%ymm6,%ymm6
	vpxor	%ymm1,%ymm4,%ymm7
	vpsrld	$19,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$13,%ymm0,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7
	vpaddd	%ymm7,%ymm6,%ymm6
	vpsrld	$6,%ymm9,%ymm7
	vpslld	$26,%ymm9,%ymm2
	vmovdqu	%ymm6,352-256-128(%rbx)
	vpaddd	%ymm12,%ymm6,%ymm6

	vpsrld	$11,%ymm9,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm9,%ymm2
	vpaddd	-32(%rbp),%ymm6,%ymm6
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm9,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm9,%ymm2
	vpandn	%ymm11,%ymm9,%ymm0
	vpand	%ymm10,%ymm9,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm13,%ymm12
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm13,%ymm1
	vpxor	%ymm4,%ymm0,%ymm0
	vpxor	%ymm13,%ymm14,%ymm4

	vpxor	%ymm1,%ymm12,%ymm12
	vpaddd	%ymm7,%ymm6,%ymm6

	vpsrld	$13,%ymm13,%ymm1

	vpslld	$19,%ymm13,%ymm2
	vpaddd	%ymm0,%ymm6,%ymm6
	vpand	%ymm4,%ymm3,%ymm3

	vpxor	%ymm1,%ymm12,%ymm7

	vpsrld	$22,%ymm13,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm13,%ymm2
	vpxor	%ymm3,%ymm14,%ymm12
	vpaddd	%ymm6,%ymm8,%ymm8

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm6,%ymm12,%ymm12
	vpaddd	%ymm7,%ymm12,%ymm12
	vmovdqu	416-256-128(%rbx),%ymm6
	vpaddd	160-128(%rax),%ymm5,%ymm5

	vpsrld	$3,%ymm6,%ymm7
	vpsrld	$7,%ymm6,%ymm1
	vpslld	$25,%ymm6,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$18,%ymm6,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$14,%ymm6,%ymm2
	vmovdqu	320-256-128(%rbx),%ymm0
	vpsrld	$10,%ymm0,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$17,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$15,%ymm0,%ymm2
	vpaddd	%ymm7,%ymm5,%ymm5
	vpxor	%ymm1,%ymm3,%ymm7
	vpsrld	$19,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$13,%ymm0,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7
	vpaddd	%ymm7,%ymm5,%ymm5
	vpsrld	$6,%ymm8,%ymm7
	vpslld	$26,%ymm8,%ymm2
	vmovdqu	%ymm5,384-256-128(%rbx)
	vpaddd	%ymm11,%ymm5,%ymm5

	vpsrld	$11,%ymm8,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm8,%ymm2
	vpaddd	0(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm8,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm8,%ymm2
	vpandn	%ymm10,%ymm8,%ymm0
	vpand	%ymm9,%ymm8,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm12,%ymm11
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm12,%ymm1
	vpxor	%ymm3,%ymm0,%ymm0
	vpxor	%ymm12,%ymm13,%ymm3

	vpxor	%ymm1,%ymm11,%ymm11
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm12,%ymm1

	vpslld	$19,%ymm12,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm3,%ymm4,%ymm4

	vpxor	%ymm1,%ymm11,%ymm7

	vpsrld	$22,%ymm12,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm12,%ymm2
	vpxor	%ymm4,%ymm13,%ymm11
	vpaddd	%ymm5,%ymm15,%ymm15

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm11,%ymm11
	vpaddd	%ymm7,%ymm11,%ymm11
	vmovdqu	448-256-128(%rbx),%ymm5
	vpaddd	192-128(%rax),%ymm6,%ymm6

	vpsrld	$3,%ymm5,%ymm7
	vpsrld	$7,%ymm5,%ymm1
	vpslld	$25,%ymm5,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$18,%ymm5,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$14,%ymm5,%ymm2
	vmovdqu	352-256-128(%rbx),%ymm0
	vpsrld	$10,%ymm0,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$17,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$15,%ymm0,%ymm2
	vpaddd	%ymm7,%ymm6,%ymm6
	vpxor	%ymm1,%ymm4,%ymm7
	vpsrld	$19,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$13,%ymm0,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7
	vpaddd	%ymm7,%ymm6,%ymm6
	vpsrld	$6,%ymm15,%ymm7
	vpslld	$26,%ymm15,%ymm2
	vmovdqu	%ymm6,416-256-128(%rbx)
	vpaddd	%ymm10,%ymm6,%ymm6

	vpsrld	$11,%ymm15,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm15,%ymm2
	vpaddd	32(%rbp),%ymm6,%ymm6
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm15,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm15,%ymm2
	vpandn	%ymm9,%ymm15,%ymm0
	vpand	%ymm8,%ymm15,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm11,%ymm10
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm11,%ymm1
	vpxor	%ymm4,%ymm0,%ymm0
	vpxor	%ymm11,%ymm12,%ymm4

	vpxor	%ymm1,%ymm10,%ymm10
	vpaddd	%ymm7,%ymm6,%ymm6

	vpsrld	$13,%ymm11,%ymm1

	vpslld	$19,%ymm11,%ymm2
	vpaddd	%ymm0,%ymm6,%ymm6
	vpand	%ymm4,%ymm3,%ymm3

	vpxor	%ymm1,%ymm10,%ymm7

	vpsrld	$22,%ymm11,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm11,%ymm2
	vpxor	%ymm3,%ymm12,%ymm10
	vpaddd	%ymm6,%ymm14,%ymm14

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm6,%ymm10,%ymm10
	vpaddd	%ymm7,%ymm10,%ymm10
	vmovdqu	480-256-128(%rbx),%ymm6
	vpaddd	224-128(%rax),%ymm5,%ymm5

	vpsrld	$3,%ymm6,%ymm7
	vpsrld	$7,%ymm6,%ymm1
	vpslld	$25,%ymm6,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$18,%ymm6,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$14,%ymm6,%ymm2
	vmovdqu	384-256-128(%rbx),%ymm0
	vpsrld	$10,%ymm0,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$17,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$15,%ymm0,%ymm2
	vpaddd	%ymm7,%ymm5,%ymm5
	vpxor	%ymm1,%ymm3,%ymm7
	vpsrld	$19,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$13,%ymm0,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7
	vpaddd	%ymm7,%ymm5,%ymm5
	vpsrld	$6,%ymm14,%ymm7
	vpslld	$26,%ymm14,%ymm2
	vmovdqu	%ymm5,448-256-128(%rbx)
	vpaddd	%ymm9,%ymm5,%ymm5

	vpsrld	$11,%ymm14,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm14,%ymm2
	vpaddd	64(%rbp),%ymm5,%ymm5
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm14,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm14,%ymm2
	vpandn	%ymm8,%ymm14,%ymm0
	vpand	%ymm15,%ymm14,%ymm3

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm10,%ymm9
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm10,%ymm1
	vpxor	%ymm3,%ymm0,%ymm0
	vpxor	%ymm10,%ymm11,%ymm3

	vpxor	%ymm1,%ymm9,%ymm9
	vpaddd	%ymm7,%ymm5,%ymm5

	vpsrld	$13,%ymm10,%ymm1

	vpslld	$19,%ymm10,%ymm2
	vpaddd	%ymm0,%ymm5,%ymm5
	vpand	%ymm3,%ymm4,%ymm4

	vpxor	%ymm1,%ymm9,%ymm7

	vpsrld	$22,%ymm10,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm10,%ymm2
	vpxor	%ymm4,%ymm11,%ymm9
	vpaddd	%ymm5,%ymm13,%ymm13

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm5,%ymm9,%ymm9
	vpaddd	%ymm7,%ymm9,%ymm9
	vmovdqu	0-128(%rax),%ymm5
	vpaddd	256-256-128(%rbx),%ymm6,%ymm6

	vpsrld	$3,%ymm5,%ymm7
	vpsrld	$7,%ymm5,%ymm1
	vpslld	$25,%ymm5,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$18,%ymm5,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$14,%ymm5,%ymm2
	vmovdqu	416-256-128(%rbx),%ymm0
	vpsrld	$10,%ymm0,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7
	vpsrld	$17,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$15,%ymm0,%ymm2
	vpaddd	%ymm7,%ymm6,%ymm6
	vpxor	%ymm1,%ymm4,%ymm7
	vpsrld	$19,%ymm0,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$13,%ymm0,%ymm2
	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7
	vpaddd	%ymm7,%ymm6,%ymm6
	vpsrld	$6,%ymm13,%ymm7
	vpslld	$26,%ymm13,%ymm2
	vmovdqu	%ymm6,480-256-128(%rbx)
	vpaddd	%ymm8,%ymm6,%ymm6

	vpsrld	$11,%ymm13,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7
	vpslld	$21,%ymm13,%ymm2
	vpaddd	96(%rbp),%ymm6,%ymm6
	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$25,%ymm13,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$7,%ymm13,%ymm2
	vpandn	%ymm15,%ymm13,%ymm0
	vpand	%ymm14,%ymm13,%ymm4

	vpxor	%ymm1,%ymm7,%ymm7

	vpsrld	$2,%ymm9,%ymm8
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$30,%ymm9,%ymm1
	vpxor	%ymm4,%ymm0,%ymm0
	vpxor	%ymm9,%ymm10,%ymm4

	vpxor	%ymm1,%ymm8,%ymm8
	vpaddd	%ymm7,%ymm6,%ymm6

	vpsrld	$13,%ymm9,%ymm1

	vpslld	$19,%ymm9,%ymm2
	vpaddd	%ymm0,%ymm6,%ymm6
	vpand	%ymm4,%ymm3,%ymm3

	vpxor	%ymm1,%ymm8,%ymm7

	vpsrld	$22,%ymm9,%ymm1
	vpxor	%ymm2,%ymm7,%ymm7

	vpslld	$10,%ymm9,%ymm2
	vpxor	%ymm3,%ymm10,%ymm8
	vpaddd	%ymm6,%ymm12,%ymm12

	vpxor	%ymm1,%ymm7,%ymm7
	vpxor	%ymm2,%ymm7,%ymm7

	vpaddd	%ymm6,%ymm8,%ymm8
	vpaddd	%ymm7,%ymm8,%ymm8
	addq	$256,%rbp
	decl	%ecx
	jnz	.Loop_16_xx_avx2

	movl	$1,%ecx
	leaq	512(%rsp),%rbx
	leaq	K256+128(%rip),%rbp
	cmpl	0(%rbx),%ecx
	cmovgeq	%rbp,%r12
	cmpl	4(%rbx),%ecx
	cmovgeq	%rbp,%r13
	cmpl	8(%rbx),%ecx
	cmovgeq	%rbp,%r14
	cmpl	12(%rbx),%ecx
	cmovgeq	%rbp,%r15
	cmpl	16(%rbx),%ecx
	cmovgeq	%rbp,%r8
	cmpl	20(%rbx),%ecx
	cmovgeq	%rbp,%r9
	cmpl	24(%rbx),%ecx
	cmovgeq	%rbp,%r10
	cmpl	28(%rbx),%ecx
	cmovgeq	%rbp,%r11
	vmovdqa	(%rbx),%ymm7
	vpxor	%ymm0,%ymm0,%ymm0
	vmovdqa	%ymm7,%ymm6
	vpcmpgtd	%ymm0,%ymm6,%ymm6
	vpaddd	%ymm6,%ymm7,%ymm7

	vmovdqu	0-128(%rdi),%ymm0
	vpand	%ymm6,%ymm8,%ymm8
	vmovdqu	32-128(%rdi),%ymm1
	vpand	%ymm6,%ymm9,%ymm9
	vmovdqu	64-128(%rdi),%ymm2
	vpand	%ymm6,%ymm10,%ymm10
	vmovdqu	96-128(%rdi),%ymm5
	vpand	%ymm6,%ymm11,%ymm11
	vpaddd	%ymm0,%ymm8,%ymm8
	vmovdqu	128-128(%rdi),%ymm0
	vpand	%ymm6,%ymm12,%ymm12
	vpaddd	%ymm1,%ymm9,%ymm9
	vmovdqu	160-128(%rdi),%ymm1
	vpand	%ymm6,%ymm13,%ymm13
	vpaddd	%ymm2,%ymm10,%ymm10
	vmovdqu	192-128(%rdi),%ymm2
	vpand	%ymm6,%ymm14,%ymm14
	vpaddd	%ymm5,%ymm11,%ymm11
	vmovdqu	224-128(%rdi),%ymm5
	vpand	%ymm6,%ymm15,%ymm15
	vpaddd	%ymm0,%ymm12,%ymm12
	vpaddd	%ymm1,%ymm13,%ymm13
	vmovdqu	%ymm8,0-128(%rdi)
	vpaddd	%ymm2,%ymm14,%ymm14
	vmovdqu	%ymm9,32-128(%rdi)
	vpaddd	%ymm5,%ymm15,%ymm15
	vmovdqu	%ymm10,64-128(%rdi)
	vmovdqu	%ymm11,96-128(%rdi)
	vmovdqu	%ymm12,128-128(%rdi)
	vmovdqu	%ymm13,160-128(%rdi)
	vmovdqu	%ymm14,192-128(%rdi)
	vmovdqu	%ymm15,224-128(%rdi)

	vmovdqu	%ymm7,(%rbx)
	leaq	256+128(%rsp),%rbx
	vmovdqu	.Lpbswap(%rip),%ymm6
	decl	%edx
	jnz	.Loop_avx2







.Ldone_avx2:
	movq	544(%rsp),%rax
.cfi_def_cfa	%rax,8
	vzeroupper
	movq	-48(%rax),%r15
.cfi_restore	%r15
	movq	-40(%rax),%r14
.cfi_restore	%r14
	movq	-32(%rax),%r13
.cfi_restore	%r13
	movq	-24(%rax),%r12
.cfi_restore	%r12
	movq	-16(%rax),%rbp
.cfi_restore	%rbp
	movq	-8(%rax),%rbx
.cfi_restore	%rbx
	leaq	(%rax),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue_avx2:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha256_multi_block_avx2,.-sha256_multi_block_avx2
.align	256
K256:
.long	1116352408,1116352408,1116352408,1116352408
.long	1116352408,1116352408,1116352408,1116352408
.long	1899447441,1899447441,1899447441,1899447441
.long	1899447441,1899447441,1899447441,1899447441
.long	3049323471,3049323471,3049323471,3049323471
.long	3049323471,3049323471,3049323471,3049323471
.long	3921009573,3921009573,3921009573,3921009573
.long	3921009573,3921009573,3921009573,3921009573
.long	961987163,961987163,961987163,961987163
.long	961987163,961987163,961987163,961987163
.long	1508970993,1508970993,1508970993,1508970993
.long	1508970993,1508970993,1508970993,1508970993
.long	2453635748,2453635748,2453635748,2453635748
.long	2453635748,2453635748,2453635748,2453635748
.long	2870763221,2870763221,2870763221,2870763221
.long	2870763221,2870763221,2870763221,2870763221
.long	3624381080,3624381080,3624381080,3624381080
.long	3624381080,3624381080,3624381080,3624381080
.long	310598401,310598401,310598401,310598401
.long	310598401,310598401,310598401,310598401
.long	607225278,607225278,607225278,607225278
.long	607225278,607225278,607225278,607225278
.long	1426881987,1426881987,1426881987,1426881987
.long	1426881987,1426881987,1426881987,1426881987
.long	1925078388,1925078388,1925078388,1925078388
.long	1925078388,1925078388,1925078388,1925078388
.long	2162078206,2162078206,2162078206,2162078206
.long	2162078206,2162078206,2162078206,2162078206
.long	2614888103,2614888103,2614888103,2614888103
.long	2614888103,2614888103,2614888103,2614888103
.long	3248222580,3248222580,3248222580,3248222580
.long	3248222580,3248222580,3248222580,3248222580
.long	3835390401,3835390401,3835390401,3835390401
.long	3835390401,3835390401,3835390401,3835390401
.long	4022224774,4022224774,4022224774,4022224774
.long	4022224774,4022224774,4022224774,4022224774
.long	264347078,264347078,264347078,264347078
.long	264347078,264347078,264347078,264347078
.long	604807628,604807628,604807628,604807628
.long	604807628,604807628,604807628,604807628
.long	770255983,770255983,770255983,770255983
.long	770255983,770255983,770255983,770255983
.long	1249150122,1249150122,1249150122,1249150122
.long	1249150122,1249150122,1249150122,1249150122
.long	1555081692,1555081692,1555081692,1555081692
.long	1555081692,1555081692,1555081692,1555081692
.long	1996064986,1996064986,1996064986,1996064986
.long	1996064986,1996064986,1996064986,1996064986
.long	2554220882,2554220882,2554220882,2554220882
.long	2554220882,2554220882,2554220882,2554220882
.long	2821834349,2821834349,2821834349,2821834349
.long	2821834349,2821834349,2821834349,2821834349
.long	2952996808,2952996808,2952996808,2952996808
.long	2952996808,2952996808,2952996808,2952996808
.long	3210313671,3210313671,3210313671,3210313671
.long	3210313671,3210313671,3210313671,3210313671
.long	3336571891,3336571891,3336571891,3336571891
.long	3336571891,3336571891,3336571891,3336571891
.long	3584528711,3584528711,3584528711,3584528711
.long	3584528711,3584528711,3584528711,3584528711
.long	113926993,113926993,113926993,113926993
.long	113926993,113926993,113926993,113926993
.long	338241895,338241895,338241895,338241895
.long	338241895,338241895,338241895,338241895
.long	666307205,666307205,666307205,666307205
.long	666307205,666307205,666307205,666307205
.long	773529912,773529912,773529912,773529912
.long	773529912,773529912,773529912,773529912
.long	1294757372,1294757372,1294757372,1294757372
.long	1294757372,1294757372,1294757372,1294757372
.long	1396182291,1396182291,1396182291,1396182291
.long	1396182291,1396182291,1396182291,1396182291
.long	1695183700,1695183700,1695183700,1695183700
.long	1695183700,1695183700,1695183700,1695183700
.long	1986661051,1986661051,1986661051,1986661051
.long	1986661051,1986661051,1986661051,1986661051
.long	2177026350,2177026350,2177026350,2177026350
.long	2177026350,2177026350,2177026350,2177026350
.long	2456956037,2456956037,2456956037,2456956037
.long	2456956037,2456956037,2456956037,2456956037
.long	2730485921,2730485921,2730485921,2730485921
.long	2730485921,2730485921,2730485921,2730485921
.long	2820302411,2820302411,2820302411,2820302411
.long	2820302411,2820302411,2820302411,2820302411
.long	3259730800,3259730800,3259730800,3259730800
.long	3259730800,3259730800,3259730800,3259730800
.long	3345764771,3345764771,3345764771,3345764771
.long	3345764771,3345764771,3345764771,3345764771
.long	3516065817,3516065817,3516065817,3516065817
.long	3516065817,3516065817,3516065817,3516065817
.long	3600352804,3600352804,3600352804,3600352804
.long	3600352804,3600352804,3600352804,3600352804
.long	4094571909,4094571909,4094571909,4094571909
.long	4094571909,4094571909,4094571909,4094571909
.long	275423344,275423344,275423344,275423344
.long	275423344,275423344,275423344,275423344
.long	430227734,430227734,430227734,430227734
.long	430227734,430227734,430227734,430227734
.long	506948616,506948616,506948616,506948616
.long	506948616,506948616,506948616,506948616
.long	659060556,659060556,659060556,659060556
.long	659060556,659060556,659060556,659060556
.long	883997877,883997877,883997877,883997877
.long	883997877,883997877,883997877,883997877
.long	958139571,958139571,958139571,958139571
.long	958139571,958139571,958139571,958139571
.long	1322822218,1322822218,1322822218,1322822218
.long	1322822218,1322822218,1322822218,1322822218
.long	1537002063,1537002063,1537002063,1537002063
.long	1537002063,1537002063,1537002063,1537002063
.long	1747873779,1747873779,1747873779,1747873779
.long	1747873779,1747873779,1747873779,1747873779
.long	1955562222,1955562222,1955562222,1955562222
.long	1955562222,1955562222,1955562222,1955562222
.long	2024104815,2024104815,2024104815,2024104815
.long	2024104815,2024104815,2024104815,2024104815
.long	2227730452,2227730452,2227730452,2227730452
.long	2227730452,2227730452,2227730452,2227730452
.long	2361852424,2361852424,2361852424,2361852424
.long	2361852424,2361852424,2361852424,2361852424
.long	2428436474,2428436474,2428436474,2428436474
.long	2428436474,2428436474,2428436474,2428436474
.long	2756734187,2756734187,2756734187,2756734187
.long	2756734187,2756734187,2756734187,2756734187
.long	3204031479,3204031479,3204031479,3204031479
.long	3204031479,3204031479,3204031479,3204031479
.long	3329325298,3329325298,3329325298,3329325298
.long	3329325298,3329325298,3329325298,3329325298
.Lpbswap:
.long	0x00010203,0x04050607,0x08090a0b,0x0c0d0e0f
.long	0x00010203,0x04050607,0x08090a0b,0x0c0d0e0f
K256_shaext:
.long	0x428a2f98,0x71374491,0xb5c0fbcf,0xe9b5dba5
.long	0x3956c25b,0x59f111f1,0x923f82a4,0xab1c5ed5
.long	0xd807aa98,0x12835b01,0x243185be,0x550c7dc3
.long	0x72be5d74,0x80deb1fe,0x9bdc06a7,0xc19bf174
.long	0xe49b69c1,0xefbe4786,0x0fc19dc6,0x240ca1cc
.long	0x2de92c6f,0x4a7484aa,0x5cb0a9dc,0x76f988da
.long	0x983e5152,0xa831c66d,0xb00327c8,0xbf597fc7
.long	0xc6e00bf3,0xd5a79147,0x06ca6351,0x14292967
.long	0x27b70a85,0x2e1b2138,0x4d2c6dfc,0x53380d13
.long	0x650a7354,0x766a0abb,0x81c2c92e,0x92722c85
.long	0xa2bfe8a1,0xa81a664b,0xc24b8b70,0xc76c51a3
.long	0xd192e819,0xd6990624,0xf40e3585,0x106aa070
.long	0x19a4c116,0x1e376c08,0x2748774c,0x34b0bcb5
.long	0x391c0cb3,0x4ed8aa4a,0x5b9cca4f,0x682e6ff3
.long	0x748f82ee,0x78a5636f,0x84c87814,0x8cc70208
.long	0x90befffa,0xa4506ceb,0xbef9a3f7,0xc67178f2
.byte	83,72,65,50,53,54,32,109,117,108,116,105,45,98,108,111,99,107,32,116,114,97,110,115,102,111,114,109,32,102,111,114,32,120,56,54,95,54,52,44,32,67,82,89,80,84,79,71,65,77,83,32,98,121,32,60,97,112,112,114,111,64,111,112,101,110,115,115,108,46,111,114,103,62,0
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                                                                              node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/crypto/sha/sha256-x86_64.s      0000664 0000000 0000000 00000277164 14746647661 0031040 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	


.globl	sha256_block_data_order
.type	sha256_block_data_order,@function
.align	16
sha256_block_data_order:
.cfi_startproc	
	leaq	OPENSSL_ia32cap_P(%rip),%r11
	movl	0(%r11),%r9d
	movl	4(%r11),%r10d
	movl	8(%r11),%r11d
	testl	$536870912,%r11d
	jnz	_shaext_shortcut
	andl	$296,%r11d
	cmpl	$296,%r11d
	je	.Lavx2_shortcut
	andl	$1073741824,%r9d
	andl	$268435968,%r10d
	orl	%r9d,%r10d
	cmpl	$1342177792,%r10d
	je	.Lavx_shortcut
	testl	$512,%r10d
	jnz	.Lssse3_shortcut
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
	shlq	$4,%rdx
	subq	$64+32,%rsp
	leaq	(%rsi,%rdx,4),%rdx
	andq	$-64,%rsp
	movq	%rdi,64+0(%rsp)
	movq	%rsi,64+8(%rsp)
	movq	%rdx,64+16(%rsp)
	movq	%rax,88(%rsp)
.cfi_escape	0x0f,0x06,0x77,0xd8,0x00,0x06,0x23,0x08
.Lprologue:

	movl	0(%rdi),%eax
	movl	4(%rdi),%ebx
	movl	8(%rdi),%ecx
	movl	12(%rdi),%edx
	movl	16(%rdi),%r8d
	movl	20(%rdi),%r9d
	movl	24(%rdi),%r10d
	movl	28(%rdi),%r11d
	jmp	.Lloop

.align	16
.Lloop:
	movl	%ebx,%edi
	leaq	K256(%rip),%rbp
	xorl	%ecx,%edi
	movl	0(%rsi),%r12d
	movl	%r8d,%r13d
	movl	%eax,%r14d
	bswapl	%r12d
	rorl	$14,%r13d
	movl	%r9d,%r15d

	xorl	%r8d,%r13d
	rorl	$9,%r14d
	xorl	%r10d,%r15d

	movl	%r12d,0(%rsp)
	xorl	%eax,%r14d
	andl	%r8d,%r15d

	rorl	$5,%r13d
	addl	%r11d,%r12d
	xorl	%r10d,%r15d

	rorl	$11,%r14d
	xorl	%r8d,%r13d
	addl	%r15d,%r12d

	movl	%eax,%r15d
	addl	(%rbp),%r12d
	xorl	%eax,%r14d

	xorl	%ebx,%r15d
	rorl	$6,%r13d
	movl	%ebx,%r11d

	andl	%r15d,%edi
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%edi,%r11d
	addl	%r12d,%edx
	addl	%r12d,%r11d

	leaq	4(%rbp),%rbp
	addl	%r14d,%r11d
	movl	4(%rsi),%r12d
	movl	%edx,%r13d
	movl	%r11d,%r14d
	bswapl	%r12d
	rorl	$14,%r13d
	movl	%r8d,%edi

	xorl	%edx,%r13d
	rorl	$9,%r14d
	xorl	%r9d,%edi

	movl	%r12d,4(%rsp)
	xorl	%r11d,%r14d
	andl	%edx,%edi

	rorl	$5,%r13d
	addl	%r10d,%r12d
	xorl	%r9d,%edi

	rorl	$11,%r14d
	xorl	%edx,%r13d
	addl	%edi,%r12d

	movl	%r11d,%edi
	addl	(%rbp),%r12d
	xorl	%r11d,%r14d

	xorl	%eax,%edi
	rorl	$6,%r13d
	movl	%eax,%r10d

	andl	%edi,%r15d
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%r15d,%r10d
	addl	%r12d,%ecx
	addl	%r12d,%r10d

	leaq	4(%rbp),%rbp
	addl	%r14d,%r10d
	movl	8(%rsi),%r12d
	movl	%ecx,%r13d
	movl	%r10d,%r14d
	bswapl	%r12d
	rorl	$14,%r13d
	movl	%edx,%r15d

	xorl	%ecx,%r13d
	rorl	$9,%r14d
	xorl	%r8d,%r15d

	movl	%r12d,8(%rsp)
	xorl	%r10d,%r14d
	andl	%ecx,%r15d

	rorl	$5,%r13d
	addl	%r9d,%r12d
	xorl	%r8d,%r15d

	rorl	$11,%r14d
	xorl	%ecx,%r13d
	addl	%r15d,%r12d

	movl	%r10d,%r15d
	addl	(%rbp),%r12d
	xorl	%r10d,%r14d

	xorl	%r11d,%r15d
	rorl	$6,%r13d
	movl	%r11d,%r9d

	andl	%r15d,%edi
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%edi,%r9d
	addl	%r12d,%ebx
	addl	%r12d,%r9d

	leaq	4(%rbp),%rbp
	addl	%r14d,%r9d
	movl	12(%rsi),%r12d
	movl	%ebx,%r13d
	movl	%r9d,%r14d
	bswapl	%r12d
	rorl	$14,%r13d
	movl	%ecx,%edi

	xorl	%ebx,%r13d
	rorl	$9,%r14d
	xorl	%edx,%edi

	movl	%r12d,12(%rsp)
	xorl	%r9d,%r14d
	andl	%ebx,%edi

	rorl	$5,%r13d
	addl	%r8d,%r12d
	xorl	%edx,%edi

	rorl	$11,%r14d
	xorl	%ebx,%r13d
	addl	%edi,%r12d

	movl	%r9d,%edi
	addl	(%rbp),%r12d
	xorl	%r9d,%r14d

	xorl	%r10d,%edi
	rorl	$6,%r13d
	movl	%r10d,%r8d

	andl	%edi,%r15d
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%r15d,%r8d
	addl	%r12d,%eax
	addl	%r12d,%r8d

	leaq	20(%rbp),%rbp
	addl	%r14d,%r8d
	movl	16(%rsi),%r12d
	movl	%eax,%r13d
	movl	%r8d,%r14d
	bswapl	%r12d
	rorl	$14,%r13d
	movl	%ebx,%r15d

	xorl	%eax,%r13d
	rorl	$9,%r14d
	xorl	%ecx,%r15d

	movl	%r12d,16(%rsp)
	xorl	%r8d,%r14d
	andl	%eax,%r15d

	rorl	$5,%r13d
	addl	%edx,%r12d
	xorl	%ecx,%r15d

	rorl	$11,%r14d
	xorl	%eax,%r13d
	addl	%r15d,%r12d

	movl	%r8d,%r15d
	addl	(%rbp),%r12d
	xorl	%r8d,%r14d

	xorl	%r9d,%r15d
	rorl	$6,%r13d
	movl	%r9d,%edx

	andl	%r15d,%edi
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%edi,%edx
	addl	%r12d,%r11d
	addl	%r12d,%edx

	leaq	4(%rbp),%rbp
	addl	%r14d,%edx
	movl	20(%rsi),%r12d
	movl	%r11d,%r13d
	movl	%edx,%r14d
	bswapl	%r12d
	rorl	$14,%r13d
	movl	%eax,%edi

	xorl	%r11d,%r13d
	rorl	$9,%r14d
	xorl	%ebx,%edi

	movl	%r12d,20(%rsp)
	xorl	%edx,%r14d
	andl	%r11d,%edi

	rorl	$5,%r13d
	addl	%ecx,%r12d
	xorl	%ebx,%edi

	rorl	$11,%r14d
	xorl	%r11d,%r13d
	addl	%edi,%r12d

	movl	%edx,%edi
	addl	(%rbp),%r12d
	xorl	%edx,%r14d

	xorl	%r8d,%edi
	rorl	$6,%r13d
	movl	%r8d,%ecx

	andl	%edi,%r15d
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%r15d,%ecx
	addl	%r12d,%r10d
	addl	%r12d,%ecx

	leaq	4(%rbp),%rbp
	addl	%r14d,%ecx
	movl	24(%rsi),%r12d
	movl	%r10d,%r13d
	movl	%ecx,%r14d
	bswapl	%r12d
	rorl	$14,%r13d
	movl	%r11d,%r15d

	xorl	%r10d,%r13d
	rorl	$9,%r14d
	xorl	%eax,%r15d

	movl	%r12d,24(%rsp)
	xorl	%ecx,%r14d
	andl	%r10d,%r15d

	rorl	$5,%r13d
	addl	%ebx,%r12d
	xorl	%eax,%r15d

	rorl	$11,%r14d
	xorl	%r10d,%r13d
	addl	%r15d,%r12d

	movl	%ecx,%r15d
	addl	(%rbp),%r12d
	xorl	%ecx,%r14d

	xorl	%edx,%r15d
	rorl	$6,%r13d
	movl	%edx,%ebx

	andl	%r15d,%edi
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%edi,%ebx
	addl	%r12d,%r9d
	addl	%r12d,%ebx

	leaq	4(%rbp),%rbp
	addl	%r14d,%ebx
	movl	28(%rsi),%r12d
	movl	%r9d,%r13d
	movl	%ebx,%r14d
	bswapl	%r12d
	rorl	$14,%r13d
	movl	%r10d,%edi

	xorl	%r9d,%r13d
	rorl	$9,%r14d
	xorl	%r11d,%edi

	movl	%r12d,28(%rsp)
	xorl	%ebx,%r14d
	andl	%r9d,%edi

	rorl	$5,%r13d
	addl	%eax,%r12d
	xorl	%r11d,%edi

	rorl	$11,%r14d
	xorl	%r9d,%r13d
	addl	%edi,%r12d

	movl	%ebx,%edi
	addl	(%rbp),%r12d
	xorl	%ebx,%r14d

	xorl	%ecx,%edi
	rorl	$6,%r13d
	movl	%ecx,%eax

	andl	%edi,%r15d
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%r15d,%eax
	addl	%r12d,%r8d
	addl	%r12d,%eax

	leaq	20(%rbp),%rbp
	addl	%r14d,%eax
	movl	32(%rsi),%r12d
	movl	%r8d,%r13d
	movl	%eax,%r14d
	bswapl	%r12d
	rorl	$14,%r13d
	movl	%r9d,%r15d

	xorl	%r8d,%r13d
	rorl	$9,%r14d
	xorl	%r10d,%r15d

	movl	%r12d,32(%rsp)
	xorl	%eax,%r14d
	andl	%r8d,%r15d

	rorl	$5,%r13d
	addl	%r11d,%r12d
	xorl	%r10d,%r15d

	rorl	$11,%r14d
	xorl	%r8d,%r13d
	addl	%r15d,%r12d

	movl	%eax,%r15d
	addl	(%rbp),%r12d
	xorl	%eax,%r14d

	xorl	%ebx,%r15d
	rorl	$6,%r13d
	movl	%ebx,%r11d

	andl	%r15d,%edi
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%edi,%r11d
	addl	%r12d,%edx
	addl	%r12d,%r11d

	leaq	4(%rbp),%rbp
	addl	%r14d,%r11d
	movl	36(%rsi),%r12d
	movl	%edx,%r13d
	movl	%r11d,%r14d
	bswapl	%r12d
	rorl	$14,%r13d
	movl	%r8d,%edi

	xorl	%edx,%r13d
	rorl	$9,%r14d
	xorl	%r9d,%edi

	movl	%r12d,36(%rsp)
	xorl	%r11d,%r14d
	andl	%edx,%edi

	rorl	$5,%r13d
	addl	%r10d,%r12d
	xorl	%r9d,%edi

	rorl	$11,%r14d
	xorl	%edx,%r13d
	addl	%edi,%r12d

	movl	%r11d,%edi
	addl	(%rbp),%r12d
	xorl	%r11d,%r14d

	xorl	%eax,%edi
	rorl	$6,%r13d
	movl	%eax,%r10d

	andl	%edi,%r15d
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%r15d,%r10d
	addl	%r12d,%ecx
	addl	%r12d,%r10d

	leaq	4(%rbp),%rbp
	addl	%r14d,%r10d
	movl	40(%rsi),%r12d
	movl	%ecx,%r13d
	movl	%r10d,%r14d
	bswapl	%r12d
	rorl	$14,%r13d
	movl	%edx,%r15d

	xorl	%ecx,%r13d
	rorl	$9,%r14d
	xorl	%r8d,%r15d

	movl	%r12d,40(%rsp)
	xorl	%r10d,%r14d
	andl	%ecx,%r15d

	rorl	$5,%r13d
	addl	%r9d,%r12d
	xorl	%r8d,%r15d

	rorl	$11,%r14d
	xorl	%ecx,%r13d
	addl	%r15d,%r12d

	movl	%r10d,%r15d
	addl	(%rbp),%r12d
	xorl	%r10d,%r14d

	xorl	%r11d,%r15d
	rorl	$6,%r13d
	movl	%r11d,%r9d

	andl	%r15d,%edi
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%edi,%r9d
	addl	%r12d,%ebx
	addl	%r12d,%r9d

	leaq	4(%rbp),%rbp
	addl	%r14d,%r9d
	movl	44(%rsi),%r12d
	movl	%ebx,%r13d
	movl	%r9d,%r14d
	bswapl	%r12d
	rorl	$14,%r13d
	movl	%ecx,%edi

	xorl	%ebx,%r13d
	rorl	$9,%r14d
	xorl	%edx,%edi

	movl	%r12d,44(%rsp)
	xorl	%r9d,%r14d
	andl	%ebx,%edi

	rorl	$5,%r13d
	addl	%r8d,%r12d
	xorl	%edx,%edi

	rorl	$11,%r14d
	xorl	%ebx,%r13d
	addl	%edi,%r12d

	movl	%r9d,%edi
	addl	(%rbp),%r12d
	xorl	%r9d,%r14d

	xorl	%r10d,%edi
	rorl	$6,%r13d
	movl	%r10d,%r8d

	andl	%edi,%r15d
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%r15d,%r8d
	addl	%r12d,%eax
	addl	%r12d,%r8d

	leaq	20(%rbp),%rbp
	addl	%r14d,%r8d
	movl	48(%rsi),%r12d
	movl	%eax,%r13d
	movl	%r8d,%r14d
	bswapl	%r12d
	rorl	$14,%r13d
	movl	%ebx,%r15d

	xorl	%eax,%r13d
	rorl	$9,%r14d
	xorl	%ecx,%r15d

	movl	%r12d,48(%rsp)
	xorl	%r8d,%r14d
	andl	%eax,%r15d

	rorl	$5,%r13d
	addl	%edx,%r12d
	xorl	%ecx,%r15d

	rorl	$11,%r14d
	xorl	%eax,%r13d
	addl	%r15d,%r12d

	movl	%r8d,%r15d
	addl	(%rbp),%r12d
	xorl	%r8d,%r14d

	xorl	%r9d,%r15d
	rorl	$6,%r13d
	movl	%r9d,%edx

	andl	%r15d,%edi
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%edi,%edx
	addl	%r12d,%r11d
	addl	%r12d,%edx

	leaq	4(%rbp),%rbp
	addl	%r14d,%edx
	movl	52(%rsi),%r12d
	movl	%r11d,%r13d
	movl	%edx,%r14d
	bswapl	%r12d
	rorl	$14,%r13d
	movl	%eax,%edi

	xorl	%r11d,%r13d
	rorl	$9,%r14d
	xorl	%ebx,%edi

	movl	%r12d,52(%rsp)
	xorl	%edx,%r14d
	andl	%r11d,%edi

	rorl	$5,%r13d
	addl	%ecx,%r12d
	xorl	%ebx,%edi

	rorl	$11,%r14d
	xorl	%r11d,%r13d
	addl	%edi,%r12d

	movl	%edx,%edi
	addl	(%rbp),%r12d
	xorl	%edx,%r14d

	xorl	%r8d,%edi
	rorl	$6,%r13d
	movl	%r8d,%ecx

	andl	%edi,%r15d
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%r15d,%ecx
	addl	%r12d,%r10d
	addl	%r12d,%ecx

	leaq	4(%rbp),%rbp
	addl	%r14d,%ecx
	movl	56(%rsi),%r12d
	movl	%r10d,%r13d
	movl	%ecx,%r14d
	bswapl	%r12d
	rorl	$14,%r13d
	movl	%r11d,%r15d

	xorl	%r10d,%r13d
	rorl	$9,%r14d
	xorl	%eax,%r15d

	movl	%r12d,56(%rsp)
	xorl	%ecx,%r14d
	andl	%r10d,%r15d

	rorl	$5,%r13d
	addl	%ebx,%r12d
	xorl	%eax,%r15d

	rorl	$11,%r14d
	xorl	%r10d,%r13d
	addl	%r15d,%r12d

	movl	%ecx,%r15d
	addl	(%rbp),%r12d
	xorl	%ecx,%r14d

	xorl	%edx,%r15d
	rorl	$6,%r13d
	movl	%edx,%ebx

	andl	%r15d,%edi
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%edi,%ebx
	addl	%r12d,%r9d
	addl	%r12d,%ebx

	leaq	4(%rbp),%rbp
	addl	%r14d,%ebx
	movl	60(%rsi),%r12d
	movl	%r9d,%r13d
	movl	%ebx,%r14d
	bswapl	%r12d
	rorl	$14,%r13d
	movl	%r10d,%edi

	xorl	%r9d,%r13d
	rorl	$9,%r14d
	xorl	%r11d,%edi

	movl	%r12d,60(%rsp)
	xorl	%ebx,%r14d
	andl	%r9d,%edi

	rorl	$5,%r13d
	addl	%eax,%r12d
	xorl	%r11d,%edi

	rorl	$11,%r14d
	xorl	%r9d,%r13d
	addl	%edi,%r12d

	movl	%ebx,%edi
	addl	(%rbp),%r12d
	xorl	%ebx,%r14d

	xorl	%ecx,%edi
	rorl	$6,%r13d
	movl	%ecx,%eax

	andl	%edi,%r15d
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%r15d,%eax
	addl	%r12d,%r8d
	addl	%r12d,%eax

	leaq	20(%rbp),%rbp
	jmp	.Lrounds_16_xx
.align	16
.Lrounds_16_xx:
	movl	4(%rsp),%r13d
	movl	56(%rsp),%r15d

	movl	%r13d,%r12d
	rorl	$11,%r13d
	addl	%r14d,%eax
	movl	%r15d,%r14d
	rorl	$2,%r15d

	xorl	%r12d,%r13d
	shrl	$3,%r12d
	rorl	$7,%r13d
	xorl	%r14d,%r15d
	shrl	$10,%r14d

	rorl	$17,%r15d
	xorl	%r13d,%r12d
	xorl	%r14d,%r15d
	addl	36(%rsp),%r12d

	addl	0(%rsp),%r12d
	movl	%r8d,%r13d
	addl	%r15d,%r12d
	movl	%eax,%r14d
	rorl	$14,%r13d
	movl	%r9d,%r15d

	xorl	%r8d,%r13d
	rorl	$9,%r14d
	xorl	%r10d,%r15d

	movl	%r12d,0(%rsp)
	xorl	%eax,%r14d
	andl	%r8d,%r15d

	rorl	$5,%r13d
	addl	%r11d,%r12d
	xorl	%r10d,%r15d

	rorl	$11,%r14d
	xorl	%r8d,%r13d
	addl	%r15d,%r12d

	movl	%eax,%r15d
	addl	(%rbp),%r12d
	xorl	%eax,%r14d

	xorl	%ebx,%r15d
	rorl	$6,%r13d
	movl	%ebx,%r11d

	andl	%r15d,%edi
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%edi,%r11d
	addl	%r12d,%edx
	addl	%r12d,%r11d

	leaq	4(%rbp),%rbp
	movl	8(%rsp),%r13d
	movl	60(%rsp),%edi

	movl	%r13d,%r12d
	rorl	$11,%r13d
	addl	%r14d,%r11d
	movl	%edi,%r14d
	rorl	$2,%edi

	xorl	%r12d,%r13d
	shrl	$3,%r12d
	rorl	$7,%r13d
	xorl	%r14d,%edi
	shrl	$10,%r14d

	rorl	$17,%edi
	xorl	%r13d,%r12d
	xorl	%r14d,%edi
	addl	40(%rsp),%r12d

	addl	4(%rsp),%r12d
	movl	%edx,%r13d
	addl	%edi,%r12d
	movl	%r11d,%r14d
	rorl	$14,%r13d
	movl	%r8d,%edi

	xorl	%edx,%r13d
	rorl	$9,%r14d
	xorl	%r9d,%edi

	movl	%r12d,4(%rsp)
	xorl	%r11d,%r14d
	andl	%edx,%edi

	rorl	$5,%r13d
	addl	%r10d,%r12d
	xorl	%r9d,%edi

	rorl	$11,%r14d
	xorl	%edx,%r13d
	addl	%edi,%r12d

	movl	%r11d,%edi
	addl	(%rbp),%r12d
	xorl	%r11d,%r14d

	xorl	%eax,%edi
	rorl	$6,%r13d
	movl	%eax,%r10d

	andl	%edi,%r15d
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%r15d,%r10d
	addl	%r12d,%ecx
	addl	%r12d,%r10d

	leaq	4(%rbp),%rbp
	movl	12(%rsp),%r13d
	movl	0(%rsp),%r15d

	movl	%r13d,%r12d
	rorl	$11,%r13d
	addl	%r14d,%r10d
	movl	%r15d,%r14d
	rorl	$2,%r15d

	xorl	%r12d,%r13d
	shrl	$3,%r12d
	rorl	$7,%r13d
	xorl	%r14d,%r15d
	shrl	$10,%r14d

	rorl	$17,%r15d
	xorl	%r13d,%r12d
	xorl	%r14d,%r15d
	addl	44(%rsp),%r12d

	addl	8(%rsp),%r12d
	movl	%ecx,%r13d
	addl	%r15d,%r12d
	movl	%r10d,%r14d
	rorl	$14,%r13d
	movl	%edx,%r15d

	xorl	%ecx,%r13d
	rorl	$9,%r14d
	xorl	%r8d,%r15d

	movl	%r12d,8(%rsp)
	xorl	%r10d,%r14d
	andl	%ecx,%r15d

	rorl	$5,%r13d
	addl	%r9d,%r12d
	xorl	%r8d,%r15d

	rorl	$11,%r14d
	xorl	%ecx,%r13d
	addl	%r15d,%r12d

	movl	%r10d,%r15d
	addl	(%rbp),%r12d
	xorl	%r10d,%r14d

	xorl	%r11d,%r15d
	rorl	$6,%r13d
	movl	%r11d,%r9d

	andl	%r15d,%edi
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%edi,%r9d
	addl	%r12d,%ebx
	addl	%r12d,%r9d

	leaq	4(%rbp),%rbp
	movl	16(%rsp),%r13d
	movl	4(%rsp),%edi

	movl	%r13d,%r12d
	rorl	$11,%r13d
	addl	%r14d,%r9d
	movl	%edi,%r14d
	rorl	$2,%edi

	xorl	%r12d,%r13d
	shrl	$3,%r12d
	rorl	$7,%r13d
	xorl	%r14d,%edi
	shrl	$10,%r14d

	rorl	$17,%edi
	xorl	%r13d,%r12d
	xorl	%r14d,%edi
	addl	48(%rsp),%r12d

	addl	12(%rsp),%r12d
	movl	%ebx,%r13d
	addl	%edi,%r12d
	movl	%r9d,%r14d
	rorl	$14,%r13d
	movl	%ecx,%edi

	xorl	%ebx,%r13d
	rorl	$9,%r14d
	xorl	%edx,%edi

	movl	%r12d,12(%rsp)
	xorl	%r9d,%r14d
	andl	%ebx,%edi

	rorl	$5,%r13d
	addl	%r8d,%r12d
	xorl	%edx,%edi

	rorl	$11,%r14d
	xorl	%ebx,%r13d
	addl	%edi,%r12d

	movl	%r9d,%edi
	addl	(%rbp),%r12d
	xorl	%r9d,%r14d

	xorl	%r10d,%edi
	rorl	$6,%r13d
	movl	%r10d,%r8d

	andl	%edi,%r15d
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%r15d,%r8d
	addl	%r12d,%eax
	addl	%r12d,%r8d

	leaq	20(%rbp),%rbp
	movl	20(%rsp),%r13d
	movl	8(%rsp),%r15d

	movl	%r13d,%r12d
	rorl	$11,%r13d
	addl	%r14d,%r8d
	movl	%r15d,%r14d
	rorl	$2,%r15d

	xorl	%r12d,%r13d
	shrl	$3,%r12d
	rorl	$7,%r13d
	xorl	%r14d,%r15d
	shrl	$10,%r14d

	rorl	$17,%r15d
	xorl	%r13d,%r12d
	xorl	%r14d,%r15d
	addl	52(%rsp),%r12d

	addl	16(%rsp),%r12d
	movl	%eax,%r13d
	addl	%r15d,%r12d
	movl	%r8d,%r14d
	rorl	$14,%r13d
	movl	%ebx,%r15d

	xorl	%eax,%r13d
	rorl	$9,%r14d
	xorl	%ecx,%r15d

	movl	%r12d,16(%rsp)
	xorl	%r8d,%r14d
	andl	%eax,%r15d

	rorl	$5,%r13d
	addl	%edx,%r12d
	xorl	%ecx,%r15d

	rorl	$11,%r14d
	xorl	%eax,%r13d
	addl	%r15d,%r12d

	movl	%r8d,%r15d
	addl	(%rbp),%r12d
	xorl	%r8d,%r14d

	xorl	%r9d,%r15d
	rorl	$6,%r13d
	movl	%r9d,%edx

	andl	%r15d,%edi
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%edi,%edx
	addl	%r12d,%r11d
	addl	%r12d,%edx

	leaq	4(%rbp),%rbp
	movl	24(%rsp),%r13d
	movl	12(%rsp),%edi

	movl	%r13d,%r12d
	rorl	$11,%r13d
	addl	%r14d,%edx
	movl	%edi,%r14d
	rorl	$2,%edi

	xorl	%r12d,%r13d
	shrl	$3,%r12d
	rorl	$7,%r13d
	xorl	%r14d,%edi
	shrl	$10,%r14d

	rorl	$17,%edi
	xorl	%r13d,%r12d
	xorl	%r14d,%edi
	addl	56(%rsp),%r12d

	addl	20(%rsp),%r12d
	movl	%r11d,%r13d
	addl	%edi,%r12d
	movl	%edx,%r14d
	rorl	$14,%r13d
	movl	%eax,%edi

	xorl	%r11d,%r13d
	rorl	$9,%r14d
	xorl	%ebx,%edi

	movl	%r12d,20(%rsp)
	xorl	%edx,%r14d
	andl	%r11d,%edi

	rorl	$5,%r13d
	addl	%ecx,%r12d
	xorl	%ebx,%edi

	rorl	$11,%r14d
	xorl	%r11d,%r13d
	addl	%edi,%r12d

	movl	%edx,%edi
	addl	(%rbp),%r12d
	xorl	%edx,%r14d

	xorl	%r8d,%edi
	rorl	$6,%r13d
	movl	%r8d,%ecx

	andl	%edi,%r15d
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%r15d,%ecx
	addl	%r12d,%r10d
	addl	%r12d,%ecx

	leaq	4(%rbp),%rbp
	movl	28(%rsp),%r13d
	movl	16(%rsp),%r15d

	movl	%r13d,%r12d
	rorl	$11,%r13d
	addl	%r14d,%ecx
	movl	%r15d,%r14d
	rorl	$2,%r15d

	xorl	%r12d,%r13d
	shrl	$3,%r12d
	rorl	$7,%r13d
	xorl	%r14d,%r15d
	shrl	$10,%r14d

	rorl	$17,%r15d
	xorl	%r13d,%r12d
	xorl	%r14d,%r15d
	addl	60(%rsp),%r12d

	addl	24(%rsp),%r12d
	movl	%r10d,%r13d
	addl	%r15d,%r12d
	movl	%ecx,%r14d
	rorl	$14,%r13d
	movl	%r11d,%r15d

	xorl	%r10d,%r13d
	rorl	$9,%r14d
	xorl	%eax,%r15d

	movl	%r12d,24(%rsp)
	xorl	%ecx,%r14d
	andl	%r10d,%r15d

	rorl	$5,%r13d
	addl	%ebx,%r12d
	xorl	%eax,%r15d

	rorl	$11,%r14d
	xorl	%r10d,%r13d
	addl	%r15d,%r12d

	movl	%ecx,%r15d
	addl	(%rbp),%r12d
	xorl	%ecx,%r14d

	xorl	%edx,%r15d
	rorl	$6,%r13d
	movl	%edx,%ebx

	andl	%r15d,%edi
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%edi,%ebx
	addl	%r12d,%r9d
	addl	%r12d,%ebx

	leaq	4(%rbp),%rbp
	movl	32(%rsp),%r13d
	movl	20(%rsp),%edi

	movl	%r13d,%r12d
	rorl	$11,%r13d
	addl	%r14d,%ebx
	movl	%edi,%r14d
	rorl	$2,%edi

	xorl	%r12d,%r13d
	shrl	$3,%r12d
	rorl	$7,%r13d
	xorl	%r14d,%edi
	shrl	$10,%r14d

	rorl	$17,%edi
	xorl	%r13d,%r12d
	xorl	%r14d,%edi
	addl	0(%rsp),%r12d

	addl	28(%rsp),%r12d
	movl	%r9d,%r13d
	addl	%edi,%r12d
	movl	%ebx,%r14d
	rorl	$14,%r13d
	movl	%r10d,%edi

	xorl	%r9d,%r13d
	rorl	$9,%r14d
	xorl	%r11d,%edi

	movl	%r12d,28(%rsp)
	xorl	%ebx,%r14d
	andl	%r9d,%edi

	rorl	$5,%r13d
	addl	%eax,%r12d
	xorl	%r11d,%edi

	rorl	$11,%r14d
	xorl	%r9d,%r13d
	addl	%edi,%r12d

	movl	%ebx,%edi
	addl	(%rbp),%r12d
	xorl	%ebx,%r14d

	xorl	%ecx,%edi
	rorl	$6,%r13d
	movl	%ecx,%eax

	andl	%edi,%r15d
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%r15d,%eax
	addl	%r12d,%r8d
	addl	%r12d,%eax

	leaq	20(%rbp),%rbp
	movl	36(%rsp),%r13d
	movl	24(%rsp),%r15d

	movl	%r13d,%r12d
	rorl	$11,%r13d
	addl	%r14d,%eax
	movl	%r15d,%r14d
	rorl	$2,%r15d

	xorl	%r12d,%r13d
	shrl	$3,%r12d
	rorl	$7,%r13d
	xorl	%r14d,%r15d
	shrl	$10,%r14d

	rorl	$17,%r15d
	xorl	%r13d,%r12d
	xorl	%r14d,%r15d
	addl	4(%rsp),%r12d

	addl	32(%rsp),%r12d
	movl	%r8d,%r13d
	addl	%r15d,%r12d
	movl	%eax,%r14d
	rorl	$14,%r13d
	movl	%r9d,%r15d

	xorl	%r8d,%r13d
	rorl	$9,%r14d
	xorl	%r10d,%r15d

	movl	%r12d,32(%rsp)
	xorl	%eax,%r14d
	andl	%r8d,%r15d

	rorl	$5,%r13d
	addl	%r11d,%r12d
	xorl	%r10d,%r15d

	rorl	$11,%r14d
	xorl	%r8d,%r13d
	addl	%r15d,%r12d

	movl	%eax,%r15d
	addl	(%rbp),%r12d
	xorl	%eax,%r14d

	xorl	%ebx,%r15d
	rorl	$6,%r13d
	movl	%ebx,%r11d

	andl	%r15d,%edi
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%edi,%r11d
	addl	%r12d,%edx
	addl	%r12d,%r11d

	leaq	4(%rbp),%rbp
	movl	40(%rsp),%r13d
	movl	28(%rsp),%edi

	movl	%r13d,%r12d
	rorl	$11,%r13d
	addl	%r14d,%r11d
	movl	%edi,%r14d
	rorl	$2,%edi

	xorl	%r12d,%r13d
	shrl	$3,%r12d
	rorl	$7,%r13d
	xorl	%r14d,%edi
	shrl	$10,%r14d

	rorl	$17,%edi
	xorl	%r13d,%r12d
	xorl	%r14d,%edi
	addl	8(%rsp),%r12d

	addl	36(%rsp),%r12d
	movl	%edx,%r13d
	addl	%edi,%r12d
	movl	%r11d,%r14d
	rorl	$14,%r13d
	movl	%r8d,%edi

	xorl	%edx,%r13d
	rorl	$9,%r14d
	xorl	%r9d,%edi

	movl	%r12d,36(%rsp)
	xorl	%r11d,%r14d
	andl	%edx,%edi

	rorl	$5,%r13d
	addl	%r10d,%r12d
	xorl	%r9d,%edi

	rorl	$11,%r14d
	xorl	%edx,%r13d
	addl	%edi,%r12d

	movl	%r11d,%edi
	addl	(%rbp),%r12d
	xorl	%r11d,%r14d

	xorl	%eax,%edi
	rorl	$6,%r13d
	movl	%eax,%r10d

	andl	%edi,%r15d
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%r15d,%r10d
	addl	%r12d,%ecx
	addl	%r12d,%r10d

	leaq	4(%rbp),%rbp
	movl	44(%rsp),%r13d
	movl	32(%rsp),%r15d

	movl	%r13d,%r12d
	rorl	$11,%r13d
	addl	%r14d,%r10d
	movl	%r15d,%r14d
	rorl	$2,%r15d

	xorl	%r12d,%r13d
	shrl	$3,%r12d
	rorl	$7,%r13d
	xorl	%r14d,%r15d
	shrl	$10,%r14d

	rorl	$17,%r15d
	xorl	%r13d,%r12d
	xorl	%r14d,%r15d
	addl	12(%rsp),%r12d

	addl	40(%rsp),%r12d
	movl	%ecx,%r13d
	addl	%r15d,%r12d
	movl	%r10d,%r14d
	rorl	$14,%r13d
	movl	%edx,%r15d

	xorl	%ecx,%r13d
	rorl	$9,%r14d
	xorl	%r8d,%r15d

	movl	%r12d,40(%rsp)
	xorl	%r10d,%r14d
	andl	%ecx,%r15d

	rorl	$5,%r13d
	addl	%r9d,%r12d
	xorl	%r8d,%r15d

	rorl	$11,%r14d
	xorl	%ecx,%r13d
	addl	%r15d,%r12d

	movl	%r10d,%r15d
	addl	(%rbp),%r12d
	xorl	%r10d,%r14d

	xorl	%r11d,%r15d
	rorl	$6,%r13d
	movl	%r11d,%r9d

	andl	%r15d,%edi
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%edi,%r9d
	addl	%r12d,%ebx
	addl	%r12d,%r9d

	leaq	4(%rbp),%rbp
	movl	48(%rsp),%r13d
	movl	36(%rsp),%edi

	movl	%r13d,%r12d
	rorl	$11,%r13d
	addl	%r14d,%r9d
	movl	%edi,%r14d
	rorl	$2,%edi

	xorl	%r12d,%r13d
	shrl	$3,%r12d
	rorl	$7,%r13d
	xorl	%r14d,%edi
	shrl	$10,%r14d

	rorl	$17,%edi
	xorl	%r13d,%r12d
	xorl	%r14d,%edi
	addl	16(%rsp),%r12d

	addl	44(%rsp),%r12d
	movl	%ebx,%r13d
	addl	%edi,%r12d
	movl	%r9d,%r14d
	rorl	$14,%r13d
	movl	%ecx,%edi

	xorl	%ebx,%r13d
	rorl	$9,%r14d
	xorl	%edx,%edi

	movl	%r12d,44(%rsp)
	xorl	%r9d,%r14d
	andl	%ebx,%edi

	rorl	$5,%r13d
	addl	%r8d,%r12d
	xorl	%edx,%edi

	rorl	$11,%r14d
	xorl	%ebx,%r13d
	addl	%edi,%r12d

	movl	%r9d,%edi
	addl	(%rbp),%r12d
	xorl	%r9d,%r14d

	xorl	%r10d,%edi
	rorl	$6,%r13d
	movl	%r10d,%r8d

	andl	%edi,%r15d
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%r15d,%r8d
	addl	%r12d,%eax
	addl	%r12d,%r8d

	leaq	20(%rbp),%rbp
	movl	52(%rsp),%r13d
	movl	40(%rsp),%r15d

	movl	%r13d,%r12d
	rorl	$11,%r13d
	addl	%r14d,%r8d
	movl	%r15d,%r14d
	rorl	$2,%r15d

	xorl	%r12d,%r13d
	shrl	$3,%r12d
	rorl	$7,%r13d
	xorl	%r14d,%r15d
	shrl	$10,%r14d

	rorl	$17,%r15d
	xorl	%r13d,%r12d
	xorl	%r14d,%r15d
	addl	20(%rsp),%r12d

	addl	48(%rsp),%r12d
	movl	%eax,%r13d
	addl	%r15d,%r12d
	movl	%r8d,%r14d
	rorl	$14,%r13d
	movl	%ebx,%r15d

	xorl	%eax,%r13d
	rorl	$9,%r14d
	xorl	%ecx,%r15d

	movl	%r12d,48(%rsp)
	xorl	%r8d,%r14d
	andl	%eax,%r15d

	rorl	$5,%r13d
	addl	%edx,%r12d
	xorl	%ecx,%r15d

	rorl	$11,%r14d
	xorl	%eax,%r13d
	addl	%r15d,%r12d

	movl	%r8d,%r15d
	addl	(%rbp),%r12d
	xorl	%r8d,%r14d

	xorl	%r9d,%r15d
	rorl	$6,%r13d
	movl	%r9d,%edx

	andl	%r15d,%edi
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%edi,%edx
	addl	%r12d,%r11d
	addl	%r12d,%edx

	leaq	4(%rbp),%rbp
	movl	56(%rsp),%r13d
	movl	44(%rsp),%edi

	movl	%r13d,%r12d
	rorl	$11,%r13d
	addl	%r14d,%edx
	movl	%edi,%r14d
	rorl	$2,%edi

	xorl	%r12d,%r13d
	shrl	$3,%r12d
	rorl	$7,%r13d
	xorl	%r14d,%edi
	shrl	$10,%r14d

	rorl	$17,%edi
	xorl	%r13d,%r12d
	xorl	%r14d,%edi
	addl	24(%rsp),%r12d

	addl	52(%rsp),%r12d
	movl	%r11d,%r13d
	addl	%edi,%r12d
	movl	%edx,%r14d
	rorl	$14,%r13d
	movl	%eax,%edi

	xorl	%r11d,%r13d
	rorl	$9,%r14d
	xorl	%ebx,%edi

	movl	%r12d,52(%rsp)
	xorl	%edx,%r14d
	andl	%r11d,%edi

	rorl	$5,%r13d
	addl	%ecx,%r12d
	xorl	%ebx,%edi

	rorl	$11,%r14d
	xorl	%r11d,%r13d
	addl	%edi,%r12d

	movl	%edx,%edi
	addl	(%rbp),%r12d
	xorl	%edx,%r14d

	xorl	%r8d,%edi
	rorl	$6,%r13d
	movl	%r8d,%ecx

	andl	%edi,%r15d
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%r15d,%ecx
	addl	%r12d,%r10d
	addl	%r12d,%ecx

	leaq	4(%rbp),%rbp
	movl	60(%rsp),%r13d
	movl	48(%rsp),%r15d

	movl	%r13d,%r12d
	rorl	$11,%r13d
	addl	%r14d,%ecx
	movl	%r15d,%r14d
	rorl	$2,%r15d

	xorl	%r12d,%r13d
	shrl	$3,%r12d
	rorl	$7,%r13d
	xorl	%r14d,%r15d
	shrl	$10,%r14d

	rorl	$17,%r15d
	xorl	%r13d,%r12d
	xorl	%r14d,%r15d
	addl	28(%rsp),%r12d

	addl	56(%rsp),%r12d
	movl	%r10d,%r13d
	addl	%r15d,%r12d
	movl	%ecx,%r14d
	rorl	$14,%r13d
	movl	%r11d,%r15d

	xorl	%r10d,%r13d
	rorl	$9,%r14d
	xorl	%eax,%r15d

	movl	%r12d,56(%rsp)
	xorl	%ecx,%r14d
	andl	%r10d,%r15d

	rorl	$5,%r13d
	addl	%ebx,%r12d
	xorl	%eax,%r15d

	rorl	$11,%r14d
	xorl	%r10d,%r13d
	addl	%r15d,%r12d

	movl	%ecx,%r15d
	addl	(%rbp),%r12d
	xorl	%ecx,%r14d

	xorl	%edx,%r15d
	rorl	$6,%r13d
	movl	%edx,%ebx

	andl	%r15d,%edi
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%edi,%ebx
	addl	%r12d,%r9d
	addl	%r12d,%ebx

	leaq	4(%rbp),%rbp
	movl	0(%rsp),%r13d
	movl	52(%rsp),%edi

	movl	%r13d,%r12d
	rorl	$11,%r13d
	addl	%r14d,%ebx
	movl	%edi,%r14d
	rorl	$2,%edi

	xorl	%r12d,%r13d
	shrl	$3,%r12d
	rorl	$7,%r13d
	xorl	%r14d,%edi
	shrl	$10,%r14d

	rorl	$17,%edi
	xorl	%r13d,%r12d
	xorl	%r14d,%edi
	addl	32(%rsp),%r12d

	addl	60(%rsp),%r12d
	movl	%r9d,%r13d
	addl	%edi,%r12d
	movl	%ebx,%r14d
	rorl	$14,%r13d
	movl	%r10d,%edi

	xorl	%r9d,%r13d
	rorl	$9,%r14d
	xorl	%r11d,%edi

	movl	%r12d,60(%rsp)
	xorl	%ebx,%r14d
	andl	%r9d,%edi

	rorl	$5,%r13d
	addl	%eax,%r12d
	xorl	%r11d,%edi

	rorl	$11,%r14d
	xorl	%r9d,%r13d
	addl	%edi,%r12d

	movl	%ebx,%edi
	addl	(%rbp),%r12d
	xorl	%ebx,%r14d

	xorl	%ecx,%edi
	rorl	$6,%r13d
	movl	%ecx,%eax

	andl	%edi,%r15d
	rorl	$2,%r14d
	addl	%r13d,%r12d

	xorl	%r15d,%eax
	addl	%r12d,%r8d
	addl	%r12d,%eax

	leaq	20(%rbp),%rbp
	cmpb	$0,3(%rbp)
	jnz	.Lrounds_16_xx

	movq	64+0(%rsp),%rdi
	addl	%r14d,%eax
	leaq	64(%rsi),%rsi

	addl	0(%rdi),%eax
	addl	4(%rdi),%ebx
	addl	8(%rdi),%ecx
	addl	12(%rdi),%edx
	addl	16(%rdi),%r8d
	addl	20(%rdi),%r9d
	addl	24(%rdi),%r10d
	addl	28(%rdi),%r11d

	cmpq	64+16(%rsp),%rsi

	movl	%eax,0(%rdi)
	movl	%ebx,4(%rdi)
	movl	%ecx,8(%rdi)
	movl	%edx,12(%rdi)
	movl	%r8d,16(%rdi)
	movl	%r9d,20(%rdi)
	movl	%r10d,24(%rdi)
	movl	%r11d,28(%rdi)
	jb	.Lloop

	movq	88(%rsp),%rsi
.cfi_def_cfa	%rsi,8
	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha256_block_data_order,.-sha256_block_data_order
.align	64
.type	K256,@object
K256:
.long	0x428a2f98,0x71374491,0xb5c0fbcf,0xe9b5dba5
.long	0x428a2f98,0x71374491,0xb5c0fbcf,0xe9b5dba5
.long	0x3956c25b,0x59f111f1,0x923f82a4,0xab1c5ed5
.long	0x3956c25b,0x59f111f1,0x923f82a4,0xab1c5ed5
.long	0xd807aa98,0x12835b01,0x243185be,0x550c7dc3
.long	0xd807aa98,0x12835b01,0x243185be,0x550c7dc3
.long	0x72be5d74,0x80deb1fe,0x9bdc06a7,0xc19bf174
.long	0x72be5d74,0x80deb1fe,0x9bdc06a7,0xc19bf174
.long	0xe49b69c1,0xefbe4786,0x0fc19dc6,0x240ca1cc
.long	0xe49b69c1,0xefbe4786,0x0fc19dc6,0x240ca1cc
.long	0x2de92c6f,0x4a7484aa,0x5cb0a9dc,0x76f988da
.long	0x2de92c6f,0x4a7484aa,0x5cb0a9dc,0x76f988da
.long	0x983e5152,0xa831c66d,0xb00327c8,0xbf597fc7
.long	0x983e5152,0xa831c66d,0xb00327c8,0xbf597fc7
.long	0xc6e00bf3,0xd5a79147,0x06ca6351,0x14292967
.long	0xc6e00bf3,0xd5a79147,0x06ca6351,0x14292967
.long	0x27b70a85,0x2e1b2138,0x4d2c6dfc,0x53380d13
.long	0x27b70a85,0x2e1b2138,0x4d2c6dfc,0x53380d13
.long	0x650a7354,0x766a0abb,0x81c2c92e,0x92722c85
.long	0x650a7354,0x766a0abb,0x81c2c92e,0x92722c85
.long	0xa2bfe8a1,0xa81a664b,0xc24b8b70,0xc76c51a3
.long	0xa2bfe8a1,0xa81a664b,0xc24b8b70,0xc76c51a3
.long	0xd192e819,0xd6990624,0xf40e3585,0x106aa070
.long	0xd192e819,0xd6990624,0xf40e3585,0x106aa070
.long	0x19a4c116,0x1e376c08,0x2748774c,0x34b0bcb5
.long	0x19a4c116,0x1e376c08,0x2748774c,0x34b0bcb5
.long	0x391c0cb3,0x4ed8aa4a,0x5b9cca4f,0x682e6ff3
.long	0x391c0cb3,0x4ed8aa4a,0x5b9cca4f,0x682e6ff3
.long	0x748f82ee,0x78a5636f,0x84c87814,0x8cc70208
.long	0x748f82ee,0x78a5636f,0x84c87814,0x8cc70208
.long	0x90befffa,0xa4506ceb,0xbef9a3f7,0xc67178f2
.long	0x90befffa,0xa4506ceb,0xbef9a3f7,0xc67178f2

.long	0x00010203,0x04050607,0x08090a0b,0x0c0d0e0f
.long	0x00010203,0x04050607,0x08090a0b,0x0c0d0e0f
.long	0x03020100,0x0b0a0908,0xffffffff,0xffffffff
.long	0x03020100,0x0b0a0908,0xffffffff,0xffffffff
.long	0xffffffff,0xffffffff,0x03020100,0x0b0a0908
.long	0xffffffff,0xffffffff,0x03020100,0x0b0a0908
.byte	83,72,65,50,53,54,32,98,108,111,99,107,32,116,114,97,110,115,102,111,114,109,32,102,111,114,32,120,56,54,95,54,52,44,32,67,82,89,80,84,79,71,65,77,83,32,98,121,32,60,97,112,112,114,111,64,111,112,101,110,115,115,108,46,111,114,103,62,0
.type	sha256_block_data_order_shaext,@function
.align	64
sha256_block_data_order_shaext:
_shaext_shortcut:
.cfi_startproc	
	leaq	K256+128(%rip),%rcx
	movdqu	(%rdi),%xmm1
	movdqu	16(%rdi),%xmm2
	movdqa	512-128(%rcx),%xmm7

	pshufd	$0x1b,%xmm1,%xmm0
	pshufd	$0xb1,%xmm1,%xmm1
	pshufd	$0x1b,%xmm2,%xmm2
	movdqa	%xmm7,%xmm8
.byte	102,15,58,15,202,8
	punpcklqdq	%xmm0,%xmm2
	jmp	.Loop_shaext

.align	16
.Loop_shaext:
	movdqu	(%rsi),%xmm3
	movdqu	16(%rsi),%xmm4
	movdqu	32(%rsi),%xmm5
.byte	102,15,56,0,223
	movdqu	48(%rsi),%xmm6

	movdqa	0-128(%rcx),%xmm0
	paddd	%xmm3,%xmm0
.byte	102,15,56,0,231
	movdqa	%xmm2,%xmm10
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	nop
	movdqa	%xmm1,%xmm9
.byte	15,56,203,202

	movdqa	32-128(%rcx),%xmm0
	paddd	%xmm4,%xmm0
.byte	102,15,56,0,239
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	leaq	64(%rsi),%rsi
.byte	15,56,204,220
.byte	15,56,203,202

	movdqa	64-128(%rcx),%xmm0
	paddd	%xmm5,%xmm0
.byte	102,15,56,0,247
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm6,%xmm7
.byte	102,15,58,15,253,4
	nop
	paddd	%xmm7,%xmm3
.byte	15,56,204,229
.byte	15,56,203,202

	movdqa	96-128(%rcx),%xmm0
	paddd	%xmm6,%xmm0
.byte	15,56,205,222
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm3,%xmm7
.byte	102,15,58,15,254,4
	nop
	paddd	%xmm7,%xmm4
.byte	15,56,204,238
.byte	15,56,203,202
	movdqa	128-128(%rcx),%xmm0
	paddd	%xmm3,%xmm0
.byte	15,56,205,227
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm4,%xmm7
.byte	102,15,58,15,251,4
	nop
	paddd	%xmm7,%xmm5
.byte	15,56,204,243
.byte	15,56,203,202
	movdqa	160-128(%rcx),%xmm0
	paddd	%xmm4,%xmm0
.byte	15,56,205,236
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm5,%xmm7
.byte	102,15,58,15,252,4
	nop
	paddd	%xmm7,%xmm6
.byte	15,56,204,220
.byte	15,56,203,202
	movdqa	192-128(%rcx),%xmm0
	paddd	%xmm5,%xmm0
.byte	15,56,205,245
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm6,%xmm7
.byte	102,15,58,15,253,4
	nop
	paddd	%xmm7,%xmm3
.byte	15,56,204,229
.byte	15,56,203,202
	movdqa	224-128(%rcx),%xmm0
	paddd	%xmm6,%xmm0
.byte	15,56,205,222
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm3,%xmm7
.byte	102,15,58,15,254,4
	nop
	paddd	%xmm7,%xmm4
.byte	15,56,204,238
.byte	15,56,203,202
	movdqa	256-128(%rcx),%xmm0
	paddd	%xmm3,%xmm0
.byte	15,56,205,227
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm4,%xmm7
.byte	102,15,58,15,251,4
	nop
	paddd	%xmm7,%xmm5
.byte	15,56,204,243
.byte	15,56,203,202
	movdqa	288-128(%rcx),%xmm0
	paddd	%xmm4,%xmm0
.byte	15,56,205,236
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm5,%xmm7
.byte	102,15,58,15,252,4
	nop
	paddd	%xmm7,%xmm6
.byte	15,56,204,220
.byte	15,56,203,202
	movdqa	320-128(%rcx),%xmm0
	paddd	%xmm5,%xmm0
.byte	15,56,205,245
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm6,%xmm7
.byte	102,15,58,15,253,4
	nop
	paddd	%xmm7,%xmm3
.byte	15,56,204,229
.byte	15,56,203,202
	movdqa	352-128(%rcx),%xmm0
	paddd	%xmm6,%xmm0
.byte	15,56,205,222
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm3,%xmm7
.byte	102,15,58,15,254,4
	nop
	paddd	%xmm7,%xmm4
.byte	15,56,204,238
.byte	15,56,203,202
	movdqa	384-128(%rcx),%xmm0
	paddd	%xmm3,%xmm0
.byte	15,56,205,227
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm4,%xmm7
.byte	102,15,58,15,251,4
	nop
	paddd	%xmm7,%xmm5
.byte	15,56,204,243
.byte	15,56,203,202
	movdqa	416-128(%rcx),%xmm0
	paddd	%xmm4,%xmm0
.byte	15,56,205,236
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	movdqa	%xmm5,%xmm7
.byte	102,15,58,15,252,4
.byte	15,56,203,202
	paddd	%xmm7,%xmm6

	movdqa	448-128(%rcx),%xmm0
	paddd	%xmm5,%xmm0
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
.byte	15,56,205,245
	movdqa	%xmm8,%xmm7
.byte	15,56,203,202

	movdqa	480-128(%rcx),%xmm0
	paddd	%xmm6,%xmm0
	nop
.byte	15,56,203,209
	pshufd	$0x0e,%xmm0,%xmm0
	decq	%rdx
	nop
.byte	15,56,203,202

	paddd	%xmm10,%xmm2
	paddd	%xmm9,%xmm1
	jnz	.Loop_shaext

	pshufd	$0xb1,%xmm2,%xmm2
	pshufd	$0x1b,%xmm1,%xmm7
	pshufd	$0xb1,%xmm1,%xmm1
	punpckhqdq	%xmm2,%xmm1
.byte	102,15,58,15,215,8

	movdqu	%xmm1,(%rdi)
	movdqu	%xmm2,16(%rdi)
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha256_block_data_order_shaext,.-sha256_block_data_order_shaext
.type	sha256_block_data_order_ssse3,@function
.align	64
sha256_block_data_order_ssse3:
.cfi_startproc	
.Lssse3_shortcut:
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
	shlq	$4,%rdx
	subq	$96,%rsp
	leaq	(%rsi,%rdx,4),%rdx
	andq	$-64,%rsp
	movq	%rdi,64+0(%rsp)
	movq	%rsi,64+8(%rsp)
	movq	%rdx,64+16(%rsp)
	movq	%rax,88(%rsp)
.cfi_escape	0x0f,0x06,0x77,0xd8,0x00,0x06,0x23,0x08
.Lprologue_ssse3:

	movl	0(%rdi),%eax
	movl	4(%rdi),%ebx
	movl	8(%rdi),%ecx
	movl	12(%rdi),%edx
	movl	16(%rdi),%r8d
	movl	20(%rdi),%r9d
	movl	24(%rdi),%r10d
	movl	28(%rdi),%r11d


	jmp	.Lloop_ssse3
.align	16
.Lloop_ssse3:
	movdqa	K256+512(%rip),%xmm7
	movdqu	0(%rsi),%xmm0
	movdqu	16(%rsi),%xmm1
	movdqu	32(%rsi),%xmm2
.byte	102,15,56,0,199
	movdqu	48(%rsi),%xmm3
	leaq	K256(%rip),%rbp
.byte	102,15,56,0,207
	movdqa	0(%rbp),%xmm4
	movdqa	32(%rbp),%xmm5
.byte	102,15,56,0,215
	paddd	%xmm0,%xmm4
	movdqa	64(%rbp),%xmm6
.byte	102,15,56,0,223
	movdqa	96(%rbp),%xmm7
	paddd	%xmm1,%xmm5
	paddd	%xmm2,%xmm6
	paddd	%xmm3,%xmm7
	movdqa	%xmm4,0(%rsp)
	movl	%eax,%r14d
	movdqa	%xmm5,16(%rsp)
	movl	%ebx,%edi
	movdqa	%xmm6,32(%rsp)
	xorl	%ecx,%edi
	movdqa	%xmm7,48(%rsp)
	movl	%r8d,%r13d
	jmp	.Lssse3_00_47

.align	16
.Lssse3_00_47:
	subq	$-128,%rbp
	rorl	$14,%r13d
	movdqa	%xmm1,%xmm4
	movl	%r14d,%eax
	movl	%r9d,%r12d
	movdqa	%xmm3,%xmm7
	rorl	$9,%r14d
	xorl	%r8d,%r13d
	xorl	%r10d,%r12d
	rorl	$5,%r13d
	xorl	%eax,%r14d
.byte	102,15,58,15,224,4
	andl	%r8d,%r12d
	xorl	%r8d,%r13d
.byte	102,15,58,15,250,4
	addl	0(%rsp),%r11d
	movl	%eax,%r15d
	xorl	%r10d,%r12d
	rorl	$11,%r14d
	movdqa	%xmm4,%xmm5
	xorl	%ebx,%r15d
	addl	%r12d,%r11d
	movdqa	%xmm4,%xmm6
	rorl	$6,%r13d
	andl	%r15d,%edi
	psrld	$3,%xmm4
	xorl	%eax,%r14d
	addl	%r13d,%r11d
	xorl	%ebx,%edi
	paddd	%xmm7,%xmm0
	rorl	$2,%r14d
	addl	%r11d,%edx
	psrld	$7,%xmm6
	addl	%edi,%r11d
	movl	%edx,%r13d
	pshufd	$250,%xmm3,%xmm7
	addl	%r11d,%r14d
	rorl	$14,%r13d
	pslld	$14,%xmm5
	movl	%r14d,%r11d
	movl	%r8d,%r12d
	pxor	%xmm6,%xmm4
	rorl	$9,%r14d
	xorl	%edx,%r13d
	xorl	%r9d,%r12d
	rorl	$5,%r13d
	psrld	$11,%xmm6
	xorl	%r11d,%r14d
	pxor	%xmm5,%xmm4
	andl	%edx,%r12d
	xorl	%edx,%r13d
	pslld	$11,%xmm5
	addl	4(%rsp),%r10d
	movl	%r11d,%edi
	pxor	%xmm6,%xmm4
	xorl	%r9d,%r12d
	rorl	$11,%r14d
	movdqa	%xmm7,%xmm6
	xorl	%eax,%edi
	addl	%r12d,%r10d
	pxor	%xmm5,%xmm4
	rorl	$6,%r13d
	andl	%edi,%r15d
	xorl	%r11d,%r14d
	psrld	$10,%xmm7
	addl	%r13d,%r10d
	xorl	%eax,%r15d
	paddd	%xmm4,%xmm0
	rorl	$2,%r14d
	addl	%r10d,%ecx
	psrlq	$17,%xmm6
	addl	%r15d,%r10d
	movl	%ecx,%r13d
	addl	%r10d,%r14d
	pxor	%xmm6,%xmm7
	rorl	$14,%r13d
	movl	%r14d,%r10d
	movl	%edx,%r12d
	rorl	$9,%r14d
	psrlq	$2,%xmm6
	xorl	%ecx,%r13d
	xorl	%r8d,%r12d
	pxor	%xmm6,%xmm7
	rorl	$5,%r13d
	xorl	%r10d,%r14d
	andl	%ecx,%r12d
	pshufd	$128,%xmm7,%xmm7
	xorl	%ecx,%r13d
	addl	8(%rsp),%r9d
	movl	%r10d,%r15d
	psrldq	$8,%xmm7
	xorl	%r8d,%r12d
	rorl	$11,%r14d
	xorl	%r11d,%r15d
	addl	%r12d,%r9d
	rorl	$6,%r13d
	paddd	%xmm7,%xmm0
	andl	%r15d,%edi
	xorl	%r10d,%r14d
	addl	%r13d,%r9d
	pshufd	$80,%xmm0,%xmm7
	xorl	%r11d,%edi
	rorl	$2,%r14d
	addl	%r9d,%ebx
	movdqa	%xmm7,%xmm6
	addl	%edi,%r9d
	movl	%ebx,%r13d
	psrld	$10,%xmm7
	addl	%r9d,%r14d
	rorl	$14,%r13d
	psrlq	$17,%xmm6
	movl	%r14d,%r9d
	movl	%ecx,%r12d
	pxor	%xmm6,%xmm7
	rorl	$9,%r14d
	xorl	%ebx,%r13d
	xorl	%edx,%r12d
	rorl	$5,%r13d
	xorl	%r9d,%r14d
	psrlq	$2,%xmm6
	andl	%ebx,%r12d
	xorl	%ebx,%r13d
	addl	12(%rsp),%r8d
	pxor	%xmm6,%xmm7
	movl	%r9d,%edi
	xorl	%edx,%r12d
	rorl	$11,%r14d
	pshufd	$8,%xmm7,%xmm7
	xorl	%r10d,%edi
	addl	%r12d,%r8d
	movdqa	0(%rbp),%xmm6
	rorl	$6,%r13d
	andl	%edi,%r15d
	pslldq	$8,%xmm7
	xorl	%r9d,%r14d
	addl	%r13d,%r8d
	xorl	%r10d,%r15d
	paddd	%xmm7,%xmm0
	rorl	$2,%r14d
	addl	%r8d,%eax
	addl	%r15d,%r8d
	paddd	%xmm0,%xmm6
	movl	%eax,%r13d
	addl	%r8d,%r14d
	movdqa	%xmm6,0(%rsp)
	rorl	$14,%r13d
	movdqa	%xmm2,%xmm4
	movl	%r14d,%r8d
	movl	%ebx,%r12d
	movdqa	%xmm0,%xmm7
	rorl	$9,%r14d
	xorl	%eax,%r13d
	xorl	%ecx,%r12d
	rorl	$5,%r13d
	xorl	%r8d,%r14d
.byte	102,15,58,15,225,4
	andl	%eax,%r12d
	xorl	%eax,%r13d
.byte	102,15,58,15,251,4
	addl	16(%rsp),%edx
	movl	%r8d,%r15d
	xorl	%ecx,%r12d
	rorl	$11,%r14d
	movdqa	%xmm4,%xmm5
	xorl	%r9d,%r15d
	addl	%r12d,%edx
	movdqa	%xmm4,%xmm6
	rorl	$6,%r13d
	andl	%r15d,%edi
	psrld	$3,%xmm4
	xorl	%r8d,%r14d
	addl	%r13d,%edx
	xorl	%r9d,%edi
	paddd	%xmm7,%xmm1
	rorl	$2,%r14d
	addl	%edx,%r11d
	psrld	$7,%xmm6
	addl	%edi,%edx
	movl	%r11d,%r13d
	pshufd	$250,%xmm0,%xmm7
	addl	%edx,%r14d
	rorl	$14,%r13d
	pslld	$14,%xmm5
	movl	%r14d,%edx
	movl	%eax,%r12d
	pxor	%xmm6,%xmm4
	rorl	$9,%r14d
	xorl	%r11d,%r13d
	xorl	%ebx,%r12d
	rorl	$5,%r13d
	psrld	$11,%xmm6
	xorl	%edx,%r14d
	pxor	%xmm5,%xmm4
	andl	%r11d,%r12d
	xorl	%r11d,%r13d
	pslld	$11,%xmm5
	addl	20(%rsp),%ecx
	movl	%edx,%edi
	pxor	%xmm6,%xmm4
	xorl	%ebx,%r12d
	rorl	$11,%r14d
	movdqa	%xmm7,%xmm6
	xorl	%r8d,%edi
	addl	%r12d,%ecx
	pxor	%xmm5,%xmm4
	rorl	$6,%r13d
	andl	%edi,%r15d
	xorl	%edx,%r14d
	psrld	$10,%xmm7
	addl	%r13d,%ecx
	xorl	%r8d,%r15d
	paddd	%xmm4,%xmm1
	rorl	$2,%r14d
	addl	%ecx,%r10d
	psrlq	$17,%xmm6
	addl	%r15d,%ecx
	movl	%r10d,%r13d
	addl	%ecx,%r14d
	pxor	%xmm6,%xmm7
	rorl	$14,%r13d
	movl	%r14d,%ecx
	movl	%r11d,%r12d
	rorl	$9,%r14d
	psrlq	$2,%xmm6
	xorl	%r10d,%r13d
	xorl	%eax,%r12d
	pxor	%xmm6,%xmm7
	rorl	$5,%r13d
	xorl	%ecx,%r14d
	andl	%r10d,%r12d
	pshufd	$128,%xmm7,%xmm7
	xorl	%r10d,%r13d
	addl	24(%rsp),%ebx
	movl	%ecx,%r15d
	psrldq	$8,%xmm7
	xorl	%eax,%r12d
	rorl	$11,%r14d
	xorl	%edx,%r15d
	addl	%r12d,%ebx
	rorl	$6,%r13d
	paddd	%xmm7,%xmm1
	andl	%r15d,%edi
	xorl	%ecx,%r14d
	addl	%r13d,%ebx
	pshufd	$80,%xmm1,%xmm7
	xorl	%edx,%edi
	rorl	$2,%r14d
	addl	%ebx,%r9d
	movdqa	%xmm7,%xmm6
	addl	%edi,%ebx
	movl	%r9d,%r13d
	psrld	$10,%xmm7
	addl	%ebx,%r14d
	rorl	$14,%r13d
	psrlq	$17,%xmm6
	movl	%r14d,%ebx
	movl	%r10d,%r12d
	pxor	%xmm6,%xmm7
	rorl	$9,%r14d
	xorl	%r9d,%r13d
	xorl	%r11d,%r12d
	rorl	$5,%r13d
	xorl	%ebx,%r14d
	psrlq	$2,%xmm6
	andl	%r9d,%r12d
	xorl	%r9d,%r13d
	addl	28(%rsp),%eax
	pxor	%xmm6,%xmm7
	movl	%ebx,%edi
	xorl	%r11d,%r12d
	rorl	$11,%r14d
	pshufd	$8,%xmm7,%xmm7
	xorl	%ecx,%edi
	addl	%r12d,%eax
	movdqa	32(%rbp),%xmm6
	rorl	$6,%r13d
	andl	%edi,%r15d
	pslldq	$8,%xmm7
	xorl	%ebx,%r14d
	addl	%r13d,%eax
	xorl	%ecx,%r15d
	paddd	%xmm7,%xmm1
	rorl	$2,%r14d
	addl	%eax,%r8d
	addl	%r15d,%eax
	paddd	%xmm1,%xmm6
	movl	%r8d,%r13d
	addl	%eax,%r14d
	movdqa	%xmm6,16(%rsp)
	rorl	$14,%r13d
	movdqa	%xmm3,%xmm4
	movl	%r14d,%eax
	movl	%r9d,%r12d
	movdqa	%xmm1,%xmm7
	rorl	$9,%r14d
	xorl	%r8d,%r13d
	xorl	%r10d,%r12d
	rorl	$5,%r13d
	xorl	%eax,%r14d
.byte	102,15,58,15,226,4
	andl	%r8d,%r12d
	xorl	%r8d,%r13d
.byte	102,15,58,15,248,4
	addl	32(%rsp),%r11d
	movl	%eax,%r15d
	xorl	%r10d,%r12d
	rorl	$11,%r14d
	movdqa	%xmm4,%xmm5
	xorl	%ebx,%r15d
	addl	%r12d,%r11d
	movdqa	%xmm4,%xmm6
	rorl	$6,%r13d
	andl	%r15d,%edi
	psrld	$3,%xmm4
	xorl	%eax,%r14d
	addl	%r13d,%r11d
	xorl	%ebx,%edi
	paddd	%xmm7,%xmm2
	rorl	$2,%r14d
	addl	%r11d,%edx
	psrld	$7,%xmm6
	addl	%edi,%r11d
	movl	%edx,%r13d
	pshufd	$250,%xmm1,%xmm7
	addl	%r11d,%r14d
	rorl	$14,%r13d
	pslld	$14,%xmm5
	movl	%r14d,%r11d
	movl	%r8d,%r12d
	pxor	%xmm6,%xmm4
	rorl	$9,%r14d
	xorl	%edx,%r13d
	xorl	%r9d,%r12d
	rorl	$5,%r13d
	psrld	$11,%xmm6
	xorl	%r11d,%r14d
	pxor	%xmm5,%xmm4
	andl	%edx,%r12d
	xorl	%edx,%r13d
	pslld	$11,%xmm5
	addl	36(%rsp),%r10d
	movl	%r11d,%edi
	pxor	%xmm6,%xmm4
	xorl	%r9d,%r12d
	rorl	$11,%r14d
	movdqa	%xmm7,%xmm6
	xorl	%eax,%edi
	addl	%r12d,%r10d
	pxor	%xmm5,%xmm4
	rorl	$6,%r13d
	andl	%edi,%r15d
	xorl	%r11d,%r14d
	psrld	$10,%xmm7
	addl	%r13d,%r10d
	xorl	%eax,%r15d
	paddd	%xmm4,%xmm2
	rorl	$2,%r14d
	addl	%r10d,%ecx
	psrlq	$17,%xmm6
	addl	%r15d,%r10d
	movl	%ecx,%r13d
	addl	%r10d,%r14d
	pxor	%xmm6,%xmm7
	rorl	$14,%r13d
	movl	%r14d,%r10d
	movl	%edx,%r12d
	rorl	$9,%r14d
	psrlq	$2,%xmm6
	xorl	%ecx,%r13d
	xorl	%r8d,%r12d
	pxor	%xmm6,%xmm7
	rorl	$5,%r13d
	xorl	%r10d,%r14d
	andl	%ecx,%r12d
	pshufd	$128,%xmm7,%xmm7
	xorl	%ecx,%r13d
	addl	40(%rsp),%r9d
	movl	%r10d,%r15d
	psrldq	$8,%xmm7
	xorl	%r8d,%r12d
	rorl	$11,%r14d
	xorl	%r11d,%r15d
	addl	%r12d,%r9d
	rorl	$6,%r13d
	paddd	%xmm7,%xmm2
	andl	%r15d,%edi
	xorl	%r10d,%r14d
	addl	%r13d,%r9d
	pshufd	$80,%xmm2,%xmm7
	xorl	%r11d,%edi
	rorl	$2,%r14d
	addl	%r9d,%ebx
	movdqa	%xmm7,%xmm6
	addl	%edi,%r9d
	movl	%ebx,%r13d
	psrld	$10,%xmm7
	addl	%r9d,%r14d
	rorl	$14,%r13d
	psrlq	$17,%xmm6
	movl	%r14d,%r9d
	movl	%ecx,%r12d
	pxor	%xmm6,%xmm7
	rorl	$9,%r14d
	xorl	%ebx,%r13d
	xorl	%edx,%r12d
	rorl	$5,%r13d
	xorl	%r9d,%r14d
	psrlq	$2,%xmm6
	andl	%ebx,%r12d
	xorl	%ebx,%r13d
	addl	44(%rsp),%r8d
	pxor	%xmm6,%xmm7
	movl	%r9d,%edi
	xorl	%edx,%r12d
	rorl	$11,%r14d
	pshufd	$8,%xmm7,%xmm7
	xorl	%r10d,%edi
	addl	%r12d,%r8d
	movdqa	64(%rbp),%xmm6
	rorl	$6,%r13d
	andl	%edi,%r15d
	pslldq	$8,%xmm7
	xorl	%r9d,%r14d
	addl	%r13d,%r8d
	xorl	%r10d,%r15d
	paddd	%xmm7,%xmm2
	rorl	$2,%r14d
	addl	%r8d,%eax
	addl	%r15d,%r8d
	paddd	%xmm2,%xmm6
	movl	%eax,%r13d
	addl	%r8d,%r14d
	movdqa	%xmm6,32(%rsp)
	rorl	$14,%r13d
	movdqa	%xmm0,%xmm4
	movl	%r14d,%r8d
	movl	%ebx,%r12d
	movdqa	%xmm2,%xmm7
	rorl	$9,%r14d
	xorl	%eax,%r13d
	xorl	%ecx,%r12d
	rorl	$5,%r13d
	xorl	%r8d,%r14d
.byte	102,15,58,15,227,4
	andl	%eax,%r12d
	xorl	%eax,%r13d
.byte	102,15,58,15,249,4
	addl	48(%rsp),%edx
	movl	%r8d,%r15d
	xorl	%ecx,%r12d
	rorl	$11,%r14d
	movdqa	%xmm4,%xmm5
	xorl	%r9d,%r15d
	addl	%r12d,%edx
	movdqa	%xmm4,%xmm6
	rorl	$6,%r13d
	andl	%r15d,%edi
	psrld	$3,%xmm4
	xorl	%r8d,%r14d
	addl	%r13d,%edx
	xorl	%r9d,%edi
	paddd	%xmm7,%xmm3
	rorl	$2,%r14d
	addl	%edx,%r11d
	psrld	$7,%xmm6
	addl	%edi,%edx
	movl	%r11d,%r13d
	pshufd	$250,%xmm2,%xmm7
	addl	%edx,%r14d
	rorl	$14,%r13d
	pslld	$14,%xmm5
	movl	%r14d,%edx
	movl	%eax,%r12d
	pxor	%xmm6,%xmm4
	rorl	$9,%r14d
	xorl	%r11d,%r13d
	xorl	%ebx,%r12d
	rorl	$5,%r13d
	psrld	$11,%xmm6
	xorl	%edx,%r14d
	pxor	%xmm5,%xmm4
	andl	%r11d,%r12d
	xorl	%r11d,%r13d
	pslld	$11,%xmm5
	addl	52(%rsp),%ecx
	movl	%edx,%edi
	pxor	%xmm6,%xmm4
	xorl	%ebx,%r12d
	rorl	$11,%r14d
	movdqa	%xmm7,%xmm6
	xorl	%r8d,%edi
	addl	%r12d,%ecx
	pxor	%xmm5,%xmm4
	rorl	$6,%r13d
	andl	%edi,%r15d
	xorl	%edx,%r14d
	psrld	$10,%xmm7
	addl	%r13d,%ecx
	xorl	%r8d,%r15d
	paddd	%xmm4,%xmm3
	rorl	$2,%r14d
	addl	%ecx,%r10d
	psrlq	$17,%xmm6
	addl	%r15d,%ecx
	movl	%r10d,%r13d
	addl	%ecx,%r14d
	pxor	%xmm6,%xmm7
	rorl	$14,%r13d
	movl	%r14d,%ecx
	movl	%r11d,%r12d
	rorl	$9,%r14d
	psrlq	$2,%xmm6
	xorl	%r10d,%r13d
	xorl	%eax,%r12d
	pxor	%xmm6,%xmm7
	rorl	$5,%r13d
	xorl	%ecx,%r14d
	andl	%r10d,%r12d
	pshufd	$128,%xmm7,%xmm7
	xorl	%r10d,%r13d
	addl	56(%rsp),%ebx
	movl	%ecx,%r15d
	psrldq	$8,%xmm7
	xorl	%eax,%r12d
	rorl	$11,%r14d
	xorl	%edx,%r15d
	addl	%r12d,%ebx
	rorl	$6,%r13d
	paddd	%xmm7,%xmm3
	andl	%r15d,%edi
	xorl	%ecx,%r14d
	addl	%r13d,%ebx
	pshufd	$80,%xmm3,%xmm7
	xorl	%edx,%edi
	rorl	$2,%r14d
	addl	%ebx,%r9d
	movdqa	%xmm7,%xmm6
	addl	%edi,%ebx
	movl	%r9d,%r13d
	psrld	$10,%xmm7
	addl	%ebx,%r14d
	rorl	$14,%r13d
	psrlq	$17,%xmm6
	movl	%r14d,%ebx
	movl	%r10d,%r12d
	pxor	%xmm6,%xmm7
	rorl	$9,%r14d
	xorl	%r9d,%r13d
	xorl	%r11d,%r12d
	rorl	$5,%r13d
	xorl	%ebx,%r14d
	psrlq	$2,%xmm6
	andl	%r9d,%r12d
	xorl	%r9d,%r13d
	addl	60(%rsp),%eax
	pxor	%xmm6,%xmm7
	movl	%ebx,%edi
	xorl	%r11d,%r12d
	rorl	$11,%r14d
	pshufd	$8,%xmm7,%xmm7
	xorl	%ecx,%edi
	addl	%r12d,%eax
	movdqa	96(%rbp),%xmm6
	rorl	$6,%r13d
	andl	%edi,%r15d
	pslldq	$8,%xmm7
	xorl	%ebx,%r14d
	addl	%r13d,%eax
	xorl	%ecx,%r15d
	paddd	%xmm7,%xmm3
	rorl	$2,%r14d
	addl	%eax,%r8d
	addl	%r15d,%eax
	paddd	%xmm3,%xmm6
	movl	%r8d,%r13d
	addl	%eax,%r14d
	movdqa	%xmm6,48(%rsp)
	cmpb	$0,131(%rbp)
	jne	.Lssse3_00_47
	rorl	$14,%r13d
	movl	%r14d,%eax
	movl	%r9d,%r12d
	rorl	$9,%r14d
	xorl	%r8d,%r13d
	xorl	%r10d,%r12d
	rorl	$5,%r13d
	xorl	%eax,%r14d
	andl	%r8d,%r12d
	xorl	%r8d,%r13d
	addl	0(%rsp),%r11d
	movl	%eax,%r15d
	xorl	%r10d,%r12d
	rorl	$11,%r14d
	xorl	%ebx,%r15d
	addl	%r12d,%r11d
	rorl	$6,%r13d
	andl	%r15d,%edi
	xorl	%eax,%r14d
	addl	%r13d,%r11d
	xorl	%ebx,%edi
	rorl	$2,%r14d
	addl	%r11d,%edx
	addl	%edi,%r11d
	movl	%edx,%r13d
	addl	%r11d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r11d
	movl	%r8d,%r12d
	rorl	$9,%r14d
	xorl	%edx,%r13d
	xorl	%r9d,%r12d
	rorl	$5,%r13d
	xorl	%r11d,%r14d
	andl	%edx,%r12d
	xorl	%edx,%r13d
	addl	4(%rsp),%r10d
	movl	%r11d,%edi
	xorl	%r9d,%r12d
	rorl	$11,%r14d
	xorl	%eax,%edi
	addl	%r12d,%r10d
	rorl	$6,%r13d
	andl	%edi,%r15d
	xorl	%r11d,%r14d
	addl	%r13d,%r10d
	xorl	%eax,%r15d
	rorl	$2,%r14d
	addl	%r10d,%ecx
	addl	%r15d,%r10d
	movl	%ecx,%r13d
	addl	%r10d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r10d
	movl	%edx,%r12d
	rorl	$9,%r14d
	xorl	%ecx,%r13d
	xorl	%r8d,%r12d
	rorl	$5,%r13d
	xorl	%r10d,%r14d
	andl	%ecx,%r12d
	xorl	%ecx,%r13d
	addl	8(%rsp),%r9d
	movl	%r10d,%r15d
	xorl	%r8d,%r12d
	rorl	$11,%r14d
	xorl	%r11d,%r15d
	addl	%r12d,%r9d
	rorl	$6,%r13d
	andl	%r15d,%edi
	xorl	%r10d,%r14d
	addl	%r13d,%r9d
	xorl	%r11d,%edi
	rorl	$2,%r14d
	addl	%r9d,%ebx
	addl	%edi,%r9d
	movl	%ebx,%r13d
	addl	%r9d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r9d
	movl	%ecx,%r12d
	rorl	$9,%r14d
	xorl	%ebx,%r13d
	xorl	%edx,%r12d
	rorl	$5,%r13d
	xorl	%r9d,%r14d
	andl	%ebx,%r12d
	xorl	%ebx,%r13d
	addl	12(%rsp),%r8d
	movl	%r9d,%edi
	xorl	%edx,%r12d
	rorl	$11,%r14d
	xorl	%r10d,%edi
	addl	%r12d,%r8d
	rorl	$6,%r13d
	andl	%edi,%r15d
	xorl	%r9d,%r14d
	addl	%r13d,%r8d
	xorl	%r10d,%r15d
	rorl	$2,%r14d
	addl	%r8d,%eax
	addl	%r15d,%r8d
	movl	%eax,%r13d
	addl	%r8d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r8d
	movl	%ebx,%r12d
	rorl	$9,%r14d
	xorl	%eax,%r13d
	xorl	%ecx,%r12d
	rorl	$5,%r13d
	xorl	%r8d,%r14d
	andl	%eax,%r12d
	xorl	%eax,%r13d
	addl	16(%rsp),%edx
	movl	%r8d,%r15d
	xorl	%ecx,%r12d
	rorl	$11,%r14d
	xorl	%r9d,%r15d
	addl	%r12d,%edx
	rorl	$6,%r13d
	andl	%r15d,%edi
	xorl	%r8d,%r14d
	addl	%r13d,%edx
	xorl	%r9d,%edi
	rorl	$2,%r14d
	addl	%edx,%r11d
	addl	%edi,%edx
	movl	%r11d,%r13d
	addl	%edx,%r14d
	rorl	$14,%r13d
	movl	%r14d,%edx
	movl	%eax,%r12d
	rorl	$9,%r14d
	xorl	%r11d,%r13d
	xorl	%ebx,%r12d
	rorl	$5,%r13d
	xorl	%edx,%r14d
	andl	%r11d,%r12d
	xorl	%r11d,%r13d
	addl	20(%rsp),%ecx
	movl	%edx,%edi
	xorl	%ebx,%r12d
	rorl	$11,%r14d
	xorl	%r8d,%edi
	addl	%r12d,%ecx
	rorl	$6,%r13d
	andl	%edi,%r15d
	xorl	%edx,%r14d
	addl	%r13d,%ecx
	xorl	%r8d,%r15d
	rorl	$2,%r14d
	addl	%ecx,%r10d
	addl	%r15d,%ecx
	movl	%r10d,%r13d
	addl	%ecx,%r14d
	rorl	$14,%r13d
	movl	%r14d,%ecx
	movl	%r11d,%r12d
	rorl	$9,%r14d
	xorl	%r10d,%r13d
	xorl	%eax,%r12d
	rorl	$5,%r13d
	xorl	%ecx,%r14d
	andl	%r10d,%r12d
	xorl	%r10d,%r13d
	addl	24(%rsp),%ebx
	movl	%ecx,%r15d
	xorl	%eax,%r12d
	rorl	$11,%r14d
	xorl	%edx,%r15d
	addl	%r12d,%ebx
	rorl	$6,%r13d
	andl	%r15d,%edi
	xorl	%ecx,%r14d
	addl	%r13d,%ebx
	xorl	%edx,%edi
	rorl	$2,%r14d
	addl	%ebx,%r9d
	addl	%edi,%ebx
	movl	%r9d,%r13d
	addl	%ebx,%r14d
	rorl	$14,%r13d
	movl	%r14d,%ebx
	movl	%r10d,%r12d
	rorl	$9,%r14d
	xorl	%r9d,%r13d
	xorl	%r11d,%r12d
	rorl	$5,%r13d
	xorl	%ebx,%r14d
	andl	%r9d,%r12d
	xorl	%r9d,%r13d
	addl	28(%rsp),%eax
	movl	%ebx,%edi
	xorl	%r11d,%r12d
	rorl	$11,%r14d
	xorl	%ecx,%edi
	addl	%r12d,%eax
	rorl	$6,%r13d
	andl	%edi,%r15d
	xorl	%ebx,%r14d
	addl	%r13d,%eax
	xorl	%ecx,%r15d
	rorl	$2,%r14d
	addl	%eax,%r8d
	addl	%r15d,%eax
	movl	%r8d,%r13d
	addl	%eax,%r14d
	rorl	$14,%r13d
	movl	%r14d,%eax
	movl	%r9d,%r12d
	rorl	$9,%r14d
	xorl	%r8d,%r13d
	xorl	%r10d,%r12d
	rorl	$5,%r13d
	xorl	%eax,%r14d
	andl	%r8d,%r12d
	xorl	%r8d,%r13d
	addl	32(%rsp),%r11d
	movl	%eax,%r15d
	xorl	%r10d,%r12d
	rorl	$11,%r14d
	xorl	%ebx,%r15d
	addl	%r12d,%r11d
	rorl	$6,%r13d
	andl	%r15d,%edi
	xorl	%eax,%r14d
	addl	%r13d,%r11d
	xorl	%ebx,%edi
	rorl	$2,%r14d
	addl	%r11d,%edx
	addl	%edi,%r11d
	movl	%edx,%r13d
	addl	%r11d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r11d
	movl	%r8d,%r12d
	rorl	$9,%r14d
	xorl	%edx,%r13d
	xorl	%r9d,%r12d
	rorl	$5,%r13d
	xorl	%r11d,%r14d
	andl	%edx,%r12d
	xorl	%edx,%r13d
	addl	36(%rsp),%r10d
	movl	%r11d,%edi
	xorl	%r9d,%r12d
	rorl	$11,%r14d
	xorl	%eax,%edi
	addl	%r12d,%r10d
	rorl	$6,%r13d
	andl	%edi,%r15d
	xorl	%r11d,%r14d
	addl	%r13d,%r10d
	xorl	%eax,%r15d
	rorl	$2,%r14d
	addl	%r10d,%ecx
	addl	%r15d,%r10d
	movl	%ecx,%r13d
	addl	%r10d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r10d
	movl	%edx,%r12d
	rorl	$9,%r14d
	xorl	%ecx,%r13d
	xorl	%r8d,%r12d
	rorl	$5,%r13d
	xorl	%r10d,%r14d
	andl	%ecx,%r12d
	xorl	%ecx,%r13d
	addl	40(%rsp),%r9d
	movl	%r10d,%r15d
	xorl	%r8d,%r12d
	rorl	$11,%r14d
	xorl	%r11d,%r15d
	addl	%r12d,%r9d
	rorl	$6,%r13d
	andl	%r15d,%edi
	xorl	%r10d,%r14d
	addl	%r13d,%r9d
	xorl	%r11d,%edi
	rorl	$2,%r14d
	addl	%r9d,%ebx
	addl	%edi,%r9d
	movl	%ebx,%r13d
	addl	%r9d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r9d
	movl	%ecx,%r12d
	rorl	$9,%r14d
	xorl	%ebx,%r13d
	xorl	%edx,%r12d
	rorl	$5,%r13d
	xorl	%r9d,%r14d
	andl	%ebx,%r12d
	xorl	%ebx,%r13d
	addl	44(%rsp),%r8d
	movl	%r9d,%edi
	xorl	%edx,%r12d
	rorl	$11,%r14d
	xorl	%r10d,%edi
	addl	%r12d,%r8d
	rorl	$6,%r13d
	andl	%edi,%r15d
	xorl	%r9d,%r14d
	addl	%r13d,%r8d
	xorl	%r10d,%r15d
	rorl	$2,%r14d
	addl	%r8d,%eax
	addl	%r15d,%r8d
	movl	%eax,%r13d
	addl	%r8d,%r14d
	rorl	$14,%r13d
	movl	%r14d,%r8d
	movl	%ebx,%r12d
	rorl	$9,%r14d
	xorl	%eax,%r13d
	xorl	%ecx,%r12d
	rorl	$5,%r13d
	xorl	%r8d,%r14d
	andl	%eax,%r12d
	xorl	%eax,%r13d
	addl	48(%rsp),%edx
	movl	%r8d,%r15d
	xorl	%ecx,%r12d
	rorl	$11,%r14d
	xorl	%r9d,%r15d
	addl	%r12d,%edx
	rorl	$6,%r13d
	andl	%r15d,%edi
	xorl	%r8d,%r14d
	addl	%r13d,%edx
	xorl	%r9d,%edi
	rorl	$2,%r14d
	addl	%edx,%r11d
	addl	%edi,%edx
	movl	%r11d,%r13d
	addl	%edx,%r14d
	rorl	$14,%r13d
	movl	%r14d,%edx
	movl	%eax,%r12d
	rorl	$9,%r14d
	xorl	%r11d,%r13d
	xorl	%ebx,%r12d
	rorl	$5,%r13d
	xorl	%edx,%r14d
	andl	%r11d,%r12d
	xorl	%r11d,%r13d
	addl	52(%rsp),%ecx
	movl	%edx,%edi
	xorl	%ebx,%r12d
	rorl	$11,%r14d
	xorl	%r8d,%edi
	addl	%r12d,%ecx
	rorl	$6,%r13d
	andl	%edi,%r15d
	xorl	%edx,%r14d
	addl	%r13d,%ecx
	xorl	%r8d,%r15d
	rorl	$2,%r14d
	addl	%ecx,%r10d
	addl	%r15d,%ecx
	movl	%r10d,%r13d
	addl	%ecx,%r14d
	rorl	$14,%r13d
	movl	%r14d,%ecx
	movl	%r11d,%r12d
	rorl	$9,%r14d
	xorl	%r10d,%r13d
	xorl	%eax,%r12d
	rorl	$5,%r13d
	xorl	%ecx,%r14d
	andl	%r10d,%r12d
	xorl	%r10d,%r13d
	addl	56(%rsp),%ebx
	movl	%ecx,%r15d
	xorl	%eax,%r12d
	rorl	$11,%r14d
	xorl	%edx,%r15d
	addl	%r12d,%ebx
	rorl	$6,%r13d
	andl	%r15d,%edi
	xorl	%ecx,%r14d
	addl	%r13d,%ebx
	xorl	%edx,%edi
	rorl	$2,%r14d
	addl	%ebx,%r9d
	addl	%edi,%ebx
	movl	%r9d,%r13d
	addl	%ebx,%r14d
	rorl	$14,%r13d
	movl	%r14d,%ebx
	movl	%r10d,%r12d
	rorl	$9,%r14d
	xorl	%r9d,%r13d
	xorl	%r11d,%r12d
	rorl	$5,%r13d
	xorl	%ebx,%r14d
	andl	%r9d,%r12d
	xorl	%r9d,%r13d
	addl	60(%rsp),%eax
	movl	%ebx,%edi
	xorl	%r11d,%r12d
	rorl	$11,%r14d
	xorl	%ecx,%edi
	addl	%r12d,%eax
	rorl	$6,%r13d
	andl	%edi,%r15d
	xorl	%ebx,%r14d
	addl	%r13d,%eax
	xorl	%ecx,%r15d
	rorl	$2,%r14d
	addl	%eax,%r8d
	addl	%r15d,%eax
	movl	%r8d,%r13d
	addl	%eax,%r14d
	movq	64+0(%rsp),%rdi
	movl	%r14d,%eax

	addl	0(%rdi),%eax
	leaq	64(%rsi),%rsi
	addl	4(%rdi),%ebx
	addl	8(%rdi),%ecx
	addl	12(%rdi),%edx
	addl	16(%rdi),%r8d
	addl	20(%rdi),%r9d
	addl	24(%rdi),%r10d
	addl	28(%rdi),%r11d

	cmpq	64+16(%rsp),%rsi

	movl	%eax,0(%rdi)
	movl	%ebx,4(%rdi)
	movl	%ecx,8(%rdi)
	movl	%edx,12(%rdi)
	movl	%r8d,16(%rdi)
	movl	%r9d,20(%rdi)
	movl	%r10d,24(%rdi)
	movl	%r11d,28(%rdi)
	jb	.Lloop_ssse3

	movq	88(%rsp),%rsi
.cfi_def_cfa	%rsi,8
	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue_ssse3:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha256_block_data_order_ssse3,.-sha256_block_data_order_ssse3
.type	sha256_block_data_order_avx,@function
.align	64
sha256_block_data_order_avx:
.cfi_startproc	
.Lavx_shortcut:
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
	shlq	$4,%rdx
	subq	$96,%rsp
	leaq	(%rsi,%rdx,4),%rdx
	andq	$-64,%rsp
	movq	%rdi,64+0(%rsp)
	movq	%rsi,64+8(%rsp)
	movq	%rdx,64+16(%rsp)
	movq	%rax,88(%rsp)
.cfi_escape	0x0f,0x06,0x77,0xd8,0x00,0x06,0x23,0x08
.Lprologue_avx:

	vzeroupper
	movl	0(%rdi),%eax
	movl	4(%rdi),%ebx
	movl	8(%rdi),%ecx
	movl	12(%rdi),%edx
	movl	16(%rdi),%r8d
	movl	20(%rdi),%r9d
	movl	24(%rdi),%r10d
	movl	28(%rdi),%r11d
	vmovdqa	K256+512+32(%rip),%xmm8
	vmovdqa	K256+512+64(%rip),%xmm9
	jmp	.Lloop_avx
.align	16
.Lloop_avx:
	vmovdqa	K256+512(%rip),%xmm7
	vmovdqu	0(%rsi),%xmm0
	vmovdqu	16(%rsi),%xmm1
	vmovdqu	32(%rsi),%xmm2
	vmovdqu	48(%rsi),%xmm3
	vpshufb	%xmm7,%xmm0,%xmm0
	leaq	K256(%rip),%rbp
	vpshufb	%xmm7,%xmm1,%xmm1
	vpshufb	%xmm7,%xmm2,%xmm2
	vpaddd	0(%rbp),%xmm0,%xmm4
	vpshufb	%xmm7,%xmm3,%xmm3
	vpaddd	32(%rbp),%xmm1,%xmm5
	vpaddd	64(%rbp),%xmm2,%xmm6
	vpaddd	96(%rbp),%xmm3,%xmm7
	vmovdqa	%xmm4,0(%rsp)
	movl	%eax,%r14d
	vmovdqa	%xmm5,16(%rsp)
	movl	%ebx,%edi
	vmovdqa	%xmm6,32(%rsp)
	xorl	%ecx,%edi
	vmovdqa	%xmm7,48(%rsp)
	movl	%r8d,%r13d
	jmp	.Lavx_00_47

.align	16
.Lavx_00_47:
	subq	$-128,%rbp
	vpalignr	$4,%xmm0,%xmm1,%xmm4
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%eax
	movl	%r9d,%r12d
	vpalignr	$4,%xmm2,%xmm3,%xmm7
	shrdl	$9,%r14d,%r14d
	xorl	%r8d,%r13d
	xorl	%r10d,%r12d
	vpsrld	$7,%xmm4,%xmm6
	shrdl	$5,%r13d,%r13d
	xorl	%eax,%r14d
	andl	%r8d,%r12d
	vpaddd	%xmm7,%xmm0,%xmm0
	xorl	%r8d,%r13d
	addl	0(%rsp),%r11d
	movl	%eax,%r15d
	vpsrld	$3,%xmm4,%xmm7
	xorl	%r10d,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%ebx,%r15d
	vpslld	$14,%xmm4,%xmm5
	addl	%r12d,%r11d
	shrdl	$6,%r13d,%r13d
	andl	%r15d,%edi
	vpxor	%xmm6,%xmm7,%xmm4
	xorl	%eax,%r14d
	addl	%r13d,%r11d
	xorl	%ebx,%edi
	vpshufd	$250,%xmm3,%xmm7
	shrdl	$2,%r14d,%r14d
	addl	%r11d,%edx
	addl	%edi,%r11d
	vpsrld	$11,%xmm6,%xmm6
	movl	%edx,%r13d
	addl	%r11d,%r14d
	shrdl	$14,%r13d,%r13d
	vpxor	%xmm5,%xmm4,%xmm4
	movl	%r14d,%r11d
	movl	%r8d,%r12d
	shrdl	$9,%r14d,%r14d
	vpslld	$11,%xmm5,%xmm5
	xorl	%edx,%r13d
	xorl	%r9d,%r12d
	shrdl	$5,%r13d,%r13d
	vpxor	%xmm6,%xmm4,%xmm4
	xorl	%r11d,%r14d
	andl	%edx,%r12d
	xorl	%edx,%r13d
	vpsrld	$10,%xmm7,%xmm6
	addl	4(%rsp),%r10d
	movl	%r11d,%edi
	xorl	%r9d,%r12d
	vpxor	%xmm5,%xmm4,%xmm4
	shrdl	$11,%r14d,%r14d
	xorl	%eax,%edi
	addl	%r12d,%r10d
	vpsrlq	$17,%xmm7,%xmm7
	shrdl	$6,%r13d,%r13d
	andl	%edi,%r15d
	xorl	%r11d,%r14d
	vpaddd	%xmm4,%xmm0,%xmm0
	addl	%r13d,%r10d
	xorl	%eax,%r15d
	shrdl	$2,%r14d,%r14d
	vpxor	%xmm7,%xmm6,%xmm6
	addl	%r10d,%ecx
	addl	%r15d,%r10d
	movl	%ecx,%r13d
	vpsrlq	$2,%xmm7,%xmm7
	addl	%r10d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r10d
	vpxor	%xmm7,%xmm6,%xmm6
	movl	%edx,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%ecx,%r13d
	vpshufb	%xmm8,%xmm6,%xmm6
	xorl	%r8d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r10d,%r14d
	vpaddd	%xmm6,%xmm0,%xmm0
	andl	%ecx,%r12d
	xorl	%ecx,%r13d
	addl	8(%rsp),%r9d
	vpshufd	$80,%xmm0,%xmm7
	movl	%r10d,%r15d
	xorl	%r8d,%r12d
	shrdl	$11,%r14d,%r14d
	vpsrld	$10,%xmm7,%xmm6
	xorl	%r11d,%r15d
	addl	%r12d,%r9d
	shrdl	$6,%r13d,%r13d
	vpsrlq	$17,%xmm7,%xmm7
	andl	%r15d,%edi
	xorl	%r10d,%r14d
	addl	%r13d,%r9d
	vpxor	%xmm7,%xmm6,%xmm6
	xorl	%r11d,%edi
	shrdl	$2,%r14d,%r14d
	addl	%r9d,%ebx
	vpsrlq	$2,%xmm7,%xmm7
	addl	%edi,%r9d
	movl	%ebx,%r13d
	addl	%r9d,%r14d
	vpxor	%xmm7,%xmm6,%xmm6
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r9d
	movl	%ecx,%r12d
	vpshufb	%xmm9,%xmm6,%xmm6
	shrdl	$9,%r14d,%r14d
	xorl	%ebx,%r13d
	xorl	%edx,%r12d
	vpaddd	%xmm6,%xmm0,%xmm0
	shrdl	$5,%r13d,%r13d
	xorl	%r9d,%r14d
	andl	%ebx,%r12d
	vpaddd	0(%rbp),%xmm0,%xmm6
	xorl	%ebx,%r13d
	addl	12(%rsp),%r8d
	movl	%r9d,%edi
	xorl	%edx,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%r10d,%edi
	addl	%r12d,%r8d
	shrdl	$6,%r13d,%r13d
	andl	%edi,%r15d
	xorl	%r9d,%r14d
	addl	%r13d,%r8d
	xorl	%r10d,%r15d
	shrdl	$2,%r14d,%r14d
	addl	%r8d,%eax
	addl	%r15d,%r8d
	movl	%eax,%r13d
	addl	%r8d,%r14d
	vmovdqa	%xmm6,0(%rsp)
	vpalignr	$4,%xmm1,%xmm2,%xmm4
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r8d
	movl	%ebx,%r12d
	vpalignr	$4,%xmm3,%xmm0,%xmm7
	shrdl	$9,%r14d,%r14d
	xorl	%eax,%r13d
	xorl	%ecx,%r12d
	vpsrld	$7,%xmm4,%xmm6
	shrdl	$5,%r13d,%r13d
	xorl	%r8d,%r14d
	andl	%eax,%r12d
	vpaddd	%xmm7,%xmm1,%xmm1
	xorl	%eax,%r13d
	addl	16(%rsp),%edx
	movl	%r8d,%r15d
	vpsrld	$3,%xmm4,%xmm7
	xorl	%ecx,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%r9d,%r15d
	vpslld	$14,%xmm4,%xmm5
	addl	%r12d,%edx
	shrdl	$6,%r13d,%r13d
	andl	%r15d,%edi
	vpxor	%xmm6,%xmm7,%xmm4
	xorl	%r8d,%r14d
	addl	%r13d,%edx
	xorl	%r9d,%edi
	vpshufd	$250,%xmm0,%xmm7
	shrdl	$2,%r14d,%r14d
	addl	%edx,%r11d
	addl	%edi,%edx
	vpsrld	$11,%xmm6,%xmm6
	movl	%r11d,%r13d
	addl	%edx,%r14d
	shrdl	$14,%r13d,%r13d
	vpxor	%xmm5,%xmm4,%xmm4
	movl	%r14d,%edx
	movl	%eax,%r12d
	shrdl	$9,%r14d,%r14d
	vpslld	$11,%xmm5,%xmm5
	xorl	%r11d,%r13d
	xorl	%ebx,%r12d
	shrdl	$5,%r13d,%r13d
	vpxor	%xmm6,%xmm4,%xmm4
	xorl	%edx,%r14d
	andl	%r11d,%r12d
	xorl	%r11d,%r13d
	vpsrld	$10,%xmm7,%xmm6
	addl	20(%rsp),%ecx
	movl	%edx,%edi
	xorl	%ebx,%r12d
	vpxor	%xmm5,%xmm4,%xmm4
	shrdl	$11,%r14d,%r14d
	xorl	%r8d,%edi
	addl	%r12d,%ecx
	vpsrlq	$17,%xmm7,%xmm7
	shrdl	$6,%r13d,%r13d
	andl	%edi,%r15d
	xorl	%edx,%r14d
	vpaddd	%xmm4,%xmm1,%xmm1
	addl	%r13d,%ecx
	xorl	%r8d,%r15d
	shrdl	$2,%r14d,%r14d
	vpxor	%xmm7,%xmm6,%xmm6
	addl	%ecx,%r10d
	addl	%r15d,%ecx
	movl	%r10d,%r13d
	vpsrlq	$2,%xmm7,%xmm7
	addl	%ecx,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%ecx
	vpxor	%xmm7,%xmm6,%xmm6
	movl	%r11d,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%r10d,%r13d
	vpshufb	%xmm8,%xmm6,%xmm6
	xorl	%eax,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%ecx,%r14d
	vpaddd	%xmm6,%xmm1,%xmm1
	andl	%r10d,%r12d
	xorl	%r10d,%r13d
	addl	24(%rsp),%ebx
	vpshufd	$80,%xmm1,%xmm7
	movl	%ecx,%r15d
	xorl	%eax,%r12d
	shrdl	$11,%r14d,%r14d
	vpsrld	$10,%xmm7,%xmm6
	xorl	%edx,%r15d
	addl	%r12d,%ebx
	shrdl	$6,%r13d,%r13d
	vpsrlq	$17,%xmm7,%xmm7
	andl	%r15d,%edi
	xorl	%ecx,%r14d
	addl	%r13d,%ebx
	vpxor	%xmm7,%xmm6,%xmm6
	xorl	%edx,%edi
	shrdl	$2,%r14d,%r14d
	addl	%ebx,%r9d
	vpsrlq	$2,%xmm7,%xmm7
	addl	%edi,%ebx
	movl	%r9d,%r13d
	addl	%ebx,%r14d
	vpxor	%xmm7,%xmm6,%xmm6
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%ebx
	movl	%r10d,%r12d
	vpshufb	%xmm9,%xmm6,%xmm6
	shrdl	$9,%r14d,%r14d
	xorl	%r9d,%r13d
	xorl	%r11d,%r12d
	vpaddd	%xmm6,%xmm1,%xmm1
	shrdl	$5,%r13d,%r13d
	xorl	%ebx,%r14d
	andl	%r9d,%r12d
	vpaddd	32(%rbp),%xmm1,%xmm6
	xorl	%r9d,%r13d
	addl	28(%rsp),%eax
	movl	%ebx,%edi
	xorl	%r11d,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%ecx,%edi
	addl	%r12d,%eax
	shrdl	$6,%r13d,%r13d
	andl	%edi,%r15d
	xorl	%ebx,%r14d
	addl	%r13d,%eax
	xorl	%ecx,%r15d
	shrdl	$2,%r14d,%r14d
	addl	%eax,%r8d
	addl	%r15d,%eax
	movl	%r8d,%r13d
	addl	%eax,%r14d
	vmovdqa	%xmm6,16(%rsp)
	vpalignr	$4,%xmm2,%xmm3,%xmm4
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%eax
	movl	%r9d,%r12d
	vpalignr	$4,%xmm0,%xmm1,%xmm7
	shrdl	$9,%r14d,%r14d
	xorl	%r8d,%r13d
	xorl	%r10d,%r12d
	vpsrld	$7,%xmm4,%xmm6
	shrdl	$5,%r13d,%r13d
	xorl	%eax,%r14d
	andl	%r8d,%r12d
	vpaddd	%xmm7,%xmm2,%xmm2
	xorl	%r8d,%r13d
	addl	32(%rsp),%r11d
	movl	%eax,%r15d
	vpsrld	$3,%xmm4,%xmm7
	xorl	%r10d,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%ebx,%r15d
	vpslld	$14,%xmm4,%xmm5
	addl	%r12d,%r11d
	shrdl	$6,%r13d,%r13d
	andl	%r15d,%edi
	vpxor	%xmm6,%xmm7,%xmm4
	xorl	%eax,%r14d
	addl	%r13d,%r11d
	xorl	%ebx,%edi
	vpshufd	$250,%xmm1,%xmm7
	shrdl	$2,%r14d,%r14d
	addl	%r11d,%edx
	addl	%edi,%r11d
	vpsrld	$11,%xmm6,%xmm6
	movl	%edx,%r13d
	addl	%r11d,%r14d
	shrdl	$14,%r13d,%r13d
	vpxor	%xmm5,%xmm4,%xmm4
	movl	%r14d,%r11d
	movl	%r8d,%r12d
	shrdl	$9,%r14d,%r14d
	vpslld	$11,%xmm5,%xmm5
	xorl	%edx,%r13d
	xorl	%r9d,%r12d
	shrdl	$5,%r13d,%r13d
	vpxor	%xmm6,%xmm4,%xmm4
	xorl	%r11d,%r14d
	andl	%edx,%r12d
	xorl	%edx,%r13d
	vpsrld	$10,%xmm7,%xmm6
	addl	36(%rsp),%r10d
	movl	%r11d,%edi
	xorl	%r9d,%r12d
	vpxor	%xmm5,%xmm4,%xmm4
	shrdl	$11,%r14d,%r14d
	xorl	%eax,%edi
	addl	%r12d,%r10d
	vpsrlq	$17,%xmm7,%xmm7
	shrdl	$6,%r13d,%r13d
	andl	%edi,%r15d
	xorl	%r11d,%r14d
	vpaddd	%xmm4,%xmm2,%xmm2
	addl	%r13d,%r10d
	xorl	%eax,%r15d
	shrdl	$2,%r14d,%r14d
	vpxor	%xmm7,%xmm6,%xmm6
	addl	%r10d,%ecx
	addl	%r15d,%r10d
	movl	%ecx,%r13d
	vpsrlq	$2,%xmm7,%xmm7
	addl	%r10d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r10d
	vpxor	%xmm7,%xmm6,%xmm6
	movl	%edx,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%ecx,%r13d
	vpshufb	%xmm8,%xmm6,%xmm6
	xorl	%r8d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r10d,%r14d
	vpaddd	%xmm6,%xmm2,%xmm2
	andl	%ecx,%r12d
	xorl	%ecx,%r13d
	addl	40(%rsp),%r9d
	vpshufd	$80,%xmm2,%xmm7
	movl	%r10d,%r15d
	xorl	%r8d,%r12d
	shrdl	$11,%r14d,%r14d
	vpsrld	$10,%xmm7,%xmm6
	xorl	%r11d,%r15d
	addl	%r12d,%r9d
	shrdl	$6,%r13d,%r13d
	vpsrlq	$17,%xmm7,%xmm7
	andl	%r15d,%edi
	xorl	%r10d,%r14d
	addl	%r13d,%r9d
	vpxor	%xmm7,%xmm6,%xmm6
	xorl	%r11d,%edi
	shrdl	$2,%r14d,%r14d
	addl	%r9d,%ebx
	vpsrlq	$2,%xmm7,%xmm7
	addl	%edi,%r9d
	movl	%ebx,%r13d
	addl	%r9d,%r14d
	vpxor	%xmm7,%xmm6,%xmm6
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r9d
	movl	%ecx,%r12d
	vpshufb	%xmm9,%xmm6,%xmm6
	shrdl	$9,%r14d,%r14d
	xorl	%ebx,%r13d
	xorl	%edx,%r12d
	vpaddd	%xmm6,%xmm2,%xmm2
	shrdl	$5,%r13d,%r13d
	xorl	%r9d,%r14d
	andl	%ebx,%r12d
	vpaddd	64(%rbp),%xmm2,%xmm6
	xorl	%ebx,%r13d
	addl	44(%rsp),%r8d
	movl	%r9d,%edi
	xorl	%edx,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%r10d,%edi
	addl	%r12d,%r8d
	shrdl	$6,%r13d,%r13d
	andl	%edi,%r15d
	xorl	%r9d,%r14d
	addl	%r13d,%r8d
	xorl	%r10d,%r15d
	shrdl	$2,%r14d,%r14d
	addl	%r8d,%eax
	addl	%r15d,%r8d
	movl	%eax,%r13d
	addl	%r8d,%r14d
	vmovdqa	%xmm6,32(%rsp)
	vpalignr	$4,%xmm3,%xmm0,%xmm4
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r8d
	movl	%ebx,%r12d
	vpalignr	$4,%xmm1,%xmm2,%xmm7
	shrdl	$9,%r14d,%r14d
	xorl	%eax,%r13d
	xorl	%ecx,%r12d
	vpsrld	$7,%xmm4,%xmm6
	shrdl	$5,%r13d,%r13d
	xorl	%r8d,%r14d
	andl	%eax,%r12d
	vpaddd	%xmm7,%xmm3,%xmm3
	xorl	%eax,%r13d
	addl	48(%rsp),%edx
	movl	%r8d,%r15d
	vpsrld	$3,%xmm4,%xmm7
	xorl	%ecx,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%r9d,%r15d
	vpslld	$14,%xmm4,%xmm5
	addl	%r12d,%edx
	shrdl	$6,%r13d,%r13d
	andl	%r15d,%edi
	vpxor	%xmm6,%xmm7,%xmm4
	xorl	%r8d,%r14d
	addl	%r13d,%edx
	xorl	%r9d,%edi
	vpshufd	$250,%xmm2,%xmm7
	shrdl	$2,%r14d,%r14d
	addl	%edx,%r11d
	addl	%edi,%edx
	vpsrld	$11,%xmm6,%xmm6
	movl	%r11d,%r13d
	addl	%edx,%r14d
	shrdl	$14,%r13d,%r13d
	vpxor	%xmm5,%xmm4,%xmm4
	movl	%r14d,%edx
	movl	%eax,%r12d
	shrdl	$9,%r14d,%r14d
	vpslld	$11,%xmm5,%xmm5
	xorl	%r11d,%r13d
	xorl	%ebx,%r12d
	shrdl	$5,%r13d,%r13d
	vpxor	%xmm6,%xmm4,%xmm4
	xorl	%edx,%r14d
	andl	%r11d,%r12d
	xorl	%r11d,%r13d
	vpsrld	$10,%xmm7,%xmm6
	addl	52(%rsp),%ecx
	movl	%edx,%edi
	xorl	%ebx,%r12d
	vpxor	%xmm5,%xmm4,%xmm4
	shrdl	$11,%r14d,%r14d
	xorl	%r8d,%edi
	addl	%r12d,%ecx
	vpsrlq	$17,%xmm7,%xmm7
	shrdl	$6,%r13d,%r13d
	andl	%edi,%r15d
	xorl	%edx,%r14d
	vpaddd	%xmm4,%xmm3,%xmm3
	addl	%r13d,%ecx
	xorl	%r8d,%r15d
	shrdl	$2,%r14d,%r14d
	vpxor	%xmm7,%xmm6,%xmm6
	addl	%ecx,%r10d
	addl	%r15d,%ecx
	movl	%r10d,%r13d
	vpsrlq	$2,%xmm7,%xmm7
	addl	%ecx,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%ecx
	vpxor	%xmm7,%xmm6,%xmm6
	movl	%r11d,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%r10d,%r13d
	vpshufb	%xmm8,%xmm6,%xmm6
	xorl	%eax,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%ecx,%r14d
	vpaddd	%xmm6,%xmm3,%xmm3
	andl	%r10d,%r12d
	xorl	%r10d,%r13d
	addl	56(%rsp),%ebx
	vpshufd	$80,%xmm3,%xmm7
	movl	%ecx,%r15d
	xorl	%eax,%r12d
	shrdl	$11,%r14d,%r14d
	vpsrld	$10,%xmm7,%xmm6
	xorl	%edx,%r15d
	addl	%r12d,%ebx
	shrdl	$6,%r13d,%r13d
	vpsrlq	$17,%xmm7,%xmm7
	andl	%r15d,%edi
	xorl	%ecx,%r14d
	addl	%r13d,%ebx
	vpxor	%xmm7,%xmm6,%xmm6
	xorl	%edx,%edi
	shrdl	$2,%r14d,%r14d
	addl	%ebx,%r9d
	vpsrlq	$2,%xmm7,%xmm7
	addl	%edi,%ebx
	movl	%r9d,%r13d
	addl	%ebx,%r14d
	vpxor	%xmm7,%xmm6,%xmm6
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%ebx
	movl	%r10d,%r12d
	vpshufb	%xmm9,%xmm6,%xmm6
	shrdl	$9,%r14d,%r14d
	xorl	%r9d,%r13d
	xorl	%r11d,%r12d
	vpaddd	%xmm6,%xmm3,%xmm3
	shrdl	$5,%r13d,%r13d
	xorl	%ebx,%r14d
	andl	%r9d,%r12d
	vpaddd	96(%rbp),%xmm3,%xmm6
	xorl	%r9d,%r13d
	addl	60(%rsp),%eax
	movl	%ebx,%edi
	xorl	%r11d,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%ecx,%edi
	addl	%r12d,%eax
	shrdl	$6,%r13d,%r13d
	andl	%edi,%r15d
	xorl	%ebx,%r14d
	addl	%r13d,%eax
	xorl	%ecx,%r15d
	shrdl	$2,%r14d,%r14d
	addl	%eax,%r8d
	addl	%r15d,%eax
	movl	%r8d,%r13d
	addl	%eax,%r14d
	vmovdqa	%xmm6,48(%rsp)
	cmpb	$0,131(%rbp)
	jne	.Lavx_00_47
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%eax
	movl	%r9d,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%r8d,%r13d
	xorl	%r10d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%eax,%r14d
	andl	%r8d,%r12d
	xorl	%r8d,%r13d
	addl	0(%rsp),%r11d
	movl	%eax,%r15d
	xorl	%r10d,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%ebx,%r15d
	addl	%r12d,%r11d
	shrdl	$6,%r13d,%r13d
	andl	%r15d,%edi
	xorl	%eax,%r14d
	addl	%r13d,%r11d
	xorl	%ebx,%edi
	shrdl	$2,%r14d,%r14d
	addl	%r11d,%edx
	addl	%edi,%r11d
	movl	%edx,%r13d
	addl	%r11d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r11d
	movl	%r8d,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%edx,%r13d
	xorl	%r9d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r11d,%r14d
	andl	%edx,%r12d
	xorl	%edx,%r13d
	addl	4(%rsp),%r10d
	movl	%r11d,%edi
	xorl	%r9d,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%eax,%edi
	addl	%r12d,%r10d
	shrdl	$6,%r13d,%r13d
	andl	%edi,%r15d
	xorl	%r11d,%r14d
	addl	%r13d,%r10d
	xorl	%eax,%r15d
	shrdl	$2,%r14d,%r14d
	addl	%r10d,%ecx
	addl	%r15d,%r10d
	movl	%ecx,%r13d
	addl	%r10d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r10d
	movl	%edx,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%ecx,%r13d
	xorl	%r8d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r10d,%r14d
	andl	%ecx,%r12d
	xorl	%ecx,%r13d
	addl	8(%rsp),%r9d
	movl	%r10d,%r15d
	xorl	%r8d,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%r11d,%r15d
	addl	%r12d,%r9d
	shrdl	$6,%r13d,%r13d
	andl	%r15d,%edi
	xorl	%r10d,%r14d
	addl	%r13d,%r9d
	xorl	%r11d,%edi
	shrdl	$2,%r14d,%r14d
	addl	%r9d,%ebx
	addl	%edi,%r9d
	movl	%ebx,%r13d
	addl	%r9d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r9d
	movl	%ecx,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%ebx,%r13d
	xorl	%edx,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r9d,%r14d
	andl	%ebx,%r12d
	xorl	%ebx,%r13d
	addl	12(%rsp),%r8d
	movl	%r9d,%edi
	xorl	%edx,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%r10d,%edi
	addl	%r12d,%r8d
	shrdl	$6,%r13d,%r13d
	andl	%edi,%r15d
	xorl	%r9d,%r14d
	addl	%r13d,%r8d
	xorl	%r10d,%r15d
	shrdl	$2,%r14d,%r14d
	addl	%r8d,%eax
	addl	%r15d,%r8d
	movl	%eax,%r13d
	addl	%r8d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r8d
	movl	%ebx,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%eax,%r13d
	xorl	%ecx,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r8d,%r14d
	andl	%eax,%r12d
	xorl	%eax,%r13d
	addl	16(%rsp),%edx
	movl	%r8d,%r15d
	xorl	%ecx,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%r9d,%r15d
	addl	%r12d,%edx
	shrdl	$6,%r13d,%r13d
	andl	%r15d,%edi
	xorl	%r8d,%r14d
	addl	%r13d,%edx
	xorl	%r9d,%edi
	shrdl	$2,%r14d,%r14d
	addl	%edx,%r11d
	addl	%edi,%edx
	movl	%r11d,%r13d
	addl	%edx,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%edx
	movl	%eax,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%r11d,%r13d
	xorl	%ebx,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%edx,%r14d
	andl	%r11d,%r12d
	xorl	%r11d,%r13d
	addl	20(%rsp),%ecx
	movl	%edx,%edi
	xorl	%ebx,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%r8d,%edi
	addl	%r12d,%ecx
	shrdl	$6,%r13d,%r13d
	andl	%edi,%r15d
	xorl	%edx,%r14d
	addl	%r13d,%ecx
	xorl	%r8d,%r15d
	shrdl	$2,%r14d,%r14d
	addl	%ecx,%r10d
	addl	%r15d,%ecx
	movl	%r10d,%r13d
	addl	%ecx,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%ecx
	movl	%r11d,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%r10d,%r13d
	xorl	%eax,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%ecx,%r14d
	andl	%r10d,%r12d
	xorl	%r10d,%r13d
	addl	24(%rsp),%ebx
	movl	%ecx,%r15d
	xorl	%eax,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%edx,%r15d
	addl	%r12d,%ebx
	shrdl	$6,%r13d,%r13d
	andl	%r15d,%edi
	xorl	%ecx,%r14d
	addl	%r13d,%ebx
	xorl	%edx,%edi
	shrdl	$2,%r14d,%r14d
	addl	%ebx,%r9d
	addl	%edi,%ebx
	movl	%r9d,%r13d
	addl	%ebx,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%ebx
	movl	%r10d,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%r9d,%r13d
	xorl	%r11d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%ebx,%r14d
	andl	%r9d,%r12d
	xorl	%r9d,%r13d
	addl	28(%rsp),%eax
	movl	%ebx,%edi
	xorl	%r11d,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%ecx,%edi
	addl	%r12d,%eax
	shrdl	$6,%r13d,%r13d
	andl	%edi,%r15d
	xorl	%ebx,%r14d
	addl	%r13d,%eax
	xorl	%ecx,%r15d
	shrdl	$2,%r14d,%r14d
	addl	%eax,%r8d
	addl	%r15d,%eax
	movl	%r8d,%r13d
	addl	%eax,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%eax
	movl	%r9d,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%r8d,%r13d
	xorl	%r10d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%eax,%r14d
	andl	%r8d,%r12d
	xorl	%r8d,%r13d
	addl	32(%rsp),%r11d
	movl	%eax,%r15d
	xorl	%r10d,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%ebx,%r15d
	addl	%r12d,%r11d
	shrdl	$6,%r13d,%r13d
	andl	%r15d,%edi
	xorl	%eax,%r14d
	addl	%r13d,%r11d
	xorl	%ebx,%edi
	shrdl	$2,%r14d,%r14d
	addl	%r11d,%edx
	addl	%edi,%r11d
	movl	%edx,%r13d
	addl	%r11d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r11d
	movl	%r8d,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%edx,%r13d
	xorl	%r9d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r11d,%r14d
	andl	%edx,%r12d
	xorl	%edx,%r13d
	addl	36(%rsp),%r10d
	movl	%r11d,%edi
	xorl	%r9d,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%eax,%edi
	addl	%r12d,%r10d
	shrdl	$6,%r13d,%r13d
	andl	%edi,%r15d
	xorl	%r11d,%r14d
	addl	%r13d,%r10d
	xorl	%eax,%r15d
	shrdl	$2,%r14d,%r14d
	addl	%r10d,%ecx
	addl	%r15d,%r10d
	movl	%ecx,%r13d
	addl	%r10d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r10d
	movl	%edx,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%ecx,%r13d
	xorl	%r8d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r10d,%r14d
	andl	%ecx,%r12d
	xorl	%ecx,%r13d
	addl	40(%rsp),%r9d
	movl	%r10d,%r15d
	xorl	%r8d,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%r11d,%r15d
	addl	%r12d,%r9d
	shrdl	$6,%r13d,%r13d
	andl	%r15d,%edi
	xorl	%r10d,%r14d
	addl	%r13d,%r9d
	xorl	%r11d,%edi
	shrdl	$2,%r14d,%r14d
	addl	%r9d,%ebx
	addl	%edi,%r9d
	movl	%ebx,%r13d
	addl	%r9d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r9d
	movl	%ecx,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%ebx,%r13d
	xorl	%edx,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r9d,%r14d
	andl	%ebx,%r12d
	xorl	%ebx,%r13d
	addl	44(%rsp),%r8d
	movl	%r9d,%edi
	xorl	%edx,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%r10d,%edi
	addl	%r12d,%r8d
	shrdl	$6,%r13d,%r13d
	andl	%edi,%r15d
	xorl	%r9d,%r14d
	addl	%r13d,%r8d
	xorl	%r10d,%r15d
	shrdl	$2,%r14d,%r14d
	addl	%r8d,%eax
	addl	%r15d,%r8d
	movl	%eax,%r13d
	addl	%r8d,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%r8d
	movl	%ebx,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%eax,%r13d
	xorl	%ecx,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%r8d,%r14d
	andl	%eax,%r12d
	xorl	%eax,%r13d
	addl	48(%rsp),%edx
	movl	%r8d,%r15d
	xorl	%ecx,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%r9d,%r15d
	addl	%r12d,%edx
	shrdl	$6,%r13d,%r13d
	andl	%r15d,%edi
	xorl	%r8d,%r14d
	addl	%r13d,%edx
	xorl	%r9d,%edi
	shrdl	$2,%r14d,%r14d
	addl	%edx,%r11d
	addl	%edi,%edx
	movl	%r11d,%r13d
	addl	%edx,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%edx
	movl	%eax,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%r11d,%r13d
	xorl	%ebx,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%edx,%r14d
	andl	%r11d,%r12d
	xorl	%r11d,%r13d
	addl	52(%rsp),%ecx
	movl	%edx,%edi
	xorl	%ebx,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%r8d,%edi
	addl	%r12d,%ecx
	shrdl	$6,%r13d,%r13d
	andl	%edi,%r15d
	xorl	%edx,%r14d
	addl	%r13d,%ecx
	xorl	%r8d,%r15d
	shrdl	$2,%r14d,%r14d
	addl	%ecx,%r10d
	addl	%r15d,%ecx
	movl	%r10d,%r13d
	addl	%ecx,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%ecx
	movl	%r11d,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%r10d,%r13d
	xorl	%eax,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%ecx,%r14d
	andl	%r10d,%r12d
	xorl	%r10d,%r13d
	addl	56(%rsp),%ebx
	movl	%ecx,%r15d
	xorl	%eax,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%edx,%r15d
	addl	%r12d,%ebx
	shrdl	$6,%r13d,%r13d
	andl	%r15d,%edi
	xorl	%ecx,%r14d
	addl	%r13d,%ebx
	xorl	%edx,%edi
	shrdl	$2,%r14d,%r14d
	addl	%ebx,%r9d
	addl	%edi,%ebx
	movl	%r9d,%r13d
	addl	%ebx,%r14d
	shrdl	$14,%r13d,%r13d
	movl	%r14d,%ebx
	movl	%r10d,%r12d
	shrdl	$9,%r14d,%r14d
	xorl	%r9d,%r13d
	xorl	%r11d,%r12d
	shrdl	$5,%r13d,%r13d
	xorl	%ebx,%r14d
	andl	%r9d,%r12d
	xorl	%r9d,%r13d
	addl	60(%rsp),%eax
	movl	%ebx,%edi
	xorl	%r11d,%r12d
	shrdl	$11,%r14d,%r14d
	xorl	%ecx,%edi
	addl	%r12d,%eax
	shrdl	$6,%r13d,%r13d
	andl	%edi,%r15d
	xorl	%ebx,%r14d
	addl	%r13d,%eax
	xorl	%ecx,%r15d
	shrdl	$2,%r14d,%r14d
	addl	%eax,%r8d
	addl	%r15d,%eax
	movl	%r8d,%r13d
	addl	%eax,%r14d
	movq	64+0(%rsp),%rdi
	movl	%r14d,%eax

	addl	0(%rdi),%eax
	leaq	64(%rsi),%rsi
	addl	4(%rdi),%ebx
	addl	8(%rdi),%ecx
	addl	12(%rdi),%edx
	addl	16(%rdi),%r8d
	addl	20(%rdi),%r9d
	addl	24(%rdi),%r10d
	addl	28(%rdi),%r11d

	cmpq	64+16(%rsp),%rsi

	movl	%eax,0(%rdi)
	movl	%ebx,4(%rdi)
	movl	%ecx,8(%rdi)
	movl	%edx,12(%rdi)
	movl	%r8d,16(%rdi)
	movl	%r9d,20(%rdi)
	movl	%r10d,24(%rdi)
	movl	%r11d,28(%rdi)
	jb	.Lloop_avx

	movq	88(%rsp),%rsi
.cfi_def_cfa	%rsi,8
	vzeroupper
	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue_avx:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha256_block_data_order_avx,.-sha256_block_data_order_avx
.type	sha256_block_data_order_avx2,@function
.align	64
sha256_block_data_order_avx2:
.cfi_startproc	
.Lavx2_shortcut:
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
	subq	$544,%rsp
	shlq	$4,%rdx
	andq	$-1024,%rsp
	leaq	(%rsi,%rdx,4),%rdx
	addq	$448,%rsp
	movq	%rdi,64+0(%rsp)
	movq	%rsi,64+8(%rsp)
	movq	%rdx,64+16(%rsp)
	movq	%rax,88(%rsp)
.cfi_escape	0x0f,0x06,0x77,0xd8,0x00,0x06,0x23,0x08
.Lprologue_avx2:

	vzeroupper
	subq	$-64,%rsi
	movl	0(%rdi),%eax
	movq	%rsi,%r12
	movl	4(%rdi),%ebx
	cmpq	%rdx,%rsi
	movl	8(%rdi),%ecx
	cmoveq	%rsp,%r12
	movl	12(%rdi),%edx
	movl	16(%rdi),%r8d
	movl	20(%rdi),%r9d
	movl	24(%rdi),%r10d
	movl	28(%rdi),%r11d
	vmovdqa	K256+512+32(%rip),%ymm8
	vmovdqa	K256+512+64(%rip),%ymm9
	jmp	.Loop_avx2
.align	16
.Loop_avx2:
	vmovdqa	K256+512(%rip),%ymm7
	vmovdqu	-64+0(%rsi),%xmm0
	vmovdqu	-64+16(%rsi),%xmm1
	vmovdqu	-64+32(%rsi),%xmm2
	vmovdqu	-64+48(%rsi),%xmm3

	vinserti128	$1,(%r12),%ymm0,%ymm0
	vinserti128	$1,16(%r12),%ymm1,%ymm1
	vpshufb	%ymm7,%ymm0,%ymm0
	vinserti128	$1,32(%r12),%ymm2,%ymm2
	vpshufb	%ymm7,%ymm1,%ymm1
	vinserti128	$1,48(%r12),%ymm3,%ymm3

	leaq	K256(%rip),%rbp
	vpshufb	%ymm7,%ymm2,%ymm2
	vpaddd	0(%rbp),%ymm0,%ymm4
	vpshufb	%ymm7,%ymm3,%ymm3
	vpaddd	32(%rbp),%ymm1,%ymm5
	vpaddd	64(%rbp),%ymm2,%ymm6
	vpaddd	96(%rbp),%ymm3,%ymm7
	vmovdqa	%ymm4,0(%rsp)
	xorl	%r14d,%r14d
	vmovdqa	%ymm5,32(%rsp)

	movq	88(%rsp),%rdi
.cfi_def_cfa	%rdi,8
	leaq	-64(%rsp),%rsp



	movq	%rdi,-8(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x78,0x06,0x23,0x08
	movl	%ebx,%edi
	vmovdqa	%ymm6,0(%rsp)
	xorl	%ecx,%edi
	vmovdqa	%ymm7,32(%rsp)
	movl	%r9d,%r12d
	subq	$-32*4,%rbp
	jmp	.Lavx2_00_47

.align	16
.Lavx2_00_47:
	leaq	-64(%rsp),%rsp
.cfi_escape	0x0f,0x05,0x77,0x38,0x06,0x23,0x08

	pushq	64-8(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x00,0x06,0x23,0x08
	leaq	8(%rsp),%rsp
.cfi_escape	0x0f,0x05,0x77,0x78,0x06,0x23,0x08
	vpalignr	$4,%ymm0,%ymm1,%ymm4
	addl	0+128(%rsp),%r11d
	andl	%r8d,%r12d
	rorxl	$25,%r8d,%r13d
	vpalignr	$4,%ymm2,%ymm3,%ymm7
	rorxl	$11,%r8d,%r15d
	leal	(%rax,%r14,1),%eax
	leal	(%r11,%r12,1),%r11d
	vpsrld	$7,%ymm4,%ymm6
	andnl	%r10d,%r8d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r8d,%r14d
	vpaddd	%ymm7,%ymm0,%ymm0
	leal	(%r11,%r12,1),%r11d
	xorl	%r14d,%r13d
	movl	%eax,%r15d
	vpsrld	$3,%ymm4,%ymm7
	rorxl	$22,%eax,%r12d
	leal	(%r11,%r13,1),%r11d
	xorl	%ebx,%r15d
	vpslld	$14,%ymm4,%ymm5
	rorxl	$13,%eax,%r14d
	rorxl	$2,%eax,%r13d
	leal	(%rdx,%r11,1),%edx
	vpxor	%ymm6,%ymm7,%ymm4
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%ebx,%edi
	vpshufd	$250,%ymm3,%ymm7
	xorl	%r13d,%r14d
	leal	(%r11,%rdi,1),%r11d
	movl	%r8d,%r12d
	vpsrld	$11,%ymm6,%ymm6
	addl	4+128(%rsp),%r10d
	andl	%edx,%r12d
	rorxl	$25,%edx,%r13d
	vpxor	%ymm5,%ymm4,%ymm4
	rorxl	$11,%edx,%edi
	leal	(%r11,%r14,1),%r11d
	leal	(%r10,%r12,1),%r10d
	vpslld	$11,%ymm5,%ymm5
	andnl	%r9d,%edx,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%edx,%r14d
	vpxor	%ymm6,%ymm4,%ymm4
	leal	(%r10,%r12,1),%r10d
	xorl	%r14d,%r13d
	movl	%r11d,%edi
	vpsrld	$10,%ymm7,%ymm6
	rorxl	$22,%r11d,%r12d
	leal	(%r10,%r13,1),%r10d
	xorl	%eax,%edi
	vpxor	%ymm5,%ymm4,%ymm4
	rorxl	$13,%r11d,%r14d
	rorxl	$2,%r11d,%r13d
	leal	(%rcx,%r10,1),%ecx
	vpsrlq	$17,%ymm7,%ymm7
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%eax,%r15d
	vpaddd	%ymm4,%ymm0,%ymm0
	xorl	%r13d,%r14d
	leal	(%r10,%r15,1),%r10d
	movl	%edx,%r12d
	vpxor	%ymm7,%ymm6,%ymm6
	addl	8+128(%rsp),%r9d
	andl	%ecx,%r12d
	rorxl	$25,%ecx,%r13d
	vpsrlq	$2,%ymm7,%ymm7
	rorxl	$11,%ecx,%r15d
	leal	(%r10,%r14,1),%r10d
	leal	(%r9,%r12,1),%r9d
	vpxor	%ymm7,%ymm6,%ymm6
	andnl	%r8d,%ecx,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%ecx,%r14d
	vpshufb	%ymm8,%ymm6,%ymm6
	leal	(%r9,%r12,1),%r9d
	xorl	%r14d,%r13d
	movl	%r10d,%r15d
	vpaddd	%ymm6,%ymm0,%ymm0
	rorxl	$22,%r10d,%r12d
	leal	(%r9,%r13,1),%r9d
	xorl	%r11d,%r15d
	vpshufd	$80,%ymm0,%ymm7
	rorxl	$13,%r10d,%r14d
	rorxl	$2,%r10d,%r13d
	leal	(%rbx,%r9,1),%ebx
	vpsrld	$10,%ymm7,%ymm6
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%r11d,%edi
	vpsrlq	$17,%ymm7,%ymm7
	xorl	%r13d,%r14d
	leal	(%r9,%rdi,1),%r9d
	movl	%ecx,%r12d
	vpxor	%ymm7,%ymm6,%ymm6
	addl	12+128(%rsp),%r8d
	andl	%ebx,%r12d
	rorxl	$25,%ebx,%r13d
	vpsrlq	$2,%ymm7,%ymm7
	rorxl	$11,%ebx,%edi
	leal	(%r9,%r14,1),%r9d
	leal	(%r8,%r12,1),%r8d
	vpxor	%ymm7,%ymm6,%ymm6
	andnl	%edx,%ebx,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%ebx,%r14d
	vpshufb	%ymm9,%ymm6,%ymm6
	leal	(%r8,%r12,1),%r8d
	xorl	%r14d,%r13d
	movl	%r9d,%edi
	vpaddd	%ymm6,%ymm0,%ymm0
	rorxl	$22,%r9d,%r12d
	leal	(%r8,%r13,1),%r8d
	xorl	%r10d,%edi
	vpaddd	0(%rbp),%ymm0,%ymm6
	rorxl	$13,%r9d,%r14d
	rorxl	$2,%r9d,%r13d
	leal	(%rax,%r8,1),%eax
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%r10d,%r15d
	xorl	%r13d,%r14d
	leal	(%r8,%r15,1),%r8d
	movl	%ebx,%r12d
	vmovdqa	%ymm6,0(%rsp)
	vpalignr	$4,%ymm1,%ymm2,%ymm4
	addl	32+128(%rsp),%edx
	andl	%eax,%r12d
	rorxl	$25,%eax,%r13d
	vpalignr	$4,%ymm3,%ymm0,%ymm7
	rorxl	$11,%eax,%r15d
	leal	(%r8,%r14,1),%r8d
	leal	(%rdx,%r12,1),%edx
	vpsrld	$7,%ymm4,%ymm6
	andnl	%ecx,%eax,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%eax,%r14d
	vpaddd	%ymm7,%ymm1,%ymm1
	leal	(%rdx,%r12,1),%edx
	xorl	%r14d,%r13d
	movl	%r8d,%r15d
	vpsrld	$3,%ymm4,%ymm7
	rorxl	$22,%r8d,%r12d
	leal	(%rdx,%r13,1),%edx
	xorl	%r9d,%r15d
	vpslld	$14,%ymm4,%ymm5
	rorxl	$13,%r8d,%r14d
	rorxl	$2,%r8d,%r13d
	leal	(%r11,%rdx,1),%r11d
	vpxor	%ymm6,%ymm7,%ymm4
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%r9d,%edi
	vpshufd	$250,%ymm0,%ymm7
	xorl	%r13d,%r14d
	leal	(%rdx,%rdi,1),%edx
	movl	%eax,%r12d
	vpsrld	$11,%ymm6,%ymm6
	addl	36+128(%rsp),%ecx
	andl	%r11d,%r12d
	rorxl	$25,%r11d,%r13d
	vpxor	%ymm5,%ymm4,%ymm4
	rorxl	$11,%r11d,%edi
	leal	(%rdx,%r14,1),%edx
	leal	(%rcx,%r12,1),%ecx
	vpslld	$11,%ymm5,%ymm5
	andnl	%ebx,%r11d,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%r11d,%r14d
	vpxor	%ymm6,%ymm4,%ymm4
	leal	(%rcx,%r12,1),%ecx
	xorl	%r14d,%r13d
	movl	%edx,%edi
	vpsrld	$10,%ymm7,%ymm6
	rorxl	$22,%edx,%r12d
	leal	(%rcx,%r13,1),%ecx
	xorl	%r8d,%edi
	vpxor	%ymm5,%ymm4,%ymm4
	rorxl	$13,%edx,%r14d
	rorxl	$2,%edx,%r13d
	leal	(%r10,%rcx,1),%r10d
	vpsrlq	$17,%ymm7,%ymm7
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%r8d,%r15d
	vpaddd	%ymm4,%ymm1,%ymm1
	xorl	%r13d,%r14d
	leal	(%rcx,%r15,1),%ecx
	movl	%r11d,%r12d
	vpxor	%ymm7,%ymm6,%ymm6
	addl	40+128(%rsp),%ebx
	andl	%r10d,%r12d
	rorxl	$25,%r10d,%r13d
	vpsrlq	$2,%ymm7,%ymm7
	rorxl	$11,%r10d,%r15d
	leal	(%rcx,%r14,1),%ecx
	leal	(%rbx,%r12,1),%ebx
	vpxor	%ymm7,%ymm6,%ymm6
	andnl	%eax,%r10d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r10d,%r14d
	vpshufb	%ymm8,%ymm6,%ymm6
	leal	(%rbx,%r12,1),%ebx
	xorl	%r14d,%r13d
	movl	%ecx,%r15d
	vpaddd	%ymm6,%ymm1,%ymm1
	rorxl	$22,%ecx,%r12d
	leal	(%rbx,%r13,1),%ebx
	xorl	%edx,%r15d
	vpshufd	$80,%ymm1,%ymm7
	rorxl	$13,%ecx,%r14d
	rorxl	$2,%ecx,%r13d
	leal	(%r9,%rbx,1),%r9d
	vpsrld	$10,%ymm7,%ymm6
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%edx,%edi
	vpsrlq	$17,%ymm7,%ymm7
	xorl	%r13d,%r14d
	leal	(%rbx,%rdi,1),%ebx
	movl	%r10d,%r12d
	vpxor	%ymm7,%ymm6,%ymm6
	addl	44+128(%rsp),%eax
	andl	%r9d,%r12d
	rorxl	$25,%r9d,%r13d
	vpsrlq	$2,%ymm7,%ymm7
	rorxl	$11,%r9d,%edi
	leal	(%rbx,%r14,1),%ebx
	leal	(%rax,%r12,1),%eax
	vpxor	%ymm7,%ymm6,%ymm6
	andnl	%r11d,%r9d,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%r9d,%r14d
	vpshufb	%ymm9,%ymm6,%ymm6
	leal	(%rax,%r12,1),%eax
	xorl	%r14d,%r13d
	movl	%ebx,%edi
	vpaddd	%ymm6,%ymm1,%ymm1
	rorxl	$22,%ebx,%r12d
	leal	(%rax,%r13,1),%eax
	xorl	%ecx,%edi
	vpaddd	32(%rbp),%ymm1,%ymm6
	rorxl	$13,%ebx,%r14d
	rorxl	$2,%ebx,%r13d
	leal	(%r8,%rax,1),%r8d
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%ecx,%r15d
	xorl	%r13d,%r14d
	leal	(%rax,%r15,1),%eax
	movl	%r9d,%r12d
	vmovdqa	%ymm6,32(%rsp)
	leaq	-64(%rsp),%rsp
.cfi_escape	0x0f,0x05,0x77,0x38,0x06,0x23,0x08

	pushq	64-8(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x00,0x06,0x23,0x08
	leaq	8(%rsp),%rsp
.cfi_escape	0x0f,0x05,0x77,0x78,0x06,0x23,0x08
	vpalignr	$4,%ymm2,%ymm3,%ymm4
	addl	0+128(%rsp),%r11d
	andl	%r8d,%r12d
	rorxl	$25,%r8d,%r13d
	vpalignr	$4,%ymm0,%ymm1,%ymm7
	rorxl	$11,%r8d,%r15d
	leal	(%rax,%r14,1),%eax
	leal	(%r11,%r12,1),%r11d
	vpsrld	$7,%ymm4,%ymm6
	andnl	%r10d,%r8d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r8d,%r14d
	vpaddd	%ymm7,%ymm2,%ymm2
	leal	(%r11,%r12,1),%r11d
	xorl	%r14d,%r13d
	movl	%eax,%r15d
	vpsrld	$3,%ymm4,%ymm7
	rorxl	$22,%eax,%r12d
	leal	(%r11,%r13,1),%r11d
	xorl	%ebx,%r15d
	vpslld	$14,%ymm4,%ymm5
	rorxl	$13,%eax,%r14d
	rorxl	$2,%eax,%r13d
	leal	(%rdx,%r11,1),%edx
	vpxor	%ymm6,%ymm7,%ymm4
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%ebx,%edi
	vpshufd	$250,%ymm1,%ymm7
	xorl	%r13d,%r14d
	leal	(%r11,%rdi,1),%r11d
	movl	%r8d,%r12d
	vpsrld	$11,%ymm6,%ymm6
	addl	4+128(%rsp),%r10d
	andl	%edx,%r12d
	rorxl	$25,%edx,%r13d
	vpxor	%ymm5,%ymm4,%ymm4
	rorxl	$11,%edx,%edi
	leal	(%r11,%r14,1),%r11d
	leal	(%r10,%r12,1),%r10d
	vpslld	$11,%ymm5,%ymm5
	andnl	%r9d,%edx,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%edx,%r14d
	vpxor	%ymm6,%ymm4,%ymm4
	leal	(%r10,%r12,1),%r10d
	xorl	%r14d,%r13d
	movl	%r11d,%edi
	vpsrld	$10,%ymm7,%ymm6
	rorxl	$22,%r11d,%r12d
	leal	(%r10,%r13,1),%r10d
	xorl	%eax,%edi
	vpxor	%ymm5,%ymm4,%ymm4
	rorxl	$13,%r11d,%r14d
	rorxl	$2,%r11d,%r13d
	leal	(%rcx,%r10,1),%ecx
	vpsrlq	$17,%ymm7,%ymm7
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%eax,%r15d
	vpaddd	%ymm4,%ymm2,%ymm2
	xorl	%r13d,%r14d
	leal	(%r10,%r15,1),%r10d
	movl	%edx,%r12d
	vpxor	%ymm7,%ymm6,%ymm6
	addl	8+128(%rsp),%r9d
	andl	%ecx,%r12d
	rorxl	$25,%ecx,%r13d
	vpsrlq	$2,%ymm7,%ymm7
	rorxl	$11,%ecx,%r15d
	leal	(%r10,%r14,1),%r10d
	leal	(%r9,%r12,1),%r9d
	vpxor	%ymm7,%ymm6,%ymm6
	andnl	%r8d,%ecx,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%ecx,%r14d
	vpshufb	%ymm8,%ymm6,%ymm6
	leal	(%r9,%r12,1),%r9d
	xorl	%r14d,%r13d
	movl	%r10d,%r15d
	vpaddd	%ymm6,%ymm2,%ymm2
	rorxl	$22,%r10d,%r12d
	leal	(%r9,%r13,1),%r9d
	xorl	%r11d,%r15d
	vpshufd	$80,%ymm2,%ymm7
	rorxl	$13,%r10d,%r14d
	rorxl	$2,%r10d,%r13d
	leal	(%rbx,%r9,1),%ebx
	vpsrld	$10,%ymm7,%ymm6
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%r11d,%edi
	vpsrlq	$17,%ymm7,%ymm7
	xorl	%r13d,%r14d
	leal	(%r9,%rdi,1),%r9d
	movl	%ecx,%r12d
	vpxor	%ymm7,%ymm6,%ymm6
	addl	12+128(%rsp),%r8d
	andl	%ebx,%r12d
	rorxl	$25,%ebx,%r13d
	vpsrlq	$2,%ymm7,%ymm7
	rorxl	$11,%ebx,%edi
	leal	(%r9,%r14,1),%r9d
	leal	(%r8,%r12,1),%r8d
	vpxor	%ymm7,%ymm6,%ymm6
	andnl	%edx,%ebx,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%ebx,%r14d
	vpshufb	%ymm9,%ymm6,%ymm6
	leal	(%r8,%r12,1),%r8d
	xorl	%r14d,%r13d
	movl	%r9d,%edi
	vpaddd	%ymm6,%ymm2,%ymm2
	rorxl	$22,%r9d,%r12d
	leal	(%r8,%r13,1),%r8d
	xorl	%r10d,%edi
	vpaddd	64(%rbp),%ymm2,%ymm6
	rorxl	$13,%r9d,%r14d
	rorxl	$2,%r9d,%r13d
	leal	(%rax,%r8,1),%eax
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%r10d,%r15d
	xorl	%r13d,%r14d
	leal	(%r8,%r15,1),%r8d
	movl	%ebx,%r12d
	vmovdqa	%ymm6,0(%rsp)
	vpalignr	$4,%ymm3,%ymm0,%ymm4
	addl	32+128(%rsp),%edx
	andl	%eax,%r12d
	rorxl	$25,%eax,%r13d
	vpalignr	$4,%ymm1,%ymm2,%ymm7
	rorxl	$11,%eax,%r15d
	leal	(%r8,%r14,1),%r8d
	leal	(%rdx,%r12,1),%edx
	vpsrld	$7,%ymm4,%ymm6
	andnl	%ecx,%eax,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%eax,%r14d
	vpaddd	%ymm7,%ymm3,%ymm3
	leal	(%rdx,%r12,1),%edx
	xorl	%r14d,%r13d
	movl	%r8d,%r15d
	vpsrld	$3,%ymm4,%ymm7
	rorxl	$22,%r8d,%r12d
	leal	(%rdx,%r13,1),%edx
	xorl	%r9d,%r15d
	vpslld	$14,%ymm4,%ymm5
	rorxl	$13,%r8d,%r14d
	rorxl	$2,%r8d,%r13d
	leal	(%r11,%rdx,1),%r11d
	vpxor	%ymm6,%ymm7,%ymm4
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%r9d,%edi
	vpshufd	$250,%ymm2,%ymm7
	xorl	%r13d,%r14d
	leal	(%rdx,%rdi,1),%edx
	movl	%eax,%r12d
	vpsrld	$11,%ymm6,%ymm6
	addl	36+128(%rsp),%ecx
	andl	%r11d,%r12d
	rorxl	$25,%r11d,%r13d
	vpxor	%ymm5,%ymm4,%ymm4
	rorxl	$11,%r11d,%edi
	leal	(%rdx,%r14,1),%edx
	leal	(%rcx,%r12,1),%ecx
	vpslld	$11,%ymm5,%ymm5
	andnl	%ebx,%r11d,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%r11d,%r14d
	vpxor	%ymm6,%ymm4,%ymm4
	leal	(%rcx,%r12,1),%ecx
	xorl	%r14d,%r13d
	movl	%edx,%edi
	vpsrld	$10,%ymm7,%ymm6
	rorxl	$22,%edx,%r12d
	leal	(%rcx,%r13,1),%ecx
	xorl	%r8d,%edi
	vpxor	%ymm5,%ymm4,%ymm4
	rorxl	$13,%edx,%r14d
	rorxl	$2,%edx,%r13d
	leal	(%r10,%rcx,1),%r10d
	vpsrlq	$17,%ymm7,%ymm7
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%r8d,%r15d
	vpaddd	%ymm4,%ymm3,%ymm3
	xorl	%r13d,%r14d
	leal	(%rcx,%r15,1),%ecx
	movl	%r11d,%r12d
	vpxor	%ymm7,%ymm6,%ymm6
	addl	40+128(%rsp),%ebx
	andl	%r10d,%r12d
	rorxl	$25,%r10d,%r13d
	vpsrlq	$2,%ymm7,%ymm7
	rorxl	$11,%r10d,%r15d
	leal	(%rcx,%r14,1),%ecx
	leal	(%rbx,%r12,1),%ebx
	vpxor	%ymm7,%ymm6,%ymm6
	andnl	%eax,%r10d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r10d,%r14d
	vpshufb	%ymm8,%ymm6,%ymm6
	leal	(%rbx,%r12,1),%ebx
	xorl	%r14d,%r13d
	movl	%ecx,%r15d
	vpaddd	%ymm6,%ymm3,%ymm3
	rorxl	$22,%ecx,%r12d
	leal	(%rbx,%r13,1),%ebx
	xorl	%edx,%r15d
	vpshufd	$80,%ymm3,%ymm7
	rorxl	$13,%ecx,%r14d
	rorxl	$2,%ecx,%r13d
	leal	(%r9,%rbx,1),%r9d
	vpsrld	$10,%ymm7,%ymm6
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%edx,%edi
	vpsrlq	$17,%ymm7,%ymm7
	xorl	%r13d,%r14d
	leal	(%rbx,%rdi,1),%ebx
	movl	%r10d,%r12d
	vpxor	%ymm7,%ymm6,%ymm6
	addl	44+128(%rsp),%eax
	andl	%r9d,%r12d
	rorxl	$25,%r9d,%r13d
	vpsrlq	$2,%ymm7,%ymm7
	rorxl	$11,%r9d,%edi
	leal	(%rbx,%r14,1),%ebx
	leal	(%rax,%r12,1),%eax
	vpxor	%ymm7,%ymm6,%ymm6
	andnl	%r11d,%r9d,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%r9d,%r14d
	vpshufb	%ymm9,%ymm6,%ymm6
	leal	(%rax,%r12,1),%eax
	xorl	%r14d,%r13d
	movl	%ebx,%edi
	vpaddd	%ymm6,%ymm3,%ymm3
	rorxl	$22,%ebx,%r12d
	leal	(%rax,%r13,1),%eax
	xorl	%ecx,%edi
	vpaddd	96(%rbp),%ymm3,%ymm6
	rorxl	$13,%ebx,%r14d
	rorxl	$2,%ebx,%r13d
	leal	(%r8,%rax,1),%r8d
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%ecx,%r15d
	xorl	%r13d,%r14d
	leal	(%rax,%r15,1),%eax
	movl	%r9d,%r12d
	vmovdqa	%ymm6,32(%rsp)
	leaq	128(%rbp),%rbp
	cmpb	$0,3(%rbp)
	jne	.Lavx2_00_47
	addl	0+64(%rsp),%r11d
	andl	%r8d,%r12d
	rorxl	$25,%r8d,%r13d
	rorxl	$11,%r8d,%r15d
	leal	(%rax,%r14,1),%eax
	leal	(%r11,%r12,1),%r11d
	andnl	%r10d,%r8d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r8d,%r14d
	leal	(%r11,%r12,1),%r11d
	xorl	%r14d,%r13d
	movl	%eax,%r15d
	rorxl	$22,%eax,%r12d
	leal	(%r11,%r13,1),%r11d
	xorl	%ebx,%r15d
	rorxl	$13,%eax,%r14d
	rorxl	$2,%eax,%r13d
	leal	(%rdx,%r11,1),%edx
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%ebx,%edi
	xorl	%r13d,%r14d
	leal	(%r11,%rdi,1),%r11d
	movl	%r8d,%r12d
	addl	4+64(%rsp),%r10d
	andl	%edx,%r12d
	rorxl	$25,%edx,%r13d
	rorxl	$11,%edx,%edi
	leal	(%r11,%r14,1),%r11d
	leal	(%r10,%r12,1),%r10d
	andnl	%r9d,%edx,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%edx,%r14d
	leal	(%r10,%r12,1),%r10d
	xorl	%r14d,%r13d
	movl	%r11d,%edi
	rorxl	$22,%r11d,%r12d
	leal	(%r10,%r13,1),%r10d
	xorl	%eax,%edi
	rorxl	$13,%r11d,%r14d
	rorxl	$2,%r11d,%r13d
	leal	(%rcx,%r10,1),%ecx
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%eax,%r15d
	xorl	%r13d,%r14d
	leal	(%r10,%r15,1),%r10d
	movl	%edx,%r12d
	addl	8+64(%rsp),%r9d
	andl	%ecx,%r12d
	rorxl	$25,%ecx,%r13d
	rorxl	$11,%ecx,%r15d
	leal	(%r10,%r14,1),%r10d
	leal	(%r9,%r12,1),%r9d
	andnl	%r8d,%ecx,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%ecx,%r14d
	leal	(%r9,%r12,1),%r9d
	xorl	%r14d,%r13d
	movl	%r10d,%r15d
	rorxl	$22,%r10d,%r12d
	leal	(%r9,%r13,1),%r9d
	xorl	%r11d,%r15d
	rorxl	$13,%r10d,%r14d
	rorxl	$2,%r10d,%r13d
	leal	(%rbx,%r9,1),%ebx
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%r11d,%edi
	xorl	%r13d,%r14d
	leal	(%r9,%rdi,1),%r9d
	movl	%ecx,%r12d
	addl	12+64(%rsp),%r8d
	andl	%ebx,%r12d
	rorxl	$25,%ebx,%r13d
	rorxl	$11,%ebx,%edi
	leal	(%r9,%r14,1),%r9d
	leal	(%r8,%r12,1),%r8d
	andnl	%edx,%ebx,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%ebx,%r14d
	leal	(%r8,%r12,1),%r8d
	xorl	%r14d,%r13d
	movl	%r9d,%edi
	rorxl	$22,%r9d,%r12d
	leal	(%r8,%r13,1),%r8d
	xorl	%r10d,%edi
	rorxl	$13,%r9d,%r14d
	rorxl	$2,%r9d,%r13d
	leal	(%rax,%r8,1),%eax
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%r10d,%r15d
	xorl	%r13d,%r14d
	leal	(%r8,%r15,1),%r8d
	movl	%ebx,%r12d
	addl	32+64(%rsp),%edx
	andl	%eax,%r12d
	rorxl	$25,%eax,%r13d
	rorxl	$11,%eax,%r15d
	leal	(%r8,%r14,1),%r8d
	leal	(%rdx,%r12,1),%edx
	andnl	%ecx,%eax,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%eax,%r14d
	leal	(%rdx,%r12,1),%edx
	xorl	%r14d,%r13d
	movl	%r8d,%r15d
	rorxl	$22,%r8d,%r12d
	leal	(%rdx,%r13,1),%edx
	xorl	%r9d,%r15d
	rorxl	$13,%r8d,%r14d
	rorxl	$2,%r8d,%r13d
	leal	(%r11,%rdx,1),%r11d
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%r9d,%edi
	xorl	%r13d,%r14d
	leal	(%rdx,%rdi,1),%edx
	movl	%eax,%r12d
	addl	36+64(%rsp),%ecx
	andl	%r11d,%r12d
	rorxl	$25,%r11d,%r13d
	rorxl	$11,%r11d,%edi
	leal	(%rdx,%r14,1),%edx
	leal	(%rcx,%r12,1),%ecx
	andnl	%ebx,%r11d,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%r11d,%r14d
	leal	(%rcx,%r12,1),%ecx
	xorl	%r14d,%r13d
	movl	%edx,%edi
	rorxl	$22,%edx,%r12d
	leal	(%rcx,%r13,1),%ecx
	xorl	%r8d,%edi
	rorxl	$13,%edx,%r14d
	rorxl	$2,%edx,%r13d
	leal	(%r10,%rcx,1),%r10d
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%r8d,%r15d
	xorl	%r13d,%r14d
	leal	(%rcx,%r15,1),%ecx
	movl	%r11d,%r12d
	addl	40+64(%rsp),%ebx
	andl	%r10d,%r12d
	rorxl	$25,%r10d,%r13d
	rorxl	$11,%r10d,%r15d
	leal	(%rcx,%r14,1),%ecx
	leal	(%rbx,%r12,1),%ebx
	andnl	%eax,%r10d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r10d,%r14d
	leal	(%rbx,%r12,1),%ebx
	xorl	%r14d,%r13d
	movl	%ecx,%r15d
	rorxl	$22,%ecx,%r12d
	leal	(%rbx,%r13,1),%ebx
	xorl	%edx,%r15d
	rorxl	$13,%ecx,%r14d
	rorxl	$2,%ecx,%r13d
	leal	(%r9,%rbx,1),%r9d
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%edx,%edi
	xorl	%r13d,%r14d
	leal	(%rbx,%rdi,1),%ebx
	movl	%r10d,%r12d
	addl	44+64(%rsp),%eax
	andl	%r9d,%r12d
	rorxl	$25,%r9d,%r13d
	rorxl	$11,%r9d,%edi
	leal	(%rbx,%r14,1),%ebx
	leal	(%rax,%r12,1),%eax
	andnl	%r11d,%r9d,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%r9d,%r14d
	leal	(%rax,%r12,1),%eax
	xorl	%r14d,%r13d
	movl	%ebx,%edi
	rorxl	$22,%ebx,%r12d
	leal	(%rax,%r13,1),%eax
	xorl	%ecx,%edi
	rorxl	$13,%ebx,%r14d
	rorxl	$2,%ebx,%r13d
	leal	(%r8,%rax,1),%r8d
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%ecx,%r15d
	xorl	%r13d,%r14d
	leal	(%rax,%r15,1),%eax
	movl	%r9d,%r12d
	addl	0(%rsp),%r11d
	andl	%r8d,%r12d
	rorxl	$25,%r8d,%r13d
	rorxl	$11,%r8d,%r15d
	leal	(%rax,%r14,1),%eax
	leal	(%r11,%r12,1),%r11d
	andnl	%r10d,%r8d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r8d,%r14d
	leal	(%r11,%r12,1),%r11d
	xorl	%r14d,%r13d
	movl	%eax,%r15d
	rorxl	$22,%eax,%r12d
	leal	(%r11,%r13,1),%r11d
	xorl	%ebx,%r15d
	rorxl	$13,%eax,%r14d
	rorxl	$2,%eax,%r13d
	leal	(%rdx,%r11,1),%edx
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%ebx,%edi
	xorl	%r13d,%r14d
	leal	(%r11,%rdi,1),%r11d
	movl	%r8d,%r12d
	addl	4(%rsp),%r10d
	andl	%edx,%r12d
	rorxl	$25,%edx,%r13d
	rorxl	$11,%edx,%edi
	leal	(%r11,%r14,1),%r11d
	leal	(%r10,%r12,1),%r10d
	andnl	%r9d,%edx,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%edx,%r14d
	leal	(%r10,%r12,1),%r10d
	xorl	%r14d,%r13d
	movl	%r11d,%edi
	rorxl	$22,%r11d,%r12d
	leal	(%r10,%r13,1),%r10d
	xorl	%eax,%edi
	rorxl	$13,%r11d,%r14d
	rorxl	$2,%r11d,%r13d
	leal	(%rcx,%r10,1),%ecx
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%eax,%r15d
	xorl	%r13d,%r14d
	leal	(%r10,%r15,1),%r10d
	movl	%edx,%r12d
	addl	8(%rsp),%r9d
	andl	%ecx,%r12d
	rorxl	$25,%ecx,%r13d
	rorxl	$11,%ecx,%r15d
	leal	(%r10,%r14,1),%r10d
	leal	(%r9,%r12,1),%r9d
	andnl	%r8d,%ecx,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%ecx,%r14d
	leal	(%r9,%r12,1),%r9d
	xorl	%r14d,%r13d
	movl	%r10d,%r15d
	rorxl	$22,%r10d,%r12d
	leal	(%r9,%r13,1),%r9d
	xorl	%r11d,%r15d
	rorxl	$13,%r10d,%r14d
	rorxl	$2,%r10d,%r13d
	leal	(%rbx,%r9,1),%ebx
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%r11d,%edi
	xorl	%r13d,%r14d
	leal	(%r9,%rdi,1),%r9d
	movl	%ecx,%r12d
	addl	12(%rsp),%r8d
	andl	%ebx,%r12d
	rorxl	$25,%ebx,%r13d
	rorxl	$11,%ebx,%edi
	leal	(%r9,%r14,1),%r9d
	leal	(%r8,%r12,1),%r8d
	andnl	%edx,%ebx,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%ebx,%r14d
	leal	(%r8,%r12,1),%r8d
	xorl	%r14d,%r13d
	movl	%r9d,%edi
	rorxl	$22,%r9d,%r12d
	leal	(%r8,%r13,1),%r8d
	xorl	%r10d,%edi
	rorxl	$13,%r9d,%r14d
	rorxl	$2,%r9d,%r13d
	leal	(%rax,%r8,1),%eax
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%r10d,%r15d
	xorl	%r13d,%r14d
	leal	(%r8,%r15,1),%r8d
	movl	%ebx,%r12d
	addl	32(%rsp),%edx
	andl	%eax,%r12d
	rorxl	$25,%eax,%r13d
	rorxl	$11,%eax,%r15d
	leal	(%r8,%r14,1),%r8d
	leal	(%rdx,%r12,1),%edx
	andnl	%ecx,%eax,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%eax,%r14d
	leal	(%rdx,%r12,1),%edx
	xorl	%r14d,%r13d
	movl	%r8d,%r15d
	rorxl	$22,%r8d,%r12d
	leal	(%rdx,%r13,1),%edx
	xorl	%r9d,%r15d
	rorxl	$13,%r8d,%r14d
	rorxl	$2,%r8d,%r13d
	leal	(%r11,%rdx,1),%r11d
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%r9d,%edi
	xorl	%r13d,%r14d
	leal	(%rdx,%rdi,1),%edx
	movl	%eax,%r12d
	addl	36(%rsp),%ecx
	andl	%r11d,%r12d
	rorxl	$25,%r11d,%r13d
	rorxl	$11,%r11d,%edi
	leal	(%rdx,%r14,1),%edx
	leal	(%rcx,%r12,1),%ecx
	andnl	%ebx,%r11d,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%r11d,%r14d
	leal	(%rcx,%r12,1),%ecx
	xorl	%r14d,%r13d
	movl	%edx,%edi
	rorxl	$22,%edx,%r12d
	leal	(%rcx,%r13,1),%ecx
	xorl	%r8d,%edi
	rorxl	$13,%edx,%r14d
	rorxl	$2,%edx,%r13d
	leal	(%r10,%rcx,1),%r10d
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%r8d,%r15d
	xorl	%r13d,%r14d
	leal	(%rcx,%r15,1),%ecx
	movl	%r11d,%r12d
	addl	40(%rsp),%ebx
	andl	%r10d,%r12d
	rorxl	$25,%r10d,%r13d
	rorxl	$11,%r10d,%r15d
	leal	(%rcx,%r14,1),%ecx
	leal	(%rbx,%r12,1),%ebx
	andnl	%eax,%r10d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r10d,%r14d
	leal	(%rbx,%r12,1),%ebx
	xorl	%r14d,%r13d
	movl	%ecx,%r15d
	rorxl	$22,%ecx,%r12d
	leal	(%rbx,%r13,1),%ebx
	xorl	%edx,%r15d
	rorxl	$13,%ecx,%r14d
	rorxl	$2,%ecx,%r13d
	leal	(%r9,%rbx,1),%r9d
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%edx,%edi
	xorl	%r13d,%r14d
	leal	(%rbx,%rdi,1),%ebx
	movl	%r10d,%r12d
	addl	44(%rsp),%eax
	andl	%r9d,%r12d
	rorxl	$25,%r9d,%r13d
	rorxl	$11,%r9d,%edi
	leal	(%rbx,%r14,1),%ebx
	leal	(%rax,%r12,1),%eax
	andnl	%r11d,%r9d,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%r9d,%r14d
	leal	(%rax,%r12,1),%eax
	xorl	%r14d,%r13d
	movl	%ebx,%edi
	rorxl	$22,%ebx,%r12d
	leal	(%rax,%r13,1),%eax
	xorl	%ecx,%edi
	rorxl	$13,%ebx,%r14d
	rorxl	$2,%ebx,%r13d
	leal	(%r8,%rax,1),%r8d
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%ecx,%r15d
	xorl	%r13d,%r14d
	leal	(%rax,%r15,1),%eax
	movl	%r9d,%r12d
	movq	512(%rsp),%rdi
	addl	%r14d,%eax

	leaq	448(%rsp),%rbp

	addl	0(%rdi),%eax
	addl	4(%rdi),%ebx
	addl	8(%rdi),%ecx
	addl	12(%rdi),%edx
	addl	16(%rdi),%r8d
	addl	20(%rdi),%r9d
	addl	24(%rdi),%r10d
	addl	28(%rdi),%r11d

	movl	%eax,0(%rdi)
	movl	%ebx,4(%rdi)
	movl	%ecx,8(%rdi)
	movl	%edx,12(%rdi)
	movl	%r8d,16(%rdi)
	movl	%r9d,20(%rdi)
	movl	%r10d,24(%rdi)
	movl	%r11d,28(%rdi)

	cmpq	80(%rbp),%rsi
	je	.Ldone_avx2

	xorl	%r14d,%r14d
	movl	%ebx,%edi
	xorl	%ecx,%edi
	movl	%r9d,%r12d
	jmp	.Lower_avx2
.align	16
.Lower_avx2:
	addl	0+16(%rbp),%r11d
	andl	%r8d,%r12d
	rorxl	$25,%r8d,%r13d
	rorxl	$11,%r8d,%r15d
	leal	(%rax,%r14,1),%eax
	leal	(%r11,%r12,1),%r11d
	andnl	%r10d,%r8d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r8d,%r14d
	leal	(%r11,%r12,1),%r11d
	xorl	%r14d,%r13d
	movl	%eax,%r15d
	rorxl	$22,%eax,%r12d
	leal	(%r11,%r13,1),%r11d
	xorl	%ebx,%r15d
	rorxl	$13,%eax,%r14d
	rorxl	$2,%eax,%r13d
	leal	(%rdx,%r11,1),%edx
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%ebx,%edi
	xorl	%r13d,%r14d
	leal	(%r11,%rdi,1),%r11d
	movl	%r8d,%r12d
	addl	4+16(%rbp),%r10d
	andl	%edx,%r12d
	rorxl	$25,%edx,%r13d
	rorxl	$11,%edx,%edi
	leal	(%r11,%r14,1),%r11d
	leal	(%r10,%r12,1),%r10d
	andnl	%r9d,%edx,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%edx,%r14d
	leal	(%r10,%r12,1),%r10d
	xorl	%r14d,%r13d
	movl	%r11d,%edi
	rorxl	$22,%r11d,%r12d
	leal	(%r10,%r13,1),%r10d
	xorl	%eax,%edi
	rorxl	$13,%r11d,%r14d
	rorxl	$2,%r11d,%r13d
	leal	(%rcx,%r10,1),%ecx
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%eax,%r15d
	xorl	%r13d,%r14d
	leal	(%r10,%r15,1),%r10d
	movl	%edx,%r12d
	addl	8+16(%rbp),%r9d
	andl	%ecx,%r12d
	rorxl	$25,%ecx,%r13d
	rorxl	$11,%ecx,%r15d
	leal	(%r10,%r14,1),%r10d
	leal	(%r9,%r12,1),%r9d
	andnl	%r8d,%ecx,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%ecx,%r14d
	leal	(%r9,%r12,1),%r9d
	xorl	%r14d,%r13d
	movl	%r10d,%r15d
	rorxl	$22,%r10d,%r12d
	leal	(%r9,%r13,1),%r9d
	xorl	%r11d,%r15d
	rorxl	$13,%r10d,%r14d
	rorxl	$2,%r10d,%r13d
	leal	(%rbx,%r9,1),%ebx
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%r11d,%edi
	xorl	%r13d,%r14d
	leal	(%r9,%rdi,1),%r9d
	movl	%ecx,%r12d
	addl	12+16(%rbp),%r8d
	andl	%ebx,%r12d
	rorxl	$25,%ebx,%r13d
	rorxl	$11,%ebx,%edi
	leal	(%r9,%r14,1),%r9d
	leal	(%r8,%r12,1),%r8d
	andnl	%edx,%ebx,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%ebx,%r14d
	leal	(%r8,%r12,1),%r8d
	xorl	%r14d,%r13d
	movl	%r9d,%edi
	rorxl	$22,%r9d,%r12d
	leal	(%r8,%r13,1),%r8d
	xorl	%r10d,%edi
	rorxl	$13,%r9d,%r14d
	rorxl	$2,%r9d,%r13d
	leal	(%rax,%r8,1),%eax
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%r10d,%r15d
	xorl	%r13d,%r14d
	leal	(%r8,%r15,1),%r8d
	movl	%ebx,%r12d
	addl	32+16(%rbp),%edx
	andl	%eax,%r12d
	rorxl	$25,%eax,%r13d
	rorxl	$11,%eax,%r15d
	leal	(%r8,%r14,1),%r8d
	leal	(%rdx,%r12,1),%edx
	andnl	%ecx,%eax,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%eax,%r14d
	leal	(%rdx,%r12,1),%edx
	xorl	%r14d,%r13d
	movl	%r8d,%r15d
	rorxl	$22,%r8d,%r12d
	leal	(%rdx,%r13,1),%edx
	xorl	%r9d,%r15d
	rorxl	$13,%r8d,%r14d
	rorxl	$2,%r8d,%r13d
	leal	(%r11,%rdx,1),%r11d
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%r9d,%edi
	xorl	%r13d,%r14d
	leal	(%rdx,%rdi,1),%edx
	movl	%eax,%r12d
	addl	36+16(%rbp),%ecx
	andl	%r11d,%r12d
	rorxl	$25,%r11d,%r13d
	rorxl	$11,%r11d,%edi
	leal	(%rdx,%r14,1),%edx
	leal	(%rcx,%r12,1),%ecx
	andnl	%ebx,%r11d,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%r11d,%r14d
	leal	(%rcx,%r12,1),%ecx
	xorl	%r14d,%r13d
	movl	%edx,%edi
	rorxl	$22,%edx,%r12d
	leal	(%rcx,%r13,1),%ecx
	xorl	%r8d,%edi
	rorxl	$13,%edx,%r14d
	rorxl	$2,%edx,%r13d
	leal	(%r10,%rcx,1),%r10d
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%r8d,%r15d
	xorl	%r13d,%r14d
	leal	(%rcx,%r15,1),%ecx
	movl	%r11d,%r12d
	addl	40+16(%rbp),%ebx
	andl	%r10d,%r12d
	rorxl	$25,%r10d,%r13d
	rorxl	$11,%r10d,%r15d
	leal	(%rcx,%r14,1),%ecx
	leal	(%rbx,%r12,1),%ebx
	andnl	%eax,%r10d,%r12d
	xorl	%r15d,%r13d
	rorxl	$6,%r10d,%r14d
	leal	(%rbx,%r12,1),%ebx
	xorl	%r14d,%r13d
	movl	%ecx,%r15d
	rorxl	$22,%ecx,%r12d
	leal	(%rbx,%r13,1),%ebx
	xorl	%edx,%r15d
	rorxl	$13,%ecx,%r14d
	rorxl	$2,%ecx,%r13d
	leal	(%r9,%rbx,1),%r9d
	andl	%r15d,%edi
	xorl	%r12d,%r14d
	xorl	%edx,%edi
	xorl	%r13d,%r14d
	leal	(%rbx,%rdi,1),%ebx
	movl	%r10d,%r12d
	addl	44+16(%rbp),%eax
	andl	%r9d,%r12d
	rorxl	$25,%r9d,%r13d
	rorxl	$11,%r9d,%edi
	leal	(%rbx,%r14,1),%ebx
	leal	(%rax,%r12,1),%eax
	andnl	%r11d,%r9d,%r12d
	xorl	%edi,%r13d
	rorxl	$6,%r9d,%r14d
	leal	(%rax,%r12,1),%eax
	xorl	%r14d,%r13d
	movl	%ebx,%edi
	rorxl	$22,%ebx,%r12d
	leal	(%rax,%r13,1),%eax
	xorl	%ecx,%edi
	rorxl	$13,%ebx,%r14d
	rorxl	$2,%ebx,%r13d
	leal	(%r8,%rax,1),%r8d
	andl	%edi,%r15d
	xorl	%r12d,%r14d
	xorl	%ecx,%r15d
	xorl	%r13d,%r14d
	leal	(%rax,%r15,1),%eax
	movl	%r9d,%r12d
	leaq	-64(%rbp),%rbp
	cmpq	%rsp,%rbp
	jae	.Lower_avx2

	movq	512(%rsp),%rdi
	addl	%r14d,%eax

	leaq	448(%rsp),%rsp

.cfi_escape	0x0f,0x06,0x77,0xd8,0x00,0x06,0x23,0x08

	addl	0(%rdi),%eax
	addl	4(%rdi),%ebx
	addl	8(%rdi),%ecx
	addl	12(%rdi),%edx
	addl	16(%rdi),%r8d
	addl	20(%rdi),%r9d
	leaq	128(%rsi),%rsi
	addl	24(%rdi),%r10d
	movq	%rsi,%r12
	addl	28(%rdi),%r11d
	cmpq	64+16(%rsp),%rsi

	movl	%eax,0(%rdi)
	cmoveq	%rsp,%r12
	movl	%ebx,4(%rdi)
	movl	%ecx,8(%rdi)
	movl	%edx,12(%rdi)
	movl	%r8d,16(%rdi)
	movl	%r9d,20(%rdi)
	movl	%r10d,24(%rdi)
	movl	%r11d,28(%rdi)

	jbe	.Loop_avx2
	leaq	(%rsp),%rbp


.cfi_escape	0x0f,0x06,0x76,0xd8,0x00,0x06,0x23,0x08

.Ldone_avx2:
	movq	88(%rbp),%rsi
.cfi_def_cfa	%rsi,8
	vzeroupper
	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue_avx2:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha256_block_data_order_avx2,.-sha256_block_data_order_avx2
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                                                                                                                                                                                                                                                            node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/crypto/sha/sha512-x86_64.s      0000664 0000000 0000000 00000275246 14746647661 0031032 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	


.globl	sha512_block_data_order
.type	sha512_block_data_order,@function
.align	16
sha512_block_data_order:
.cfi_startproc	
	leaq	OPENSSL_ia32cap_P(%rip),%r11
	movl	0(%r11),%r9d
	movl	4(%r11),%r10d
	movl	8(%r11),%r11d
	testl	$2048,%r10d
	jnz	.Lxop_shortcut
	andl	$296,%r11d
	cmpl	$296,%r11d
	je	.Lavx2_shortcut
	andl	$1073741824,%r9d
	andl	$268435968,%r10d
	orl	%r9d,%r10d
	cmpl	$1342177792,%r10d
	je	.Lavx_shortcut
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
	shlq	$4,%rdx
	subq	$128+32,%rsp
	leaq	(%rsi,%rdx,8),%rdx
	andq	$-64,%rsp
	movq	%rdi,128+0(%rsp)
	movq	%rsi,128+8(%rsp)
	movq	%rdx,128+16(%rsp)
	movq	%rax,152(%rsp)
.cfi_escape	0x0f,0x06,0x77,0x98,0x01,0x06,0x23,0x08
.Lprologue:

	movq	0(%rdi),%rax
	movq	8(%rdi),%rbx
	movq	16(%rdi),%rcx
	movq	24(%rdi),%rdx
	movq	32(%rdi),%r8
	movq	40(%rdi),%r9
	movq	48(%rdi),%r10
	movq	56(%rdi),%r11
	jmp	.Lloop

.align	16
.Lloop:
	movq	%rbx,%rdi
	leaq	K512(%rip),%rbp
	xorq	%rcx,%rdi
	movq	0(%rsi),%r12
	movq	%r8,%r13
	movq	%rax,%r14
	bswapq	%r12
	rorq	$23,%r13
	movq	%r9,%r15

	xorq	%r8,%r13
	rorq	$5,%r14
	xorq	%r10,%r15

	movq	%r12,0(%rsp)
	xorq	%rax,%r14
	andq	%r8,%r15

	rorq	$4,%r13
	addq	%r11,%r12
	xorq	%r10,%r15

	rorq	$6,%r14
	xorq	%r8,%r13
	addq	%r15,%r12

	movq	%rax,%r15
	addq	(%rbp),%r12
	xorq	%rax,%r14

	xorq	%rbx,%r15
	rorq	$14,%r13
	movq	%rbx,%r11

	andq	%r15,%rdi
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%rdi,%r11
	addq	%r12,%rdx
	addq	%r12,%r11

	leaq	8(%rbp),%rbp
	addq	%r14,%r11
	movq	8(%rsi),%r12
	movq	%rdx,%r13
	movq	%r11,%r14
	bswapq	%r12
	rorq	$23,%r13
	movq	%r8,%rdi

	xorq	%rdx,%r13
	rorq	$5,%r14
	xorq	%r9,%rdi

	movq	%r12,8(%rsp)
	xorq	%r11,%r14
	andq	%rdx,%rdi

	rorq	$4,%r13
	addq	%r10,%r12
	xorq	%r9,%rdi

	rorq	$6,%r14
	xorq	%rdx,%r13
	addq	%rdi,%r12

	movq	%r11,%rdi
	addq	(%rbp),%r12
	xorq	%r11,%r14

	xorq	%rax,%rdi
	rorq	$14,%r13
	movq	%rax,%r10

	andq	%rdi,%r15
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%r15,%r10
	addq	%r12,%rcx
	addq	%r12,%r10

	leaq	24(%rbp),%rbp
	addq	%r14,%r10
	movq	16(%rsi),%r12
	movq	%rcx,%r13
	movq	%r10,%r14
	bswapq	%r12
	rorq	$23,%r13
	movq	%rdx,%r15

	xorq	%rcx,%r13
	rorq	$5,%r14
	xorq	%r8,%r15

	movq	%r12,16(%rsp)
	xorq	%r10,%r14
	andq	%rcx,%r15

	rorq	$4,%r13
	addq	%r9,%r12
	xorq	%r8,%r15

	rorq	$6,%r14
	xorq	%rcx,%r13
	addq	%r15,%r12

	movq	%r10,%r15
	addq	(%rbp),%r12
	xorq	%r10,%r14

	xorq	%r11,%r15
	rorq	$14,%r13
	movq	%r11,%r9

	andq	%r15,%rdi
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%rdi,%r9
	addq	%r12,%rbx
	addq	%r12,%r9

	leaq	8(%rbp),%rbp
	addq	%r14,%r9
	movq	24(%rsi),%r12
	movq	%rbx,%r13
	movq	%r9,%r14
	bswapq	%r12
	rorq	$23,%r13
	movq	%rcx,%rdi

	xorq	%rbx,%r13
	rorq	$5,%r14
	xorq	%rdx,%rdi

	movq	%r12,24(%rsp)
	xorq	%r9,%r14
	andq	%rbx,%rdi

	rorq	$4,%r13
	addq	%r8,%r12
	xorq	%rdx,%rdi

	rorq	$6,%r14
	xorq	%rbx,%r13
	addq	%rdi,%r12

	movq	%r9,%rdi
	addq	(%rbp),%r12
	xorq	%r9,%r14

	xorq	%r10,%rdi
	rorq	$14,%r13
	movq	%r10,%r8

	andq	%rdi,%r15
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%r15,%r8
	addq	%r12,%rax
	addq	%r12,%r8

	leaq	24(%rbp),%rbp
	addq	%r14,%r8
	movq	32(%rsi),%r12
	movq	%rax,%r13
	movq	%r8,%r14
	bswapq	%r12
	rorq	$23,%r13
	movq	%rbx,%r15

	xorq	%rax,%r13
	rorq	$5,%r14
	xorq	%rcx,%r15

	movq	%r12,32(%rsp)
	xorq	%r8,%r14
	andq	%rax,%r15

	rorq	$4,%r13
	addq	%rdx,%r12
	xorq	%rcx,%r15

	rorq	$6,%r14
	xorq	%rax,%r13
	addq	%r15,%r12

	movq	%r8,%r15
	addq	(%rbp),%r12
	xorq	%r8,%r14

	xorq	%r9,%r15
	rorq	$14,%r13
	movq	%r9,%rdx

	andq	%r15,%rdi
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%rdi,%rdx
	addq	%r12,%r11
	addq	%r12,%rdx

	leaq	8(%rbp),%rbp
	addq	%r14,%rdx
	movq	40(%rsi),%r12
	movq	%r11,%r13
	movq	%rdx,%r14
	bswapq	%r12
	rorq	$23,%r13
	movq	%rax,%rdi

	xorq	%r11,%r13
	rorq	$5,%r14
	xorq	%rbx,%rdi

	movq	%r12,40(%rsp)
	xorq	%rdx,%r14
	andq	%r11,%rdi

	rorq	$4,%r13
	addq	%rcx,%r12
	xorq	%rbx,%rdi

	rorq	$6,%r14
	xorq	%r11,%r13
	addq	%rdi,%r12

	movq	%rdx,%rdi
	addq	(%rbp),%r12
	xorq	%rdx,%r14

	xorq	%r8,%rdi
	rorq	$14,%r13
	movq	%r8,%rcx

	andq	%rdi,%r15
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%r15,%rcx
	addq	%r12,%r10
	addq	%r12,%rcx

	leaq	24(%rbp),%rbp
	addq	%r14,%rcx
	movq	48(%rsi),%r12
	movq	%r10,%r13
	movq	%rcx,%r14
	bswapq	%r12
	rorq	$23,%r13
	movq	%r11,%r15

	xorq	%r10,%r13
	rorq	$5,%r14
	xorq	%rax,%r15

	movq	%r12,48(%rsp)
	xorq	%rcx,%r14
	andq	%r10,%r15

	rorq	$4,%r13
	addq	%rbx,%r12
	xorq	%rax,%r15

	rorq	$6,%r14
	xorq	%r10,%r13
	addq	%r15,%r12

	movq	%rcx,%r15
	addq	(%rbp),%r12
	xorq	%rcx,%r14

	xorq	%rdx,%r15
	rorq	$14,%r13
	movq	%rdx,%rbx

	andq	%r15,%rdi
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%rdi,%rbx
	addq	%r12,%r9
	addq	%r12,%rbx

	leaq	8(%rbp),%rbp
	addq	%r14,%rbx
	movq	56(%rsi),%r12
	movq	%r9,%r13
	movq	%rbx,%r14
	bswapq	%r12
	rorq	$23,%r13
	movq	%r10,%rdi

	xorq	%r9,%r13
	rorq	$5,%r14
	xorq	%r11,%rdi

	movq	%r12,56(%rsp)
	xorq	%rbx,%r14
	andq	%r9,%rdi

	rorq	$4,%r13
	addq	%rax,%r12
	xorq	%r11,%rdi

	rorq	$6,%r14
	xorq	%r9,%r13
	addq	%rdi,%r12

	movq	%rbx,%rdi
	addq	(%rbp),%r12
	xorq	%rbx,%r14

	xorq	%rcx,%rdi
	rorq	$14,%r13
	movq	%rcx,%rax

	andq	%rdi,%r15
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%r15,%rax
	addq	%r12,%r8
	addq	%r12,%rax

	leaq	24(%rbp),%rbp
	addq	%r14,%rax
	movq	64(%rsi),%r12
	movq	%r8,%r13
	movq	%rax,%r14
	bswapq	%r12
	rorq	$23,%r13
	movq	%r9,%r15

	xorq	%r8,%r13
	rorq	$5,%r14
	xorq	%r10,%r15

	movq	%r12,64(%rsp)
	xorq	%rax,%r14
	andq	%r8,%r15

	rorq	$4,%r13
	addq	%r11,%r12
	xorq	%r10,%r15

	rorq	$6,%r14
	xorq	%r8,%r13
	addq	%r15,%r12

	movq	%rax,%r15
	addq	(%rbp),%r12
	xorq	%rax,%r14

	xorq	%rbx,%r15
	rorq	$14,%r13
	movq	%rbx,%r11

	andq	%r15,%rdi
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%rdi,%r11
	addq	%r12,%rdx
	addq	%r12,%r11

	leaq	8(%rbp),%rbp
	addq	%r14,%r11
	movq	72(%rsi),%r12
	movq	%rdx,%r13
	movq	%r11,%r14
	bswapq	%r12
	rorq	$23,%r13
	movq	%r8,%rdi

	xorq	%rdx,%r13
	rorq	$5,%r14
	xorq	%r9,%rdi

	movq	%r12,72(%rsp)
	xorq	%r11,%r14
	andq	%rdx,%rdi

	rorq	$4,%r13
	addq	%r10,%r12
	xorq	%r9,%rdi

	rorq	$6,%r14
	xorq	%rdx,%r13
	addq	%rdi,%r12

	movq	%r11,%rdi
	addq	(%rbp),%r12
	xorq	%r11,%r14

	xorq	%rax,%rdi
	rorq	$14,%r13
	movq	%rax,%r10

	andq	%rdi,%r15
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%r15,%r10
	addq	%r12,%rcx
	addq	%r12,%r10

	leaq	24(%rbp),%rbp
	addq	%r14,%r10
	movq	80(%rsi),%r12
	movq	%rcx,%r13
	movq	%r10,%r14
	bswapq	%r12
	rorq	$23,%r13
	movq	%rdx,%r15

	xorq	%rcx,%r13
	rorq	$5,%r14
	xorq	%r8,%r15

	movq	%r12,80(%rsp)
	xorq	%r10,%r14
	andq	%rcx,%r15

	rorq	$4,%r13
	addq	%r9,%r12
	xorq	%r8,%r15

	rorq	$6,%r14
	xorq	%rcx,%r13
	addq	%r15,%r12

	movq	%r10,%r15
	addq	(%rbp),%r12
	xorq	%r10,%r14

	xorq	%r11,%r15
	rorq	$14,%r13
	movq	%r11,%r9

	andq	%r15,%rdi
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%rdi,%r9
	addq	%r12,%rbx
	addq	%r12,%r9

	leaq	8(%rbp),%rbp
	addq	%r14,%r9
	movq	88(%rsi),%r12
	movq	%rbx,%r13
	movq	%r9,%r14
	bswapq	%r12
	rorq	$23,%r13
	movq	%rcx,%rdi

	xorq	%rbx,%r13
	rorq	$5,%r14
	xorq	%rdx,%rdi

	movq	%r12,88(%rsp)
	xorq	%r9,%r14
	andq	%rbx,%rdi

	rorq	$4,%r13
	addq	%r8,%r12
	xorq	%rdx,%rdi

	rorq	$6,%r14
	xorq	%rbx,%r13
	addq	%rdi,%r12

	movq	%r9,%rdi
	addq	(%rbp),%r12
	xorq	%r9,%r14

	xorq	%r10,%rdi
	rorq	$14,%r13
	movq	%r10,%r8

	andq	%rdi,%r15
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%r15,%r8
	addq	%r12,%rax
	addq	%r12,%r8

	leaq	24(%rbp),%rbp
	addq	%r14,%r8
	movq	96(%rsi),%r12
	movq	%rax,%r13
	movq	%r8,%r14
	bswapq	%r12
	rorq	$23,%r13
	movq	%rbx,%r15

	xorq	%rax,%r13
	rorq	$5,%r14
	xorq	%rcx,%r15

	movq	%r12,96(%rsp)
	xorq	%r8,%r14
	andq	%rax,%r15

	rorq	$4,%r13
	addq	%rdx,%r12
	xorq	%rcx,%r15

	rorq	$6,%r14
	xorq	%rax,%r13
	addq	%r15,%r12

	movq	%r8,%r15
	addq	(%rbp),%r12
	xorq	%r8,%r14

	xorq	%r9,%r15
	rorq	$14,%r13
	movq	%r9,%rdx

	andq	%r15,%rdi
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%rdi,%rdx
	addq	%r12,%r11
	addq	%r12,%rdx

	leaq	8(%rbp),%rbp
	addq	%r14,%rdx
	movq	104(%rsi),%r12
	movq	%r11,%r13
	movq	%rdx,%r14
	bswapq	%r12
	rorq	$23,%r13
	movq	%rax,%rdi

	xorq	%r11,%r13
	rorq	$5,%r14
	xorq	%rbx,%rdi

	movq	%r12,104(%rsp)
	xorq	%rdx,%r14
	andq	%r11,%rdi

	rorq	$4,%r13
	addq	%rcx,%r12
	xorq	%rbx,%rdi

	rorq	$6,%r14
	xorq	%r11,%r13
	addq	%rdi,%r12

	movq	%rdx,%rdi
	addq	(%rbp),%r12
	xorq	%rdx,%r14

	xorq	%r8,%rdi
	rorq	$14,%r13
	movq	%r8,%rcx

	andq	%rdi,%r15
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%r15,%rcx
	addq	%r12,%r10
	addq	%r12,%rcx

	leaq	24(%rbp),%rbp
	addq	%r14,%rcx
	movq	112(%rsi),%r12
	movq	%r10,%r13
	movq	%rcx,%r14
	bswapq	%r12
	rorq	$23,%r13
	movq	%r11,%r15

	xorq	%r10,%r13
	rorq	$5,%r14
	xorq	%rax,%r15

	movq	%r12,112(%rsp)
	xorq	%rcx,%r14
	andq	%r10,%r15

	rorq	$4,%r13
	addq	%rbx,%r12
	xorq	%rax,%r15

	rorq	$6,%r14
	xorq	%r10,%r13
	addq	%r15,%r12

	movq	%rcx,%r15
	addq	(%rbp),%r12
	xorq	%rcx,%r14

	xorq	%rdx,%r15
	rorq	$14,%r13
	movq	%rdx,%rbx

	andq	%r15,%rdi
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%rdi,%rbx
	addq	%r12,%r9
	addq	%r12,%rbx

	leaq	8(%rbp),%rbp
	addq	%r14,%rbx
	movq	120(%rsi),%r12
	movq	%r9,%r13
	movq	%rbx,%r14
	bswapq	%r12
	rorq	$23,%r13
	movq	%r10,%rdi

	xorq	%r9,%r13
	rorq	$5,%r14
	xorq	%r11,%rdi

	movq	%r12,120(%rsp)
	xorq	%rbx,%r14
	andq	%r9,%rdi

	rorq	$4,%r13
	addq	%rax,%r12
	xorq	%r11,%rdi

	rorq	$6,%r14
	xorq	%r9,%r13
	addq	%rdi,%r12

	movq	%rbx,%rdi
	addq	(%rbp),%r12
	xorq	%rbx,%r14

	xorq	%rcx,%rdi
	rorq	$14,%r13
	movq	%rcx,%rax

	andq	%rdi,%r15
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%r15,%rax
	addq	%r12,%r8
	addq	%r12,%rax

	leaq	24(%rbp),%rbp
	jmp	.Lrounds_16_xx
.align	16
.Lrounds_16_xx:
	movq	8(%rsp),%r13
	movq	112(%rsp),%r15

	movq	%r13,%r12
	rorq	$7,%r13
	addq	%r14,%rax
	movq	%r15,%r14
	rorq	$42,%r15

	xorq	%r12,%r13
	shrq	$7,%r12
	rorq	$1,%r13
	xorq	%r14,%r15
	shrq	$6,%r14

	rorq	$19,%r15
	xorq	%r13,%r12
	xorq	%r14,%r15
	addq	72(%rsp),%r12

	addq	0(%rsp),%r12
	movq	%r8,%r13
	addq	%r15,%r12
	movq	%rax,%r14
	rorq	$23,%r13
	movq	%r9,%r15

	xorq	%r8,%r13
	rorq	$5,%r14
	xorq	%r10,%r15

	movq	%r12,0(%rsp)
	xorq	%rax,%r14
	andq	%r8,%r15

	rorq	$4,%r13
	addq	%r11,%r12
	xorq	%r10,%r15

	rorq	$6,%r14
	xorq	%r8,%r13
	addq	%r15,%r12

	movq	%rax,%r15
	addq	(%rbp),%r12
	xorq	%rax,%r14

	xorq	%rbx,%r15
	rorq	$14,%r13
	movq	%rbx,%r11

	andq	%r15,%rdi
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%rdi,%r11
	addq	%r12,%rdx
	addq	%r12,%r11

	leaq	8(%rbp),%rbp
	movq	16(%rsp),%r13
	movq	120(%rsp),%rdi

	movq	%r13,%r12
	rorq	$7,%r13
	addq	%r14,%r11
	movq	%rdi,%r14
	rorq	$42,%rdi

	xorq	%r12,%r13
	shrq	$7,%r12
	rorq	$1,%r13
	xorq	%r14,%rdi
	shrq	$6,%r14

	rorq	$19,%rdi
	xorq	%r13,%r12
	xorq	%r14,%rdi
	addq	80(%rsp),%r12

	addq	8(%rsp),%r12
	movq	%rdx,%r13
	addq	%rdi,%r12
	movq	%r11,%r14
	rorq	$23,%r13
	movq	%r8,%rdi

	xorq	%rdx,%r13
	rorq	$5,%r14
	xorq	%r9,%rdi

	movq	%r12,8(%rsp)
	xorq	%r11,%r14
	andq	%rdx,%rdi

	rorq	$4,%r13
	addq	%r10,%r12
	xorq	%r9,%rdi

	rorq	$6,%r14
	xorq	%rdx,%r13
	addq	%rdi,%r12

	movq	%r11,%rdi
	addq	(%rbp),%r12
	xorq	%r11,%r14

	xorq	%rax,%rdi
	rorq	$14,%r13
	movq	%rax,%r10

	andq	%rdi,%r15
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%r15,%r10
	addq	%r12,%rcx
	addq	%r12,%r10

	leaq	24(%rbp),%rbp
	movq	24(%rsp),%r13
	movq	0(%rsp),%r15

	movq	%r13,%r12
	rorq	$7,%r13
	addq	%r14,%r10
	movq	%r15,%r14
	rorq	$42,%r15

	xorq	%r12,%r13
	shrq	$7,%r12
	rorq	$1,%r13
	xorq	%r14,%r15
	shrq	$6,%r14

	rorq	$19,%r15
	xorq	%r13,%r12
	xorq	%r14,%r15
	addq	88(%rsp),%r12

	addq	16(%rsp),%r12
	movq	%rcx,%r13
	addq	%r15,%r12
	movq	%r10,%r14
	rorq	$23,%r13
	movq	%rdx,%r15

	xorq	%rcx,%r13
	rorq	$5,%r14
	xorq	%r8,%r15

	movq	%r12,16(%rsp)
	xorq	%r10,%r14
	andq	%rcx,%r15

	rorq	$4,%r13
	addq	%r9,%r12
	xorq	%r8,%r15

	rorq	$6,%r14
	xorq	%rcx,%r13
	addq	%r15,%r12

	movq	%r10,%r15
	addq	(%rbp),%r12
	xorq	%r10,%r14

	xorq	%r11,%r15
	rorq	$14,%r13
	movq	%r11,%r9

	andq	%r15,%rdi
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%rdi,%r9
	addq	%r12,%rbx
	addq	%r12,%r9

	leaq	8(%rbp),%rbp
	movq	32(%rsp),%r13
	movq	8(%rsp),%rdi

	movq	%r13,%r12
	rorq	$7,%r13
	addq	%r14,%r9
	movq	%rdi,%r14
	rorq	$42,%rdi

	xorq	%r12,%r13
	shrq	$7,%r12
	rorq	$1,%r13
	xorq	%r14,%rdi
	shrq	$6,%r14

	rorq	$19,%rdi
	xorq	%r13,%r12
	xorq	%r14,%rdi
	addq	96(%rsp),%r12

	addq	24(%rsp),%r12
	movq	%rbx,%r13
	addq	%rdi,%r12
	movq	%r9,%r14
	rorq	$23,%r13
	movq	%rcx,%rdi

	xorq	%rbx,%r13
	rorq	$5,%r14
	xorq	%rdx,%rdi

	movq	%r12,24(%rsp)
	xorq	%r9,%r14
	andq	%rbx,%rdi

	rorq	$4,%r13
	addq	%r8,%r12
	xorq	%rdx,%rdi

	rorq	$6,%r14
	xorq	%rbx,%r13
	addq	%rdi,%r12

	movq	%r9,%rdi
	addq	(%rbp),%r12
	xorq	%r9,%r14

	xorq	%r10,%rdi
	rorq	$14,%r13
	movq	%r10,%r8

	andq	%rdi,%r15
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%r15,%r8
	addq	%r12,%rax
	addq	%r12,%r8

	leaq	24(%rbp),%rbp
	movq	40(%rsp),%r13
	movq	16(%rsp),%r15

	movq	%r13,%r12
	rorq	$7,%r13
	addq	%r14,%r8
	movq	%r15,%r14
	rorq	$42,%r15

	xorq	%r12,%r13
	shrq	$7,%r12
	rorq	$1,%r13
	xorq	%r14,%r15
	shrq	$6,%r14

	rorq	$19,%r15
	xorq	%r13,%r12
	xorq	%r14,%r15
	addq	104(%rsp),%r12

	addq	32(%rsp),%r12
	movq	%rax,%r13
	addq	%r15,%r12
	movq	%r8,%r14
	rorq	$23,%r13
	movq	%rbx,%r15

	xorq	%rax,%r13
	rorq	$5,%r14
	xorq	%rcx,%r15

	movq	%r12,32(%rsp)
	xorq	%r8,%r14
	andq	%rax,%r15

	rorq	$4,%r13
	addq	%rdx,%r12
	xorq	%rcx,%r15

	rorq	$6,%r14
	xorq	%rax,%r13
	addq	%r15,%r12

	movq	%r8,%r15
	addq	(%rbp),%r12
	xorq	%r8,%r14

	xorq	%r9,%r15
	rorq	$14,%r13
	movq	%r9,%rdx

	andq	%r15,%rdi
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%rdi,%rdx
	addq	%r12,%r11
	addq	%r12,%rdx

	leaq	8(%rbp),%rbp
	movq	48(%rsp),%r13
	movq	24(%rsp),%rdi

	movq	%r13,%r12
	rorq	$7,%r13
	addq	%r14,%rdx
	movq	%rdi,%r14
	rorq	$42,%rdi

	xorq	%r12,%r13
	shrq	$7,%r12
	rorq	$1,%r13
	xorq	%r14,%rdi
	shrq	$6,%r14

	rorq	$19,%rdi
	xorq	%r13,%r12
	xorq	%r14,%rdi
	addq	112(%rsp),%r12

	addq	40(%rsp),%r12
	movq	%r11,%r13
	addq	%rdi,%r12
	movq	%rdx,%r14
	rorq	$23,%r13
	movq	%rax,%rdi

	xorq	%r11,%r13
	rorq	$5,%r14
	xorq	%rbx,%rdi

	movq	%r12,40(%rsp)
	xorq	%rdx,%r14
	andq	%r11,%rdi

	rorq	$4,%r13
	addq	%rcx,%r12
	xorq	%rbx,%rdi

	rorq	$6,%r14
	xorq	%r11,%r13
	addq	%rdi,%r12

	movq	%rdx,%rdi
	addq	(%rbp),%r12
	xorq	%rdx,%r14

	xorq	%r8,%rdi
	rorq	$14,%r13
	movq	%r8,%rcx

	andq	%rdi,%r15
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%r15,%rcx
	addq	%r12,%r10
	addq	%r12,%rcx

	leaq	24(%rbp),%rbp
	movq	56(%rsp),%r13
	movq	32(%rsp),%r15

	movq	%r13,%r12
	rorq	$7,%r13
	addq	%r14,%rcx
	movq	%r15,%r14
	rorq	$42,%r15

	xorq	%r12,%r13
	shrq	$7,%r12
	rorq	$1,%r13
	xorq	%r14,%r15
	shrq	$6,%r14

	rorq	$19,%r15
	xorq	%r13,%r12
	xorq	%r14,%r15
	addq	120(%rsp),%r12

	addq	48(%rsp),%r12
	movq	%r10,%r13
	addq	%r15,%r12
	movq	%rcx,%r14
	rorq	$23,%r13
	movq	%r11,%r15

	xorq	%r10,%r13
	rorq	$5,%r14
	xorq	%rax,%r15

	movq	%r12,48(%rsp)
	xorq	%rcx,%r14
	andq	%r10,%r15

	rorq	$4,%r13
	addq	%rbx,%r12
	xorq	%rax,%r15

	rorq	$6,%r14
	xorq	%r10,%r13
	addq	%r15,%r12

	movq	%rcx,%r15
	addq	(%rbp),%r12
	xorq	%rcx,%r14

	xorq	%rdx,%r15
	rorq	$14,%r13
	movq	%rdx,%rbx

	andq	%r15,%rdi
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%rdi,%rbx
	addq	%r12,%r9
	addq	%r12,%rbx

	leaq	8(%rbp),%rbp
	movq	64(%rsp),%r13
	movq	40(%rsp),%rdi

	movq	%r13,%r12
	rorq	$7,%r13
	addq	%r14,%rbx
	movq	%rdi,%r14
	rorq	$42,%rdi

	xorq	%r12,%r13
	shrq	$7,%r12
	rorq	$1,%r13
	xorq	%r14,%rdi
	shrq	$6,%r14

	rorq	$19,%rdi
	xorq	%r13,%r12
	xorq	%r14,%rdi
	addq	0(%rsp),%r12

	addq	56(%rsp),%r12
	movq	%r9,%r13
	addq	%rdi,%r12
	movq	%rbx,%r14
	rorq	$23,%r13
	movq	%r10,%rdi

	xorq	%r9,%r13
	rorq	$5,%r14
	xorq	%r11,%rdi

	movq	%r12,56(%rsp)
	xorq	%rbx,%r14
	andq	%r9,%rdi

	rorq	$4,%r13
	addq	%rax,%r12
	xorq	%r11,%rdi

	rorq	$6,%r14
	xorq	%r9,%r13
	addq	%rdi,%r12

	movq	%rbx,%rdi
	addq	(%rbp),%r12
	xorq	%rbx,%r14

	xorq	%rcx,%rdi
	rorq	$14,%r13
	movq	%rcx,%rax

	andq	%rdi,%r15
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%r15,%rax
	addq	%r12,%r8
	addq	%r12,%rax

	leaq	24(%rbp),%rbp
	movq	72(%rsp),%r13
	movq	48(%rsp),%r15

	movq	%r13,%r12
	rorq	$7,%r13
	addq	%r14,%rax
	movq	%r15,%r14
	rorq	$42,%r15

	xorq	%r12,%r13
	shrq	$7,%r12
	rorq	$1,%r13
	xorq	%r14,%r15
	shrq	$6,%r14

	rorq	$19,%r15
	xorq	%r13,%r12
	xorq	%r14,%r15
	addq	8(%rsp),%r12

	addq	64(%rsp),%r12
	movq	%r8,%r13
	addq	%r15,%r12
	movq	%rax,%r14
	rorq	$23,%r13
	movq	%r9,%r15

	xorq	%r8,%r13
	rorq	$5,%r14
	xorq	%r10,%r15

	movq	%r12,64(%rsp)
	xorq	%rax,%r14
	andq	%r8,%r15

	rorq	$4,%r13
	addq	%r11,%r12
	xorq	%r10,%r15

	rorq	$6,%r14
	xorq	%r8,%r13
	addq	%r15,%r12

	movq	%rax,%r15
	addq	(%rbp),%r12
	xorq	%rax,%r14

	xorq	%rbx,%r15
	rorq	$14,%r13
	movq	%rbx,%r11

	andq	%r15,%rdi
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%rdi,%r11
	addq	%r12,%rdx
	addq	%r12,%r11

	leaq	8(%rbp),%rbp
	movq	80(%rsp),%r13
	movq	56(%rsp),%rdi

	movq	%r13,%r12
	rorq	$7,%r13
	addq	%r14,%r11
	movq	%rdi,%r14
	rorq	$42,%rdi

	xorq	%r12,%r13
	shrq	$7,%r12
	rorq	$1,%r13
	xorq	%r14,%rdi
	shrq	$6,%r14

	rorq	$19,%rdi
	xorq	%r13,%r12
	xorq	%r14,%rdi
	addq	16(%rsp),%r12

	addq	72(%rsp),%r12
	movq	%rdx,%r13
	addq	%rdi,%r12
	movq	%r11,%r14
	rorq	$23,%r13
	movq	%r8,%rdi

	xorq	%rdx,%r13
	rorq	$5,%r14
	xorq	%r9,%rdi

	movq	%r12,72(%rsp)
	xorq	%r11,%r14
	andq	%rdx,%rdi

	rorq	$4,%r13
	addq	%r10,%r12
	xorq	%r9,%rdi

	rorq	$6,%r14
	xorq	%rdx,%r13
	addq	%rdi,%r12

	movq	%r11,%rdi
	addq	(%rbp),%r12
	xorq	%r11,%r14

	xorq	%rax,%rdi
	rorq	$14,%r13
	movq	%rax,%r10

	andq	%rdi,%r15
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%r15,%r10
	addq	%r12,%rcx
	addq	%r12,%r10

	leaq	24(%rbp),%rbp
	movq	88(%rsp),%r13
	movq	64(%rsp),%r15

	movq	%r13,%r12
	rorq	$7,%r13
	addq	%r14,%r10
	movq	%r15,%r14
	rorq	$42,%r15

	xorq	%r12,%r13
	shrq	$7,%r12
	rorq	$1,%r13
	xorq	%r14,%r15
	shrq	$6,%r14

	rorq	$19,%r15
	xorq	%r13,%r12
	xorq	%r14,%r15
	addq	24(%rsp),%r12

	addq	80(%rsp),%r12
	movq	%rcx,%r13
	addq	%r15,%r12
	movq	%r10,%r14
	rorq	$23,%r13
	movq	%rdx,%r15

	xorq	%rcx,%r13
	rorq	$5,%r14
	xorq	%r8,%r15

	movq	%r12,80(%rsp)
	xorq	%r10,%r14
	andq	%rcx,%r15

	rorq	$4,%r13
	addq	%r9,%r12
	xorq	%r8,%r15

	rorq	$6,%r14
	xorq	%rcx,%r13
	addq	%r15,%r12

	movq	%r10,%r15
	addq	(%rbp),%r12
	xorq	%r10,%r14

	xorq	%r11,%r15
	rorq	$14,%r13
	movq	%r11,%r9

	andq	%r15,%rdi
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%rdi,%r9
	addq	%r12,%rbx
	addq	%r12,%r9

	leaq	8(%rbp),%rbp
	movq	96(%rsp),%r13
	movq	72(%rsp),%rdi

	movq	%r13,%r12
	rorq	$7,%r13
	addq	%r14,%r9
	movq	%rdi,%r14
	rorq	$42,%rdi

	xorq	%r12,%r13
	shrq	$7,%r12
	rorq	$1,%r13
	xorq	%r14,%rdi
	shrq	$6,%r14

	rorq	$19,%rdi
	xorq	%r13,%r12
	xorq	%r14,%rdi
	addq	32(%rsp),%r12

	addq	88(%rsp),%r12
	movq	%rbx,%r13
	addq	%rdi,%r12
	movq	%r9,%r14
	rorq	$23,%r13
	movq	%rcx,%rdi

	xorq	%rbx,%r13
	rorq	$5,%r14
	xorq	%rdx,%rdi

	movq	%r12,88(%rsp)
	xorq	%r9,%r14
	andq	%rbx,%rdi

	rorq	$4,%r13
	addq	%r8,%r12
	xorq	%rdx,%rdi

	rorq	$6,%r14
	xorq	%rbx,%r13
	addq	%rdi,%r12

	movq	%r9,%rdi
	addq	(%rbp),%r12
	xorq	%r9,%r14

	xorq	%r10,%rdi
	rorq	$14,%r13
	movq	%r10,%r8

	andq	%rdi,%r15
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%r15,%r8
	addq	%r12,%rax
	addq	%r12,%r8

	leaq	24(%rbp),%rbp
	movq	104(%rsp),%r13
	movq	80(%rsp),%r15

	movq	%r13,%r12
	rorq	$7,%r13
	addq	%r14,%r8
	movq	%r15,%r14
	rorq	$42,%r15

	xorq	%r12,%r13
	shrq	$7,%r12
	rorq	$1,%r13
	xorq	%r14,%r15
	shrq	$6,%r14

	rorq	$19,%r15
	xorq	%r13,%r12
	xorq	%r14,%r15
	addq	40(%rsp),%r12

	addq	96(%rsp),%r12
	movq	%rax,%r13
	addq	%r15,%r12
	movq	%r8,%r14
	rorq	$23,%r13
	movq	%rbx,%r15

	xorq	%rax,%r13
	rorq	$5,%r14
	xorq	%rcx,%r15

	movq	%r12,96(%rsp)
	xorq	%r8,%r14
	andq	%rax,%r15

	rorq	$4,%r13
	addq	%rdx,%r12
	xorq	%rcx,%r15

	rorq	$6,%r14
	xorq	%rax,%r13
	addq	%r15,%r12

	movq	%r8,%r15
	addq	(%rbp),%r12
	xorq	%r8,%r14

	xorq	%r9,%r15
	rorq	$14,%r13
	movq	%r9,%rdx

	andq	%r15,%rdi
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%rdi,%rdx
	addq	%r12,%r11
	addq	%r12,%rdx

	leaq	8(%rbp),%rbp
	movq	112(%rsp),%r13
	movq	88(%rsp),%rdi

	movq	%r13,%r12
	rorq	$7,%r13
	addq	%r14,%rdx
	movq	%rdi,%r14
	rorq	$42,%rdi

	xorq	%r12,%r13
	shrq	$7,%r12
	rorq	$1,%r13
	xorq	%r14,%rdi
	shrq	$6,%r14

	rorq	$19,%rdi
	xorq	%r13,%r12
	xorq	%r14,%rdi
	addq	48(%rsp),%r12

	addq	104(%rsp),%r12
	movq	%r11,%r13
	addq	%rdi,%r12
	movq	%rdx,%r14
	rorq	$23,%r13
	movq	%rax,%rdi

	xorq	%r11,%r13
	rorq	$5,%r14
	xorq	%rbx,%rdi

	movq	%r12,104(%rsp)
	xorq	%rdx,%r14
	andq	%r11,%rdi

	rorq	$4,%r13
	addq	%rcx,%r12
	xorq	%rbx,%rdi

	rorq	$6,%r14
	xorq	%r11,%r13
	addq	%rdi,%r12

	movq	%rdx,%rdi
	addq	(%rbp),%r12
	xorq	%rdx,%r14

	xorq	%r8,%rdi
	rorq	$14,%r13
	movq	%r8,%rcx

	andq	%rdi,%r15
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%r15,%rcx
	addq	%r12,%r10
	addq	%r12,%rcx

	leaq	24(%rbp),%rbp
	movq	120(%rsp),%r13
	movq	96(%rsp),%r15

	movq	%r13,%r12
	rorq	$7,%r13
	addq	%r14,%rcx
	movq	%r15,%r14
	rorq	$42,%r15

	xorq	%r12,%r13
	shrq	$7,%r12
	rorq	$1,%r13
	xorq	%r14,%r15
	shrq	$6,%r14

	rorq	$19,%r15
	xorq	%r13,%r12
	xorq	%r14,%r15
	addq	56(%rsp),%r12

	addq	112(%rsp),%r12
	movq	%r10,%r13
	addq	%r15,%r12
	movq	%rcx,%r14
	rorq	$23,%r13
	movq	%r11,%r15

	xorq	%r10,%r13
	rorq	$5,%r14
	xorq	%rax,%r15

	movq	%r12,112(%rsp)
	xorq	%rcx,%r14
	andq	%r10,%r15

	rorq	$4,%r13
	addq	%rbx,%r12
	xorq	%rax,%r15

	rorq	$6,%r14
	xorq	%r10,%r13
	addq	%r15,%r12

	movq	%rcx,%r15
	addq	(%rbp),%r12
	xorq	%rcx,%r14

	xorq	%rdx,%r15
	rorq	$14,%r13
	movq	%rdx,%rbx

	andq	%r15,%rdi
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%rdi,%rbx
	addq	%r12,%r9
	addq	%r12,%rbx

	leaq	8(%rbp),%rbp
	movq	0(%rsp),%r13
	movq	104(%rsp),%rdi

	movq	%r13,%r12
	rorq	$7,%r13
	addq	%r14,%rbx
	movq	%rdi,%r14
	rorq	$42,%rdi

	xorq	%r12,%r13
	shrq	$7,%r12
	rorq	$1,%r13
	xorq	%r14,%rdi
	shrq	$6,%r14

	rorq	$19,%rdi
	xorq	%r13,%r12
	xorq	%r14,%rdi
	addq	64(%rsp),%r12

	addq	120(%rsp),%r12
	movq	%r9,%r13
	addq	%rdi,%r12
	movq	%rbx,%r14
	rorq	$23,%r13
	movq	%r10,%rdi

	xorq	%r9,%r13
	rorq	$5,%r14
	xorq	%r11,%rdi

	movq	%r12,120(%rsp)
	xorq	%rbx,%r14
	andq	%r9,%rdi

	rorq	$4,%r13
	addq	%rax,%r12
	xorq	%r11,%rdi

	rorq	$6,%r14
	xorq	%r9,%r13
	addq	%rdi,%r12

	movq	%rbx,%rdi
	addq	(%rbp),%r12
	xorq	%rbx,%r14

	xorq	%rcx,%rdi
	rorq	$14,%r13
	movq	%rcx,%rax

	andq	%rdi,%r15
	rorq	$28,%r14
	addq	%r13,%r12

	xorq	%r15,%rax
	addq	%r12,%r8
	addq	%r12,%rax

	leaq	24(%rbp),%rbp
	cmpb	$0,7(%rbp)
	jnz	.Lrounds_16_xx

	movq	128+0(%rsp),%rdi
	addq	%r14,%rax
	leaq	128(%rsi),%rsi

	addq	0(%rdi),%rax
	addq	8(%rdi),%rbx
	addq	16(%rdi),%rcx
	addq	24(%rdi),%rdx
	addq	32(%rdi),%r8
	addq	40(%rdi),%r9
	addq	48(%rdi),%r10
	addq	56(%rdi),%r11

	cmpq	128+16(%rsp),%rsi

	movq	%rax,0(%rdi)
	movq	%rbx,8(%rdi)
	movq	%rcx,16(%rdi)
	movq	%rdx,24(%rdi)
	movq	%r8,32(%rdi)
	movq	%r9,40(%rdi)
	movq	%r10,48(%rdi)
	movq	%r11,56(%rdi)
	jb	.Lloop

	movq	152(%rsp),%rsi
.cfi_def_cfa	%rsi,8
	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha512_block_data_order,.-sha512_block_data_order
.align	64
.type	K512,@object
K512:
.quad	0x428a2f98d728ae22,0x7137449123ef65cd
.quad	0x428a2f98d728ae22,0x7137449123ef65cd
.quad	0xb5c0fbcfec4d3b2f,0xe9b5dba58189dbbc
.quad	0xb5c0fbcfec4d3b2f,0xe9b5dba58189dbbc
.quad	0x3956c25bf348b538,0x59f111f1b605d019
.quad	0x3956c25bf348b538,0x59f111f1b605d019
.quad	0x923f82a4af194f9b,0xab1c5ed5da6d8118
.quad	0x923f82a4af194f9b,0xab1c5ed5da6d8118
.quad	0xd807aa98a3030242,0x12835b0145706fbe
.quad	0xd807aa98a3030242,0x12835b0145706fbe
.quad	0x243185be4ee4b28c,0x550c7dc3d5ffb4e2
.quad	0x243185be4ee4b28c,0x550c7dc3d5ffb4e2
.quad	0x72be5d74f27b896f,0x80deb1fe3b1696b1
.quad	0x72be5d74f27b896f,0x80deb1fe3b1696b1
.quad	0x9bdc06a725c71235,0xc19bf174cf692694
.quad	0x9bdc06a725c71235,0xc19bf174cf692694
.quad	0xe49b69c19ef14ad2,0xefbe4786384f25e3
.quad	0xe49b69c19ef14ad2,0xefbe4786384f25e3
.quad	0x0fc19dc68b8cd5b5,0x240ca1cc77ac9c65
.quad	0x0fc19dc68b8cd5b5,0x240ca1cc77ac9c65
.quad	0x2de92c6f592b0275,0x4a7484aa6ea6e483
.quad	0x2de92c6f592b0275,0x4a7484aa6ea6e483
.quad	0x5cb0a9dcbd41fbd4,0x76f988da831153b5
.quad	0x5cb0a9dcbd41fbd4,0x76f988da831153b5
.quad	0x983e5152ee66dfab,0xa831c66d2db43210
.quad	0x983e5152ee66dfab,0xa831c66d2db43210
.quad	0xb00327c898fb213f,0xbf597fc7beef0ee4
.quad	0xb00327c898fb213f,0xbf597fc7beef0ee4
.quad	0xc6e00bf33da88fc2,0xd5a79147930aa725
.quad	0xc6e00bf33da88fc2,0xd5a79147930aa725
.quad	0x06ca6351e003826f,0x142929670a0e6e70
.quad	0x06ca6351e003826f,0x142929670a0e6e70
.quad	0x27b70a8546d22ffc,0x2e1b21385c26c926
.quad	0x27b70a8546d22ffc,0x2e1b21385c26c926
.quad	0x4d2c6dfc5ac42aed,0x53380d139d95b3df
.quad	0x4d2c6dfc5ac42aed,0x53380d139d95b3df
.quad	0x650a73548baf63de,0x766a0abb3c77b2a8
.quad	0x650a73548baf63de,0x766a0abb3c77b2a8
.quad	0x81c2c92e47edaee6,0x92722c851482353b
.quad	0x81c2c92e47edaee6,0x92722c851482353b
.quad	0xa2bfe8a14cf10364,0xa81a664bbc423001
.quad	0xa2bfe8a14cf10364,0xa81a664bbc423001
.quad	0xc24b8b70d0f89791,0xc76c51a30654be30
.quad	0xc24b8b70d0f89791,0xc76c51a30654be30
.quad	0xd192e819d6ef5218,0xd69906245565a910
.quad	0xd192e819d6ef5218,0xd69906245565a910
.quad	0xf40e35855771202a,0x106aa07032bbd1b8
.quad	0xf40e35855771202a,0x106aa07032bbd1b8
.quad	0x19a4c116b8d2d0c8,0x1e376c085141ab53
.quad	0x19a4c116b8d2d0c8,0x1e376c085141ab53
.quad	0x2748774cdf8eeb99,0x34b0bcb5e19b48a8
.quad	0x2748774cdf8eeb99,0x34b0bcb5e19b48a8
.quad	0x391c0cb3c5c95a63,0x4ed8aa4ae3418acb
.quad	0x391c0cb3c5c95a63,0x4ed8aa4ae3418acb
.quad	0x5b9cca4f7763e373,0x682e6ff3d6b2b8a3
.quad	0x5b9cca4f7763e373,0x682e6ff3d6b2b8a3
.quad	0x748f82ee5defb2fc,0x78a5636f43172f60
.quad	0x748f82ee5defb2fc,0x78a5636f43172f60
.quad	0x84c87814a1f0ab72,0x8cc702081a6439ec
.quad	0x84c87814a1f0ab72,0x8cc702081a6439ec
.quad	0x90befffa23631e28,0xa4506cebde82bde9
.quad	0x90befffa23631e28,0xa4506cebde82bde9
.quad	0xbef9a3f7b2c67915,0xc67178f2e372532b
.quad	0xbef9a3f7b2c67915,0xc67178f2e372532b
.quad	0xca273eceea26619c,0xd186b8c721c0c207
.quad	0xca273eceea26619c,0xd186b8c721c0c207
.quad	0xeada7dd6cde0eb1e,0xf57d4f7fee6ed178
.quad	0xeada7dd6cde0eb1e,0xf57d4f7fee6ed178
.quad	0x06f067aa72176fba,0x0a637dc5a2c898a6
.quad	0x06f067aa72176fba,0x0a637dc5a2c898a6
.quad	0x113f9804bef90dae,0x1b710b35131c471b
.quad	0x113f9804bef90dae,0x1b710b35131c471b
.quad	0x28db77f523047d84,0x32caab7b40c72493
.quad	0x28db77f523047d84,0x32caab7b40c72493
.quad	0x3c9ebe0a15c9bebc,0x431d67c49c100d4c
.quad	0x3c9ebe0a15c9bebc,0x431d67c49c100d4c
.quad	0x4cc5d4becb3e42b6,0x597f299cfc657e2a
.quad	0x4cc5d4becb3e42b6,0x597f299cfc657e2a
.quad	0x5fcb6fab3ad6faec,0x6c44198c4a475817
.quad	0x5fcb6fab3ad6faec,0x6c44198c4a475817

.quad	0x0001020304050607,0x08090a0b0c0d0e0f
.quad	0x0001020304050607,0x08090a0b0c0d0e0f
.byte	83,72,65,53,49,50,32,98,108,111,99,107,32,116,114,97,110,115,102,111,114,109,32,102,111,114,32,120,56,54,95,54,52,44,32,67,82,89,80,84,79,71,65,77,83,32,98,121,32,60,97,112,112,114,111,64,111,112,101,110,115,115,108,46,111,114,103,62,0
.type	sha512_block_data_order_xop,@function
.align	64
sha512_block_data_order_xop:
.cfi_startproc	
.Lxop_shortcut:
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
	shlq	$4,%rdx
	subq	$160,%rsp
	leaq	(%rsi,%rdx,8),%rdx
	andq	$-64,%rsp
	movq	%rdi,128+0(%rsp)
	movq	%rsi,128+8(%rsp)
	movq	%rdx,128+16(%rsp)
	movq	%rax,152(%rsp)
.cfi_escape	0x0f,0x06,0x77,0x98,0x01,0x06,0x23,0x08
.Lprologue_xop:

	vzeroupper
	movq	0(%rdi),%rax
	movq	8(%rdi),%rbx
	movq	16(%rdi),%rcx
	movq	24(%rdi),%rdx
	movq	32(%rdi),%r8
	movq	40(%rdi),%r9
	movq	48(%rdi),%r10
	movq	56(%rdi),%r11
	jmp	.Lloop_xop
.align	16
.Lloop_xop:
	vmovdqa	K512+1280(%rip),%xmm11
	vmovdqu	0(%rsi),%xmm0
	leaq	K512+128(%rip),%rbp
	vmovdqu	16(%rsi),%xmm1
	vmovdqu	32(%rsi),%xmm2
	vpshufb	%xmm11,%xmm0,%xmm0
	vmovdqu	48(%rsi),%xmm3
	vpshufb	%xmm11,%xmm1,%xmm1
	vmovdqu	64(%rsi),%xmm4
	vpshufb	%xmm11,%xmm2,%xmm2
	vmovdqu	80(%rsi),%xmm5
	vpshufb	%xmm11,%xmm3,%xmm3
	vmovdqu	96(%rsi),%xmm6
	vpshufb	%xmm11,%xmm4,%xmm4
	vmovdqu	112(%rsi),%xmm7
	vpshufb	%xmm11,%xmm5,%xmm5
	vpaddq	-128(%rbp),%xmm0,%xmm8
	vpshufb	%xmm11,%xmm6,%xmm6
	vpaddq	-96(%rbp),%xmm1,%xmm9
	vpshufb	%xmm11,%xmm7,%xmm7
	vpaddq	-64(%rbp),%xmm2,%xmm10
	vpaddq	-32(%rbp),%xmm3,%xmm11
	vmovdqa	%xmm8,0(%rsp)
	vpaddq	0(%rbp),%xmm4,%xmm8
	vmovdqa	%xmm9,16(%rsp)
	vpaddq	32(%rbp),%xmm5,%xmm9
	vmovdqa	%xmm10,32(%rsp)
	vpaddq	64(%rbp),%xmm6,%xmm10
	vmovdqa	%xmm11,48(%rsp)
	vpaddq	96(%rbp),%xmm7,%xmm11
	vmovdqa	%xmm8,64(%rsp)
	movq	%rax,%r14
	vmovdqa	%xmm9,80(%rsp)
	movq	%rbx,%rdi
	vmovdqa	%xmm10,96(%rsp)
	xorq	%rcx,%rdi
	vmovdqa	%xmm11,112(%rsp)
	movq	%r8,%r13
	jmp	.Lxop_00_47

.align	16
.Lxop_00_47:
	addq	$256,%rbp
	vpalignr	$8,%xmm0,%xmm1,%xmm8
	rorq	$23,%r13
	movq	%r14,%rax
	vpalignr	$8,%xmm4,%xmm5,%xmm11
	movq	%r9,%r12
	rorq	$5,%r14
.byte	143,72,120,195,200,56
	xorq	%r8,%r13
	xorq	%r10,%r12
	vpsrlq	$7,%xmm8,%xmm8
	rorq	$4,%r13
	xorq	%rax,%r14
	vpaddq	%xmm11,%xmm0,%xmm0
	andq	%r8,%r12
	xorq	%r8,%r13
	addq	0(%rsp),%r11
	movq	%rax,%r15
.byte	143,72,120,195,209,7
	xorq	%r10,%r12
	rorq	$6,%r14
	vpxor	%xmm9,%xmm8,%xmm8
	xorq	%rbx,%r15
	addq	%r12,%r11
	rorq	$14,%r13
	andq	%r15,%rdi
.byte	143,104,120,195,223,3
	xorq	%rax,%r14
	addq	%r13,%r11
	vpxor	%xmm10,%xmm8,%xmm8
	xorq	%rbx,%rdi
	rorq	$28,%r14
	vpsrlq	$6,%xmm7,%xmm10
	addq	%r11,%rdx
	addq	%rdi,%r11
	vpaddq	%xmm8,%xmm0,%xmm0
	movq	%rdx,%r13
	addq	%r11,%r14
.byte	143,72,120,195,203,42
	rorq	$23,%r13
	movq	%r14,%r11
	vpxor	%xmm10,%xmm11,%xmm11
	movq	%r8,%r12
	rorq	$5,%r14
	xorq	%rdx,%r13
	xorq	%r9,%r12
	vpxor	%xmm9,%xmm11,%xmm11
	rorq	$4,%r13
	xorq	%r11,%r14
	andq	%rdx,%r12
	xorq	%rdx,%r13
	vpaddq	%xmm11,%xmm0,%xmm0
	addq	8(%rsp),%r10
	movq	%r11,%rdi
	xorq	%r9,%r12
	rorq	$6,%r14
	vpaddq	-128(%rbp),%xmm0,%xmm10
	xorq	%rax,%rdi
	addq	%r12,%r10
	rorq	$14,%r13
	andq	%rdi,%r15
	xorq	%r11,%r14
	addq	%r13,%r10
	xorq	%rax,%r15
	rorq	$28,%r14
	addq	%r10,%rcx
	addq	%r15,%r10
	movq	%rcx,%r13
	addq	%r10,%r14
	vmovdqa	%xmm10,0(%rsp)
	vpalignr	$8,%xmm1,%xmm2,%xmm8
	rorq	$23,%r13
	movq	%r14,%r10
	vpalignr	$8,%xmm5,%xmm6,%xmm11
	movq	%rdx,%r12
	rorq	$5,%r14
.byte	143,72,120,195,200,56
	xorq	%rcx,%r13
	xorq	%r8,%r12
	vpsrlq	$7,%xmm8,%xmm8
	rorq	$4,%r13
	xorq	%r10,%r14
	vpaddq	%xmm11,%xmm1,%xmm1
	andq	%rcx,%r12
	xorq	%rcx,%r13
	addq	16(%rsp),%r9
	movq	%r10,%r15
.byte	143,72,120,195,209,7
	xorq	%r8,%r12
	rorq	$6,%r14
	vpxor	%xmm9,%xmm8,%xmm8
	xorq	%r11,%r15
	addq	%r12,%r9
	rorq	$14,%r13
	andq	%r15,%rdi
.byte	143,104,120,195,216,3
	xorq	%r10,%r14
	addq	%r13,%r9
	vpxor	%xmm10,%xmm8,%xmm8
	xorq	%r11,%rdi
	rorq	$28,%r14
	vpsrlq	$6,%xmm0,%xmm10
	addq	%r9,%rbx
	addq	%rdi,%r9
	vpaddq	%xmm8,%xmm1,%xmm1
	movq	%rbx,%r13
	addq	%r9,%r14
.byte	143,72,120,195,203,42
	rorq	$23,%r13
	movq	%r14,%r9
	vpxor	%xmm10,%xmm11,%xmm11
	movq	%rcx,%r12
	rorq	$5,%r14
	xorq	%rbx,%r13
	xorq	%rdx,%r12
	vpxor	%xmm9,%xmm11,%xmm11
	rorq	$4,%r13
	xorq	%r9,%r14
	andq	%rbx,%r12
	xorq	%rbx,%r13
	vpaddq	%xmm11,%xmm1,%xmm1
	addq	24(%rsp),%r8
	movq	%r9,%rdi
	xorq	%rdx,%r12
	rorq	$6,%r14
	vpaddq	-96(%rbp),%xmm1,%xmm10
	xorq	%r10,%rdi
	addq	%r12,%r8
	rorq	$14,%r13
	andq	%rdi,%r15
	xorq	%r9,%r14
	addq	%r13,%r8
	xorq	%r10,%r15
	rorq	$28,%r14
	addq	%r8,%rax
	addq	%r15,%r8
	movq	%rax,%r13
	addq	%r8,%r14
	vmovdqa	%xmm10,16(%rsp)
	vpalignr	$8,%xmm2,%xmm3,%xmm8
	rorq	$23,%r13
	movq	%r14,%r8
	vpalignr	$8,%xmm6,%xmm7,%xmm11
	movq	%rbx,%r12
	rorq	$5,%r14
.byte	143,72,120,195,200,56
	xorq	%rax,%r13
	xorq	%rcx,%r12
	vpsrlq	$7,%xmm8,%xmm8
	rorq	$4,%r13
	xorq	%r8,%r14
	vpaddq	%xmm11,%xmm2,%xmm2
	andq	%rax,%r12
	xorq	%rax,%r13
	addq	32(%rsp),%rdx
	movq	%r8,%r15
.byte	143,72,120,195,209,7
	xorq	%rcx,%r12
	rorq	$6,%r14
	vpxor	%xmm9,%xmm8,%xmm8
	xorq	%r9,%r15
	addq	%r12,%rdx
	rorq	$14,%r13
	andq	%r15,%rdi
.byte	143,104,120,195,217,3
	xorq	%r8,%r14
	addq	%r13,%rdx
	vpxor	%xmm10,%xmm8,%xmm8
	xorq	%r9,%rdi
	rorq	$28,%r14
	vpsrlq	$6,%xmm1,%xmm10
	addq	%rdx,%r11
	addq	%rdi,%rdx
	vpaddq	%xmm8,%xmm2,%xmm2
	movq	%r11,%r13
	addq	%rdx,%r14
.byte	143,72,120,195,203,42
	rorq	$23,%r13
	movq	%r14,%rdx
	vpxor	%xmm10,%xmm11,%xmm11
	movq	%rax,%r12
	rorq	$5,%r14
	xorq	%r11,%r13
	xorq	%rbx,%r12
	vpxor	%xmm9,%xmm11,%xmm11
	rorq	$4,%r13
	xorq	%rdx,%r14
	andq	%r11,%r12
	xorq	%r11,%r13
	vpaddq	%xmm11,%xmm2,%xmm2
	addq	40(%rsp),%rcx
	movq	%rdx,%rdi
	xorq	%rbx,%r12
	rorq	$6,%r14
	vpaddq	-64(%rbp),%xmm2,%xmm10
	xorq	%r8,%rdi
	addq	%r12,%rcx
	rorq	$14,%r13
	andq	%rdi,%r15
	xorq	%rdx,%r14
	addq	%r13,%rcx
	xorq	%r8,%r15
	rorq	$28,%r14
	addq	%rcx,%r10
	addq	%r15,%rcx
	movq	%r10,%r13
	addq	%rcx,%r14
	vmovdqa	%xmm10,32(%rsp)
	vpalignr	$8,%xmm3,%xmm4,%xmm8
	rorq	$23,%r13
	movq	%r14,%rcx
	vpalignr	$8,%xmm7,%xmm0,%xmm11
	movq	%r11,%r12
	rorq	$5,%r14
.byte	143,72,120,195,200,56
	xorq	%r10,%r13
	xorq	%rax,%r12
	vpsrlq	$7,%xmm8,%xmm8
	rorq	$4,%r13
	xorq	%rcx,%r14
	vpaddq	%xmm11,%xmm3,%xmm3
	andq	%r10,%r12
	xorq	%r10,%r13
	addq	48(%rsp),%rbx
	movq	%rcx,%r15
.byte	143,72,120,195,209,7
	xorq	%rax,%r12
	rorq	$6,%r14
	vpxor	%xmm9,%xmm8,%xmm8
	xorq	%rdx,%r15
	addq	%r12,%rbx
	rorq	$14,%r13
	andq	%r15,%rdi
.byte	143,104,120,195,218,3
	xorq	%rcx,%r14
	addq	%r13,%rbx
	vpxor	%xmm10,%xmm8,%xmm8
	xorq	%rdx,%rdi
	rorq	$28,%r14
	vpsrlq	$6,%xmm2,%xmm10
	addq	%rbx,%r9
	addq	%rdi,%rbx
	vpaddq	%xmm8,%xmm3,%xmm3
	movq	%r9,%r13
	addq	%rbx,%r14
.byte	143,72,120,195,203,42
	rorq	$23,%r13
	movq	%r14,%rbx
	vpxor	%xmm10,%xmm11,%xmm11
	movq	%r10,%r12
	rorq	$5,%r14
	xorq	%r9,%r13
	xorq	%r11,%r12
	vpxor	%xmm9,%xmm11,%xmm11
	rorq	$4,%r13
	xorq	%rbx,%r14
	andq	%r9,%r12
	xorq	%r9,%r13
	vpaddq	%xmm11,%xmm3,%xmm3
	addq	56(%rsp),%rax
	movq	%rbx,%rdi
	xorq	%r11,%r12
	rorq	$6,%r14
	vpaddq	-32(%rbp),%xmm3,%xmm10
	xorq	%rcx,%rdi
	addq	%r12,%rax
	rorq	$14,%r13
	andq	%rdi,%r15
	xorq	%rbx,%r14
	addq	%r13,%rax
	xorq	%rcx,%r15
	rorq	$28,%r14
	addq	%rax,%r8
	addq	%r15,%rax
	movq	%r8,%r13
	addq	%rax,%r14
	vmovdqa	%xmm10,48(%rsp)
	vpalignr	$8,%xmm4,%xmm5,%xmm8
	rorq	$23,%r13
	movq	%r14,%rax
	vpalignr	$8,%xmm0,%xmm1,%xmm11
	movq	%r9,%r12
	rorq	$5,%r14
.byte	143,72,120,195,200,56
	xorq	%r8,%r13
	xorq	%r10,%r12
	vpsrlq	$7,%xmm8,%xmm8
	rorq	$4,%r13
	xorq	%rax,%r14
	vpaddq	%xmm11,%xmm4,%xmm4
	andq	%r8,%r12
	xorq	%r8,%r13
	addq	64(%rsp),%r11
	movq	%rax,%r15
.byte	143,72,120,195,209,7
	xorq	%r10,%r12
	rorq	$6,%r14
	vpxor	%xmm9,%xmm8,%xmm8
	xorq	%rbx,%r15
	addq	%r12,%r11
	rorq	$14,%r13
	andq	%r15,%rdi
.byte	143,104,120,195,219,3
	xorq	%rax,%r14
	addq	%r13,%r11
	vpxor	%xmm10,%xmm8,%xmm8
	xorq	%rbx,%rdi
	rorq	$28,%r14
	vpsrlq	$6,%xmm3,%xmm10
	addq	%r11,%rdx
	addq	%rdi,%r11
	vpaddq	%xmm8,%xmm4,%xmm4
	movq	%rdx,%r13
	addq	%r11,%r14
.byte	143,72,120,195,203,42
	rorq	$23,%r13
	movq	%r14,%r11
	vpxor	%xmm10,%xmm11,%xmm11
	movq	%r8,%r12
	rorq	$5,%r14
	xorq	%rdx,%r13
	xorq	%r9,%r12
	vpxor	%xmm9,%xmm11,%xmm11
	rorq	$4,%r13
	xorq	%r11,%r14
	andq	%rdx,%r12
	xorq	%rdx,%r13
	vpaddq	%xmm11,%xmm4,%xmm4
	addq	72(%rsp),%r10
	movq	%r11,%rdi
	xorq	%r9,%r12
	rorq	$6,%r14
	vpaddq	0(%rbp),%xmm4,%xmm10
	xorq	%rax,%rdi
	addq	%r12,%r10
	rorq	$14,%r13
	andq	%rdi,%r15
	xorq	%r11,%r14
	addq	%r13,%r10
	xorq	%rax,%r15
	rorq	$28,%r14
	addq	%r10,%rcx
	addq	%r15,%r10
	movq	%rcx,%r13
	addq	%r10,%r14
	vmovdqa	%xmm10,64(%rsp)
	vpalignr	$8,%xmm5,%xmm6,%xmm8
	rorq	$23,%r13
	movq	%r14,%r10
	vpalignr	$8,%xmm1,%xmm2,%xmm11
	movq	%rdx,%r12
	rorq	$5,%r14
.byte	143,72,120,195,200,56
	xorq	%rcx,%r13
	xorq	%r8,%r12
	vpsrlq	$7,%xmm8,%xmm8
	rorq	$4,%r13
	xorq	%r10,%r14
	vpaddq	%xmm11,%xmm5,%xmm5
	andq	%rcx,%r12
	xorq	%rcx,%r13
	addq	80(%rsp),%r9
	movq	%r10,%r15
.byte	143,72,120,195,209,7
	xorq	%r8,%r12
	rorq	$6,%r14
	vpxor	%xmm9,%xmm8,%xmm8
	xorq	%r11,%r15
	addq	%r12,%r9
	rorq	$14,%r13
	andq	%r15,%rdi
.byte	143,104,120,195,220,3
	xorq	%r10,%r14
	addq	%r13,%r9
	vpxor	%xmm10,%xmm8,%xmm8
	xorq	%r11,%rdi
	rorq	$28,%r14
	vpsrlq	$6,%xmm4,%xmm10
	addq	%r9,%rbx
	addq	%rdi,%r9
	vpaddq	%xmm8,%xmm5,%xmm5
	movq	%rbx,%r13
	addq	%r9,%r14
.byte	143,72,120,195,203,42
	rorq	$23,%r13
	movq	%r14,%r9
	vpxor	%xmm10,%xmm11,%xmm11
	movq	%rcx,%r12
	rorq	$5,%r14
	xorq	%rbx,%r13
	xorq	%rdx,%r12
	vpxor	%xmm9,%xmm11,%xmm11
	rorq	$4,%r13
	xorq	%r9,%r14
	andq	%rbx,%r12
	xorq	%rbx,%r13
	vpaddq	%xmm11,%xmm5,%xmm5
	addq	88(%rsp),%r8
	movq	%r9,%rdi
	xorq	%rdx,%r12
	rorq	$6,%r14
	vpaddq	32(%rbp),%xmm5,%xmm10
	xorq	%r10,%rdi
	addq	%r12,%r8
	rorq	$14,%r13
	andq	%rdi,%r15
	xorq	%r9,%r14
	addq	%r13,%r8
	xorq	%r10,%r15
	rorq	$28,%r14
	addq	%r8,%rax
	addq	%r15,%r8
	movq	%rax,%r13
	addq	%r8,%r14
	vmovdqa	%xmm10,80(%rsp)
	vpalignr	$8,%xmm6,%xmm7,%xmm8
	rorq	$23,%r13
	movq	%r14,%r8
	vpalignr	$8,%xmm2,%xmm3,%xmm11
	movq	%rbx,%r12
	rorq	$5,%r14
.byte	143,72,120,195,200,56
	xorq	%rax,%r13
	xorq	%rcx,%r12
	vpsrlq	$7,%xmm8,%xmm8
	rorq	$4,%r13
	xorq	%r8,%r14
	vpaddq	%xmm11,%xmm6,%xmm6
	andq	%rax,%r12
	xorq	%rax,%r13
	addq	96(%rsp),%rdx
	movq	%r8,%r15
.byte	143,72,120,195,209,7
	xorq	%rcx,%r12
	rorq	$6,%r14
	vpxor	%xmm9,%xmm8,%xmm8
	xorq	%r9,%r15
	addq	%r12,%rdx
	rorq	$14,%r13
	andq	%r15,%rdi
.byte	143,104,120,195,221,3
	xorq	%r8,%r14
	addq	%r13,%rdx
	vpxor	%xmm10,%xmm8,%xmm8
	xorq	%r9,%rdi
	rorq	$28,%r14
	vpsrlq	$6,%xmm5,%xmm10
	addq	%rdx,%r11
	addq	%rdi,%rdx
	vpaddq	%xmm8,%xmm6,%xmm6
	movq	%r11,%r13
	addq	%rdx,%r14
.byte	143,72,120,195,203,42
	rorq	$23,%r13
	movq	%r14,%rdx
	vpxor	%xmm10,%xmm11,%xmm11
	movq	%rax,%r12
	rorq	$5,%r14
	xorq	%r11,%r13
	xorq	%rbx,%r12
	vpxor	%xmm9,%xmm11,%xmm11
	rorq	$4,%r13
	xorq	%rdx,%r14
	andq	%r11,%r12
	xorq	%r11,%r13
	vpaddq	%xmm11,%xmm6,%xmm6
	addq	104(%rsp),%rcx
	movq	%rdx,%rdi
	xorq	%rbx,%r12
	rorq	$6,%r14
	vpaddq	64(%rbp),%xmm6,%xmm10
	xorq	%r8,%rdi
	addq	%r12,%rcx
	rorq	$14,%r13
	andq	%rdi,%r15
	xorq	%rdx,%r14
	addq	%r13,%rcx
	xorq	%r8,%r15
	rorq	$28,%r14
	addq	%rcx,%r10
	addq	%r15,%rcx
	movq	%r10,%r13
	addq	%rcx,%r14
	vmovdqa	%xmm10,96(%rsp)
	vpalignr	$8,%xmm7,%xmm0,%xmm8
	rorq	$23,%r13
	movq	%r14,%rcx
	vpalignr	$8,%xmm3,%xmm4,%xmm11
	movq	%r11,%r12
	rorq	$5,%r14
.byte	143,72,120,195,200,56
	xorq	%r10,%r13
	xorq	%rax,%r12
	vpsrlq	$7,%xmm8,%xmm8
	rorq	$4,%r13
	xorq	%rcx,%r14
	vpaddq	%xmm11,%xmm7,%xmm7
	andq	%r10,%r12
	xorq	%r10,%r13
	addq	112(%rsp),%rbx
	movq	%rcx,%r15
.byte	143,72,120,195,209,7
	xorq	%rax,%r12
	rorq	$6,%r14
	vpxor	%xmm9,%xmm8,%xmm8
	xorq	%rdx,%r15
	addq	%r12,%rbx
	rorq	$14,%r13
	andq	%r15,%rdi
.byte	143,104,120,195,222,3
	xorq	%rcx,%r14
	addq	%r13,%rbx
	vpxor	%xmm10,%xmm8,%xmm8
	xorq	%rdx,%rdi
	rorq	$28,%r14
	vpsrlq	$6,%xmm6,%xmm10
	addq	%rbx,%r9
	addq	%rdi,%rbx
	vpaddq	%xmm8,%xmm7,%xmm7
	movq	%r9,%r13
	addq	%rbx,%r14
.byte	143,72,120,195,203,42
	rorq	$23,%r13
	movq	%r14,%rbx
	vpxor	%xmm10,%xmm11,%xmm11
	movq	%r10,%r12
	rorq	$5,%r14
	xorq	%r9,%r13
	xorq	%r11,%r12
	vpxor	%xmm9,%xmm11,%xmm11
	rorq	$4,%r13
	xorq	%rbx,%r14
	andq	%r9,%r12
	xorq	%r9,%r13
	vpaddq	%xmm11,%xmm7,%xmm7
	addq	120(%rsp),%rax
	movq	%rbx,%rdi
	xorq	%r11,%r12
	rorq	$6,%r14
	vpaddq	96(%rbp),%xmm7,%xmm10
	xorq	%rcx,%rdi
	addq	%r12,%rax
	rorq	$14,%r13
	andq	%rdi,%r15
	xorq	%rbx,%r14
	addq	%r13,%rax
	xorq	%rcx,%r15
	rorq	$28,%r14
	addq	%rax,%r8
	addq	%r15,%rax
	movq	%r8,%r13
	addq	%rax,%r14
	vmovdqa	%xmm10,112(%rsp)
	cmpb	$0,135(%rbp)
	jne	.Lxop_00_47
	rorq	$23,%r13
	movq	%r14,%rax
	movq	%r9,%r12
	rorq	$5,%r14
	xorq	%r8,%r13
	xorq	%r10,%r12
	rorq	$4,%r13
	xorq	%rax,%r14
	andq	%r8,%r12
	xorq	%r8,%r13
	addq	0(%rsp),%r11
	movq	%rax,%r15
	xorq	%r10,%r12
	rorq	$6,%r14
	xorq	%rbx,%r15
	addq	%r12,%r11
	rorq	$14,%r13
	andq	%r15,%rdi
	xorq	%rax,%r14
	addq	%r13,%r11
	xorq	%rbx,%rdi
	rorq	$28,%r14
	addq	%r11,%rdx
	addq	%rdi,%r11
	movq	%rdx,%r13
	addq	%r11,%r14
	rorq	$23,%r13
	movq	%r14,%r11
	movq	%r8,%r12
	rorq	$5,%r14
	xorq	%rdx,%r13
	xorq	%r9,%r12
	rorq	$4,%r13
	xorq	%r11,%r14
	andq	%rdx,%r12
	xorq	%rdx,%r13
	addq	8(%rsp),%r10
	movq	%r11,%rdi
	xorq	%r9,%r12
	rorq	$6,%r14
	xorq	%rax,%rdi
	addq	%r12,%r10
	rorq	$14,%r13
	andq	%rdi,%r15
	xorq	%r11,%r14
	addq	%r13,%r10
	xorq	%rax,%r15
	rorq	$28,%r14
	addq	%r10,%rcx
	addq	%r15,%r10
	movq	%rcx,%r13
	addq	%r10,%r14
	rorq	$23,%r13
	movq	%r14,%r10
	movq	%rdx,%r12
	rorq	$5,%r14
	xorq	%rcx,%r13
	xorq	%r8,%r12
	rorq	$4,%r13
	xorq	%r10,%r14
	andq	%rcx,%r12
	xorq	%rcx,%r13
	addq	16(%rsp),%r9
	movq	%r10,%r15
	xorq	%r8,%r12
	rorq	$6,%r14
	xorq	%r11,%r15
	addq	%r12,%r9
	rorq	$14,%r13
	andq	%r15,%rdi
	xorq	%r10,%r14
	addq	%r13,%r9
	xorq	%r11,%rdi
	rorq	$28,%r14
	addq	%r9,%rbx
	addq	%rdi,%r9
	movq	%rbx,%r13
	addq	%r9,%r14
	rorq	$23,%r13
	movq	%r14,%r9
	movq	%rcx,%r12
	rorq	$5,%r14
	xorq	%rbx,%r13
	xorq	%rdx,%r12
	rorq	$4,%r13
	xorq	%r9,%r14
	andq	%rbx,%r12
	xorq	%rbx,%r13
	addq	24(%rsp),%r8
	movq	%r9,%rdi
	xorq	%rdx,%r12
	rorq	$6,%r14
	xorq	%r10,%rdi
	addq	%r12,%r8
	rorq	$14,%r13
	andq	%rdi,%r15
	xorq	%r9,%r14
	addq	%r13,%r8
	xorq	%r10,%r15
	rorq	$28,%r14
	addq	%r8,%rax
	addq	%r15,%r8
	movq	%rax,%r13
	addq	%r8,%r14
	rorq	$23,%r13
	movq	%r14,%r8
	movq	%rbx,%r12
	rorq	$5,%r14
	xorq	%rax,%r13
	xorq	%rcx,%r12
	rorq	$4,%r13
	xorq	%r8,%r14
	andq	%rax,%r12
	xorq	%rax,%r13
	addq	32(%rsp),%rdx
	movq	%r8,%r15
	xorq	%rcx,%r12
	rorq	$6,%r14
	xorq	%r9,%r15
	addq	%r12,%rdx
	rorq	$14,%r13
	andq	%r15,%rdi
	xorq	%r8,%r14
	addq	%r13,%rdx
	xorq	%r9,%rdi
	rorq	$28,%r14
	addq	%rdx,%r11
	addq	%rdi,%rdx
	movq	%r11,%r13
	addq	%rdx,%r14
	rorq	$23,%r13
	movq	%r14,%rdx
	movq	%rax,%r12
	rorq	$5,%r14
	xorq	%r11,%r13
	xorq	%rbx,%r12
	rorq	$4,%r13
	xorq	%rdx,%r14
	andq	%r11,%r12
	xorq	%r11,%r13
	addq	40(%rsp),%rcx
	movq	%rdx,%rdi
	xorq	%rbx,%r12
	rorq	$6,%r14
	xorq	%r8,%rdi
	addq	%r12,%rcx
	rorq	$14,%r13
	andq	%rdi,%r15
	xorq	%rdx,%r14
	addq	%r13,%rcx
	xorq	%r8,%r15
	rorq	$28,%r14
	addq	%rcx,%r10
	addq	%r15,%rcx
	movq	%r10,%r13
	addq	%rcx,%r14
	rorq	$23,%r13
	movq	%r14,%rcx
	movq	%r11,%r12
	rorq	$5,%r14
	xorq	%r10,%r13
	xorq	%rax,%r12
	rorq	$4,%r13
	xorq	%rcx,%r14
	andq	%r10,%r12
	xorq	%r10,%r13
	addq	48(%rsp),%rbx
	movq	%rcx,%r15
	xorq	%rax,%r12
	rorq	$6,%r14
	xorq	%rdx,%r15
	addq	%r12,%rbx
	rorq	$14,%r13
	andq	%r15,%rdi
	xorq	%rcx,%r14
	addq	%r13,%rbx
	xorq	%rdx,%rdi
	rorq	$28,%r14
	addq	%rbx,%r9
	addq	%rdi,%rbx
	movq	%r9,%r13
	addq	%rbx,%r14
	rorq	$23,%r13
	movq	%r14,%rbx
	movq	%r10,%r12
	rorq	$5,%r14
	xorq	%r9,%r13
	xorq	%r11,%r12
	rorq	$4,%r13
	xorq	%rbx,%r14
	andq	%r9,%r12
	xorq	%r9,%r13
	addq	56(%rsp),%rax
	movq	%rbx,%rdi
	xorq	%r11,%r12
	rorq	$6,%r14
	xorq	%rcx,%rdi
	addq	%r12,%rax
	rorq	$14,%r13
	andq	%rdi,%r15
	xorq	%rbx,%r14
	addq	%r13,%rax
	xorq	%rcx,%r15
	rorq	$28,%r14
	addq	%rax,%r8
	addq	%r15,%rax
	movq	%r8,%r13
	addq	%rax,%r14
	rorq	$23,%r13
	movq	%r14,%rax
	movq	%r9,%r12
	rorq	$5,%r14
	xorq	%r8,%r13
	xorq	%r10,%r12
	rorq	$4,%r13
	xorq	%rax,%r14
	andq	%r8,%r12
	xorq	%r8,%r13
	addq	64(%rsp),%r11
	movq	%rax,%r15
	xorq	%r10,%r12
	rorq	$6,%r14
	xorq	%rbx,%r15
	addq	%r12,%r11
	rorq	$14,%r13
	andq	%r15,%rdi
	xorq	%rax,%r14
	addq	%r13,%r11
	xorq	%rbx,%rdi
	rorq	$28,%r14
	addq	%r11,%rdx
	addq	%rdi,%r11
	movq	%rdx,%r13
	addq	%r11,%r14
	rorq	$23,%r13
	movq	%r14,%r11
	movq	%r8,%r12
	rorq	$5,%r14
	xorq	%rdx,%r13
	xorq	%r9,%r12
	rorq	$4,%r13
	xorq	%r11,%r14
	andq	%rdx,%r12
	xorq	%rdx,%r13
	addq	72(%rsp),%r10
	movq	%r11,%rdi
	xorq	%r9,%r12
	rorq	$6,%r14
	xorq	%rax,%rdi
	addq	%r12,%r10
	rorq	$14,%r13
	andq	%rdi,%r15
	xorq	%r11,%r14
	addq	%r13,%r10
	xorq	%rax,%r15
	rorq	$28,%r14
	addq	%r10,%rcx
	addq	%r15,%r10
	movq	%rcx,%r13
	addq	%r10,%r14
	rorq	$23,%r13
	movq	%r14,%r10
	movq	%rdx,%r12
	rorq	$5,%r14
	xorq	%rcx,%r13
	xorq	%r8,%r12
	rorq	$4,%r13
	xorq	%r10,%r14
	andq	%rcx,%r12
	xorq	%rcx,%r13
	addq	80(%rsp),%r9
	movq	%r10,%r15
	xorq	%r8,%r12
	rorq	$6,%r14
	xorq	%r11,%r15
	addq	%r12,%r9
	rorq	$14,%r13
	andq	%r15,%rdi
	xorq	%r10,%r14
	addq	%r13,%r9
	xorq	%r11,%rdi
	rorq	$28,%r14
	addq	%r9,%rbx
	addq	%rdi,%r9
	movq	%rbx,%r13
	addq	%r9,%r14
	rorq	$23,%r13
	movq	%r14,%r9
	movq	%rcx,%r12
	rorq	$5,%r14
	xorq	%rbx,%r13
	xorq	%rdx,%r12
	rorq	$4,%r13
	xorq	%r9,%r14
	andq	%rbx,%r12
	xorq	%rbx,%r13
	addq	88(%rsp),%r8
	movq	%r9,%rdi
	xorq	%rdx,%r12
	rorq	$6,%r14
	xorq	%r10,%rdi
	addq	%r12,%r8
	rorq	$14,%r13
	andq	%rdi,%r15
	xorq	%r9,%r14
	addq	%r13,%r8
	xorq	%r10,%r15
	rorq	$28,%r14
	addq	%r8,%rax
	addq	%r15,%r8
	movq	%rax,%r13
	addq	%r8,%r14
	rorq	$23,%r13
	movq	%r14,%r8
	movq	%rbx,%r12
	rorq	$5,%r14
	xorq	%rax,%r13
	xorq	%rcx,%r12
	rorq	$4,%r13
	xorq	%r8,%r14
	andq	%rax,%r12
	xorq	%rax,%r13
	addq	96(%rsp),%rdx
	movq	%r8,%r15
	xorq	%rcx,%r12
	rorq	$6,%r14
	xorq	%r9,%r15
	addq	%r12,%rdx
	rorq	$14,%r13
	andq	%r15,%rdi
	xorq	%r8,%r14
	addq	%r13,%rdx
	xorq	%r9,%rdi
	rorq	$28,%r14
	addq	%rdx,%r11
	addq	%rdi,%rdx
	movq	%r11,%r13
	addq	%rdx,%r14
	rorq	$23,%r13
	movq	%r14,%rdx
	movq	%rax,%r12
	rorq	$5,%r14
	xorq	%r11,%r13
	xorq	%rbx,%r12
	rorq	$4,%r13
	xorq	%rdx,%r14
	andq	%r11,%r12
	xorq	%r11,%r13
	addq	104(%rsp),%rcx
	movq	%rdx,%rdi
	xorq	%rbx,%r12
	rorq	$6,%r14
	xorq	%r8,%rdi
	addq	%r12,%rcx
	rorq	$14,%r13
	andq	%rdi,%r15
	xorq	%rdx,%r14
	addq	%r13,%rcx
	xorq	%r8,%r15
	rorq	$28,%r14
	addq	%rcx,%r10
	addq	%r15,%rcx
	movq	%r10,%r13
	addq	%rcx,%r14
	rorq	$23,%r13
	movq	%r14,%rcx
	movq	%r11,%r12
	rorq	$5,%r14
	xorq	%r10,%r13
	xorq	%rax,%r12
	rorq	$4,%r13
	xorq	%rcx,%r14
	andq	%r10,%r12
	xorq	%r10,%r13
	addq	112(%rsp),%rbx
	movq	%rcx,%r15
	xorq	%rax,%r12
	rorq	$6,%r14
	xorq	%rdx,%r15
	addq	%r12,%rbx
	rorq	$14,%r13
	andq	%r15,%rdi
	xorq	%rcx,%r14
	addq	%r13,%rbx
	xorq	%rdx,%rdi
	rorq	$28,%r14
	addq	%rbx,%r9
	addq	%rdi,%rbx
	movq	%r9,%r13
	addq	%rbx,%r14
	rorq	$23,%r13
	movq	%r14,%rbx
	movq	%r10,%r12
	rorq	$5,%r14
	xorq	%r9,%r13
	xorq	%r11,%r12
	rorq	$4,%r13
	xorq	%rbx,%r14
	andq	%r9,%r12
	xorq	%r9,%r13
	addq	120(%rsp),%rax
	movq	%rbx,%rdi
	xorq	%r11,%r12
	rorq	$6,%r14
	xorq	%rcx,%rdi
	addq	%r12,%rax
	rorq	$14,%r13
	andq	%rdi,%r15
	xorq	%rbx,%r14
	addq	%r13,%rax
	xorq	%rcx,%r15
	rorq	$28,%r14
	addq	%rax,%r8
	addq	%r15,%rax
	movq	%r8,%r13
	addq	%rax,%r14
	movq	128+0(%rsp),%rdi
	movq	%r14,%rax

	addq	0(%rdi),%rax
	leaq	128(%rsi),%rsi
	addq	8(%rdi),%rbx
	addq	16(%rdi),%rcx
	addq	24(%rdi),%rdx
	addq	32(%rdi),%r8
	addq	40(%rdi),%r9
	addq	48(%rdi),%r10
	addq	56(%rdi),%r11

	cmpq	128+16(%rsp),%rsi

	movq	%rax,0(%rdi)
	movq	%rbx,8(%rdi)
	movq	%rcx,16(%rdi)
	movq	%rdx,24(%rdi)
	movq	%r8,32(%rdi)
	movq	%r9,40(%rdi)
	movq	%r10,48(%rdi)
	movq	%r11,56(%rdi)
	jb	.Lloop_xop

	movq	152(%rsp),%rsi
.cfi_def_cfa	%rsi,8
	vzeroupper
	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue_xop:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha512_block_data_order_xop,.-sha512_block_data_order_xop
.type	sha512_block_data_order_avx,@function
.align	64
sha512_block_data_order_avx:
.cfi_startproc	
.Lavx_shortcut:
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
	shlq	$4,%rdx
	subq	$160,%rsp
	leaq	(%rsi,%rdx,8),%rdx
	andq	$-64,%rsp
	movq	%rdi,128+0(%rsp)
	movq	%rsi,128+8(%rsp)
	movq	%rdx,128+16(%rsp)
	movq	%rax,152(%rsp)
.cfi_escape	0x0f,0x06,0x77,0x98,0x01,0x06,0x23,0x08
.Lprologue_avx:

	vzeroupper
	movq	0(%rdi),%rax
	movq	8(%rdi),%rbx
	movq	16(%rdi),%rcx
	movq	24(%rdi),%rdx
	movq	32(%rdi),%r8
	movq	40(%rdi),%r9
	movq	48(%rdi),%r10
	movq	56(%rdi),%r11
	jmp	.Lloop_avx
.align	16
.Lloop_avx:
	vmovdqa	K512+1280(%rip),%xmm11
	vmovdqu	0(%rsi),%xmm0
	leaq	K512+128(%rip),%rbp
	vmovdqu	16(%rsi),%xmm1
	vmovdqu	32(%rsi),%xmm2
	vpshufb	%xmm11,%xmm0,%xmm0
	vmovdqu	48(%rsi),%xmm3
	vpshufb	%xmm11,%xmm1,%xmm1
	vmovdqu	64(%rsi),%xmm4
	vpshufb	%xmm11,%xmm2,%xmm2
	vmovdqu	80(%rsi),%xmm5
	vpshufb	%xmm11,%xmm3,%xmm3
	vmovdqu	96(%rsi),%xmm6
	vpshufb	%xmm11,%xmm4,%xmm4
	vmovdqu	112(%rsi),%xmm7
	vpshufb	%xmm11,%xmm5,%xmm5
	vpaddq	-128(%rbp),%xmm0,%xmm8
	vpshufb	%xmm11,%xmm6,%xmm6
	vpaddq	-96(%rbp),%xmm1,%xmm9
	vpshufb	%xmm11,%xmm7,%xmm7
	vpaddq	-64(%rbp),%xmm2,%xmm10
	vpaddq	-32(%rbp),%xmm3,%xmm11
	vmovdqa	%xmm8,0(%rsp)
	vpaddq	0(%rbp),%xmm4,%xmm8
	vmovdqa	%xmm9,16(%rsp)
	vpaddq	32(%rbp),%xmm5,%xmm9
	vmovdqa	%xmm10,32(%rsp)
	vpaddq	64(%rbp),%xmm6,%xmm10
	vmovdqa	%xmm11,48(%rsp)
	vpaddq	96(%rbp),%xmm7,%xmm11
	vmovdqa	%xmm8,64(%rsp)
	movq	%rax,%r14
	vmovdqa	%xmm9,80(%rsp)
	movq	%rbx,%rdi
	vmovdqa	%xmm10,96(%rsp)
	xorq	%rcx,%rdi
	vmovdqa	%xmm11,112(%rsp)
	movq	%r8,%r13
	jmp	.Lavx_00_47

.align	16
.Lavx_00_47:
	addq	$256,%rbp
	vpalignr	$8,%xmm0,%xmm1,%xmm8
	shrdq	$23,%r13,%r13
	movq	%r14,%rax
	vpalignr	$8,%xmm4,%xmm5,%xmm11
	movq	%r9,%r12
	shrdq	$5,%r14,%r14
	vpsrlq	$1,%xmm8,%xmm10
	xorq	%r8,%r13
	xorq	%r10,%r12
	vpaddq	%xmm11,%xmm0,%xmm0
	shrdq	$4,%r13,%r13
	xorq	%rax,%r14
	vpsrlq	$7,%xmm8,%xmm11
	andq	%r8,%r12
	xorq	%r8,%r13
	vpsllq	$56,%xmm8,%xmm9
	addq	0(%rsp),%r11
	movq	%rax,%r15
	vpxor	%xmm10,%xmm11,%xmm8
	xorq	%r10,%r12
	shrdq	$6,%r14,%r14
	vpsrlq	$7,%xmm10,%xmm10
	xorq	%rbx,%r15
	addq	%r12,%r11
	vpxor	%xmm9,%xmm8,%xmm8
	shrdq	$14,%r13,%r13
	andq	%r15,%rdi
	vpsllq	$7,%xmm9,%xmm9
	xorq	%rax,%r14
	addq	%r13,%r11
	vpxor	%xmm10,%xmm8,%xmm8
	xorq	%rbx,%rdi
	shrdq	$28,%r14,%r14
	vpsrlq	$6,%xmm7,%xmm11
	addq	%r11,%rdx
	addq	%rdi,%r11
	vpxor	%xmm9,%xmm8,%xmm8
	movq	%rdx,%r13
	addq	%r11,%r14
	vpsllq	$3,%xmm7,%xmm10
	shrdq	$23,%r13,%r13
	movq	%r14,%r11
	vpaddq	%xmm8,%xmm0,%xmm0
	movq	%r8,%r12
	shrdq	$5,%r14,%r14
	vpsrlq	$19,%xmm7,%xmm9
	xorq	%rdx,%r13
	xorq	%r9,%r12
	vpxor	%xmm10,%xmm11,%xmm11
	shrdq	$4,%r13,%r13
	xorq	%r11,%r14
	vpsllq	$42,%xmm10,%xmm10
	andq	%rdx,%r12
	xorq	%rdx,%r13
	vpxor	%xmm9,%xmm11,%xmm11
	addq	8(%rsp),%r10
	movq	%r11,%rdi
	vpsrlq	$42,%xmm9,%xmm9
	xorq	%r9,%r12
	shrdq	$6,%r14,%r14
	vpxor	%xmm10,%xmm11,%xmm11
	xorq	%rax,%rdi
	addq	%r12,%r10
	vpxor	%xmm9,%xmm11,%xmm11
	shrdq	$14,%r13,%r13
	andq	%rdi,%r15
	vpaddq	%xmm11,%xmm0,%xmm0
	xorq	%r11,%r14
	addq	%r13,%r10
	vpaddq	-128(%rbp),%xmm0,%xmm10
	xorq	%rax,%r15
	shrdq	$28,%r14,%r14
	addq	%r10,%rcx
	addq	%r15,%r10
	movq	%rcx,%r13
	addq	%r10,%r14
	vmovdqa	%xmm10,0(%rsp)
	vpalignr	$8,%xmm1,%xmm2,%xmm8
	shrdq	$23,%r13,%r13
	movq	%r14,%r10
	vpalignr	$8,%xmm5,%xmm6,%xmm11
	movq	%rdx,%r12
	shrdq	$5,%r14,%r14
	vpsrlq	$1,%xmm8,%xmm10
	xorq	%rcx,%r13
	xorq	%r8,%r12
	vpaddq	%xmm11,%xmm1,%xmm1
	shrdq	$4,%r13,%r13
	xorq	%r10,%r14
	vpsrlq	$7,%xmm8,%xmm11
	andq	%rcx,%r12
	xorq	%rcx,%r13
	vpsllq	$56,%xmm8,%xmm9
	addq	16(%rsp),%r9
	movq	%r10,%r15
	vpxor	%xmm10,%xmm11,%xmm8
	xorq	%r8,%r12
	shrdq	$6,%r14,%r14
	vpsrlq	$7,%xmm10,%xmm10
	xorq	%r11,%r15
	addq	%r12,%r9
	vpxor	%xmm9,%xmm8,%xmm8
	shrdq	$14,%r13,%r13
	andq	%r15,%rdi
	vpsllq	$7,%xmm9,%xmm9
	xorq	%r10,%r14
	addq	%r13,%r9
	vpxor	%xmm10,%xmm8,%xmm8
	xorq	%r11,%rdi
	shrdq	$28,%r14,%r14
	vpsrlq	$6,%xmm0,%xmm11
	addq	%r9,%rbx
	addq	%rdi,%r9
	vpxor	%xmm9,%xmm8,%xmm8
	movq	%rbx,%r13
	addq	%r9,%r14
	vpsllq	$3,%xmm0,%xmm10
	shrdq	$23,%r13,%r13
	movq	%r14,%r9
	vpaddq	%xmm8,%xmm1,%xmm1
	movq	%rcx,%r12
	shrdq	$5,%r14,%r14
	vpsrlq	$19,%xmm0,%xmm9
	xorq	%rbx,%r13
	xorq	%rdx,%r12
	vpxor	%xmm10,%xmm11,%xmm11
	shrdq	$4,%r13,%r13
	xorq	%r9,%r14
	vpsllq	$42,%xmm10,%xmm10
	andq	%rbx,%r12
	xorq	%rbx,%r13
	vpxor	%xmm9,%xmm11,%xmm11
	addq	24(%rsp),%r8
	movq	%r9,%rdi
	vpsrlq	$42,%xmm9,%xmm9
	xorq	%rdx,%r12
	shrdq	$6,%r14,%r14
	vpxor	%xmm10,%xmm11,%xmm11
	xorq	%r10,%rdi
	addq	%r12,%r8
	vpxor	%xmm9,%xmm11,%xmm11
	shrdq	$14,%r13,%r13
	andq	%rdi,%r15
	vpaddq	%xmm11,%xmm1,%xmm1
	xorq	%r9,%r14
	addq	%r13,%r8
	vpaddq	-96(%rbp),%xmm1,%xmm10
	xorq	%r10,%r15
	shrdq	$28,%r14,%r14
	addq	%r8,%rax
	addq	%r15,%r8
	movq	%rax,%r13
	addq	%r8,%r14
	vmovdqa	%xmm10,16(%rsp)
	vpalignr	$8,%xmm2,%xmm3,%xmm8
	shrdq	$23,%r13,%r13
	movq	%r14,%r8
	vpalignr	$8,%xmm6,%xmm7,%xmm11
	movq	%rbx,%r12
	shrdq	$5,%r14,%r14
	vpsrlq	$1,%xmm8,%xmm10
	xorq	%rax,%r13
	xorq	%rcx,%r12
	vpaddq	%xmm11,%xmm2,%xmm2
	shrdq	$4,%r13,%r13
	xorq	%r8,%r14
	vpsrlq	$7,%xmm8,%xmm11
	andq	%rax,%r12
	xorq	%rax,%r13
	vpsllq	$56,%xmm8,%xmm9
	addq	32(%rsp),%rdx
	movq	%r8,%r15
	vpxor	%xmm10,%xmm11,%xmm8
	xorq	%rcx,%r12
	shrdq	$6,%r14,%r14
	vpsrlq	$7,%xmm10,%xmm10
	xorq	%r9,%r15
	addq	%r12,%rdx
	vpxor	%xmm9,%xmm8,%xmm8
	shrdq	$14,%r13,%r13
	andq	%r15,%rdi
	vpsllq	$7,%xmm9,%xmm9
	xorq	%r8,%r14
	addq	%r13,%rdx
	vpxor	%xmm10,%xmm8,%xmm8
	xorq	%r9,%rdi
	shrdq	$28,%r14,%r14
	vpsrlq	$6,%xmm1,%xmm11
	addq	%rdx,%r11
	addq	%rdi,%rdx
	vpxor	%xmm9,%xmm8,%xmm8
	movq	%r11,%r13
	addq	%rdx,%r14
	vpsllq	$3,%xmm1,%xmm10
	shrdq	$23,%r13,%r13
	movq	%r14,%rdx
	vpaddq	%xmm8,%xmm2,%xmm2
	movq	%rax,%r12
	shrdq	$5,%r14,%r14
	vpsrlq	$19,%xmm1,%xmm9
	xorq	%r11,%r13
	xorq	%rbx,%r12
	vpxor	%xmm10,%xmm11,%xmm11
	shrdq	$4,%r13,%r13
	xorq	%rdx,%r14
	vpsllq	$42,%xmm10,%xmm10
	andq	%r11,%r12
	xorq	%r11,%r13
	vpxor	%xmm9,%xmm11,%xmm11
	addq	40(%rsp),%rcx
	movq	%rdx,%rdi
	vpsrlq	$42,%xmm9,%xmm9
	xorq	%rbx,%r12
	shrdq	$6,%r14,%r14
	vpxor	%xmm10,%xmm11,%xmm11
	xorq	%r8,%rdi
	addq	%r12,%rcx
	vpxor	%xmm9,%xmm11,%xmm11
	shrdq	$14,%r13,%r13
	andq	%rdi,%r15
	vpaddq	%xmm11,%xmm2,%xmm2
	xorq	%rdx,%r14
	addq	%r13,%rcx
	vpaddq	-64(%rbp),%xmm2,%xmm10
	xorq	%r8,%r15
	shrdq	$28,%r14,%r14
	addq	%rcx,%r10
	addq	%r15,%rcx
	movq	%r10,%r13
	addq	%rcx,%r14
	vmovdqa	%xmm10,32(%rsp)
	vpalignr	$8,%xmm3,%xmm4,%xmm8
	shrdq	$23,%r13,%r13
	movq	%r14,%rcx
	vpalignr	$8,%xmm7,%xmm0,%xmm11
	movq	%r11,%r12
	shrdq	$5,%r14,%r14
	vpsrlq	$1,%xmm8,%xmm10
	xorq	%r10,%r13
	xorq	%rax,%r12
	vpaddq	%xmm11,%xmm3,%xmm3
	shrdq	$4,%r13,%r13
	xorq	%rcx,%r14
	vpsrlq	$7,%xmm8,%xmm11
	andq	%r10,%r12
	xorq	%r10,%r13
	vpsllq	$56,%xmm8,%xmm9
	addq	48(%rsp),%rbx
	movq	%rcx,%r15
	vpxor	%xmm10,%xmm11,%xmm8
	xorq	%rax,%r12
	shrdq	$6,%r14,%r14
	vpsrlq	$7,%xmm10,%xmm10
	xorq	%rdx,%r15
	addq	%r12,%rbx
	vpxor	%xmm9,%xmm8,%xmm8
	shrdq	$14,%r13,%r13
	andq	%r15,%rdi
	vpsllq	$7,%xmm9,%xmm9
	xorq	%rcx,%r14
	addq	%r13,%rbx
	vpxor	%xmm10,%xmm8,%xmm8
	xorq	%rdx,%rdi
	shrdq	$28,%r14,%r14
	vpsrlq	$6,%xmm2,%xmm11
	addq	%rbx,%r9
	addq	%rdi,%rbx
	vpxor	%xmm9,%xmm8,%xmm8
	movq	%r9,%r13
	addq	%rbx,%r14
	vpsllq	$3,%xmm2,%xmm10
	shrdq	$23,%r13,%r13
	movq	%r14,%rbx
	vpaddq	%xmm8,%xmm3,%xmm3
	movq	%r10,%r12
	shrdq	$5,%r14,%r14
	vpsrlq	$19,%xmm2,%xmm9
	xorq	%r9,%r13
	xorq	%r11,%r12
	vpxor	%xmm10,%xmm11,%xmm11
	shrdq	$4,%r13,%r13
	xorq	%rbx,%r14
	vpsllq	$42,%xmm10,%xmm10
	andq	%r9,%r12
	xorq	%r9,%r13
	vpxor	%xmm9,%xmm11,%xmm11
	addq	56(%rsp),%rax
	movq	%rbx,%rdi
	vpsrlq	$42,%xmm9,%xmm9
	xorq	%r11,%r12
	shrdq	$6,%r14,%r14
	vpxor	%xmm10,%xmm11,%xmm11
	xorq	%rcx,%rdi
	addq	%r12,%rax
	vpxor	%xmm9,%xmm11,%xmm11
	shrdq	$14,%r13,%r13
	andq	%rdi,%r15
	vpaddq	%xmm11,%xmm3,%xmm3
	xorq	%rbx,%r14
	addq	%r13,%rax
	vpaddq	-32(%rbp),%xmm3,%xmm10
	xorq	%rcx,%r15
	shrdq	$28,%r14,%r14
	addq	%rax,%r8
	addq	%r15,%rax
	movq	%r8,%r13
	addq	%rax,%r14
	vmovdqa	%xmm10,48(%rsp)
	vpalignr	$8,%xmm4,%xmm5,%xmm8
	shrdq	$23,%r13,%r13
	movq	%r14,%rax
	vpalignr	$8,%xmm0,%xmm1,%xmm11
	movq	%r9,%r12
	shrdq	$5,%r14,%r14
	vpsrlq	$1,%xmm8,%xmm10
	xorq	%r8,%r13
	xorq	%r10,%r12
	vpaddq	%xmm11,%xmm4,%xmm4
	shrdq	$4,%r13,%r13
	xorq	%rax,%r14
	vpsrlq	$7,%xmm8,%xmm11
	andq	%r8,%r12
	xorq	%r8,%r13
	vpsllq	$56,%xmm8,%xmm9
	addq	64(%rsp),%r11
	movq	%rax,%r15
	vpxor	%xmm10,%xmm11,%xmm8
	xorq	%r10,%r12
	shrdq	$6,%r14,%r14
	vpsrlq	$7,%xmm10,%xmm10
	xorq	%rbx,%r15
	addq	%r12,%r11
	vpxor	%xmm9,%xmm8,%xmm8
	shrdq	$14,%r13,%r13
	andq	%r15,%rdi
	vpsllq	$7,%xmm9,%xmm9
	xorq	%rax,%r14
	addq	%r13,%r11
	vpxor	%xmm10,%xmm8,%xmm8
	xorq	%rbx,%rdi
	shrdq	$28,%r14,%r14
	vpsrlq	$6,%xmm3,%xmm11
	addq	%r11,%rdx
	addq	%rdi,%r11
	vpxor	%xmm9,%xmm8,%xmm8
	movq	%rdx,%r13
	addq	%r11,%r14
	vpsllq	$3,%xmm3,%xmm10
	shrdq	$23,%r13,%r13
	movq	%r14,%r11
	vpaddq	%xmm8,%xmm4,%xmm4
	movq	%r8,%r12
	shrdq	$5,%r14,%r14
	vpsrlq	$19,%xmm3,%xmm9
	xorq	%rdx,%r13
	xorq	%r9,%r12
	vpxor	%xmm10,%xmm11,%xmm11
	shrdq	$4,%r13,%r13
	xorq	%r11,%r14
	vpsllq	$42,%xmm10,%xmm10
	andq	%rdx,%r12
	xorq	%rdx,%r13
	vpxor	%xmm9,%xmm11,%xmm11
	addq	72(%rsp),%r10
	movq	%r11,%rdi
	vpsrlq	$42,%xmm9,%xmm9
	xorq	%r9,%r12
	shrdq	$6,%r14,%r14
	vpxor	%xmm10,%xmm11,%xmm11
	xorq	%rax,%rdi
	addq	%r12,%r10
	vpxor	%xmm9,%xmm11,%xmm11
	shrdq	$14,%r13,%r13
	andq	%rdi,%r15
	vpaddq	%xmm11,%xmm4,%xmm4
	xorq	%r11,%r14
	addq	%r13,%r10
	vpaddq	0(%rbp),%xmm4,%xmm10
	xorq	%rax,%r15
	shrdq	$28,%r14,%r14
	addq	%r10,%rcx
	addq	%r15,%r10
	movq	%rcx,%r13
	addq	%r10,%r14
	vmovdqa	%xmm10,64(%rsp)
	vpalignr	$8,%xmm5,%xmm6,%xmm8
	shrdq	$23,%r13,%r13
	movq	%r14,%r10
	vpalignr	$8,%xmm1,%xmm2,%xmm11
	movq	%rdx,%r12
	shrdq	$5,%r14,%r14
	vpsrlq	$1,%xmm8,%xmm10
	xorq	%rcx,%r13
	xorq	%r8,%r12
	vpaddq	%xmm11,%xmm5,%xmm5
	shrdq	$4,%r13,%r13
	xorq	%r10,%r14
	vpsrlq	$7,%xmm8,%xmm11
	andq	%rcx,%r12
	xorq	%rcx,%r13
	vpsllq	$56,%xmm8,%xmm9
	addq	80(%rsp),%r9
	movq	%r10,%r15
	vpxor	%xmm10,%xmm11,%xmm8
	xorq	%r8,%r12
	shrdq	$6,%r14,%r14
	vpsrlq	$7,%xmm10,%xmm10
	xorq	%r11,%r15
	addq	%r12,%r9
	vpxor	%xmm9,%xmm8,%xmm8
	shrdq	$14,%r13,%r13
	andq	%r15,%rdi
	vpsllq	$7,%xmm9,%xmm9
	xorq	%r10,%r14
	addq	%r13,%r9
	vpxor	%xmm10,%xmm8,%xmm8
	xorq	%r11,%rdi
	shrdq	$28,%r14,%r14
	vpsrlq	$6,%xmm4,%xmm11
	addq	%r9,%rbx
	addq	%rdi,%r9
	vpxor	%xmm9,%xmm8,%xmm8
	movq	%rbx,%r13
	addq	%r9,%r14
	vpsllq	$3,%xmm4,%xmm10
	shrdq	$23,%r13,%r13
	movq	%r14,%r9
	vpaddq	%xmm8,%xmm5,%xmm5
	movq	%rcx,%r12
	shrdq	$5,%r14,%r14
	vpsrlq	$19,%xmm4,%xmm9
	xorq	%rbx,%r13
	xorq	%rdx,%r12
	vpxor	%xmm10,%xmm11,%xmm11
	shrdq	$4,%r13,%r13
	xorq	%r9,%r14
	vpsllq	$42,%xmm10,%xmm10
	andq	%rbx,%r12
	xorq	%rbx,%r13
	vpxor	%xmm9,%xmm11,%xmm11
	addq	88(%rsp),%r8
	movq	%r9,%rdi
	vpsrlq	$42,%xmm9,%xmm9
	xorq	%rdx,%r12
	shrdq	$6,%r14,%r14
	vpxor	%xmm10,%xmm11,%xmm11
	xorq	%r10,%rdi
	addq	%r12,%r8
	vpxor	%xmm9,%xmm11,%xmm11
	shrdq	$14,%r13,%r13
	andq	%rdi,%r15
	vpaddq	%xmm11,%xmm5,%xmm5
	xorq	%r9,%r14
	addq	%r13,%r8
	vpaddq	32(%rbp),%xmm5,%xmm10
	xorq	%r10,%r15
	shrdq	$28,%r14,%r14
	addq	%r8,%rax
	addq	%r15,%r8
	movq	%rax,%r13
	addq	%r8,%r14
	vmovdqa	%xmm10,80(%rsp)
	vpalignr	$8,%xmm6,%xmm7,%xmm8
	shrdq	$23,%r13,%r13
	movq	%r14,%r8
	vpalignr	$8,%xmm2,%xmm3,%xmm11
	movq	%rbx,%r12
	shrdq	$5,%r14,%r14
	vpsrlq	$1,%xmm8,%xmm10
	xorq	%rax,%r13
	xorq	%rcx,%r12
	vpaddq	%xmm11,%xmm6,%xmm6
	shrdq	$4,%r13,%r13
	xorq	%r8,%r14
	vpsrlq	$7,%xmm8,%xmm11
	andq	%rax,%r12
	xorq	%rax,%r13
	vpsllq	$56,%xmm8,%xmm9
	addq	96(%rsp),%rdx
	movq	%r8,%r15
	vpxor	%xmm10,%xmm11,%xmm8
	xorq	%rcx,%r12
	shrdq	$6,%r14,%r14
	vpsrlq	$7,%xmm10,%xmm10
	xorq	%r9,%r15
	addq	%r12,%rdx
	vpxor	%xmm9,%xmm8,%xmm8
	shrdq	$14,%r13,%r13
	andq	%r15,%rdi
	vpsllq	$7,%xmm9,%xmm9
	xorq	%r8,%r14
	addq	%r13,%rdx
	vpxor	%xmm10,%xmm8,%xmm8
	xorq	%r9,%rdi
	shrdq	$28,%r14,%r14
	vpsrlq	$6,%xmm5,%xmm11
	addq	%rdx,%r11
	addq	%rdi,%rdx
	vpxor	%xmm9,%xmm8,%xmm8
	movq	%r11,%r13
	addq	%rdx,%r14
	vpsllq	$3,%xmm5,%xmm10
	shrdq	$23,%r13,%r13
	movq	%r14,%rdx
	vpaddq	%xmm8,%xmm6,%xmm6
	movq	%rax,%r12
	shrdq	$5,%r14,%r14
	vpsrlq	$19,%xmm5,%xmm9
	xorq	%r11,%r13
	xorq	%rbx,%r12
	vpxor	%xmm10,%xmm11,%xmm11
	shrdq	$4,%r13,%r13
	xorq	%rdx,%r14
	vpsllq	$42,%xmm10,%xmm10
	andq	%r11,%r12
	xorq	%r11,%r13
	vpxor	%xmm9,%xmm11,%xmm11
	addq	104(%rsp),%rcx
	movq	%rdx,%rdi
	vpsrlq	$42,%xmm9,%xmm9
	xorq	%rbx,%r12
	shrdq	$6,%r14,%r14
	vpxor	%xmm10,%xmm11,%xmm11
	xorq	%r8,%rdi
	addq	%r12,%rcx
	vpxor	%xmm9,%xmm11,%xmm11
	shrdq	$14,%r13,%r13
	andq	%rdi,%r15
	vpaddq	%xmm11,%xmm6,%xmm6
	xorq	%rdx,%r14
	addq	%r13,%rcx
	vpaddq	64(%rbp),%xmm6,%xmm10
	xorq	%r8,%r15
	shrdq	$28,%r14,%r14
	addq	%rcx,%r10
	addq	%r15,%rcx
	movq	%r10,%r13
	addq	%rcx,%r14
	vmovdqa	%xmm10,96(%rsp)
	vpalignr	$8,%xmm7,%xmm0,%xmm8
	shrdq	$23,%r13,%r13
	movq	%r14,%rcx
	vpalignr	$8,%xmm3,%xmm4,%xmm11
	movq	%r11,%r12
	shrdq	$5,%r14,%r14
	vpsrlq	$1,%xmm8,%xmm10
	xorq	%r10,%r13
	xorq	%rax,%r12
	vpaddq	%xmm11,%xmm7,%xmm7
	shrdq	$4,%r13,%r13
	xorq	%rcx,%r14
	vpsrlq	$7,%xmm8,%xmm11
	andq	%r10,%r12
	xorq	%r10,%r13
	vpsllq	$56,%xmm8,%xmm9
	addq	112(%rsp),%rbx
	movq	%rcx,%r15
	vpxor	%xmm10,%xmm11,%xmm8
	xorq	%rax,%r12
	shrdq	$6,%r14,%r14
	vpsrlq	$7,%xmm10,%xmm10
	xorq	%rdx,%r15
	addq	%r12,%rbx
	vpxor	%xmm9,%xmm8,%xmm8
	shrdq	$14,%r13,%r13
	andq	%r15,%rdi
	vpsllq	$7,%xmm9,%xmm9
	xorq	%rcx,%r14
	addq	%r13,%rbx
	vpxor	%xmm10,%xmm8,%xmm8
	xorq	%rdx,%rdi
	shrdq	$28,%r14,%r14
	vpsrlq	$6,%xmm6,%xmm11
	addq	%rbx,%r9
	addq	%rdi,%rbx
	vpxor	%xmm9,%xmm8,%xmm8
	movq	%r9,%r13
	addq	%rbx,%r14
	vpsllq	$3,%xmm6,%xmm10
	shrdq	$23,%r13,%r13
	movq	%r14,%rbx
	vpaddq	%xmm8,%xmm7,%xmm7
	movq	%r10,%r12
	shrdq	$5,%r14,%r14
	vpsrlq	$19,%xmm6,%xmm9
	xorq	%r9,%r13
	xorq	%r11,%r12
	vpxor	%xmm10,%xmm11,%xmm11
	shrdq	$4,%r13,%r13
	xorq	%rbx,%r14
	vpsllq	$42,%xmm10,%xmm10
	andq	%r9,%r12
	xorq	%r9,%r13
	vpxor	%xmm9,%xmm11,%xmm11
	addq	120(%rsp),%rax
	movq	%rbx,%rdi
	vpsrlq	$42,%xmm9,%xmm9
	xorq	%r11,%r12
	shrdq	$6,%r14,%r14
	vpxor	%xmm10,%xmm11,%xmm11
	xorq	%rcx,%rdi
	addq	%r12,%rax
	vpxor	%xmm9,%xmm11,%xmm11
	shrdq	$14,%r13,%r13
	andq	%rdi,%r15
	vpaddq	%xmm11,%xmm7,%xmm7
	xorq	%rbx,%r14
	addq	%r13,%rax
	vpaddq	96(%rbp),%xmm7,%xmm10
	xorq	%rcx,%r15
	shrdq	$28,%r14,%r14
	addq	%rax,%r8
	addq	%r15,%rax
	movq	%r8,%r13
	addq	%rax,%r14
	vmovdqa	%xmm10,112(%rsp)
	cmpb	$0,135(%rbp)
	jne	.Lavx_00_47
	shrdq	$23,%r13,%r13
	movq	%r14,%rax
	movq	%r9,%r12
	shrdq	$5,%r14,%r14
	xorq	%r8,%r13
	xorq	%r10,%r12
	shrdq	$4,%r13,%r13
	xorq	%rax,%r14
	andq	%r8,%r12
	xorq	%r8,%r13
	addq	0(%rsp),%r11
	movq	%rax,%r15
	xorq	%r10,%r12
	shrdq	$6,%r14,%r14
	xorq	%rbx,%r15
	addq	%r12,%r11
	shrdq	$14,%r13,%r13
	andq	%r15,%rdi
	xorq	%rax,%r14
	addq	%r13,%r11
	xorq	%rbx,%rdi
	shrdq	$28,%r14,%r14
	addq	%r11,%rdx
	addq	%rdi,%r11
	movq	%rdx,%r13
	addq	%r11,%r14
	shrdq	$23,%r13,%r13
	movq	%r14,%r11
	movq	%r8,%r12
	shrdq	$5,%r14,%r14
	xorq	%rdx,%r13
	xorq	%r9,%r12
	shrdq	$4,%r13,%r13
	xorq	%r11,%r14
	andq	%rdx,%r12
	xorq	%rdx,%r13
	addq	8(%rsp),%r10
	movq	%r11,%rdi
	xorq	%r9,%r12
	shrdq	$6,%r14,%r14
	xorq	%rax,%rdi
	addq	%r12,%r10
	shrdq	$14,%r13,%r13
	andq	%rdi,%r15
	xorq	%r11,%r14
	addq	%r13,%r10
	xorq	%rax,%r15
	shrdq	$28,%r14,%r14
	addq	%r10,%rcx
	addq	%r15,%r10
	movq	%rcx,%r13
	addq	%r10,%r14
	shrdq	$23,%r13,%r13
	movq	%r14,%r10
	movq	%rdx,%r12
	shrdq	$5,%r14,%r14
	xorq	%rcx,%r13
	xorq	%r8,%r12
	shrdq	$4,%r13,%r13
	xorq	%r10,%r14
	andq	%rcx,%r12
	xorq	%rcx,%r13
	addq	16(%rsp),%r9
	movq	%r10,%r15
	xorq	%r8,%r12
	shrdq	$6,%r14,%r14
	xorq	%r11,%r15
	addq	%r12,%r9
	shrdq	$14,%r13,%r13
	andq	%r15,%rdi
	xorq	%r10,%r14
	addq	%r13,%r9
	xorq	%r11,%rdi
	shrdq	$28,%r14,%r14
	addq	%r9,%rbx
	addq	%rdi,%r9
	movq	%rbx,%r13
	addq	%r9,%r14
	shrdq	$23,%r13,%r13
	movq	%r14,%r9
	movq	%rcx,%r12
	shrdq	$5,%r14,%r14
	xorq	%rbx,%r13
	xorq	%rdx,%r12
	shrdq	$4,%r13,%r13
	xorq	%r9,%r14
	andq	%rbx,%r12
	xorq	%rbx,%r13
	addq	24(%rsp),%r8
	movq	%r9,%rdi
	xorq	%rdx,%r12
	shrdq	$6,%r14,%r14
	xorq	%r10,%rdi
	addq	%r12,%r8
	shrdq	$14,%r13,%r13
	andq	%rdi,%r15
	xorq	%r9,%r14
	addq	%r13,%r8
	xorq	%r10,%r15
	shrdq	$28,%r14,%r14
	addq	%r8,%rax
	addq	%r15,%r8
	movq	%rax,%r13
	addq	%r8,%r14
	shrdq	$23,%r13,%r13
	movq	%r14,%r8
	movq	%rbx,%r12
	shrdq	$5,%r14,%r14
	xorq	%rax,%r13
	xorq	%rcx,%r12
	shrdq	$4,%r13,%r13
	xorq	%r8,%r14
	andq	%rax,%r12
	xorq	%rax,%r13
	addq	32(%rsp),%rdx
	movq	%r8,%r15
	xorq	%rcx,%r12
	shrdq	$6,%r14,%r14
	xorq	%r9,%r15
	addq	%r12,%rdx
	shrdq	$14,%r13,%r13
	andq	%r15,%rdi
	xorq	%r8,%r14
	addq	%r13,%rdx
	xorq	%r9,%rdi
	shrdq	$28,%r14,%r14
	addq	%rdx,%r11
	addq	%rdi,%rdx
	movq	%r11,%r13
	addq	%rdx,%r14
	shrdq	$23,%r13,%r13
	movq	%r14,%rdx
	movq	%rax,%r12
	shrdq	$5,%r14,%r14
	xorq	%r11,%r13
	xorq	%rbx,%r12
	shrdq	$4,%r13,%r13
	xorq	%rdx,%r14
	andq	%r11,%r12
	xorq	%r11,%r13
	addq	40(%rsp),%rcx
	movq	%rdx,%rdi
	xorq	%rbx,%r12
	shrdq	$6,%r14,%r14
	xorq	%r8,%rdi
	addq	%r12,%rcx
	shrdq	$14,%r13,%r13
	andq	%rdi,%r15
	xorq	%rdx,%r14
	addq	%r13,%rcx
	xorq	%r8,%r15
	shrdq	$28,%r14,%r14
	addq	%rcx,%r10
	addq	%r15,%rcx
	movq	%r10,%r13
	addq	%rcx,%r14
	shrdq	$23,%r13,%r13
	movq	%r14,%rcx
	movq	%r11,%r12
	shrdq	$5,%r14,%r14
	xorq	%r10,%r13
	xorq	%rax,%r12
	shrdq	$4,%r13,%r13
	xorq	%rcx,%r14
	andq	%r10,%r12
	xorq	%r10,%r13
	addq	48(%rsp),%rbx
	movq	%rcx,%r15
	xorq	%rax,%r12
	shrdq	$6,%r14,%r14
	xorq	%rdx,%r15
	addq	%r12,%rbx
	shrdq	$14,%r13,%r13
	andq	%r15,%rdi
	xorq	%rcx,%r14
	addq	%r13,%rbx
	xorq	%rdx,%rdi
	shrdq	$28,%r14,%r14
	addq	%rbx,%r9
	addq	%rdi,%rbx
	movq	%r9,%r13
	addq	%rbx,%r14
	shrdq	$23,%r13,%r13
	movq	%r14,%rbx
	movq	%r10,%r12
	shrdq	$5,%r14,%r14
	xorq	%r9,%r13
	xorq	%r11,%r12
	shrdq	$4,%r13,%r13
	xorq	%rbx,%r14
	andq	%r9,%r12
	xorq	%r9,%r13
	addq	56(%rsp),%rax
	movq	%rbx,%rdi
	xorq	%r11,%r12
	shrdq	$6,%r14,%r14
	xorq	%rcx,%rdi
	addq	%r12,%rax
	shrdq	$14,%r13,%r13
	andq	%rdi,%r15
	xorq	%rbx,%r14
	addq	%r13,%rax
	xorq	%rcx,%r15
	shrdq	$28,%r14,%r14
	addq	%rax,%r8
	addq	%r15,%rax
	movq	%r8,%r13
	addq	%rax,%r14
	shrdq	$23,%r13,%r13
	movq	%r14,%rax
	movq	%r9,%r12
	shrdq	$5,%r14,%r14
	xorq	%r8,%r13
	xorq	%r10,%r12
	shrdq	$4,%r13,%r13
	xorq	%rax,%r14
	andq	%r8,%r12
	xorq	%r8,%r13
	addq	64(%rsp),%r11
	movq	%rax,%r15
	xorq	%r10,%r12
	shrdq	$6,%r14,%r14
	xorq	%rbx,%r15
	addq	%r12,%r11
	shrdq	$14,%r13,%r13
	andq	%r15,%rdi
	xorq	%rax,%r14
	addq	%r13,%r11
	xorq	%rbx,%rdi
	shrdq	$28,%r14,%r14
	addq	%r11,%rdx
	addq	%rdi,%r11
	movq	%rdx,%r13
	addq	%r11,%r14
	shrdq	$23,%r13,%r13
	movq	%r14,%r11
	movq	%r8,%r12
	shrdq	$5,%r14,%r14
	xorq	%rdx,%r13
	xorq	%r9,%r12
	shrdq	$4,%r13,%r13
	xorq	%r11,%r14
	andq	%rdx,%r12
	xorq	%rdx,%r13
	addq	72(%rsp),%r10
	movq	%r11,%rdi
	xorq	%r9,%r12
	shrdq	$6,%r14,%r14
	xorq	%rax,%rdi
	addq	%r12,%r10
	shrdq	$14,%r13,%r13
	andq	%rdi,%r15
	xorq	%r11,%r14
	addq	%r13,%r10
	xorq	%rax,%r15
	shrdq	$28,%r14,%r14
	addq	%r10,%rcx
	addq	%r15,%r10
	movq	%rcx,%r13
	addq	%r10,%r14
	shrdq	$23,%r13,%r13
	movq	%r14,%r10
	movq	%rdx,%r12
	shrdq	$5,%r14,%r14
	xorq	%rcx,%r13
	xorq	%r8,%r12
	shrdq	$4,%r13,%r13
	xorq	%r10,%r14
	andq	%rcx,%r12
	xorq	%rcx,%r13
	addq	80(%rsp),%r9
	movq	%r10,%r15
	xorq	%r8,%r12
	shrdq	$6,%r14,%r14
	xorq	%r11,%r15
	addq	%r12,%r9
	shrdq	$14,%r13,%r13
	andq	%r15,%rdi
	xorq	%r10,%r14
	addq	%r13,%r9
	xorq	%r11,%rdi
	shrdq	$28,%r14,%r14
	addq	%r9,%rbx
	addq	%rdi,%r9
	movq	%rbx,%r13
	addq	%r9,%r14
	shrdq	$23,%r13,%r13
	movq	%r14,%r9
	movq	%rcx,%r12
	shrdq	$5,%r14,%r14
	xorq	%rbx,%r13
	xorq	%rdx,%r12
	shrdq	$4,%r13,%r13
	xorq	%r9,%r14
	andq	%rbx,%r12
	xorq	%rbx,%r13
	addq	88(%rsp),%r8
	movq	%r9,%rdi
	xorq	%rdx,%r12
	shrdq	$6,%r14,%r14
	xorq	%r10,%rdi
	addq	%r12,%r8
	shrdq	$14,%r13,%r13
	andq	%rdi,%r15
	xorq	%r9,%r14
	addq	%r13,%r8
	xorq	%r10,%r15
	shrdq	$28,%r14,%r14
	addq	%r8,%rax
	addq	%r15,%r8
	movq	%rax,%r13
	addq	%r8,%r14
	shrdq	$23,%r13,%r13
	movq	%r14,%r8
	movq	%rbx,%r12
	shrdq	$5,%r14,%r14
	xorq	%rax,%r13
	xorq	%rcx,%r12
	shrdq	$4,%r13,%r13
	xorq	%r8,%r14
	andq	%rax,%r12
	xorq	%rax,%r13
	addq	96(%rsp),%rdx
	movq	%r8,%r15
	xorq	%rcx,%r12
	shrdq	$6,%r14,%r14
	xorq	%r9,%r15
	addq	%r12,%rdx
	shrdq	$14,%r13,%r13
	andq	%r15,%rdi
	xorq	%r8,%r14
	addq	%r13,%rdx
	xorq	%r9,%rdi
	shrdq	$28,%r14,%r14
	addq	%rdx,%r11
	addq	%rdi,%rdx
	movq	%r11,%r13
	addq	%rdx,%r14
	shrdq	$23,%r13,%r13
	movq	%r14,%rdx
	movq	%rax,%r12
	shrdq	$5,%r14,%r14
	xorq	%r11,%r13
	xorq	%rbx,%r12
	shrdq	$4,%r13,%r13
	xorq	%rdx,%r14
	andq	%r11,%r12
	xorq	%r11,%r13
	addq	104(%rsp),%rcx
	movq	%rdx,%rdi
	xorq	%rbx,%r12
	shrdq	$6,%r14,%r14
	xorq	%r8,%rdi
	addq	%r12,%rcx
	shrdq	$14,%r13,%r13
	andq	%rdi,%r15
	xorq	%rdx,%r14
	addq	%r13,%rcx
	xorq	%r8,%r15
	shrdq	$28,%r14,%r14
	addq	%rcx,%r10
	addq	%r15,%rcx
	movq	%r10,%r13
	addq	%rcx,%r14
	shrdq	$23,%r13,%r13
	movq	%r14,%rcx
	movq	%r11,%r12
	shrdq	$5,%r14,%r14
	xorq	%r10,%r13
	xorq	%rax,%r12
	shrdq	$4,%r13,%r13
	xorq	%rcx,%r14
	andq	%r10,%r12
	xorq	%r10,%r13
	addq	112(%rsp),%rbx
	movq	%rcx,%r15
	xorq	%rax,%r12
	shrdq	$6,%r14,%r14
	xorq	%rdx,%r15
	addq	%r12,%rbx
	shrdq	$14,%r13,%r13
	andq	%r15,%rdi
	xorq	%rcx,%r14
	addq	%r13,%rbx
	xorq	%rdx,%rdi
	shrdq	$28,%r14,%r14
	addq	%rbx,%r9
	addq	%rdi,%rbx
	movq	%r9,%r13
	addq	%rbx,%r14
	shrdq	$23,%r13,%r13
	movq	%r14,%rbx
	movq	%r10,%r12
	shrdq	$5,%r14,%r14
	xorq	%r9,%r13
	xorq	%r11,%r12
	shrdq	$4,%r13,%r13
	xorq	%rbx,%r14
	andq	%r9,%r12
	xorq	%r9,%r13
	addq	120(%rsp),%rax
	movq	%rbx,%rdi
	xorq	%r11,%r12
	shrdq	$6,%r14,%r14
	xorq	%rcx,%rdi
	addq	%r12,%rax
	shrdq	$14,%r13,%r13
	andq	%rdi,%r15
	xorq	%rbx,%r14
	addq	%r13,%rax
	xorq	%rcx,%r15
	shrdq	$28,%r14,%r14
	addq	%rax,%r8
	addq	%r15,%rax
	movq	%r8,%r13
	addq	%rax,%r14
	movq	128+0(%rsp),%rdi
	movq	%r14,%rax

	addq	0(%rdi),%rax
	leaq	128(%rsi),%rsi
	addq	8(%rdi),%rbx
	addq	16(%rdi),%rcx
	addq	24(%rdi),%rdx
	addq	32(%rdi),%r8
	addq	40(%rdi),%r9
	addq	48(%rdi),%r10
	addq	56(%rdi),%r11

	cmpq	128+16(%rsp),%rsi

	movq	%rax,0(%rdi)
	movq	%rbx,8(%rdi)
	movq	%rcx,16(%rdi)
	movq	%rdx,24(%rdi)
	movq	%r8,32(%rdi)
	movq	%r9,40(%rdi)
	movq	%r10,48(%rdi)
	movq	%r11,56(%rdi)
	jb	.Lloop_avx

	movq	152(%rsp),%rsi
.cfi_def_cfa	%rsi,8
	vzeroupper
	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue_avx:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha512_block_data_order_avx,.-sha512_block_data_order_avx
.type	sha512_block_data_order_avx2,@function
.align	64
sha512_block_data_order_avx2:
.cfi_startproc	
.Lavx2_shortcut:
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56
	subq	$1312,%rsp
	shlq	$4,%rdx
	andq	$-2048,%rsp
	leaq	(%rsi,%rdx,8),%rdx
	addq	$1152,%rsp
	movq	%rdi,128+0(%rsp)
	movq	%rsi,128+8(%rsp)
	movq	%rdx,128+16(%rsp)
	movq	%rax,152(%rsp)
.cfi_escape	0x0f,0x06,0x77,0x98,0x01,0x06,0x23,0x08
.Lprologue_avx2:

	vzeroupper
	subq	$-128,%rsi
	movq	0(%rdi),%rax
	movq	%rsi,%r12
	movq	8(%rdi),%rbx
	cmpq	%rdx,%rsi
	movq	16(%rdi),%rcx
	cmoveq	%rsp,%r12
	movq	24(%rdi),%rdx
	movq	32(%rdi),%r8
	movq	40(%rdi),%r9
	movq	48(%rdi),%r10
	movq	56(%rdi),%r11
	jmp	.Loop_avx2
.align	16
.Loop_avx2:
	vmovdqu	-128(%rsi),%xmm0
	vmovdqu	-128+16(%rsi),%xmm1
	vmovdqu	-128+32(%rsi),%xmm2
	leaq	K512+128(%rip),%rbp
	vmovdqu	-128+48(%rsi),%xmm3
	vmovdqu	-128+64(%rsi),%xmm4
	vmovdqu	-128+80(%rsi),%xmm5
	vmovdqu	-128+96(%rsi),%xmm6
	vmovdqu	-128+112(%rsi),%xmm7

	vmovdqa	1152(%rbp),%ymm10
	vinserti128	$1,(%r12),%ymm0,%ymm0
	vinserti128	$1,16(%r12),%ymm1,%ymm1
	vpshufb	%ymm10,%ymm0,%ymm0
	vinserti128	$1,32(%r12),%ymm2,%ymm2
	vpshufb	%ymm10,%ymm1,%ymm1
	vinserti128	$1,48(%r12),%ymm3,%ymm3
	vpshufb	%ymm10,%ymm2,%ymm2
	vinserti128	$1,64(%r12),%ymm4,%ymm4
	vpshufb	%ymm10,%ymm3,%ymm3
	vinserti128	$1,80(%r12),%ymm5,%ymm5
	vpshufb	%ymm10,%ymm4,%ymm4
	vinserti128	$1,96(%r12),%ymm6,%ymm6
	vpshufb	%ymm10,%ymm5,%ymm5
	vinserti128	$1,112(%r12),%ymm7,%ymm7

	vpaddq	-128(%rbp),%ymm0,%ymm8
	vpshufb	%ymm10,%ymm6,%ymm6
	vpaddq	-96(%rbp),%ymm1,%ymm9
	vpshufb	%ymm10,%ymm7,%ymm7
	vpaddq	-64(%rbp),%ymm2,%ymm10
	vpaddq	-32(%rbp),%ymm3,%ymm11
	vmovdqa	%ymm8,0(%rsp)
	vpaddq	0(%rbp),%ymm4,%ymm8
	vmovdqa	%ymm9,32(%rsp)
	vpaddq	32(%rbp),%ymm5,%ymm9
	vmovdqa	%ymm10,64(%rsp)
	vpaddq	64(%rbp),%ymm6,%ymm10
	vmovdqa	%ymm11,96(%rsp)

	movq	152(%rsp),%rdi
.cfi_def_cfa	%rdi,8
	leaq	-128(%rsp),%rsp



	movq	%rdi,-8(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x78,0x06,0x23,0x08
	vpaddq	96(%rbp),%ymm7,%ymm11
	vmovdqa	%ymm8,0(%rsp)
	xorq	%r14,%r14
	vmovdqa	%ymm9,32(%rsp)
	movq	%rbx,%rdi
	vmovdqa	%ymm10,64(%rsp)
	xorq	%rcx,%rdi
	vmovdqa	%ymm11,96(%rsp)
	movq	%r9,%r12
	addq	$32*8,%rbp
	jmp	.Lavx2_00_47

.align	16
.Lavx2_00_47:
	leaq	-128(%rsp),%rsp
.cfi_escape	0x0f,0x06,0x77,0xf8,0x00,0x06,0x23,0x08

	pushq	128-8(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x00,0x06,0x23,0x08
	leaq	8(%rsp),%rsp
.cfi_escape	0x0f,0x05,0x77,0x78,0x06,0x23,0x08
	vpalignr	$8,%ymm0,%ymm1,%ymm8
	addq	0+256(%rsp),%r11
	andq	%r8,%r12
	rorxq	$41,%r8,%r13
	vpalignr	$8,%ymm4,%ymm5,%ymm11
	rorxq	$18,%r8,%r15
	leaq	(%rax,%r14,1),%rax
	leaq	(%r11,%r12,1),%r11
	vpsrlq	$1,%ymm8,%ymm10
	andnq	%r10,%r8,%r12
	xorq	%r15,%r13
	rorxq	$14,%r8,%r14
	vpaddq	%ymm11,%ymm0,%ymm0
	vpsrlq	$7,%ymm8,%ymm11
	leaq	(%r11,%r12,1),%r11
	xorq	%r14,%r13
	movq	%rax,%r15
	vpsllq	$56,%ymm8,%ymm9
	vpxor	%ymm10,%ymm11,%ymm8
	rorxq	$39,%rax,%r12
	leaq	(%r11,%r13,1),%r11
	xorq	%rbx,%r15
	vpsrlq	$7,%ymm10,%ymm10
	vpxor	%ymm9,%ymm8,%ymm8
	rorxq	$34,%rax,%r14
	rorxq	$28,%rax,%r13
	leaq	(%rdx,%r11,1),%rdx
	vpsllq	$7,%ymm9,%ymm9
	vpxor	%ymm10,%ymm8,%ymm8
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%rbx,%rdi
	vpsrlq	$6,%ymm7,%ymm11
	vpxor	%ymm9,%ymm8,%ymm8
	xorq	%r13,%r14
	leaq	(%r11,%rdi,1),%r11
	movq	%r8,%r12
	vpsllq	$3,%ymm7,%ymm10
	vpaddq	%ymm8,%ymm0,%ymm0
	addq	8+256(%rsp),%r10
	andq	%rdx,%r12
	rorxq	$41,%rdx,%r13
	vpsrlq	$19,%ymm7,%ymm9
	vpxor	%ymm10,%ymm11,%ymm11
	rorxq	$18,%rdx,%rdi
	leaq	(%r11,%r14,1),%r11
	leaq	(%r10,%r12,1),%r10
	vpsllq	$42,%ymm10,%ymm10
	vpxor	%ymm9,%ymm11,%ymm11
	andnq	%r9,%rdx,%r12
	xorq	%rdi,%r13
	rorxq	$14,%rdx,%r14
	vpsrlq	$42,%ymm9,%ymm9
	vpxor	%ymm10,%ymm11,%ymm11
	leaq	(%r10,%r12,1),%r10
	xorq	%r14,%r13
	movq	%r11,%rdi
	vpxor	%ymm9,%ymm11,%ymm11
	rorxq	$39,%r11,%r12
	leaq	(%r10,%r13,1),%r10
	xorq	%rax,%rdi
	vpaddq	%ymm11,%ymm0,%ymm0
	rorxq	$34,%r11,%r14
	rorxq	$28,%r11,%r13
	leaq	(%rcx,%r10,1),%rcx
	vpaddq	-128(%rbp),%ymm0,%ymm10
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%rax,%r15
	xorq	%r13,%r14
	leaq	(%r10,%r15,1),%r10
	movq	%rdx,%r12
	vmovdqa	%ymm10,0(%rsp)
	vpalignr	$8,%ymm1,%ymm2,%ymm8
	addq	32+256(%rsp),%r9
	andq	%rcx,%r12
	rorxq	$41,%rcx,%r13
	vpalignr	$8,%ymm5,%ymm6,%ymm11
	rorxq	$18,%rcx,%r15
	leaq	(%r10,%r14,1),%r10
	leaq	(%r9,%r12,1),%r9
	vpsrlq	$1,%ymm8,%ymm10
	andnq	%r8,%rcx,%r12
	xorq	%r15,%r13
	rorxq	$14,%rcx,%r14
	vpaddq	%ymm11,%ymm1,%ymm1
	vpsrlq	$7,%ymm8,%ymm11
	leaq	(%r9,%r12,1),%r9
	xorq	%r14,%r13
	movq	%r10,%r15
	vpsllq	$56,%ymm8,%ymm9
	vpxor	%ymm10,%ymm11,%ymm8
	rorxq	$39,%r10,%r12
	leaq	(%r9,%r13,1),%r9
	xorq	%r11,%r15
	vpsrlq	$7,%ymm10,%ymm10
	vpxor	%ymm9,%ymm8,%ymm8
	rorxq	$34,%r10,%r14
	rorxq	$28,%r10,%r13
	leaq	(%rbx,%r9,1),%rbx
	vpsllq	$7,%ymm9,%ymm9
	vpxor	%ymm10,%ymm8,%ymm8
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%r11,%rdi
	vpsrlq	$6,%ymm0,%ymm11
	vpxor	%ymm9,%ymm8,%ymm8
	xorq	%r13,%r14
	leaq	(%r9,%rdi,1),%r9
	movq	%rcx,%r12
	vpsllq	$3,%ymm0,%ymm10
	vpaddq	%ymm8,%ymm1,%ymm1
	addq	40+256(%rsp),%r8
	andq	%rbx,%r12
	rorxq	$41,%rbx,%r13
	vpsrlq	$19,%ymm0,%ymm9
	vpxor	%ymm10,%ymm11,%ymm11
	rorxq	$18,%rbx,%rdi
	leaq	(%r9,%r14,1),%r9
	leaq	(%r8,%r12,1),%r8
	vpsllq	$42,%ymm10,%ymm10
	vpxor	%ymm9,%ymm11,%ymm11
	andnq	%rdx,%rbx,%r12
	xorq	%rdi,%r13
	rorxq	$14,%rbx,%r14
	vpsrlq	$42,%ymm9,%ymm9
	vpxor	%ymm10,%ymm11,%ymm11
	leaq	(%r8,%r12,1),%r8
	xorq	%r14,%r13
	movq	%r9,%rdi
	vpxor	%ymm9,%ymm11,%ymm11
	rorxq	$39,%r9,%r12
	leaq	(%r8,%r13,1),%r8
	xorq	%r10,%rdi
	vpaddq	%ymm11,%ymm1,%ymm1
	rorxq	$34,%r9,%r14
	rorxq	$28,%r9,%r13
	leaq	(%rax,%r8,1),%rax
	vpaddq	-96(%rbp),%ymm1,%ymm10
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%r10,%r15
	xorq	%r13,%r14
	leaq	(%r8,%r15,1),%r8
	movq	%rbx,%r12
	vmovdqa	%ymm10,32(%rsp)
	vpalignr	$8,%ymm2,%ymm3,%ymm8
	addq	64+256(%rsp),%rdx
	andq	%rax,%r12
	rorxq	$41,%rax,%r13
	vpalignr	$8,%ymm6,%ymm7,%ymm11
	rorxq	$18,%rax,%r15
	leaq	(%r8,%r14,1),%r8
	leaq	(%rdx,%r12,1),%rdx
	vpsrlq	$1,%ymm8,%ymm10
	andnq	%rcx,%rax,%r12
	xorq	%r15,%r13
	rorxq	$14,%rax,%r14
	vpaddq	%ymm11,%ymm2,%ymm2
	vpsrlq	$7,%ymm8,%ymm11
	leaq	(%rdx,%r12,1),%rdx
	xorq	%r14,%r13
	movq	%r8,%r15
	vpsllq	$56,%ymm8,%ymm9
	vpxor	%ymm10,%ymm11,%ymm8
	rorxq	$39,%r8,%r12
	leaq	(%rdx,%r13,1),%rdx
	xorq	%r9,%r15
	vpsrlq	$7,%ymm10,%ymm10
	vpxor	%ymm9,%ymm8,%ymm8
	rorxq	$34,%r8,%r14
	rorxq	$28,%r8,%r13
	leaq	(%r11,%rdx,1),%r11
	vpsllq	$7,%ymm9,%ymm9
	vpxor	%ymm10,%ymm8,%ymm8
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%r9,%rdi
	vpsrlq	$6,%ymm1,%ymm11
	vpxor	%ymm9,%ymm8,%ymm8
	xorq	%r13,%r14
	leaq	(%rdx,%rdi,1),%rdx
	movq	%rax,%r12
	vpsllq	$3,%ymm1,%ymm10
	vpaddq	%ymm8,%ymm2,%ymm2
	addq	72+256(%rsp),%rcx
	andq	%r11,%r12
	rorxq	$41,%r11,%r13
	vpsrlq	$19,%ymm1,%ymm9
	vpxor	%ymm10,%ymm11,%ymm11
	rorxq	$18,%r11,%rdi
	leaq	(%rdx,%r14,1),%rdx
	leaq	(%rcx,%r12,1),%rcx
	vpsllq	$42,%ymm10,%ymm10
	vpxor	%ymm9,%ymm11,%ymm11
	andnq	%rbx,%r11,%r12
	xorq	%rdi,%r13
	rorxq	$14,%r11,%r14
	vpsrlq	$42,%ymm9,%ymm9
	vpxor	%ymm10,%ymm11,%ymm11
	leaq	(%rcx,%r12,1),%rcx
	xorq	%r14,%r13
	movq	%rdx,%rdi
	vpxor	%ymm9,%ymm11,%ymm11
	rorxq	$39,%rdx,%r12
	leaq	(%rcx,%r13,1),%rcx
	xorq	%r8,%rdi
	vpaddq	%ymm11,%ymm2,%ymm2
	rorxq	$34,%rdx,%r14
	rorxq	$28,%rdx,%r13
	leaq	(%r10,%rcx,1),%r10
	vpaddq	-64(%rbp),%ymm2,%ymm10
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%r8,%r15
	xorq	%r13,%r14
	leaq	(%rcx,%r15,1),%rcx
	movq	%r11,%r12
	vmovdqa	%ymm10,64(%rsp)
	vpalignr	$8,%ymm3,%ymm4,%ymm8
	addq	96+256(%rsp),%rbx
	andq	%r10,%r12
	rorxq	$41,%r10,%r13
	vpalignr	$8,%ymm7,%ymm0,%ymm11
	rorxq	$18,%r10,%r15
	leaq	(%rcx,%r14,1),%rcx
	leaq	(%rbx,%r12,1),%rbx
	vpsrlq	$1,%ymm8,%ymm10
	andnq	%rax,%r10,%r12
	xorq	%r15,%r13
	rorxq	$14,%r10,%r14
	vpaddq	%ymm11,%ymm3,%ymm3
	vpsrlq	$7,%ymm8,%ymm11
	leaq	(%rbx,%r12,1),%rbx
	xorq	%r14,%r13
	movq	%rcx,%r15
	vpsllq	$56,%ymm8,%ymm9
	vpxor	%ymm10,%ymm11,%ymm8
	rorxq	$39,%rcx,%r12
	leaq	(%rbx,%r13,1),%rbx
	xorq	%rdx,%r15
	vpsrlq	$7,%ymm10,%ymm10
	vpxor	%ymm9,%ymm8,%ymm8
	rorxq	$34,%rcx,%r14
	rorxq	$28,%rcx,%r13
	leaq	(%r9,%rbx,1),%r9
	vpsllq	$7,%ymm9,%ymm9
	vpxor	%ymm10,%ymm8,%ymm8
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%rdx,%rdi
	vpsrlq	$6,%ymm2,%ymm11
	vpxor	%ymm9,%ymm8,%ymm8
	xorq	%r13,%r14
	leaq	(%rbx,%rdi,1),%rbx
	movq	%r10,%r12
	vpsllq	$3,%ymm2,%ymm10
	vpaddq	%ymm8,%ymm3,%ymm3
	addq	104+256(%rsp),%rax
	andq	%r9,%r12
	rorxq	$41,%r9,%r13
	vpsrlq	$19,%ymm2,%ymm9
	vpxor	%ymm10,%ymm11,%ymm11
	rorxq	$18,%r9,%rdi
	leaq	(%rbx,%r14,1),%rbx
	leaq	(%rax,%r12,1),%rax
	vpsllq	$42,%ymm10,%ymm10
	vpxor	%ymm9,%ymm11,%ymm11
	andnq	%r11,%r9,%r12
	xorq	%rdi,%r13
	rorxq	$14,%r9,%r14
	vpsrlq	$42,%ymm9,%ymm9
	vpxor	%ymm10,%ymm11,%ymm11
	leaq	(%rax,%r12,1),%rax
	xorq	%r14,%r13
	movq	%rbx,%rdi
	vpxor	%ymm9,%ymm11,%ymm11
	rorxq	$39,%rbx,%r12
	leaq	(%rax,%r13,1),%rax
	xorq	%rcx,%rdi
	vpaddq	%ymm11,%ymm3,%ymm3
	rorxq	$34,%rbx,%r14
	rorxq	$28,%rbx,%r13
	leaq	(%r8,%rax,1),%r8
	vpaddq	-32(%rbp),%ymm3,%ymm10
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%rcx,%r15
	xorq	%r13,%r14
	leaq	(%rax,%r15,1),%rax
	movq	%r9,%r12
	vmovdqa	%ymm10,96(%rsp)
	leaq	-128(%rsp),%rsp
.cfi_escape	0x0f,0x06,0x77,0xf8,0x00,0x06,0x23,0x08

	pushq	128-8(%rsp)
.cfi_escape	0x0f,0x05,0x77,0x00,0x06,0x23,0x08
	leaq	8(%rsp),%rsp
.cfi_escape	0x0f,0x05,0x77,0x78,0x06,0x23,0x08
	vpalignr	$8,%ymm4,%ymm5,%ymm8
	addq	0+256(%rsp),%r11
	andq	%r8,%r12
	rorxq	$41,%r8,%r13
	vpalignr	$8,%ymm0,%ymm1,%ymm11
	rorxq	$18,%r8,%r15
	leaq	(%rax,%r14,1),%rax
	leaq	(%r11,%r12,1),%r11
	vpsrlq	$1,%ymm8,%ymm10
	andnq	%r10,%r8,%r12
	xorq	%r15,%r13
	rorxq	$14,%r8,%r14
	vpaddq	%ymm11,%ymm4,%ymm4
	vpsrlq	$7,%ymm8,%ymm11
	leaq	(%r11,%r12,1),%r11
	xorq	%r14,%r13
	movq	%rax,%r15
	vpsllq	$56,%ymm8,%ymm9
	vpxor	%ymm10,%ymm11,%ymm8
	rorxq	$39,%rax,%r12
	leaq	(%r11,%r13,1),%r11
	xorq	%rbx,%r15
	vpsrlq	$7,%ymm10,%ymm10
	vpxor	%ymm9,%ymm8,%ymm8
	rorxq	$34,%rax,%r14
	rorxq	$28,%rax,%r13
	leaq	(%rdx,%r11,1),%rdx
	vpsllq	$7,%ymm9,%ymm9
	vpxor	%ymm10,%ymm8,%ymm8
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%rbx,%rdi
	vpsrlq	$6,%ymm3,%ymm11
	vpxor	%ymm9,%ymm8,%ymm8
	xorq	%r13,%r14
	leaq	(%r11,%rdi,1),%r11
	movq	%r8,%r12
	vpsllq	$3,%ymm3,%ymm10
	vpaddq	%ymm8,%ymm4,%ymm4
	addq	8+256(%rsp),%r10
	andq	%rdx,%r12
	rorxq	$41,%rdx,%r13
	vpsrlq	$19,%ymm3,%ymm9
	vpxor	%ymm10,%ymm11,%ymm11
	rorxq	$18,%rdx,%rdi
	leaq	(%r11,%r14,1),%r11
	leaq	(%r10,%r12,1),%r10
	vpsllq	$42,%ymm10,%ymm10
	vpxor	%ymm9,%ymm11,%ymm11
	andnq	%r9,%rdx,%r12
	xorq	%rdi,%r13
	rorxq	$14,%rdx,%r14
	vpsrlq	$42,%ymm9,%ymm9
	vpxor	%ymm10,%ymm11,%ymm11
	leaq	(%r10,%r12,1),%r10
	xorq	%r14,%r13
	movq	%r11,%rdi
	vpxor	%ymm9,%ymm11,%ymm11
	rorxq	$39,%r11,%r12
	leaq	(%r10,%r13,1),%r10
	xorq	%rax,%rdi
	vpaddq	%ymm11,%ymm4,%ymm4
	rorxq	$34,%r11,%r14
	rorxq	$28,%r11,%r13
	leaq	(%rcx,%r10,1),%rcx
	vpaddq	0(%rbp),%ymm4,%ymm10
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%rax,%r15
	xorq	%r13,%r14
	leaq	(%r10,%r15,1),%r10
	movq	%rdx,%r12
	vmovdqa	%ymm10,0(%rsp)
	vpalignr	$8,%ymm5,%ymm6,%ymm8
	addq	32+256(%rsp),%r9
	andq	%rcx,%r12
	rorxq	$41,%rcx,%r13
	vpalignr	$8,%ymm1,%ymm2,%ymm11
	rorxq	$18,%rcx,%r15
	leaq	(%r10,%r14,1),%r10
	leaq	(%r9,%r12,1),%r9
	vpsrlq	$1,%ymm8,%ymm10
	andnq	%r8,%rcx,%r12
	xorq	%r15,%r13
	rorxq	$14,%rcx,%r14
	vpaddq	%ymm11,%ymm5,%ymm5
	vpsrlq	$7,%ymm8,%ymm11
	leaq	(%r9,%r12,1),%r9
	xorq	%r14,%r13
	movq	%r10,%r15
	vpsllq	$56,%ymm8,%ymm9
	vpxor	%ymm10,%ymm11,%ymm8
	rorxq	$39,%r10,%r12
	leaq	(%r9,%r13,1),%r9
	xorq	%r11,%r15
	vpsrlq	$7,%ymm10,%ymm10
	vpxor	%ymm9,%ymm8,%ymm8
	rorxq	$34,%r10,%r14
	rorxq	$28,%r10,%r13
	leaq	(%rbx,%r9,1),%rbx
	vpsllq	$7,%ymm9,%ymm9
	vpxor	%ymm10,%ymm8,%ymm8
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%r11,%rdi
	vpsrlq	$6,%ymm4,%ymm11
	vpxor	%ymm9,%ymm8,%ymm8
	xorq	%r13,%r14
	leaq	(%r9,%rdi,1),%r9
	movq	%rcx,%r12
	vpsllq	$3,%ymm4,%ymm10
	vpaddq	%ymm8,%ymm5,%ymm5
	addq	40+256(%rsp),%r8
	andq	%rbx,%r12
	rorxq	$41,%rbx,%r13
	vpsrlq	$19,%ymm4,%ymm9
	vpxor	%ymm10,%ymm11,%ymm11
	rorxq	$18,%rbx,%rdi
	leaq	(%r9,%r14,1),%r9
	leaq	(%r8,%r12,1),%r8
	vpsllq	$42,%ymm10,%ymm10
	vpxor	%ymm9,%ymm11,%ymm11
	andnq	%rdx,%rbx,%r12
	xorq	%rdi,%r13
	rorxq	$14,%rbx,%r14
	vpsrlq	$42,%ymm9,%ymm9
	vpxor	%ymm10,%ymm11,%ymm11
	leaq	(%r8,%r12,1),%r8
	xorq	%r14,%r13
	movq	%r9,%rdi
	vpxor	%ymm9,%ymm11,%ymm11
	rorxq	$39,%r9,%r12
	leaq	(%r8,%r13,1),%r8
	xorq	%r10,%rdi
	vpaddq	%ymm11,%ymm5,%ymm5
	rorxq	$34,%r9,%r14
	rorxq	$28,%r9,%r13
	leaq	(%rax,%r8,1),%rax
	vpaddq	32(%rbp),%ymm5,%ymm10
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%r10,%r15
	xorq	%r13,%r14
	leaq	(%r8,%r15,1),%r8
	movq	%rbx,%r12
	vmovdqa	%ymm10,32(%rsp)
	vpalignr	$8,%ymm6,%ymm7,%ymm8
	addq	64+256(%rsp),%rdx
	andq	%rax,%r12
	rorxq	$41,%rax,%r13
	vpalignr	$8,%ymm2,%ymm3,%ymm11
	rorxq	$18,%rax,%r15
	leaq	(%r8,%r14,1),%r8
	leaq	(%rdx,%r12,1),%rdx
	vpsrlq	$1,%ymm8,%ymm10
	andnq	%rcx,%rax,%r12
	xorq	%r15,%r13
	rorxq	$14,%rax,%r14
	vpaddq	%ymm11,%ymm6,%ymm6
	vpsrlq	$7,%ymm8,%ymm11
	leaq	(%rdx,%r12,1),%rdx
	xorq	%r14,%r13
	movq	%r8,%r15
	vpsllq	$56,%ymm8,%ymm9
	vpxor	%ymm10,%ymm11,%ymm8
	rorxq	$39,%r8,%r12
	leaq	(%rdx,%r13,1),%rdx
	xorq	%r9,%r15
	vpsrlq	$7,%ymm10,%ymm10
	vpxor	%ymm9,%ymm8,%ymm8
	rorxq	$34,%r8,%r14
	rorxq	$28,%r8,%r13
	leaq	(%r11,%rdx,1),%r11
	vpsllq	$7,%ymm9,%ymm9
	vpxor	%ymm10,%ymm8,%ymm8
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%r9,%rdi
	vpsrlq	$6,%ymm5,%ymm11
	vpxor	%ymm9,%ymm8,%ymm8
	xorq	%r13,%r14
	leaq	(%rdx,%rdi,1),%rdx
	movq	%rax,%r12
	vpsllq	$3,%ymm5,%ymm10
	vpaddq	%ymm8,%ymm6,%ymm6
	addq	72+256(%rsp),%rcx
	andq	%r11,%r12
	rorxq	$41,%r11,%r13
	vpsrlq	$19,%ymm5,%ymm9
	vpxor	%ymm10,%ymm11,%ymm11
	rorxq	$18,%r11,%rdi
	leaq	(%rdx,%r14,1),%rdx
	leaq	(%rcx,%r12,1),%rcx
	vpsllq	$42,%ymm10,%ymm10
	vpxor	%ymm9,%ymm11,%ymm11
	andnq	%rbx,%r11,%r12
	xorq	%rdi,%r13
	rorxq	$14,%r11,%r14
	vpsrlq	$42,%ymm9,%ymm9
	vpxor	%ymm10,%ymm11,%ymm11
	leaq	(%rcx,%r12,1),%rcx
	xorq	%r14,%r13
	movq	%rdx,%rdi
	vpxor	%ymm9,%ymm11,%ymm11
	rorxq	$39,%rdx,%r12
	leaq	(%rcx,%r13,1),%rcx
	xorq	%r8,%rdi
	vpaddq	%ymm11,%ymm6,%ymm6
	rorxq	$34,%rdx,%r14
	rorxq	$28,%rdx,%r13
	leaq	(%r10,%rcx,1),%r10
	vpaddq	64(%rbp),%ymm6,%ymm10
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%r8,%r15
	xorq	%r13,%r14
	leaq	(%rcx,%r15,1),%rcx
	movq	%r11,%r12
	vmovdqa	%ymm10,64(%rsp)
	vpalignr	$8,%ymm7,%ymm0,%ymm8
	addq	96+256(%rsp),%rbx
	andq	%r10,%r12
	rorxq	$41,%r10,%r13
	vpalignr	$8,%ymm3,%ymm4,%ymm11
	rorxq	$18,%r10,%r15
	leaq	(%rcx,%r14,1),%rcx
	leaq	(%rbx,%r12,1),%rbx
	vpsrlq	$1,%ymm8,%ymm10
	andnq	%rax,%r10,%r12
	xorq	%r15,%r13
	rorxq	$14,%r10,%r14
	vpaddq	%ymm11,%ymm7,%ymm7
	vpsrlq	$7,%ymm8,%ymm11
	leaq	(%rbx,%r12,1),%rbx
	xorq	%r14,%r13
	movq	%rcx,%r15
	vpsllq	$56,%ymm8,%ymm9
	vpxor	%ymm10,%ymm11,%ymm8
	rorxq	$39,%rcx,%r12
	leaq	(%rbx,%r13,1),%rbx
	xorq	%rdx,%r15
	vpsrlq	$7,%ymm10,%ymm10
	vpxor	%ymm9,%ymm8,%ymm8
	rorxq	$34,%rcx,%r14
	rorxq	$28,%rcx,%r13
	leaq	(%r9,%rbx,1),%r9
	vpsllq	$7,%ymm9,%ymm9
	vpxor	%ymm10,%ymm8,%ymm8
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%rdx,%rdi
	vpsrlq	$6,%ymm6,%ymm11
	vpxor	%ymm9,%ymm8,%ymm8
	xorq	%r13,%r14
	leaq	(%rbx,%rdi,1),%rbx
	movq	%r10,%r12
	vpsllq	$3,%ymm6,%ymm10
	vpaddq	%ymm8,%ymm7,%ymm7
	addq	104+256(%rsp),%rax
	andq	%r9,%r12
	rorxq	$41,%r9,%r13
	vpsrlq	$19,%ymm6,%ymm9
	vpxor	%ymm10,%ymm11,%ymm11
	rorxq	$18,%r9,%rdi
	leaq	(%rbx,%r14,1),%rbx
	leaq	(%rax,%r12,1),%rax
	vpsllq	$42,%ymm10,%ymm10
	vpxor	%ymm9,%ymm11,%ymm11
	andnq	%r11,%r9,%r12
	xorq	%rdi,%r13
	rorxq	$14,%r9,%r14
	vpsrlq	$42,%ymm9,%ymm9
	vpxor	%ymm10,%ymm11,%ymm11
	leaq	(%rax,%r12,1),%rax
	xorq	%r14,%r13
	movq	%rbx,%rdi
	vpxor	%ymm9,%ymm11,%ymm11
	rorxq	$39,%rbx,%r12
	leaq	(%rax,%r13,1),%rax
	xorq	%rcx,%rdi
	vpaddq	%ymm11,%ymm7,%ymm7
	rorxq	$34,%rbx,%r14
	rorxq	$28,%rbx,%r13
	leaq	(%r8,%rax,1),%r8
	vpaddq	96(%rbp),%ymm7,%ymm10
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%rcx,%r15
	xorq	%r13,%r14
	leaq	(%rax,%r15,1),%rax
	movq	%r9,%r12
	vmovdqa	%ymm10,96(%rsp)
	leaq	256(%rbp),%rbp
	cmpb	$0,-121(%rbp)
	jne	.Lavx2_00_47
	addq	0+128(%rsp),%r11
	andq	%r8,%r12
	rorxq	$41,%r8,%r13
	rorxq	$18,%r8,%r15
	leaq	(%rax,%r14,1),%rax
	leaq	(%r11,%r12,1),%r11
	andnq	%r10,%r8,%r12
	xorq	%r15,%r13
	rorxq	$14,%r8,%r14
	leaq	(%r11,%r12,1),%r11
	xorq	%r14,%r13
	movq	%rax,%r15
	rorxq	$39,%rax,%r12
	leaq	(%r11,%r13,1),%r11
	xorq	%rbx,%r15
	rorxq	$34,%rax,%r14
	rorxq	$28,%rax,%r13
	leaq	(%rdx,%r11,1),%rdx
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%rbx,%rdi
	xorq	%r13,%r14
	leaq	(%r11,%rdi,1),%r11
	movq	%r8,%r12
	addq	8+128(%rsp),%r10
	andq	%rdx,%r12
	rorxq	$41,%rdx,%r13
	rorxq	$18,%rdx,%rdi
	leaq	(%r11,%r14,1),%r11
	leaq	(%r10,%r12,1),%r10
	andnq	%r9,%rdx,%r12
	xorq	%rdi,%r13
	rorxq	$14,%rdx,%r14
	leaq	(%r10,%r12,1),%r10
	xorq	%r14,%r13
	movq	%r11,%rdi
	rorxq	$39,%r11,%r12
	leaq	(%r10,%r13,1),%r10
	xorq	%rax,%rdi
	rorxq	$34,%r11,%r14
	rorxq	$28,%r11,%r13
	leaq	(%rcx,%r10,1),%rcx
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%rax,%r15
	xorq	%r13,%r14
	leaq	(%r10,%r15,1),%r10
	movq	%rdx,%r12
	addq	32+128(%rsp),%r9
	andq	%rcx,%r12
	rorxq	$41,%rcx,%r13
	rorxq	$18,%rcx,%r15
	leaq	(%r10,%r14,1),%r10
	leaq	(%r9,%r12,1),%r9
	andnq	%r8,%rcx,%r12
	xorq	%r15,%r13
	rorxq	$14,%rcx,%r14
	leaq	(%r9,%r12,1),%r9
	xorq	%r14,%r13
	movq	%r10,%r15
	rorxq	$39,%r10,%r12
	leaq	(%r9,%r13,1),%r9
	xorq	%r11,%r15
	rorxq	$34,%r10,%r14
	rorxq	$28,%r10,%r13
	leaq	(%rbx,%r9,1),%rbx
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%r11,%rdi
	xorq	%r13,%r14
	leaq	(%r9,%rdi,1),%r9
	movq	%rcx,%r12
	addq	40+128(%rsp),%r8
	andq	%rbx,%r12
	rorxq	$41,%rbx,%r13
	rorxq	$18,%rbx,%rdi
	leaq	(%r9,%r14,1),%r9
	leaq	(%r8,%r12,1),%r8
	andnq	%rdx,%rbx,%r12
	xorq	%rdi,%r13
	rorxq	$14,%rbx,%r14
	leaq	(%r8,%r12,1),%r8
	xorq	%r14,%r13
	movq	%r9,%rdi
	rorxq	$39,%r9,%r12
	leaq	(%r8,%r13,1),%r8
	xorq	%r10,%rdi
	rorxq	$34,%r9,%r14
	rorxq	$28,%r9,%r13
	leaq	(%rax,%r8,1),%rax
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%r10,%r15
	xorq	%r13,%r14
	leaq	(%r8,%r15,1),%r8
	movq	%rbx,%r12
	addq	64+128(%rsp),%rdx
	andq	%rax,%r12
	rorxq	$41,%rax,%r13
	rorxq	$18,%rax,%r15
	leaq	(%r8,%r14,1),%r8
	leaq	(%rdx,%r12,1),%rdx
	andnq	%rcx,%rax,%r12
	xorq	%r15,%r13
	rorxq	$14,%rax,%r14
	leaq	(%rdx,%r12,1),%rdx
	xorq	%r14,%r13
	movq	%r8,%r15
	rorxq	$39,%r8,%r12
	leaq	(%rdx,%r13,1),%rdx
	xorq	%r9,%r15
	rorxq	$34,%r8,%r14
	rorxq	$28,%r8,%r13
	leaq	(%r11,%rdx,1),%r11
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%r9,%rdi
	xorq	%r13,%r14
	leaq	(%rdx,%rdi,1),%rdx
	movq	%rax,%r12
	addq	72+128(%rsp),%rcx
	andq	%r11,%r12
	rorxq	$41,%r11,%r13
	rorxq	$18,%r11,%rdi
	leaq	(%rdx,%r14,1),%rdx
	leaq	(%rcx,%r12,1),%rcx
	andnq	%rbx,%r11,%r12
	xorq	%rdi,%r13
	rorxq	$14,%r11,%r14
	leaq	(%rcx,%r12,1),%rcx
	xorq	%r14,%r13
	movq	%rdx,%rdi
	rorxq	$39,%rdx,%r12
	leaq	(%rcx,%r13,1),%rcx
	xorq	%r8,%rdi
	rorxq	$34,%rdx,%r14
	rorxq	$28,%rdx,%r13
	leaq	(%r10,%rcx,1),%r10
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%r8,%r15
	xorq	%r13,%r14
	leaq	(%rcx,%r15,1),%rcx
	movq	%r11,%r12
	addq	96+128(%rsp),%rbx
	andq	%r10,%r12
	rorxq	$41,%r10,%r13
	rorxq	$18,%r10,%r15
	leaq	(%rcx,%r14,1),%rcx
	leaq	(%rbx,%r12,1),%rbx
	andnq	%rax,%r10,%r12
	xorq	%r15,%r13
	rorxq	$14,%r10,%r14
	leaq	(%rbx,%r12,1),%rbx
	xorq	%r14,%r13
	movq	%rcx,%r15
	rorxq	$39,%rcx,%r12
	leaq	(%rbx,%r13,1),%rbx
	xorq	%rdx,%r15
	rorxq	$34,%rcx,%r14
	rorxq	$28,%rcx,%r13
	leaq	(%r9,%rbx,1),%r9
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%rdx,%rdi
	xorq	%r13,%r14
	leaq	(%rbx,%rdi,1),%rbx
	movq	%r10,%r12
	addq	104+128(%rsp),%rax
	andq	%r9,%r12
	rorxq	$41,%r9,%r13
	rorxq	$18,%r9,%rdi
	leaq	(%rbx,%r14,1),%rbx
	leaq	(%rax,%r12,1),%rax
	andnq	%r11,%r9,%r12
	xorq	%rdi,%r13
	rorxq	$14,%r9,%r14
	leaq	(%rax,%r12,1),%rax
	xorq	%r14,%r13
	movq	%rbx,%rdi
	rorxq	$39,%rbx,%r12
	leaq	(%rax,%r13,1),%rax
	xorq	%rcx,%rdi
	rorxq	$34,%rbx,%r14
	rorxq	$28,%rbx,%r13
	leaq	(%r8,%rax,1),%r8
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%rcx,%r15
	xorq	%r13,%r14
	leaq	(%rax,%r15,1),%rax
	movq	%r9,%r12
	addq	0(%rsp),%r11
	andq	%r8,%r12
	rorxq	$41,%r8,%r13
	rorxq	$18,%r8,%r15
	leaq	(%rax,%r14,1),%rax
	leaq	(%r11,%r12,1),%r11
	andnq	%r10,%r8,%r12
	xorq	%r15,%r13
	rorxq	$14,%r8,%r14
	leaq	(%r11,%r12,1),%r11
	xorq	%r14,%r13
	movq	%rax,%r15
	rorxq	$39,%rax,%r12
	leaq	(%r11,%r13,1),%r11
	xorq	%rbx,%r15
	rorxq	$34,%rax,%r14
	rorxq	$28,%rax,%r13
	leaq	(%rdx,%r11,1),%rdx
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%rbx,%rdi
	xorq	%r13,%r14
	leaq	(%r11,%rdi,1),%r11
	movq	%r8,%r12
	addq	8(%rsp),%r10
	andq	%rdx,%r12
	rorxq	$41,%rdx,%r13
	rorxq	$18,%rdx,%rdi
	leaq	(%r11,%r14,1),%r11
	leaq	(%r10,%r12,1),%r10
	andnq	%r9,%rdx,%r12
	xorq	%rdi,%r13
	rorxq	$14,%rdx,%r14
	leaq	(%r10,%r12,1),%r10
	xorq	%r14,%r13
	movq	%r11,%rdi
	rorxq	$39,%r11,%r12
	leaq	(%r10,%r13,1),%r10
	xorq	%rax,%rdi
	rorxq	$34,%r11,%r14
	rorxq	$28,%r11,%r13
	leaq	(%rcx,%r10,1),%rcx
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%rax,%r15
	xorq	%r13,%r14
	leaq	(%r10,%r15,1),%r10
	movq	%rdx,%r12
	addq	32(%rsp),%r9
	andq	%rcx,%r12
	rorxq	$41,%rcx,%r13
	rorxq	$18,%rcx,%r15
	leaq	(%r10,%r14,1),%r10
	leaq	(%r9,%r12,1),%r9
	andnq	%r8,%rcx,%r12
	xorq	%r15,%r13
	rorxq	$14,%rcx,%r14
	leaq	(%r9,%r12,1),%r9
	xorq	%r14,%r13
	movq	%r10,%r15
	rorxq	$39,%r10,%r12
	leaq	(%r9,%r13,1),%r9
	xorq	%r11,%r15
	rorxq	$34,%r10,%r14
	rorxq	$28,%r10,%r13
	leaq	(%rbx,%r9,1),%rbx
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%r11,%rdi
	xorq	%r13,%r14
	leaq	(%r9,%rdi,1),%r9
	movq	%rcx,%r12
	addq	40(%rsp),%r8
	andq	%rbx,%r12
	rorxq	$41,%rbx,%r13
	rorxq	$18,%rbx,%rdi
	leaq	(%r9,%r14,1),%r9
	leaq	(%r8,%r12,1),%r8
	andnq	%rdx,%rbx,%r12
	xorq	%rdi,%r13
	rorxq	$14,%rbx,%r14
	leaq	(%r8,%r12,1),%r8
	xorq	%r14,%r13
	movq	%r9,%rdi
	rorxq	$39,%r9,%r12
	leaq	(%r8,%r13,1),%r8
	xorq	%r10,%rdi
	rorxq	$34,%r9,%r14
	rorxq	$28,%r9,%r13
	leaq	(%rax,%r8,1),%rax
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%r10,%r15
	xorq	%r13,%r14
	leaq	(%r8,%r15,1),%r8
	movq	%rbx,%r12
	addq	64(%rsp),%rdx
	andq	%rax,%r12
	rorxq	$41,%rax,%r13
	rorxq	$18,%rax,%r15
	leaq	(%r8,%r14,1),%r8
	leaq	(%rdx,%r12,1),%rdx
	andnq	%rcx,%rax,%r12
	xorq	%r15,%r13
	rorxq	$14,%rax,%r14
	leaq	(%rdx,%r12,1),%rdx
	xorq	%r14,%r13
	movq	%r8,%r15
	rorxq	$39,%r8,%r12
	leaq	(%rdx,%r13,1),%rdx
	xorq	%r9,%r15
	rorxq	$34,%r8,%r14
	rorxq	$28,%r8,%r13
	leaq	(%r11,%rdx,1),%r11
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%r9,%rdi
	xorq	%r13,%r14
	leaq	(%rdx,%rdi,1),%rdx
	movq	%rax,%r12
	addq	72(%rsp),%rcx
	andq	%r11,%r12
	rorxq	$41,%r11,%r13
	rorxq	$18,%r11,%rdi
	leaq	(%rdx,%r14,1),%rdx
	leaq	(%rcx,%r12,1),%rcx
	andnq	%rbx,%r11,%r12
	xorq	%rdi,%r13
	rorxq	$14,%r11,%r14
	leaq	(%rcx,%r12,1),%rcx
	xorq	%r14,%r13
	movq	%rdx,%rdi
	rorxq	$39,%rdx,%r12
	leaq	(%rcx,%r13,1),%rcx
	xorq	%r8,%rdi
	rorxq	$34,%rdx,%r14
	rorxq	$28,%rdx,%r13
	leaq	(%r10,%rcx,1),%r10
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%r8,%r15
	xorq	%r13,%r14
	leaq	(%rcx,%r15,1),%rcx
	movq	%r11,%r12
	addq	96(%rsp),%rbx
	andq	%r10,%r12
	rorxq	$41,%r10,%r13
	rorxq	$18,%r10,%r15
	leaq	(%rcx,%r14,1),%rcx
	leaq	(%rbx,%r12,1),%rbx
	andnq	%rax,%r10,%r12
	xorq	%r15,%r13
	rorxq	$14,%r10,%r14
	leaq	(%rbx,%r12,1),%rbx
	xorq	%r14,%r13
	movq	%rcx,%r15
	rorxq	$39,%rcx,%r12
	leaq	(%rbx,%r13,1),%rbx
	xorq	%rdx,%r15
	rorxq	$34,%rcx,%r14
	rorxq	$28,%rcx,%r13
	leaq	(%r9,%rbx,1),%r9
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%rdx,%rdi
	xorq	%r13,%r14
	leaq	(%rbx,%rdi,1),%rbx
	movq	%r10,%r12
	addq	104(%rsp),%rax
	andq	%r9,%r12
	rorxq	$41,%r9,%r13
	rorxq	$18,%r9,%rdi
	leaq	(%rbx,%r14,1),%rbx
	leaq	(%rax,%r12,1),%rax
	andnq	%r11,%r9,%r12
	xorq	%rdi,%r13
	rorxq	$14,%r9,%r14
	leaq	(%rax,%r12,1),%rax
	xorq	%r14,%r13
	movq	%rbx,%rdi
	rorxq	$39,%rbx,%r12
	leaq	(%rax,%r13,1),%rax
	xorq	%rcx,%rdi
	rorxq	$34,%rbx,%r14
	rorxq	$28,%rbx,%r13
	leaq	(%r8,%rax,1),%r8
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%rcx,%r15
	xorq	%r13,%r14
	leaq	(%rax,%r15,1),%rax
	movq	%r9,%r12
	movq	1280(%rsp),%rdi
	addq	%r14,%rax

	leaq	1152(%rsp),%rbp

	addq	0(%rdi),%rax
	addq	8(%rdi),%rbx
	addq	16(%rdi),%rcx
	addq	24(%rdi),%rdx
	addq	32(%rdi),%r8
	addq	40(%rdi),%r9
	addq	48(%rdi),%r10
	addq	56(%rdi),%r11

	movq	%rax,0(%rdi)
	movq	%rbx,8(%rdi)
	movq	%rcx,16(%rdi)
	movq	%rdx,24(%rdi)
	movq	%r8,32(%rdi)
	movq	%r9,40(%rdi)
	movq	%r10,48(%rdi)
	movq	%r11,56(%rdi)

	cmpq	144(%rbp),%rsi
	je	.Ldone_avx2

	xorq	%r14,%r14
	movq	%rbx,%rdi
	xorq	%rcx,%rdi
	movq	%r9,%r12
	jmp	.Lower_avx2
.align	16
.Lower_avx2:
	addq	0+16(%rbp),%r11
	andq	%r8,%r12
	rorxq	$41,%r8,%r13
	rorxq	$18,%r8,%r15
	leaq	(%rax,%r14,1),%rax
	leaq	(%r11,%r12,1),%r11
	andnq	%r10,%r8,%r12
	xorq	%r15,%r13
	rorxq	$14,%r8,%r14
	leaq	(%r11,%r12,1),%r11
	xorq	%r14,%r13
	movq	%rax,%r15
	rorxq	$39,%rax,%r12
	leaq	(%r11,%r13,1),%r11
	xorq	%rbx,%r15
	rorxq	$34,%rax,%r14
	rorxq	$28,%rax,%r13
	leaq	(%rdx,%r11,1),%rdx
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%rbx,%rdi
	xorq	%r13,%r14
	leaq	(%r11,%rdi,1),%r11
	movq	%r8,%r12
	addq	8+16(%rbp),%r10
	andq	%rdx,%r12
	rorxq	$41,%rdx,%r13
	rorxq	$18,%rdx,%rdi
	leaq	(%r11,%r14,1),%r11
	leaq	(%r10,%r12,1),%r10
	andnq	%r9,%rdx,%r12
	xorq	%rdi,%r13
	rorxq	$14,%rdx,%r14
	leaq	(%r10,%r12,1),%r10
	xorq	%r14,%r13
	movq	%r11,%rdi
	rorxq	$39,%r11,%r12
	leaq	(%r10,%r13,1),%r10
	xorq	%rax,%rdi
	rorxq	$34,%r11,%r14
	rorxq	$28,%r11,%r13
	leaq	(%rcx,%r10,1),%rcx
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%rax,%r15
	xorq	%r13,%r14
	leaq	(%r10,%r15,1),%r10
	movq	%rdx,%r12
	addq	32+16(%rbp),%r9
	andq	%rcx,%r12
	rorxq	$41,%rcx,%r13
	rorxq	$18,%rcx,%r15
	leaq	(%r10,%r14,1),%r10
	leaq	(%r9,%r12,1),%r9
	andnq	%r8,%rcx,%r12
	xorq	%r15,%r13
	rorxq	$14,%rcx,%r14
	leaq	(%r9,%r12,1),%r9
	xorq	%r14,%r13
	movq	%r10,%r15
	rorxq	$39,%r10,%r12
	leaq	(%r9,%r13,1),%r9
	xorq	%r11,%r15
	rorxq	$34,%r10,%r14
	rorxq	$28,%r10,%r13
	leaq	(%rbx,%r9,1),%rbx
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%r11,%rdi
	xorq	%r13,%r14
	leaq	(%r9,%rdi,1),%r9
	movq	%rcx,%r12
	addq	40+16(%rbp),%r8
	andq	%rbx,%r12
	rorxq	$41,%rbx,%r13
	rorxq	$18,%rbx,%rdi
	leaq	(%r9,%r14,1),%r9
	leaq	(%r8,%r12,1),%r8
	andnq	%rdx,%rbx,%r12
	xorq	%rdi,%r13
	rorxq	$14,%rbx,%r14
	leaq	(%r8,%r12,1),%r8
	xorq	%r14,%r13
	movq	%r9,%rdi
	rorxq	$39,%r9,%r12
	leaq	(%r8,%r13,1),%r8
	xorq	%r10,%rdi
	rorxq	$34,%r9,%r14
	rorxq	$28,%r9,%r13
	leaq	(%rax,%r8,1),%rax
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%r10,%r15
	xorq	%r13,%r14
	leaq	(%r8,%r15,1),%r8
	movq	%rbx,%r12
	addq	64+16(%rbp),%rdx
	andq	%rax,%r12
	rorxq	$41,%rax,%r13
	rorxq	$18,%rax,%r15
	leaq	(%r8,%r14,1),%r8
	leaq	(%rdx,%r12,1),%rdx
	andnq	%rcx,%rax,%r12
	xorq	%r15,%r13
	rorxq	$14,%rax,%r14
	leaq	(%rdx,%r12,1),%rdx
	xorq	%r14,%r13
	movq	%r8,%r15
	rorxq	$39,%r8,%r12
	leaq	(%rdx,%r13,1),%rdx
	xorq	%r9,%r15
	rorxq	$34,%r8,%r14
	rorxq	$28,%r8,%r13
	leaq	(%r11,%rdx,1),%r11
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%r9,%rdi
	xorq	%r13,%r14
	leaq	(%rdx,%rdi,1),%rdx
	movq	%rax,%r12
	addq	72+16(%rbp),%rcx
	andq	%r11,%r12
	rorxq	$41,%r11,%r13
	rorxq	$18,%r11,%rdi
	leaq	(%rdx,%r14,1),%rdx
	leaq	(%rcx,%r12,1),%rcx
	andnq	%rbx,%r11,%r12
	xorq	%rdi,%r13
	rorxq	$14,%r11,%r14
	leaq	(%rcx,%r12,1),%rcx
	xorq	%r14,%r13
	movq	%rdx,%rdi
	rorxq	$39,%rdx,%r12
	leaq	(%rcx,%r13,1),%rcx
	xorq	%r8,%rdi
	rorxq	$34,%rdx,%r14
	rorxq	$28,%rdx,%r13
	leaq	(%r10,%rcx,1),%r10
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%r8,%r15
	xorq	%r13,%r14
	leaq	(%rcx,%r15,1),%rcx
	movq	%r11,%r12
	addq	96+16(%rbp),%rbx
	andq	%r10,%r12
	rorxq	$41,%r10,%r13
	rorxq	$18,%r10,%r15
	leaq	(%rcx,%r14,1),%rcx
	leaq	(%rbx,%r12,1),%rbx
	andnq	%rax,%r10,%r12
	xorq	%r15,%r13
	rorxq	$14,%r10,%r14
	leaq	(%rbx,%r12,1),%rbx
	xorq	%r14,%r13
	movq	%rcx,%r15
	rorxq	$39,%rcx,%r12
	leaq	(%rbx,%r13,1),%rbx
	xorq	%rdx,%r15
	rorxq	$34,%rcx,%r14
	rorxq	$28,%rcx,%r13
	leaq	(%r9,%rbx,1),%r9
	andq	%r15,%rdi
	xorq	%r12,%r14
	xorq	%rdx,%rdi
	xorq	%r13,%r14
	leaq	(%rbx,%rdi,1),%rbx
	movq	%r10,%r12
	addq	104+16(%rbp),%rax
	andq	%r9,%r12
	rorxq	$41,%r9,%r13
	rorxq	$18,%r9,%rdi
	leaq	(%rbx,%r14,1),%rbx
	leaq	(%rax,%r12,1),%rax
	andnq	%r11,%r9,%r12
	xorq	%rdi,%r13
	rorxq	$14,%r9,%r14
	leaq	(%rax,%r12,1),%rax
	xorq	%r14,%r13
	movq	%rbx,%rdi
	rorxq	$39,%rbx,%r12
	leaq	(%rax,%r13,1),%rax
	xorq	%rcx,%rdi
	rorxq	$34,%rbx,%r14
	rorxq	$28,%rbx,%r13
	leaq	(%r8,%rax,1),%r8
	andq	%rdi,%r15
	xorq	%r12,%r14
	xorq	%rcx,%r15
	xorq	%r13,%r14
	leaq	(%rax,%r15,1),%rax
	movq	%r9,%r12
	leaq	-128(%rbp),%rbp
	cmpq	%rsp,%rbp
	jae	.Lower_avx2

	movq	1280(%rsp),%rdi
	addq	%r14,%rax

	leaq	1152(%rsp),%rsp

.cfi_escape	0x0f,0x06,0x77,0x98,0x01,0x06,0x23,0x08

	addq	0(%rdi),%rax
	addq	8(%rdi),%rbx
	addq	16(%rdi),%rcx
	addq	24(%rdi),%rdx
	addq	32(%rdi),%r8
	addq	40(%rdi),%r9
	leaq	256(%rsi),%rsi
	addq	48(%rdi),%r10
	movq	%rsi,%r12
	addq	56(%rdi),%r11
	cmpq	128+16(%rsp),%rsi

	movq	%rax,0(%rdi)
	cmoveq	%rsp,%r12
	movq	%rbx,8(%rdi)
	movq	%rcx,16(%rdi)
	movq	%rdx,24(%rdi)
	movq	%r8,32(%rdi)
	movq	%r9,40(%rdi)
	movq	%r10,48(%rdi)
	movq	%r11,56(%rdi)

	jbe	.Loop_avx2
	leaq	(%rsp),%rbp


.cfi_escape	0x0f,0x06,0x76,0x98,0x01,0x06,0x23,0x08

.Ldone_avx2:
	movq	152(%rbp),%rsi
.cfi_def_cfa	%rsi,8
	vzeroupper
	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue_avx2:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	sha512_block_data_order_avx2,.-sha512_block_data_order_avx2
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                                                                                                                                                                                                          node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/crypto/whrlpool/                0000775 0000000 0000000 00000000000 14746647661 0027762 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/crypto/whrlpool/wp-x86_64.s     0000664 0000000 0000000 00000071766 14746647661 0031551 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	

.globl	whirlpool_block
.type	whirlpool_block,@function
.align	16
whirlpool_block:
.cfi_startproc	
	movq	%rsp,%rax
.cfi_def_cfa_register	%rax
	pushq	%rbx
.cfi_offset	%rbx,-16
	pushq	%rbp
.cfi_offset	%rbp,-24
	pushq	%r12
.cfi_offset	%r12,-32
	pushq	%r13
.cfi_offset	%r13,-40
	pushq	%r14
.cfi_offset	%r14,-48
	pushq	%r15
.cfi_offset	%r15,-56

	subq	$128+40,%rsp
	andq	$-64,%rsp

	leaq	128(%rsp),%r10
	movq	%rdi,0(%r10)
	movq	%rsi,8(%r10)
	movq	%rdx,16(%r10)
	movq	%rax,32(%r10)
.cfi_escape	0x0f,0x06,0x77,0xa0,0x01,0x06,0x23,0x08
.Lprologue:

	movq	%r10,%rbx
	leaq	.Ltable(%rip),%rbp

	xorq	%rcx,%rcx
	xorq	%rdx,%rdx
	movq	0(%rdi),%r8
	movq	8(%rdi),%r9
	movq	16(%rdi),%r10
	movq	24(%rdi),%r11
	movq	32(%rdi),%r12
	movq	40(%rdi),%r13
	movq	48(%rdi),%r14
	movq	56(%rdi),%r15
.Louterloop:
	movq	%r8,0(%rsp)
	movq	%r9,8(%rsp)
	movq	%r10,16(%rsp)
	movq	%r11,24(%rsp)
	movq	%r12,32(%rsp)
	movq	%r13,40(%rsp)
	movq	%r14,48(%rsp)
	movq	%r15,56(%rsp)
	xorq	0(%rsi),%r8
	xorq	8(%rsi),%r9
	xorq	16(%rsi),%r10
	xorq	24(%rsi),%r11
	xorq	32(%rsi),%r12
	xorq	40(%rsi),%r13
	xorq	48(%rsi),%r14
	xorq	56(%rsi),%r15
	movq	%r8,64+0(%rsp)
	movq	%r9,64+8(%rsp)
	movq	%r10,64+16(%rsp)
	movq	%r11,64+24(%rsp)
	movq	%r12,64+32(%rsp)
	movq	%r13,64+40(%rsp)
	movq	%r14,64+48(%rsp)
	movq	%r15,64+56(%rsp)
	xorq	%rsi,%rsi
	movq	%rsi,24(%rbx)
	jmp	.Lround
.align	16
.Lround:
	movq	4096(%rbp,%rsi,8),%r8
	movl	0(%rsp),%eax
	movl	4(%rsp),%ebx
	movzbl	%al,%ecx
	movzbl	%ah,%edx
	shrl	$16,%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	0(%rbp,%rsi,8),%r8
	movq	7(%rbp,%rdi,8),%r9
	movl	0+8(%rsp),%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	movq	6(%rbp,%rsi,8),%r10
	movq	5(%rbp,%rdi,8),%r11
	shrl	$16,%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	movq	4(%rbp,%rsi,8),%r12
	movq	3(%rbp,%rdi,8),%r13
	movl	0+8+4(%rsp),%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	movq	2(%rbp,%rsi,8),%r14
	movq	1(%rbp,%rdi,8),%r15
	shrl	$16,%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	0(%rbp,%rsi,8),%r9
	xorq	7(%rbp,%rdi,8),%r10
	movl	8+8(%rsp),%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	6(%rbp,%rsi,8),%r11
	xorq	5(%rbp,%rdi,8),%r12
	shrl	$16,%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	4(%rbp,%rsi,8),%r13
	xorq	3(%rbp,%rdi,8),%r14
	movl	8+8+4(%rsp),%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	2(%rbp,%rsi,8),%r15
	xorq	1(%rbp,%rdi,8),%r8
	shrl	$16,%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	0(%rbp,%rsi,8),%r10
	xorq	7(%rbp,%rdi,8),%r11
	movl	16+8(%rsp),%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	6(%rbp,%rsi,8),%r12
	xorq	5(%rbp,%rdi,8),%r13
	shrl	$16,%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	4(%rbp,%rsi,8),%r14
	xorq	3(%rbp,%rdi,8),%r15
	movl	16+8+4(%rsp),%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	2(%rbp,%rsi,8),%r8
	xorq	1(%rbp,%rdi,8),%r9
	shrl	$16,%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	0(%rbp,%rsi,8),%r11
	xorq	7(%rbp,%rdi,8),%r12
	movl	24+8(%rsp),%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	6(%rbp,%rsi,8),%r13
	xorq	5(%rbp,%rdi,8),%r14
	shrl	$16,%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	4(%rbp,%rsi,8),%r15
	xorq	3(%rbp,%rdi,8),%r8
	movl	24+8+4(%rsp),%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	2(%rbp,%rsi,8),%r9
	xorq	1(%rbp,%rdi,8),%r10
	shrl	$16,%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	0(%rbp,%rsi,8),%r12
	xorq	7(%rbp,%rdi,8),%r13
	movl	32+8(%rsp),%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	6(%rbp,%rsi,8),%r14
	xorq	5(%rbp,%rdi,8),%r15
	shrl	$16,%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	4(%rbp,%rsi,8),%r8
	xorq	3(%rbp,%rdi,8),%r9
	movl	32+8+4(%rsp),%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	2(%rbp,%rsi,8),%r10
	xorq	1(%rbp,%rdi,8),%r11
	shrl	$16,%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	0(%rbp,%rsi,8),%r13
	xorq	7(%rbp,%rdi,8),%r14
	movl	40+8(%rsp),%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	6(%rbp,%rsi,8),%r15
	xorq	5(%rbp,%rdi,8),%r8
	shrl	$16,%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	4(%rbp,%rsi,8),%r9
	xorq	3(%rbp,%rdi,8),%r10
	movl	40+8+4(%rsp),%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	2(%rbp,%rsi,8),%r11
	xorq	1(%rbp,%rdi,8),%r12
	shrl	$16,%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	0(%rbp,%rsi,8),%r14
	xorq	7(%rbp,%rdi,8),%r15
	movl	48+8(%rsp),%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	6(%rbp,%rsi,8),%r8
	xorq	5(%rbp,%rdi,8),%r9
	shrl	$16,%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	4(%rbp,%rsi,8),%r10
	xorq	3(%rbp,%rdi,8),%r11
	movl	48+8+4(%rsp),%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	2(%rbp,%rsi,8),%r12
	xorq	1(%rbp,%rdi,8),%r13
	shrl	$16,%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	0(%rbp,%rsi,8),%r15
	xorq	7(%rbp,%rdi,8),%r8
	movl	56+8(%rsp),%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	6(%rbp,%rsi,8),%r9
	xorq	5(%rbp,%rdi,8),%r10
	shrl	$16,%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	4(%rbp,%rsi,8),%r11
	xorq	3(%rbp,%rdi,8),%r12
	movl	56+8+4(%rsp),%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	2(%rbp,%rsi,8),%r13
	xorq	1(%rbp,%rdi,8),%r14
	movq	%r8,0(%rsp)
	movq	%r9,8(%rsp)
	movq	%r10,16(%rsp)
	movq	%r11,24(%rsp)
	movq	%r12,32(%rsp)
	movq	%r13,40(%rsp)
	movq	%r14,48(%rsp)
	movq	%r15,56(%rsp)
	shrl	$16,%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	0(%rbp,%rsi,8),%r8
	xorq	7(%rbp,%rdi,8),%r9
	movl	64+0+8(%rsp),%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	6(%rbp,%rsi,8),%r10
	xorq	5(%rbp,%rdi,8),%r11
	shrl	$16,%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	4(%rbp,%rsi,8),%r12
	xorq	3(%rbp,%rdi,8),%r13
	movl	64+0+8+4(%rsp),%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	2(%rbp,%rsi,8),%r14
	xorq	1(%rbp,%rdi,8),%r15
	shrl	$16,%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	0(%rbp,%rsi,8),%r9
	xorq	7(%rbp,%rdi,8),%r10
	movl	64+8+8(%rsp),%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	6(%rbp,%rsi,8),%r11
	xorq	5(%rbp,%rdi,8),%r12
	shrl	$16,%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	4(%rbp,%rsi,8),%r13
	xorq	3(%rbp,%rdi,8),%r14
	movl	64+8+8+4(%rsp),%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	2(%rbp,%rsi,8),%r15
	xorq	1(%rbp,%rdi,8),%r8
	shrl	$16,%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	0(%rbp,%rsi,8),%r10
	xorq	7(%rbp,%rdi,8),%r11
	movl	64+16+8(%rsp),%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	6(%rbp,%rsi,8),%r12
	xorq	5(%rbp,%rdi,8),%r13
	shrl	$16,%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	4(%rbp,%rsi,8),%r14
	xorq	3(%rbp,%rdi,8),%r15
	movl	64+16+8+4(%rsp),%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	2(%rbp,%rsi,8),%r8
	xorq	1(%rbp,%rdi,8),%r9
	shrl	$16,%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	0(%rbp,%rsi,8),%r11
	xorq	7(%rbp,%rdi,8),%r12
	movl	64+24+8(%rsp),%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	6(%rbp,%rsi,8),%r13
	xorq	5(%rbp,%rdi,8),%r14
	shrl	$16,%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	4(%rbp,%rsi,8),%r15
	xorq	3(%rbp,%rdi,8),%r8
	movl	64+24+8+4(%rsp),%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	2(%rbp,%rsi,8),%r9
	xorq	1(%rbp,%rdi,8),%r10
	shrl	$16,%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	0(%rbp,%rsi,8),%r12
	xorq	7(%rbp,%rdi,8),%r13
	movl	64+32+8(%rsp),%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	6(%rbp,%rsi,8),%r14
	xorq	5(%rbp,%rdi,8),%r15
	shrl	$16,%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	4(%rbp,%rsi,8),%r8
	xorq	3(%rbp,%rdi,8),%r9
	movl	64+32+8+4(%rsp),%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	2(%rbp,%rsi,8),%r10
	xorq	1(%rbp,%rdi,8),%r11
	shrl	$16,%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	0(%rbp,%rsi,8),%r13
	xorq	7(%rbp,%rdi,8),%r14
	movl	64+40+8(%rsp),%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	6(%rbp,%rsi,8),%r15
	xorq	5(%rbp,%rdi,8),%r8
	shrl	$16,%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	4(%rbp,%rsi,8),%r9
	xorq	3(%rbp,%rdi,8),%r10
	movl	64+40+8+4(%rsp),%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	2(%rbp,%rsi,8),%r11
	xorq	1(%rbp,%rdi,8),%r12
	shrl	$16,%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	0(%rbp,%rsi,8),%r14
	xorq	7(%rbp,%rdi,8),%r15
	movl	64+48+8(%rsp),%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	6(%rbp,%rsi,8),%r8
	xorq	5(%rbp,%rdi,8),%r9
	shrl	$16,%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	4(%rbp,%rsi,8),%r10
	xorq	3(%rbp,%rdi,8),%r11
	movl	64+48+8+4(%rsp),%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	2(%rbp,%rsi,8),%r12
	xorq	1(%rbp,%rdi,8),%r13
	shrl	$16,%eax
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	0(%rbp,%rsi,8),%r15
	xorq	7(%rbp,%rdi,8),%r8

	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	6(%rbp,%rsi,8),%r9
	xorq	5(%rbp,%rdi,8),%r10
	shrl	$16,%ebx
	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%bl,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%bh,%edx
	xorq	4(%rbp,%rsi,8),%r11
	xorq	3(%rbp,%rdi,8),%r12

	leaq	(%rcx,%rcx,1),%rsi
	movzbl	%al,%ecx
	leaq	(%rdx,%rdx,1),%rdi
	movzbl	%ah,%edx
	xorq	2(%rbp,%rsi,8),%r13
	xorq	1(%rbp,%rdi,8),%r14
	leaq	128(%rsp),%rbx
	movq	24(%rbx),%rsi
	addq	$1,%rsi
	cmpq	$10,%rsi
	je	.Lroundsdone

	movq	%rsi,24(%rbx)
	movq	%r8,64+0(%rsp)
	movq	%r9,64+8(%rsp)
	movq	%r10,64+16(%rsp)
	movq	%r11,64+24(%rsp)
	movq	%r12,64+32(%rsp)
	movq	%r13,64+40(%rsp)
	movq	%r14,64+48(%rsp)
	movq	%r15,64+56(%rsp)
	jmp	.Lround
.align	16
.Lroundsdone:
	movq	0(%rbx),%rdi
	movq	8(%rbx),%rsi
	movq	16(%rbx),%rax
	xorq	0(%rsi),%r8
	xorq	8(%rsi),%r9
	xorq	16(%rsi),%r10
	xorq	24(%rsi),%r11
	xorq	32(%rsi),%r12
	xorq	40(%rsi),%r13
	xorq	48(%rsi),%r14
	xorq	56(%rsi),%r15
	xorq	0(%rdi),%r8
	xorq	8(%rdi),%r9
	xorq	16(%rdi),%r10
	xorq	24(%rdi),%r11
	xorq	32(%rdi),%r12
	xorq	40(%rdi),%r13
	xorq	48(%rdi),%r14
	xorq	56(%rdi),%r15
	movq	%r8,0(%rdi)
	movq	%r9,8(%rdi)
	movq	%r10,16(%rdi)
	movq	%r11,24(%rdi)
	movq	%r12,32(%rdi)
	movq	%r13,40(%rdi)
	movq	%r14,48(%rdi)
	movq	%r15,56(%rdi)
	leaq	64(%rsi),%rsi
	subq	$1,%rax
	jz	.Lalldone
	movq	%rsi,8(%rbx)
	movq	%rax,16(%rbx)
	jmp	.Louterloop
.Lalldone:
	movq	32(%rbx),%rsi
.cfi_def_cfa	%rsi,8
	movq	-48(%rsi),%r15
.cfi_restore	%r15
	movq	-40(%rsi),%r14
.cfi_restore	%r14
	movq	-32(%rsi),%r13
.cfi_restore	%r13
	movq	-24(%rsi),%r12
.cfi_restore	%r12
	movq	-16(%rsi),%rbp
.cfi_restore	%rbp
	movq	-8(%rsi),%rbx
.cfi_restore	%rbx
	leaq	(%rsi),%rsp
.cfi_def_cfa_register	%rsp
.Lepilogue:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	whirlpool_block,.-whirlpool_block

.align	64
.type	.Ltable,@object
.Ltable:
.byte	24,24,96,24,192,120,48,216,24,24,96,24,192,120,48,216
.byte	35,35,140,35,5,175,70,38,35,35,140,35,5,175,70,38
.byte	198,198,63,198,126,249,145,184,198,198,63,198,126,249,145,184
.byte	232,232,135,232,19,111,205,251,232,232,135,232,19,111,205,251
.byte	135,135,38,135,76,161,19,203,135,135,38,135,76,161,19,203
.byte	184,184,218,184,169,98,109,17,184,184,218,184,169,98,109,17
.byte	1,1,4,1,8,5,2,9,1,1,4,1,8,5,2,9
.byte	79,79,33,79,66,110,158,13,79,79,33,79,66,110,158,13
.byte	54,54,216,54,173,238,108,155,54,54,216,54,173,238,108,155
.byte	166,166,162,166,89,4,81,255,166,166,162,166,89,4,81,255
.byte	210,210,111,210,222,189,185,12,210,210,111,210,222,189,185,12
.byte	245,245,243,245,251,6,247,14,245,245,243,245,251,6,247,14
.byte	121,121,249,121,239,128,242,150,121,121,249,121,239,128,242,150
.byte	111,111,161,111,95,206,222,48,111,111,161,111,95,206,222,48
.byte	145,145,126,145,252,239,63,109,145,145,126,145,252,239,63,109
.byte	82,82,85,82,170,7,164,248,82,82,85,82,170,7,164,248
.byte	96,96,157,96,39,253,192,71,96,96,157,96,39,253,192,71
.byte	188,188,202,188,137,118,101,53,188,188,202,188,137,118,101,53
.byte	155,155,86,155,172,205,43,55,155,155,86,155,172,205,43,55
.byte	142,142,2,142,4,140,1,138,142,142,2,142,4,140,1,138
.byte	163,163,182,163,113,21,91,210,163,163,182,163,113,21,91,210
.byte	12,12,48,12,96,60,24,108,12,12,48,12,96,60,24,108
.byte	123,123,241,123,255,138,246,132,123,123,241,123,255,138,246,132
.byte	53,53,212,53,181,225,106,128,53,53,212,53,181,225,106,128
.byte	29,29,116,29,232,105,58,245,29,29,116,29,232,105,58,245
.byte	224,224,167,224,83,71,221,179,224,224,167,224,83,71,221,179
.byte	215,215,123,215,246,172,179,33,215,215,123,215,246,172,179,33
.byte	194,194,47,194,94,237,153,156,194,194,47,194,94,237,153,156
.byte	46,46,184,46,109,150,92,67,46,46,184,46,109,150,92,67
.byte	75,75,49,75,98,122,150,41,75,75,49,75,98,122,150,41
.byte	254,254,223,254,163,33,225,93,254,254,223,254,163,33,225,93
.byte	87,87,65,87,130,22,174,213,87,87,65,87,130,22,174,213
.byte	21,21,84,21,168,65,42,189,21,21,84,21,168,65,42,189
.byte	119,119,193,119,159,182,238,232,119,119,193,119,159,182,238,232
.byte	55,55,220,55,165,235,110,146,55,55,220,55,165,235,110,146
.byte	229,229,179,229,123,86,215,158,229,229,179,229,123,86,215,158
.byte	159,159,70,159,140,217,35,19,159,159,70,159,140,217,35,19
.byte	240,240,231,240,211,23,253,35,240,240,231,240,211,23,253,35
.byte	74,74,53,74,106,127,148,32,74,74,53,74,106,127,148,32
.byte	218,218,79,218,158,149,169,68,218,218,79,218,158,149,169,68
.byte	88,88,125,88,250,37,176,162,88,88,125,88,250,37,176,162
.byte	201,201,3,201,6,202,143,207,201,201,3,201,6,202,143,207
.byte	41,41,164,41,85,141,82,124,41,41,164,41,85,141,82,124
.byte	10,10,40,10,80,34,20,90,10,10,40,10,80,34,20,90
.byte	177,177,254,177,225,79,127,80,177,177,254,177,225,79,127,80
.byte	160,160,186,160,105,26,93,201,160,160,186,160,105,26,93,201
.byte	107,107,177,107,127,218,214,20,107,107,177,107,127,218,214,20
.byte	133,133,46,133,92,171,23,217,133,133,46,133,92,171,23,217
.byte	189,189,206,189,129,115,103,60,189,189,206,189,129,115,103,60
.byte	93,93,105,93,210,52,186,143,93,93,105,93,210,52,186,143
.byte	16,16,64,16,128,80,32,144,16,16,64,16,128,80,32,144
.byte	244,244,247,244,243,3,245,7,244,244,247,244,243,3,245,7
.byte	203,203,11,203,22,192,139,221,203,203,11,203,22,192,139,221
.byte	62,62,248,62,237,198,124,211,62,62,248,62,237,198,124,211
.byte	5,5,20,5,40,17,10,45,5,5,20,5,40,17,10,45
.byte	103,103,129,103,31,230,206,120,103,103,129,103,31,230,206,120
.byte	228,228,183,228,115,83,213,151,228,228,183,228,115,83,213,151
.byte	39,39,156,39,37,187,78,2,39,39,156,39,37,187,78,2
.byte	65,65,25,65,50,88,130,115,65,65,25,65,50,88,130,115
.byte	139,139,22,139,44,157,11,167,139,139,22,139,44,157,11,167
.byte	167,167,166,167,81,1,83,246,167,167,166,167,81,1,83,246
.byte	125,125,233,125,207,148,250,178,125,125,233,125,207,148,250,178
.byte	149,149,110,149,220,251,55,73,149,149,110,149,220,251,55,73
.byte	216,216,71,216,142,159,173,86,216,216,71,216,142,159,173,86
.byte	251,251,203,251,139,48,235,112,251,251,203,251,139,48,235,112
.byte	238,238,159,238,35,113,193,205,238,238,159,238,35,113,193,205
.byte	124,124,237,124,199,145,248,187,124,124,237,124,199,145,248,187
.byte	102,102,133,102,23,227,204,113,102,102,133,102,23,227,204,113
.byte	221,221,83,221,166,142,167,123,221,221,83,221,166,142,167,123
.byte	23,23,92,23,184,75,46,175,23,23,92,23,184,75,46,175
.byte	71,71,1,71,2,70,142,69,71,71,1,71,2,70,142,69
.byte	158,158,66,158,132,220,33,26,158,158,66,158,132,220,33,26
.byte	202,202,15,202,30,197,137,212,202,202,15,202,30,197,137,212
.byte	45,45,180,45,117,153,90,88,45,45,180,45,117,153,90,88
.byte	191,191,198,191,145,121,99,46,191,191,198,191,145,121,99,46
.byte	7,7,28,7,56,27,14,63,7,7,28,7,56,27,14,63
.byte	173,173,142,173,1,35,71,172,173,173,142,173,1,35,71,172
.byte	90,90,117,90,234,47,180,176,90,90,117,90,234,47,180,176
.byte	131,131,54,131,108,181,27,239,131,131,54,131,108,181,27,239
.byte	51,51,204,51,133,255,102,182,51,51,204,51,133,255,102,182
.byte	99,99,145,99,63,242,198,92,99,99,145,99,63,242,198,92
.byte	2,2,8,2,16,10,4,18,2,2,8,2,16,10,4,18
.byte	170,170,146,170,57,56,73,147,170,170,146,170,57,56,73,147
.byte	113,113,217,113,175,168,226,222,113,113,217,113,175,168,226,222
.byte	200,200,7,200,14,207,141,198,200,200,7,200,14,207,141,198
.byte	25,25,100,25,200,125,50,209,25,25,100,25,200,125,50,209
.byte	73,73,57,73,114,112,146,59,73,73,57,73,114,112,146,59
.byte	217,217,67,217,134,154,175,95,217,217,67,217,134,154,175,95
.byte	242,242,239,242,195,29,249,49,242,242,239,242,195,29,249,49
.byte	227,227,171,227,75,72,219,168,227,227,171,227,75,72,219,168
.byte	91,91,113,91,226,42,182,185,91,91,113,91,226,42,182,185
.byte	136,136,26,136,52,146,13,188,136,136,26,136,52,146,13,188
.byte	154,154,82,154,164,200,41,62,154,154,82,154,164,200,41,62
.byte	38,38,152,38,45,190,76,11,38,38,152,38,45,190,76,11
.byte	50,50,200,50,141,250,100,191,50,50,200,50,141,250,100,191
.byte	176,176,250,176,233,74,125,89,176,176,250,176,233,74,125,89
.byte	233,233,131,233,27,106,207,242,233,233,131,233,27,106,207,242
.byte	15,15,60,15,120,51,30,119,15,15,60,15,120,51,30,119
.byte	213,213,115,213,230,166,183,51,213,213,115,213,230,166,183,51
.byte	128,128,58,128,116,186,29,244,128,128,58,128,116,186,29,244
.byte	190,190,194,190,153,124,97,39,190,190,194,190,153,124,97,39
.byte	205,205,19,205,38,222,135,235,205,205,19,205,38,222,135,235
.byte	52,52,208,52,189,228,104,137,52,52,208,52,189,228,104,137
.byte	72,72,61,72,122,117,144,50,72,72,61,72,122,117,144,50
.byte	255,255,219,255,171,36,227,84,255,255,219,255,171,36,227,84
.byte	122,122,245,122,247,143,244,141,122,122,245,122,247,143,244,141
.byte	144,144,122,144,244,234,61,100,144,144,122,144,244,234,61,100
.byte	95,95,97,95,194,62,190,157,95,95,97,95,194,62,190,157
.byte	32,32,128,32,29,160,64,61,32,32,128,32,29,160,64,61
.byte	104,104,189,104,103,213,208,15,104,104,189,104,103,213,208,15
.byte	26,26,104,26,208,114,52,202,26,26,104,26,208,114,52,202
.byte	174,174,130,174,25,44,65,183,174,174,130,174,25,44,65,183
.byte	180,180,234,180,201,94,117,125,180,180,234,180,201,94,117,125
.byte	84,84,77,84,154,25,168,206,84,84,77,84,154,25,168,206
.byte	147,147,118,147,236,229,59,127,147,147,118,147,236,229,59,127
.byte	34,34,136,34,13,170,68,47,34,34,136,34,13,170,68,47
.byte	100,100,141,100,7,233,200,99,100,100,141,100,7,233,200,99
.byte	241,241,227,241,219,18,255,42,241,241,227,241,219,18,255,42
.byte	115,115,209,115,191,162,230,204,115,115,209,115,191,162,230,204
.byte	18,18,72,18,144,90,36,130,18,18,72,18,144,90,36,130
.byte	64,64,29,64,58,93,128,122,64,64,29,64,58,93,128,122
.byte	8,8,32,8,64,40,16,72,8,8,32,8,64,40,16,72
.byte	195,195,43,195,86,232,155,149,195,195,43,195,86,232,155,149
.byte	236,236,151,236,51,123,197,223,236,236,151,236,51,123,197,223
.byte	219,219,75,219,150,144,171,77,219,219,75,219,150,144,171,77
.byte	161,161,190,161,97,31,95,192,161,161,190,161,97,31,95,192
.byte	141,141,14,141,28,131,7,145,141,141,14,141,28,131,7,145
.byte	61,61,244,61,245,201,122,200,61,61,244,61,245,201,122,200
.byte	151,151,102,151,204,241,51,91,151,151,102,151,204,241,51,91
.byte	0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
.byte	207,207,27,207,54,212,131,249,207,207,27,207,54,212,131,249
.byte	43,43,172,43,69,135,86,110,43,43,172,43,69,135,86,110
.byte	118,118,197,118,151,179,236,225,118,118,197,118,151,179,236,225
.byte	130,130,50,130,100,176,25,230,130,130,50,130,100,176,25,230
.byte	214,214,127,214,254,169,177,40,214,214,127,214,254,169,177,40
.byte	27,27,108,27,216,119,54,195,27,27,108,27,216,119,54,195
.byte	181,181,238,181,193,91,119,116,181,181,238,181,193,91,119,116
.byte	175,175,134,175,17,41,67,190,175,175,134,175,17,41,67,190
.byte	106,106,181,106,119,223,212,29,106,106,181,106,119,223,212,29
.byte	80,80,93,80,186,13,160,234,80,80,93,80,186,13,160,234
.byte	69,69,9,69,18,76,138,87,69,69,9,69,18,76,138,87
.byte	243,243,235,243,203,24,251,56,243,243,235,243,203,24,251,56
.byte	48,48,192,48,157,240,96,173,48,48,192,48,157,240,96,173
.byte	239,239,155,239,43,116,195,196,239,239,155,239,43,116,195,196
.byte	63,63,252,63,229,195,126,218,63,63,252,63,229,195,126,218
.byte	85,85,73,85,146,28,170,199,85,85,73,85,146,28,170,199
.byte	162,162,178,162,121,16,89,219,162,162,178,162,121,16,89,219
.byte	234,234,143,234,3,101,201,233,234,234,143,234,3,101,201,233
.byte	101,101,137,101,15,236,202,106,101,101,137,101,15,236,202,106
.byte	186,186,210,186,185,104,105,3,186,186,210,186,185,104,105,3
.byte	47,47,188,47,101,147,94,74,47,47,188,47,101,147,94,74
.byte	192,192,39,192,78,231,157,142,192,192,39,192,78,231,157,142
.byte	222,222,95,222,190,129,161,96,222,222,95,222,190,129,161,96
.byte	28,28,112,28,224,108,56,252,28,28,112,28,224,108,56,252
.byte	253,253,211,253,187,46,231,70,253,253,211,253,187,46,231,70
.byte	77,77,41,77,82,100,154,31,77,77,41,77,82,100,154,31
.byte	146,146,114,146,228,224,57,118,146,146,114,146,228,224,57,118
.byte	117,117,201,117,143,188,234,250,117,117,201,117,143,188,234,250
.byte	6,6,24,6,48,30,12,54,6,6,24,6,48,30,12,54
.byte	138,138,18,138,36,152,9,174,138,138,18,138,36,152,9,174
.byte	178,178,242,178,249,64,121,75,178,178,242,178,249,64,121,75
.byte	230,230,191,230,99,89,209,133,230,230,191,230,99,89,209,133
.byte	14,14,56,14,112,54,28,126,14,14,56,14,112,54,28,126
.byte	31,31,124,31,248,99,62,231,31,31,124,31,248,99,62,231
.byte	98,98,149,98,55,247,196,85,98,98,149,98,55,247,196,85
.byte	212,212,119,212,238,163,181,58,212,212,119,212,238,163,181,58
.byte	168,168,154,168,41,50,77,129,168,168,154,168,41,50,77,129
.byte	150,150,98,150,196,244,49,82,150,150,98,150,196,244,49,82
.byte	249,249,195,249,155,58,239,98,249,249,195,249,155,58,239,98
.byte	197,197,51,197,102,246,151,163,197,197,51,197,102,246,151,163
.byte	37,37,148,37,53,177,74,16,37,37,148,37,53,177,74,16
.byte	89,89,121,89,242,32,178,171,89,89,121,89,242,32,178,171
.byte	132,132,42,132,84,174,21,208,132,132,42,132,84,174,21,208
.byte	114,114,213,114,183,167,228,197,114,114,213,114,183,167,228,197
.byte	57,57,228,57,213,221,114,236,57,57,228,57,213,221,114,236
.byte	76,76,45,76,90,97,152,22,76,76,45,76,90,97,152,22
.byte	94,94,101,94,202,59,188,148,94,94,101,94,202,59,188,148
.byte	120,120,253,120,231,133,240,159,120,120,253,120,231,133,240,159
.byte	56,56,224,56,221,216,112,229,56,56,224,56,221,216,112,229
.byte	140,140,10,140,20,134,5,152,140,140,10,140,20,134,5,152
.byte	209,209,99,209,198,178,191,23,209,209,99,209,198,178,191,23
.byte	165,165,174,165,65,11,87,228,165,165,174,165,65,11,87,228
.byte	226,226,175,226,67,77,217,161,226,226,175,226,67,77,217,161
.byte	97,97,153,97,47,248,194,78,97,97,153,97,47,248,194,78
.byte	179,179,246,179,241,69,123,66,179,179,246,179,241,69,123,66
.byte	33,33,132,33,21,165,66,52,33,33,132,33,21,165,66,52
.byte	156,156,74,156,148,214,37,8,156,156,74,156,148,214,37,8
.byte	30,30,120,30,240,102,60,238,30,30,120,30,240,102,60,238
.byte	67,67,17,67,34,82,134,97,67,67,17,67,34,82,134,97
.byte	199,199,59,199,118,252,147,177,199,199,59,199,118,252,147,177
.byte	252,252,215,252,179,43,229,79,252,252,215,252,179,43,229,79
.byte	4,4,16,4,32,20,8,36,4,4,16,4,32,20,8,36
.byte	81,81,89,81,178,8,162,227,81,81,89,81,178,8,162,227
.byte	153,153,94,153,188,199,47,37,153,153,94,153,188,199,47,37
.byte	109,109,169,109,79,196,218,34,109,109,169,109,79,196,218,34
.byte	13,13,52,13,104,57,26,101,13,13,52,13,104,57,26,101
.byte	250,250,207,250,131,53,233,121,250,250,207,250,131,53,233,121
.byte	223,223,91,223,182,132,163,105,223,223,91,223,182,132,163,105
.byte	126,126,229,126,215,155,252,169,126,126,229,126,215,155,252,169
.byte	36,36,144,36,61,180,72,25,36,36,144,36,61,180,72,25
.byte	59,59,236,59,197,215,118,254,59,59,236,59,197,215,118,254
.byte	171,171,150,171,49,61,75,154,171,171,150,171,49,61,75,154
.byte	206,206,31,206,62,209,129,240,206,206,31,206,62,209,129,240
.byte	17,17,68,17,136,85,34,153,17,17,68,17,136,85,34,153
.byte	143,143,6,143,12,137,3,131,143,143,6,143,12,137,3,131
.byte	78,78,37,78,74,107,156,4,78,78,37,78,74,107,156,4
.byte	183,183,230,183,209,81,115,102,183,183,230,183,209,81,115,102
.byte	235,235,139,235,11,96,203,224,235,235,139,235,11,96,203,224
.byte	60,60,240,60,253,204,120,193,60,60,240,60,253,204,120,193
.byte	129,129,62,129,124,191,31,253,129,129,62,129,124,191,31,253
.byte	148,148,106,148,212,254,53,64,148,148,106,148,212,254,53,64
.byte	247,247,251,247,235,12,243,28,247,247,251,247,235,12,243,28
.byte	185,185,222,185,161,103,111,24,185,185,222,185,161,103,111,24
.byte	19,19,76,19,152,95,38,139,19,19,76,19,152,95,38,139
.byte	44,44,176,44,125,156,88,81,44,44,176,44,125,156,88,81
.byte	211,211,107,211,214,184,187,5,211,211,107,211,214,184,187,5
.byte	231,231,187,231,107,92,211,140,231,231,187,231,107,92,211,140
.byte	110,110,165,110,87,203,220,57,110,110,165,110,87,203,220,57
.byte	196,196,55,196,110,243,149,170,196,196,55,196,110,243,149,170
.byte	3,3,12,3,24,15,6,27,3,3,12,3,24,15,6,27
.byte	86,86,69,86,138,19,172,220,86,86,69,86,138,19,172,220
.byte	68,68,13,68,26,73,136,94,68,68,13,68,26,73,136,94
.byte	127,127,225,127,223,158,254,160,127,127,225,127,223,158,254,160
.byte	169,169,158,169,33,55,79,136,169,169,158,169,33,55,79,136
.byte	42,42,168,42,77,130,84,103,42,42,168,42,77,130,84,103
.byte	187,187,214,187,177,109,107,10,187,187,214,187,177,109,107,10
.byte	193,193,35,193,70,226,159,135,193,193,35,193,70,226,159,135
.byte	83,83,81,83,162,2,166,241,83,83,81,83,162,2,166,241
.byte	220,220,87,220,174,139,165,114,220,220,87,220,174,139,165,114
.byte	11,11,44,11,88,39,22,83,11,11,44,11,88,39,22,83
.byte	157,157,78,157,156,211,39,1,157,157,78,157,156,211,39,1
.byte	108,108,173,108,71,193,216,43,108,108,173,108,71,193,216,43
.byte	49,49,196,49,149,245,98,164,49,49,196,49,149,245,98,164
.byte	116,116,205,116,135,185,232,243,116,116,205,116,135,185,232,243
.byte	246,246,255,246,227,9,241,21,246,246,255,246,227,9,241,21
.byte	70,70,5,70,10,67,140,76,70,70,5,70,10,67,140,76
.byte	172,172,138,172,9,38,69,165,172,172,138,172,9,38,69,165
.byte	137,137,30,137,60,151,15,181,137,137,30,137,60,151,15,181
.byte	20,20,80,20,160,68,40,180,20,20,80,20,160,68,40,180
.byte	225,225,163,225,91,66,223,186,225,225,163,225,91,66,223,186
.byte	22,22,88,22,176,78,44,166,22,22,88,22,176,78,44,166
.byte	58,58,232,58,205,210,116,247,58,58,232,58,205,210,116,247
.byte	105,105,185,105,111,208,210,6,105,105,185,105,111,208,210,6
.byte	9,9,36,9,72,45,18,65,9,9,36,9,72,45,18,65
.byte	112,112,221,112,167,173,224,215,112,112,221,112,167,173,224,215
.byte	182,182,226,182,217,84,113,111,182,182,226,182,217,84,113,111
.byte	208,208,103,208,206,183,189,30,208,208,103,208,206,183,189,30
.byte	237,237,147,237,59,126,199,214,237,237,147,237,59,126,199,214
.byte	204,204,23,204,46,219,133,226,204,204,23,204,46,219,133,226
.byte	66,66,21,66,42,87,132,104,66,66,21,66,42,87,132,104
.byte	152,152,90,152,180,194,45,44,152,152,90,152,180,194,45,44
.byte	164,164,170,164,73,14,85,237,164,164,170,164,73,14,85,237
.byte	40,40,160,40,93,136,80,117,40,40,160,40,93,136,80,117
.byte	92,92,109,92,218,49,184,134,92,92,109,92,218,49,184,134
.byte	248,248,199,248,147,63,237,107,248,248,199,248,147,63,237,107
.byte	134,134,34,134,68,164,17,194,134,134,34,134,68,164,17,194
.byte	24,35,198,232,135,184,1,79
.byte	54,166,210,245,121,111,145,82
.byte	96,188,155,142,163,12,123,53
.byte	29,224,215,194,46,75,254,87
.byte	21,119,55,229,159,240,74,218
.byte	88,201,41,10,177,160,107,133
.byte	189,93,16,244,203,62,5,103
.byte	228,39,65,139,167,125,149,216
.byte	251,238,124,102,221,23,71,158
.byte	202,45,191,7,173,90,131,51
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
          node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/crypto/x86_64cpuid.s            0000664 0000000 0000000 00000017761 14746647661 0030277 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        
.hidden	OPENSSL_cpuid_setup
.section	.init
	call	OPENSSL_cpuid_setup

.hidden	OPENSSL_ia32cap_P
.comm	OPENSSL_ia32cap_P,16,4

.text	

.globl	OPENSSL_atomic_add
.type	OPENSSL_atomic_add,@function
.align	16
OPENSSL_atomic_add:
.cfi_startproc	
.byte	243,15,30,250
	movl	(%rdi),%eax
.Lspin:	leaq	(%rsi,%rax,1),%r8
.byte	0xf0
	cmpxchgl	%r8d,(%rdi)
	jne	.Lspin
	movl	%r8d,%eax
.byte	0x48,0x98
	.byte	0xf3,0xc3
.cfi_endproc	
.size	OPENSSL_atomic_add,.-OPENSSL_atomic_add

.globl	OPENSSL_rdtsc
.type	OPENSSL_rdtsc,@function
.align	16
OPENSSL_rdtsc:
.cfi_startproc	
.byte	243,15,30,250
	rdtsc
	shlq	$32,%rdx
	orq	%rdx,%rax
	.byte	0xf3,0xc3
.cfi_endproc	
.size	OPENSSL_rdtsc,.-OPENSSL_rdtsc

.globl	OPENSSL_ia32_cpuid
.type	OPENSSL_ia32_cpuid,@function
.align	16
OPENSSL_ia32_cpuid:
.cfi_startproc	
.byte	243,15,30,250
	movq	%rbx,%r8
.cfi_register	%rbx,%r8

	xorl	%eax,%eax
	movq	%rax,8(%rdi)
	cpuid
	movl	%eax,%r11d

	xorl	%eax,%eax
	cmpl	$0x756e6547,%ebx
	setne	%al
	movl	%eax,%r9d
	cmpl	$0x49656e69,%edx
	setne	%al
	orl	%eax,%r9d
	cmpl	$0x6c65746e,%ecx
	setne	%al
	orl	%eax,%r9d
	jz	.Lintel

	cmpl	$0x68747541,%ebx
	setne	%al
	movl	%eax,%r10d
	cmpl	$0x69746E65,%edx
	setne	%al
	orl	%eax,%r10d
	cmpl	$0x444D4163,%ecx
	setne	%al
	orl	%eax,%r10d
	jnz	.Lintel


	movl	$0x80000000,%eax
	cpuid
	cmpl	$0x80000001,%eax
	jb	.Lintel
	movl	%eax,%r10d
	movl	$0x80000001,%eax
	cpuid
	orl	%ecx,%r9d
	andl	$0x00000801,%r9d

	cmpl	$0x80000008,%r10d
	jb	.Lintel

	movl	$0x80000008,%eax
	cpuid
	movzbq	%cl,%r10
	incq	%r10

	movl	$1,%eax
	cpuid
	btl	$28,%edx
	jnc	.Lgeneric
	shrl	$16,%ebx
	cmpb	%r10b,%bl
	ja	.Lgeneric
	andl	$0xefffffff,%edx
	jmp	.Lgeneric

.Lintel:
	cmpl	$4,%r11d
	movl	$-1,%r10d
	jb	.Lnocacheinfo

	movl	$4,%eax
	movl	$0,%ecx
	cpuid
	movl	%eax,%r10d
	shrl	$14,%r10d
	andl	$0xfff,%r10d

.Lnocacheinfo:
	movl	$1,%eax
	cpuid
	movd	%eax,%xmm0
	andl	$0xbfefffff,%edx
	cmpl	$0,%r9d
	jne	.Lnotintel
	orl	$0x40000000,%edx
	andb	$15,%ah
	cmpb	$15,%ah
	jne	.LnotP4
	orl	$0x00100000,%edx
.LnotP4:
	cmpb	$6,%ah
	jne	.Lnotintel
	andl	$0x0fff0ff0,%eax
	cmpl	$0x00050670,%eax
	je	.Lknights
	cmpl	$0x00080650,%eax
	jne	.Lnotintel
.Lknights:
	andl	$0xfbffffff,%ecx

.Lnotintel:
	btl	$28,%edx
	jnc	.Lgeneric
	andl	$0xefffffff,%edx
	cmpl	$0,%r10d
	je	.Lgeneric

	orl	$0x10000000,%edx
	shrl	$16,%ebx
	cmpb	$1,%bl
	ja	.Lgeneric
	andl	$0xefffffff,%edx
.Lgeneric:
	andl	$0x00000800,%r9d
	andl	$0xfffff7ff,%ecx
	orl	%ecx,%r9d

	movl	%edx,%r10d

	cmpl	$7,%r11d
	jb	.Lno_extended_info
	movl	$7,%eax
	xorl	%ecx,%ecx
	cpuid
	btl	$26,%r9d
	jc	.Lnotknights
	andl	$0xfff7ffff,%ebx
.Lnotknights:
	movd	%xmm0,%eax
	andl	$0x0fff0ff0,%eax
	cmpl	$0x00050650,%eax
	jne	.Lnotskylakex
	andl	$0xfffeffff,%ebx

.Lnotskylakex:
	movl	%ebx,8(%rdi)
	movl	%ecx,12(%rdi)
.Lno_extended_info:

	btl	$27,%r9d
	jnc	.Lclear_avx
	xorl	%ecx,%ecx
.byte	0x0f,0x01,0xd0
	andl	$0xe6,%eax
	cmpl	$0xe6,%eax
	je	.Ldone
	andl	$0x3fdeffff,8(%rdi)




	andl	$6,%eax
	cmpl	$6,%eax
	je	.Ldone
.Lclear_avx:
	movl	$0xefffe7ff,%eax
	andl	%eax,%r9d
	movl	$0x3fdeffdf,%eax
	andl	%eax,8(%rdi)
.Ldone:
	shlq	$32,%r9
	movl	%r10d,%eax
	movq	%r8,%rbx
.cfi_restore	%rbx
	orq	%r9,%rax
	.byte	0xf3,0xc3
.cfi_endproc	
.size	OPENSSL_ia32_cpuid,.-OPENSSL_ia32_cpuid

.globl	OPENSSL_cleanse
.type	OPENSSL_cleanse,@function
.align	16
OPENSSL_cleanse:
.cfi_startproc	
.byte	243,15,30,250
	xorq	%rax,%rax
	cmpq	$15,%rsi
	jae	.Lot
	cmpq	$0,%rsi
	je	.Lret
.Little:
	movb	%al,(%rdi)
	subq	$1,%rsi
	leaq	1(%rdi),%rdi
	jnz	.Little
.Lret:
	.byte	0xf3,0xc3
.align	16
.Lot:
	testq	$7,%rdi
	jz	.Laligned
	movb	%al,(%rdi)
	leaq	-1(%rsi),%rsi
	leaq	1(%rdi),%rdi
	jmp	.Lot
.Laligned:
	movq	%rax,(%rdi)
	leaq	-8(%rsi),%rsi
	testq	$-8,%rsi
	leaq	8(%rdi),%rdi
	jnz	.Laligned
	cmpq	$0,%rsi
	jne	.Little
	.byte	0xf3,0xc3
.cfi_endproc	
.size	OPENSSL_cleanse,.-OPENSSL_cleanse

.globl	CRYPTO_memcmp
.type	CRYPTO_memcmp,@function
.align	16
CRYPTO_memcmp:
.cfi_startproc	
.byte	243,15,30,250
	xorq	%rax,%rax
	xorq	%r10,%r10
	cmpq	$0,%rdx
	je	.Lno_data
	cmpq	$16,%rdx
	jne	.Loop_cmp
	movq	(%rdi),%r10
	movq	8(%rdi),%r11
	movq	$1,%rdx
	xorq	(%rsi),%r10
	xorq	8(%rsi),%r11
	orq	%r11,%r10
	cmovnzq	%rdx,%rax
	.byte	0xf3,0xc3

.align	16
.Loop_cmp:
	movb	(%rdi),%r10b
	leaq	1(%rdi),%rdi
	xorb	(%rsi),%r10b
	leaq	1(%rsi),%rsi
	orb	%r10b,%al
	decq	%rdx
	jnz	.Loop_cmp
	negq	%rax
	shrq	$63,%rax
.Lno_data:
	.byte	0xf3,0xc3
.cfi_endproc	
.size	CRYPTO_memcmp,.-CRYPTO_memcmp
.globl	OPENSSL_wipe_cpu
.type	OPENSSL_wipe_cpu,@function
.align	16
OPENSSL_wipe_cpu:
.cfi_startproc	
.byte	243,15,30,250
	pxor	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	pxor	%xmm2,%xmm2
	pxor	%xmm3,%xmm3
	pxor	%xmm4,%xmm4
	pxor	%xmm5,%xmm5
	pxor	%xmm6,%xmm6
	pxor	%xmm7,%xmm7
	pxor	%xmm8,%xmm8
	pxor	%xmm9,%xmm9
	pxor	%xmm10,%xmm10
	pxor	%xmm11,%xmm11
	pxor	%xmm12,%xmm12
	pxor	%xmm13,%xmm13
	pxor	%xmm14,%xmm14
	pxor	%xmm15,%xmm15
	xorq	%rcx,%rcx
	xorq	%rdx,%rdx
	xorq	%rsi,%rsi
	xorq	%rdi,%rdi
	xorq	%r8,%r8
	xorq	%r9,%r9
	xorq	%r10,%r10
	xorq	%r11,%r11
	leaq	8(%rsp),%rax
	.byte	0xf3,0xc3
.cfi_endproc	
.size	OPENSSL_wipe_cpu,.-OPENSSL_wipe_cpu
.globl	OPENSSL_instrument_bus
.type	OPENSSL_instrument_bus,@function
.align	16
OPENSSL_instrument_bus:
.cfi_startproc	
.byte	243,15,30,250
	movq	%rdi,%r10
	movq	%rsi,%rcx
	movq	%rsi,%r11

	rdtsc
	movl	%eax,%r8d
	movl	$0,%r9d
	clflush	(%r10)
.byte	0xf0
	addl	%r9d,(%r10)
	jmp	.Loop
.align	16
.Loop:	rdtsc
	movl	%eax,%edx
	subl	%r8d,%eax
	movl	%edx,%r8d
	movl	%eax,%r9d
	clflush	(%r10)
.byte	0xf0
	addl	%eax,(%r10)
	leaq	4(%r10),%r10
	subq	$1,%rcx
	jnz	.Loop

	movq	%r11,%rax
	.byte	0xf3,0xc3
.cfi_endproc	
.size	OPENSSL_instrument_bus,.-OPENSSL_instrument_bus

.globl	OPENSSL_instrument_bus2
.type	OPENSSL_instrument_bus2,@function
.align	16
OPENSSL_instrument_bus2:
.cfi_startproc	
.byte	243,15,30,250
	movq	%rdi,%r10
	movq	%rsi,%rcx
	movq	%rdx,%r11
	movq	%rcx,8(%rsp)

	rdtsc
	movl	%eax,%r8d
	movl	$0,%r9d

	clflush	(%r10)
.byte	0xf0
	addl	%r9d,(%r10)

	rdtsc
	movl	%eax,%edx
	subl	%r8d,%eax
	movl	%edx,%r8d
	movl	%eax,%r9d
.Loop2:
	clflush	(%r10)
.byte	0xf0
	addl	%eax,(%r10)

	subq	$1,%r11
	jz	.Ldone2

	rdtsc
	movl	%eax,%edx
	subl	%r8d,%eax
	movl	%edx,%r8d
	cmpl	%r9d,%eax
	movl	%eax,%r9d
	movl	$0,%edx
	setne	%dl
	subq	%rdx,%rcx
	leaq	(%r10,%rdx,4),%r10
	jnz	.Loop2

.Ldone2:
	movq	8(%rsp),%rax
	subq	%rcx,%rax
	.byte	0xf3,0xc3
.cfi_endproc	
.size	OPENSSL_instrument_bus2,.-OPENSSL_instrument_bus2
.globl	OPENSSL_ia32_rdrand_bytes
.type	OPENSSL_ia32_rdrand_bytes,@function
.align	16
OPENSSL_ia32_rdrand_bytes:
.cfi_startproc	
.byte	243,15,30,250
	xorq	%rax,%rax
	cmpq	$0,%rsi
	je	.Ldone_rdrand_bytes

	movq	$8,%r11
.Loop_rdrand_bytes:
.byte	73,15,199,242
	jc	.Lbreak_rdrand_bytes
	decq	%r11
	jnz	.Loop_rdrand_bytes
	jmp	.Ldone_rdrand_bytes

.align	16
.Lbreak_rdrand_bytes:
	cmpq	$8,%rsi
	jb	.Ltail_rdrand_bytes
	movq	%r10,(%rdi)
	leaq	8(%rdi),%rdi
	addq	$8,%rax
	subq	$8,%rsi
	jz	.Ldone_rdrand_bytes
	movq	$8,%r11
	jmp	.Loop_rdrand_bytes

.align	16
.Ltail_rdrand_bytes:
	movb	%r10b,(%rdi)
	leaq	1(%rdi),%rdi
	incq	%rax
	shrq	$8,%r10
	decq	%rsi
	jnz	.Ltail_rdrand_bytes

.Ldone_rdrand_bytes:
	xorq	%r10,%r10
	.byte	0xf3,0xc3
.cfi_endproc	
.size	OPENSSL_ia32_rdrand_bytes,.-OPENSSL_ia32_rdrand_bytes
.globl	OPENSSL_ia32_rdseed_bytes
.type	OPENSSL_ia32_rdseed_bytes,@function
.align	16
OPENSSL_ia32_rdseed_bytes:
.cfi_startproc	
.byte	243,15,30,250
	xorq	%rax,%rax
	cmpq	$0,%rsi
	je	.Ldone_rdseed_bytes

	movq	$8,%r11
.Loop_rdseed_bytes:
.byte	73,15,199,250
	jc	.Lbreak_rdseed_bytes
	decq	%r11
	jnz	.Loop_rdseed_bytes
	jmp	.Ldone_rdseed_bytes

.align	16
.Lbreak_rdseed_bytes:
	cmpq	$8,%rsi
	jb	.Ltail_rdseed_bytes
	movq	%r10,(%rdi)
	leaq	8(%rdi),%rdi
	addq	$8,%rax
	subq	$8,%rsi
	jz	.Ldone_rdseed_bytes
	movq	$8,%r11
	jmp	.Loop_rdseed_bytes

.align	16
.Ltail_rdseed_bytes:
	movb	%r10b,(%rdi)
	leaq	1(%rdi),%rdi
	incq	%rax
	shrq	$8,%r10
	decq	%rsi
	jnz	.Ltail_rdseed_bytes

.Ldone_rdseed_bytes:
	xorq	%r10,%r10
	.byte	0xf3,0xc3
.cfi_endproc	
.size	OPENSSL_ia32_rdseed_bytes,.-OPENSSL_ia32_rdseed_bytes
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
               node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/engines/                        0000775 0000000 0000000 00000000000 14746647661 0026224 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/engines/e_padlock-x86_64.s      0000664 0000000 0000000 00000044133 14746647661 0031272 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        .text	
.globl	padlock_capability
.type	padlock_capability,@function
.align	16
padlock_capability:
	movq	%rbx,%r8
	xorl	%eax,%eax
	cpuid
	xorl	%eax,%eax
	cmpl	$0x746e6543,%ebx
	jne	.Lzhaoxin
	cmpl	$0x48727561,%edx
	jne	.Lnoluck
	cmpl	$0x736c7561,%ecx
	jne	.Lnoluck
	jmp	.LzhaoxinEnd
.Lzhaoxin:
	cmpl	$0x68532020,%ebx
	jne	.Lnoluck
	cmpl	$0x68676e61,%edx
	jne	.Lnoluck
	cmpl	$0x20206961,%ecx
	jne	.Lnoluck
.LzhaoxinEnd:
	movl	$0xC0000000,%eax
	cpuid
	movl	%eax,%edx
	xorl	%eax,%eax
	cmpl	$0xC0000001,%edx
	jb	.Lnoluck
	movl	$0xC0000001,%eax
	cpuid
	movl	%edx,%eax
	andl	$0xffffffef,%eax
	orl	$0x10,%eax
.Lnoluck:
	movq	%r8,%rbx
	.byte	0xf3,0xc3
.size	padlock_capability,.-padlock_capability

.globl	padlock_key_bswap
.type	padlock_key_bswap,@function
.align	16
padlock_key_bswap:
	movl	240(%rdi),%edx
	incl	%edx
	shll	$2,%edx
.Lbswap_loop:
	movl	(%rdi),%eax
	bswapl	%eax
	movl	%eax,(%rdi)
	leaq	4(%rdi),%rdi
	subl	$1,%edx
	jnz	.Lbswap_loop
	.byte	0xf3,0xc3
.size	padlock_key_bswap,.-padlock_key_bswap

.globl	padlock_verify_context
.type	padlock_verify_context,@function
.align	16
padlock_verify_context:
	movq	%rdi,%rdx
	pushf
	leaq	.Lpadlock_saved_context(%rip),%rax
	call	_padlock_verify_ctx
	leaq	8(%rsp),%rsp
	.byte	0xf3,0xc3
.size	padlock_verify_context,.-padlock_verify_context

.type	_padlock_verify_ctx,@function
.align	16
_padlock_verify_ctx:
	movq	8(%rsp),%r8
	btq	$30,%r8
	jnc	.Lverified
	cmpq	(%rax),%rdx
	je	.Lverified
	pushf
	popf
.Lverified:
	movq	%rdx,(%rax)
	.byte	0xf3,0xc3
.size	_padlock_verify_ctx,.-_padlock_verify_ctx

.globl	padlock_reload_key
.type	padlock_reload_key,@function
.align	16
padlock_reload_key:
	pushf
	popf
	.byte	0xf3,0xc3
.size	padlock_reload_key,.-padlock_reload_key

.globl	padlock_aes_block
.type	padlock_aes_block,@function
.align	16
padlock_aes_block:
	movq	%rbx,%r8
	movq	$1,%rcx
	leaq	32(%rdx),%rbx
	leaq	16(%rdx),%rdx
.byte	0xf3,0x0f,0xa7,0xc8
	movq	%r8,%rbx
	.byte	0xf3,0xc3
.size	padlock_aes_block,.-padlock_aes_block

.globl	padlock_xstore
.type	padlock_xstore,@function
.align	16
padlock_xstore:
	movl	%esi,%edx
.byte	0x0f,0xa7,0xc0
	.byte	0xf3,0xc3
.size	padlock_xstore,.-padlock_xstore

.globl	padlock_sha1_oneshot
.type	padlock_sha1_oneshot,@function
.align	16
padlock_sha1_oneshot:
	movq	%rdx,%rcx
	movq	%rdi,%rdx
	movups	(%rdi),%xmm0
	subq	$128+8,%rsp
	movl	16(%rdi),%eax
	movaps	%xmm0,(%rsp)
	movq	%rsp,%rdi
	movl	%eax,16(%rsp)
	xorq	%rax,%rax
.byte	0xf3,0x0f,0xa6,0xc8
	movaps	(%rsp),%xmm0
	movl	16(%rsp),%eax
	addq	$128+8,%rsp
	movups	%xmm0,(%rdx)
	movl	%eax,16(%rdx)
	.byte	0xf3,0xc3
.size	padlock_sha1_oneshot,.-padlock_sha1_oneshot

.globl	padlock_sha1_blocks
.type	padlock_sha1_blocks,@function
.align	16
padlock_sha1_blocks:
	movq	%rdx,%rcx
	movq	%rdi,%rdx
	movups	(%rdi),%xmm0
	subq	$128+8,%rsp
	movl	16(%rdi),%eax
	movaps	%xmm0,(%rsp)
	movq	%rsp,%rdi
	movl	%eax,16(%rsp)
	movq	$-1,%rax
.byte	0xf3,0x0f,0xa6,0xc8
	movaps	(%rsp),%xmm0
	movl	16(%rsp),%eax
	addq	$128+8,%rsp
	movups	%xmm0,(%rdx)
	movl	%eax,16(%rdx)
	.byte	0xf3,0xc3
.size	padlock_sha1_blocks,.-padlock_sha1_blocks

.globl	padlock_sha256_oneshot
.type	padlock_sha256_oneshot,@function
.align	16
padlock_sha256_oneshot:
	movq	%rdx,%rcx
	movq	%rdi,%rdx
	movups	(%rdi),%xmm0
	subq	$128+8,%rsp
	movups	16(%rdi),%xmm1
	movaps	%xmm0,(%rsp)
	movq	%rsp,%rdi
	movaps	%xmm1,16(%rsp)
	xorq	%rax,%rax
.byte	0xf3,0x0f,0xa6,0xd0
	movaps	(%rsp),%xmm0
	movaps	16(%rsp),%xmm1
	addq	$128+8,%rsp
	movups	%xmm0,(%rdx)
	movups	%xmm1,16(%rdx)
	.byte	0xf3,0xc3
.size	padlock_sha256_oneshot,.-padlock_sha256_oneshot

.globl	padlock_sha256_blocks
.type	padlock_sha256_blocks,@function
.align	16
padlock_sha256_blocks:
	movq	%rdx,%rcx
	movq	%rdi,%rdx
	movups	(%rdi),%xmm0
	subq	$128+8,%rsp
	movups	16(%rdi),%xmm1
	movaps	%xmm0,(%rsp)
	movq	%rsp,%rdi
	movaps	%xmm1,16(%rsp)
	movq	$-1,%rax
.byte	0xf3,0x0f,0xa6,0xd0
	movaps	(%rsp),%xmm0
	movaps	16(%rsp),%xmm1
	addq	$128+8,%rsp
	movups	%xmm0,(%rdx)
	movups	%xmm1,16(%rdx)
	.byte	0xf3,0xc3
.size	padlock_sha256_blocks,.-padlock_sha256_blocks

.globl	padlock_sha512_blocks
.type	padlock_sha512_blocks,@function
.align	16
padlock_sha512_blocks:
	movq	%rdx,%rcx
	movq	%rdi,%rdx
	movups	(%rdi),%xmm0
	subq	$128+8,%rsp
	movups	16(%rdi),%xmm1
	movups	32(%rdi),%xmm2
	movups	48(%rdi),%xmm3
	movaps	%xmm0,(%rsp)
	movq	%rsp,%rdi
	movaps	%xmm1,16(%rsp)
	movaps	%xmm2,32(%rsp)
	movaps	%xmm3,48(%rsp)
.byte	0xf3,0x0f,0xa6,0xe0
	movaps	(%rsp),%xmm0
	movaps	16(%rsp),%xmm1
	movaps	32(%rsp),%xmm2
	movaps	48(%rsp),%xmm3
	addq	$128+8,%rsp
	movups	%xmm0,(%rdx)
	movups	%xmm1,16(%rdx)
	movups	%xmm2,32(%rdx)
	movups	%xmm3,48(%rdx)
	.byte	0xf3,0xc3
.size	padlock_sha512_blocks,.-padlock_sha512_blocks
.globl	padlock_ecb_encrypt
.type	padlock_ecb_encrypt,@function
.align	16
padlock_ecb_encrypt:
	pushq	%rbp
	pushq	%rbx

	xorl	%eax,%eax
	testq	$15,%rdx
	jnz	.Lecb_abort
	testq	$15,%rcx
	jnz	.Lecb_abort
	leaq	.Lpadlock_saved_context(%rip),%rax
	pushf
	cld
	call	_padlock_verify_ctx
	leaq	16(%rdx),%rdx
	xorl	%eax,%eax
	xorl	%ebx,%ebx
	testl	$32,(%rdx)
	jnz	.Lecb_aligned
	testq	$0x0f,%rdi
	setz	%al
	testq	$0x0f,%rsi
	setz	%bl
	testl	%ebx,%eax
	jnz	.Lecb_aligned
	negq	%rax
	movq	$512,%rbx
	notq	%rax
	leaq	(%rsp),%rbp
	cmpq	%rbx,%rcx
	cmovcq	%rcx,%rbx
	andq	%rbx,%rax
	movq	%rcx,%rbx
	negq	%rax
	andq	$512-1,%rbx
	leaq	(%rax,%rbp,1),%rsp
	movq	$512,%rax
	cmovzq	%rax,%rbx
	cmpq	%rbx,%rcx
	ja	.Lecb_loop
	movq	%rsi,%rax
	cmpq	%rsp,%rbp
	cmoveq	%rdi,%rax
	addq	%rcx,%rax
	negq	%rax
	andq	$0xfff,%rax
	cmpq	$128,%rax
	movq	$-128,%rax
	cmovaeq	%rbx,%rax
	andq	%rax,%rbx
	jz	.Lecb_unaligned_tail
	jmp	.Lecb_loop
.align	16
.Lecb_loop:
	cmpq	%rcx,%rbx
	cmovaq	%rcx,%rbx
	movq	%rdi,%r8
	movq	%rsi,%r9
	movq	%rcx,%r10
	movq	%rbx,%rcx
	movq	%rbx,%r11
	testq	$0x0f,%rdi
	cmovnzq	%rsp,%rdi
	testq	$0x0f,%rsi
	jz	.Lecb_inp_aligned
	shrq	$3,%rcx
.byte	0xf3,0x48,0xa5
	subq	%rbx,%rdi
	movq	%rbx,%rcx
	movq	%rdi,%rsi
.Lecb_inp_aligned:
	leaq	-16(%rdx),%rax
	leaq	16(%rdx),%rbx
	shrq	$4,%rcx
.byte	0xf3,0x0f,0xa7,200
	movq	%r8,%rdi
	movq	%r11,%rbx
	testq	$0x0f,%rdi
	jz	.Lecb_out_aligned
	movq	%rbx,%rcx
	leaq	(%rsp),%rsi
	shrq	$3,%rcx
.byte	0xf3,0x48,0xa5
	subq	%rbx,%rdi
.Lecb_out_aligned:
	movq	%r9,%rsi
	movq	%r10,%rcx
	addq	%rbx,%rdi
	addq	%rbx,%rsi
	subq	%rbx,%rcx
	movq	$512,%rbx
	jz	.Lecb_break
	cmpq	%rbx,%rcx
	jae	.Lecb_loop
.Lecb_unaligned_tail:
	xorl	%eax,%eax
	cmpq	%rsp,%rbp
	cmoveq	%rcx,%rax
	movq	%rdi,%r8
	movq	%rcx,%rbx
	subq	%rax,%rsp
	shrq	$3,%rcx
	leaq	(%rsp),%rdi
.byte	0xf3,0x48,0xa5
	movq	%rsp,%rsi
	movq	%r8,%rdi
	movq	%rbx,%rcx
	jmp	.Lecb_loop
.align	16
.Lecb_break:
	cmpq	%rbp,%rsp
	je	.Lecb_done

	pxor	%xmm0,%xmm0
	leaq	(%rsp),%rax
.Lecb_bzero:
	movaps	%xmm0,(%rax)
	leaq	16(%rax),%rax
	cmpq	%rax,%rbp
	ja	.Lecb_bzero

.Lecb_done:
	leaq	(%rbp),%rsp
	jmp	.Lecb_exit

.align	16
.Lecb_aligned:
	leaq	(%rsi,%rcx,1),%rbp
	negq	%rbp
	andq	$0xfff,%rbp
	xorl	%eax,%eax
	cmpq	$128,%rbp
	movq	$128-1,%rbp
	cmovaeq	%rax,%rbp
	andq	%rcx,%rbp
	subq	%rbp,%rcx
	jz	.Lecb_aligned_tail
	leaq	-16(%rdx),%rax
	leaq	16(%rdx),%rbx
	shrq	$4,%rcx
.byte	0xf3,0x0f,0xa7,200
	testq	%rbp,%rbp
	jz	.Lecb_exit

.Lecb_aligned_tail:
	movq	%rdi,%r8
	movq	%rbp,%rbx
	movq	%rbp,%rcx
	leaq	(%rsp),%rbp
	subq	%rcx,%rsp
	shrq	$3,%rcx
	leaq	(%rsp),%rdi
.byte	0xf3,0x48,0xa5
	leaq	(%r8),%rdi
	leaq	(%rsp),%rsi
	movq	%rbx,%rcx
	jmp	.Lecb_loop
.Lecb_exit:
	movl	$1,%eax
	leaq	8(%rsp),%rsp
.Lecb_abort:
	popq	%rbx
	popq	%rbp
	.byte	0xf3,0xc3
.size	padlock_ecb_encrypt,.-padlock_ecb_encrypt
.globl	padlock_cbc_encrypt
.type	padlock_cbc_encrypt,@function
.align	16
padlock_cbc_encrypt:
	pushq	%rbp
	pushq	%rbx

	xorl	%eax,%eax
	testq	$15,%rdx
	jnz	.Lcbc_abort
	testq	$15,%rcx
	jnz	.Lcbc_abort
	leaq	.Lpadlock_saved_context(%rip),%rax
	pushf
	cld
	call	_padlock_verify_ctx
	leaq	16(%rdx),%rdx
	xorl	%eax,%eax
	xorl	%ebx,%ebx
	testl	$32,(%rdx)
	jnz	.Lcbc_aligned
	testq	$0x0f,%rdi
	setz	%al
	testq	$0x0f,%rsi
	setz	%bl
	testl	%ebx,%eax
	jnz	.Lcbc_aligned
	negq	%rax
	movq	$512,%rbx
	notq	%rax
	leaq	(%rsp),%rbp
	cmpq	%rbx,%rcx
	cmovcq	%rcx,%rbx
	andq	%rbx,%rax
	movq	%rcx,%rbx
	negq	%rax
	andq	$512-1,%rbx
	leaq	(%rax,%rbp,1),%rsp
	movq	$512,%rax
	cmovzq	%rax,%rbx
	cmpq	%rbx,%rcx
	ja	.Lcbc_loop
	movq	%rsi,%rax
	cmpq	%rsp,%rbp
	cmoveq	%rdi,%rax
	addq	%rcx,%rax
	negq	%rax
	andq	$0xfff,%rax
	cmpq	$64,%rax
	movq	$-64,%rax
	cmovaeq	%rbx,%rax
	andq	%rax,%rbx
	jz	.Lcbc_unaligned_tail
	jmp	.Lcbc_loop
.align	16
.Lcbc_loop:
	cmpq	%rcx,%rbx
	cmovaq	%rcx,%rbx
	movq	%rdi,%r8
	movq	%rsi,%r9
	movq	%rcx,%r10
	movq	%rbx,%rcx
	movq	%rbx,%r11
	testq	$0x0f,%rdi
	cmovnzq	%rsp,%rdi
	testq	$0x0f,%rsi
	jz	.Lcbc_inp_aligned
	shrq	$3,%rcx
.byte	0xf3,0x48,0xa5
	subq	%rbx,%rdi
	movq	%rbx,%rcx
	movq	%rdi,%rsi
.Lcbc_inp_aligned:
	leaq	-16(%rdx),%rax
	leaq	16(%rdx),%rbx
	shrq	$4,%rcx
.byte	0xf3,0x0f,0xa7,208
	movdqa	(%rax),%xmm0
	movdqa	%xmm0,-16(%rdx)
	movq	%r8,%rdi
	movq	%r11,%rbx
	testq	$0x0f,%rdi
	jz	.Lcbc_out_aligned
	movq	%rbx,%rcx
	leaq	(%rsp),%rsi
	shrq	$3,%rcx
.byte	0xf3,0x48,0xa5
	subq	%rbx,%rdi
.Lcbc_out_aligned:
	movq	%r9,%rsi
	movq	%r10,%rcx
	addq	%rbx,%rdi
	addq	%rbx,%rsi
	subq	%rbx,%rcx
	movq	$512,%rbx
	jz	.Lcbc_break
	cmpq	%rbx,%rcx
	jae	.Lcbc_loop
.Lcbc_unaligned_tail:
	xorl	%eax,%eax
	cmpq	%rsp,%rbp
	cmoveq	%rcx,%rax
	movq	%rdi,%r8
	movq	%rcx,%rbx
	subq	%rax,%rsp
	shrq	$3,%rcx
	leaq	(%rsp),%rdi
.byte	0xf3,0x48,0xa5
	movq	%rsp,%rsi
	movq	%r8,%rdi
	movq	%rbx,%rcx
	jmp	.Lcbc_loop
.align	16
.Lcbc_break:
	cmpq	%rbp,%rsp
	je	.Lcbc_done

	pxor	%xmm0,%xmm0
	leaq	(%rsp),%rax
.Lcbc_bzero:
	movaps	%xmm0,(%rax)
	leaq	16(%rax),%rax
	cmpq	%rax,%rbp
	ja	.Lcbc_bzero

.Lcbc_done:
	leaq	(%rbp),%rsp
	jmp	.Lcbc_exit

.align	16
.Lcbc_aligned:
	leaq	(%rsi,%rcx,1),%rbp
	negq	%rbp
	andq	$0xfff,%rbp
	xorl	%eax,%eax
	cmpq	$64,%rbp
	movq	$64-1,%rbp
	cmovaeq	%rax,%rbp
	andq	%rcx,%rbp
	subq	%rbp,%rcx
	jz	.Lcbc_aligned_tail
	leaq	-16(%rdx),%rax
	leaq	16(%rdx),%rbx
	shrq	$4,%rcx
.byte	0xf3,0x0f,0xa7,208
	movdqa	(%rax),%xmm0
	movdqa	%xmm0,-16(%rdx)
	testq	%rbp,%rbp
	jz	.Lcbc_exit

.Lcbc_aligned_tail:
	movq	%rdi,%r8
	movq	%rbp,%rbx
	movq	%rbp,%rcx
	leaq	(%rsp),%rbp
	subq	%rcx,%rsp
	shrq	$3,%rcx
	leaq	(%rsp),%rdi
.byte	0xf3,0x48,0xa5
	leaq	(%r8),%rdi
	leaq	(%rsp),%rsi
	movq	%rbx,%rcx
	jmp	.Lcbc_loop
.Lcbc_exit:
	movl	$1,%eax
	leaq	8(%rsp),%rsp
.Lcbc_abort:
	popq	%rbx
	popq	%rbp
	.byte	0xf3,0xc3
.size	padlock_cbc_encrypt,.-padlock_cbc_encrypt
.globl	padlock_cfb_encrypt
.type	padlock_cfb_encrypt,@function
.align	16
padlock_cfb_encrypt:
	pushq	%rbp
	pushq	%rbx

	xorl	%eax,%eax
	testq	$15,%rdx
	jnz	.Lcfb_abort
	testq	$15,%rcx
	jnz	.Lcfb_abort
	leaq	.Lpadlock_saved_context(%rip),%rax
	pushf
	cld
	call	_padlock_verify_ctx
	leaq	16(%rdx),%rdx
	xorl	%eax,%eax
	xorl	%ebx,%ebx
	testl	$32,(%rdx)
	jnz	.Lcfb_aligned
	testq	$0x0f,%rdi
	setz	%al
	testq	$0x0f,%rsi
	setz	%bl
	testl	%ebx,%eax
	jnz	.Lcfb_aligned
	negq	%rax
	movq	$512,%rbx
	notq	%rax
	leaq	(%rsp),%rbp
	cmpq	%rbx,%rcx
	cmovcq	%rcx,%rbx
	andq	%rbx,%rax
	movq	%rcx,%rbx
	negq	%rax
	andq	$512-1,%rbx
	leaq	(%rax,%rbp,1),%rsp
	movq	$512,%rax
	cmovzq	%rax,%rbx
	jmp	.Lcfb_loop
.align	16
.Lcfb_loop:
	cmpq	%rcx,%rbx
	cmovaq	%rcx,%rbx
	movq	%rdi,%r8
	movq	%rsi,%r9
	movq	%rcx,%r10
	movq	%rbx,%rcx
	movq	%rbx,%r11
	testq	$0x0f,%rdi
	cmovnzq	%rsp,%rdi
	testq	$0x0f,%rsi
	jz	.Lcfb_inp_aligned
	shrq	$3,%rcx
.byte	0xf3,0x48,0xa5
	subq	%rbx,%rdi
	movq	%rbx,%rcx
	movq	%rdi,%rsi
.Lcfb_inp_aligned:
	leaq	-16(%rdx),%rax
	leaq	16(%rdx),%rbx
	shrq	$4,%rcx
.byte	0xf3,0x0f,0xa7,224
	movdqa	(%rax),%xmm0
	movdqa	%xmm0,-16(%rdx)
	movq	%r8,%rdi
	movq	%r11,%rbx
	testq	$0x0f,%rdi
	jz	.Lcfb_out_aligned
	movq	%rbx,%rcx
	leaq	(%rsp),%rsi
	shrq	$3,%rcx
.byte	0xf3,0x48,0xa5
	subq	%rbx,%rdi
.Lcfb_out_aligned:
	movq	%r9,%rsi
	movq	%r10,%rcx
	addq	%rbx,%rdi
	addq	%rbx,%rsi
	subq	%rbx,%rcx
	movq	$512,%rbx
	jnz	.Lcfb_loop
	cmpq	%rbp,%rsp
	je	.Lcfb_done

	pxor	%xmm0,%xmm0
	leaq	(%rsp),%rax
.Lcfb_bzero:
	movaps	%xmm0,(%rax)
	leaq	16(%rax),%rax
	cmpq	%rax,%rbp
	ja	.Lcfb_bzero

.Lcfb_done:
	leaq	(%rbp),%rsp
	jmp	.Lcfb_exit

.align	16
.Lcfb_aligned:
	leaq	-16(%rdx),%rax
	leaq	16(%rdx),%rbx
	shrq	$4,%rcx
.byte	0xf3,0x0f,0xa7,224
	movdqa	(%rax),%xmm0
	movdqa	%xmm0,-16(%rdx)
.Lcfb_exit:
	movl	$1,%eax
	leaq	8(%rsp),%rsp
.Lcfb_abort:
	popq	%rbx
	popq	%rbp
	.byte	0xf3,0xc3
.size	padlock_cfb_encrypt,.-padlock_cfb_encrypt
.globl	padlock_ofb_encrypt
.type	padlock_ofb_encrypt,@function
.align	16
padlock_ofb_encrypt:
	pushq	%rbp
	pushq	%rbx

	xorl	%eax,%eax
	testq	$15,%rdx
	jnz	.Lofb_abort
	testq	$15,%rcx
	jnz	.Lofb_abort
	leaq	.Lpadlock_saved_context(%rip),%rax
	pushf
	cld
	call	_padlock_verify_ctx
	leaq	16(%rdx),%rdx
	xorl	%eax,%eax
	xorl	%ebx,%ebx
	testl	$32,(%rdx)
	jnz	.Lofb_aligned
	testq	$0x0f,%rdi
	setz	%al
	testq	$0x0f,%rsi
	setz	%bl
	testl	%ebx,%eax
	jnz	.Lofb_aligned
	negq	%rax
	movq	$512,%rbx
	notq	%rax
	leaq	(%rsp),%rbp
	cmpq	%rbx,%rcx
	cmovcq	%rcx,%rbx
	andq	%rbx,%rax
	movq	%rcx,%rbx
	negq	%rax
	andq	$512-1,%rbx
	leaq	(%rax,%rbp,1),%rsp
	movq	$512,%rax
	cmovzq	%rax,%rbx
	jmp	.Lofb_loop
.align	16
.Lofb_loop:
	cmpq	%rcx,%rbx
	cmovaq	%rcx,%rbx
	movq	%rdi,%r8
	movq	%rsi,%r9
	movq	%rcx,%r10
	movq	%rbx,%rcx
	movq	%rbx,%r11
	testq	$0x0f,%rdi
	cmovnzq	%rsp,%rdi
	testq	$0x0f,%rsi
	jz	.Lofb_inp_aligned
	shrq	$3,%rcx
.byte	0xf3,0x48,0xa5
	subq	%rbx,%rdi
	movq	%rbx,%rcx
	movq	%rdi,%rsi
.Lofb_inp_aligned:
	leaq	-16(%rdx),%rax
	leaq	16(%rdx),%rbx
	shrq	$4,%rcx
.byte	0xf3,0x0f,0xa7,232
	movdqa	(%rax),%xmm0
	movdqa	%xmm0,-16(%rdx)
	movq	%r8,%rdi
	movq	%r11,%rbx
	testq	$0x0f,%rdi
	jz	.Lofb_out_aligned
	movq	%rbx,%rcx
	leaq	(%rsp),%rsi
	shrq	$3,%rcx
.byte	0xf3,0x48,0xa5
	subq	%rbx,%rdi
.Lofb_out_aligned:
	movq	%r9,%rsi
	movq	%r10,%rcx
	addq	%rbx,%rdi
	addq	%rbx,%rsi
	subq	%rbx,%rcx
	movq	$512,%rbx
	jnz	.Lofb_loop
	cmpq	%rbp,%rsp
	je	.Lofb_done

	pxor	%xmm0,%xmm0
	leaq	(%rsp),%rax
.Lofb_bzero:
	movaps	%xmm0,(%rax)
	leaq	16(%rax),%rax
	cmpq	%rax,%rbp
	ja	.Lofb_bzero

.Lofb_done:
	leaq	(%rbp),%rsp
	jmp	.Lofb_exit

.align	16
.Lofb_aligned:
	leaq	-16(%rdx),%rax
	leaq	16(%rdx),%rbx
	shrq	$4,%rcx
.byte	0xf3,0x0f,0xa7,232
	movdqa	(%rax),%xmm0
	movdqa	%xmm0,-16(%rdx)
.Lofb_exit:
	movl	$1,%eax
	leaq	8(%rsp),%rsp
.Lofb_abort:
	popq	%rbx
	popq	%rbp
	.byte	0xf3,0xc3
.size	padlock_ofb_encrypt,.-padlock_ofb_encrypt
.globl	padlock_ctr32_encrypt
.type	padlock_ctr32_encrypt,@function
.align	16
padlock_ctr32_encrypt:
	pushq	%rbp
	pushq	%rbx

	xorl	%eax,%eax
	testq	$15,%rdx
	jnz	.Lctr32_abort
	testq	$15,%rcx
	jnz	.Lctr32_abort
	leaq	.Lpadlock_saved_context(%rip),%rax
	pushf
	cld
	call	_padlock_verify_ctx
	leaq	16(%rdx),%rdx
	xorl	%eax,%eax
	xorl	%ebx,%ebx
	testl	$32,(%rdx)
	jnz	.Lctr32_aligned
	testq	$0x0f,%rdi
	setz	%al
	testq	$0x0f,%rsi
	setz	%bl
	testl	%ebx,%eax
	jnz	.Lctr32_aligned
	negq	%rax
	movq	$512,%rbx
	notq	%rax
	leaq	(%rsp),%rbp
	cmpq	%rbx,%rcx
	cmovcq	%rcx,%rbx
	andq	%rbx,%rax
	movq	%rcx,%rbx
	negq	%rax
	andq	$512-1,%rbx
	leaq	(%rax,%rbp,1),%rsp
	movq	$512,%rax
	cmovzq	%rax,%rbx
.Lctr32_reenter:
	movl	-4(%rdx),%eax
	bswapl	%eax
	negl	%eax
	andl	$31,%eax
	movq	$512,%rbx
	shll	$4,%eax
	cmovzq	%rbx,%rax
	cmpq	%rax,%rcx
	cmovaq	%rax,%rbx
	cmovbeq	%rcx,%rbx
	cmpq	%rbx,%rcx
	ja	.Lctr32_loop
	movq	%rsi,%rax
	cmpq	%rsp,%rbp
	cmoveq	%rdi,%rax
	addq	%rcx,%rax
	negq	%rax
	andq	$0xfff,%rax
	cmpq	$32,%rax
	movq	$-32,%rax
	cmovaeq	%rbx,%rax
	andq	%rax,%rbx
	jz	.Lctr32_unaligned_tail
	jmp	.Lctr32_loop
.align	16
.Lctr32_loop:
	cmpq	%rcx,%rbx
	cmovaq	%rcx,%rbx
	movq	%rdi,%r8
	movq	%rsi,%r9
	movq	%rcx,%r10
	movq	%rbx,%rcx
	movq	%rbx,%r11
	testq	$0x0f,%rdi
	cmovnzq	%rsp,%rdi
	testq	$0x0f,%rsi
	jz	.Lctr32_inp_aligned
	shrq	$3,%rcx
.byte	0xf3,0x48,0xa5
	subq	%rbx,%rdi
	movq	%rbx,%rcx
	movq	%rdi,%rsi
.Lctr32_inp_aligned:
	leaq	-16(%rdx),%rax
	leaq	16(%rdx),%rbx
	shrq	$4,%rcx
.byte	0xf3,0x0f,0xa7,216
	movl	-4(%rdx),%eax
	testl	$0xffff0000,%eax
	jnz	.Lctr32_no_carry
	bswapl	%eax
	addl	$0x10000,%eax
	bswapl	%eax
	movl	%eax,-4(%rdx)
.Lctr32_no_carry:
	movq	%r8,%rdi
	movq	%r11,%rbx
	testq	$0x0f,%rdi
	jz	.Lctr32_out_aligned
	movq	%rbx,%rcx
	leaq	(%rsp),%rsi
	shrq	$3,%rcx
.byte	0xf3,0x48,0xa5
	subq	%rbx,%rdi
.Lctr32_out_aligned:
	movq	%r9,%rsi
	movq	%r10,%rcx
	addq	%rbx,%rdi
	addq	%rbx,%rsi
	subq	%rbx,%rcx
	movq	$512,%rbx
	jz	.Lctr32_break
	cmpq	%rbx,%rcx
	jae	.Lctr32_loop
	movq	%rcx,%rbx
	movq	%rsi,%rax
	cmpq	%rsp,%rbp
	cmoveq	%rdi,%rax
	addq	%rcx,%rax
	negq	%rax
	andq	$0xfff,%rax
	cmpq	$32,%rax
	movq	$-32,%rax
	cmovaeq	%rbx,%rax
	andq	%rax,%rbx
	jnz	.Lctr32_loop
.Lctr32_unaligned_tail:
	xorl	%eax,%eax
	cmpq	%rsp,%rbp
	cmoveq	%rcx,%rax
	movq	%rdi,%r8
	movq	%rcx,%rbx
	subq	%rax,%rsp
	shrq	$3,%rcx
	leaq	(%rsp),%rdi
.byte	0xf3,0x48,0xa5
	movq	%rsp,%rsi
	movq	%r8,%rdi
	movq	%rbx,%rcx
	jmp	.Lctr32_loop
.align	16
.Lctr32_break:
	cmpq	%rbp,%rsp
	je	.Lctr32_done

	pxor	%xmm0,%xmm0
	leaq	(%rsp),%rax
.Lctr32_bzero:
	movaps	%xmm0,(%rax)
	leaq	16(%rax),%rax
	cmpq	%rax,%rbp
	ja	.Lctr32_bzero

.Lctr32_done:
	leaq	(%rbp),%rsp
	jmp	.Lctr32_exit

.align	16
.Lctr32_aligned:
	movl	-4(%rdx),%eax
	bswapl	%eax
	negl	%eax
	andl	$0xffff,%eax
	movq	$1048576,%rbx
	shll	$4,%eax
	cmovzq	%rbx,%rax
	cmpq	%rax,%rcx
	cmovaq	%rax,%rbx
	cmovbeq	%rcx,%rbx
	jbe	.Lctr32_aligned_skip

.Lctr32_aligned_loop:
	movq	%rcx,%r10
	movq	%rbx,%rcx
	movq	%rbx,%r11

	leaq	-16(%rdx),%rax
	leaq	16(%rdx),%rbx
	shrq	$4,%rcx
.byte	0xf3,0x0f,0xa7,216

	movl	-4(%rdx),%eax
	bswapl	%eax
	addl	$0x10000,%eax
	bswapl	%eax
	movl	%eax,-4(%rdx)

	movq	%r10,%rcx
	subq	%r11,%rcx
	movq	$1048576,%rbx
	jz	.Lctr32_exit
	cmpq	%rbx,%rcx
	jae	.Lctr32_aligned_loop

.Lctr32_aligned_skip:
	leaq	(%rsi,%rcx,1),%rbp
	negq	%rbp
	andq	$0xfff,%rbp
	xorl	%eax,%eax
	cmpq	$32,%rbp
	movq	$32-1,%rbp
	cmovaeq	%rax,%rbp
	andq	%rcx,%rbp
	subq	%rbp,%rcx
	jz	.Lctr32_aligned_tail
	leaq	-16(%rdx),%rax
	leaq	16(%rdx),%rbx
	shrq	$4,%rcx
.byte	0xf3,0x0f,0xa7,216
	testq	%rbp,%rbp
	jz	.Lctr32_exit

.Lctr32_aligned_tail:
	movq	%rdi,%r8
	movq	%rbp,%rbx
	movq	%rbp,%rcx
	leaq	(%rsp),%rbp
	subq	%rcx,%rsp
	shrq	$3,%rcx
	leaq	(%rsp),%rdi
.byte	0xf3,0x48,0xa5
	leaq	(%r8),%rdi
	leaq	(%rsp),%rsi
	movq	%rbx,%rcx
	jmp	.Lctr32_loop
.Lctr32_exit:
	movl	$1,%eax
	leaq	8(%rsp),%rsp
.Lctr32_abort:
	popq	%rbx
	popq	%rbp
	.byte	0xf3,0xc3
.size	padlock_ctr32_encrypt,.-padlock_ctr32_encrypt
.byte	86,73,65,32,80,97,100,108,111,99,107,32,120,56,54,95,54,52,32,109,111,100,117,108,101,44,32,67,82,89,80,84,79,71,65,77,83,32,98,121,32,60,97,112,112,114,111,64,111,112,101,110,115,115,108,46,111,114,103,62,0
.align	16
.data	
.align	8
.Lpadlock_saved_context:
.quad	0
	.section ".note.gnu.property", "a"
	.p2align 3
	.long 1f - 0f
	.long 4f - 1f
	.long 5
0:
	# "GNU" encoded with .byte, since .asciz isn't supported
	# on Solaris.
	.byte 0x47
	.byte 0x4e
	.byte 0x55
	.byte 0
1:
	.p2align 3
	.long 0xc0000002
	.long 3f - 2f
2:
	.long 3
3:
	.p2align 3
4:
                                                                                                                                                                                                                                                                                                                                                                                                                                     node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/                        0000775 0000000 0000000 00000000000 14746647661 0026217 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/crypto/                 0000775 0000000 0000000 00000000000 14746647661 0027537 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/crypto/bn_conf.h        0000664 0000000 0000000 00000001505 14746647661 0031315 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /* WARNING: do not edit! */
/* Generated by Makefile from include/crypto/bn_conf.h.in */
/*
 * Copyright 2016-2021 The OpenSSL Project Authors. All Rights Reserved.
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 */

#ifndef OSSL_CRYPTO_BN_CONF_H
# define OSSL_CRYPTO_BN_CONF_H
# pragma once

/*
 * The contents of this file are not used in the UEFI build, as
 * both 32-bit and 64-bit builds are supported from a single run
 * of the Configure script.
 */

/* Should we define BN_DIV2W here? */

/* Only one for the following should be defined */
#define SIXTY_FOUR_BIT_LONG
#undef SIXTY_FOUR_BIT
#undef THIRTY_TWO_BIT

#endif
                                                                                                                                                                                           node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/crypto/dso_conf.h       0000664 0000000 0000000 00000001106 14746647661 0031500 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /* WARNING: do not edit! */
/* Generated by Makefile from include/crypto/dso_conf.h.in */
/*
 * Copyright 2016-2021 The OpenSSL Project Authors. All Rights Reserved.
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 */

#ifndef OSSL_CRYPTO_DSO_CONF_H
# define OSSL_CRYPTO_DSO_CONF_H
# pragma once

# define DSO_DLFCN
# define HAVE_DLFCN_H
# define DSO_EXTENSION ".so"
#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                          node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/openssl/                0000775 0000000 0000000 00000000000 14746647661 0027702 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/openssl/asn1.h          0000664 0000000 0000000 00000166762 14746647661 0030737 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /*
 * WARNING: do not edit!
 * Generated by Makefile from include/openssl/asn1.h.in
 *
 * Copyright 1995-2021 The OpenSSL Project Authors. All Rights Reserved.
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 */



#ifndef OPENSSL_ASN1_H
# define OPENSSL_ASN1_H
# pragma once

# include <openssl/macros.h>
# ifndef OPENSSL_NO_DEPRECATED_3_0
#  define HEADER_ASN1_H
# endif

# include <time.h>
# include <openssl/e_os2.h>
# include <openssl/opensslconf.h>
# include <openssl/bio.h>
# include <openssl/safestack.h>
# include <openssl/asn1err.h>
# include <openssl/symhacks.h>

# include <openssl/types.h>
# include <openssl/bn.h>

# ifdef OPENSSL_BUILD_SHLIBCRYPTO
#  undef OPENSSL_EXTERN
#  define OPENSSL_EXTERN OPENSSL_EXPORT
# endif

#ifdef  __cplusplus
extern "C" {
#endif

# define V_ASN1_UNIVERSAL                0x00
# define V_ASN1_APPLICATION              0x40
# define V_ASN1_CONTEXT_SPECIFIC         0x80
# define V_ASN1_PRIVATE                  0xc0

# define V_ASN1_CONSTRUCTED              0x20
# define V_ASN1_PRIMITIVE_TAG            0x1f
# define V_ASN1_PRIMATIVE_TAG /*compat*/ V_ASN1_PRIMITIVE_TAG

# define V_ASN1_APP_CHOOSE               -2/* let the recipient choose */
# define V_ASN1_OTHER                    -3/* used in ASN1_TYPE */
# define V_ASN1_ANY                      -4/* used in ASN1 template code */

# define V_ASN1_UNDEF                    -1
/* ASN.1 tag values */
# define V_ASN1_EOC                      0
# define V_ASN1_BOOLEAN                  1 /**/
# define V_ASN1_INTEGER                  2
# define V_ASN1_BIT_STRING               3
# define V_ASN1_OCTET_STRING             4
# define V_ASN1_NULL                     5
# define V_ASN1_OBJECT                   6
# define V_ASN1_OBJECT_DESCRIPTOR        7
# define V_ASN1_EXTERNAL                 8
# define V_ASN1_REAL                     9
# define V_ASN1_ENUMERATED               10
# define V_ASN1_UTF8STRING               12
# define V_ASN1_SEQUENCE                 16
# define V_ASN1_SET                      17
# define V_ASN1_NUMERICSTRING            18 /**/
# define V_ASN1_PRINTABLESTRING          19
# define V_ASN1_T61STRING                20
# define V_ASN1_TELETEXSTRING            20/* alias */
# define V_ASN1_VIDEOTEXSTRING           21 /**/
# define V_ASN1_IA5STRING                22
# define V_ASN1_UTCTIME                  23
# define V_ASN1_GENERALIZEDTIME          24 /**/
# define V_ASN1_GRAPHICSTRING            25 /**/
# define V_ASN1_ISO64STRING              26 /**/
# define V_ASN1_VISIBLESTRING            26/* alias */
# define V_ASN1_GENERALSTRING            27 /**/
# define V_ASN1_UNIVERSALSTRING          28 /**/
# define V_ASN1_BMPSTRING                30

/*
 * NB the constants below are used internally by ASN1_INTEGER
 * and ASN1_ENUMERATED to indicate the sign. They are *not* on
 * the wire tag values.
 */

# define V_ASN1_NEG                      0x100
# define V_ASN1_NEG_INTEGER              (2 | V_ASN1_NEG)
# define V_ASN1_NEG_ENUMERATED           (10 | V_ASN1_NEG)

/* For use with d2i_ASN1_type_bytes() */
# define B_ASN1_NUMERICSTRING    0x0001
# define B_ASN1_PRINTABLESTRING  0x0002
# define B_ASN1_T61STRING        0x0004
# define B_ASN1_TELETEXSTRING    0x0004
# define B_ASN1_VIDEOTEXSTRING   0x0008
# define B_ASN1_IA5STRING        0x0010
# define B_ASN1_GRAPHICSTRING    0x0020
# define B_ASN1_ISO64STRING      0x0040
# define B_ASN1_VISIBLESTRING    0x0040
# define B_ASN1_GENERALSTRING    0x0080
# define B_ASN1_UNIVERSALSTRING  0x0100
# define B_ASN1_OCTET_STRING     0x0200
# define B_ASN1_BIT_STRING       0x0400
# define B_ASN1_BMPSTRING        0x0800
# define B_ASN1_UNKNOWN          0x1000
# define B_ASN1_UTF8STRING       0x2000
# define B_ASN1_UTCTIME          0x4000
# define B_ASN1_GENERALIZEDTIME  0x8000
# define B_ASN1_SEQUENCE         0x10000
/* For use with ASN1_mbstring_copy() */
# define MBSTRING_FLAG           0x1000
# define MBSTRING_UTF8           (MBSTRING_FLAG)
# define MBSTRING_ASC            (MBSTRING_FLAG|1)
# define MBSTRING_BMP            (MBSTRING_FLAG|2)
# define MBSTRING_UNIV           (MBSTRING_FLAG|4)
# define SMIME_OLDMIME           0x400
# define SMIME_CRLFEOL           0x800
# define SMIME_STREAM            0x1000

/* Stacks for types not otherwise defined in this header */
SKM_DEFINE_STACK_OF_INTERNAL(X509_ALGOR, X509_ALGOR, X509_ALGOR)
#define sk_X509_ALGOR_num(sk) OPENSSL_sk_num(ossl_check_const_X509_ALGOR_sk_type(sk))
#define sk_X509_ALGOR_value(sk, idx) ((X509_ALGOR *)OPENSSL_sk_value(ossl_check_const_X509_ALGOR_sk_type(sk), (idx)))
#define sk_X509_ALGOR_new(cmp) ((STACK_OF(X509_ALGOR) *)OPENSSL_sk_new(ossl_check_X509_ALGOR_compfunc_type(cmp)))
#define sk_X509_ALGOR_new_null() ((STACK_OF(X509_ALGOR) *)OPENSSL_sk_new_null())
#define sk_X509_ALGOR_new_reserve(cmp, n) ((STACK_OF(X509_ALGOR) *)OPENSSL_sk_new_reserve(ossl_check_X509_ALGOR_compfunc_type(cmp), (n)))
#define sk_X509_ALGOR_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_X509_ALGOR_sk_type(sk), (n))
#define sk_X509_ALGOR_free(sk) OPENSSL_sk_free(ossl_check_X509_ALGOR_sk_type(sk))
#define sk_X509_ALGOR_zero(sk) OPENSSL_sk_zero(ossl_check_X509_ALGOR_sk_type(sk))
#define sk_X509_ALGOR_delete(sk, i) ((X509_ALGOR *)OPENSSL_sk_delete(ossl_check_X509_ALGOR_sk_type(sk), (i)))
#define sk_X509_ALGOR_delete_ptr(sk, ptr) ((X509_ALGOR *)OPENSSL_sk_delete_ptr(ossl_check_X509_ALGOR_sk_type(sk), ossl_check_X509_ALGOR_type(ptr)))
#define sk_X509_ALGOR_push(sk, ptr) OPENSSL_sk_push(ossl_check_X509_ALGOR_sk_type(sk), ossl_check_X509_ALGOR_type(ptr))
#define sk_X509_ALGOR_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_X509_ALGOR_sk_type(sk), ossl_check_X509_ALGOR_type(ptr))
#define sk_X509_ALGOR_pop(sk) ((X509_ALGOR *)OPENSSL_sk_pop(ossl_check_X509_ALGOR_sk_type(sk)))
#define sk_X509_ALGOR_shift(sk) ((X509_ALGOR *)OPENSSL_sk_shift(ossl_check_X509_ALGOR_sk_type(sk)))
#define sk_X509_ALGOR_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_X509_ALGOR_sk_type(sk),ossl_check_X509_ALGOR_freefunc_type(freefunc))
#define sk_X509_ALGOR_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_X509_ALGOR_sk_type(sk), ossl_check_X509_ALGOR_type(ptr), (idx))
#define sk_X509_ALGOR_set(sk, idx, ptr) ((X509_ALGOR *)OPENSSL_sk_set(ossl_check_X509_ALGOR_sk_type(sk), (idx), ossl_check_X509_ALGOR_type(ptr)))
#define sk_X509_ALGOR_find(sk, ptr) OPENSSL_sk_find(ossl_check_X509_ALGOR_sk_type(sk), ossl_check_X509_ALGOR_type(ptr))
#define sk_X509_ALGOR_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_X509_ALGOR_sk_type(sk), ossl_check_X509_ALGOR_type(ptr))
#define sk_X509_ALGOR_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_X509_ALGOR_sk_type(sk), ossl_check_X509_ALGOR_type(ptr), pnum)
#define sk_X509_ALGOR_sort(sk) OPENSSL_sk_sort(ossl_check_X509_ALGOR_sk_type(sk))
#define sk_X509_ALGOR_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_X509_ALGOR_sk_type(sk))
#define sk_X509_ALGOR_dup(sk) ((STACK_OF(X509_ALGOR) *)OPENSSL_sk_dup(ossl_check_const_X509_ALGOR_sk_type(sk)))
#define sk_X509_ALGOR_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(X509_ALGOR) *)OPENSSL_sk_deep_copy(ossl_check_const_X509_ALGOR_sk_type(sk), ossl_check_X509_ALGOR_copyfunc_type(copyfunc), ossl_check_X509_ALGOR_freefunc_type(freefunc)))
#define sk_X509_ALGOR_set_cmp_func(sk, cmp) ((sk_X509_ALGOR_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_X509_ALGOR_sk_type(sk), ossl_check_X509_ALGOR_compfunc_type(cmp)))



# define ASN1_STRING_FLAG_BITS_LEFT 0x08/* Set if 0x07 has bits left value */
/*
 * This indicates that the ASN1_STRING is not a real value but just a place
 * holder for the location where indefinite length constructed data should be
 * inserted in the memory buffer
 */
# define ASN1_STRING_FLAG_NDEF 0x010

/*
 * This flag is used by the CMS code to indicate that a string is not
 * complete and is a place holder for content when it had all been accessed.
 * The flag will be reset when content has been written to it.
 */

# define ASN1_STRING_FLAG_CONT 0x020
/*
 * This flag is used by ASN1 code to indicate an ASN1_STRING is an MSTRING
 * type.
 */
# define ASN1_STRING_FLAG_MSTRING 0x040
/* String is embedded and only content should be freed */
# define ASN1_STRING_FLAG_EMBED 0x080
/* String should be parsed in RFC 5280's time format */
# define ASN1_STRING_FLAG_X509_TIME 0x100
/* This is the base type that holds just about everything :-) */
struct asn1_string_st {
    int length;
    int type;
    unsigned char *data;
    /*
     * The value of the following field depends on the type being held.  It
     * is mostly being used for BIT_STRING so if the input data has a
     * non-zero 'unused bits' value, it will be handled correctly
     */
    long flags;
};

/*
 * ASN1_ENCODING structure: this is used to save the received encoding of an
 * ASN1 type. This is useful to get round problems with invalid encodings
 * which can break signatures.
 */

typedef struct ASN1_ENCODING_st {
    unsigned char *enc;         /* DER encoding */
    long len;                   /* Length of encoding */
    int modified;               /* set to 1 if 'enc' is invalid */
} ASN1_ENCODING;

/* Used with ASN1 LONG type: if a long is set to this it is omitted */
# define ASN1_LONG_UNDEF 0x7fffffffL

# define STABLE_FLAGS_MALLOC     0x01
/*
 * A zero passed to ASN1_STRING_TABLE_new_add for the flags is interpreted
 * as "don't change" and STABLE_FLAGS_MALLOC is always set. By setting
 * STABLE_FLAGS_MALLOC only we can clear the existing value. Use the alias
 * STABLE_FLAGS_CLEAR to reflect this.
 */
# define STABLE_FLAGS_CLEAR      STABLE_FLAGS_MALLOC
# define STABLE_NO_MASK          0x02
# define DIRSTRING_TYPE  \
 (B_ASN1_PRINTABLESTRING|B_ASN1_T61STRING|B_ASN1_BMPSTRING|B_ASN1_UTF8STRING)
# define PKCS9STRING_TYPE (DIRSTRING_TYPE|B_ASN1_IA5STRING)

struct asn1_string_table_st {
    int nid;
    long minsize;
    long maxsize;
    unsigned long mask;
    unsigned long flags;
};

SKM_DEFINE_STACK_OF_INTERNAL(ASN1_STRING_TABLE, ASN1_STRING_TABLE, ASN1_STRING_TABLE)
#define sk_ASN1_STRING_TABLE_num(sk) OPENSSL_sk_num(ossl_check_const_ASN1_STRING_TABLE_sk_type(sk))
#define sk_ASN1_STRING_TABLE_value(sk, idx) ((ASN1_STRING_TABLE *)OPENSSL_sk_value(ossl_check_const_ASN1_STRING_TABLE_sk_type(sk), (idx)))
#define sk_ASN1_STRING_TABLE_new(cmp) ((STACK_OF(ASN1_STRING_TABLE) *)OPENSSL_sk_new(ossl_check_ASN1_STRING_TABLE_compfunc_type(cmp)))
#define sk_ASN1_STRING_TABLE_new_null() ((STACK_OF(ASN1_STRING_TABLE) *)OPENSSL_sk_new_null())
#define sk_ASN1_STRING_TABLE_new_reserve(cmp, n) ((STACK_OF(ASN1_STRING_TABLE) *)OPENSSL_sk_new_reserve(ossl_check_ASN1_STRING_TABLE_compfunc_type(cmp), (n)))
#define sk_ASN1_STRING_TABLE_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_ASN1_STRING_TABLE_sk_type(sk), (n))
#define sk_ASN1_STRING_TABLE_free(sk) OPENSSL_sk_free(ossl_check_ASN1_STRING_TABLE_sk_type(sk))
#define sk_ASN1_STRING_TABLE_zero(sk) OPENSSL_sk_zero(ossl_check_ASN1_STRING_TABLE_sk_type(sk))
#define sk_ASN1_STRING_TABLE_delete(sk, i) ((ASN1_STRING_TABLE *)OPENSSL_sk_delete(ossl_check_ASN1_STRING_TABLE_sk_type(sk), (i)))
#define sk_ASN1_STRING_TABLE_delete_ptr(sk, ptr) ((ASN1_STRING_TABLE *)OPENSSL_sk_delete_ptr(ossl_check_ASN1_STRING_TABLE_sk_type(sk), ossl_check_ASN1_STRING_TABLE_type(ptr)))
#define sk_ASN1_STRING_TABLE_push(sk, ptr) OPENSSL_sk_push(ossl_check_ASN1_STRING_TABLE_sk_type(sk), ossl_check_ASN1_STRING_TABLE_type(ptr))
#define sk_ASN1_STRING_TABLE_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_ASN1_STRING_TABLE_sk_type(sk), ossl_check_ASN1_STRING_TABLE_type(ptr))
#define sk_ASN1_STRING_TABLE_pop(sk) ((ASN1_STRING_TABLE *)OPENSSL_sk_pop(ossl_check_ASN1_STRING_TABLE_sk_type(sk)))
#define sk_ASN1_STRING_TABLE_shift(sk) ((ASN1_STRING_TABLE *)OPENSSL_sk_shift(ossl_check_ASN1_STRING_TABLE_sk_type(sk)))
#define sk_ASN1_STRING_TABLE_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_ASN1_STRING_TABLE_sk_type(sk),ossl_check_ASN1_STRING_TABLE_freefunc_type(freefunc))
#define sk_ASN1_STRING_TABLE_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_ASN1_STRING_TABLE_sk_type(sk), ossl_check_ASN1_STRING_TABLE_type(ptr), (idx))
#define sk_ASN1_STRING_TABLE_set(sk, idx, ptr) ((ASN1_STRING_TABLE *)OPENSSL_sk_set(ossl_check_ASN1_STRING_TABLE_sk_type(sk), (idx), ossl_check_ASN1_STRING_TABLE_type(ptr)))
#define sk_ASN1_STRING_TABLE_find(sk, ptr) OPENSSL_sk_find(ossl_check_ASN1_STRING_TABLE_sk_type(sk), ossl_check_ASN1_STRING_TABLE_type(ptr))
#define sk_ASN1_STRING_TABLE_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_ASN1_STRING_TABLE_sk_type(sk), ossl_check_ASN1_STRING_TABLE_type(ptr))
#define sk_ASN1_STRING_TABLE_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_ASN1_STRING_TABLE_sk_type(sk), ossl_check_ASN1_STRING_TABLE_type(ptr), pnum)
#define sk_ASN1_STRING_TABLE_sort(sk) OPENSSL_sk_sort(ossl_check_ASN1_STRING_TABLE_sk_type(sk))
#define sk_ASN1_STRING_TABLE_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_ASN1_STRING_TABLE_sk_type(sk))
#define sk_ASN1_STRING_TABLE_dup(sk) ((STACK_OF(ASN1_STRING_TABLE) *)OPENSSL_sk_dup(ossl_check_const_ASN1_STRING_TABLE_sk_type(sk)))
#define sk_ASN1_STRING_TABLE_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(ASN1_STRING_TABLE) *)OPENSSL_sk_deep_copy(ossl_check_const_ASN1_STRING_TABLE_sk_type(sk), ossl_check_ASN1_STRING_TABLE_copyfunc_type(copyfunc), ossl_check_ASN1_STRING_TABLE_freefunc_type(freefunc)))
#define sk_ASN1_STRING_TABLE_set_cmp_func(sk, cmp) ((sk_ASN1_STRING_TABLE_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_ASN1_STRING_TABLE_sk_type(sk), ossl_check_ASN1_STRING_TABLE_compfunc_type(cmp)))


/* size limits: this stuff is taken straight from RFC2459 */

# define ub_name                         32768
# define ub_common_name                  64
# define ub_locality_name                128
# define ub_state_name                   128
# define ub_organization_name            64
# define ub_organization_unit_name       64
# define ub_title                        64
# define ub_email_address                128

/*
 * Declarations for template structures: for full definitions see asn1t.h
 */
typedef struct ASN1_TEMPLATE_st ASN1_TEMPLATE;
typedef struct ASN1_TLC_st ASN1_TLC;
/* This is just an opaque pointer */
typedef struct ASN1_VALUE_st ASN1_VALUE;

/* Declare ASN1 functions: the implement macro in in asn1t.h */

/*
 * The mysterious 'extern' that's passed to some macros is innocuous,
 * and is there to quiet pre-C99 compilers that may complain about empty
 * arguments in macro calls.
 */

# define DECLARE_ASN1_FUNCTIONS_attr(attr, type)                            \
    DECLARE_ASN1_FUNCTIONS_name_attr(attr, type, type)
# define DECLARE_ASN1_FUNCTIONS(type)                                       \
    DECLARE_ASN1_FUNCTIONS_attr(extern, type)

# define DECLARE_ASN1_ALLOC_FUNCTIONS_attr(attr, type)                      \
    DECLARE_ASN1_ALLOC_FUNCTIONS_name_attr(attr, type, type)
# define DECLARE_ASN1_ALLOC_FUNCTIONS(type)                                 \
    DECLARE_ASN1_ALLOC_FUNCTIONS_attr(extern, type)

# define DECLARE_ASN1_FUNCTIONS_name_attr(attr, type, name)                 \
    DECLARE_ASN1_ALLOC_FUNCTIONS_name_attr(attr, type, name)                \
    DECLARE_ASN1_ENCODE_FUNCTIONS_name_attr(attr, type, name)
# define DECLARE_ASN1_FUNCTIONS_name(type, name)                            \
    DECLARE_ASN1_FUNCTIONS_name_attr(extern, type, name)

# define DECLARE_ASN1_ENCODE_FUNCTIONS_attr(attr, type, itname, name)       \
    DECLARE_ASN1_ENCODE_FUNCTIONS_only_attr(attr, type, name)               \
    DECLARE_ASN1_ITEM_attr(attr, itname)
# define DECLARE_ASN1_ENCODE_FUNCTIONS(type, itname, name)                  \
    DECLARE_ASN1_ENCODE_FUNCTIONS_attr(extern, type, itname, name)

# define DECLARE_ASN1_ENCODE_FUNCTIONS_name_attr(attr, type, name)          \
    DECLARE_ASN1_ENCODE_FUNCTIONS_attr(attr, type, name, name)
# define DECLARE_ASN1_ENCODE_FUNCTIONS_name(type, name) \
    DECLARE_ASN1_ENCODE_FUNCTIONS_name_attr(extern, type, name)

# define DECLARE_ASN1_ENCODE_FUNCTIONS_only_attr(attr, type, name)          \
    attr type *d2i_##name(type **a, const unsigned char **in, long len);    \
    attr int i2d_##name(const type *a, unsigned char **out);
# define DECLARE_ASN1_ENCODE_FUNCTIONS_only(type, name)                     \
    DECLARE_ASN1_ENCODE_FUNCTIONS_only_attr(extern, type, name)

# define DECLARE_ASN1_NDEF_FUNCTION_attr(attr, name)                        \
    attr int i2d_##name##_NDEF(const name *a, unsigned char **out);
# define DECLARE_ASN1_NDEF_FUNCTION(name)                                   \
    DECLARE_ASN1_NDEF_FUNCTION_attr(extern, name)

# define DECLARE_ASN1_ALLOC_FUNCTIONS_name_attr(attr, type, name)           \
    attr type *name##_new(void);                                            \
    attr void name##_free(type *a);
# define DECLARE_ASN1_ALLOC_FUNCTIONS_name(type, name)                      \
    DECLARE_ASN1_ALLOC_FUNCTIONS_name_attr(extern, type, name)

# define DECLARE_ASN1_DUP_FUNCTION_attr(attr, type)                         \
    DECLARE_ASN1_DUP_FUNCTION_name_attr(attr, type, type)
# define DECLARE_ASN1_DUP_FUNCTION(type)                                    \
    DECLARE_ASN1_DUP_FUNCTION_attr(extern, type)

# define DECLARE_ASN1_DUP_FUNCTION_name_attr(attr, type, name)              \
    attr type *name##_dup(const type *a);
# define DECLARE_ASN1_DUP_FUNCTION_name(type, name)                         \
    DECLARE_ASN1_DUP_FUNCTION_name_attr(extern, type, name)

# define DECLARE_ASN1_PRINT_FUNCTION_attr(attr, stname)                     \
    DECLARE_ASN1_PRINT_FUNCTION_fname_attr(attr, stname, stname)
# define DECLARE_ASN1_PRINT_FUNCTION(stname)                                \
    DECLARE_ASN1_PRINT_FUNCTION_attr(extern, stname)

# define DECLARE_ASN1_PRINT_FUNCTION_fname_attr(attr, stname, fname)        \
    attr int fname##_print_ctx(BIO *out, const stname *x, int indent,       \
                               const ASN1_PCTX *pctx);
# define DECLARE_ASN1_PRINT_FUNCTION_fname(stname, fname)                   \
    DECLARE_ASN1_PRINT_FUNCTION_fname_attr(extern, stname, fname)

# define D2I_OF(type) type *(*)(type **,const unsigned char **,long)
# define I2D_OF(type) int (*)(const type *,unsigned char **)

# define CHECKED_D2I_OF(type, d2i) \
    ((d2i_of_void*) (1 ? d2i : ((D2I_OF(type))0)))
# define CHECKED_I2D_OF(type, i2d) \
    ((i2d_of_void*) (1 ? i2d : ((I2D_OF(type))0)))
# define CHECKED_NEW_OF(type, xnew) \
    ((void *(*)(void)) (1 ? xnew : ((type *(*)(void))0)))
# define CHECKED_PTR_OF(type, p) \
    ((void*) (1 ? p : (type*)0))
# define CHECKED_PPTR_OF(type, p) \
    ((void**) (1 ? p : (type**)0))

# define TYPEDEF_D2I_OF(type) typedef type *d2i_of_##type(type **,const unsigned char **,long)
# define TYPEDEF_I2D_OF(type) typedef int i2d_of_##type(const type *,unsigned char **)
# define TYPEDEF_D2I2D_OF(type) TYPEDEF_D2I_OF(type); TYPEDEF_I2D_OF(type)

typedef void *d2i_of_void(void **, const unsigned char **, long);
typedef int i2d_of_void(const void *, unsigned char **);

/*-
 * The following macros and typedefs allow an ASN1_ITEM
 * to be embedded in a structure and referenced. Since
 * the ASN1_ITEM pointers need to be globally accessible
 * (possibly from shared libraries) they may exist in
 * different forms. On platforms that support it the
 * ASN1_ITEM structure itself will be globally exported.
 * Other platforms will export a function that returns
 * an ASN1_ITEM pointer.
 *
 * To handle both cases transparently the macros below
 * should be used instead of hard coding an ASN1_ITEM
 * pointer in a structure.
 *
 * The structure will look like this:
 *
 * typedef struct SOMETHING_st {
 *      ...
 *      ASN1_ITEM_EXP *iptr;
 *      ...
 * } SOMETHING;
 *
 * It would be initialised as e.g.:
 *
 * SOMETHING somevar = {...,ASN1_ITEM_ref(X509),...};
 *
 * and the actual pointer extracted with:
 *
 * const ASN1_ITEM *it = ASN1_ITEM_ptr(somevar.iptr);
 *
 * Finally an ASN1_ITEM pointer can be extracted from an
 * appropriate reference with: ASN1_ITEM_rptr(X509). This
 * would be used when a function takes an ASN1_ITEM * argument.
 *
 */


/*
 * Platforms that can't easily handle shared global variables are declared as
 * functions returning ASN1_ITEM pointers.
 */

/* ASN1_ITEM pointer exported type */
typedef const ASN1_ITEM *ASN1_ITEM_EXP (void);

/* Macro to obtain ASN1_ITEM pointer from exported type */
# define ASN1_ITEM_ptr(iptr) (iptr())

/* Macro to include ASN1_ITEM pointer from base type */
# define ASN1_ITEM_ref(iptr) (iptr##_it)

# define ASN1_ITEM_rptr(ref) (ref##_it())

# define DECLARE_ASN1_ITEM_attr(attr, name)                                 \
    attr const ASN1_ITEM * name##_it(void);
# define DECLARE_ASN1_ITEM(name)                                            \
    DECLARE_ASN1_ITEM_attr(extern, name)

/* Parameters used by ASN1_STRING_print_ex() */

/*
 * These determine which characters to escape: RFC2253 special characters,
 * control characters and MSB set characters
 */

# define ASN1_STRFLGS_ESC_2253           1
# define ASN1_STRFLGS_ESC_CTRL           2
# define ASN1_STRFLGS_ESC_MSB            4

/* Lower 8 bits are reserved as an output type specifier */
# define ASN1_DTFLGS_TYPE_MASK    0x0FUL
# define ASN1_DTFLGS_RFC822       0x00UL
# define ASN1_DTFLGS_ISO8601      0x01UL

/*
 * This flag determines how we do escaping: normally RC2253 backslash only,
 * set this to use backslash and quote.
 */

# define ASN1_STRFLGS_ESC_QUOTE          8

/* These three flags are internal use only. */

/* Character is a valid PrintableString character */
# define CHARTYPE_PRINTABLESTRING        0x10
/* Character needs escaping if it is the first character */
# define CHARTYPE_FIRST_ESC_2253         0x20
/* Character needs escaping if it is the last character */
# define CHARTYPE_LAST_ESC_2253          0x40

/*
 * NB the internal flags are safely reused below by flags handled at the top
 * level.
 */

/*
 * If this is set we convert all character strings to UTF8 first
 */

# define ASN1_STRFLGS_UTF8_CONVERT       0x10

/*
 * If this is set we don't attempt to interpret content: just assume all
 * strings are 1 byte per character. This will produce some pretty odd
 * looking output!
 */

# define ASN1_STRFLGS_IGNORE_TYPE        0x20

/* If this is set we include the string type in the output */
# define ASN1_STRFLGS_SHOW_TYPE          0x40

/*
 * This determines which strings to display and which to 'dump' (hex dump of
 * content octets or DER encoding). We can only dump non character strings or
 * everything. If we don't dump 'unknown' they are interpreted as character
 * strings with 1 octet per character and are subject to the usual escaping
 * options.
 */

# define ASN1_STRFLGS_DUMP_ALL           0x80
# define ASN1_STRFLGS_DUMP_UNKNOWN       0x100

/*
 * These determine what 'dumping' does, we can dump the content octets or the
 * DER encoding: both use the RFC2253 #XXXXX notation.
 */

# define ASN1_STRFLGS_DUMP_DER           0x200

/*
 * This flag specifies that RC2254 escaping shall be performed.
 */
#define ASN1_STRFLGS_ESC_2254           0x400

/*
 * All the string flags consistent with RFC2253, escaping control characters
 * isn't essential in RFC2253 but it is advisable anyway.
 */

# define ASN1_STRFLGS_RFC2253    (ASN1_STRFLGS_ESC_2253 | \
                                ASN1_STRFLGS_ESC_CTRL | \
                                ASN1_STRFLGS_ESC_MSB | \
                                ASN1_STRFLGS_UTF8_CONVERT | \
                                ASN1_STRFLGS_DUMP_UNKNOWN | \
                                ASN1_STRFLGS_DUMP_DER)


struct asn1_type_st {
    int type;
    union {
        char *ptr;
        ASN1_BOOLEAN boolean;
        ASN1_STRING *asn1_string;
        ASN1_OBJECT *object;
        ASN1_INTEGER *integer;
        ASN1_ENUMERATED *enumerated;
        ASN1_BIT_STRING *bit_string;
        ASN1_OCTET_STRING *octet_string;
        ASN1_PRINTABLESTRING *printablestring;
        ASN1_T61STRING *t61string;
        ASN1_IA5STRING *ia5string;
        ASN1_GENERALSTRING *generalstring;
        ASN1_BMPSTRING *bmpstring;
        ASN1_UNIVERSALSTRING *universalstring;
        ASN1_UTCTIME *utctime;
        ASN1_GENERALIZEDTIME *generalizedtime;
        ASN1_VISIBLESTRING *visiblestring;
        ASN1_UTF8STRING *utf8string;
        /*
         * set and sequence are left complete and still contain the set or
         * sequence bytes
         */
        ASN1_STRING *set;
        ASN1_STRING *sequence;
        ASN1_VALUE *asn1_value;
    } value;
};

SKM_DEFINE_STACK_OF_INTERNAL(ASN1_TYPE, ASN1_TYPE, ASN1_TYPE)
#define sk_ASN1_TYPE_num(sk) OPENSSL_sk_num(ossl_check_const_ASN1_TYPE_sk_type(sk))
#define sk_ASN1_TYPE_value(sk, idx) ((ASN1_TYPE *)OPENSSL_sk_value(ossl_check_const_ASN1_TYPE_sk_type(sk), (idx)))
#define sk_ASN1_TYPE_new(cmp) ((STACK_OF(ASN1_TYPE) *)OPENSSL_sk_new(ossl_check_ASN1_TYPE_compfunc_type(cmp)))
#define sk_ASN1_TYPE_new_null() ((STACK_OF(ASN1_TYPE) *)OPENSSL_sk_new_null())
#define sk_ASN1_TYPE_new_reserve(cmp, n) ((STACK_OF(ASN1_TYPE) *)OPENSSL_sk_new_reserve(ossl_check_ASN1_TYPE_compfunc_type(cmp), (n)))
#define sk_ASN1_TYPE_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_ASN1_TYPE_sk_type(sk), (n))
#define sk_ASN1_TYPE_free(sk) OPENSSL_sk_free(ossl_check_ASN1_TYPE_sk_type(sk))
#define sk_ASN1_TYPE_zero(sk) OPENSSL_sk_zero(ossl_check_ASN1_TYPE_sk_type(sk))
#define sk_ASN1_TYPE_delete(sk, i) ((ASN1_TYPE *)OPENSSL_sk_delete(ossl_check_ASN1_TYPE_sk_type(sk), (i)))
#define sk_ASN1_TYPE_delete_ptr(sk, ptr) ((ASN1_TYPE *)OPENSSL_sk_delete_ptr(ossl_check_ASN1_TYPE_sk_type(sk), ossl_check_ASN1_TYPE_type(ptr)))
#define sk_ASN1_TYPE_push(sk, ptr) OPENSSL_sk_push(ossl_check_ASN1_TYPE_sk_type(sk), ossl_check_ASN1_TYPE_type(ptr))
#define sk_ASN1_TYPE_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_ASN1_TYPE_sk_type(sk), ossl_check_ASN1_TYPE_type(ptr))
#define sk_ASN1_TYPE_pop(sk) ((ASN1_TYPE *)OPENSSL_sk_pop(ossl_check_ASN1_TYPE_sk_type(sk)))
#define sk_ASN1_TYPE_shift(sk) ((ASN1_TYPE *)OPENSSL_sk_shift(ossl_check_ASN1_TYPE_sk_type(sk)))
#define sk_ASN1_TYPE_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_ASN1_TYPE_sk_type(sk),ossl_check_ASN1_TYPE_freefunc_type(freefunc))
#define sk_ASN1_TYPE_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_ASN1_TYPE_sk_type(sk), ossl_check_ASN1_TYPE_type(ptr), (idx))
#define sk_ASN1_TYPE_set(sk, idx, ptr) ((ASN1_TYPE *)OPENSSL_sk_set(ossl_check_ASN1_TYPE_sk_type(sk), (idx), ossl_check_ASN1_TYPE_type(ptr)))
#define sk_ASN1_TYPE_find(sk, ptr) OPENSSL_sk_find(ossl_check_ASN1_TYPE_sk_type(sk), ossl_check_ASN1_TYPE_type(ptr))
#define sk_ASN1_TYPE_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_ASN1_TYPE_sk_type(sk), ossl_check_ASN1_TYPE_type(ptr))
#define sk_ASN1_TYPE_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_ASN1_TYPE_sk_type(sk), ossl_check_ASN1_TYPE_type(ptr), pnum)
#define sk_ASN1_TYPE_sort(sk) OPENSSL_sk_sort(ossl_check_ASN1_TYPE_sk_type(sk))
#define sk_ASN1_TYPE_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_ASN1_TYPE_sk_type(sk))
#define sk_ASN1_TYPE_dup(sk) ((STACK_OF(ASN1_TYPE) *)OPENSSL_sk_dup(ossl_check_const_ASN1_TYPE_sk_type(sk)))
#define sk_ASN1_TYPE_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(ASN1_TYPE) *)OPENSSL_sk_deep_copy(ossl_check_const_ASN1_TYPE_sk_type(sk), ossl_check_ASN1_TYPE_copyfunc_type(copyfunc), ossl_check_ASN1_TYPE_freefunc_type(freefunc)))
#define sk_ASN1_TYPE_set_cmp_func(sk, cmp) ((sk_ASN1_TYPE_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_ASN1_TYPE_sk_type(sk), ossl_check_ASN1_TYPE_compfunc_type(cmp)))


typedef STACK_OF(ASN1_TYPE) ASN1_SEQUENCE_ANY;

DECLARE_ASN1_ENCODE_FUNCTIONS_name(ASN1_SEQUENCE_ANY, ASN1_SEQUENCE_ANY)
DECLARE_ASN1_ENCODE_FUNCTIONS_name(ASN1_SEQUENCE_ANY, ASN1_SET_ANY)

/* This is used to contain a list of bit names */
typedef struct BIT_STRING_BITNAME_st {
    int bitnum;
    const char *lname;
    const char *sname;
} BIT_STRING_BITNAME;

# define B_ASN1_TIME \
                        B_ASN1_UTCTIME | \
                        B_ASN1_GENERALIZEDTIME

# define B_ASN1_PRINTABLE \
                        B_ASN1_NUMERICSTRING| \
                        B_ASN1_PRINTABLESTRING| \
                        B_ASN1_T61STRING| \
                        B_ASN1_IA5STRING| \
                        B_ASN1_BIT_STRING| \
                        B_ASN1_UNIVERSALSTRING|\
                        B_ASN1_BMPSTRING|\
                        B_ASN1_UTF8STRING|\
                        B_ASN1_SEQUENCE|\
                        B_ASN1_UNKNOWN

# define B_ASN1_DIRECTORYSTRING \
                        B_ASN1_PRINTABLESTRING| \
                        B_ASN1_TELETEXSTRING|\
                        B_ASN1_BMPSTRING|\
                        B_ASN1_UNIVERSALSTRING|\
                        B_ASN1_UTF8STRING

# define B_ASN1_DISPLAYTEXT \
                        B_ASN1_IA5STRING| \
                        B_ASN1_VISIBLESTRING| \
                        B_ASN1_BMPSTRING|\
                        B_ASN1_UTF8STRING

DECLARE_ASN1_ALLOC_FUNCTIONS_name(ASN1_TYPE, ASN1_TYPE)
DECLARE_ASN1_ENCODE_FUNCTIONS(ASN1_TYPE, ASN1_ANY, ASN1_TYPE)

int ASN1_TYPE_get(const ASN1_TYPE *a);
void ASN1_TYPE_set(ASN1_TYPE *a, int type, void *value);
int ASN1_TYPE_set1(ASN1_TYPE *a, int type, const void *value);
int ASN1_TYPE_cmp(const ASN1_TYPE *a, const ASN1_TYPE *b);

ASN1_TYPE *ASN1_TYPE_pack_sequence(const ASN1_ITEM *it, void *s, ASN1_TYPE **t);
void *ASN1_TYPE_unpack_sequence(const ASN1_ITEM *it, const ASN1_TYPE *t);

SKM_DEFINE_STACK_OF_INTERNAL(ASN1_OBJECT, ASN1_OBJECT, ASN1_OBJECT)
#define sk_ASN1_OBJECT_num(sk) OPENSSL_sk_num(ossl_check_const_ASN1_OBJECT_sk_type(sk))
#define sk_ASN1_OBJECT_value(sk, idx) ((ASN1_OBJECT *)OPENSSL_sk_value(ossl_check_const_ASN1_OBJECT_sk_type(sk), (idx)))
#define sk_ASN1_OBJECT_new(cmp) ((STACK_OF(ASN1_OBJECT) *)OPENSSL_sk_new(ossl_check_ASN1_OBJECT_compfunc_type(cmp)))
#define sk_ASN1_OBJECT_new_null() ((STACK_OF(ASN1_OBJECT) *)OPENSSL_sk_new_null())
#define sk_ASN1_OBJECT_new_reserve(cmp, n) ((STACK_OF(ASN1_OBJECT) *)OPENSSL_sk_new_reserve(ossl_check_ASN1_OBJECT_compfunc_type(cmp), (n)))
#define sk_ASN1_OBJECT_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_ASN1_OBJECT_sk_type(sk), (n))
#define sk_ASN1_OBJECT_free(sk) OPENSSL_sk_free(ossl_check_ASN1_OBJECT_sk_type(sk))
#define sk_ASN1_OBJECT_zero(sk) OPENSSL_sk_zero(ossl_check_ASN1_OBJECT_sk_type(sk))
#define sk_ASN1_OBJECT_delete(sk, i) ((ASN1_OBJECT *)OPENSSL_sk_delete(ossl_check_ASN1_OBJECT_sk_type(sk), (i)))
#define sk_ASN1_OBJECT_delete_ptr(sk, ptr) ((ASN1_OBJECT *)OPENSSL_sk_delete_ptr(ossl_check_ASN1_OBJECT_sk_type(sk), ossl_check_ASN1_OBJECT_type(ptr)))
#define sk_ASN1_OBJECT_push(sk, ptr) OPENSSL_sk_push(ossl_check_ASN1_OBJECT_sk_type(sk), ossl_check_ASN1_OBJECT_type(ptr))
#define sk_ASN1_OBJECT_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_ASN1_OBJECT_sk_type(sk), ossl_check_ASN1_OBJECT_type(ptr))
#define sk_ASN1_OBJECT_pop(sk) ((ASN1_OBJECT *)OPENSSL_sk_pop(ossl_check_ASN1_OBJECT_sk_type(sk)))
#define sk_ASN1_OBJECT_shift(sk) ((ASN1_OBJECT *)OPENSSL_sk_shift(ossl_check_ASN1_OBJECT_sk_type(sk)))
#define sk_ASN1_OBJECT_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_ASN1_OBJECT_sk_type(sk),ossl_check_ASN1_OBJECT_freefunc_type(freefunc))
#define sk_ASN1_OBJECT_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_ASN1_OBJECT_sk_type(sk), ossl_check_ASN1_OBJECT_type(ptr), (idx))
#define sk_ASN1_OBJECT_set(sk, idx, ptr) ((ASN1_OBJECT *)OPENSSL_sk_set(ossl_check_ASN1_OBJECT_sk_type(sk), (idx), ossl_check_ASN1_OBJECT_type(ptr)))
#define sk_ASN1_OBJECT_find(sk, ptr) OPENSSL_sk_find(ossl_check_ASN1_OBJECT_sk_type(sk), ossl_check_ASN1_OBJECT_type(ptr))
#define sk_ASN1_OBJECT_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_ASN1_OBJECT_sk_type(sk), ossl_check_ASN1_OBJECT_type(ptr))
#define sk_ASN1_OBJECT_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_ASN1_OBJECT_sk_type(sk), ossl_check_ASN1_OBJECT_type(ptr), pnum)
#define sk_ASN1_OBJECT_sort(sk) OPENSSL_sk_sort(ossl_check_ASN1_OBJECT_sk_type(sk))
#define sk_ASN1_OBJECT_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_ASN1_OBJECT_sk_type(sk))
#define sk_ASN1_OBJECT_dup(sk) ((STACK_OF(ASN1_OBJECT) *)OPENSSL_sk_dup(ossl_check_const_ASN1_OBJECT_sk_type(sk)))
#define sk_ASN1_OBJECT_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(ASN1_OBJECT) *)OPENSSL_sk_deep_copy(ossl_check_const_ASN1_OBJECT_sk_type(sk), ossl_check_ASN1_OBJECT_copyfunc_type(copyfunc), ossl_check_ASN1_OBJECT_freefunc_type(freefunc)))
#define sk_ASN1_OBJECT_set_cmp_func(sk, cmp) ((sk_ASN1_OBJECT_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_ASN1_OBJECT_sk_type(sk), ossl_check_ASN1_OBJECT_compfunc_type(cmp)))


DECLARE_ASN1_FUNCTIONS(ASN1_OBJECT)

ASN1_STRING *ASN1_STRING_new(void);
void ASN1_STRING_free(ASN1_STRING *a);
void ASN1_STRING_clear_free(ASN1_STRING *a);
int ASN1_STRING_copy(ASN1_STRING *dst, const ASN1_STRING *str);
DECLARE_ASN1_DUP_FUNCTION(ASN1_STRING)
ASN1_STRING *ASN1_STRING_type_new(int type);
int ASN1_STRING_cmp(const ASN1_STRING *a, const ASN1_STRING *b);
  /*
   * Since this is used to store all sorts of things, via macros, for now,
   * make its data void *
   */
int ASN1_STRING_set(ASN1_STRING *str, const void *data, int len);
void ASN1_STRING_set0(ASN1_STRING *str, void *data, int len);
int ASN1_STRING_length(const ASN1_STRING *x);
# ifndef OPENSSL_NO_DEPRECATED_3_0
OSSL_DEPRECATEDIN_3_0 void ASN1_STRING_length_set(ASN1_STRING *x, int n);
# endif
int ASN1_STRING_type(const ASN1_STRING *x);
# ifndef OPENSSL_NO_DEPRECATED_1_1_0
OSSL_DEPRECATEDIN_1_1_0 unsigned char *ASN1_STRING_data(ASN1_STRING *x);
# endif
const unsigned char *ASN1_STRING_get0_data(const ASN1_STRING *x);

DECLARE_ASN1_FUNCTIONS(ASN1_BIT_STRING)
int ASN1_BIT_STRING_set(ASN1_BIT_STRING *a, unsigned char *d, int length);
int ASN1_BIT_STRING_set_bit(ASN1_BIT_STRING *a, int n, int value);
int ASN1_BIT_STRING_get_bit(const ASN1_BIT_STRING *a, int n);
int ASN1_BIT_STRING_check(const ASN1_BIT_STRING *a,
                          const unsigned char *flags, int flags_len);

int ASN1_BIT_STRING_name_print(BIO *out, ASN1_BIT_STRING *bs,
                               BIT_STRING_BITNAME *tbl, int indent);
int ASN1_BIT_STRING_num_asc(const char *name, BIT_STRING_BITNAME *tbl);
int ASN1_BIT_STRING_set_asc(ASN1_BIT_STRING *bs, const char *name, int value,
                            BIT_STRING_BITNAME *tbl);

SKM_DEFINE_STACK_OF_INTERNAL(ASN1_INTEGER, ASN1_INTEGER, ASN1_INTEGER)
#define sk_ASN1_INTEGER_num(sk) OPENSSL_sk_num(ossl_check_const_ASN1_INTEGER_sk_type(sk))
#define sk_ASN1_INTEGER_value(sk, idx) ((ASN1_INTEGER *)OPENSSL_sk_value(ossl_check_const_ASN1_INTEGER_sk_type(sk), (idx)))
#define sk_ASN1_INTEGER_new(cmp) ((STACK_OF(ASN1_INTEGER) *)OPENSSL_sk_new(ossl_check_ASN1_INTEGER_compfunc_type(cmp)))
#define sk_ASN1_INTEGER_new_null() ((STACK_OF(ASN1_INTEGER) *)OPENSSL_sk_new_null())
#define sk_ASN1_INTEGER_new_reserve(cmp, n) ((STACK_OF(ASN1_INTEGER) *)OPENSSL_sk_new_reserve(ossl_check_ASN1_INTEGER_compfunc_type(cmp), (n)))
#define sk_ASN1_INTEGER_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_ASN1_INTEGER_sk_type(sk), (n))
#define sk_ASN1_INTEGER_free(sk) OPENSSL_sk_free(ossl_check_ASN1_INTEGER_sk_type(sk))
#define sk_ASN1_INTEGER_zero(sk) OPENSSL_sk_zero(ossl_check_ASN1_INTEGER_sk_type(sk))
#define sk_ASN1_INTEGER_delete(sk, i) ((ASN1_INTEGER *)OPENSSL_sk_delete(ossl_check_ASN1_INTEGER_sk_type(sk), (i)))
#define sk_ASN1_INTEGER_delete_ptr(sk, ptr) ((ASN1_INTEGER *)OPENSSL_sk_delete_ptr(ossl_check_ASN1_INTEGER_sk_type(sk), ossl_check_ASN1_INTEGER_type(ptr)))
#define sk_ASN1_INTEGER_push(sk, ptr) OPENSSL_sk_push(ossl_check_ASN1_INTEGER_sk_type(sk), ossl_check_ASN1_INTEGER_type(ptr))
#define sk_ASN1_INTEGER_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_ASN1_INTEGER_sk_type(sk), ossl_check_ASN1_INTEGER_type(ptr))
#define sk_ASN1_INTEGER_pop(sk) ((ASN1_INTEGER *)OPENSSL_sk_pop(ossl_check_ASN1_INTEGER_sk_type(sk)))
#define sk_ASN1_INTEGER_shift(sk) ((ASN1_INTEGER *)OPENSSL_sk_shift(ossl_check_ASN1_INTEGER_sk_type(sk)))
#define sk_ASN1_INTEGER_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_ASN1_INTEGER_sk_type(sk),ossl_check_ASN1_INTEGER_freefunc_type(freefunc))
#define sk_ASN1_INTEGER_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_ASN1_INTEGER_sk_type(sk), ossl_check_ASN1_INTEGER_type(ptr), (idx))
#define sk_ASN1_INTEGER_set(sk, idx, ptr) ((ASN1_INTEGER *)OPENSSL_sk_set(ossl_check_ASN1_INTEGER_sk_type(sk), (idx), ossl_check_ASN1_INTEGER_type(ptr)))
#define sk_ASN1_INTEGER_find(sk, ptr) OPENSSL_sk_find(ossl_check_ASN1_INTEGER_sk_type(sk), ossl_check_ASN1_INTEGER_type(ptr))
#define sk_ASN1_INTEGER_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_ASN1_INTEGER_sk_type(sk), ossl_check_ASN1_INTEGER_type(ptr))
#define sk_ASN1_INTEGER_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_ASN1_INTEGER_sk_type(sk), ossl_check_ASN1_INTEGER_type(ptr), pnum)
#define sk_ASN1_INTEGER_sort(sk) OPENSSL_sk_sort(ossl_check_ASN1_INTEGER_sk_type(sk))
#define sk_ASN1_INTEGER_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_ASN1_INTEGER_sk_type(sk))
#define sk_ASN1_INTEGER_dup(sk) ((STACK_OF(ASN1_INTEGER) *)OPENSSL_sk_dup(ossl_check_const_ASN1_INTEGER_sk_type(sk)))
#define sk_ASN1_INTEGER_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(ASN1_INTEGER) *)OPENSSL_sk_deep_copy(ossl_check_const_ASN1_INTEGER_sk_type(sk), ossl_check_ASN1_INTEGER_copyfunc_type(copyfunc), ossl_check_ASN1_INTEGER_freefunc_type(freefunc)))
#define sk_ASN1_INTEGER_set_cmp_func(sk, cmp) ((sk_ASN1_INTEGER_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_ASN1_INTEGER_sk_type(sk), ossl_check_ASN1_INTEGER_compfunc_type(cmp)))



DECLARE_ASN1_FUNCTIONS(ASN1_INTEGER)
ASN1_INTEGER *d2i_ASN1_UINTEGER(ASN1_INTEGER **a, const unsigned char **pp,
                                long length);
DECLARE_ASN1_DUP_FUNCTION(ASN1_INTEGER)
int ASN1_INTEGER_cmp(const ASN1_INTEGER *x, const ASN1_INTEGER *y);

DECLARE_ASN1_FUNCTIONS(ASN1_ENUMERATED)

int ASN1_UTCTIME_check(const ASN1_UTCTIME *a);
ASN1_UTCTIME *ASN1_UTCTIME_set(ASN1_UTCTIME *s, time_t t);
ASN1_UTCTIME *ASN1_UTCTIME_adj(ASN1_UTCTIME *s, time_t t,
                               int offset_day, long offset_sec);
int ASN1_UTCTIME_set_string(ASN1_UTCTIME *s, const char *str);
int ASN1_UTCTIME_cmp_time_t(const ASN1_UTCTIME *s, time_t t);

int ASN1_GENERALIZEDTIME_check(const ASN1_GENERALIZEDTIME *a);
ASN1_GENERALIZEDTIME *ASN1_GENERALIZEDTIME_set(ASN1_GENERALIZEDTIME *s,
                                               time_t t);
ASN1_GENERALIZEDTIME *ASN1_GENERALIZEDTIME_adj(ASN1_GENERALIZEDTIME *s,
                                               time_t t, int offset_day,
                                               long offset_sec);
int ASN1_GENERALIZEDTIME_set_string(ASN1_GENERALIZEDTIME *s, const char *str);

int ASN1_TIME_diff(int *pday, int *psec,
                   const ASN1_TIME *from, const ASN1_TIME *to);

DECLARE_ASN1_FUNCTIONS(ASN1_OCTET_STRING)
DECLARE_ASN1_DUP_FUNCTION(ASN1_OCTET_STRING)
int ASN1_OCTET_STRING_cmp(const ASN1_OCTET_STRING *a,
                          const ASN1_OCTET_STRING *b);
int ASN1_OCTET_STRING_set(ASN1_OCTET_STRING *str, const unsigned char *data,
                          int len);

SKM_DEFINE_STACK_OF_INTERNAL(ASN1_UTF8STRING, ASN1_UTF8STRING, ASN1_UTF8STRING)
#define sk_ASN1_UTF8STRING_num(sk) OPENSSL_sk_num(ossl_check_const_ASN1_UTF8STRING_sk_type(sk))
#define sk_ASN1_UTF8STRING_value(sk, idx) ((ASN1_UTF8STRING *)OPENSSL_sk_value(ossl_check_const_ASN1_UTF8STRING_sk_type(sk), (idx)))
#define sk_ASN1_UTF8STRING_new(cmp) ((STACK_OF(ASN1_UTF8STRING) *)OPENSSL_sk_new(ossl_check_ASN1_UTF8STRING_compfunc_type(cmp)))
#define sk_ASN1_UTF8STRING_new_null() ((STACK_OF(ASN1_UTF8STRING) *)OPENSSL_sk_new_null())
#define sk_ASN1_UTF8STRING_new_reserve(cmp, n) ((STACK_OF(ASN1_UTF8STRING) *)OPENSSL_sk_new_reserve(ossl_check_ASN1_UTF8STRING_compfunc_type(cmp), (n)))
#define sk_ASN1_UTF8STRING_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_ASN1_UTF8STRING_sk_type(sk), (n))
#define sk_ASN1_UTF8STRING_free(sk) OPENSSL_sk_free(ossl_check_ASN1_UTF8STRING_sk_type(sk))
#define sk_ASN1_UTF8STRING_zero(sk) OPENSSL_sk_zero(ossl_check_ASN1_UTF8STRING_sk_type(sk))
#define sk_ASN1_UTF8STRING_delete(sk, i) ((ASN1_UTF8STRING *)OPENSSL_sk_delete(ossl_check_ASN1_UTF8STRING_sk_type(sk), (i)))
#define sk_ASN1_UTF8STRING_delete_ptr(sk, ptr) ((ASN1_UTF8STRING *)OPENSSL_sk_delete_ptr(ossl_check_ASN1_UTF8STRING_sk_type(sk), ossl_check_ASN1_UTF8STRING_type(ptr)))
#define sk_ASN1_UTF8STRING_push(sk, ptr) OPENSSL_sk_push(ossl_check_ASN1_UTF8STRING_sk_type(sk), ossl_check_ASN1_UTF8STRING_type(ptr))
#define sk_ASN1_UTF8STRING_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_ASN1_UTF8STRING_sk_type(sk), ossl_check_ASN1_UTF8STRING_type(ptr))
#define sk_ASN1_UTF8STRING_pop(sk) ((ASN1_UTF8STRING *)OPENSSL_sk_pop(ossl_check_ASN1_UTF8STRING_sk_type(sk)))
#define sk_ASN1_UTF8STRING_shift(sk) ((ASN1_UTF8STRING *)OPENSSL_sk_shift(ossl_check_ASN1_UTF8STRING_sk_type(sk)))
#define sk_ASN1_UTF8STRING_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_ASN1_UTF8STRING_sk_type(sk),ossl_check_ASN1_UTF8STRING_freefunc_type(freefunc))
#define sk_ASN1_UTF8STRING_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_ASN1_UTF8STRING_sk_type(sk), ossl_check_ASN1_UTF8STRING_type(ptr), (idx))
#define sk_ASN1_UTF8STRING_set(sk, idx, ptr) ((ASN1_UTF8STRING *)OPENSSL_sk_set(ossl_check_ASN1_UTF8STRING_sk_type(sk), (idx), ossl_check_ASN1_UTF8STRING_type(ptr)))
#define sk_ASN1_UTF8STRING_find(sk, ptr) OPENSSL_sk_find(ossl_check_ASN1_UTF8STRING_sk_type(sk), ossl_check_ASN1_UTF8STRING_type(ptr))
#define sk_ASN1_UTF8STRING_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_ASN1_UTF8STRING_sk_type(sk), ossl_check_ASN1_UTF8STRING_type(ptr))
#define sk_ASN1_UTF8STRING_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_ASN1_UTF8STRING_sk_type(sk), ossl_check_ASN1_UTF8STRING_type(ptr), pnum)
#define sk_ASN1_UTF8STRING_sort(sk) OPENSSL_sk_sort(ossl_check_ASN1_UTF8STRING_sk_type(sk))
#define sk_ASN1_UTF8STRING_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_ASN1_UTF8STRING_sk_type(sk))
#define sk_ASN1_UTF8STRING_dup(sk) ((STACK_OF(ASN1_UTF8STRING) *)OPENSSL_sk_dup(ossl_check_const_ASN1_UTF8STRING_sk_type(sk)))
#define sk_ASN1_UTF8STRING_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(ASN1_UTF8STRING) *)OPENSSL_sk_deep_copy(ossl_check_const_ASN1_UTF8STRING_sk_type(sk), ossl_check_ASN1_UTF8STRING_copyfunc_type(copyfunc), ossl_check_ASN1_UTF8STRING_freefunc_type(freefunc)))
#define sk_ASN1_UTF8STRING_set_cmp_func(sk, cmp) ((sk_ASN1_UTF8STRING_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_ASN1_UTF8STRING_sk_type(sk), ossl_check_ASN1_UTF8STRING_compfunc_type(cmp)))


DECLARE_ASN1_FUNCTIONS(ASN1_VISIBLESTRING)
DECLARE_ASN1_FUNCTIONS(ASN1_UNIVERSALSTRING)
DECLARE_ASN1_FUNCTIONS(ASN1_UTF8STRING)
DECLARE_ASN1_FUNCTIONS(ASN1_NULL)
DECLARE_ASN1_FUNCTIONS(ASN1_BMPSTRING)

int UTF8_getc(const unsigned char *str, int len, unsigned long *val);
int UTF8_putc(unsigned char *str, int len, unsigned long value);

SKM_DEFINE_STACK_OF_INTERNAL(ASN1_GENERALSTRING, ASN1_GENERALSTRING, ASN1_GENERALSTRING)
#define sk_ASN1_GENERALSTRING_num(sk) OPENSSL_sk_num(ossl_check_const_ASN1_GENERALSTRING_sk_type(sk))
#define sk_ASN1_GENERALSTRING_value(sk, idx) ((ASN1_GENERALSTRING *)OPENSSL_sk_value(ossl_check_const_ASN1_GENERALSTRING_sk_type(sk), (idx)))
#define sk_ASN1_GENERALSTRING_new(cmp) ((STACK_OF(ASN1_GENERALSTRING) *)OPENSSL_sk_new(ossl_check_ASN1_GENERALSTRING_compfunc_type(cmp)))
#define sk_ASN1_GENERALSTRING_new_null() ((STACK_OF(ASN1_GENERALSTRING) *)OPENSSL_sk_new_null())
#define sk_ASN1_GENERALSTRING_new_reserve(cmp, n) ((STACK_OF(ASN1_GENERALSTRING) *)OPENSSL_sk_new_reserve(ossl_check_ASN1_GENERALSTRING_compfunc_type(cmp), (n)))
#define sk_ASN1_GENERALSTRING_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_ASN1_GENERALSTRING_sk_type(sk), (n))
#define sk_ASN1_GENERALSTRING_free(sk) OPENSSL_sk_free(ossl_check_ASN1_GENERALSTRING_sk_type(sk))
#define sk_ASN1_GENERALSTRING_zero(sk) OPENSSL_sk_zero(ossl_check_ASN1_GENERALSTRING_sk_type(sk))
#define sk_ASN1_GENERALSTRING_delete(sk, i) ((ASN1_GENERALSTRING *)OPENSSL_sk_delete(ossl_check_ASN1_GENERALSTRING_sk_type(sk), (i)))
#define sk_ASN1_GENERALSTRING_delete_ptr(sk, ptr) ((ASN1_GENERALSTRING *)OPENSSL_sk_delete_ptr(ossl_check_ASN1_GENERALSTRING_sk_type(sk), ossl_check_ASN1_GENERALSTRING_type(ptr)))
#define sk_ASN1_GENERALSTRING_push(sk, ptr) OPENSSL_sk_push(ossl_check_ASN1_GENERALSTRING_sk_type(sk), ossl_check_ASN1_GENERALSTRING_type(ptr))
#define sk_ASN1_GENERALSTRING_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_ASN1_GENERALSTRING_sk_type(sk), ossl_check_ASN1_GENERALSTRING_type(ptr))
#define sk_ASN1_GENERALSTRING_pop(sk) ((ASN1_GENERALSTRING *)OPENSSL_sk_pop(ossl_check_ASN1_GENERALSTRING_sk_type(sk)))
#define sk_ASN1_GENERALSTRING_shift(sk) ((ASN1_GENERALSTRING *)OPENSSL_sk_shift(ossl_check_ASN1_GENERALSTRING_sk_type(sk)))
#define sk_ASN1_GENERALSTRING_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_ASN1_GENERALSTRING_sk_type(sk),ossl_check_ASN1_GENERALSTRING_freefunc_type(freefunc))
#define sk_ASN1_GENERALSTRING_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_ASN1_GENERALSTRING_sk_type(sk), ossl_check_ASN1_GENERALSTRING_type(ptr), (idx))
#define sk_ASN1_GENERALSTRING_set(sk, idx, ptr) ((ASN1_GENERALSTRING *)OPENSSL_sk_set(ossl_check_ASN1_GENERALSTRING_sk_type(sk), (idx), ossl_check_ASN1_GENERALSTRING_type(ptr)))
#define sk_ASN1_GENERALSTRING_find(sk, ptr) OPENSSL_sk_find(ossl_check_ASN1_GENERALSTRING_sk_type(sk), ossl_check_ASN1_GENERALSTRING_type(ptr))
#define sk_ASN1_GENERALSTRING_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_ASN1_GENERALSTRING_sk_type(sk), ossl_check_ASN1_GENERALSTRING_type(ptr))
#define sk_ASN1_GENERALSTRING_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_ASN1_GENERALSTRING_sk_type(sk), ossl_check_ASN1_GENERALSTRING_type(ptr), pnum)
#define sk_ASN1_GENERALSTRING_sort(sk) OPENSSL_sk_sort(ossl_check_ASN1_GENERALSTRING_sk_type(sk))
#define sk_ASN1_GENERALSTRING_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_ASN1_GENERALSTRING_sk_type(sk))
#define sk_ASN1_GENERALSTRING_dup(sk) ((STACK_OF(ASN1_GENERALSTRING) *)OPENSSL_sk_dup(ossl_check_const_ASN1_GENERALSTRING_sk_type(sk)))
#define sk_ASN1_GENERALSTRING_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(ASN1_GENERALSTRING) *)OPENSSL_sk_deep_copy(ossl_check_const_ASN1_GENERALSTRING_sk_type(sk), ossl_check_ASN1_GENERALSTRING_copyfunc_type(copyfunc), ossl_check_ASN1_GENERALSTRING_freefunc_type(freefunc)))
#define sk_ASN1_GENERALSTRING_set_cmp_func(sk, cmp) ((sk_ASN1_GENERALSTRING_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_ASN1_GENERALSTRING_sk_type(sk), ossl_check_ASN1_GENERALSTRING_compfunc_type(cmp)))


DECLARE_ASN1_FUNCTIONS_name(ASN1_STRING, ASN1_PRINTABLE)

DECLARE_ASN1_FUNCTIONS_name(ASN1_STRING, DIRECTORYSTRING)
DECLARE_ASN1_FUNCTIONS_name(ASN1_STRING, DISPLAYTEXT)
DECLARE_ASN1_FUNCTIONS(ASN1_PRINTABLESTRING)
DECLARE_ASN1_FUNCTIONS(ASN1_T61STRING)
DECLARE_ASN1_FUNCTIONS(ASN1_IA5STRING)
DECLARE_ASN1_FUNCTIONS(ASN1_GENERALSTRING)
DECLARE_ASN1_FUNCTIONS(ASN1_UTCTIME)
DECLARE_ASN1_FUNCTIONS(ASN1_GENERALIZEDTIME)
DECLARE_ASN1_FUNCTIONS(ASN1_TIME)

DECLARE_ASN1_DUP_FUNCTION(ASN1_TIME)
DECLARE_ASN1_DUP_FUNCTION(ASN1_UTCTIME)
DECLARE_ASN1_DUP_FUNCTION(ASN1_GENERALIZEDTIME)

DECLARE_ASN1_ITEM(ASN1_OCTET_STRING_NDEF)

ASN1_TIME *ASN1_TIME_set(ASN1_TIME *s, time_t t);
ASN1_TIME *ASN1_TIME_adj(ASN1_TIME *s, time_t t,
                         int offset_day, long offset_sec);
int ASN1_TIME_check(const ASN1_TIME *t);
ASN1_GENERALIZEDTIME *ASN1_TIME_to_generalizedtime(const ASN1_TIME *t,
                                                   ASN1_GENERALIZEDTIME **out);
int ASN1_TIME_set_string(ASN1_TIME *s, const char *str);
int ASN1_TIME_set_string_X509(ASN1_TIME *s, const char *str);
int ASN1_TIME_to_tm(const ASN1_TIME *s, struct tm *tm);
int ASN1_TIME_normalize(ASN1_TIME *s);
int ASN1_TIME_cmp_time_t(const ASN1_TIME *s, time_t t);
int ASN1_TIME_compare(const ASN1_TIME *a, const ASN1_TIME *b);

int i2a_ASN1_INTEGER(BIO *bp, const ASN1_INTEGER *a);
int a2i_ASN1_INTEGER(BIO *bp, ASN1_INTEGER *bs, char *buf, int size);
int i2a_ASN1_ENUMERATED(BIO *bp, const ASN1_ENUMERATED *a);
int a2i_ASN1_ENUMERATED(BIO *bp, ASN1_ENUMERATED *bs, char *buf, int size);
int i2a_ASN1_OBJECT(BIO *bp, const ASN1_OBJECT *a);
int a2i_ASN1_STRING(BIO *bp, ASN1_STRING *bs, char *buf, int size);
int i2a_ASN1_STRING(BIO *bp, const ASN1_STRING *a, int type);
int i2t_ASN1_OBJECT(char *buf, int buf_len, const ASN1_OBJECT *a);

int a2d_ASN1_OBJECT(unsigned char *out, int olen, const char *buf, int num);
ASN1_OBJECT *ASN1_OBJECT_create(int nid, unsigned char *data, int len,
                                const char *sn, const char *ln);

int ASN1_INTEGER_get_int64(int64_t *pr, const ASN1_INTEGER *a);
int ASN1_INTEGER_set_int64(ASN1_INTEGER *a, int64_t r);
int ASN1_INTEGER_get_uint64(uint64_t *pr, const ASN1_INTEGER *a);
int ASN1_INTEGER_set_uint64(ASN1_INTEGER *a, uint64_t r);

int ASN1_INTEGER_set(ASN1_INTEGER *a, long v);
long ASN1_INTEGER_get(const ASN1_INTEGER *a);
ASN1_INTEGER *BN_to_ASN1_INTEGER(const BIGNUM *bn, ASN1_INTEGER *ai);
BIGNUM *ASN1_INTEGER_to_BN(const ASN1_INTEGER *ai, BIGNUM *bn);

int ASN1_ENUMERATED_get_int64(int64_t *pr, const ASN1_ENUMERATED *a);
int ASN1_ENUMERATED_set_int64(ASN1_ENUMERATED *a, int64_t r);


int ASN1_ENUMERATED_set(ASN1_ENUMERATED *a, long v);
long ASN1_ENUMERATED_get(const ASN1_ENUMERATED *a);
ASN1_ENUMERATED *BN_to_ASN1_ENUMERATED(const BIGNUM *bn, ASN1_ENUMERATED *ai);
BIGNUM *ASN1_ENUMERATED_to_BN(const ASN1_ENUMERATED *ai, BIGNUM *bn);

/* General */
/* given a string, return the correct type, max is the maximum length */
int ASN1_PRINTABLE_type(const unsigned char *s, int max);

unsigned long ASN1_tag2bit(int tag);

/* SPECIALS */
int ASN1_get_object(const unsigned char **pp, long *plength, int *ptag,
                    int *pclass, long omax);
int ASN1_check_infinite_end(unsigned char **p, long len);
int ASN1_const_check_infinite_end(const unsigned char **p, long len);
void ASN1_put_object(unsigned char **pp, int constructed, int length,
                     int tag, int xclass);
int ASN1_put_eoc(unsigned char **pp);
int ASN1_object_size(int constructed, int length, int tag);

/* Used to implement other functions */
void *ASN1_dup(i2d_of_void *i2d, d2i_of_void *d2i, const void *x);

# define ASN1_dup_of(type,i2d,d2i,x) \
    ((type*)ASN1_dup(CHECKED_I2D_OF(type, i2d), \
                     CHECKED_D2I_OF(type, d2i), \
                     CHECKED_PTR_OF(const type, x)))

void *ASN1_item_dup(const ASN1_ITEM *it, const void *x);
int ASN1_item_sign_ex(const ASN1_ITEM *it, X509_ALGOR *algor1,
                      X509_ALGOR *algor2, ASN1_BIT_STRING *signature,
                      const void *data, const ASN1_OCTET_STRING *id,
                      EVP_PKEY *pkey, const EVP_MD *md, OSSL_LIB_CTX *libctx,
                      const char *propq);
int ASN1_item_verify_ex(const ASN1_ITEM *it, const X509_ALGOR *alg,
                        const ASN1_BIT_STRING *signature, const void *data,
                        const ASN1_OCTET_STRING *id, EVP_PKEY *pkey,
                        OSSL_LIB_CTX *libctx, const char *propq);

/* ASN1 alloc/free macros for when a type is only used internally */

# define M_ASN1_new_of(type) (type *)ASN1_item_new(ASN1_ITEM_rptr(type))
# define M_ASN1_free_of(x, type) \
                ASN1_item_free(CHECKED_PTR_OF(type, x), ASN1_ITEM_rptr(type))

# ifndef OPENSSL_NO_STDIO
void *ASN1_d2i_fp(void *(*xnew) (void), d2i_of_void *d2i, FILE *in, void **x);

#  define ASN1_d2i_fp_of(type,xnew,d2i,in,x) \
    ((type*)ASN1_d2i_fp(CHECKED_NEW_OF(type, xnew), \
                        CHECKED_D2I_OF(type, d2i), \
                        in, \
                        CHECKED_PPTR_OF(type, x)))

void *ASN1_item_d2i_fp_ex(const ASN1_ITEM *it, FILE *in, void *x,
                          OSSL_LIB_CTX *libctx, const char *propq);
void *ASN1_item_d2i_fp(const ASN1_ITEM *it, FILE *in, void *x);
int ASN1_i2d_fp(i2d_of_void *i2d, FILE *out, const void *x);

#  define ASN1_i2d_fp_of(type,i2d,out,x) \
    (ASN1_i2d_fp(CHECKED_I2D_OF(type, i2d), \
                 out, \
                 CHECKED_PTR_OF(const type, x)))

int ASN1_item_i2d_fp(const ASN1_ITEM *it, FILE *out, const void *x);
int ASN1_STRING_print_ex_fp(FILE *fp, const ASN1_STRING *str, unsigned long flags);
# endif

int ASN1_STRING_to_UTF8(unsigned char **out, const ASN1_STRING *in);

void *ASN1_d2i_bio(void *(*xnew) (void), d2i_of_void *d2i, BIO *in, void **x);

#  define ASN1_d2i_bio_of(type,xnew,d2i,in,x) \
    ((type*)ASN1_d2i_bio( CHECKED_NEW_OF(type, xnew), \
                          CHECKED_D2I_OF(type, d2i), \
                          in, \
                          CHECKED_PPTR_OF(type, x)))

void *ASN1_item_d2i_bio_ex(const ASN1_ITEM *it, BIO *in, void *pval,
                           OSSL_LIB_CTX *libctx, const char *propq);
void *ASN1_item_d2i_bio(const ASN1_ITEM *it, BIO *in, void *pval);
int ASN1_i2d_bio(i2d_of_void *i2d, BIO *out, const void *x);

#  define ASN1_i2d_bio_of(type,i2d,out,x) \
    (ASN1_i2d_bio(CHECKED_I2D_OF(type, i2d), \
                  out, \
                  CHECKED_PTR_OF(const type, x)))

int ASN1_item_i2d_bio(const ASN1_ITEM *it, BIO *out, const void *x);
BIO *ASN1_item_i2d_mem_bio(const ASN1_ITEM *it, const ASN1_VALUE *val);
int ASN1_UTCTIME_print(BIO *fp, const ASN1_UTCTIME *a);
int ASN1_GENERALIZEDTIME_print(BIO *fp, const ASN1_GENERALIZEDTIME *a);
int ASN1_TIME_print(BIO *bp, const ASN1_TIME *tm);
int ASN1_TIME_print_ex(BIO *bp, const ASN1_TIME *tm, unsigned long flags);
int ASN1_STRING_print(BIO *bp, const ASN1_STRING *v);
int ASN1_STRING_print_ex(BIO *out, const ASN1_STRING *str, unsigned long flags);
int ASN1_buf_print(BIO *bp, const unsigned char *buf, size_t buflen, int off);
int ASN1_bn_print(BIO *bp, const char *number, const BIGNUM *num,
                  unsigned char *buf, int off);
int ASN1_parse(BIO *bp, const unsigned char *pp, long len, int indent);
int ASN1_parse_dump(BIO *bp, const unsigned char *pp, long len, int indent,
                    int dump);
const char *ASN1_tag2str(int tag);

/* Used to load and write Netscape format cert */

int ASN1_UNIVERSALSTRING_to_string(ASN1_UNIVERSALSTRING *s);

int ASN1_TYPE_set_octetstring(ASN1_TYPE *a, unsigned char *data, int len);
int ASN1_TYPE_get_octetstring(const ASN1_TYPE *a, unsigned char *data, int max_len);
int ASN1_TYPE_set_int_octetstring(ASN1_TYPE *a, long num,
                                  unsigned char *data, int len);
int ASN1_TYPE_get_int_octetstring(const ASN1_TYPE *a, long *num,
                                  unsigned char *data, int max_len);

void *ASN1_item_unpack(const ASN1_STRING *oct, const ASN1_ITEM *it);

ASN1_STRING *ASN1_item_pack(void *obj, const ASN1_ITEM *it,
                            ASN1_OCTET_STRING **oct);

void ASN1_STRING_set_default_mask(unsigned long mask);
int ASN1_STRING_set_default_mask_asc(const char *p);
unsigned long ASN1_STRING_get_default_mask(void);
int ASN1_mbstring_copy(ASN1_STRING **out, const unsigned char *in, int len,
                       int inform, unsigned long mask);
int ASN1_mbstring_ncopy(ASN1_STRING **out, const unsigned char *in, int len,
                        int inform, unsigned long mask,
                        long minsize, long maxsize);

ASN1_STRING *ASN1_STRING_set_by_NID(ASN1_STRING **out,
                                    const unsigned char *in, int inlen,
                                    int inform, int nid);
ASN1_STRING_TABLE *ASN1_STRING_TABLE_get(int nid);
int ASN1_STRING_TABLE_add(int, long, long, unsigned long, unsigned long);
void ASN1_STRING_TABLE_cleanup(void);

/* ASN1 template functions */

/* Old API compatible functions */
ASN1_VALUE *ASN1_item_new(const ASN1_ITEM *it);
ASN1_VALUE *ASN1_item_new_ex(const ASN1_ITEM *it, OSSL_LIB_CTX *libctx,
                             const char *propq);
void ASN1_item_free(ASN1_VALUE *val, const ASN1_ITEM *it);
ASN1_VALUE *ASN1_item_d2i_ex(ASN1_VALUE **val, const unsigned char **in,
                             long len, const ASN1_ITEM *it,
                             OSSL_LIB_CTX *libctx, const char *propq);
ASN1_VALUE *ASN1_item_d2i(ASN1_VALUE **val, const unsigned char **in,
                          long len, const ASN1_ITEM *it);
int ASN1_item_i2d(const ASN1_VALUE *val, unsigned char **out, const ASN1_ITEM *it);
int ASN1_item_ndef_i2d(const ASN1_VALUE *val, unsigned char **out,
                       const ASN1_ITEM *it);

void ASN1_add_oid_module(void);
void ASN1_add_stable_module(void);

ASN1_TYPE *ASN1_generate_nconf(const char *str, CONF *nconf);
ASN1_TYPE *ASN1_generate_v3(const char *str, X509V3_CTX *cnf);
int ASN1_str2mask(const char *str, unsigned long *pmask);

/* ASN1 Print flags */

/* Indicate missing OPTIONAL fields */
# define ASN1_PCTX_FLAGS_SHOW_ABSENT             0x001
/* Mark start and end of SEQUENCE */
# define ASN1_PCTX_FLAGS_SHOW_SEQUENCE           0x002
/* Mark start and end of SEQUENCE/SET OF */
# define ASN1_PCTX_FLAGS_SHOW_SSOF               0x004
/* Show the ASN1 type of primitives */
# define ASN1_PCTX_FLAGS_SHOW_TYPE               0x008
/* Don't show ASN1 type of ANY */
# define ASN1_PCTX_FLAGS_NO_ANY_TYPE             0x010
/* Don't show ASN1 type of MSTRINGs */
# define ASN1_PCTX_FLAGS_NO_MSTRING_TYPE         0x020
/* Don't show field names in SEQUENCE */
# define ASN1_PCTX_FLAGS_NO_FIELD_NAME           0x040
/* Show structure names of each SEQUENCE field */
# define ASN1_PCTX_FLAGS_SHOW_FIELD_STRUCT_NAME  0x080
/* Don't show structure name even at top level */
# define ASN1_PCTX_FLAGS_NO_STRUCT_NAME          0x100

int ASN1_item_print(BIO *out, const ASN1_VALUE *ifld, int indent,
                    const ASN1_ITEM *it, const ASN1_PCTX *pctx);
ASN1_PCTX *ASN1_PCTX_new(void);
void ASN1_PCTX_free(ASN1_PCTX *p);
unsigned long ASN1_PCTX_get_flags(const ASN1_PCTX *p);
void ASN1_PCTX_set_flags(ASN1_PCTX *p, unsigned long flags);
unsigned long ASN1_PCTX_get_nm_flags(const ASN1_PCTX *p);
void ASN1_PCTX_set_nm_flags(ASN1_PCTX *p, unsigned long flags);
unsigned long ASN1_PCTX_get_cert_flags(const ASN1_PCTX *p);
void ASN1_PCTX_set_cert_flags(ASN1_PCTX *p, unsigned long flags);
unsigned long ASN1_PCTX_get_oid_flags(const ASN1_PCTX *p);
void ASN1_PCTX_set_oid_flags(ASN1_PCTX *p, unsigned long flags);
unsigned long ASN1_PCTX_get_str_flags(const ASN1_PCTX *p);
void ASN1_PCTX_set_str_flags(ASN1_PCTX *p, unsigned long flags);

ASN1_SCTX *ASN1_SCTX_new(int (*scan_cb) (ASN1_SCTX *ctx));
void ASN1_SCTX_free(ASN1_SCTX *p);
const ASN1_ITEM *ASN1_SCTX_get_item(ASN1_SCTX *p);
const ASN1_TEMPLATE *ASN1_SCTX_get_template(ASN1_SCTX *p);
unsigned long ASN1_SCTX_get_flags(ASN1_SCTX *p);
void ASN1_SCTX_set_app_data(ASN1_SCTX *p, void *data);
void *ASN1_SCTX_get_app_data(ASN1_SCTX *p);

const BIO_METHOD *BIO_f_asn1(void);

/* cannot constify val because of CMS_stream() */
BIO *BIO_new_NDEF(BIO *out, ASN1_VALUE *val, const ASN1_ITEM *it);

int i2d_ASN1_bio_stream(BIO *out, ASN1_VALUE *val, BIO *in, int flags,
                        const ASN1_ITEM *it);
int PEM_write_bio_ASN1_stream(BIO *out, ASN1_VALUE *val, BIO *in, int flags,
                              const char *hdr, const ASN1_ITEM *it);
/* cannot constify val because of CMS_dataFinal() */
int SMIME_write_ASN1(BIO *bio, ASN1_VALUE *val, BIO *data, int flags,
                     int ctype_nid, int econt_nid,
                     STACK_OF(X509_ALGOR) *mdalgs, const ASN1_ITEM *it);
int SMIME_write_ASN1_ex(BIO *bio, ASN1_VALUE *val, BIO *data, int flags,
                        int ctype_nid, int econt_nid,
                        STACK_OF(X509_ALGOR) *mdalgs, const ASN1_ITEM *it,
                        OSSL_LIB_CTX *libctx, const char *propq);
ASN1_VALUE *SMIME_read_ASN1(BIO *bio, BIO **bcont, const ASN1_ITEM *it);
ASN1_VALUE *SMIME_read_ASN1_ex(BIO *bio, int flags, BIO **bcont,
                               const ASN1_ITEM *it, ASN1_VALUE **x,
                               OSSL_LIB_CTX *libctx, const char *propq);
int SMIME_crlf_copy(BIO *in, BIO *out, int flags);
int SMIME_text(BIO *in, BIO *out);

const ASN1_ITEM *ASN1_ITEM_lookup(const char *name);
const ASN1_ITEM *ASN1_ITEM_get(size_t i);

/* Legacy compatibility */
# define DECLARE_ASN1_FUNCTIONS_fname(type, itname, name) \
         DECLARE_ASN1_ALLOC_FUNCTIONS_name(type, name) \
         DECLARE_ASN1_ENCODE_FUNCTIONS(type, itname, name)
# define DECLARE_ASN1_FUNCTIONS_const(type) DECLARE_ASN1_FUNCTIONS(type)
# define DECLARE_ASN1_ENCODE_FUNCTIONS_const(type, name) \
         DECLARE_ASN1_ENCODE_FUNCTIONS(type, name)
# define I2D_OF_const(type) I2D_OF(type)
# define ASN1_dup_of_const(type,i2d,d2i,x) ASN1_dup_of(type,i2d,d2i,x)
# define ASN1_i2d_fp_of_const(type,i2d,out,x) ASN1_i2d_fp_of(type,i2d,out,x)
# define ASN1_i2d_bio_of_const(type,i2d,out,x) ASN1_i2d_bio_of(type,i2d,out,x)

# ifdef  __cplusplus
}
# endif
#endif
              node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/openssl/asn1t.h         0000664 0000000 0000000 00000106141 14746647661 0031104 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /*
 * WARNING: do not edit!
 * Generated by Makefile from include/openssl/asn1t.h.in
 *
 * Copyright 2000-2021 The OpenSSL Project Authors. All Rights Reserved.
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 */



#ifndef OPENSSL_ASN1T_H
# define OPENSSL_ASN1T_H
# pragma once

# include <openssl/macros.h>
# ifndef OPENSSL_NO_DEPRECATED_3_0
#  define HEADER_ASN1T_H
# endif

# include <stddef.h>
# include <openssl/e_os2.h>
# include <openssl/asn1.h>

# ifdef OPENSSL_BUILD_SHLIBCRYPTO
#  undef OPENSSL_EXTERN
#  define OPENSSL_EXTERN OPENSSL_EXPORT
# endif

/* ASN1 template defines, structures and functions */

#ifdef  __cplusplus
extern "C" {
#endif

/*-
 * These are the possible values for the itype field of the
 * ASN1_ITEM structure and determine how it is interpreted.
 *
 * For PRIMITIVE types the underlying type
 * determines the behaviour if items is NULL.
 *
 * Otherwise templates must contain a single
 * template and the type is treated in the
 * same way as the type specified in the template.
 *
 * For SEQUENCE types the templates field points
 * to the members, the size field is the
 * structure size.
 *
 * For CHOICE types the templates field points
 * to each possible member (typically a union)
 * and the 'size' field is the offset of the
 * selector.
 *
 * The 'funcs' field is used for application-specific
 * data and functions.
 *
 * The EXTERN type uses a new style d2i/i2d.
 * The new style should be used where possible
 * because it avoids things like the d2i IMPLICIT
 * hack.
 *
 * MSTRING is a multiple string type, it is used
 * for a CHOICE of character strings where the
 * actual strings all occupy an ASN1_STRING
 * structure. In this case the 'utype' field
 * has a special meaning, it is used as a mask
 * of acceptable types using the B_ASN1 constants.
 *
 * NDEF_SEQUENCE is the same as SEQUENCE except
 * that it will use indefinite length constructed
 * encoding if requested.
 *
 */

# define ASN1_ITYPE_PRIMITIVE            0x0
# define ASN1_ITYPE_SEQUENCE             0x1
# define ASN1_ITYPE_CHOICE               0x2
/* unused value                          0x3 */
# define ASN1_ITYPE_EXTERN               0x4
# define ASN1_ITYPE_MSTRING              0x5
# define ASN1_ITYPE_NDEF_SEQUENCE        0x6

/* Macro to obtain ASN1_ADB pointer from a type (only used internally) */
# define ASN1_ADB_ptr(iptr) ((const ASN1_ADB *)((iptr)()))

/* Macros for start and end of ASN1_ITEM definition */

# define ASN1_ITEM_start(itname) \
        const ASN1_ITEM * itname##_it(void) \
        { \
                static const ASN1_ITEM local_it = {

# define static_ASN1_ITEM_start(itname) \
        static ASN1_ITEM_start(itname)

# define ASN1_ITEM_end(itname) \
                }; \
        return &local_it; \
        }

/* Macros to aid ASN1 template writing */

# define ASN1_ITEM_TEMPLATE(tname) \
        static const ASN1_TEMPLATE tname##_item_tt

# define ASN1_ITEM_TEMPLATE_END(tname) \
        ;\
        ASN1_ITEM_start(tname) \
                ASN1_ITYPE_PRIMITIVE,\
                -1,\
                &tname##_item_tt,\
                0,\
                NULL,\
                0,\
                #tname \
        ASN1_ITEM_end(tname)
# define static_ASN1_ITEM_TEMPLATE_END(tname) \
        ;\
        static_ASN1_ITEM_start(tname) \
                ASN1_ITYPE_PRIMITIVE,\
                -1,\
                &tname##_item_tt,\
                0,\
                NULL,\
                0,\
                #tname \
        ASN1_ITEM_end(tname)

/* This is a ASN1 type which just embeds a template */

/*-
 * This pair helps declare a SEQUENCE. We can do:
 *
 *      ASN1_SEQUENCE(stname) = {
 *              ... SEQUENCE components ...
 *      } ASN1_SEQUENCE_END(stname)
 *
 *      This will produce an ASN1_ITEM called stname_it
 *      for a structure called stname.
 *
 *      If you want the same structure but a different
 *      name then use:
 *
 *      ASN1_SEQUENCE(itname) = {
 *              ... SEQUENCE components ...
 *      } ASN1_SEQUENCE_END_name(stname, itname)
 *
 *      This will create an item called itname_it using
 *      a structure called stname.
 */

# define ASN1_SEQUENCE(tname) \
        static const ASN1_TEMPLATE tname##_seq_tt[]

# define ASN1_SEQUENCE_END(stname) ASN1_SEQUENCE_END_name(stname, stname)

# define static_ASN1_SEQUENCE_END(stname) static_ASN1_SEQUENCE_END_name(stname, stname)

# define ASN1_SEQUENCE_END_name(stname, tname) \
        ;\
        ASN1_ITEM_start(tname) \
                ASN1_ITYPE_SEQUENCE,\
                V_ASN1_SEQUENCE,\
                tname##_seq_tt,\
                sizeof(tname##_seq_tt) / sizeof(ASN1_TEMPLATE),\
                NULL,\
                sizeof(stname),\
                #tname \
        ASN1_ITEM_end(tname)

# define static_ASN1_SEQUENCE_END_name(stname, tname) \
        ;\
        static_ASN1_ITEM_start(tname) \
                ASN1_ITYPE_SEQUENCE,\
                V_ASN1_SEQUENCE,\
                tname##_seq_tt,\
                sizeof(tname##_seq_tt) / sizeof(ASN1_TEMPLATE),\
                NULL,\
                sizeof(stname),\
                #stname \
        ASN1_ITEM_end(tname)

# define ASN1_NDEF_SEQUENCE(tname) \
        ASN1_SEQUENCE(tname)

# define ASN1_NDEF_SEQUENCE_cb(tname, cb) \
        ASN1_SEQUENCE_cb(tname, cb)

# define ASN1_SEQUENCE_cb(tname, cb) \
        static const ASN1_AUX tname##_aux = {NULL, 0, 0, 0, cb, 0, NULL}; \
        ASN1_SEQUENCE(tname)

# define ASN1_SEQUENCE_const_cb(tname, const_cb) \
        static const ASN1_AUX tname##_aux = \
            {NULL, ASN1_AFLG_CONST_CB, 0, 0, NULL, 0, const_cb}; \
        ASN1_SEQUENCE(tname)

# define ASN1_SEQUENCE_cb_const_cb(tname, cb, const_cb) \
        static const ASN1_AUX tname##_aux = \
            {NULL, ASN1_AFLG_CONST_CB, 0, 0, cb, 0, const_cb}; \
        ASN1_SEQUENCE(tname)

# define ASN1_SEQUENCE_ref(tname, cb) \
        static const ASN1_AUX tname##_aux = {NULL, ASN1_AFLG_REFCOUNT, offsetof(tname, references), offsetof(tname, lock), cb, 0, NULL}; \
        ASN1_SEQUENCE(tname)

# define ASN1_SEQUENCE_enc(tname, enc, cb) \
        static const ASN1_AUX tname##_aux = {NULL, ASN1_AFLG_ENCODING, 0, 0, cb, offsetof(tname, enc), NULL}; \
        ASN1_SEQUENCE(tname)

# define ASN1_NDEF_SEQUENCE_END(tname) \
        ;\
        ASN1_ITEM_start(tname) \
                ASN1_ITYPE_NDEF_SEQUENCE,\
                V_ASN1_SEQUENCE,\
                tname##_seq_tt,\
                sizeof(tname##_seq_tt) / sizeof(ASN1_TEMPLATE),\
                NULL,\
                sizeof(tname),\
                #tname \
        ASN1_ITEM_end(tname)
# define static_ASN1_NDEF_SEQUENCE_END(tname) \
        ;\
        static_ASN1_ITEM_start(tname) \
                ASN1_ITYPE_NDEF_SEQUENCE,\
                V_ASN1_SEQUENCE,\
                tname##_seq_tt,\
                sizeof(tname##_seq_tt) / sizeof(ASN1_TEMPLATE),\
                NULL,\
                sizeof(tname),\
                #tname \
        ASN1_ITEM_end(tname)


# define ASN1_SEQUENCE_END_enc(stname, tname) ASN1_SEQUENCE_END_ref(stname, tname)

# define ASN1_SEQUENCE_END_cb(stname, tname) ASN1_SEQUENCE_END_ref(stname, tname)
# define static_ASN1_SEQUENCE_END_cb(stname, tname) static_ASN1_SEQUENCE_END_ref(stname, tname)

# define ASN1_SEQUENCE_END_ref(stname, tname) \
        ;\
        ASN1_ITEM_start(tname) \
                ASN1_ITYPE_SEQUENCE,\
                V_ASN1_SEQUENCE,\
                tname##_seq_tt,\
                sizeof(tname##_seq_tt) / sizeof(ASN1_TEMPLATE),\
                &tname##_aux,\
                sizeof(stname),\
                #tname \
        ASN1_ITEM_end(tname)
# define static_ASN1_SEQUENCE_END_ref(stname, tname) \
        ;\
        static_ASN1_ITEM_start(tname) \
                ASN1_ITYPE_SEQUENCE,\
                V_ASN1_SEQUENCE,\
                tname##_seq_tt,\
                sizeof(tname##_seq_tt) / sizeof(ASN1_TEMPLATE),\
                &tname##_aux,\
                sizeof(stname),\
                #stname \
        ASN1_ITEM_end(tname)

# define ASN1_NDEF_SEQUENCE_END_cb(stname, tname) \
        ;\
        ASN1_ITEM_start(tname) \
                ASN1_ITYPE_NDEF_SEQUENCE,\
                V_ASN1_SEQUENCE,\
                tname##_seq_tt,\
                sizeof(tname##_seq_tt) / sizeof(ASN1_TEMPLATE),\
                &tname##_aux,\
                sizeof(stname),\
                #stname \
        ASN1_ITEM_end(tname)

/*-
 * This pair helps declare a CHOICE type. We can do:
 *
 *      ASN1_CHOICE(chname) = {
 *              ... CHOICE options ...
 *      ASN1_CHOICE_END(chname)
 *
 *      This will produce an ASN1_ITEM called chname_it
 *      for a structure called chname. The structure
 *      definition must look like this:
 *      typedef struct {
 *              int type;
 *              union {
 *                      ASN1_SOMETHING *opt1;
 *                      ASN1_SOMEOTHER *opt2;
 *              } value;
 *      } chname;
 *
 *      the name of the selector must be 'type'.
 *      to use an alternative selector name use the
 *      ASN1_CHOICE_END_selector() version.
 */

# define ASN1_CHOICE(tname) \
        static const ASN1_TEMPLATE tname##_ch_tt[]

# define ASN1_CHOICE_cb(tname, cb) \
        static const ASN1_AUX tname##_aux = {NULL, 0, 0, 0, cb, 0, NULL}; \
        ASN1_CHOICE(tname)

# define ASN1_CHOICE_END(stname) ASN1_CHOICE_END_name(stname, stname)

# define static_ASN1_CHOICE_END(stname) static_ASN1_CHOICE_END_name(stname, stname)

# define ASN1_CHOICE_END_name(stname, tname) ASN1_CHOICE_END_selector(stname, tname, type)

# define static_ASN1_CHOICE_END_name(stname, tname) static_ASN1_CHOICE_END_selector(stname, tname, type)

# define ASN1_CHOICE_END_selector(stname, tname, selname) \
        ;\
        ASN1_ITEM_start(tname) \
                ASN1_ITYPE_CHOICE,\
                offsetof(stname,selname) ,\
                tname##_ch_tt,\
                sizeof(tname##_ch_tt) / sizeof(ASN1_TEMPLATE),\
                NULL,\
                sizeof(stname),\
                #stname \
        ASN1_ITEM_end(tname)

# define static_ASN1_CHOICE_END_selector(stname, tname, selname) \
        ;\
        static_ASN1_ITEM_start(tname) \
                ASN1_ITYPE_CHOICE,\
                offsetof(stname,selname) ,\
                tname##_ch_tt,\
                sizeof(tname##_ch_tt) / sizeof(ASN1_TEMPLATE),\
                NULL,\
                sizeof(stname),\
                #stname \
        ASN1_ITEM_end(tname)

# define ASN1_CHOICE_END_cb(stname, tname, selname) \
        ;\
        ASN1_ITEM_start(tname) \
                ASN1_ITYPE_CHOICE,\
                offsetof(stname,selname) ,\
                tname##_ch_tt,\
                sizeof(tname##_ch_tt) / sizeof(ASN1_TEMPLATE),\
                &tname##_aux,\
                sizeof(stname),\
                #stname \
        ASN1_ITEM_end(tname)

/* This helps with the template wrapper form of ASN1_ITEM */

# define ASN1_EX_TEMPLATE_TYPE(flags, tag, name, type) { \
        (flags), (tag), 0,\
        #name, ASN1_ITEM_ref(type) }

/* These help with SEQUENCE or CHOICE components */

/* used to declare other types */

# define ASN1_EX_TYPE(flags, tag, stname, field, type) { \
        (flags), (tag), offsetof(stname, field),\
        #field, ASN1_ITEM_ref(type) }

/* implicit and explicit helper macros */

# define ASN1_IMP_EX(stname, field, type, tag, ex) \
         ASN1_EX_TYPE(ASN1_TFLG_IMPLICIT | (ex), tag, stname, field, type)

# define ASN1_EXP_EX(stname, field, type, tag, ex) \
         ASN1_EX_TYPE(ASN1_TFLG_EXPLICIT | (ex), tag, stname, field, type)

/* Any defined by macros: the field used is in the table itself */

# define ASN1_ADB_OBJECT(tblname) { ASN1_TFLG_ADB_OID, -1, 0, #tblname, tblname##_adb }
# define ASN1_ADB_INTEGER(tblname) { ASN1_TFLG_ADB_INT, -1, 0, #tblname, tblname##_adb }

/* Plain simple type */
# define ASN1_SIMPLE(stname, field, type) ASN1_EX_TYPE(0,0, stname, field, type)
/* Embedded simple type */
# define ASN1_EMBED(stname, field, type) ASN1_EX_TYPE(ASN1_TFLG_EMBED,0, stname, field, type)

/* OPTIONAL simple type */
# define ASN1_OPT(stname, field, type) ASN1_EX_TYPE(ASN1_TFLG_OPTIONAL, 0, stname, field, type)
# define ASN1_OPT_EMBED(stname, field, type) ASN1_EX_TYPE(ASN1_TFLG_OPTIONAL|ASN1_TFLG_EMBED, 0, stname, field, type)

/* IMPLICIT tagged simple type */
# define ASN1_IMP(stname, field, type, tag) ASN1_IMP_EX(stname, field, type, tag, 0)
# define ASN1_IMP_EMBED(stname, field, type, tag) ASN1_IMP_EX(stname, field, type, tag, ASN1_TFLG_EMBED)

/* IMPLICIT tagged OPTIONAL simple type */
# define ASN1_IMP_OPT(stname, field, type, tag) ASN1_IMP_EX(stname, field, type, tag, ASN1_TFLG_OPTIONAL)
# define ASN1_IMP_OPT_EMBED(stname, field, type, tag) ASN1_IMP_EX(stname, field, type, tag, ASN1_TFLG_OPTIONAL|ASN1_TFLG_EMBED)

/* Same as above but EXPLICIT */

# define ASN1_EXP(stname, field, type, tag) ASN1_EXP_EX(stname, field, type, tag, 0)
# define ASN1_EXP_EMBED(stname, field, type, tag) ASN1_EXP_EX(stname, field, type, tag, ASN1_TFLG_EMBED)
# define ASN1_EXP_OPT(stname, field, type, tag) ASN1_EXP_EX(stname, field, type, tag, ASN1_TFLG_OPTIONAL)
# define ASN1_EXP_OPT_EMBED(stname, field, type, tag) ASN1_EXP_EX(stname, field, type, tag, ASN1_TFLG_OPTIONAL|ASN1_TFLG_EMBED)

/* SEQUENCE OF type */
# define ASN1_SEQUENCE_OF(stname, field, type) \
                ASN1_EX_TYPE(ASN1_TFLG_SEQUENCE_OF, 0, stname, field, type)

/* OPTIONAL SEQUENCE OF */
# define ASN1_SEQUENCE_OF_OPT(stname, field, type) \
                ASN1_EX_TYPE(ASN1_TFLG_SEQUENCE_OF|ASN1_TFLG_OPTIONAL, 0, stname, field, type)

/* Same as above but for SET OF */

# define ASN1_SET_OF(stname, field, type) \
                ASN1_EX_TYPE(ASN1_TFLG_SET_OF, 0, stname, field, type)

# define ASN1_SET_OF_OPT(stname, field, type) \
                ASN1_EX_TYPE(ASN1_TFLG_SET_OF|ASN1_TFLG_OPTIONAL, 0, stname, field, type)

/* Finally compound types of SEQUENCE, SET, IMPLICIT, EXPLICIT and OPTIONAL */

# define ASN1_IMP_SET_OF(stname, field, type, tag) \
                        ASN1_IMP_EX(stname, field, type, tag, ASN1_TFLG_SET_OF)

# define ASN1_EXP_SET_OF(stname, field, type, tag) \
                        ASN1_EXP_EX(stname, field, type, tag, ASN1_TFLG_SET_OF)

# define ASN1_IMP_SET_OF_OPT(stname, field, type, tag) \
                        ASN1_IMP_EX(stname, field, type, tag, ASN1_TFLG_SET_OF|ASN1_TFLG_OPTIONAL)

# define ASN1_EXP_SET_OF_OPT(stname, field, type, tag) \
                        ASN1_EXP_EX(stname, field, type, tag, ASN1_TFLG_SET_OF|ASN1_TFLG_OPTIONAL)

# define ASN1_IMP_SEQUENCE_OF(stname, field, type, tag) \
                        ASN1_IMP_EX(stname, field, type, tag, ASN1_TFLG_SEQUENCE_OF)

# define ASN1_IMP_SEQUENCE_OF_OPT(stname, field, type, tag) \
                        ASN1_IMP_EX(stname, field, type, tag, ASN1_TFLG_SEQUENCE_OF|ASN1_TFLG_OPTIONAL)

# define ASN1_EXP_SEQUENCE_OF(stname, field, type, tag) \
                        ASN1_EXP_EX(stname, field, type, tag, ASN1_TFLG_SEQUENCE_OF)

# define ASN1_EXP_SEQUENCE_OF_OPT(stname, field, type, tag) \
                        ASN1_EXP_EX(stname, field, type, tag, ASN1_TFLG_SEQUENCE_OF|ASN1_TFLG_OPTIONAL)

/* EXPLICIT using indefinite length constructed form */
# define ASN1_NDEF_EXP(stname, field, type, tag) \
                        ASN1_EXP_EX(stname, field, type, tag, ASN1_TFLG_NDEF)

/* EXPLICIT OPTIONAL using indefinite length constructed form */
# define ASN1_NDEF_EXP_OPT(stname, field, type, tag) \
                        ASN1_EXP_EX(stname, field, type, tag, ASN1_TFLG_OPTIONAL|ASN1_TFLG_NDEF)

/* Macros for the ASN1_ADB structure */

# define ASN1_ADB(name) \
        static const ASN1_ADB_TABLE name##_adbtbl[]

# define ASN1_ADB_END(name, flags, field, adb_cb, def, none) \
        ;\
        static const ASN1_ITEM *name##_adb(void) \
        { \
        static const ASN1_ADB internal_adb = \
                {\
                flags,\
                offsetof(name, field),\
                adb_cb,\
                name##_adbtbl,\
                sizeof(name##_adbtbl) / sizeof(ASN1_ADB_TABLE),\
                def,\
                none\
                }; \
                return (const ASN1_ITEM *) &internal_adb; \
        } \
        void dummy_function(void)

# define ADB_ENTRY(val, template) {val, template}

# define ASN1_ADB_TEMPLATE(name) \
        static const ASN1_TEMPLATE name##_tt

/*
 * This is the ASN1 template structure that defines a wrapper round the
 * actual type. It determines the actual position of the field in the value
 * structure, various flags such as OPTIONAL and the field name.
 */

struct ASN1_TEMPLATE_st {
    unsigned long flags;        /* Various flags */
    long tag;                   /* tag, not used if no tagging */
    unsigned long offset;       /* Offset of this field in structure */
    const char *field_name;     /* Field name */
    ASN1_ITEM_EXP *item;        /* Relevant ASN1_ITEM or ASN1_ADB */
};

/* Macro to extract ASN1_ITEM and ASN1_ADB pointer from ASN1_TEMPLATE */

# define ASN1_TEMPLATE_item(t) (t->item_ptr)
# define ASN1_TEMPLATE_adb(t) (t->item_ptr)

typedef struct ASN1_ADB_TABLE_st ASN1_ADB_TABLE;
typedef struct ASN1_ADB_st ASN1_ADB;

struct ASN1_ADB_st {
    unsigned long flags;        /* Various flags */
    unsigned long offset;       /* Offset of selector field */
    int (*adb_cb)(long *psel);  /* Application callback */
    const ASN1_ADB_TABLE *tbl;  /* Table of possible types */
    long tblcount;              /* Number of entries in tbl */
    const ASN1_TEMPLATE *default_tt; /* Type to use if no match */
    const ASN1_TEMPLATE *null_tt; /* Type to use if selector is NULL */
};

struct ASN1_ADB_TABLE_st {
    long value;                 /* NID for an object or value for an int */
    const ASN1_TEMPLATE tt;     /* item for this value */
};

/* template flags */

/* Field is optional */
# define ASN1_TFLG_OPTIONAL      (0x1)

/* Field is a SET OF */
# define ASN1_TFLG_SET_OF        (0x1 << 1)

/* Field is a SEQUENCE OF */
# define ASN1_TFLG_SEQUENCE_OF   (0x2 << 1)

/*
 * Special case: this refers to a SET OF that will be sorted into DER order
 * when encoded *and* the corresponding STACK will be modified to match the
 * new order.
 */
# define ASN1_TFLG_SET_ORDER     (0x3 << 1)

/* Mask for SET OF or SEQUENCE OF */
# define ASN1_TFLG_SK_MASK       (0x3 << 1)

/*
 * These flags mean the tag should be taken from the tag field. If EXPLICIT
 * then the underlying type is used for the inner tag.
 */

/* IMPLICIT tagging */
# define ASN1_TFLG_IMPTAG        (0x1 << 3)

/* EXPLICIT tagging, inner tag from underlying type */
# define ASN1_TFLG_EXPTAG        (0x2 << 3)

# define ASN1_TFLG_TAG_MASK      (0x3 << 3)

/* context specific IMPLICIT */
# define ASN1_TFLG_IMPLICIT      (ASN1_TFLG_IMPTAG|ASN1_TFLG_CONTEXT)

/* context specific EXPLICIT */
# define ASN1_TFLG_EXPLICIT      (ASN1_TFLG_EXPTAG|ASN1_TFLG_CONTEXT)

/*
 * If tagging is in force these determine the type of tag to use. Otherwise
 * the tag is determined by the underlying type. These values reflect the
 * actual octet format.
 */

/* Universal tag */
# define ASN1_TFLG_UNIVERSAL     (0x0<<6)
/* Application tag */
# define ASN1_TFLG_APPLICATION   (0x1<<6)
/* Context specific tag */
# define ASN1_TFLG_CONTEXT       (0x2<<6)
/* Private tag */
# define ASN1_TFLG_PRIVATE       (0x3<<6)

# define ASN1_TFLG_TAG_CLASS     (0x3<<6)

/*
 * These are for ANY DEFINED BY type. In this case the 'item' field points to
 * an ASN1_ADB structure which contains a table of values to decode the
 * relevant type
 */

# define ASN1_TFLG_ADB_MASK      (0x3<<8)

# define ASN1_TFLG_ADB_OID       (0x1<<8)

# define ASN1_TFLG_ADB_INT       (0x1<<9)

/*
 * This flag when present in a SEQUENCE OF, SET OF or EXPLICIT causes
 * indefinite length constructed encoding to be used if required.
 */

# define ASN1_TFLG_NDEF          (0x1<<11)

/* Field is embedded and not a pointer */
# define ASN1_TFLG_EMBED         (0x1 << 12)

/* This is the actual ASN1 item itself */

struct ASN1_ITEM_st {
    char itype;                 /* The item type, primitive, SEQUENCE, CHOICE
                                 * or extern */
    long utype;                 /* underlying type */
    const ASN1_TEMPLATE *templates; /* If SEQUENCE or CHOICE this contains
                                     * the contents */
    long tcount;                /* Number of templates if SEQUENCE or CHOICE */
    const void *funcs;          /* further data and type-specific functions */
    /* funcs can be ASN1_PRIMITIVE_FUNCS*, ASN1_EXTERN_FUNCS*, or ASN1_AUX* */
    long size;                  /* Structure size (usually) */
    const char *sname;          /* Structure name */
};

/*
 * Cache for ASN1 tag and length, so we don't keep re-reading it for things
 * like CHOICE
 */

struct ASN1_TLC_st {
    char valid;                 /* Values below are valid */
    int ret;                    /* return value */
    long plen;                  /* length */
    int ptag;                   /* class value */
    int pclass;                 /* class value */
    int hdrlen;                 /* header length */
};

/* Typedefs for ASN1 function pointers */
typedef int ASN1_ex_d2i(ASN1_VALUE **pval, const unsigned char **in, long len,
                        const ASN1_ITEM *it, int tag, int aclass, char opt,
                        ASN1_TLC *ctx);

typedef int ASN1_ex_d2i_ex(ASN1_VALUE **pval, const unsigned char **in, long len,
                           const ASN1_ITEM *it, int tag, int aclass, char opt,
                           ASN1_TLC *ctx, OSSL_LIB_CTX *libctx,
                           const char *propq);
typedef int ASN1_ex_i2d(const ASN1_VALUE **pval, unsigned char **out,
                        const ASN1_ITEM *it, int tag, int aclass);
typedef int ASN1_ex_new_func(ASN1_VALUE **pval, const ASN1_ITEM *it);
typedef int ASN1_ex_new_ex_func(ASN1_VALUE **pval, const ASN1_ITEM *it,
                                OSSL_LIB_CTX *libctx, const char *propq);
typedef void ASN1_ex_free_func(ASN1_VALUE **pval, const ASN1_ITEM *it);

typedef int ASN1_ex_print_func(BIO *out, const ASN1_VALUE **pval,
                               int indent, const char *fname,
                               const ASN1_PCTX *pctx);

typedef int ASN1_primitive_i2c(const ASN1_VALUE **pval, unsigned char *cont,
                               int *putype, const ASN1_ITEM *it);
typedef int ASN1_primitive_c2i(ASN1_VALUE **pval, const unsigned char *cont,
                               int len, int utype, char *free_cont,
                               const ASN1_ITEM *it);
typedef int ASN1_primitive_print(BIO *out, const ASN1_VALUE **pval,
                                 const ASN1_ITEM *it, int indent,
                                 const ASN1_PCTX *pctx);

typedef struct ASN1_EXTERN_FUNCS_st {
    void *app_data;
    ASN1_ex_new_func *asn1_ex_new;
    ASN1_ex_free_func *asn1_ex_free;
    ASN1_ex_free_func *asn1_ex_clear;
    ASN1_ex_d2i *asn1_ex_d2i;
    ASN1_ex_i2d *asn1_ex_i2d;
    ASN1_ex_print_func *asn1_ex_print;
    ASN1_ex_new_ex_func *asn1_ex_new_ex;
    ASN1_ex_d2i_ex *asn1_ex_d2i_ex;
} ASN1_EXTERN_FUNCS;

typedef struct ASN1_PRIMITIVE_FUNCS_st {
    void *app_data;
    unsigned long flags;
    ASN1_ex_new_func *prim_new;
    ASN1_ex_free_func *prim_free;
    ASN1_ex_free_func *prim_clear;
    ASN1_primitive_c2i *prim_c2i;
    ASN1_primitive_i2c *prim_i2c;
    ASN1_primitive_print *prim_print;
} ASN1_PRIMITIVE_FUNCS;

/*
 * This is the ASN1_AUX structure: it handles various miscellaneous
 * requirements. For example the use of reference counts and an informational
 * callback. The "informational callback" is called at various points during
 * the ASN1 encoding and decoding. It can be used to provide minor
 * customisation of the structures used. This is most useful where the
 * supplied routines *almost* do the right thing but need some extra help at
 * a few points. If the callback returns zero then it is assumed a fatal
 * error has occurred and the main operation should be abandoned. If major
 * changes in the default behaviour are required then an external type is
 * more appropriate.
 * For the operations ASN1_OP_I2D_PRE, ASN1_OP_I2D_POST, ASN1_OP_PRINT_PRE, and
 * ASN1_OP_PRINT_POST, meanwhile a variant of the callback with const parameter
 * 'in' is provided to make clear statically that its input is not modified. If
 * and only if this variant is in use the flag ASN1_AFLG_CONST_CB must be set.
 */

typedef int ASN1_aux_cb(int operation, ASN1_VALUE **in, const ASN1_ITEM *it,
                        void *exarg);
typedef int ASN1_aux_const_cb(int operation, const ASN1_VALUE **in,
                              const ASN1_ITEM *it, void *exarg);

typedef struct ASN1_AUX_st {
    void *app_data;
    int flags;
    int ref_offset;             /* Offset of reference value */
    int ref_lock;               /* Offset of lock value */
    ASN1_aux_cb *asn1_cb;
    int enc_offset;             /* Offset of ASN1_ENCODING structure */
    ASN1_aux_const_cb *asn1_const_cb; /* for ASN1_OP_I2D_ and ASN1_OP_PRINT_ */
} ASN1_AUX;

/* For print related callbacks exarg points to this structure */
typedef struct ASN1_PRINT_ARG_st {
    BIO *out;
    int indent;
    const ASN1_PCTX *pctx;
} ASN1_PRINT_ARG;

/* For streaming related callbacks exarg points to this structure */
typedef struct ASN1_STREAM_ARG_st {
    /* BIO to stream through */
    BIO *out;
    /* BIO with filters appended */
    BIO *ndef_bio;
    /* Streaming I/O boundary */
    unsigned char **boundary;
} ASN1_STREAM_ARG;

/* Flags in ASN1_AUX */

/* Use a reference count */
# define ASN1_AFLG_REFCOUNT      1
/* Save the encoding of structure (useful for signatures) */
# define ASN1_AFLG_ENCODING      2
/* The Sequence length is invalid */
# define ASN1_AFLG_BROKEN        4
/* Use the new asn1_const_cb */
# define ASN1_AFLG_CONST_CB      8

/* operation values for asn1_cb */

# define ASN1_OP_NEW_PRE         0
# define ASN1_OP_NEW_POST        1
# define ASN1_OP_FREE_PRE        2
# define ASN1_OP_FREE_POST       3
# define ASN1_OP_D2I_PRE         4
# define ASN1_OP_D2I_POST        5
# define ASN1_OP_I2D_PRE         6
# define ASN1_OP_I2D_POST        7
# define ASN1_OP_PRINT_PRE       8
# define ASN1_OP_PRINT_POST      9
# define ASN1_OP_STREAM_PRE      10
# define ASN1_OP_STREAM_POST     11
# define ASN1_OP_DETACHED_PRE    12
# define ASN1_OP_DETACHED_POST   13
# define ASN1_OP_DUP_PRE         14
# define ASN1_OP_DUP_POST        15
# define ASN1_OP_GET0_LIBCTX     16
# define ASN1_OP_GET0_PROPQ      17

/* Macro to implement a primitive type */
# define IMPLEMENT_ASN1_TYPE(stname) IMPLEMENT_ASN1_TYPE_ex(stname, stname, 0)
# define IMPLEMENT_ASN1_TYPE_ex(itname, vname, ex) \
                                ASN1_ITEM_start(itname) \
                                        ASN1_ITYPE_PRIMITIVE, V_##vname, NULL, 0, NULL, ex, #itname \
                                ASN1_ITEM_end(itname)

/* Macro to implement a multi string type */
# define IMPLEMENT_ASN1_MSTRING(itname, mask) \
                                ASN1_ITEM_start(itname) \
                                        ASN1_ITYPE_MSTRING, mask, NULL, 0, NULL, sizeof(ASN1_STRING), #itname \
                                ASN1_ITEM_end(itname)

# define IMPLEMENT_EXTERN_ASN1(sname, tag, fptrs) \
        ASN1_ITEM_start(sname) \
                ASN1_ITYPE_EXTERN, \
                tag, \
                NULL, \
                0, \
                &fptrs, \
                0, \
                #sname \
        ASN1_ITEM_end(sname)

/* Macro to implement standard functions in terms of ASN1_ITEM structures */

# define IMPLEMENT_ASN1_FUNCTIONS(stname) IMPLEMENT_ASN1_FUNCTIONS_fname(stname, stname, stname)

# define IMPLEMENT_ASN1_FUNCTIONS_name(stname, itname) IMPLEMENT_ASN1_FUNCTIONS_fname(stname, itname, itname)

# define IMPLEMENT_ASN1_FUNCTIONS_ENCODE_name(stname, itname) \
                        IMPLEMENT_ASN1_FUNCTIONS_ENCODE_fname(stname, itname, itname)

# define IMPLEMENT_STATIC_ASN1_ALLOC_FUNCTIONS(stname) \
                IMPLEMENT_ASN1_ALLOC_FUNCTIONS_pfname(static, stname, stname, stname)

# define IMPLEMENT_ASN1_ALLOC_FUNCTIONS(stname) \
                IMPLEMENT_ASN1_ALLOC_FUNCTIONS_fname(stname, stname, stname)

# define IMPLEMENT_ASN1_ALLOC_FUNCTIONS_pfname(pre, stname, itname, fname) \
        pre stname *fname##_new(void) \
        { \
                return (stname *)ASN1_item_new(ASN1_ITEM_rptr(itname)); \
        } \
        pre void fname##_free(stname *a) \
        { \
                ASN1_item_free((ASN1_VALUE *)a, ASN1_ITEM_rptr(itname)); \
        }

# define IMPLEMENT_ASN1_ALLOC_FUNCTIONS_fname(stname, itname, fname) \
        stname *fname##_new(void) \
        { \
                return (stname *)ASN1_item_new(ASN1_ITEM_rptr(itname)); \
        } \
        void fname##_free(stname *a) \
        { \
                ASN1_item_free((ASN1_VALUE *)a, ASN1_ITEM_rptr(itname)); \
        }

# define IMPLEMENT_ASN1_FUNCTIONS_fname(stname, itname, fname) \
        IMPLEMENT_ASN1_ENCODE_FUNCTIONS_fname(stname, itname, fname) \
        IMPLEMENT_ASN1_ALLOC_FUNCTIONS_fname(stname, itname, fname)

# define IMPLEMENT_ASN1_ENCODE_FUNCTIONS_fname(stname, itname, fname) \
        stname *d2i_##fname(stname **a, const unsigned char **in, long len) \
        { \
                return (stname *)ASN1_item_d2i((ASN1_VALUE **)a, in, len, ASN1_ITEM_rptr(itname));\
        } \
        int i2d_##fname(const stname *a, unsigned char **out) \
        { \
                return ASN1_item_i2d((const ASN1_VALUE *)a, out, ASN1_ITEM_rptr(itname));\
        }

# define IMPLEMENT_ASN1_NDEF_FUNCTION(stname) \
        int i2d_##stname##_NDEF(const stname *a, unsigned char **out) \
        { \
                return ASN1_item_ndef_i2d((const ASN1_VALUE *)a, out, ASN1_ITEM_rptr(stname));\
        }

# define IMPLEMENT_STATIC_ASN1_ENCODE_FUNCTIONS(stname) \
        static stname *d2i_##stname(stname **a, \
                                   const unsigned char **in, long len) \
        { \
                return (stname *)ASN1_item_d2i((ASN1_VALUE **)a, in, len, \
                                               ASN1_ITEM_rptr(stname)); \
        } \
        static int i2d_##stname(const stname *a, unsigned char **out) \
        { \
                return ASN1_item_i2d((const ASN1_VALUE *)a, out, \
                                     ASN1_ITEM_rptr(stname)); \
        }

# define IMPLEMENT_ASN1_DUP_FUNCTION(stname) \
        stname * stname##_dup(const stname *x) \
        { \
        return ASN1_item_dup(ASN1_ITEM_rptr(stname), x); \
        }

# define IMPLEMENT_ASN1_PRINT_FUNCTION(stname) \
        IMPLEMENT_ASN1_PRINT_FUNCTION_fname(stname, stname, stname)

# define IMPLEMENT_ASN1_PRINT_FUNCTION_fname(stname, itname, fname) \
        int fname##_print_ctx(BIO *out, const stname *x, int indent, \
                                                const ASN1_PCTX *pctx) \
        { \
                return ASN1_item_print(out, (const ASN1_VALUE *)x, indent, \
                        ASN1_ITEM_rptr(itname), pctx); \
        }

/* external definitions for primitive types */

DECLARE_ASN1_ITEM(ASN1_BOOLEAN)
DECLARE_ASN1_ITEM(ASN1_TBOOLEAN)
DECLARE_ASN1_ITEM(ASN1_FBOOLEAN)
DECLARE_ASN1_ITEM(ASN1_SEQUENCE)
DECLARE_ASN1_ITEM(CBIGNUM)
DECLARE_ASN1_ITEM(BIGNUM)
DECLARE_ASN1_ITEM(INT32)
DECLARE_ASN1_ITEM(ZINT32)
DECLARE_ASN1_ITEM(UINT32)
DECLARE_ASN1_ITEM(ZUINT32)
DECLARE_ASN1_ITEM(INT64)
DECLARE_ASN1_ITEM(ZINT64)
DECLARE_ASN1_ITEM(UINT64)
DECLARE_ASN1_ITEM(ZUINT64)

# ifndef OPENSSL_NO_DEPRECATED_3_0
/*
 * LONG and ZLONG are strongly discouraged for use as stored data, as the
 * underlying C type (long) differs in size depending on the architecture.
 * They are designed with 32-bit longs in mind.
 */
DECLARE_ASN1_ITEM(LONG)
DECLARE_ASN1_ITEM(ZLONG)
# endif

SKM_DEFINE_STACK_OF_INTERNAL(ASN1_VALUE, ASN1_VALUE, ASN1_VALUE)
#define sk_ASN1_VALUE_num(sk) OPENSSL_sk_num(ossl_check_const_ASN1_VALUE_sk_type(sk))
#define sk_ASN1_VALUE_value(sk, idx) ((ASN1_VALUE *)OPENSSL_sk_value(ossl_check_const_ASN1_VALUE_sk_type(sk), (idx)))
#define sk_ASN1_VALUE_new(cmp) ((STACK_OF(ASN1_VALUE) *)OPENSSL_sk_new(ossl_check_ASN1_VALUE_compfunc_type(cmp)))
#define sk_ASN1_VALUE_new_null() ((STACK_OF(ASN1_VALUE) *)OPENSSL_sk_new_null())
#define sk_ASN1_VALUE_new_reserve(cmp, n) ((STACK_OF(ASN1_VALUE) *)OPENSSL_sk_new_reserve(ossl_check_ASN1_VALUE_compfunc_type(cmp), (n)))
#define sk_ASN1_VALUE_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_ASN1_VALUE_sk_type(sk), (n))
#define sk_ASN1_VALUE_free(sk) OPENSSL_sk_free(ossl_check_ASN1_VALUE_sk_type(sk))
#define sk_ASN1_VALUE_zero(sk) OPENSSL_sk_zero(ossl_check_ASN1_VALUE_sk_type(sk))
#define sk_ASN1_VALUE_delete(sk, i) ((ASN1_VALUE *)OPENSSL_sk_delete(ossl_check_ASN1_VALUE_sk_type(sk), (i)))
#define sk_ASN1_VALUE_delete_ptr(sk, ptr) ((ASN1_VALUE *)OPENSSL_sk_delete_ptr(ossl_check_ASN1_VALUE_sk_type(sk), ossl_check_ASN1_VALUE_type(ptr)))
#define sk_ASN1_VALUE_push(sk, ptr) OPENSSL_sk_push(ossl_check_ASN1_VALUE_sk_type(sk), ossl_check_ASN1_VALUE_type(ptr))
#define sk_ASN1_VALUE_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_ASN1_VALUE_sk_type(sk), ossl_check_ASN1_VALUE_type(ptr))
#define sk_ASN1_VALUE_pop(sk) ((ASN1_VALUE *)OPENSSL_sk_pop(ossl_check_ASN1_VALUE_sk_type(sk)))
#define sk_ASN1_VALUE_shift(sk) ((ASN1_VALUE *)OPENSSL_sk_shift(ossl_check_ASN1_VALUE_sk_type(sk)))
#define sk_ASN1_VALUE_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_ASN1_VALUE_sk_type(sk),ossl_check_ASN1_VALUE_freefunc_type(freefunc))
#define sk_ASN1_VALUE_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_ASN1_VALUE_sk_type(sk), ossl_check_ASN1_VALUE_type(ptr), (idx))
#define sk_ASN1_VALUE_set(sk, idx, ptr) ((ASN1_VALUE *)OPENSSL_sk_set(ossl_check_ASN1_VALUE_sk_type(sk), (idx), ossl_check_ASN1_VALUE_type(ptr)))
#define sk_ASN1_VALUE_find(sk, ptr) OPENSSL_sk_find(ossl_check_ASN1_VALUE_sk_type(sk), ossl_check_ASN1_VALUE_type(ptr))
#define sk_ASN1_VALUE_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_ASN1_VALUE_sk_type(sk), ossl_check_ASN1_VALUE_type(ptr))
#define sk_ASN1_VALUE_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_ASN1_VALUE_sk_type(sk), ossl_check_ASN1_VALUE_type(ptr), pnum)
#define sk_ASN1_VALUE_sort(sk) OPENSSL_sk_sort(ossl_check_ASN1_VALUE_sk_type(sk))
#define sk_ASN1_VALUE_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_ASN1_VALUE_sk_type(sk))
#define sk_ASN1_VALUE_dup(sk) ((STACK_OF(ASN1_VALUE) *)OPENSSL_sk_dup(ossl_check_const_ASN1_VALUE_sk_type(sk)))
#define sk_ASN1_VALUE_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(ASN1_VALUE) *)OPENSSL_sk_deep_copy(ossl_check_const_ASN1_VALUE_sk_type(sk), ossl_check_ASN1_VALUE_copyfunc_type(copyfunc), ossl_check_ASN1_VALUE_freefunc_type(freefunc)))
#define sk_ASN1_VALUE_set_cmp_func(sk, cmp) ((sk_ASN1_VALUE_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_ASN1_VALUE_sk_type(sk), ossl_check_ASN1_VALUE_compfunc_type(cmp)))



/* Functions used internally by the ASN1 code */

int ASN1_item_ex_new(ASN1_VALUE **pval, const ASN1_ITEM *it);
void ASN1_item_ex_free(ASN1_VALUE **pval, const ASN1_ITEM *it);

int ASN1_item_ex_d2i(ASN1_VALUE **pval, const unsigned char **in, long len,
                     const ASN1_ITEM *it, int tag, int aclass, char opt,
                     ASN1_TLC *ctx);

int ASN1_item_ex_i2d(const ASN1_VALUE **pval, unsigned char **out,
                     const ASN1_ITEM *it, int tag, int aclass);

/* Legacy compatibility */
# define IMPLEMENT_ASN1_FUNCTIONS_const(name) IMPLEMENT_ASN1_FUNCTIONS(name)
# define IMPLEMENT_ASN1_ENCODE_FUNCTIONS_const_fname(stname, itname, fname) \
         IMPLEMENT_ASN1_ENCODE_FUNCTIONS_fname(stname, itname, fname)

#ifdef  __cplusplus
}
#endif
#endif
                                                                                                                                                                                                                                                                                                                                                                                                                               node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/openssl/bio.h           0000664 0000000 0000000 00000115644 14746647661 0030637 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /*
 * WARNING: do not edit!
 * Generated by Makefile from include/openssl/bio.h.in
 *
 * Copyright 1995-2022 The OpenSSL Project Authors. All Rights Reserved.
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 */


#ifndef OPENSSL_BIO_H
# define OPENSSL_BIO_H
# pragma once

# include <openssl/macros.h>
# ifndef OPENSSL_NO_DEPRECATED_3_0
#  define HEADER_BIO_H
# endif

# include <openssl/e_os2.h>

# ifndef OPENSSL_NO_STDIO
#  include <stdio.h>
# endif
# include <stdarg.h>

# include <openssl/crypto.h>
# include <openssl/bioerr.h>
# include <openssl/core.h>

#ifdef  __cplusplus
extern "C" {
#endif

/* There are the classes of BIOs */
# define BIO_TYPE_DESCRIPTOR     0x0100 /* socket, fd, connect or accept */
# define BIO_TYPE_FILTER         0x0200
# define BIO_TYPE_SOURCE_SINK    0x0400

/* These are the 'types' of BIOs */
# define BIO_TYPE_NONE             0
# define BIO_TYPE_MEM            ( 1|BIO_TYPE_SOURCE_SINK)
# define BIO_TYPE_FILE           ( 2|BIO_TYPE_SOURCE_SINK)

# define BIO_TYPE_FD             ( 4|BIO_TYPE_SOURCE_SINK|BIO_TYPE_DESCRIPTOR)
# define BIO_TYPE_SOCKET         ( 5|BIO_TYPE_SOURCE_SINK|BIO_TYPE_DESCRIPTOR)
# define BIO_TYPE_NULL           ( 6|BIO_TYPE_SOURCE_SINK)
# define BIO_TYPE_SSL            ( 7|BIO_TYPE_FILTER)
# define BIO_TYPE_MD             ( 8|BIO_TYPE_FILTER)
# define BIO_TYPE_BUFFER         ( 9|BIO_TYPE_FILTER)
# define BIO_TYPE_CIPHER         (10|BIO_TYPE_FILTER)
# define BIO_TYPE_BASE64         (11|BIO_TYPE_FILTER)
# define BIO_TYPE_CONNECT        (12|BIO_TYPE_SOURCE_SINK|BIO_TYPE_DESCRIPTOR)
# define BIO_TYPE_ACCEPT         (13|BIO_TYPE_SOURCE_SINK|BIO_TYPE_DESCRIPTOR)

# define BIO_TYPE_NBIO_TEST      (16|BIO_TYPE_FILTER)/* server proxy BIO */
# define BIO_TYPE_NULL_FILTER    (17|BIO_TYPE_FILTER)
# define BIO_TYPE_BIO            (19|BIO_TYPE_SOURCE_SINK)/* half a BIO pair */
# define BIO_TYPE_LINEBUFFER     (20|BIO_TYPE_FILTER)
# define BIO_TYPE_DGRAM          (21|BIO_TYPE_SOURCE_SINK|BIO_TYPE_DESCRIPTOR)
# define BIO_TYPE_ASN1           (22|BIO_TYPE_FILTER)
# define BIO_TYPE_COMP           (23|BIO_TYPE_FILTER)
# ifndef OPENSSL_NO_SCTP
#  define BIO_TYPE_DGRAM_SCTP    (24|BIO_TYPE_SOURCE_SINK|BIO_TYPE_DESCRIPTOR)
# endif
# define BIO_TYPE_CORE_TO_PROV   (25|BIO_TYPE_SOURCE_SINK)

#define BIO_TYPE_START           128

/*
 * BIO_FILENAME_READ|BIO_CLOSE to open or close on free.
 * BIO_set_fp(in,stdin,BIO_NOCLOSE);
 */
# define BIO_NOCLOSE             0x00
# define BIO_CLOSE               0x01

/*
 * These are used in the following macros and are passed to BIO_ctrl()
 */
# define BIO_CTRL_RESET          1/* opt - rewind/zero etc */
# define BIO_CTRL_EOF            2/* opt - are we at the eof */
# define BIO_CTRL_INFO           3/* opt - extra tit-bits */
# define BIO_CTRL_SET            4/* man - set the 'IO' type */
# define BIO_CTRL_GET            5/* man - get the 'IO' type */
# define BIO_CTRL_PUSH           6/* opt - internal, used to signify change */
# define BIO_CTRL_POP            7/* opt - internal, used to signify change */
# define BIO_CTRL_GET_CLOSE      8/* man - set the 'close' on free */
# define BIO_CTRL_SET_CLOSE      9/* man - set the 'close' on free */
# define BIO_CTRL_PENDING        10/* opt - is their more data buffered */
# define BIO_CTRL_FLUSH          11/* opt - 'flush' buffered output */
# define BIO_CTRL_DUP            12/* man - extra stuff for 'duped' BIO */
# define BIO_CTRL_WPENDING       13/* opt - number of bytes still to write */
# define BIO_CTRL_SET_CALLBACK   14/* opt - set callback function */
# define BIO_CTRL_GET_CALLBACK   15/* opt - set callback function */

# define BIO_CTRL_PEEK           29/* BIO_f_buffer special */
# define BIO_CTRL_SET_FILENAME   30/* BIO_s_file special */

/* dgram BIO stuff */
# define BIO_CTRL_DGRAM_CONNECT       31/* BIO dgram special */
# define BIO_CTRL_DGRAM_SET_CONNECTED 32/* allow for an externally connected
                                         * socket to be passed in */
# define BIO_CTRL_DGRAM_SET_RECV_TIMEOUT 33/* setsockopt, essentially */
# define BIO_CTRL_DGRAM_GET_RECV_TIMEOUT 34/* getsockopt, essentially */
# define BIO_CTRL_DGRAM_SET_SEND_TIMEOUT 35/* setsockopt, essentially */
# define BIO_CTRL_DGRAM_GET_SEND_TIMEOUT 36/* getsockopt, essentially */

# define BIO_CTRL_DGRAM_GET_RECV_TIMER_EXP 37/* flag whether the last */
# define BIO_CTRL_DGRAM_GET_SEND_TIMER_EXP 38/* I/O operation timed out */

/* #ifdef IP_MTU_DISCOVER */
# define BIO_CTRL_DGRAM_MTU_DISCOVER       39/* set DF bit on egress packets */
/* #endif */

# define BIO_CTRL_DGRAM_QUERY_MTU          40/* as kernel for current MTU */
# define BIO_CTRL_DGRAM_GET_FALLBACK_MTU   47
# define BIO_CTRL_DGRAM_GET_MTU            41/* get cached value for MTU */
# define BIO_CTRL_DGRAM_SET_MTU            42/* set cached value for MTU.
                                              * want to use this if asking
                                              * the kernel fails */

# define BIO_CTRL_DGRAM_MTU_EXCEEDED       43/* check whether the MTU was
                                              * exceed in the previous write
                                              * operation */

# define BIO_CTRL_DGRAM_GET_PEER           46
# define BIO_CTRL_DGRAM_SET_PEER           44/* Destination for the data */

# define BIO_CTRL_DGRAM_SET_NEXT_TIMEOUT   45/* Next DTLS handshake timeout
                                              * to adjust socket timeouts */
# define BIO_CTRL_DGRAM_SET_DONT_FRAG      48

# define BIO_CTRL_DGRAM_GET_MTU_OVERHEAD   49

/* Deliberately outside of OPENSSL_NO_SCTP - used in bss_dgram.c */
#  define BIO_CTRL_DGRAM_SCTP_SET_IN_HANDSHAKE    50
# ifndef OPENSSL_NO_SCTP
/* SCTP stuff */
#  define BIO_CTRL_DGRAM_SCTP_ADD_AUTH_KEY                51
#  define BIO_CTRL_DGRAM_SCTP_NEXT_AUTH_KEY               52
#  define BIO_CTRL_DGRAM_SCTP_AUTH_CCS_RCVD               53
#  define BIO_CTRL_DGRAM_SCTP_GET_SNDINFO         60
#  define BIO_CTRL_DGRAM_SCTP_SET_SNDINFO         61
#  define BIO_CTRL_DGRAM_SCTP_GET_RCVINFO         62
#  define BIO_CTRL_DGRAM_SCTP_SET_RCVINFO         63
#  define BIO_CTRL_DGRAM_SCTP_GET_PRINFO                  64
#  define BIO_CTRL_DGRAM_SCTP_SET_PRINFO                  65
#  define BIO_CTRL_DGRAM_SCTP_SAVE_SHUTDOWN               70
# endif

# define BIO_CTRL_DGRAM_SET_PEEK_MODE      71

/*
 * internal BIO:
 * # define BIO_CTRL_SET_KTLS_SEND                 72
 * # define BIO_CTRL_SET_KTLS_SEND_CTRL_MSG        74
 * # define BIO_CTRL_CLEAR_KTLS_CTRL_MSG           75
 */

# define BIO_CTRL_GET_KTLS_SEND                 73
# define BIO_CTRL_GET_KTLS_RECV                 76

# define BIO_CTRL_DGRAM_SCTP_WAIT_FOR_DRY       77
# define BIO_CTRL_DGRAM_SCTP_MSG_WAITING        78

/* BIO_f_prefix controls */
# define BIO_CTRL_SET_PREFIX                    79
# define BIO_CTRL_SET_INDENT                    80
# define BIO_CTRL_GET_INDENT                    81

# ifndef OPENSSL_NO_KTLS
#  define BIO_get_ktls_send(b)         \
     (BIO_ctrl(b, BIO_CTRL_GET_KTLS_SEND, 0, NULL) > 0)
#  define BIO_get_ktls_recv(b)         \
     (BIO_ctrl(b, BIO_CTRL_GET_KTLS_RECV, 0, NULL) > 0)
# else
#  define BIO_get_ktls_send(b)  (0)
#  define BIO_get_ktls_recv(b)  (0)
# endif

/* modifiers */
# define BIO_FP_READ             0x02
# define BIO_FP_WRITE            0x04
# define BIO_FP_APPEND           0x08
# define BIO_FP_TEXT             0x10

# define BIO_FLAGS_READ          0x01
# define BIO_FLAGS_WRITE         0x02
# define BIO_FLAGS_IO_SPECIAL    0x04
# define BIO_FLAGS_RWS (BIO_FLAGS_READ|BIO_FLAGS_WRITE|BIO_FLAGS_IO_SPECIAL)
# define BIO_FLAGS_SHOULD_RETRY  0x08
# ifndef OPENSSL_NO_DEPRECATED_3_0
/* This #define was replaced by an internal constant and should not be used. */
#  define BIO_FLAGS_UPLINK       0
# endif

# define BIO_FLAGS_BASE64_NO_NL  0x100

/*
 * This is used with memory BIOs:
 * BIO_FLAGS_MEM_RDONLY means we shouldn't free up or change the data in any way;
 * BIO_FLAGS_NONCLEAR_RST means we shouldn't clear data on reset.
 */
# define BIO_FLAGS_MEM_RDONLY    0x200
# define BIO_FLAGS_NONCLEAR_RST  0x400
# define BIO_FLAGS_IN_EOF        0x800

/* the BIO FLAGS values 0x1000 to 0x4000 are reserved for internal KTLS flags */

typedef union bio_addr_st BIO_ADDR;
typedef struct bio_addrinfo_st BIO_ADDRINFO;

int BIO_get_new_index(void);
void BIO_set_flags(BIO *b, int flags);
int BIO_test_flags(const BIO *b, int flags);
void BIO_clear_flags(BIO *b, int flags);

# define BIO_get_flags(b) BIO_test_flags(b, ~(0x0))
# define BIO_set_retry_special(b) \
                BIO_set_flags(b, (BIO_FLAGS_IO_SPECIAL|BIO_FLAGS_SHOULD_RETRY))
# define BIO_set_retry_read(b) \
                BIO_set_flags(b, (BIO_FLAGS_READ|BIO_FLAGS_SHOULD_RETRY))
# define BIO_set_retry_write(b) \
                BIO_set_flags(b, (BIO_FLAGS_WRITE|BIO_FLAGS_SHOULD_RETRY))

/* These are normally used internally in BIOs */
# define BIO_clear_retry_flags(b) \
                BIO_clear_flags(b, (BIO_FLAGS_RWS|BIO_FLAGS_SHOULD_RETRY))
# define BIO_get_retry_flags(b) \
                BIO_test_flags(b, (BIO_FLAGS_RWS|BIO_FLAGS_SHOULD_RETRY))

/* These should be used by the application to tell why we should retry */
# define BIO_should_read(a)              BIO_test_flags(a, BIO_FLAGS_READ)
# define BIO_should_write(a)             BIO_test_flags(a, BIO_FLAGS_WRITE)
# define BIO_should_io_special(a)        BIO_test_flags(a, BIO_FLAGS_IO_SPECIAL)
# define BIO_retry_type(a)               BIO_test_flags(a, BIO_FLAGS_RWS)
# define BIO_should_retry(a)             BIO_test_flags(a, BIO_FLAGS_SHOULD_RETRY)

/*
 * The next three are used in conjunction with the BIO_should_io_special()
 * condition.  After this returns true, BIO *BIO_get_retry_BIO(BIO *bio, int
 * *reason); will walk the BIO stack and return the 'reason' for the special
 * and the offending BIO. Given a BIO, BIO_get_retry_reason(bio) will return
 * the code.
 */
/*
 * Returned from the SSL bio when the certificate retrieval code had an error
 */
# define BIO_RR_SSL_X509_LOOKUP          0x01
/* Returned from the connect BIO when a connect would have blocked */
# define BIO_RR_CONNECT                  0x02
/* Returned from the accept BIO when an accept would have blocked */
# define BIO_RR_ACCEPT                   0x03

/* These are passed by the BIO callback */
# define BIO_CB_FREE     0x01
# define BIO_CB_READ     0x02
# define BIO_CB_WRITE    0x03
# define BIO_CB_PUTS     0x04
# define BIO_CB_GETS     0x05
# define BIO_CB_CTRL     0x06

/*
 * The callback is called before and after the underling operation, The
 * BIO_CB_RETURN flag indicates if it is after the call
 */
# define BIO_CB_RETURN   0x80
# define BIO_CB_return(a) ((a)|BIO_CB_RETURN)
# define BIO_cb_pre(a)   (!((a)&BIO_CB_RETURN))
# define BIO_cb_post(a)  ((a)&BIO_CB_RETURN)

# ifndef OPENSSL_NO_DEPRECATED_3_0
typedef long (*BIO_callback_fn)(BIO *b, int oper, const char *argp, int argi,
                                long argl, long ret);
OSSL_DEPRECATEDIN_3_0 BIO_callback_fn BIO_get_callback(const BIO *b);
OSSL_DEPRECATEDIN_3_0 void BIO_set_callback(BIO *b, BIO_callback_fn callback);
OSSL_DEPRECATEDIN_3_0 long BIO_debug_callback(BIO *bio, int cmd,
                                               const char *argp, int argi,
                                               long argl, long ret);
# endif

typedef long (*BIO_callback_fn_ex)(BIO *b, int oper, const char *argp,
                                   size_t len, int argi,
                                   long argl, int ret, size_t *processed);
BIO_callback_fn_ex BIO_get_callback_ex(const BIO *b);
void BIO_set_callback_ex(BIO *b, BIO_callback_fn_ex callback);
long BIO_debug_callback_ex(BIO *bio, int oper, const char *argp, size_t len,
                           int argi, long argl, int ret, size_t *processed);

char *BIO_get_callback_arg(const BIO *b);
void BIO_set_callback_arg(BIO *b, char *arg);

typedef struct bio_method_st BIO_METHOD;

const char *BIO_method_name(const BIO *b);
int BIO_method_type(const BIO *b);

typedef int BIO_info_cb(BIO *, int, int);
typedef BIO_info_cb bio_info_cb;  /* backward compatibility */

SKM_DEFINE_STACK_OF_INTERNAL(BIO, BIO, BIO)
#define sk_BIO_num(sk) OPENSSL_sk_num(ossl_check_const_BIO_sk_type(sk))
#define sk_BIO_value(sk, idx) ((BIO *)OPENSSL_sk_value(ossl_check_const_BIO_sk_type(sk), (idx)))
#define sk_BIO_new(cmp) ((STACK_OF(BIO) *)OPENSSL_sk_new(ossl_check_BIO_compfunc_type(cmp)))
#define sk_BIO_new_null() ((STACK_OF(BIO) *)OPENSSL_sk_new_null())
#define sk_BIO_new_reserve(cmp, n) ((STACK_OF(BIO) *)OPENSSL_sk_new_reserve(ossl_check_BIO_compfunc_type(cmp), (n)))
#define sk_BIO_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_BIO_sk_type(sk), (n))
#define sk_BIO_free(sk) OPENSSL_sk_free(ossl_check_BIO_sk_type(sk))
#define sk_BIO_zero(sk) OPENSSL_sk_zero(ossl_check_BIO_sk_type(sk))
#define sk_BIO_delete(sk, i) ((BIO *)OPENSSL_sk_delete(ossl_check_BIO_sk_type(sk), (i)))
#define sk_BIO_delete_ptr(sk, ptr) ((BIO *)OPENSSL_sk_delete_ptr(ossl_check_BIO_sk_type(sk), ossl_check_BIO_type(ptr)))
#define sk_BIO_push(sk, ptr) OPENSSL_sk_push(ossl_check_BIO_sk_type(sk), ossl_check_BIO_type(ptr))
#define sk_BIO_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_BIO_sk_type(sk), ossl_check_BIO_type(ptr))
#define sk_BIO_pop(sk) ((BIO *)OPENSSL_sk_pop(ossl_check_BIO_sk_type(sk)))
#define sk_BIO_shift(sk) ((BIO *)OPENSSL_sk_shift(ossl_check_BIO_sk_type(sk)))
#define sk_BIO_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_BIO_sk_type(sk),ossl_check_BIO_freefunc_type(freefunc))
#define sk_BIO_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_BIO_sk_type(sk), ossl_check_BIO_type(ptr), (idx))
#define sk_BIO_set(sk, idx, ptr) ((BIO *)OPENSSL_sk_set(ossl_check_BIO_sk_type(sk), (idx), ossl_check_BIO_type(ptr)))
#define sk_BIO_find(sk, ptr) OPENSSL_sk_find(ossl_check_BIO_sk_type(sk), ossl_check_BIO_type(ptr))
#define sk_BIO_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_BIO_sk_type(sk), ossl_check_BIO_type(ptr))
#define sk_BIO_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_BIO_sk_type(sk), ossl_check_BIO_type(ptr), pnum)
#define sk_BIO_sort(sk) OPENSSL_sk_sort(ossl_check_BIO_sk_type(sk))
#define sk_BIO_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_BIO_sk_type(sk))
#define sk_BIO_dup(sk) ((STACK_OF(BIO) *)OPENSSL_sk_dup(ossl_check_const_BIO_sk_type(sk)))
#define sk_BIO_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(BIO) *)OPENSSL_sk_deep_copy(ossl_check_const_BIO_sk_type(sk), ossl_check_BIO_copyfunc_type(copyfunc), ossl_check_BIO_freefunc_type(freefunc)))
#define sk_BIO_set_cmp_func(sk, cmp) ((sk_BIO_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_BIO_sk_type(sk), ossl_check_BIO_compfunc_type(cmp)))



/* Prefix and suffix callback in ASN1 BIO */
typedef int asn1_ps_func (BIO *b, unsigned char **pbuf, int *plen,
                          void *parg);

typedef void (*BIO_dgram_sctp_notification_handler_fn) (BIO *b,
                                                        void *context,
                                                        void *buf);
# ifndef OPENSSL_NO_SCTP
/* SCTP parameter structs */
struct bio_dgram_sctp_sndinfo {
    uint16_t snd_sid;
    uint16_t snd_flags;
    uint32_t snd_ppid;
    uint32_t snd_context;
};

struct bio_dgram_sctp_rcvinfo {
    uint16_t rcv_sid;
    uint16_t rcv_ssn;
    uint16_t rcv_flags;
    uint32_t rcv_ppid;
    uint32_t rcv_tsn;
    uint32_t rcv_cumtsn;
    uint32_t rcv_context;
};

struct bio_dgram_sctp_prinfo {
    uint16_t pr_policy;
    uint32_t pr_value;
};
# endif

/*
 * #define BIO_CONN_get_param_hostname BIO_ctrl
 */

# define BIO_C_SET_CONNECT                       100
# define BIO_C_DO_STATE_MACHINE                  101
# define BIO_C_SET_NBIO                          102
/* # define BIO_C_SET_PROXY_PARAM                   103 */
# define BIO_C_SET_FD                            104
# define BIO_C_GET_FD                            105
# define BIO_C_SET_FILE_PTR                      106
# define BIO_C_GET_FILE_PTR                      107
# define BIO_C_SET_FILENAME                      108
# define BIO_C_SET_SSL                           109
# define BIO_C_GET_SSL                           110
# define BIO_C_SET_MD                            111
# define BIO_C_GET_MD                            112
# define BIO_C_GET_CIPHER_STATUS                 113
# define BIO_C_SET_BUF_MEM                       114
# define BIO_C_GET_BUF_MEM_PTR                   115
# define BIO_C_GET_BUFF_NUM_LINES                116
# define BIO_C_SET_BUFF_SIZE                     117
# define BIO_C_SET_ACCEPT                        118
# define BIO_C_SSL_MODE                          119
# define BIO_C_GET_MD_CTX                        120
/* # define BIO_C_GET_PROXY_PARAM                   121 */
# define BIO_C_SET_BUFF_READ_DATA                122/* data to read first */
# define BIO_C_GET_CONNECT                       123
# define BIO_C_GET_ACCEPT                        124
# define BIO_C_SET_SSL_RENEGOTIATE_BYTES         125
# define BIO_C_GET_SSL_NUM_RENEGOTIATES          126
# define BIO_C_SET_SSL_RENEGOTIATE_TIMEOUT       127
# define BIO_C_FILE_SEEK                         128
# define BIO_C_GET_CIPHER_CTX                    129
# define BIO_C_SET_BUF_MEM_EOF_RETURN            130/* return end of input
                                                     * value */
# define BIO_C_SET_BIND_MODE                     131
# define BIO_C_GET_BIND_MODE                     132
# define BIO_C_FILE_TELL                         133
# define BIO_C_GET_SOCKS                         134
# define BIO_C_SET_SOCKS                         135

# define BIO_C_SET_WRITE_BUF_SIZE                136/* for BIO_s_bio */
# define BIO_C_GET_WRITE_BUF_SIZE                137
# define BIO_C_MAKE_BIO_PAIR                     138
# define BIO_C_DESTROY_BIO_PAIR                  139
# define BIO_C_GET_WRITE_GUARANTEE               140
# define BIO_C_GET_READ_REQUEST                  141
# define BIO_C_SHUTDOWN_WR                       142
# define BIO_C_NREAD0                            143
# define BIO_C_NREAD                             144
# define BIO_C_NWRITE0                           145
# define BIO_C_NWRITE                            146
# define BIO_C_RESET_READ_REQUEST                147
# define BIO_C_SET_MD_CTX                        148

# define BIO_C_SET_PREFIX                        149
# define BIO_C_GET_PREFIX                        150
# define BIO_C_SET_SUFFIX                        151
# define BIO_C_GET_SUFFIX                        152

# define BIO_C_SET_EX_ARG                        153
# define BIO_C_GET_EX_ARG                        154

# define BIO_C_SET_CONNECT_MODE                  155

# define BIO_set_app_data(s,arg)         BIO_set_ex_data(s,0,arg)
# define BIO_get_app_data(s)             BIO_get_ex_data(s,0)

# define BIO_set_nbio(b,n)             BIO_ctrl(b,BIO_C_SET_NBIO,(n),NULL)

# ifndef OPENSSL_NO_SOCK
/* IP families we support, for BIO_s_connect() and BIO_s_accept() */
/* Note: the underlying operating system may not support some of them */
#  define BIO_FAMILY_IPV4                         4
#  define BIO_FAMILY_IPV6                         6
#  define BIO_FAMILY_IPANY                        256

/* BIO_s_connect() */
#  define BIO_set_conn_hostname(b,name) BIO_ctrl(b,BIO_C_SET_CONNECT,0, \
                                                 (char *)(name))
#  define BIO_set_conn_port(b,port)     BIO_ctrl(b,BIO_C_SET_CONNECT,1, \
                                                 (char *)(port))
#  define BIO_set_conn_address(b,addr)  BIO_ctrl(b,BIO_C_SET_CONNECT,2, \
                                                 (char *)(addr))
#  define BIO_set_conn_ip_family(b,f)   BIO_int_ctrl(b,BIO_C_SET_CONNECT,3,f)
#  define BIO_get_conn_hostname(b)      ((const char *)BIO_ptr_ctrl(b,BIO_C_GET_CONNECT,0))
#  define BIO_get_conn_port(b)          ((const char *)BIO_ptr_ctrl(b,BIO_C_GET_CONNECT,1))
#  define BIO_get_conn_address(b)       ((const BIO_ADDR *)BIO_ptr_ctrl(b,BIO_C_GET_CONNECT,2))
#  define BIO_get_conn_ip_family(b)     BIO_ctrl(b,BIO_C_GET_CONNECT,3,NULL)
#  define BIO_set_conn_mode(b,n)        BIO_ctrl(b,BIO_C_SET_CONNECT_MODE,(n),NULL)

/* BIO_s_accept() */
#  define BIO_set_accept_name(b,name)   BIO_ctrl(b,BIO_C_SET_ACCEPT,0, \
                                                 (char *)(name))
#  define BIO_set_accept_port(b,port)   BIO_ctrl(b,BIO_C_SET_ACCEPT,1, \
                                                 (char *)(port))
#  define BIO_get_accept_name(b)        ((const char *)BIO_ptr_ctrl(b,BIO_C_GET_ACCEPT,0))
#  define BIO_get_accept_port(b)        ((const char *)BIO_ptr_ctrl(b,BIO_C_GET_ACCEPT,1))
#  define BIO_get_peer_name(b)          ((const char *)BIO_ptr_ctrl(b,BIO_C_GET_ACCEPT,2))
#  define BIO_get_peer_port(b)          ((const char *)BIO_ptr_ctrl(b,BIO_C_GET_ACCEPT,3))
/* #define BIO_set_nbio(b,n)    BIO_ctrl(b,BIO_C_SET_NBIO,(n),NULL) */
#  define BIO_set_nbio_accept(b,n)      BIO_ctrl(b,BIO_C_SET_ACCEPT,2,(n)?(void *)"a":NULL)
#  define BIO_set_accept_bios(b,bio)    BIO_ctrl(b,BIO_C_SET_ACCEPT,3, \
                                                 (char *)(bio))
#  define BIO_set_accept_ip_family(b,f) BIO_int_ctrl(b,BIO_C_SET_ACCEPT,4,f)
#  define BIO_get_accept_ip_family(b)   BIO_ctrl(b,BIO_C_GET_ACCEPT,4,NULL)

/* Aliases kept for backward compatibility */
#  define BIO_BIND_NORMAL                 0
#  define BIO_BIND_REUSEADDR              BIO_SOCK_REUSEADDR
#  define BIO_BIND_REUSEADDR_IF_UNUSED    BIO_SOCK_REUSEADDR
#  define BIO_set_bind_mode(b,mode) BIO_ctrl(b,BIO_C_SET_BIND_MODE,mode,NULL)
#  define BIO_get_bind_mode(b)    BIO_ctrl(b,BIO_C_GET_BIND_MODE,0,NULL)
# endif /* OPENSSL_NO_SOCK */

# define BIO_do_connect(b)       BIO_do_handshake(b)
# define BIO_do_accept(b)        BIO_do_handshake(b)

# define BIO_do_handshake(b)     BIO_ctrl(b,BIO_C_DO_STATE_MACHINE,0,NULL)

/* BIO_s_datagram(), BIO_s_fd(), BIO_s_socket(), BIO_s_accept() and BIO_s_connect() */
# define BIO_set_fd(b,fd,c)      BIO_int_ctrl(b,BIO_C_SET_FD,c,fd)
# define BIO_get_fd(b,c)         BIO_ctrl(b,BIO_C_GET_FD,0,(char *)(c))

/* BIO_s_file() */
# define BIO_set_fp(b,fp,c)      BIO_ctrl(b,BIO_C_SET_FILE_PTR,c,(char *)(fp))
# define BIO_get_fp(b,fpp)       BIO_ctrl(b,BIO_C_GET_FILE_PTR,0,(char *)(fpp))

/* BIO_s_fd() and BIO_s_file() */
# define BIO_seek(b,ofs) (int)BIO_ctrl(b,BIO_C_FILE_SEEK,ofs,NULL)
# define BIO_tell(b)     (int)BIO_ctrl(b,BIO_C_FILE_TELL,0,NULL)

/*
 * name is cast to lose const, but might be better to route through a
 * function so we can do it safely
 */
# ifdef CONST_STRICT
/*
 * If you are wondering why this isn't defined, its because CONST_STRICT is
 * purely a compile-time kludge to allow const to be checked.
 */
int BIO_read_filename(BIO *b, const char *name);
# else
#  define BIO_read_filename(b,name) (int)BIO_ctrl(b,BIO_C_SET_FILENAME, \
                BIO_CLOSE|BIO_FP_READ,(char *)(name))
# endif
# define BIO_write_filename(b,name) (int)BIO_ctrl(b,BIO_C_SET_FILENAME, \
                BIO_CLOSE|BIO_FP_WRITE,name)
# define BIO_append_filename(b,name) (int)BIO_ctrl(b,BIO_C_SET_FILENAME, \
                BIO_CLOSE|BIO_FP_APPEND,name)
# define BIO_rw_filename(b,name) (int)BIO_ctrl(b,BIO_C_SET_FILENAME, \
                BIO_CLOSE|BIO_FP_READ|BIO_FP_WRITE,name)

/*
 * WARNING WARNING, this ups the reference count on the read bio of the SSL
 * structure.  This is because the ssl read BIO is now pointed to by the
 * next_bio field in the bio.  So when you free the BIO, make sure you are
 * doing a BIO_free_all() to catch the underlying BIO.
 */
# define BIO_set_ssl(b,ssl,c)    BIO_ctrl(b,BIO_C_SET_SSL,c,(char *)(ssl))
# define BIO_get_ssl(b,sslp)     BIO_ctrl(b,BIO_C_GET_SSL,0,(char *)(sslp))
# define BIO_set_ssl_mode(b,client)      BIO_ctrl(b,BIO_C_SSL_MODE,client,NULL)
# define BIO_set_ssl_renegotiate_bytes(b,num) \
        BIO_ctrl(b,BIO_C_SET_SSL_RENEGOTIATE_BYTES,num,NULL)
# define BIO_get_num_renegotiates(b) \
        BIO_ctrl(b,BIO_C_GET_SSL_NUM_RENEGOTIATES,0,NULL)
# define BIO_set_ssl_renegotiate_timeout(b,seconds) \
        BIO_ctrl(b,BIO_C_SET_SSL_RENEGOTIATE_TIMEOUT,seconds,NULL)

/* defined in evp.h */
/* #define BIO_set_md(b,md)     BIO_ctrl(b,BIO_C_SET_MD,1,(char *)(md)) */

# define BIO_get_mem_data(b,pp)  BIO_ctrl(b,BIO_CTRL_INFO,0,(char *)(pp))
# define BIO_set_mem_buf(b,bm,c) BIO_ctrl(b,BIO_C_SET_BUF_MEM,c,(char *)(bm))
# define BIO_get_mem_ptr(b,pp)   BIO_ctrl(b,BIO_C_GET_BUF_MEM_PTR,0, \
                                          (char *)(pp))
# define BIO_set_mem_eof_return(b,v) \
                                BIO_ctrl(b,BIO_C_SET_BUF_MEM_EOF_RETURN,v,NULL)

/* For the BIO_f_buffer() type */
# define BIO_get_buffer_num_lines(b)     BIO_ctrl(b,BIO_C_GET_BUFF_NUM_LINES,0,NULL)
# define BIO_set_buffer_size(b,size)     BIO_ctrl(b,BIO_C_SET_BUFF_SIZE,size,NULL)
# define BIO_set_read_buffer_size(b,size) BIO_int_ctrl(b,BIO_C_SET_BUFF_SIZE,size,0)
# define BIO_set_write_buffer_size(b,size) BIO_int_ctrl(b,BIO_C_SET_BUFF_SIZE,size,1)
# define BIO_set_buffer_read_data(b,buf,num) BIO_ctrl(b,BIO_C_SET_BUFF_READ_DATA,num,buf)

/* Don't use the next one unless you know what you are doing :-) */
# define BIO_dup_state(b,ret)    BIO_ctrl(b,BIO_CTRL_DUP,0,(char *)(ret))

# define BIO_reset(b)            (int)BIO_ctrl(b,BIO_CTRL_RESET,0,NULL)
# define BIO_eof(b)              (int)BIO_ctrl(b,BIO_CTRL_EOF,0,NULL)
# define BIO_set_close(b,c)      (int)BIO_ctrl(b,BIO_CTRL_SET_CLOSE,(c),NULL)
# define BIO_get_close(b)        (int)BIO_ctrl(b,BIO_CTRL_GET_CLOSE,0,NULL)
# define BIO_pending(b)          (int)BIO_ctrl(b,BIO_CTRL_PENDING,0,NULL)
# define BIO_wpending(b)         (int)BIO_ctrl(b,BIO_CTRL_WPENDING,0,NULL)
/* ...pending macros have inappropriate return type */
size_t BIO_ctrl_pending(BIO *b);
size_t BIO_ctrl_wpending(BIO *b);
# define BIO_flush(b)            (int)BIO_ctrl(b,BIO_CTRL_FLUSH,0,NULL)
# define BIO_get_info_callback(b,cbp) (int)BIO_ctrl(b,BIO_CTRL_GET_CALLBACK,0, \
                                                   cbp)
# define BIO_set_info_callback(b,cb) (int)BIO_callback_ctrl(b,BIO_CTRL_SET_CALLBACK,cb)

/* For the BIO_f_buffer() type */
# define BIO_buffer_get_num_lines(b) BIO_ctrl(b,BIO_CTRL_GET,0,NULL)
# define BIO_buffer_peek(b,s,l) BIO_ctrl(b,BIO_CTRL_PEEK,(l),(s))

/* For BIO_s_bio() */
# define BIO_set_write_buf_size(b,size) (int)BIO_ctrl(b,BIO_C_SET_WRITE_BUF_SIZE,size,NULL)
# define BIO_get_write_buf_size(b,size) (size_t)BIO_ctrl(b,BIO_C_GET_WRITE_BUF_SIZE,size,NULL)
# define BIO_make_bio_pair(b1,b2)   (int)BIO_ctrl(b1,BIO_C_MAKE_BIO_PAIR,0,b2)
# define BIO_destroy_bio_pair(b)    (int)BIO_ctrl(b,BIO_C_DESTROY_BIO_PAIR,0,NULL)
# define BIO_shutdown_wr(b) (int)BIO_ctrl(b, BIO_C_SHUTDOWN_WR, 0, NULL)
/* macros with inappropriate type -- but ...pending macros use int too: */
# define BIO_get_write_guarantee(b) (int)BIO_ctrl(b,BIO_C_GET_WRITE_GUARANTEE,0,NULL)
# define BIO_get_read_request(b)    (int)BIO_ctrl(b,BIO_C_GET_READ_REQUEST,0,NULL)
size_t BIO_ctrl_get_write_guarantee(BIO *b);
size_t BIO_ctrl_get_read_request(BIO *b);
int BIO_ctrl_reset_read_request(BIO *b);

/* ctrl macros for dgram */
# define BIO_ctrl_dgram_connect(b,peer)  \
                     (int)BIO_ctrl(b,BIO_CTRL_DGRAM_CONNECT,0, (char *)(peer))
# define BIO_ctrl_set_connected(b,peer) \
         (int)BIO_ctrl(b, BIO_CTRL_DGRAM_SET_CONNECTED, 0, (char *)(peer))
# define BIO_dgram_recv_timedout(b) \
         (int)BIO_ctrl(b, BIO_CTRL_DGRAM_GET_RECV_TIMER_EXP, 0, NULL)
# define BIO_dgram_send_timedout(b) \
         (int)BIO_ctrl(b, BIO_CTRL_DGRAM_GET_SEND_TIMER_EXP, 0, NULL)
# define BIO_dgram_get_peer(b,peer) \
         (int)BIO_ctrl(b, BIO_CTRL_DGRAM_GET_PEER, 0, (char *)(peer))
# define BIO_dgram_set_peer(b,peer) \
         (int)BIO_ctrl(b, BIO_CTRL_DGRAM_SET_PEER, 0, (char *)(peer))
# define BIO_dgram_get_mtu_overhead(b) \
         (unsigned int)BIO_ctrl((b), BIO_CTRL_DGRAM_GET_MTU_OVERHEAD, 0, NULL)

/* ctrl macros for BIO_f_prefix */
# define BIO_set_prefix(b,p) BIO_ctrl((b), BIO_CTRL_SET_PREFIX, 0, (void *)(p))
# define BIO_set_indent(b,i) BIO_ctrl((b), BIO_CTRL_SET_INDENT, (i), NULL)
# define BIO_get_indent(b) BIO_ctrl((b), BIO_CTRL_GET_INDENT, 0, NULL)

#define BIO_get_ex_new_index(l, p, newf, dupf, freef) \
    CRYPTO_get_ex_new_index(CRYPTO_EX_INDEX_BIO, l, p, newf, dupf, freef)
int BIO_set_ex_data(BIO *bio, int idx, void *data);
void *BIO_get_ex_data(const BIO *bio, int idx);
uint64_t BIO_number_read(BIO *bio);
uint64_t BIO_number_written(BIO *bio);

/* For BIO_f_asn1() */
int BIO_asn1_set_prefix(BIO *b, asn1_ps_func *prefix,
                        asn1_ps_func *prefix_free);
int BIO_asn1_get_prefix(BIO *b, asn1_ps_func **pprefix,
                        asn1_ps_func **pprefix_free);
int BIO_asn1_set_suffix(BIO *b, asn1_ps_func *suffix,
                        asn1_ps_func *suffix_free);
int BIO_asn1_get_suffix(BIO *b, asn1_ps_func **psuffix,
                        asn1_ps_func **psuffix_free);

const BIO_METHOD *BIO_s_file(void);
BIO *BIO_new_file(const char *filename, const char *mode);
BIO *BIO_new_from_core_bio(OSSL_LIB_CTX *libctx, OSSL_CORE_BIO *corebio);
# ifndef OPENSSL_NO_STDIO
BIO *BIO_new_fp(FILE *stream, int close_flag);
# endif
BIO *BIO_new_ex(OSSL_LIB_CTX *libctx, const BIO_METHOD *method);
BIO *BIO_new(const BIO_METHOD *type);
int BIO_free(BIO *a);
void BIO_set_data(BIO *a, void *ptr);
void *BIO_get_data(BIO *a);
void BIO_set_init(BIO *a, int init);
int BIO_get_init(BIO *a);
void BIO_set_shutdown(BIO *a, int shut);
int BIO_get_shutdown(BIO *a);
void BIO_vfree(BIO *a);
int BIO_up_ref(BIO *a);
int BIO_read(BIO *b, void *data, int dlen);
int BIO_read_ex(BIO *b, void *data, size_t dlen, size_t *readbytes);
int BIO_gets(BIO *bp, char *buf, int size);
int BIO_get_line(BIO *bio, char *buf, int size);
int BIO_write(BIO *b, const void *data, int dlen);
int BIO_write_ex(BIO *b, const void *data, size_t dlen, size_t *written);
int BIO_puts(BIO *bp, const char *buf);
int BIO_indent(BIO *b, int indent, int max);
long BIO_ctrl(BIO *bp, int cmd, long larg, void *parg);
long BIO_callback_ctrl(BIO *b, int cmd, BIO_info_cb *fp);
void *BIO_ptr_ctrl(BIO *bp, int cmd, long larg);
long BIO_int_ctrl(BIO *bp, int cmd, long larg, int iarg);
BIO *BIO_push(BIO *b, BIO *append);
BIO *BIO_pop(BIO *b);
void BIO_free_all(BIO *a);
BIO *BIO_find_type(BIO *b, int bio_type);
BIO *BIO_next(BIO *b);
void BIO_set_next(BIO *b, BIO *next);
BIO *BIO_get_retry_BIO(BIO *bio, int *reason);
int BIO_get_retry_reason(BIO *bio);
void BIO_set_retry_reason(BIO *bio, int reason);
BIO *BIO_dup_chain(BIO *in);

int BIO_nread0(BIO *bio, char **buf);
int BIO_nread(BIO *bio, char **buf, int num);
int BIO_nwrite0(BIO *bio, char **buf);
int BIO_nwrite(BIO *bio, char **buf, int num);

const BIO_METHOD *BIO_s_mem(void);
const BIO_METHOD *BIO_s_secmem(void);
BIO *BIO_new_mem_buf(const void *buf, int len);
# ifndef OPENSSL_NO_SOCK
const BIO_METHOD *BIO_s_socket(void);
const BIO_METHOD *BIO_s_connect(void);
const BIO_METHOD *BIO_s_accept(void);
# endif
const BIO_METHOD *BIO_s_fd(void);
const BIO_METHOD *BIO_s_log(void);
const BIO_METHOD *BIO_s_bio(void);
const BIO_METHOD *BIO_s_null(void);
const BIO_METHOD *BIO_f_null(void);
const BIO_METHOD *BIO_f_buffer(void);
const BIO_METHOD *BIO_f_readbuffer(void);
const BIO_METHOD *BIO_f_linebuffer(void);
const BIO_METHOD *BIO_f_nbio_test(void);
const BIO_METHOD *BIO_f_prefix(void);
const BIO_METHOD *BIO_s_core(void);
# ifndef OPENSSL_NO_DGRAM
const BIO_METHOD *BIO_s_datagram(void);
int BIO_dgram_non_fatal_error(int error);
BIO *BIO_new_dgram(int fd, int close_flag);
#  ifndef OPENSSL_NO_SCTP
const BIO_METHOD *BIO_s_datagram_sctp(void);
BIO *BIO_new_dgram_sctp(int fd, int close_flag);
int BIO_dgram_is_sctp(BIO *bio);
int BIO_dgram_sctp_notification_cb(BIO *b,
                BIO_dgram_sctp_notification_handler_fn handle_notifications,
                void *context);
int BIO_dgram_sctp_wait_for_dry(BIO *b);
int BIO_dgram_sctp_msg_waiting(BIO *b);
#  endif
# endif

# ifndef OPENSSL_NO_SOCK
int BIO_sock_should_retry(int i);
int BIO_sock_non_fatal_error(int error);
int BIO_socket_wait(int fd, int for_read, time_t max_time);
# endif
int BIO_wait(BIO *bio, time_t max_time, unsigned int nap_milliseconds);
int BIO_do_connect_retry(BIO *bio, int timeout, int nap_milliseconds);

int BIO_fd_should_retry(int i);
int BIO_fd_non_fatal_error(int error);
int BIO_dump_cb(int (*cb) (const void *data, size_t len, void *u),
                void *u, const void *s, int len);
int BIO_dump_indent_cb(int (*cb) (const void *data, size_t len, void *u),
                       void *u, const void *s, int len, int indent);
int BIO_dump(BIO *b, const void *bytes, int len);
int BIO_dump_indent(BIO *b, const void *bytes, int len, int indent);
# ifndef OPENSSL_NO_STDIO
int BIO_dump_fp(FILE *fp, const void *s, int len);
int BIO_dump_indent_fp(FILE *fp, const void *s, int len, int indent);
# endif
int BIO_hex_string(BIO *out, int indent, int width, const void *data,
                   int datalen);

# ifndef OPENSSL_NO_SOCK
BIO_ADDR *BIO_ADDR_new(void);
int BIO_ADDR_rawmake(BIO_ADDR *ap, int family,
                     const void *where, size_t wherelen, unsigned short port);
void BIO_ADDR_free(BIO_ADDR *);
void BIO_ADDR_clear(BIO_ADDR *ap);
int BIO_ADDR_family(const BIO_ADDR *ap);
int BIO_ADDR_rawaddress(const BIO_ADDR *ap, void *p, size_t *l);
unsigned short BIO_ADDR_rawport(const BIO_ADDR *ap);
char *BIO_ADDR_hostname_string(const BIO_ADDR *ap, int numeric);
char *BIO_ADDR_service_string(const BIO_ADDR *ap, int numeric);
char *BIO_ADDR_path_string(const BIO_ADDR *ap);

const BIO_ADDRINFO *BIO_ADDRINFO_next(const BIO_ADDRINFO *bai);
int BIO_ADDRINFO_family(const BIO_ADDRINFO *bai);
int BIO_ADDRINFO_socktype(const BIO_ADDRINFO *bai);
int BIO_ADDRINFO_protocol(const BIO_ADDRINFO *bai);
const BIO_ADDR *BIO_ADDRINFO_address(const BIO_ADDRINFO *bai);
void BIO_ADDRINFO_free(BIO_ADDRINFO *bai);

enum BIO_hostserv_priorities {
    BIO_PARSE_PRIO_HOST, BIO_PARSE_PRIO_SERV
};
int BIO_parse_hostserv(const char *hostserv, char **host, char **service,
                       enum BIO_hostserv_priorities hostserv_prio);
enum BIO_lookup_type {
    BIO_LOOKUP_CLIENT, BIO_LOOKUP_SERVER
};
int BIO_lookup(const char *host, const char *service,
               enum BIO_lookup_type lookup_type,
               int family, int socktype, BIO_ADDRINFO **res);
int BIO_lookup_ex(const char *host, const char *service,
                  int lookup_type, int family, int socktype, int protocol,
                  BIO_ADDRINFO **res);
int BIO_sock_error(int sock);
int BIO_socket_ioctl(int fd, long type, void *arg);
int BIO_socket_nbio(int fd, int mode);
int BIO_sock_init(void);
# ifndef OPENSSL_NO_DEPRECATED_1_1_0
#  define BIO_sock_cleanup() while(0) continue
# endif
int BIO_set_tcp_ndelay(int sock, int turn_on);
# ifndef OPENSSL_NO_DEPRECATED_1_1_0
OSSL_DEPRECATEDIN_1_1_0 struct hostent *BIO_gethostbyname(const char *name);
OSSL_DEPRECATEDIN_1_1_0 int BIO_get_port(const char *str, unsigned short *port_ptr);
OSSL_DEPRECATEDIN_1_1_0 int BIO_get_host_ip(const char *str, unsigned char *ip);
OSSL_DEPRECATEDIN_1_1_0 int BIO_get_accept_socket(char *host_port, int mode);
OSSL_DEPRECATEDIN_1_1_0 int BIO_accept(int sock, char **ip_port);
# endif

union BIO_sock_info_u {
    BIO_ADDR *addr;
};
enum BIO_sock_info_type {
    BIO_SOCK_INFO_ADDRESS
};
int BIO_sock_info(int sock,
                  enum BIO_sock_info_type type, union BIO_sock_info_u *info);

#  define BIO_SOCK_REUSEADDR    0x01
#  define BIO_SOCK_V6_ONLY      0x02
#  define BIO_SOCK_KEEPALIVE    0x04
#  define BIO_SOCK_NONBLOCK     0x08
#  define BIO_SOCK_NODELAY      0x10

int BIO_socket(int domain, int socktype, int protocol, int options);
int BIO_connect(int sock, const BIO_ADDR *addr, int options);
int BIO_bind(int sock, const BIO_ADDR *addr, int options);
int BIO_listen(int sock, const BIO_ADDR *addr, int options);
int BIO_accept_ex(int accept_sock, BIO_ADDR *addr, int options);
int BIO_closesocket(int sock);

BIO *BIO_new_socket(int sock, int close_flag);
BIO *BIO_new_connect(const char *host_port);
BIO *BIO_new_accept(const char *host_port);
# endif /* OPENSSL_NO_SOCK*/

BIO *BIO_new_fd(int fd, int close_flag);

int BIO_new_bio_pair(BIO **bio1, size_t writebuf1,
                     BIO **bio2, size_t writebuf2);
/*
 * If successful, returns 1 and in *bio1, *bio2 two BIO pair endpoints.
 * Otherwise returns 0 and sets *bio1 and *bio2 to NULL. Size 0 uses default
 * value.
 */

void BIO_copy_next_retry(BIO *b);

/*
 * long BIO_ghbn_ctrl(int cmd,int iarg,char *parg);
 */

# define ossl_bio__attr__(x)
# if defined(__GNUC__) && defined(__STDC_VERSION__) \
    && !defined(__MINGW32__) && !defined(__MINGW64__) \
    && !defined(__APPLE__)
    /*
     * Because we support the 'z' modifier, which made its appearance in C99,
     * we can't use __attribute__ with pre C99 dialects.
     */
#  if __STDC_VERSION__ >= 199901L
#   undef ossl_bio__attr__
#   define ossl_bio__attr__ __attribute__
#   if __GNUC__*10 + __GNUC_MINOR__ >= 44
#    define ossl_bio__printf__ __gnu_printf__
#   else
#    define ossl_bio__printf__ __printf__
#   endif
#  endif
# endif
int BIO_printf(BIO *bio, const char *format, ...)
ossl_bio__attr__((__format__(ossl_bio__printf__, 2, 3)));
int BIO_vprintf(BIO *bio, const char *format, va_list args)
ossl_bio__attr__((__format__(ossl_bio__printf__, 2, 0)));
int BIO_snprintf(char *buf, size_t n, const char *format, ...)
ossl_bio__attr__((__format__(ossl_bio__printf__, 3, 4)));
int BIO_vsnprintf(char *buf, size_t n, const char *format, va_list args)
ossl_bio__attr__((__format__(ossl_bio__printf__, 3, 0)));
# undef ossl_bio__attr__
# undef ossl_bio__printf__


BIO_METHOD *BIO_meth_new(int type, const char *name);
void BIO_meth_free(BIO_METHOD *biom);
int (*BIO_meth_get_write(const BIO_METHOD *biom)) (BIO *, const char *, int);
int (*BIO_meth_get_write_ex(const BIO_METHOD *biom)) (BIO *, const char *, size_t,
                                                size_t *);
int BIO_meth_set_write(BIO_METHOD *biom,
                       int (*write) (BIO *, const char *, int));
int BIO_meth_set_write_ex(BIO_METHOD *biom,
                       int (*bwrite) (BIO *, const char *, size_t, size_t *));
int (*BIO_meth_get_read(const BIO_METHOD *biom)) (BIO *, char *, int);
int (*BIO_meth_get_read_ex(const BIO_METHOD *biom)) (BIO *, char *, size_t, size_t *);
int BIO_meth_set_read(BIO_METHOD *biom,
                      int (*read) (BIO *, char *, int));
int BIO_meth_set_read_ex(BIO_METHOD *biom,
                         int (*bread) (BIO *, char *, size_t, size_t *));
int (*BIO_meth_get_puts(const BIO_METHOD *biom)) (BIO *, const char *);
int BIO_meth_set_puts(BIO_METHOD *biom,
                      int (*puts) (BIO *, const char *));
int (*BIO_meth_get_gets(const BIO_METHOD *biom)) (BIO *, char *, int);
int BIO_meth_set_gets(BIO_METHOD *biom,
                      int (*ossl_gets) (BIO *, char *, int));
long (*BIO_meth_get_ctrl(const BIO_METHOD *biom)) (BIO *, int, long, void *);
int BIO_meth_set_ctrl(BIO_METHOD *biom,
                      long (*ctrl) (BIO *, int, long, void *));
int (*BIO_meth_get_create(const BIO_METHOD *bion)) (BIO *);
int BIO_meth_set_create(BIO_METHOD *biom, int (*create) (BIO *));
int (*BIO_meth_get_destroy(const BIO_METHOD *biom)) (BIO *);
int BIO_meth_set_destroy(BIO_METHOD *biom, int (*destroy) (BIO *));
long (*BIO_meth_get_callback_ctrl(const BIO_METHOD *biom))
                                 (BIO *, int, BIO_info_cb *);
int BIO_meth_set_callback_ctrl(BIO_METHOD *biom,
                               long (*callback_ctrl) (BIO *, int,
                                                      BIO_info_cb *));

# ifdef  __cplusplus
}
# endif
#endif
                                                                                            node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/openssl/cmp.h           0000664 0000000 0000000 00000120243 14746647661 0030634 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /*
 * WARNING: do not edit!
 * Generated by Makefile from include/openssl/cmp.h.in
 *
 * Copyright 2007-2023 The OpenSSL Project Authors. All Rights Reserved.
 * Copyright Nokia 2007-2019
 * Copyright Siemens AG 2015-2019
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 */



#ifndef OPENSSL_CMP_H
# define OPENSSL_CMP_H

# include <openssl/opensslconf.h>
# ifndef OPENSSL_NO_CMP

#  include <openssl/crmf.h>
#  include <openssl/cmperr.h>
#  include <openssl/cmp_util.h>
#  include <openssl/http.h>

/* explicit #includes not strictly needed since implied by the above: */
#  include <openssl/types.h>
#  include <openssl/safestack.h>
#  include <openssl/x509.h>
#  include <openssl/x509v3.h>

#  ifdef __cplusplus
extern "C" {
#  endif

#  define OSSL_CMP_PVNO 2

/*-
 *   PKIFailureInfo ::= BIT STRING {
 *   -- since we can fail in more than one way!
 *   -- More codes may be added in the future if/when required.
 *       badAlg              (0),
 *       -- unrecognized or unsupported Algorithm Identifier
 *       badMessageCheck     (1),
 *       -- integrity check failed (e.g., signature did not verify)
 *       badRequest          (2),
 *       -- transaction not permitted or supported
 *       badTime             (3),
 *       -- messageTime was not sufficiently close to the system time,
 *       -- as defined by local policy
 *       badCertId           (4),
 *       -- no certificate could be found matching the provided criteria
 *       badDataFormat       (5),
 *       -- the data submitted has the wrong format
 *       wrongAuthority      (6),
 *       -- the authority indicated in the request is different from the
 *       -- one creating the response token
 *       incorrectData       (7),
 *       -- the requester's data is incorrect (for notary services)
 *       missingTimeStamp    (8),
 *       -- when the timestamp is missing but should be there
 *       -- (by policy)
 *       badPOP              (9),
 *       -- the proof-of-possession failed
 *       certRevoked         (10),
 *          -- the certificate has already been revoked
 *       certConfirmed       (11),
 *          -- the certificate has already been confirmed
 *       wrongIntegrity      (12),
 *          -- invalid integrity, password based instead of signature or
 *          -- vice versa
 *       badRecipientNonce   (13),
 *          -- invalid recipient nonce, either missing or wrong value
 *       timeNotAvailable    (14),
 *          -- the TSA's time source is not available
 *       unacceptedPolicy    (15),
 *          -- the requested TSA policy is not supported by the TSA.
 *       unacceptedExtension (16),
 *          -- the requested extension is not supported by the TSA.
 *       addInfoNotAvailable (17),
 *          -- the additional information requested could not be
 *          -- understood or is not available
 *       badSenderNonce      (18),
 *          -- invalid sender nonce, either missing or wrong size
 *       badCertTemplate     (19),
 *          -- invalid cert. template or missing mandatory information
 *       signerNotTrusted    (20),
 *          -- signer of the message unknown or not trusted
 *       transactionIdInUse  (21),
 *          -- the transaction identifier is already in use
 *       unsupportedVersion  (22),
 *          -- the version of the message is not supported
 *       notAuthorized       (23),
 *          -- the sender was not authorized to make the preceding
 *          -- request or perform the preceding action
 *       systemUnavail       (24),
 *       -- the request cannot be handled due to system unavailability
 *       systemFailure       (25),
 *       -- the request cannot be handled due to system failure
 *       duplicateCertReq    (26)
 *       -- certificate cannot be issued because a duplicate
 *       -- certificate already exists
 *   }
 */
#  define OSSL_CMP_PKIFAILUREINFO_badAlg 0
#  define OSSL_CMP_PKIFAILUREINFO_badMessageCheck 1
#  define OSSL_CMP_PKIFAILUREINFO_badRequest 2
#  define OSSL_CMP_PKIFAILUREINFO_badTime 3
#  define OSSL_CMP_PKIFAILUREINFO_badCertId 4
#  define OSSL_CMP_PKIFAILUREINFO_badDataFormat 5
#  define OSSL_CMP_PKIFAILUREINFO_wrongAuthority 6
#  define OSSL_CMP_PKIFAILUREINFO_incorrectData 7
#  define OSSL_CMP_PKIFAILUREINFO_missingTimeStamp 8
#  define OSSL_CMP_PKIFAILUREINFO_badPOP 9
#  define OSSL_CMP_PKIFAILUREINFO_certRevoked 10
#  define OSSL_CMP_PKIFAILUREINFO_certConfirmed 11
#  define OSSL_CMP_PKIFAILUREINFO_wrongIntegrity 12
#  define OSSL_CMP_PKIFAILUREINFO_badRecipientNonce 13
#  define OSSL_CMP_PKIFAILUREINFO_timeNotAvailable 14
#  define OSSL_CMP_PKIFAILUREINFO_unacceptedPolicy 15
#  define OSSL_CMP_PKIFAILUREINFO_unacceptedExtension 16
#  define OSSL_CMP_PKIFAILUREINFO_addInfoNotAvailable 17
#  define OSSL_CMP_PKIFAILUREINFO_badSenderNonce 18
#  define OSSL_CMP_PKIFAILUREINFO_badCertTemplate 19
#  define OSSL_CMP_PKIFAILUREINFO_signerNotTrusted 20
#  define OSSL_CMP_PKIFAILUREINFO_transactionIdInUse 21
#  define OSSL_CMP_PKIFAILUREINFO_unsupportedVersion 22
#  define OSSL_CMP_PKIFAILUREINFO_notAuthorized 23
#  define OSSL_CMP_PKIFAILUREINFO_systemUnavail 24
#  define OSSL_CMP_PKIFAILUREINFO_systemFailure 25
#  define OSSL_CMP_PKIFAILUREINFO_duplicateCertReq 26
#  define OSSL_CMP_PKIFAILUREINFO_MAX 26
#  define OSSL_CMP_PKIFAILUREINFO_MAX_BIT_PATTERN \
    ((1 << (OSSL_CMP_PKIFAILUREINFO_MAX + 1)) - 1)
#  if OSSL_CMP_PKIFAILUREINFO_MAX_BIT_PATTERN > INT_MAX
#   error CMP_PKIFAILUREINFO_MAX bit pattern does not fit in type int
#  endif

typedef ASN1_BIT_STRING OSSL_CMP_PKIFAILUREINFO;

#  define OSSL_CMP_CTX_FAILINFO_badAlg (1 << 0)
#  define OSSL_CMP_CTX_FAILINFO_badMessageCheck (1 << 1)
#  define OSSL_CMP_CTX_FAILINFO_badRequest (1 << 2)
#  define OSSL_CMP_CTX_FAILINFO_badTime (1 << 3)
#  define OSSL_CMP_CTX_FAILINFO_badCertId (1 << 4)
#  define OSSL_CMP_CTX_FAILINFO_badDataFormat (1 << 5)
#  define OSSL_CMP_CTX_FAILINFO_wrongAuthority (1 << 6)
#  define OSSL_CMP_CTX_FAILINFO_incorrectData (1 << 7)
#  define OSSL_CMP_CTX_FAILINFO_missingTimeStamp (1 << 8)
#  define OSSL_CMP_CTX_FAILINFO_badPOP (1 << 9)
#  define OSSL_CMP_CTX_FAILINFO_certRevoked (1 << 10)
#  define OSSL_CMP_CTX_FAILINFO_certConfirmed (1 << 11)
#  define OSSL_CMP_CTX_FAILINFO_wrongIntegrity (1 << 12)
#  define OSSL_CMP_CTX_FAILINFO_badRecipientNonce (1 << 13)
#  define OSSL_CMP_CTX_FAILINFO_timeNotAvailable (1 << 14)
#  define OSSL_CMP_CTX_FAILINFO_unacceptedPolicy (1 << 15)
#  define OSSL_CMP_CTX_FAILINFO_unacceptedExtension (1 << 16)
#  define OSSL_CMP_CTX_FAILINFO_addInfoNotAvailable (1 << 17)
#  define OSSL_CMP_CTX_FAILINFO_badSenderNonce (1 << 18)
#  define OSSL_CMP_CTX_FAILINFO_badCertTemplate (1 << 19)
#  define OSSL_CMP_CTX_FAILINFO_signerNotTrusted (1 << 20)
#  define OSSL_CMP_CTX_FAILINFO_transactionIdInUse (1 << 21)
#  define OSSL_CMP_CTX_FAILINFO_unsupportedVersion (1 << 22)
#  define OSSL_CMP_CTX_FAILINFO_notAuthorized (1 << 23)
#  define OSSL_CMP_CTX_FAILINFO_systemUnavail (1 << 24)
#  define OSSL_CMP_CTX_FAILINFO_systemFailure (1 << 25)
#  define OSSL_CMP_CTX_FAILINFO_duplicateCertReq (1 << 26)

/*-
 *   PKIStatus ::= INTEGER {
 *       accepted                (0),
 *       -- you got exactly what you asked for
 *       grantedWithMods        (1),
 *       -- you got something like what you asked for; the
 *       -- requester is responsible for ascertaining the differences
 *       rejection              (2),
 *       -- you don't get it, more information elsewhere in the message
 *       waiting                (3),
 *       -- the request body part has not yet been processed; expect to
 *       -- hear more later (note: proper handling of this status
 *       -- response MAY use the polling req/rep PKIMessages specified
 *       -- in Section 5.3.22; alternatively, polling in the underlying
 *       -- transport layer MAY have some utility in this regard)
 *       revocationWarning      (4),
 *       -- this message contains a warning that a revocation is
 *       -- imminent
 *       revocationNotification (5),
 *       -- notification that a revocation has occurred
 *       keyUpdateWarning       (6)
 *       -- update already done for the oldCertId specified in
 *       -- CertReqMsg
 *   }
 */
#  define OSSL_CMP_PKISTATUS_request                -3
#  define OSSL_CMP_PKISTATUS_trans                  -2
#  define OSSL_CMP_PKISTATUS_unspecified            -1
#  define OSSL_CMP_PKISTATUS_accepted               0
#  define OSSL_CMP_PKISTATUS_grantedWithMods        1
#  define OSSL_CMP_PKISTATUS_rejection              2
#  define OSSL_CMP_PKISTATUS_waiting                3
#  define OSSL_CMP_PKISTATUS_revocationWarning      4
#  define OSSL_CMP_PKISTATUS_revocationNotification 5
#  define OSSL_CMP_PKISTATUS_keyUpdateWarning       6

typedef ASN1_INTEGER OSSL_CMP_PKISTATUS;
DECLARE_ASN1_ITEM(OSSL_CMP_PKISTATUS)

#  define OSSL_CMP_CERTORENCCERT_CERTIFICATE 0
#  define OSSL_CMP_CERTORENCCERT_ENCRYPTEDCERT 1

/* data type declarations */
typedef struct ossl_cmp_ctx_st OSSL_CMP_CTX;
typedef struct ossl_cmp_pkiheader_st OSSL_CMP_PKIHEADER;
DECLARE_ASN1_FUNCTIONS(OSSL_CMP_PKIHEADER)
typedef struct ossl_cmp_msg_st OSSL_CMP_MSG;
DECLARE_ASN1_DUP_FUNCTION(OSSL_CMP_MSG)
DECLARE_ASN1_ENCODE_FUNCTIONS(OSSL_CMP_MSG, OSSL_CMP_MSG, OSSL_CMP_MSG)
typedef struct ossl_cmp_certstatus_st OSSL_CMP_CERTSTATUS;
SKM_DEFINE_STACK_OF_INTERNAL(OSSL_CMP_CERTSTATUS, OSSL_CMP_CERTSTATUS, OSSL_CMP_CERTSTATUS)
#define sk_OSSL_CMP_CERTSTATUS_num(sk) OPENSSL_sk_num(ossl_check_const_OSSL_CMP_CERTSTATUS_sk_type(sk))
#define sk_OSSL_CMP_CERTSTATUS_value(sk, idx) ((OSSL_CMP_CERTSTATUS *)OPENSSL_sk_value(ossl_check_const_OSSL_CMP_CERTSTATUS_sk_type(sk), (idx)))
#define sk_OSSL_CMP_CERTSTATUS_new(cmp) ((STACK_OF(OSSL_CMP_CERTSTATUS) *)OPENSSL_sk_new(ossl_check_OSSL_CMP_CERTSTATUS_compfunc_type(cmp)))
#define sk_OSSL_CMP_CERTSTATUS_new_null() ((STACK_OF(OSSL_CMP_CERTSTATUS) *)OPENSSL_sk_new_null())
#define sk_OSSL_CMP_CERTSTATUS_new_reserve(cmp, n) ((STACK_OF(OSSL_CMP_CERTSTATUS) *)OPENSSL_sk_new_reserve(ossl_check_OSSL_CMP_CERTSTATUS_compfunc_type(cmp), (n)))
#define sk_OSSL_CMP_CERTSTATUS_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_OSSL_CMP_CERTSTATUS_sk_type(sk), (n))
#define sk_OSSL_CMP_CERTSTATUS_free(sk) OPENSSL_sk_free(ossl_check_OSSL_CMP_CERTSTATUS_sk_type(sk))
#define sk_OSSL_CMP_CERTSTATUS_zero(sk) OPENSSL_sk_zero(ossl_check_OSSL_CMP_CERTSTATUS_sk_type(sk))
#define sk_OSSL_CMP_CERTSTATUS_delete(sk, i) ((OSSL_CMP_CERTSTATUS *)OPENSSL_sk_delete(ossl_check_OSSL_CMP_CERTSTATUS_sk_type(sk), (i)))
#define sk_OSSL_CMP_CERTSTATUS_delete_ptr(sk, ptr) ((OSSL_CMP_CERTSTATUS *)OPENSSL_sk_delete_ptr(ossl_check_OSSL_CMP_CERTSTATUS_sk_type(sk), ossl_check_OSSL_CMP_CERTSTATUS_type(ptr)))
#define sk_OSSL_CMP_CERTSTATUS_push(sk, ptr) OPENSSL_sk_push(ossl_check_OSSL_CMP_CERTSTATUS_sk_type(sk), ossl_check_OSSL_CMP_CERTSTATUS_type(ptr))
#define sk_OSSL_CMP_CERTSTATUS_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_OSSL_CMP_CERTSTATUS_sk_type(sk), ossl_check_OSSL_CMP_CERTSTATUS_type(ptr))
#define sk_OSSL_CMP_CERTSTATUS_pop(sk) ((OSSL_CMP_CERTSTATUS *)OPENSSL_sk_pop(ossl_check_OSSL_CMP_CERTSTATUS_sk_type(sk)))
#define sk_OSSL_CMP_CERTSTATUS_shift(sk) ((OSSL_CMP_CERTSTATUS *)OPENSSL_sk_shift(ossl_check_OSSL_CMP_CERTSTATUS_sk_type(sk)))
#define sk_OSSL_CMP_CERTSTATUS_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_OSSL_CMP_CERTSTATUS_sk_type(sk),ossl_check_OSSL_CMP_CERTSTATUS_freefunc_type(freefunc))
#define sk_OSSL_CMP_CERTSTATUS_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_OSSL_CMP_CERTSTATUS_sk_type(sk), ossl_check_OSSL_CMP_CERTSTATUS_type(ptr), (idx))
#define sk_OSSL_CMP_CERTSTATUS_set(sk, idx, ptr) ((OSSL_CMP_CERTSTATUS *)OPENSSL_sk_set(ossl_check_OSSL_CMP_CERTSTATUS_sk_type(sk), (idx), ossl_check_OSSL_CMP_CERTSTATUS_type(ptr)))
#define sk_OSSL_CMP_CERTSTATUS_find(sk, ptr) OPENSSL_sk_find(ossl_check_OSSL_CMP_CERTSTATUS_sk_type(sk), ossl_check_OSSL_CMP_CERTSTATUS_type(ptr))
#define sk_OSSL_CMP_CERTSTATUS_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_OSSL_CMP_CERTSTATUS_sk_type(sk), ossl_check_OSSL_CMP_CERTSTATUS_type(ptr))
#define sk_OSSL_CMP_CERTSTATUS_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_OSSL_CMP_CERTSTATUS_sk_type(sk), ossl_check_OSSL_CMP_CERTSTATUS_type(ptr), pnum)
#define sk_OSSL_CMP_CERTSTATUS_sort(sk) OPENSSL_sk_sort(ossl_check_OSSL_CMP_CERTSTATUS_sk_type(sk))
#define sk_OSSL_CMP_CERTSTATUS_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_OSSL_CMP_CERTSTATUS_sk_type(sk))
#define sk_OSSL_CMP_CERTSTATUS_dup(sk) ((STACK_OF(OSSL_CMP_CERTSTATUS) *)OPENSSL_sk_dup(ossl_check_const_OSSL_CMP_CERTSTATUS_sk_type(sk)))
#define sk_OSSL_CMP_CERTSTATUS_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(OSSL_CMP_CERTSTATUS) *)OPENSSL_sk_deep_copy(ossl_check_const_OSSL_CMP_CERTSTATUS_sk_type(sk), ossl_check_OSSL_CMP_CERTSTATUS_copyfunc_type(copyfunc), ossl_check_OSSL_CMP_CERTSTATUS_freefunc_type(freefunc)))
#define sk_OSSL_CMP_CERTSTATUS_set_cmp_func(sk, cmp) ((sk_OSSL_CMP_CERTSTATUS_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_OSSL_CMP_CERTSTATUS_sk_type(sk), ossl_check_OSSL_CMP_CERTSTATUS_compfunc_type(cmp)))

typedef struct ossl_cmp_itav_st OSSL_CMP_ITAV;
DECLARE_ASN1_DUP_FUNCTION(OSSL_CMP_ITAV)
SKM_DEFINE_STACK_OF_INTERNAL(OSSL_CMP_ITAV, OSSL_CMP_ITAV, OSSL_CMP_ITAV)
#define sk_OSSL_CMP_ITAV_num(sk) OPENSSL_sk_num(ossl_check_const_OSSL_CMP_ITAV_sk_type(sk))
#define sk_OSSL_CMP_ITAV_value(sk, idx) ((OSSL_CMP_ITAV *)OPENSSL_sk_value(ossl_check_const_OSSL_CMP_ITAV_sk_type(sk), (idx)))
#define sk_OSSL_CMP_ITAV_new(cmp) ((STACK_OF(OSSL_CMP_ITAV) *)OPENSSL_sk_new(ossl_check_OSSL_CMP_ITAV_compfunc_type(cmp)))
#define sk_OSSL_CMP_ITAV_new_null() ((STACK_OF(OSSL_CMP_ITAV) *)OPENSSL_sk_new_null())
#define sk_OSSL_CMP_ITAV_new_reserve(cmp, n) ((STACK_OF(OSSL_CMP_ITAV) *)OPENSSL_sk_new_reserve(ossl_check_OSSL_CMP_ITAV_compfunc_type(cmp), (n)))
#define sk_OSSL_CMP_ITAV_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_OSSL_CMP_ITAV_sk_type(sk), (n))
#define sk_OSSL_CMP_ITAV_free(sk) OPENSSL_sk_free(ossl_check_OSSL_CMP_ITAV_sk_type(sk))
#define sk_OSSL_CMP_ITAV_zero(sk) OPENSSL_sk_zero(ossl_check_OSSL_CMP_ITAV_sk_type(sk))
#define sk_OSSL_CMP_ITAV_delete(sk, i) ((OSSL_CMP_ITAV *)OPENSSL_sk_delete(ossl_check_OSSL_CMP_ITAV_sk_type(sk), (i)))
#define sk_OSSL_CMP_ITAV_delete_ptr(sk, ptr) ((OSSL_CMP_ITAV *)OPENSSL_sk_delete_ptr(ossl_check_OSSL_CMP_ITAV_sk_type(sk), ossl_check_OSSL_CMP_ITAV_type(ptr)))
#define sk_OSSL_CMP_ITAV_push(sk, ptr) OPENSSL_sk_push(ossl_check_OSSL_CMP_ITAV_sk_type(sk), ossl_check_OSSL_CMP_ITAV_type(ptr))
#define sk_OSSL_CMP_ITAV_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_OSSL_CMP_ITAV_sk_type(sk), ossl_check_OSSL_CMP_ITAV_type(ptr))
#define sk_OSSL_CMP_ITAV_pop(sk) ((OSSL_CMP_ITAV *)OPENSSL_sk_pop(ossl_check_OSSL_CMP_ITAV_sk_type(sk)))
#define sk_OSSL_CMP_ITAV_shift(sk) ((OSSL_CMP_ITAV *)OPENSSL_sk_shift(ossl_check_OSSL_CMP_ITAV_sk_type(sk)))
#define sk_OSSL_CMP_ITAV_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_OSSL_CMP_ITAV_sk_type(sk),ossl_check_OSSL_CMP_ITAV_freefunc_type(freefunc))
#define sk_OSSL_CMP_ITAV_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_OSSL_CMP_ITAV_sk_type(sk), ossl_check_OSSL_CMP_ITAV_type(ptr), (idx))
#define sk_OSSL_CMP_ITAV_set(sk, idx, ptr) ((OSSL_CMP_ITAV *)OPENSSL_sk_set(ossl_check_OSSL_CMP_ITAV_sk_type(sk), (idx), ossl_check_OSSL_CMP_ITAV_type(ptr)))
#define sk_OSSL_CMP_ITAV_find(sk, ptr) OPENSSL_sk_find(ossl_check_OSSL_CMP_ITAV_sk_type(sk), ossl_check_OSSL_CMP_ITAV_type(ptr))
#define sk_OSSL_CMP_ITAV_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_OSSL_CMP_ITAV_sk_type(sk), ossl_check_OSSL_CMP_ITAV_type(ptr))
#define sk_OSSL_CMP_ITAV_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_OSSL_CMP_ITAV_sk_type(sk), ossl_check_OSSL_CMP_ITAV_type(ptr), pnum)
#define sk_OSSL_CMP_ITAV_sort(sk) OPENSSL_sk_sort(ossl_check_OSSL_CMP_ITAV_sk_type(sk))
#define sk_OSSL_CMP_ITAV_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_OSSL_CMP_ITAV_sk_type(sk))
#define sk_OSSL_CMP_ITAV_dup(sk) ((STACK_OF(OSSL_CMP_ITAV) *)OPENSSL_sk_dup(ossl_check_const_OSSL_CMP_ITAV_sk_type(sk)))
#define sk_OSSL_CMP_ITAV_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(OSSL_CMP_ITAV) *)OPENSSL_sk_deep_copy(ossl_check_const_OSSL_CMP_ITAV_sk_type(sk), ossl_check_OSSL_CMP_ITAV_copyfunc_type(copyfunc), ossl_check_OSSL_CMP_ITAV_freefunc_type(freefunc)))
#define sk_OSSL_CMP_ITAV_set_cmp_func(sk, cmp) ((sk_OSSL_CMP_ITAV_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_OSSL_CMP_ITAV_sk_type(sk), ossl_check_OSSL_CMP_ITAV_compfunc_type(cmp)))

typedef struct ossl_cmp_revrepcontent_st OSSL_CMP_REVREPCONTENT;
typedef struct ossl_cmp_pkisi_st OSSL_CMP_PKISI;
DECLARE_ASN1_FUNCTIONS(OSSL_CMP_PKISI)
DECLARE_ASN1_DUP_FUNCTION(OSSL_CMP_PKISI)
SKM_DEFINE_STACK_OF_INTERNAL(OSSL_CMP_PKISI, OSSL_CMP_PKISI, OSSL_CMP_PKISI)
#define sk_OSSL_CMP_PKISI_num(sk) OPENSSL_sk_num(ossl_check_const_OSSL_CMP_PKISI_sk_type(sk))
#define sk_OSSL_CMP_PKISI_value(sk, idx) ((OSSL_CMP_PKISI *)OPENSSL_sk_value(ossl_check_const_OSSL_CMP_PKISI_sk_type(sk), (idx)))
#define sk_OSSL_CMP_PKISI_new(cmp) ((STACK_OF(OSSL_CMP_PKISI) *)OPENSSL_sk_new(ossl_check_OSSL_CMP_PKISI_compfunc_type(cmp)))
#define sk_OSSL_CMP_PKISI_new_null() ((STACK_OF(OSSL_CMP_PKISI) *)OPENSSL_sk_new_null())
#define sk_OSSL_CMP_PKISI_new_reserve(cmp, n) ((STACK_OF(OSSL_CMP_PKISI) *)OPENSSL_sk_new_reserve(ossl_check_OSSL_CMP_PKISI_compfunc_type(cmp), (n)))
#define sk_OSSL_CMP_PKISI_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_OSSL_CMP_PKISI_sk_type(sk), (n))
#define sk_OSSL_CMP_PKISI_free(sk) OPENSSL_sk_free(ossl_check_OSSL_CMP_PKISI_sk_type(sk))
#define sk_OSSL_CMP_PKISI_zero(sk) OPENSSL_sk_zero(ossl_check_OSSL_CMP_PKISI_sk_type(sk))
#define sk_OSSL_CMP_PKISI_delete(sk, i) ((OSSL_CMP_PKISI *)OPENSSL_sk_delete(ossl_check_OSSL_CMP_PKISI_sk_type(sk), (i)))
#define sk_OSSL_CMP_PKISI_delete_ptr(sk, ptr) ((OSSL_CMP_PKISI *)OPENSSL_sk_delete_ptr(ossl_check_OSSL_CMP_PKISI_sk_type(sk), ossl_check_OSSL_CMP_PKISI_type(ptr)))
#define sk_OSSL_CMP_PKISI_push(sk, ptr) OPENSSL_sk_push(ossl_check_OSSL_CMP_PKISI_sk_type(sk), ossl_check_OSSL_CMP_PKISI_type(ptr))
#define sk_OSSL_CMP_PKISI_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_OSSL_CMP_PKISI_sk_type(sk), ossl_check_OSSL_CMP_PKISI_type(ptr))
#define sk_OSSL_CMP_PKISI_pop(sk) ((OSSL_CMP_PKISI *)OPENSSL_sk_pop(ossl_check_OSSL_CMP_PKISI_sk_type(sk)))
#define sk_OSSL_CMP_PKISI_shift(sk) ((OSSL_CMP_PKISI *)OPENSSL_sk_shift(ossl_check_OSSL_CMP_PKISI_sk_type(sk)))
#define sk_OSSL_CMP_PKISI_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_OSSL_CMP_PKISI_sk_type(sk),ossl_check_OSSL_CMP_PKISI_freefunc_type(freefunc))
#define sk_OSSL_CMP_PKISI_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_OSSL_CMP_PKISI_sk_type(sk), ossl_check_OSSL_CMP_PKISI_type(ptr), (idx))
#define sk_OSSL_CMP_PKISI_set(sk, idx, ptr) ((OSSL_CMP_PKISI *)OPENSSL_sk_set(ossl_check_OSSL_CMP_PKISI_sk_type(sk), (idx), ossl_check_OSSL_CMP_PKISI_type(ptr)))
#define sk_OSSL_CMP_PKISI_find(sk, ptr) OPENSSL_sk_find(ossl_check_OSSL_CMP_PKISI_sk_type(sk), ossl_check_OSSL_CMP_PKISI_type(ptr))
#define sk_OSSL_CMP_PKISI_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_OSSL_CMP_PKISI_sk_type(sk), ossl_check_OSSL_CMP_PKISI_type(ptr))
#define sk_OSSL_CMP_PKISI_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_OSSL_CMP_PKISI_sk_type(sk), ossl_check_OSSL_CMP_PKISI_type(ptr), pnum)
#define sk_OSSL_CMP_PKISI_sort(sk) OPENSSL_sk_sort(ossl_check_OSSL_CMP_PKISI_sk_type(sk))
#define sk_OSSL_CMP_PKISI_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_OSSL_CMP_PKISI_sk_type(sk))
#define sk_OSSL_CMP_PKISI_dup(sk) ((STACK_OF(OSSL_CMP_PKISI) *)OPENSSL_sk_dup(ossl_check_const_OSSL_CMP_PKISI_sk_type(sk)))
#define sk_OSSL_CMP_PKISI_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(OSSL_CMP_PKISI) *)OPENSSL_sk_deep_copy(ossl_check_const_OSSL_CMP_PKISI_sk_type(sk), ossl_check_OSSL_CMP_PKISI_copyfunc_type(copyfunc), ossl_check_OSSL_CMP_PKISI_freefunc_type(freefunc)))
#define sk_OSSL_CMP_PKISI_set_cmp_func(sk, cmp) ((sk_OSSL_CMP_PKISI_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_OSSL_CMP_PKISI_sk_type(sk), ossl_check_OSSL_CMP_PKISI_compfunc_type(cmp)))

typedef struct ossl_cmp_certrepmessage_st OSSL_CMP_CERTREPMESSAGE;
SKM_DEFINE_STACK_OF_INTERNAL(OSSL_CMP_CERTREPMESSAGE, OSSL_CMP_CERTREPMESSAGE, OSSL_CMP_CERTREPMESSAGE)
#define sk_OSSL_CMP_CERTREPMESSAGE_num(sk) OPENSSL_sk_num(ossl_check_const_OSSL_CMP_CERTREPMESSAGE_sk_type(sk))
#define sk_OSSL_CMP_CERTREPMESSAGE_value(sk, idx) ((OSSL_CMP_CERTREPMESSAGE *)OPENSSL_sk_value(ossl_check_const_OSSL_CMP_CERTREPMESSAGE_sk_type(sk), (idx)))
#define sk_OSSL_CMP_CERTREPMESSAGE_new(cmp) ((STACK_OF(OSSL_CMP_CERTREPMESSAGE) *)OPENSSL_sk_new(ossl_check_OSSL_CMP_CERTREPMESSAGE_compfunc_type(cmp)))
#define sk_OSSL_CMP_CERTREPMESSAGE_new_null() ((STACK_OF(OSSL_CMP_CERTREPMESSAGE) *)OPENSSL_sk_new_null())
#define sk_OSSL_CMP_CERTREPMESSAGE_new_reserve(cmp, n) ((STACK_OF(OSSL_CMP_CERTREPMESSAGE) *)OPENSSL_sk_new_reserve(ossl_check_OSSL_CMP_CERTREPMESSAGE_compfunc_type(cmp), (n)))
#define sk_OSSL_CMP_CERTREPMESSAGE_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_OSSL_CMP_CERTREPMESSAGE_sk_type(sk), (n))
#define sk_OSSL_CMP_CERTREPMESSAGE_free(sk) OPENSSL_sk_free(ossl_check_OSSL_CMP_CERTREPMESSAGE_sk_type(sk))
#define sk_OSSL_CMP_CERTREPMESSAGE_zero(sk) OPENSSL_sk_zero(ossl_check_OSSL_CMP_CERTREPMESSAGE_sk_type(sk))
#define sk_OSSL_CMP_CERTREPMESSAGE_delete(sk, i) ((OSSL_CMP_CERTREPMESSAGE *)OPENSSL_sk_delete(ossl_check_OSSL_CMP_CERTREPMESSAGE_sk_type(sk), (i)))
#define sk_OSSL_CMP_CERTREPMESSAGE_delete_ptr(sk, ptr) ((OSSL_CMP_CERTREPMESSAGE *)OPENSSL_sk_delete_ptr(ossl_check_OSSL_CMP_CERTREPMESSAGE_sk_type(sk), ossl_check_OSSL_CMP_CERTREPMESSAGE_type(ptr)))
#define sk_OSSL_CMP_CERTREPMESSAGE_push(sk, ptr) OPENSSL_sk_push(ossl_check_OSSL_CMP_CERTREPMESSAGE_sk_type(sk), ossl_check_OSSL_CMP_CERTREPMESSAGE_type(ptr))
#define sk_OSSL_CMP_CERTREPMESSAGE_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_OSSL_CMP_CERTREPMESSAGE_sk_type(sk), ossl_check_OSSL_CMP_CERTREPMESSAGE_type(ptr))
#define sk_OSSL_CMP_CERTREPMESSAGE_pop(sk) ((OSSL_CMP_CERTREPMESSAGE *)OPENSSL_sk_pop(ossl_check_OSSL_CMP_CERTREPMESSAGE_sk_type(sk)))
#define sk_OSSL_CMP_CERTREPMESSAGE_shift(sk) ((OSSL_CMP_CERTREPMESSAGE *)OPENSSL_sk_shift(ossl_check_OSSL_CMP_CERTREPMESSAGE_sk_type(sk)))
#define sk_OSSL_CMP_CERTREPMESSAGE_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_OSSL_CMP_CERTREPMESSAGE_sk_type(sk),ossl_check_OSSL_CMP_CERTREPMESSAGE_freefunc_type(freefunc))
#define sk_OSSL_CMP_CERTREPMESSAGE_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_OSSL_CMP_CERTREPMESSAGE_sk_type(sk), ossl_check_OSSL_CMP_CERTREPMESSAGE_type(ptr), (idx))
#define sk_OSSL_CMP_CERTREPMESSAGE_set(sk, idx, ptr) ((OSSL_CMP_CERTREPMESSAGE *)OPENSSL_sk_set(ossl_check_OSSL_CMP_CERTREPMESSAGE_sk_type(sk), (idx), ossl_check_OSSL_CMP_CERTREPMESSAGE_type(ptr)))
#define sk_OSSL_CMP_CERTREPMESSAGE_find(sk, ptr) OPENSSL_sk_find(ossl_check_OSSL_CMP_CERTREPMESSAGE_sk_type(sk), ossl_check_OSSL_CMP_CERTREPMESSAGE_type(ptr))
#define sk_OSSL_CMP_CERTREPMESSAGE_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_OSSL_CMP_CERTREPMESSAGE_sk_type(sk), ossl_check_OSSL_CMP_CERTREPMESSAGE_type(ptr))
#define sk_OSSL_CMP_CERTREPMESSAGE_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_OSSL_CMP_CERTREPMESSAGE_sk_type(sk), ossl_check_OSSL_CMP_CERTREPMESSAGE_type(ptr), pnum)
#define sk_OSSL_CMP_CERTREPMESSAGE_sort(sk) OPENSSL_sk_sort(ossl_check_OSSL_CMP_CERTREPMESSAGE_sk_type(sk))
#define sk_OSSL_CMP_CERTREPMESSAGE_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_OSSL_CMP_CERTREPMESSAGE_sk_type(sk))
#define sk_OSSL_CMP_CERTREPMESSAGE_dup(sk) ((STACK_OF(OSSL_CMP_CERTREPMESSAGE) *)OPENSSL_sk_dup(ossl_check_const_OSSL_CMP_CERTREPMESSAGE_sk_type(sk)))
#define sk_OSSL_CMP_CERTREPMESSAGE_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(OSSL_CMP_CERTREPMESSAGE) *)OPENSSL_sk_deep_copy(ossl_check_const_OSSL_CMP_CERTREPMESSAGE_sk_type(sk), ossl_check_OSSL_CMP_CERTREPMESSAGE_copyfunc_type(copyfunc), ossl_check_OSSL_CMP_CERTREPMESSAGE_freefunc_type(freefunc)))
#define sk_OSSL_CMP_CERTREPMESSAGE_set_cmp_func(sk, cmp) ((sk_OSSL_CMP_CERTREPMESSAGE_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_OSSL_CMP_CERTREPMESSAGE_sk_type(sk), ossl_check_OSSL_CMP_CERTREPMESSAGE_compfunc_type(cmp)))

typedef struct ossl_cmp_pollrep_st OSSL_CMP_POLLREP;
typedef STACK_OF(OSSL_CMP_POLLREP) OSSL_CMP_POLLREPCONTENT;
typedef struct ossl_cmp_certresponse_st OSSL_CMP_CERTRESPONSE;
SKM_DEFINE_STACK_OF_INTERNAL(OSSL_CMP_CERTRESPONSE, OSSL_CMP_CERTRESPONSE, OSSL_CMP_CERTRESPONSE)
#define sk_OSSL_CMP_CERTRESPONSE_num(sk) OPENSSL_sk_num(ossl_check_const_OSSL_CMP_CERTRESPONSE_sk_type(sk))
#define sk_OSSL_CMP_CERTRESPONSE_value(sk, idx) ((OSSL_CMP_CERTRESPONSE *)OPENSSL_sk_value(ossl_check_const_OSSL_CMP_CERTRESPONSE_sk_type(sk), (idx)))
#define sk_OSSL_CMP_CERTRESPONSE_new(cmp) ((STACK_OF(OSSL_CMP_CERTRESPONSE) *)OPENSSL_sk_new(ossl_check_OSSL_CMP_CERTRESPONSE_compfunc_type(cmp)))
#define sk_OSSL_CMP_CERTRESPONSE_new_null() ((STACK_OF(OSSL_CMP_CERTRESPONSE) *)OPENSSL_sk_new_null())
#define sk_OSSL_CMP_CERTRESPONSE_new_reserve(cmp, n) ((STACK_OF(OSSL_CMP_CERTRESPONSE) *)OPENSSL_sk_new_reserve(ossl_check_OSSL_CMP_CERTRESPONSE_compfunc_type(cmp), (n)))
#define sk_OSSL_CMP_CERTRESPONSE_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_OSSL_CMP_CERTRESPONSE_sk_type(sk), (n))
#define sk_OSSL_CMP_CERTRESPONSE_free(sk) OPENSSL_sk_free(ossl_check_OSSL_CMP_CERTRESPONSE_sk_type(sk))
#define sk_OSSL_CMP_CERTRESPONSE_zero(sk) OPENSSL_sk_zero(ossl_check_OSSL_CMP_CERTRESPONSE_sk_type(sk))
#define sk_OSSL_CMP_CERTRESPONSE_delete(sk, i) ((OSSL_CMP_CERTRESPONSE *)OPENSSL_sk_delete(ossl_check_OSSL_CMP_CERTRESPONSE_sk_type(sk), (i)))
#define sk_OSSL_CMP_CERTRESPONSE_delete_ptr(sk, ptr) ((OSSL_CMP_CERTRESPONSE *)OPENSSL_sk_delete_ptr(ossl_check_OSSL_CMP_CERTRESPONSE_sk_type(sk), ossl_check_OSSL_CMP_CERTRESPONSE_type(ptr)))
#define sk_OSSL_CMP_CERTRESPONSE_push(sk, ptr) OPENSSL_sk_push(ossl_check_OSSL_CMP_CERTRESPONSE_sk_type(sk), ossl_check_OSSL_CMP_CERTRESPONSE_type(ptr))
#define sk_OSSL_CMP_CERTRESPONSE_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_OSSL_CMP_CERTRESPONSE_sk_type(sk), ossl_check_OSSL_CMP_CERTRESPONSE_type(ptr))
#define sk_OSSL_CMP_CERTRESPONSE_pop(sk) ((OSSL_CMP_CERTRESPONSE *)OPENSSL_sk_pop(ossl_check_OSSL_CMP_CERTRESPONSE_sk_type(sk)))
#define sk_OSSL_CMP_CERTRESPONSE_shift(sk) ((OSSL_CMP_CERTRESPONSE *)OPENSSL_sk_shift(ossl_check_OSSL_CMP_CERTRESPONSE_sk_type(sk)))
#define sk_OSSL_CMP_CERTRESPONSE_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_OSSL_CMP_CERTRESPONSE_sk_type(sk),ossl_check_OSSL_CMP_CERTRESPONSE_freefunc_type(freefunc))
#define sk_OSSL_CMP_CERTRESPONSE_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_OSSL_CMP_CERTRESPONSE_sk_type(sk), ossl_check_OSSL_CMP_CERTRESPONSE_type(ptr), (idx))
#define sk_OSSL_CMP_CERTRESPONSE_set(sk, idx, ptr) ((OSSL_CMP_CERTRESPONSE *)OPENSSL_sk_set(ossl_check_OSSL_CMP_CERTRESPONSE_sk_type(sk), (idx), ossl_check_OSSL_CMP_CERTRESPONSE_type(ptr)))
#define sk_OSSL_CMP_CERTRESPONSE_find(sk, ptr) OPENSSL_sk_find(ossl_check_OSSL_CMP_CERTRESPONSE_sk_type(sk), ossl_check_OSSL_CMP_CERTRESPONSE_type(ptr))
#define sk_OSSL_CMP_CERTRESPONSE_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_OSSL_CMP_CERTRESPONSE_sk_type(sk), ossl_check_OSSL_CMP_CERTRESPONSE_type(ptr))
#define sk_OSSL_CMP_CERTRESPONSE_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_OSSL_CMP_CERTRESPONSE_sk_type(sk), ossl_check_OSSL_CMP_CERTRESPONSE_type(ptr), pnum)
#define sk_OSSL_CMP_CERTRESPONSE_sort(sk) OPENSSL_sk_sort(ossl_check_OSSL_CMP_CERTRESPONSE_sk_type(sk))
#define sk_OSSL_CMP_CERTRESPONSE_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_OSSL_CMP_CERTRESPONSE_sk_type(sk))
#define sk_OSSL_CMP_CERTRESPONSE_dup(sk) ((STACK_OF(OSSL_CMP_CERTRESPONSE) *)OPENSSL_sk_dup(ossl_check_const_OSSL_CMP_CERTRESPONSE_sk_type(sk)))
#define sk_OSSL_CMP_CERTRESPONSE_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(OSSL_CMP_CERTRESPONSE) *)OPENSSL_sk_deep_copy(ossl_check_const_OSSL_CMP_CERTRESPONSE_sk_type(sk), ossl_check_OSSL_CMP_CERTRESPONSE_copyfunc_type(copyfunc), ossl_check_OSSL_CMP_CERTRESPONSE_freefunc_type(freefunc)))
#define sk_OSSL_CMP_CERTRESPONSE_set_cmp_func(sk, cmp) ((sk_OSSL_CMP_CERTRESPONSE_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_OSSL_CMP_CERTRESPONSE_sk_type(sk), ossl_check_OSSL_CMP_CERTRESPONSE_compfunc_type(cmp)))

typedef STACK_OF(ASN1_UTF8STRING) OSSL_CMP_PKIFREETEXT;

/*
 * function DECLARATIONS
 */

/* from cmp_asn.c */
OSSL_CMP_ITAV *OSSL_CMP_ITAV_create(ASN1_OBJECT *type, ASN1_TYPE *value);
void OSSL_CMP_ITAV_set0(OSSL_CMP_ITAV *itav, ASN1_OBJECT *type,
                        ASN1_TYPE *value);
ASN1_OBJECT *OSSL_CMP_ITAV_get0_type(const OSSL_CMP_ITAV *itav);
ASN1_TYPE *OSSL_CMP_ITAV_get0_value(const OSSL_CMP_ITAV *itav);
int OSSL_CMP_ITAV_push0_stack_item(STACK_OF(OSSL_CMP_ITAV) **itav_sk_p,
                                   OSSL_CMP_ITAV *itav);
void OSSL_CMP_ITAV_free(OSSL_CMP_ITAV *itav);
void OSSL_CMP_MSG_free(OSSL_CMP_MSG *msg);

/* from cmp_ctx.c */
OSSL_CMP_CTX *OSSL_CMP_CTX_new(OSSL_LIB_CTX *libctx, const char *propq);
void OSSL_CMP_CTX_free(OSSL_CMP_CTX *ctx);
int OSSL_CMP_CTX_reinit(OSSL_CMP_CTX *ctx);
/* CMP general options: */
#  define OSSL_CMP_OPT_LOG_VERBOSITY 0
/* CMP transfer options: */
#  define OSSL_CMP_OPT_KEEP_ALIVE 10
#  define OSSL_CMP_OPT_MSG_TIMEOUT 11
#  define OSSL_CMP_OPT_TOTAL_TIMEOUT 12
/* CMP request options: */
#  define OSSL_CMP_OPT_VALIDITY_DAYS 20
#  define OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT 21
#  define OSSL_CMP_OPT_SUBJECTALTNAME_CRITICAL 22
#  define OSSL_CMP_OPT_POLICIES_CRITICAL 23
#  define OSSL_CMP_OPT_POPO_METHOD 24
#  define OSSL_CMP_OPT_IMPLICIT_CONFIRM 25
#  define OSSL_CMP_OPT_DISABLE_CONFIRM 26
#  define OSSL_CMP_OPT_REVOCATION_REASON 27
/* CMP protection options: */
#  define OSSL_CMP_OPT_UNPROTECTED_SEND 30
#  define OSSL_CMP_OPT_UNPROTECTED_ERRORS 31
#  define OSSL_CMP_OPT_OWF_ALGNID 32
#  define OSSL_CMP_OPT_MAC_ALGNID 33
#  define OSSL_CMP_OPT_DIGEST_ALGNID 34
#  define OSSL_CMP_OPT_IGNORE_KEYUSAGE 35
#  define OSSL_CMP_OPT_PERMIT_TA_IN_EXTRACERTS_FOR_IR 36
int OSSL_CMP_CTX_set_option(OSSL_CMP_CTX *ctx, int opt, int val);
int OSSL_CMP_CTX_get_option(const OSSL_CMP_CTX *ctx, int opt);
/* CMP-specific callback for logging and outputting the error queue: */
int OSSL_CMP_CTX_set_log_cb(OSSL_CMP_CTX *ctx, OSSL_CMP_log_cb_t cb);
#  define OSSL_CMP_CTX_set_log_verbosity(ctx, level) \
    OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_LOG_VERBOSITY, level)
void OSSL_CMP_CTX_print_errors(const OSSL_CMP_CTX *ctx);
/* message transfer: */
int OSSL_CMP_CTX_set1_serverPath(OSSL_CMP_CTX *ctx, const char *path);
int OSSL_CMP_CTX_set1_server(OSSL_CMP_CTX *ctx, const char *address);
int OSSL_CMP_CTX_set_serverPort(OSSL_CMP_CTX *ctx, int port);
int OSSL_CMP_CTX_set1_proxy(OSSL_CMP_CTX *ctx, const char *name);
int OSSL_CMP_CTX_set1_no_proxy(OSSL_CMP_CTX *ctx, const char *names);
int OSSL_CMP_CTX_set_http_cb(OSSL_CMP_CTX *ctx, OSSL_HTTP_bio_cb_t cb);
int OSSL_CMP_CTX_set_http_cb_arg(OSSL_CMP_CTX *ctx, void *arg);
void *OSSL_CMP_CTX_get_http_cb_arg(const OSSL_CMP_CTX *ctx);
typedef OSSL_CMP_MSG *(*OSSL_CMP_transfer_cb_t) (OSSL_CMP_CTX *ctx,
                                                 const OSSL_CMP_MSG *req);
int OSSL_CMP_CTX_set_transfer_cb(OSSL_CMP_CTX *ctx, OSSL_CMP_transfer_cb_t cb);
int OSSL_CMP_CTX_set_transfer_cb_arg(OSSL_CMP_CTX *ctx, void *arg);
void *OSSL_CMP_CTX_get_transfer_cb_arg(const OSSL_CMP_CTX *ctx);
/* server authentication: */
int OSSL_CMP_CTX_set1_srvCert(OSSL_CMP_CTX *ctx, X509 *cert);
int OSSL_CMP_CTX_set1_expected_sender(OSSL_CMP_CTX *ctx, const X509_NAME *name);
int OSSL_CMP_CTX_set0_trustedStore(OSSL_CMP_CTX *ctx, X509_STORE *store);
X509_STORE *OSSL_CMP_CTX_get0_trustedStore(const OSSL_CMP_CTX *ctx);
int OSSL_CMP_CTX_set1_untrusted(OSSL_CMP_CTX *ctx, STACK_OF(X509) *certs);
STACK_OF(X509) *OSSL_CMP_CTX_get0_untrusted(const OSSL_CMP_CTX *ctx);
/* client authentication: */
int OSSL_CMP_CTX_set1_cert(OSSL_CMP_CTX *ctx, X509 *cert);
int OSSL_CMP_CTX_build_cert_chain(OSSL_CMP_CTX *ctx, X509_STORE *own_trusted,
                                  STACK_OF(X509) *candidates);
int OSSL_CMP_CTX_set1_pkey(OSSL_CMP_CTX *ctx, EVP_PKEY *pkey);
int OSSL_CMP_CTX_set1_referenceValue(OSSL_CMP_CTX *ctx,
                                     const unsigned char *ref, int len);
int OSSL_CMP_CTX_set1_secretValue(OSSL_CMP_CTX *ctx,
                                  const unsigned char *sec, int len);
/* CMP message header and extra certificates: */
int OSSL_CMP_CTX_set1_recipient(OSSL_CMP_CTX *ctx, const X509_NAME *name);
int OSSL_CMP_CTX_push0_geninfo_ITAV(OSSL_CMP_CTX *ctx, OSSL_CMP_ITAV *itav);
int OSSL_CMP_CTX_reset_geninfo_ITAVs(OSSL_CMP_CTX *ctx);
int OSSL_CMP_CTX_set1_extraCertsOut(OSSL_CMP_CTX *ctx,
                                    STACK_OF(X509) *extraCertsOut);
/* certificate template: */
int OSSL_CMP_CTX_set0_newPkey(OSSL_CMP_CTX *ctx, int priv, EVP_PKEY *pkey);
EVP_PKEY *OSSL_CMP_CTX_get0_newPkey(const OSSL_CMP_CTX *ctx, int priv);
int OSSL_CMP_CTX_set1_issuer(OSSL_CMP_CTX *ctx, const X509_NAME *name);
int OSSL_CMP_CTX_set1_subjectName(OSSL_CMP_CTX *ctx, const X509_NAME *name);
int OSSL_CMP_CTX_push1_subjectAltName(OSSL_CMP_CTX *ctx,
                                      const GENERAL_NAME *name);
int OSSL_CMP_CTX_set0_reqExtensions(OSSL_CMP_CTX *ctx, X509_EXTENSIONS *exts);
int OSSL_CMP_CTX_reqExtensions_have_SAN(OSSL_CMP_CTX *ctx);
int OSSL_CMP_CTX_push0_policy(OSSL_CMP_CTX *ctx, POLICYINFO *pinfo);
int OSSL_CMP_CTX_set1_oldCert(OSSL_CMP_CTX *ctx, X509 *cert);
int OSSL_CMP_CTX_set1_p10CSR(OSSL_CMP_CTX *ctx, const X509_REQ *csr);
/* misc body contents: */
int OSSL_CMP_CTX_push0_genm_ITAV(OSSL_CMP_CTX *ctx, OSSL_CMP_ITAV *itav);
/* certificate confirmation: */
typedef int (*OSSL_CMP_certConf_cb_t) (OSSL_CMP_CTX *ctx, X509 *cert,
                                       int fail_info, const char **txt);
int OSSL_CMP_certConf_cb(OSSL_CMP_CTX *ctx, X509 *cert, int fail_info,
                         const char **text);
int OSSL_CMP_CTX_set_certConf_cb(OSSL_CMP_CTX *ctx, OSSL_CMP_certConf_cb_t cb);
int OSSL_CMP_CTX_set_certConf_cb_arg(OSSL_CMP_CTX *ctx, void *arg);
void *OSSL_CMP_CTX_get_certConf_cb_arg(const OSSL_CMP_CTX *ctx);
/* result fetching: */
int OSSL_CMP_CTX_get_status(const OSSL_CMP_CTX *ctx);
OSSL_CMP_PKIFREETEXT *OSSL_CMP_CTX_get0_statusString(const OSSL_CMP_CTX *ctx);
int OSSL_CMP_CTX_get_failInfoCode(const OSSL_CMP_CTX *ctx);
#  define OSSL_CMP_PKISI_BUFLEN 1024
X509 *OSSL_CMP_CTX_get0_newCert(const OSSL_CMP_CTX *ctx);
STACK_OF(X509) *OSSL_CMP_CTX_get1_newChain(const OSSL_CMP_CTX *ctx);
STACK_OF(X509) *OSSL_CMP_CTX_get1_caPubs(const OSSL_CMP_CTX *ctx);
STACK_OF(X509) *OSSL_CMP_CTX_get1_extraCertsIn(const OSSL_CMP_CTX *ctx);
int OSSL_CMP_CTX_set1_transactionID(OSSL_CMP_CTX *ctx,
                                    const ASN1_OCTET_STRING *id);
int OSSL_CMP_CTX_set1_senderNonce(OSSL_CMP_CTX *ctx,
                                  const ASN1_OCTET_STRING *nonce);

/* from cmp_status.c */
char *OSSL_CMP_CTX_snprint_PKIStatus(const OSSL_CMP_CTX *ctx, char *buf,
                                     size_t bufsize);
char *OSSL_CMP_snprint_PKIStatusInfo(const OSSL_CMP_PKISI *statusInfo,
                                     char *buf, size_t bufsize);
OSSL_CMP_PKISI *
OSSL_CMP_STATUSINFO_new(int status, int fail_info, const char *text);

/* from cmp_hdr.c */
ASN1_OCTET_STRING *OSSL_CMP_HDR_get0_transactionID(const
                                                   OSSL_CMP_PKIHEADER *hdr);
ASN1_OCTET_STRING *OSSL_CMP_HDR_get0_recipNonce(const OSSL_CMP_PKIHEADER *hdr);

/* from cmp_msg.c */
OSSL_CMP_PKIHEADER *OSSL_CMP_MSG_get0_header(const OSSL_CMP_MSG *msg);
int OSSL_CMP_MSG_get_bodytype(const OSSL_CMP_MSG *msg);
int OSSL_CMP_MSG_update_transactionID(OSSL_CMP_CTX *ctx, OSSL_CMP_MSG *msg);
int OSSL_CMP_MSG_update_recipNonce(OSSL_CMP_CTX *ctx, OSSL_CMP_MSG *msg);
OSSL_CRMF_MSG *OSSL_CMP_CTX_setup_CRM(OSSL_CMP_CTX *ctx, int for_KUR, int rid);
OSSL_CMP_MSG *OSSL_CMP_MSG_read(const char *file, OSSL_LIB_CTX *libctx,
                                const char *propq);
int OSSL_CMP_MSG_write(const char *file, const OSSL_CMP_MSG *msg);
OSSL_CMP_MSG *d2i_OSSL_CMP_MSG_bio(BIO *bio, OSSL_CMP_MSG **msg);
int i2d_OSSL_CMP_MSG_bio(BIO *bio, const OSSL_CMP_MSG *msg);

/* from cmp_vfy.c */
int OSSL_CMP_validate_msg(OSSL_CMP_CTX *ctx, const OSSL_CMP_MSG *msg);
int OSSL_CMP_validate_cert_path(const OSSL_CMP_CTX *ctx,
                                X509_STORE *trusted_store, X509 *cert);

/* from cmp_http.c */
OSSL_CMP_MSG *OSSL_CMP_MSG_http_perform(OSSL_CMP_CTX *ctx,
                                        const OSSL_CMP_MSG *req);

/* from cmp_server.c */
typedef struct ossl_cmp_srv_ctx_st OSSL_CMP_SRV_CTX;
OSSL_CMP_MSG *OSSL_CMP_SRV_process_request(OSSL_CMP_SRV_CTX *srv_ctx,
                                           const OSSL_CMP_MSG *req);
OSSL_CMP_MSG * OSSL_CMP_CTX_server_perform(OSSL_CMP_CTX *client_ctx,
                                           const OSSL_CMP_MSG *req);
OSSL_CMP_SRV_CTX *OSSL_CMP_SRV_CTX_new(OSSL_LIB_CTX *libctx, const char *propq);
void OSSL_CMP_SRV_CTX_free(OSSL_CMP_SRV_CTX *srv_ctx);
typedef OSSL_CMP_PKISI *(*OSSL_CMP_SRV_cert_request_cb_t)
    (OSSL_CMP_SRV_CTX *srv_ctx, const OSSL_CMP_MSG *req, int certReqId,
     const OSSL_CRMF_MSG *crm, const X509_REQ *p10cr,
     X509 **certOut, STACK_OF(X509) **chainOut, STACK_OF(X509) **caPubs);
typedef OSSL_CMP_PKISI *(*OSSL_CMP_SRV_rr_cb_t)(OSSL_CMP_SRV_CTX *srv_ctx,
                                                const OSSL_CMP_MSG *req,
                                                const X509_NAME *issuer,
                                                const ASN1_INTEGER *serial);
typedef int (*OSSL_CMP_SRV_genm_cb_t)(OSSL_CMP_SRV_CTX *srv_ctx,
                                      const OSSL_CMP_MSG *req,
                                      const STACK_OF(OSSL_CMP_ITAV) *in,
                                      STACK_OF(OSSL_CMP_ITAV) **out);
typedef void (*OSSL_CMP_SRV_error_cb_t)(OSSL_CMP_SRV_CTX *srv_ctx,
                                        const OSSL_CMP_MSG *req,
                                        const OSSL_CMP_PKISI *statusInfo,
                                        const ASN1_INTEGER *errorCode,
                                        const OSSL_CMP_PKIFREETEXT *errDetails);
typedef int (*OSSL_CMP_SRV_certConf_cb_t)(OSSL_CMP_SRV_CTX *srv_ctx,
                                          const OSSL_CMP_MSG *req,
                                          int certReqId,
                                          const ASN1_OCTET_STRING *certHash,
                                          const OSSL_CMP_PKISI *si);
typedef int (*OSSL_CMP_SRV_pollReq_cb_t)(OSSL_CMP_SRV_CTX *srv_ctx,
                                         const OSSL_CMP_MSG *req, int certReqId,
                                         OSSL_CMP_MSG **certReq,
                                         int64_t *check_after);
int OSSL_CMP_SRV_CTX_init(OSSL_CMP_SRV_CTX *srv_ctx, void *custom_ctx,
                          OSSL_CMP_SRV_cert_request_cb_t process_cert_request,
                          OSSL_CMP_SRV_rr_cb_t process_rr,
                          OSSL_CMP_SRV_genm_cb_t process_genm,
                          OSSL_CMP_SRV_error_cb_t process_error,
                          OSSL_CMP_SRV_certConf_cb_t process_certConf,
                          OSSL_CMP_SRV_pollReq_cb_t process_pollReq);
OSSL_CMP_CTX *OSSL_CMP_SRV_CTX_get0_cmp_ctx(const OSSL_CMP_SRV_CTX *srv_ctx);
void *OSSL_CMP_SRV_CTX_get0_custom_ctx(const OSSL_CMP_SRV_CTX *srv_ctx);
int OSSL_CMP_SRV_CTX_set_send_unprotected_errors(OSSL_CMP_SRV_CTX *srv_ctx,
                                                 int val);
int OSSL_CMP_SRV_CTX_set_accept_unprotected(OSSL_CMP_SRV_CTX *srv_ctx, int val);
int OSSL_CMP_SRV_CTX_set_accept_raverified(OSSL_CMP_SRV_CTX *srv_ctx, int val);
int OSSL_CMP_SRV_CTX_set_grant_implicit_confirm(OSSL_CMP_SRV_CTX *srv_ctx,
                                                int val);

/* from cmp_client.c */
X509 *OSSL_CMP_exec_certreq(OSSL_CMP_CTX *ctx, int req_type,
                            const OSSL_CRMF_MSG *crm);
#  define OSSL_CMP_IR    0
#  define OSSL_CMP_CR    2
#  define OSSL_CMP_P10CR 4
#  define OSSL_CMP_KUR   7
#  define OSSL_CMP_exec_IR_ses(ctx) \
    OSSL_CMP_exec_certreq(ctx, OSSL_CMP_IR, NULL)
#  define OSSL_CMP_exec_CR_ses(ctx) \
    OSSL_CMP_exec_certreq(ctx, OSSL_CMP_CR, NULL)
#  define OSSL_CMP_exec_P10CR_ses(ctx) \
    OSSL_CMP_exec_certreq(ctx, OSSL_CMP_P10CR, NULL)
#  define OSSL_CMP_exec_KUR_ses(ctx) \
    OSSL_CMP_exec_certreq(ctx, OSSL_CMP_KUR, NULL)
int OSSL_CMP_try_certreq(OSSL_CMP_CTX *ctx, int req_type,
                         const OSSL_CRMF_MSG *crm, int *checkAfter);
int OSSL_CMP_exec_RR_ses(OSSL_CMP_CTX *ctx);
STACK_OF(OSSL_CMP_ITAV) *OSSL_CMP_exec_GENM_ses(OSSL_CMP_CTX *ctx);

#  ifdef  __cplusplus
}
#  endif
# endif /* !defined(OPENSSL_NO_CMP) */
#endif /* !defined(OPENSSL_CMP_H) */
                                                                                                                                                                                                                                                                                                                                                             node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/openssl/cms.h           0000664 0000000 0000000 00000102441 14746647661 0030637 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /*
 * WARNING: do not edit!
 * Generated by Makefile from include/openssl/cms.h.in
 *
 * Copyright 2008-2021 The OpenSSL Project Authors. All Rights Reserved.
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 */



#ifndef OPENSSL_CMS_H
# define OPENSSL_CMS_H
# pragma once

# include <openssl/macros.h>
# ifndef OPENSSL_NO_DEPRECATED_3_0
#  define HEADER_CMS_H
# endif

# include <openssl/opensslconf.h>

# ifndef OPENSSL_NO_CMS
# include <openssl/x509.h>
# include <openssl/x509v3.h>
# include <openssl/cmserr.h>
# ifdef __cplusplus
extern "C" {
# endif

typedef struct CMS_ContentInfo_st CMS_ContentInfo;
typedef struct CMS_SignerInfo_st CMS_SignerInfo;
typedef struct CMS_CertificateChoices CMS_CertificateChoices;
typedef struct CMS_RevocationInfoChoice_st CMS_RevocationInfoChoice;
typedef struct CMS_RecipientInfo_st CMS_RecipientInfo;
typedef struct CMS_ReceiptRequest_st CMS_ReceiptRequest;
typedef struct CMS_Receipt_st CMS_Receipt;
typedef struct CMS_RecipientEncryptedKey_st CMS_RecipientEncryptedKey;
typedef struct CMS_OtherKeyAttribute_st CMS_OtherKeyAttribute;

SKM_DEFINE_STACK_OF_INTERNAL(CMS_SignerInfo, CMS_SignerInfo, CMS_SignerInfo)
#define sk_CMS_SignerInfo_num(sk) OPENSSL_sk_num(ossl_check_const_CMS_SignerInfo_sk_type(sk))
#define sk_CMS_SignerInfo_value(sk, idx) ((CMS_SignerInfo *)OPENSSL_sk_value(ossl_check_const_CMS_SignerInfo_sk_type(sk), (idx)))
#define sk_CMS_SignerInfo_new(cmp) ((STACK_OF(CMS_SignerInfo) *)OPENSSL_sk_new(ossl_check_CMS_SignerInfo_compfunc_type(cmp)))
#define sk_CMS_SignerInfo_new_null() ((STACK_OF(CMS_SignerInfo) *)OPENSSL_sk_new_null())
#define sk_CMS_SignerInfo_new_reserve(cmp, n) ((STACK_OF(CMS_SignerInfo) *)OPENSSL_sk_new_reserve(ossl_check_CMS_SignerInfo_compfunc_type(cmp), (n)))
#define sk_CMS_SignerInfo_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_CMS_SignerInfo_sk_type(sk), (n))
#define sk_CMS_SignerInfo_free(sk) OPENSSL_sk_free(ossl_check_CMS_SignerInfo_sk_type(sk))
#define sk_CMS_SignerInfo_zero(sk) OPENSSL_sk_zero(ossl_check_CMS_SignerInfo_sk_type(sk))
#define sk_CMS_SignerInfo_delete(sk, i) ((CMS_SignerInfo *)OPENSSL_sk_delete(ossl_check_CMS_SignerInfo_sk_type(sk), (i)))
#define sk_CMS_SignerInfo_delete_ptr(sk, ptr) ((CMS_SignerInfo *)OPENSSL_sk_delete_ptr(ossl_check_CMS_SignerInfo_sk_type(sk), ossl_check_CMS_SignerInfo_type(ptr)))
#define sk_CMS_SignerInfo_push(sk, ptr) OPENSSL_sk_push(ossl_check_CMS_SignerInfo_sk_type(sk), ossl_check_CMS_SignerInfo_type(ptr))
#define sk_CMS_SignerInfo_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_CMS_SignerInfo_sk_type(sk), ossl_check_CMS_SignerInfo_type(ptr))
#define sk_CMS_SignerInfo_pop(sk) ((CMS_SignerInfo *)OPENSSL_sk_pop(ossl_check_CMS_SignerInfo_sk_type(sk)))
#define sk_CMS_SignerInfo_shift(sk) ((CMS_SignerInfo *)OPENSSL_sk_shift(ossl_check_CMS_SignerInfo_sk_type(sk)))
#define sk_CMS_SignerInfo_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_CMS_SignerInfo_sk_type(sk),ossl_check_CMS_SignerInfo_freefunc_type(freefunc))
#define sk_CMS_SignerInfo_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_CMS_SignerInfo_sk_type(sk), ossl_check_CMS_SignerInfo_type(ptr), (idx))
#define sk_CMS_SignerInfo_set(sk, idx, ptr) ((CMS_SignerInfo *)OPENSSL_sk_set(ossl_check_CMS_SignerInfo_sk_type(sk), (idx), ossl_check_CMS_SignerInfo_type(ptr)))
#define sk_CMS_SignerInfo_find(sk, ptr) OPENSSL_sk_find(ossl_check_CMS_SignerInfo_sk_type(sk), ossl_check_CMS_SignerInfo_type(ptr))
#define sk_CMS_SignerInfo_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_CMS_SignerInfo_sk_type(sk), ossl_check_CMS_SignerInfo_type(ptr))
#define sk_CMS_SignerInfo_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_CMS_SignerInfo_sk_type(sk), ossl_check_CMS_SignerInfo_type(ptr), pnum)
#define sk_CMS_SignerInfo_sort(sk) OPENSSL_sk_sort(ossl_check_CMS_SignerInfo_sk_type(sk))
#define sk_CMS_SignerInfo_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_CMS_SignerInfo_sk_type(sk))
#define sk_CMS_SignerInfo_dup(sk) ((STACK_OF(CMS_SignerInfo) *)OPENSSL_sk_dup(ossl_check_const_CMS_SignerInfo_sk_type(sk)))
#define sk_CMS_SignerInfo_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(CMS_SignerInfo) *)OPENSSL_sk_deep_copy(ossl_check_const_CMS_SignerInfo_sk_type(sk), ossl_check_CMS_SignerInfo_copyfunc_type(copyfunc), ossl_check_CMS_SignerInfo_freefunc_type(freefunc)))
#define sk_CMS_SignerInfo_set_cmp_func(sk, cmp) ((sk_CMS_SignerInfo_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_CMS_SignerInfo_sk_type(sk), ossl_check_CMS_SignerInfo_compfunc_type(cmp)))
SKM_DEFINE_STACK_OF_INTERNAL(CMS_RecipientEncryptedKey, CMS_RecipientEncryptedKey, CMS_RecipientEncryptedKey)
#define sk_CMS_RecipientEncryptedKey_num(sk) OPENSSL_sk_num(ossl_check_const_CMS_RecipientEncryptedKey_sk_type(sk))
#define sk_CMS_RecipientEncryptedKey_value(sk, idx) ((CMS_RecipientEncryptedKey *)OPENSSL_sk_value(ossl_check_const_CMS_RecipientEncryptedKey_sk_type(sk), (idx)))
#define sk_CMS_RecipientEncryptedKey_new(cmp) ((STACK_OF(CMS_RecipientEncryptedKey) *)OPENSSL_sk_new(ossl_check_CMS_RecipientEncryptedKey_compfunc_type(cmp)))
#define sk_CMS_RecipientEncryptedKey_new_null() ((STACK_OF(CMS_RecipientEncryptedKey) *)OPENSSL_sk_new_null())
#define sk_CMS_RecipientEncryptedKey_new_reserve(cmp, n) ((STACK_OF(CMS_RecipientEncryptedKey) *)OPENSSL_sk_new_reserve(ossl_check_CMS_RecipientEncryptedKey_compfunc_type(cmp), (n)))
#define sk_CMS_RecipientEncryptedKey_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_CMS_RecipientEncryptedKey_sk_type(sk), (n))
#define sk_CMS_RecipientEncryptedKey_free(sk) OPENSSL_sk_free(ossl_check_CMS_RecipientEncryptedKey_sk_type(sk))
#define sk_CMS_RecipientEncryptedKey_zero(sk) OPENSSL_sk_zero(ossl_check_CMS_RecipientEncryptedKey_sk_type(sk))
#define sk_CMS_RecipientEncryptedKey_delete(sk, i) ((CMS_RecipientEncryptedKey *)OPENSSL_sk_delete(ossl_check_CMS_RecipientEncryptedKey_sk_type(sk), (i)))
#define sk_CMS_RecipientEncryptedKey_delete_ptr(sk, ptr) ((CMS_RecipientEncryptedKey *)OPENSSL_sk_delete_ptr(ossl_check_CMS_RecipientEncryptedKey_sk_type(sk), ossl_check_CMS_RecipientEncryptedKey_type(ptr)))
#define sk_CMS_RecipientEncryptedKey_push(sk, ptr) OPENSSL_sk_push(ossl_check_CMS_RecipientEncryptedKey_sk_type(sk), ossl_check_CMS_RecipientEncryptedKey_type(ptr))
#define sk_CMS_RecipientEncryptedKey_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_CMS_RecipientEncryptedKey_sk_type(sk), ossl_check_CMS_RecipientEncryptedKey_type(ptr))
#define sk_CMS_RecipientEncryptedKey_pop(sk) ((CMS_RecipientEncryptedKey *)OPENSSL_sk_pop(ossl_check_CMS_RecipientEncryptedKey_sk_type(sk)))
#define sk_CMS_RecipientEncryptedKey_shift(sk) ((CMS_RecipientEncryptedKey *)OPENSSL_sk_shift(ossl_check_CMS_RecipientEncryptedKey_sk_type(sk)))
#define sk_CMS_RecipientEncryptedKey_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_CMS_RecipientEncryptedKey_sk_type(sk),ossl_check_CMS_RecipientEncryptedKey_freefunc_type(freefunc))
#define sk_CMS_RecipientEncryptedKey_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_CMS_RecipientEncryptedKey_sk_type(sk), ossl_check_CMS_RecipientEncryptedKey_type(ptr), (idx))
#define sk_CMS_RecipientEncryptedKey_set(sk, idx, ptr) ((CMS_RecipientEncryptedKey *)OPENSSL_sk_set(ossl_check_CMS_RecipientEncryptedKey_sk_type(sk), (idx), ossl_check_CMS_RecipientEncryptedKey_type(ptr)))
#define sk_CMS_RecipientEncryptedKey_find(sk, ptr) OPENSSL_sk_find(ossl_check_CMS_RecipientEncryptedKey_sk_type(sk), ossl_check_CMS_RecipientEncryptedKey_type(ptr))
#define sk_CMS_RecipientEncryptedKey_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_CMS_RecipientEncryptedKey_sk_type(sk), ossl_check_CMS_RecipientEncryptedKey_type(ptr))
#define sk_CMS_RecipientEncryptedKey_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_CMS_RecipientEncryptedKey_sk_type(sk), ossl_check_CMS_RecipientEncryptedKey_type(ptr), pnum)
#define sk_CMS_RecipientEncryptedKey_sort(sk) OPENSSL_sk_sort(ossl_check_CMS_RecipientEncryptedKey_sk_type(sk))
#define sk_CMS_RecipientEncryptedKey_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_CMS_RecipientEncryptedKey_sk_type(sk))
#define sk_CMS_RecipientEncryptedKey_dup(sk) ((STACK_OF(CMS_RecipientEncryptedKey) *)OPENSSL_sk_dup(ossl_check_const_CMS_RecipientEncryptedKey_sk_type(sk)))
#define sk_CMS_RecipientEncryptedKey_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(CMS_RecipientEncryptedKey) *)OPENSSL_sk_deep_copy(ossl_check_const_CMS_RecipientEncryptedKey_sk_type(sk), ossl_check_CMS_RecipientEncryptedKey_copyfunc_type(copyfunc), ossl_check_CMS_RecipientEncryptedKey_freefunc_type(freefunc)))
#define sk_CMS_RecipientEncryptedKey_set_cmp_func(sk, cmp) ((sk_CMS_RecipientEncryptedKey_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_CMS_RecipientEncryptedKey_sk_type(sk), ossl_check_CMS_RecipientEncryptedKey_compfunc_type(cmp)))
SKM_DEFINE_STACK_OF_INTERNAL(CMS_RecipientInfo, CMS_RecipientInfo, CMS_RecipientInfo)
#define sk_CMS_RecipientInfo_num(sk) OPENSSL_sk_num(ossl_check_const_CMS_RecipientInfo_sk_type(sk))
#define sk_CMS_RecipientInfo_value(sk, idx) ((CMS_RecipientInfo *)OPENSSL_sk_value(ossl_check_const_CMS_RecipientInfo_sk_type(sk), (idx)))
#define sk_CMS_RecipientInfo_new(cmp) ((STACK_OF(CMS_RecipientInfo) *)OPENSSL_sk_new(ossl_check_CMS_RecipientInfo_compfunc_type(cmp)))
#define sk_CMS_RecipientInfo_new_null() ((STACK_OF(CMS_RecipientInfo) *)OPENSSL_sk_new_null())
#define sk_CMS_RecipientInfo_new_reserve(cmp, n) ((STACK_OF(CMS_RecipientInfo) *)OPENSSL_sk_new_reserve(ossl_check_CMS_RecipientInfo_compfunc_type(cmp), (n)))
#define sk_CMS_RecipientInfo_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_CMS_RecipientInfo_sk_type(sk), (n))
#define sk_CMS_RecipientInfo_free(sk) OPENSSL_sk_free(ossl_check_CMS_RecipientInfo_sk_type(sk))
#define sk_CMS_RecipientInfo_zero(sk) OPENSSL_sk_zero(ossl_check_CMS_RecipientInfo_sk_type(sk))
#define sk_CMS_RecipientInfo_delete(sk, i) ((CMS_RecipientInfo *)OPENSSL_sk_delete(ossl_check_CMS_RecipientInfo_sk_type(sk), (i)))
#define sk_CMS_RecipientInfo_delete_ptr(sk, ptr) ((CMS_RecipientInfo *)OPENSSL_sk_delete_ptr(ossl_check_CMS_RecipientInfo_sk_type(sk), ossl_check_CMS_RecipientInfo_type(ptr)))
#define sk_CMS_RecipientInfo_push(sk, ptr) OPENSSL_sk_push(ossl_check_CMS_RecipientInfo_sk_type(sk), ossl_check_CMS_RecipientInfo_type(ptr))
#define sk_CMS_RecipientInfo_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_CMS_RecipientInfo_sk_type(sk), ossl_check_CMS_RecipientInfo_type(ptr))
#define sk_CMS_RecipientInfo_pop(sk) ((CMS_RecipientInfo *)OPENSSL_sk_pop(ossl_check_CMS_RecipientInfo_sk_type(sk)))
#define sk_CMS_RecipientInfo_shift(sk) ((CMS_RecipientInfo *)OPENSSL_sk_shift(ossl_check_CMS_RecipientInfo_sk_type(sk)))
#define sk_CMS_RecipientInfo_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_CMS_RecipientInfo_sk_type(sk),ossl_check_CMS_RecipientInfo_freefunc_type(freefunc))
#define sk_CMS_RecipientInfo_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_CMS_RecipientInfo_sk_type(sk), ossl_check_CMS_RecipientInfo_type(ptr), (idx))
#define sk_CMS_RecipientInfo_set(sk, idx, ptr) ((CMS_RecipientInfo *)OPENSSL_sk_set(ossl_check_CMS_RecipientInfo_sk_type(sk), (idx), ossl_check_CMS_RecipientInfo_type(ptr)))
#define sk_CMS_RecipientInfo_find(sk, ptr) OPENSSL_sk_find(ossl_check_CMS_RecipientInfo_sk_type(sk), ossl_check_CMS_RecipientInfo_type(ptr))
#define sk_CMS_RecipientInfo_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_CMS_RecipientInfo_sk_type(sk), ossl_check_CMS_RecipientInfo_type(ptr))
#define sk_CMS_RecipientInfo_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_CMS_RecipientInfo_sk_type(sk), ossl_check_CMS_RecipientInfo_type(ptr), pnum)
#define sk_CMS_RecipientInfo_sort(sk) OPENSSL_sk_sort(ossl_check_CMS_RecipientInfo_sk_type(sk))
#define sk_CMS_RecipientInfo_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_CMS_RecipientInfo_sk_type(sk))
#define sk_CMS_RecipientInfo_dup(sk) ((STACK_OF(CMS_RecipientInfo) *)OPENSSL_sk_dup(ossl_check_const_CMS_RecipientInfo_sk_type(sk)))
#define sk_CMS_RecipientInfo_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(CMS_RecipientInfo) *)OPENSSL_sk_deep_copy(ossl_check_const_CMS_RecipientInfo_sk_type(sk), ossl_check_CMS_RecipientInfo_copyfunc_type(copyfunc), ossl_check_CMS_RecipientInfo_freefunc_type(freefunc)))
#define sk_CMS_RecipientInfo_set_cmp_func(sk, cmp) ((sk_CMS_RecipientInfo_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_CMS_RecipientInfo_sk_type(sk), ossl_check_CMS_RecipientInfo_compfunc_type(cmp)))
SKM_DEFINE_STACK_OF_INTERNAL(CMS_RevocationInfoChoice, CMS_RevocationInfoChoice, CMS_RevocationInfoChoice)
#define sk_CMS_RevocationInfoChoice_num(sk) OPENSSL_sk_num(ossl_check_const_CMS_RevocationInfoChoice_sk_type(sk))
#define sk_CMS_RevocationInfoChoice_value(sk, idx) ((CMS_RevocationInfoChoice *)OPENSSL_sk_value(ossl_check_const_CMS_RevocationInfoChoice_sk_type(sk), (idx)))
#define sk_CMS_RevocationInfoChoice_new(cmp) ((STACK_OF(CMS_RevocationInfoChoice) *)OPENSSL_sk_new(ossl_check_CMS_RevocationInfoChoice_compfunc_type(cmp)))
#define sk_CMS_RevocationInfoChoice_new_null() ((STACK_OF(CMS_RevocationInfoChoice) *)OPENSSL_sk_new_null())
#define sk_CMS_RevocationInfoChoice_new_reserve(cmp, n) ((STACK_OF(CMS_RevocationInfoChoice) *)OPENSSL_sk_new_reserve(ossl_check_CMS_RevocationInfoChoice_compfunc_type(cmp), (n)))
#define sk_CMS_RevocationInfoChoice_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_CMS_RevocationInfoChoice_sk_type(sk), (n))
#define sk_CMS_RevocationInfoChoice_free(sk) OPENSSL_sk_free(ossl_check_CMS_RevocationInfoChoice_sk_type(sk))
#define sk_CMS_RevocationInfoChoice_zero(sk) OPENSSL_sk_zero(ossl_check_CMS_RevocationInfoChoice_sk_type(sk))
#define sk_CMS_RevocationInfoChoice_delete(sk, i) ((CMS_RevocationInfoChoice *)OPENSSL_sk_delete(ossl_check_CMS_RevocationInfoChoice_sk_type(sk), (i)))
#define sk_CMS_RevocationInfoChoice_delete_ptr(sk, ptr) ((CMS_RevocationInfoChoice *)OPENSSL_sk_delete_ptr(ossl_check_CMS_RevocationInfoChoice_sk_type(sk), ossl_check_CMS_RevocationInfoChoice_type(ptr)))
#define sk_CMS_RevocationInfoChoice_push(sk, ptr) OPENSSL_sk_push(ossl_check_CMS_RevocationInfoChoice_sk_type(sk), ossl_check_CMS_RevocationInfoChoice_type(ptr))
#define sk_CMS_RevocationInfoChoice_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_CMS_RevocationInfoChoice_sk_type(sk), ossl_check_CMS_RevocationInfoChoice_type(ptr))
#define sk_CMS_RevocationInfoChoice_pop(sk) ((CMS_RevocationInfoChoice *)OPENSSL_sk_pop(ossl_check_CMS_RevocationInfoChoice_sk_type(sk)))
#define sk_CMS_RevocationInfoChoice_shift(sk) ((CMS_RevocationInfoChoice *)OPENSSL_sk_shift(ossl_check_CMS_RevocationInfoChoice_sk_type(sk)))
#define sk_CMS_RevocationInfoChoice_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_CMS_RevocationInfoChoice_sk_type(sk),ossl_check_CMS_RevocationInfoChoice_freefunc_type(freefunc))
#define sk_CMS_RevocationInfoChoice_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_CMS_RevocationInfoChoice_sk_type(sk), ossl_check_CMS_RevocationInfoChoice_type(ptr), (idx))
#define sk_CMS_RevocationInfoChoice_set(sk, idx, ptr) ((CMS_RevocationInfoChoice *)OPENSSL_sk_set(ossl_check_CMS_RevocationInfoChoice_sk_type(sk), (idx), ossl_check_CMS_RevocationInfoChoice_type(ptr)))
#define sk_CMS_RevocationInfoChoice_find(sk, ptr) OPENSSL_sk_find(ossl_check_CMS_RevocationInfoChoice_sk_type(sk), ossl_check_CMS_RevocationInfoChoice_type(ptr))
#define sk_CMS_RevocationInfoChoice_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_CMS_RevocationInfoChoice_sk_type(sk), ossl_check_CMS_RevocationInfoChoice_type(ptr))
#define sk_CMS_RevocationInfoChoice_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_CMS_RevocationInfoChoice_sk_type(sk), ossl_check_CMS_RevocationInfoChoice_type(ptr), pnum)
#define sk_CMS_RevocationInfoChoice_sort(sk) OPENSSL_sk_sort(ossl_check_CMS_RevocationInfoChoice_sk_type(sk))
#define sk_CMS_RevocationInfoChoice_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_CMS_RevocationInfoChoice_sk_type(sk))
#define sk_CMS_RevocationInfoChoice_dup(sk) ((STACK_OF(CMS_RevocationInfoChoice) *)OPENSSL_sk_dup(ossl_check_const_CMS_RevocationInfoChoice_sk_type(sk)))
#define sk_CMS_RevocationInfoChoice_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(CMS_RevocationInfoChoice) *)OPENSSL_sk_deep_copy(ossl_check_const_CMS_RevocationInfoChoice_sk_type(sk), ossl_check_CMS_RevocationInfoChoice_copyfunc_type(copyfunc), ossl_check_CMS_RevocationInfoChoice_freefunc_type(freefunc)))
#define sk_CMS_RevocationInfoChoice_set_cmp_func(sk, cmp) ((sk_CMS_RevocationInfoChoice_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_CMS_RevocationInfoChoice_sk_type(sk), ossl_check_CMS_RevocationInfoChoice_compfunc_type(cmp)))


DECLARE_ASN1_FUNCTIONS(CMS_ContentInfo)
DECLARE_ASN1_FUNCTIONS(CMS_ReceiptRequest)
DECLARE_ASN1_PRINT_FUNCTION(CMS_ContentInfo)

CMS_ContentInfo *CMS_ContentInfo_new_ex(OSSL_LIB_CTX *libctx, const char *propq);

# define CMS_SIGNERINFO_ISSUER_SERIAL    0
# define CMS_SIGNERINFO_KEYIDENTIFIER    1

# define CMS_RECIPINFO_NONE              -1
# define CMS_RECIPINFO_TRANS             0
# define CMS_RECIPINFO_AGREE             1
# define CMS_RECIPINFO_KEK               2
# define CMS_RECIPINFO_PASS              3
# define CMS_RECIPINFO_OTHER             4

/* S/MIME related flags */

# define CMS_TEXT                        0x1
# define CMS_NOCERTS                     0x2
# define CMS_NO_CONTENT_VERIFY           0x4
# define CMS_NO_ATTR_VERIFY              0x8
# define CMS_NOSIGS                      \
                        (CMS_NO_CONTENT_VERIFY|CMS_NO_ATTR_VERIFY)
# define CMS_NOINTERN                    0x10
# define CMS_NO_SIGNER_CERT_VERIFY       0x20
# define CMS_NOVERIFY                    0x20
# define CMS_DETACHED                    0x40
# define CMS_BINARY                      0x80
# define CMS_NOATTR                      0x100
# define CMS_NOSMIMECAP                  0x200
# define CMS_NOOLDMIMETYPE               0x400
# define CMS_CRLFEOL                     0x800
# define CMS_STREAM                      0x1000
# define CMS_NOCRL                       0x2000
# define CMS_PARTIAL                     0x4000
# define CMS_REUSE_DIGEST                0x8000
# define CMS_USE_KEYID                   0x10000
# define CMS_DEBUG_DECRYPT               0x20000
# define CMS_KEY_PARAM                   0x40000
# define CMS_ASCIICRLF                   0x80000
# define CMS_CADES                       0x100000
# define CMS_USE_ORIGINATOR_KEYID        0x200000

const ASN1_OBJECT *CMS_get0_type(const CMS_ContentInfo *cms);

BIO *CMS_dataInit(CMS_ContentInfo *cms, BIO *icont);
int CMS_dataFinal(CMS_ContentInfo *cms, BIO *bio);

ASN1_OCTET_STRING **CMS_get0_content(CMS_ContentInfo *cms);
int CMS_is_detached(CMS_ContentInfo *cms);
int CMS_set_detached(CMS_ContentInfo *cms, int detached);

# ifdef OPENSSL_PEM_H
DECLARE_PEM_rw(CMS, CMS_ContentInfo)
# endif
int CMS_stream(unsigned char ***boundary, CMS_ContentInfo *cms);
CMS_ContentInfo *d2i_CMS_bio(BIO *bp, CMS_ContentInfo **cms);
int i2d_CMS_bio(BIO *bp, CMS_ContentInfo *cms);

BIO *BIO_new_CMS(BIO *out, CMS_ContentInfo *cms);
int i2d_CMS_bio_stream(BIO *out, CMS_ContentInfo *cms, BIO *in, int flags);
int PEM_write_bio_CMS_stream(BIO *out, CMS_ContentInfo *cms, BIO *in,
                             int flags);
CMS_ContentInfo *SMIME_read_CMS(BIO *bio, BIO **bcont);
CMS_ContentInfo *SMIME_read_CMS_ex(BIO *bio, int flags, BIO **bcont, CMS_ContentInfo **ci);
int SMIME_write_CMS(BIO *bio, CMS_ContentInfo *cms, BIO *data, int flags);

int CMS_final(CMS_ContentInfo *cms, BIO *data, BIO *dcont,
              unsigned int flags);

CMS_ContentInfo *CMS_sign(X509 *signcert, EVP_PKEY *pkey,
                          STACK_OF(X509) *certs, BIO *data,
                          unsigned int flags);
CMS_ContentInfo *CMS_sign_ex(X509 *signcert, EVP_PKEY *pkey,
                             STACK_OF(X509) *certs, BIO *data,
                             unsigned int flags, OSSL_LIB_CTX *ctx,
                             const char *propq);

CMS_ContentInfo *CMS_sign_receipt(CMS_SignerInfo *si,
                                  X509 *signcert, EVP_PKEY *pkey,
                                  STACK_OF(X509) *certs, unsigned int flags);

int CMS_data(CMS_ContentInfo *cms, BIO *out, unsigned int flags);
CMS_ContentInfo *CMS_data_create(BIO *in, unsigned int flags);
CMS_ContentInfo *CMS_data_create_ex(BIO *in, unsigned int flags,
                                    OSSL_LIB_CTX *ctx, const char *propq);

int CMS_digest_verify(CMS_ContentInfo *cms, BIO *dcont, BIO *out,
                      unsigned int flags);
CMS_ContentInfo *CMS_digest_create(BIO *in, const EVP_MD *md,
                                   unsigned int flags);
CMS_ContentInfo *CMS_digest_create_ex(BIO *in, const EVP_MD *md,
                                      unsigned int flags, OSSL_LIB_CTX *ctx,
                                      const char *propq);

int CMS_EncryptedData_decrypt(CMS_ContentInfo *cms,
                              const unsigned char *key, size_t keylen,
                              BIO *dcont, BIO *out, unsigned int flags);

CMS_ContentInfo *CMS_EncryptedData_encrypt(BIO *in, const EVP_CIPHER *cipher,
                                           const unsigned char *key,
                                           size_t keylen, unsigned int flags);
CMS_ContentInfo *CMS_EncryptedData_encrypt_ex(BIO *in, const EVP_CIPHER *cipher,
                                              const unsigned char *key,
                                              size_t keylen, unsigned int flags,
                                              OSSL_LIB_CTX *ctx,
                                              const char *propq);

int CMS_EncryptedData_set1_key(CMS_ContentInfo *cms, const EVP_CIPHER *ciph,
                               const unsigned char *key, size_t keylen);

int CMS_verify(CMS_ContentInfo *cms, STACK_OF(X509) *certs,
               X509_STORE *store, BIO *dcont, BIO *out, unsigned int flags);

int CMS_verify_receipt(CMS_ContentInfo *rcms, CMS_ContentInfo *ocms,
                       STACK_OF(X509) *certs,
                       X509_STORE *store, unsigned int flags);

STACK_OF(X509) *CMS_get0_signers(CMS_ContentInfo *cms);

CMS_ContentInfo *CMS_encrypt(STACK_OF(X509) *certs, BIO *in,
                             const EVP_CIPHER *cipher, unsigned int flags);
CMS_ContentInfo *CMS_encrypt_ex(STACK_OF(X509) *certs, BIO *in,
                                const EVP_CIPHER *cipher, unsigned int flags,
                                OSSL_LIB_CTX *ctx, const char *propq);

int CMS_decrypt(CMS_ContentInfo *cms, EVP_PKEY *pkey, X509 *cert,
                BIO *dcont, BIO *out, unsigned int flags);

int CMS_decrypt_set1_pkey(CMS_ContentInfo *cms, EVP_PKEY *pk, X509 *cert);
int CMS_decrypt_set1_pkey_and_peer(CMS_ContentInfo *cms, EVP_PKEY *pk,
                                   X509 *cert, X509 *peer);
int CMS_decrypt_set1_key(CMS_ContentInfo *cms,
                         unsigned char *key, size_t keylen,
                         const unsigned char *id, size_t idlen);
int CMS_decrypt_set1_password(CMS_ContentInfo *cms,
                              unsigned char *pass, ossl_ssize_t passlen);

STACK_OF(CMS_RecipientInfo) *CMS_get0_RecipientInfos(CMS_ContentInfo *cms);
int CMS_RecipientInfo_type(CMS_RecipientInfo *ri);
EVP_PKEY_CTX *CMS_RecipientInfo_get0_pkey_ctx(CMS_RecipientInfo *ri);
CMS_ContentInfo *CMS_AuthEnvelopedData_create(const EVP_CIPHER *cipher);
CMS_ContentInfo *
CMS_AuthEnvelopedData_create_ex(const EVP_CIPHER *cipher, OSSL_LIB_CTX *ctx,
                                const char *propq);
CMS_ContentInfo *CMS_EnvelopedData_create(const EVP_CIPHER *cipher);
CMS_ContentInfo *CMS_EnvelopedData_create_ex(const EVP_CIPHER *cipher,
                                             OSSL_LIB_CTX *ctx,
                                             const char *propq);

CMS_RecipientInfo *CMS_add1_recipient_cert(CMS_ContentInfo *cms,
                                           X509 *recip, unsigned int flags);
CMS_RecipientInfo *CMS_add1_recipient(CMS_ContentInfo *cms, X509 *recip,
     EVP_PKEY *originatorPrivKey, X509 * originator, unsigned int flags);
int CMS_RecipientInfo_set0_pkey(CMS_RecipientInfo *ri, EVP_PKEY *pkey);
int CMS_RecipientInfo_ktri_cert_cmp(CMS_RecipientInfo *ri, X509 *cert);
int CMS_RecipientInfo_ktri_get0_algs(CMS_RecipientInfo *ri,
                                     EVP_PKEY **pk, X509 **recip,
                                     X509_ALGOR **palg);
int CMS_RecipientInfo_ktri_get0_signer_id(CMS_RecipientInfo *ri,
                                          ASN1_OCTET_STRING **keyid,
                                          X509_NAME **issuer,
                                          ASN1_INTEGER **sno);

CMS_RecipientInfo *CMS_add0_recipient_key(CMS_ContentInfo *cms, int nid,
                                          unsigned char *key, size_t keylen,
                                          unsigned char *id, size_t idlen,
                                          ASN1_GENERALIZEDTIME *date,
                                          ASN1_OBJECT *otherTypeId,
                                          ASN1_TYPE *otherType);

int CMS_RecipientInfo_kekri_get0_id(CMS_RecipientInfo *ri,
                                    X509_ALGOR **palg,
                                    ASN1_OCTET_STRING **pid,
                                    ASN1_GENERALIZEDTIME **pdate,
                                    ASN1_OBJECT **potherid,
                                    ASN1_TYPE **pothertype);

int CMS_RecipientInfo_set0_key(CMS_RecipientInfo *ri,
                               unsigned char *key, size_t keylen);

int CMS_RecipientInfo_kekri_id_cmp(CMS_RecipientInfo *ri,
                                   const unsigned char *id, size_t idlen);

int CMS_RecipientInfo_set0_password(CMS_RecipientInfo *ri,
                                    unsigned char *pass,
                                    ossl_ssize_t passlen);

CMS_RecipientInfo *CMS_add0_recipient_password(CMS_ContentInfo *cms,
                                               int iter, int wrap_nid,
                                               int pbe_nid,
                                               unsigned char *pass,
                                               ossl_ssize_t passlen,
                                               const EVP_CIPHER *kekciph);

int CMS_RecipientInfo_decrypt(CMS_ContentInfo *cms, CMS_RecipientInfo *ri);
int CMS_RecipientInfo_encrypt(const CMS_ContentInfo *cms, CMS_RecipientInfo *ri);

int CMS_uncompress(CMS_ContentInfo *cms, BIO *dcont, BIO *out,
                   unsigned int flags);
CMS_ContentInfo *CMS_compress(BIO *in, int comp_nid, unsigned int flags);

int CMS_set1_eContentType(CMS_ContentInfo *cms, const ASN1_OBJECT *oid);
const ASN1_OBJECT *CMS_get0_eContentType(CMS_ContentInfo *cms);

CMS_CertificateChoices *CMS_add0_CertificateChoices(CMS_ContentInfo *cms);
int CMS_add0_cert(CMS_ContentInfo *cms, X509 *cert);
int CMS_add1_cert(CMS_ContentInfo *cms, X509 *cert);
STACK_OF(X509) *CMS_get1_certs(CMS_ContentInfo *cms);

CMS_RevocationInfoChoice *CMS_add0_RevocationInfoChoice(CMS_ContentInfo *cms);
int CMS_add0_crl(CMS_ContentInfo *cms, X509_CRL *crl);
int CMS_add1_crl(CMS_ContentInfo *cms, X509_CRL *crl);
STACK_OF(X509_CRL) *CMS_get1_crls(CMS_ContentInfo *cms);

int CMS_SignedData_init(CMS_ContentInfo *cms);
CMS_SignerInfo *CMS_add1_signer(CMS_ContentInfo *cms,
                                X509 *signer, EVP_PKEY *pk, const EVP_MD *md,
                                unsigned int flags);
EVP_PKEY_CTX *CMS_SignerInfo_get0_pkey_ctx(CMS_SignerInfo *si);
EVP_MD_CTX *CMS_SignerInfo_get0_md_ctx(CMS_SignerInfo *si);
STACK_OF(CMS_SignerInfo) *CMS_get0_SignerInfos(CMS_ContentInfo *cms);

void CMS_SignerInfo_set1_signer_cert(CMS_SignerInfo *si, X509 *signer);
int CMS_SignerInfo_get0_signer_id(CMS_SignerInfo *si,
                                  ASN1_OCTET_STRING **keyid,
                                  X509_NAME **issuer, ASN1_INTEGER **sno);
int CMS_SignerInfo_cert_cmp(CMS_SignerInfo *si, X509 *cert);
int CMS_set1_signers_certs(CMS_ContentInfo *cms, STACK_OF(X509) *certs,
                           unsigned int flags);
void CMS_SignerInfo_get0_algs(CMS_SignerInfo *si, EVP_PKEY **pk,
                              X509 **signer, X509_ALGOR **pdig,
                              X509_ALGOR **psig);
ASN1_OCTET_STRING *CMS_SignerInfo_get0_signature(CMS_SignerInfo *si);
int CMS_SignerInfo_sign(CMS_SignerInfo *si);
int CMS_SignerInfo_verify(CMS_SignerInfo *si);
int CMS_SignerInfo_verify_content(CMS_SignerInfo *si, BIO *chain);

int CMS_add_smimecap(CMS_SignerInfo *si, STACK_OF(X509_ALGOR) *algs);
int CMS_add_simple_smimecap(STACK_OF(X509_ALGOR) **algs,
                            int algnid, int keysize);
int CMS_add_standard_smimecap(STACK_OF(X509_ALGOR) **smcap);

int CMS_signed_get_attr_count(const CMS_SignerInfo *si);
int CMS_signed_get_attr_by_NID(const CMS_SignerInfo *si, int nid,
                               int lastpos);
int CMS_signed_get_attr_by_OBJ(const CMS_SignerInfo *si, const ASN1_OBJECT *obj,
                               int lastpos);
X509_ATTRIBUTE *CMS_signed_get_attr(const CMS_SignerInfo *si, int loc);
X509_ATTRIBUTE *CMS_signed_delete_attr(CMS_SignerInfo *si, int loc);
int CMS_signed_add1_attr(CMS_SignerInfo *si, X509_ATTRIBUTE *attr);
int CMS_signed_add1_attr_by_OBJ(CMS_SignerInfo *si,
                                const ASN1_OBJECT *obj, int type,
                                const void *bytes, int len);
int CMS_signed_add1_attr_by_NID(CMS_SignerInfo *si,
                                int nid, int type,
                                const void *bytes, int len);
int CMS_signed_add1_attr_by_txt(CMS_SignerInfo *si,
                                const char *attrname, int type,
                                const void *bytes, int len);
void *CMS_signed_get0_data_by_OBJ(const CMS_SignerInfo *si,
                                  const ASN1_OBJECT *oid,
                                  int lastpos, int type);

int CMS_unsigned_get_attr_count(const CMS_SignerInfo *si);
int CMS_unsigned_get_attr_by_NID(const CMS_SignerInfo *si, int nid,
                                 int lastpos);
int CMS_unsigned_get_attr_by_OBJ(const CMS_SignerInfo *si,
                                 const ASN1_OBJECT *obj, int lastpos);
X509_ATTRIBUTE *CMS_unsigned_get_attr(const CMS_SignerInfo *si, int loc);
X509_ATTRIBUTE *CMS_unsigned_delete_attr(CMS_SignerInfo *si, int loc);
int CMS_unsigned_add1_attr(CMS_SignerInfo *si, X509_ATTRIBUTE *attr);
int CMS_unsigned_add1_attr_by_OBJ(CMS_SignerInfo *si,
                                  const ASN1_OBJECT *obj, int type,
                                  const void *bytes, int len);
int CMS_unsigned_add1_attr_by_NID(CMS_SignerInfo *si,
                                  int nid, int type,
                                  const void *bytes, int len);
int CMS_unsigned_add1_attr_by_txt(CMS_SignerInfo *si,
                                  const char *attrname, int type,
                                  const void *bytes, int len);
void *CMS_unsigned_get0_data_by_OBJ(CMS_SignerInfo *si, ASN1_OBJECT *oid,
                                    int lastpos, int type);

int CMS_get1_ReceiptRequest(CMS_SignerInfo *si, CMS_ReceiptRequest **prr);
CMS_ReceiptRequest *CMS_ReceiptRequest_create0(
    unsigned char *id, int idlen, int allorfirst,
    STACK_OF(GENERAL_NAMES) *receiptList,
    STACK_OF(GENERAL_NAMES) *receiptsTo);
CMS_ReceiptRequest *CMS_ReceiptRequest_create0_ex(
    unsigned char *id, int idlen, int allorfirst,
    STACK_OF(GENERAL_NAMES) *receiptList,
    STACK_OF(GENERAL_NAMES) *receiptsTo,
    OSSL_LIB_CTX *ctx);

int CMS_add1_ReceiptRequest(CMS_SignerInfo *si, CMS_ReceiptRequest *rr);
void CMS_ReceiptRequest_get0_values(CMS_ReceiptRequest *rr,
                                    ASN1_STRING **pcid,
                                    int *pallorfirst,
                                    STACK_OF(GENERAL_NAMES) **plist,
                                    STACK_OF(GENERAL_NAMES) **prto);
int CMS_RecipientInfo_kari_get0_alg(CMS_RecipientInfo *ri,
                                    X509_ALGOR **palg,
                                    ASN1_OCTET_STRING **pukm);
STACK_OF(CMS_RecipientEncryptedKey)
*CMS_RecipientInfo_kari_get0_reks(CMS_RecipientInfo *ri);

int CMS_RecipientInfo_kari_get0_orig_id(CMS_RecipientInfo *ri,
                                        X509_ALGOR **pubalg,
                                        ASN1_BIT_STRING **pubkey,
                                        ASN1_OCTET_STRING **keyid,
                                        X509_NAME **issuer,
                                        ASN1_INTEGER **sno);

int CMS_RecipientInfo_kari_orig_id_cmp(CMS_RecipientInfo *ri, X509 *cert);

int CMS_RecipientEncryptedKey_get0_id(CMS_RecipientEncryptedKey *rek,
                                      ASN1_OCTET_STRING **keyid,
                                      ASN1_GENERALIZEDTIME **tm,
                                      CMS_OtherKeyAttribute **other,
                                      X509_NAME **issuer, ASN1_INTEGER **sno);
int CMS_RecipientEncryptedKey_cert_cmp(CMS_RecipientEncryptedKey *rek,
                                       X509 *cert);
int CMS_RecipientInfo_kari_set0_pkey(CMS_RecipientInfo *ri, EVP_PKEY *pk);
int CMS_RecipientInfo_kari_set0_pkey_and_peer(CMS_RecipientInfo *ri, EVP_PKEY *pk, X509 *peer);
EVP_CIPHER_CTX *CMS_RecipientInfo_kari_get0_ctx(CMS_RecipientInfo *ri);
int CMS_RecipientInfo_kari_decrypt(CMS_ContentInfo *cms,
                                   CMS_RecipientInfo *ri,
                                   CMS_RecipientEncryptedKey *rek);

int CMS_SharedInfo_encode(unsigned char **pder, X509_ALGOR *kekalg,
                          ASN1_OCTET_STRING *ukm, int keylen);

/* Backward compatibility for spelling errors. */
# define CMS_R_UNKNOWN_DIGEST_ALGORITM CMS_R_UNKNOWN_DIGEST_ALGORITHM
# define CMS_R_UNSUPPORTED_RECPIENTINFO_TYPE \
    CMS_R_UNSUPPORTED_RECIPIENTINFO_TYPE

#  ifdef  __cplusplus
}
#  endif
# endif
#endif
                                                                                                                                                                                                                               node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/openssl/conf.h          0000664 0000000 0000000 00000024365 14746647661 0031012 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /*
 * WARNING: do not edit!
 * Generated by Makefile from include/openssl/conf.h.in
 *
 * Copyright 1995-2021 The OpenSSL Project Authors. All Rights Reserved.
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 */



#ifndef  OPENSSL_CONF_H
# define OPENSSL_CONF_H
# pragma once

# include <openssl/macros.h>
# ifndef OPENSSL_NO_DEPRECATED_3_0
#  define HEADER_CONF_H
# endif

# include <openssl/bio.h>
# include <openssl/lhash.h>
# include <openssl/safestack.h>
# include <openssl/e_os2.h>
# include <openssl/types.h>
# include <openssl/conferr.h>

#ifdef  __cplusplus
extern "C" {
#endif

typedef struct {
    char *section;
    char *name;
    char *value;
} CONF_VALUE;

SKM_DEFINE_STACK_OF_INTERNAL(CONF_VALUE, CONF_VALUE, CONF_VALUE)
#define sk_CONF_VALUE_num(sk) OPENSSL_sk_num(ossl_check_const_CONF_VALUE_sk_type(sk))
#define sk_CONF_VALUE_value(sk, idx) ((CONF_VALUE *)OPENSSL_sk_value(ossl_check_const_CONF_VALUE_sk_type(sk), (idx)))
#define sk_CONF_VALUE_new(cmp) ((STACK_OF(CONF_VALUE) *)OPENSSL_sk_new(ossl_check_CONF_VALUE_compfunc_type(cmp)))
#define sk_CONF_VALUE_new_null() ((STACK_OF(CONF_VALUE) *)OPENSSL_sk_new_null())
#define sk_CONF_VALUE_new_reserve(cmp, n) ((STACK_OF(CONF_VALUE) *)OPENSSL_sk_new_reserve(ossl_check_CONF_VALUE_compfunc_type(cmp), (n)))
#define sk_CONF_VALUE_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_CONF_VALUE_sk_type(sk), (n))
#define sk_CONF_VALUE_free(sk) OPENSSL_sk_free(ossl_check_CONF_VALUE_sk_type(sk))
#define sk_CONF_VALUE_zero(sk) OPENSSL_sk_zero(ossl_check_CONF_VALUE_sk_type(sk))
#define sk_CONF_VALUE_delete(sk, i) ((CONF_VALUE *)OPENSSL_sk_delete(ossl_check_CONF_VALUE_sk_type(sk), (i)))
#define sk_CONF_VALUE_delete_ptr(sk, ptr) ((CONF_VALUE *)OPENSSL_sk_delete_ptr(ossl_check_CONF_VALUE_sk_type(sk), ossl_check_CONF_VALUE_type(ptr)))
#define sk_CONF_VALUE_push(sk, ptr) OPENSSL_sk_push(ossl_check_CONF_VALUE_sk_type(sk), ossl_check_CONF_VALUE_type(ptr))
#define sk_CONF_VALUE_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_CONF_VALUE_sk_type(sk), ossl_check_CONF_VALUE_type(ptr))
#define sk_CONF_VALUE_pop(sk) ((CONF_VALUE *)OPENSSL_sk_pop(ossl_check_CONF_VALUE_sk_type(sk)))
#define sk_CONF_VALUE_shift(sk) ((CONF_VALUE *)OPENSSL_sk_shift(ossl_check_CONF_VALUE_sk_type(sk)))
#define sk_CONF_VALUE_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_CONF_VALUE_sk_type(sk),ossl_check_CONF_VALUE_freefunc_type(freefunc))
#define sk_CONF_VALUE_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_CONF_VALUE_sk_type(sk), ossl_check_CONF_VALUE_type(ptr), (idx))
#define sk_CONF_VALUE_set(sk, idx, ptr) ((CONF_VALUE *)OPENSSL_sk_set(ossl_check_CONF_VALUE_sk_type(sk), (idx), ossl_check_CONF_VALUE_type(ptr)))
#define sk_CONF_VALUE_find(sk, ptr) OPENSSL_sk_find(ossl_check_CONF_VALUE_sk_type(sk), ossl_check_CONF_VALUE_type(ptr))
#define sk_CONF_VALUE_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_CONF_VALUE_sk_type(sk), ossl_check_CONF_VALUE_type(ptr))
#define sk_CONF_VALUE_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_CONF_VALUE_sk_type(sk), ossl_check_CONF_VALUE_type(ptr), pnum)
#define sk_CONF_VALUE_sort(sk) OPENSSL_sk_sort(ossl_check_CONF_VALUE_sk_type(sk))
#define sk_CONF_VALUE_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_CONF_VALUE_sk_type(sk))
#define sk_CONF_VALUE_dup(sk) ((STACK_OF(CONF_VALUE) *)OPENSSL_sk_dup(ossl_check_const_CONF_VALUE_sk_type(sk)))
#define sk_CONF_VALUE_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(CONF_VALUE) *)OPENSSL_sk_deep_copy(ossl_check_const_CONF_VALUE_sk_type(sk), ossl_check_CONF_VALUE_copyfunc_type(copyfunc), ossl_check_CONF_VALUE_freefunc_type(freefunc)))
#define sk_CONF_VALUE_set_cmp_func(sk, cmp) ((sk_CONF_VALUE_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_CONF_VALUE_sk_type(sk), ossl_check_CONF_VALUE_compfunc_type(cmp)))
DEFINE_LHASH_OF_INTERNAL(CONF_VALUE);
#define lh_CONF_VALUE_new(hfn, cmp) ((LHASH_OF(CONF_VALUE) *)OPENSSL_LH_new(ossl_check_CONF_VALUE_lh_hashfunc_type(hfn), ossl_check_CONF_VALUE_lh_compfunc_type(cmp)))
#define lh_CONF_VALUE_free(lh) OPENSSL_LH_free(ossl_check_CONF_VALUE_lh_type(lh))
#define lh_CONF_VALUE_flush(lh) OPENSSL_LH_flush(ossl_check_CONF_VALUE_lh_type(lh))
#define lh_CONF_VALUE_insert(lh, ptr) ((CONF_VALUE *)OPENSSL_LH_insert(ossl_check_CONF_VALUE_lh_type(lh), ossl_check_CONF_VALUE_lh_plain_type(ptr)))
#define lh_CONF_VALUE_delete(lh, ptr) ((CONF_VALUE *)OPENSSL_LH_delete(ossl_check_CONF_VALUE_lh_type(lh), ossl_check_const_CONF_VALUE_lh_plain_type(ptr)))
#define lh_CONF_VALUE_retrieve(lh, ptr) ((CONF_VALUE *)OPENSSL_LH_retrieve(ossl_check_CONF_VALUE_lh_type(lh), ossl_check_const_CONF_VALUE_lh_plain_type(ptr)))
#define lh_CONF_VALUE_error(lh) OPENSSL_LH_error(ossl_check_CONF_VALUE_lh_type(lh))
#define lh_CONF_VALUE_num_items(lh) OPENSSL_LH_num_items(ossl_check_CONF_VALUE_lh_type(lh))
#define lh_CONF_VALUE_node_stats_bio(lh, out) OPENSSL_LH_node_stats_bio(ossl_check_const_CONF_VALUE_lh_type(lh), out)
#define lh_CONF_VALUE_node_usage_stats_bio(lh, out) OPENSSL_LH_node_usage_stats_bio(ossl_check_const_CONF_VALUE_lh_type(lh), out)
#define lh_CONF_VALUE_stats_bio(lh, out) OPENSSL_LH_stats_bio(ossl_check_const_CONF_VALUE_lh_type(lh), out)
#define lh_CONF_VALUE_get_down_load(lh) OPENSSL_LH_get_down_load(ossl_check_CONF_VALUE_lh_type(lh))
#define lh_CONF_VALUE_set_down_load(lh, dl) OPENSSL_LH_set_down_load(ossl_check_CONF_VALUE_lh_type(lh), dl)
#define lh_CONF_VALUE_doall(lh, dfn) OPENSSL_LH_doall(ossl_check_CONF_VALUE_lh_type(lh), ossl_check_CONF_VALUE_lh_doallfunc_type(dfn))


struct conf_st;
struct conf_method_st;
typedef struct conf_method_st CONF_METHOD;

# ifndef OPENSSL_NO_DEPRECATED_3_0
#  include <openssl/conftypes.h>
# endif

/* Module definitions */
typedef struct conf_imodule_st CONF_IMODULE;
typedef struct conf_module_st CONF_MODULE;

STACK_OF(CONF_MODULE);
STACK_OF(CONF_IMODULE);

/* DSO module function typedefs */
typedef int conf_init_func (CONF_IMODULE *md, const CONF *cnf);
typedef void conf_finish_func (CONF_IMODULE *md);

# define CONF_MFLAGS_IGNORE_ERRORS       0x1
# define CONF_MFLAGS_IGNORE_RETURN_CODES 0x2
# define CONF_MFLAGS_SILENT              0x4
# define CONF_MFLAGS_NO_DSO              0x8
# define CONF_MFLAGS_IGNORE_MISSING_FILE 0x10
# define CONF_MFLAGS_DEFAULT_SECTION     0x20

int CONF_set_default_method(CONF_METHOD *meth);
void CONF_set_nconf(CONF *conf, LHASH_OF(CONF_VALUE) *hash);
LHASH_OF(CONF_VALUE) *CONF_load(LHASH_OF(CONF_VALUE) *conf, const char *file,
                                long *eline);
# ifndef OPENSSL_NO_STDIO
LHASH_OF(CONF_VALUE) *CONF_load_fp(LHASH_OF(CONF_VALUE) *conf, FILE *fp,
                                   long *eline);
# endif
LHASH_OF(CONF_VALUE) *CONF_load_bio(LHASH_OF(CONF_VALUE) *conf, BIO *bp,
                                    long *eline);
STACK_OF(CONF_VALUE) *CONF_get_section(LHASH_OF(CONF_VALUE) *conf,
                                       const char *section);
char *CONF_get_string(LHASH_OF(CONF_VALUE) *conf, const char *group,
                      const char *name);
long CONF_get_number(LHASH_OF(CONF_VALUE) *conf, const char *group,
                     const char *name);
void CONF_free(LHASH_OF(CONF_VALUE) *conf);
#ifndef OPENSSL_NO_STDIO
int CONF_dump_fp(LHASH_OF(CONF_VALUE) *conf, FILE *out);
#endif
int CONF_dump_bio(LHASH_OF(CONF_VALUE) *conf, BIO *out);
#ifndef OPENSSL_NO_DEPRECATED_1_1_0
OSSL_DEPRECATEDIN_1_1_0 void OPENSSL_config(const char *config_name);
#endif

#ifndef OPENSSL_NO_DEPRECATED_1_1_0
# define OPENSSL_no_config() \
    OPENSSL_init_crypto(OPENSSL_INIT_NO_LOAD_CONFIG, NULL)
#endif

/*
 * New conf code.  The semantics are different from the functions above. If
 * that wasn't the case, the above functions would have been replaced
 */

CONF *NCONF_new_ex(OSSL_LIB_CTX *libctx, CONF_METHOD *meth);
OSSL_LIB_CTX *NCONF_get0_libctx(const CONF *conf);
CONF *NCONF_new(CONF_METHOD *meth);
CONF_METHOD *NCONF_default(void);
#ifndef OPENSSL_NO_DEPRECATED_3_0
OSSL_DEPRECATEDIN_3_0 CONF_METHOD *NCONF_WIN32(void);
#endif
void NCONF_free(CONF *conf);
void NCONF_free_data(CONF *conf);

int NCONF_load(CONF *conf, const char *file, long *eline);
# ifndef OPENSSL_NO_STDIO
int NCONF_load_fp(CONF *conf, FILE *fp, long *eline);
# endif
int NCONF_load_bio(CONF *conf, BIO *bp, long *eline);
STACK_OF(OPENSSL_CSTRING) *NCONF_get_section_names(const CONF *conf);
STACK_OF(CONF_VALUE) *NCONF_get_section(const CONF *conf,
                                        const char *section);
char *NCONF_get_string(const CONF *conf, const char *group, const char *name);
int NCONF_get_number_e(const CONF *conf, const char *group, const char *name,
                       long *result);
#ifndef OPENSSL_NO_STDIO
int NCONF_dump_fp(const CONF *conf, FILE *out);
#endif
int NCONF_dump_bio(const CONF *conf, BIO *out);

#define NCONF_get_number(c,g,n,r) NCONF_get_number_e(c,g,n,r)

/* Module functions */

int CONF_modules_load(const CONF *cnf, const char *appname,
                      unsigned long flags);
int CONF_modules_load_file_ex(OSSL_LIB_CTX *libctx, const char *filename,
                              const char *appname, unsigned long flags);
int CONF_modules_load_file(const char *filename, const char *appname,
                           unsigned long flags);
void CONF_modules_unload(int all);
void CONF_modules_finish(void);
#ifndef OPENSSL_NO_DEPRECATED_1_1_0
# define CONF_modules_free() while(0) continue
#endif
int CONF_module_add(const char *name, conf_init_func *ifunc,
                    conf_finish_func *ffunc);

const char *CONF_imodule_get_name(const CONF_IMODULE *md);
const char *CONF_imodule_get_value(const CONF_IMODULE *md);
void *CONF_imodule_get_usr_data(const CONF_IMODULE *md);
void CONF_imodule_set_usr_data(CONF_IMODULE *md, void *usr_data);
CONF_MODULE *CONF_imodule_get_module(const CONF_IMODULE *md);
unsigned long CONF_imodule_get_flags(const CONF_IMODULE *md);
void CONF_imodule_set_flags(CONF_IMODULE *md, unsigned long flags);
void *CONF_module_get_usr_data(CONF_MODULE *pmod);
void CONF_module_set_usr_data(CONF_MODULE *pmod, void *usr_data);

char *CONF_get1_default_config_file(void);

int CONF_parse_list(const char *list, int sep, int nospc,
                    int (*list_cb) (const char *elem, int len, void *usr),
                    void *arg);

void OPENSSL_load_builtin_modules(void);


# ifdef  __cplusplus
}
# endif
#endif
                                                                                                                                                                                                                                                                           node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/openssl/configuration.h 0000664 0000000 0000000 00000006012 14746647661 0032721 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /*
 * WARNING: do not edit!
 * Generated by configdata.pm from Configurations/common0.tmpl, Configurations/unix-Makefile.tmpl
 * via Makefile.in
 *
 * Copyright 2016-2021 The OpenSSL Project Authors. All Rights Reserved.
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 */

#ifndef OPENSSL_CONFIGURATION_H
# define OPENSSL_CONFIGURATION_H
# pragma once

# ifdef  __cplusplus
extern "C" {
# endif

# ifdef OPENSSL_ALGORITHM_DEFINES
#  error OPENSSL_ALGORITHM_DEFINES no longer supported
# endif

/*
 * OpenSSL was configured with the following options:
 */

# define OPENSSL_CONFIGURED_API 30000
# ifndef OPENSSL_RAND_SEED_OS
#  define OPENSSL_RAND_SEED_OS
# endif
# ifndef OPENSSL_THREADS
#  define OPENSSL_THREADS
# endif
# ifndef OPENSSL_NO_AFALGENG
#  define OPENSSL_NO_AFALGENG
# endif
# ifndef OPENSSL_NO_ASAN
#  define OPENSSL_NO_ASAN
# endif
# ifndef OPENSSL_NO_COMP
#  define OPENSSL_NO_COMP
# endif
# ifndef OPENSSL_NO_CRYPTO_MDEBUG
#  define OPENSSL_NO_CRYPTO_MDEBUG
# endif
# ifndef OPENSSL_NO_CRYPTO_MDEBUG_BACKTRACE
#  define OPENSSL_NO_CRYPTO_MDEBUG_BACKTRACE
# endif
# ifndef OPENSSL_NO_DEVCRYPTOENG
#  define OPENSSL_NO_DEVCRYPTOENG
# endif
# ifndef OPENSSL_NO_EC_NISTP_64_GCC_128
#  define OPENSSL_NO_EC_NISTP_64_GCC_128
# endif
# ifndef OPENSSL_NO_EGD
#  define OPENSSL_NO_EGD
# endif
# ifndef OPENSSL_NO_EXTERNAL_TESTS
#  define OPENSSL_NO_EXTERNAL_TESTS
# endif
# ifndef OPENSSL_NO_FUZZ_AFL
#  define OPENSSL_NO_FUZZ_AFL
# endif
# ifndef OPENSSL_NO_FUZZ_LIBFUZZER
#  define OPENSSL_NO_FUZZ_LIBFUZZER
# endif
# ifndef OPENSSL_NO_KTLS
#  define OPENSSL_NO_KTLS
# endif
# ifndef OPENSSL_NO_LOADERENG
#  define OPENSSL_NO_LOADERENG
# endif
# ifndef OPENSSL_NO_MD2
#  define OPENSSL_NO_MD2
# endif
# ifndef OPENSSL_NO_MSAN
#  define OPENSSL_NO_MSAN
# endif
# ifndef OPENSSL_NO_RC5
#  define OPENSSL_NO_RC5
# endif
# ifndef OPENSSL_NO_SCTP
#  define OPENSSL_NO_SCTP
# endif
# ifndef OPENSSL_NO_SSL3
#  define OPENSSL_NO_SSL3
# endif
# ifndef OPENSSL_NO_SSL3_METHOD
#  define OPENSSL_NO_SSL3_METHOD
# endif
# ifndef OPENSSL_NO_TRACE
#  define OPENSSL_NO_TRACE
# endif
# ifndef OPENSSL_NO_UBSAN
#  define OPENSSL_NO_UBSAN
# endif
# ifndef OPENSSL_NO_UNIT_TEST
#  define OPENSSL_NO_UNIT_TEST
# endif
# ifndef OPENSSL_NO_UPLINK
#  define OPENSSL_NO_UPLINK
# endif
# ifndef OPENSSL_NO_WEAK_SSL_CIPHERS
#  define OPENSSL_NO_WEAK_SSL_CIPHERS
# endif
# ifndef OPENSSL_NO_DYNAMIC_ENGINE
#  define OPENSSL_NO_DYNAMIC_ENGINE
# endif


/* Generate 80386 code? */
# undef I386_ONLY

/*
 * The following are cipher-specific, but are part of the public API.
 */
# if !defined(OPENSSL_SYS_UEFI)
#  undef BN_LLONG
/* Only one for the following should be defined */
#  define SIXTY_FOUR_BIT_LONG
#  undef SIXTY_FOUR_BIT
#  undef THIRTY_TWO_BIT
# endif

# define RC4_INT unsigned int

# ifdef  __cplusplus
}
# endif

#endif                          /* OPENSSL_CONFIGURATION_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/openssl/crmf.h          0000664 0000000 0000000 00000034464 14746647661 0031015 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /*-
 * WARNING: do not edit!
 * Generated by Makefile from include/openssl/crmf.h.in
 *
 * Copyright 2007-2021 The OpenSSL Project Authors. All Rights Reserved.
 * Copyright Nokia 2007-2019
 * Copyright Siemens AG 2015-2019
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 *
 * CRMF (RFC 4211) implementation by M. Peylo, M. Viljanen, and D. von Oheimb.
 */



#ifndef OPENSSL_CRMF_H
# define OPENSSL_CRMF_H

# include <openssl/opensslconf.h>

# ifndef OPENSSL_NO_CRMF
#  include <openssl/opensslv.h>
#  include <openssl/safestack.h>
#  include <openssl/crmferr.h>
#  include <openssl/x509v3.h> /* for GENERAL_NAME etc. */

/* explicit #includes not strictly needed since implied by the above: */
#  include <openssl/types.h>
#  include <openssl/x509.h>

#  ifdef __cplusplus
extern "C" {
#  endif

#  define OSSL_CRMF_POPOPRIVKEY_THISMESSAGE          0
#  define OSSL_CRMF_POPOPRIVKEY_SUBSEQUENTMESSAGE    1
#  define OSSL_CRMF_POPOPRIVKEY_DHMAC                2
#  define OSSL_CRMF_POPOPRIVKEY_AGREEMAC             3
#  define OSSL_CRMF_POPOPRIVKEY_ENCRYPTEDKEY         4

#  define OSSL_CRMF_SUBSEQUENTMESSAGE_ENCRCERT       0
#  define OSSL_CRMF_SUBSEQUENTMESSAGE_CHALLENGERESP  1

typedef struct ossl_crmf_encryptedvalue_st OSSL_CRMF_ENCRYPTEDVALUE;
DECLARE_ASN1_FUNCTIONS(OSSL_CRMF_ENCRYPTEDVALUE)
typedef struct ossl_crmf_msg_st OSSL_CRMF_MSG;
DECLARE_ASN1_FUNCTIONS(OSSL_CRMF_MSG)
DECLARE_ASN1_DUP_FUNCTION(OSSL_CRMF_MSG)
SKM_DEFINE_STACK_OF_INTERNAL(OSSL_CRMF_MSG, OSSL_CRMF_MSG, OSSL_CRMF_MSG)
#define sk_OSSL_CRMF_MSG_num(sk) OPENSSL_sk_num(ossl_check_const_OSSL_CRMF_MSG_sk_type(sk))
#define sk_OSSL_CRMF_MSG_value(sk, idx) ((OSSL_CRMF_MSG *)OPENSSL_sk_value(ossl_check_const_OSSL_CRMF_MSG_sk_type(sk), (idx)))
#define sk_OSSL_CRMF_MSG_new(cmp) ((STACK_OF(OSSL_CRMF_MSG) *)OPENSSL_sk_new(ossl_check_OSSL_CRMF_MSG_compfunc_type(cmp)))
#define sk_OSSL_CRMF_MSG_new_null() ((STACK_OF(OSSL_CRMF_MSG) *)OPENSSL_sk_new_null())
#define sk_OSSL_CRMF_MSG_new_reserve(cmp, n) ((STACK_OF(OSSL_CRMF_MSG) *)OPENSSL_sk_new_reserve(ossl_check_OSSL_CRMF_MSG_compfunc_type(cmp), (n)))
#define sk_OSSL_CRMF_MSG_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_OSSL_CRMF_MSG_sk_type(sk), (n))
#define sk_OSSL_CRMF_MSG_free(sk) OPENSSL_sk_free(ossl_check_OSSL_CRMF_MSG_sk_type(sk))
#define sk_OSSL_CRMF_MSG_zero(sk) OPENSSL_sk_zero(ossl_check_OSSL_CRMF_MSG_sk_type(sk))
#define sk_OSSL_CRMF_MSG_delete(sk, i) ((OSSL_CRMF_MSG *)OPENSSL_sk_delete(ossl_check_OSSL_CRMF_MSG_sk_type(sk), (i)))
#define sk_OSSL_CRMF_MSG_delete_ptr(sk, ptr) ((OSSL_CRMF_MSG *)OPENSSL_sk_delete_ptr(ossl_check_OSSL_CRMF_MSG_sk_type(sk), ossl_check_OSSL_CRMF_MSG_type(ptr)))
#define sk_OSSL_CRMF_MSG_push(sk, ptr) OPENSSL_sk_push(ossl_check_OSSL_CRMF_MSG_sk_type(sk), ossl_check_OSSL_CRMF_MSG_type(ptr))
#define sk_OSSL_CRMF_MSG_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_OSSL_CRMF_MSG_sk_type(sk), ossl_check_OSSL_CRMF_MSG_type(ptr))
#define sk_OSSL_CRMF_MSG_pop(sk) ((OSSL_CRMF_MSG *)OPENSSL_sk_pop(ossl_check_OSSL_CRMF_MSG_sk_type(sk)))
#define sk_OSSL_CRMF_MSG_shift(sk) ((OSSL_CRMF_MSG *)OPENSSL_sk_shift(ossl_check_OSSL_CRMF_MSG_sk_type(sk)))
#define sk_OSSL_CRMF_MSG_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_OSSL_CRMF_MSG_sk_type(sk),ossl_check_OSSL_CRMF_MSG_freefunc_type(freefunc))
#define sk_OSSL_CRMF_MSG_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_OSSL_CRMF_MSG_sk_type(sk), ossl_check_OSSL_CRMF_MSG_type(ptr), (idx))
#define sk_OSSL_CRMF_MSG_set(sk, idx, ptr) ((OSSL_CRMF_MSG *)OPENSSL_sk_set(ossl_check_OSSL_CRMF_MSG_sk_type(sk), (idx), ossl_check_OSSL_CRMF_MSG_type(ptr)))
#define sk_OSSL_CRMF_MSG_find(sk, ptr) OPENSSL_sk_find(ossl_check_OSSL_CRMF_MSG_sk_type(sk), ossl_check_OSSL_CRMF_MSG_type(ptr))
#define sk_OSSL_CRMF_MSG_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_OSSL_CRMF_MSG_sk_type(sk), ossl_check_OSSL_CRMF_MSG_type(ptr))
#define sk_OSSL_CRMF_MSG_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_OSSL_CRMF_MSG_sk_type(sk), ossl_check_OSSL_CRMF_MSG_type(ptr), pnum)
#define sk_OSSL_CRMF_MSG_sort(sk) OPENSSL_sk_sort(ossl_check_OSSL_CRMF_MSG_sk_type(sk))
#define sk_OSSL_CRMF_MSG_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_OSSL_CRMF_MSG_sk_type(sk))
#define sk_OSSL_CRMF_MSG_dup(sk) ((STACK_OF(OSSL_CRMF_MSG) *)OPENSSL_sk_dup(ossl_check_const_OSSL_CRMF_MSG_sk_type(sk)))
#define sk_OSSL_CRMF_MSG_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(OSSL_CRMF_MSG) *)OPENSSL_sk_deep_copy(ossl_check_const_OSSL_CRMF_MSG_sk_type(sk), ossl_check_OSSL_CRMF_MSG_copyfunc_type(copyfunc), ossl_check_OSSL_CRMF_MSG_freefunc_type(freefunc)))
#define sk_OSSL_CRMF_MSG_set_cmp_func(sk, cmp) ((sk_OSSL_CRMF_MSG_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_OSSL_CRMF_MSG_sk_type(sk), ossl_check_OSSL_CRMF_MSG_compfunc_type(cmp)))

typedef struct ossl_crmf_attributetypeandvalue_st OSSL_CRMF_ATTRIBUTETYPEANDVALUE;
typedef struct ossl_crmf_pbmparameter_st OSSL_CRMF_PBMPARAMETER;
DECLARE_ASN1_FUNCTIONS(OSSL_CRMF_PBMPARAMETER)
typedef struct ossl_crmf_poposigningkey_st OSSL_CRMF_POPOSIGNINGKEY;
typedef struct ossl_crmf_certrequest_st OSSL_CRMF_CERTREQUEST;
typedef struct ossl_crmf_certid_st OSSL_CRMF_CERTID;
DECLARE_ASN1_FUNCTIONS(OSSL_CRMF_CERTID)
DECLARE_ASN1_DUP_FUNCTION(OSSL_CRMF_CERTID)
SKM_DEFINE_STACK_OF_INTERNAL(OSSL_CRMF_CERTID, OSSL_CRMF_CERTID, OSSL_CRMF_CERTID)
#define sk_OSSL_CRMF_CERTID_num(sk) OPENSSL_sk_num(ossl_check_const_OSSL_CRMF_CERTID_sk_type(sk))
#define sk_OSSL_CRMF_CERTID_value(sk, idx) ((OSSL_CRMF_CERTID *)OPENSSL_sk_value(ossl_check_const_OSSL_CRMF_CERTID_sk_type(sk), (idx)))
#define sk_OSSL_CRMF_CERTID_new(cmp) ((STACK_OF(OSSL_CRMF_CERTID) *)OPENSSL_sk_new(ossl_check_OSSL_CRMF_CERTID_compfunc_type(cmp)))
#define sk_OSSL_CRMF_CERTID_new_null() ((STACK_OF(OSSL_CRMF_CERTID) *)OPENSSL_sk_new_null())
#define sk_OSSL_CRMF_CERTID_new_reserve(cmp, n) ((STACK_OF(OSSL_CRMF_CERTID) *)OPENSSL_sk_new_reserve(ossl_check_OSSL_CRMF_CERTID_compfunc_type(cmp), (n)))
#define sk_OSSL_CRMF_CERTID_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_OSSL_CRMF_CERTID_sk_type(sk), (n))
#define sk_OSSL_CRMF_CERTID_free(sk) OPENSSL_sk_free(ossl_check_OSSL_CRMF_CERTID_sk_type(sk))
#define sk_OSSL_CRMF_CERTID_zero(sk) OPENSSL_sk_zero(ossl_check_OSSL_CRMF_CERTID_sk_type(sk))
#define sk_OSSL_CRMF_CERTID_delete(sk, i) ((OSSL_CRMF_CERTID *)OPENSSL_sk_delete(ossl_check_OSSL_CRMF_CERTID_sk_type(sk), (i)))
#define sk_OSSL_CRMF_CERTID_delete_ptr(sk, ptr) ((OSSL_CRMF_CERTID *)OPENSSL_sk_delete_ptr(ossl_check_OSSL_CRMF_CERTID_sk_type(sk), ossl_check_OSSL_CRMF_CERTID_type(ptr)))
#define sk_OSSL_CRMF_CERTID_push(sk, ptr) OPENSSL_sk_push(ossl_check_OSSL_CRMF_CERTID_sk_type(sk), ossl_check_OSSL_CRMF_CERTID_type(ptr))
#define sk_OSSL_CRMF_CERTID_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_OSSL_CRMF_CERTID_sk_type(sk), ossl_check_OSSL_CRMF_CERTID_type(ptr))
#define sk_OSSL_CRMF_CERTID_pop(sk) ((OSSL_CRMF_CERTID *)OPENSSL_sk_pop(ossl_check_OSSL_CRMF_CERTID_sk_type(sk)))
#define sk_OSSL_CRMF_CERTID_shift(sk) ((OSSL_CRMF_CERTID *)OPENSSL_sk_shift(ossl_check_OSSL_CRMF_CERTID_sk_type(sk)))
#define sk_OSSL_CRMF_CERTID_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_OSSL_CRMF_CERTID_sk_type(sk),ossl_check_OSSL_CRMF_CERTID_freefunc_type(freefunc))
#define sk_OSSL_CRMF_CERTID_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_OSSL_CRMF_CERTID_sk_type(sk), ossl_check_OSSL_CRMF_CERTID_type(ptr), (idx))
#define sk_OSSL_CRMF_CERTID_set(sk, idx, ptr) ((OSSL_CRMF_CERTID *)OPENSSL_sk_set(ossl_check_OSSL_CRMF_CERTID_sk_type(sk), (idx), ossl_check_OSSL_CRMF_CERTID_type(ptr)))
#define sk_OSSL_CRMF_CERTID_find(sk, ptr) OPENSSL_sk_find(ossl_check_OSSL_CRMF_CERTID_sk_type(sk), ossl_check_OSSL_CRMF_CERTID_type(ptr))
#define sk_OSSL_CRMF_CERTID_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_OSSL_CRMF_CERTID_sk_type(sk), ossl_check_OSSL_CRMF_CERTID_type(ptr))
#define sk_OSSL_CRMF_CERTID_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_OSSL_CRMF_CERTID_sk_type(sk), ossl_check_OSSL_CRMF_CERTID_type(ptr), pnum)
#define sk_OSSL_CRMF_CERTID_sort(sk) OPENSSL_sk_sort(ossl_check_OSSL_CRMF_CERTID_sk_type(sk))
#define sk_OSSL_CRMF_CERTID_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_OSSL_CRMF_CERTID_sk_type(sk))
#define sk_OSSL_CRMF_CERTID_dup(sk) ((STACK_OF(OSSL_CRMF_CERTID) *)OPENSSL_sk_dup(ossl_check_const_OSSL_CRMF_CERTID_sk_type(sk)))
#define sk_OSSL_CRMF_CERTID_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(OSSL_CRMF_CERTID) *)OPENSSL_sk_deep_copy(ossl_check_const_OSSL_CRMF_CERTID_sk_type(sk), ossl_check_OSSL_CRMF_CERTID_copyfunc_type(copyfunc), ossl_check_OSSL_CRMF_CERTID_freefunc_type(freefunc)))
#define sk_OSSL_CRMF_CERTID_set_cmp_func(sk, cmp) ((sk_OSSL_CRMF_CERTID_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_OSSL_CRMF_CERTID_sk_type(sk), ossl_check_OSSL_CRMF_CERTID_compfunc_type(cmp)))


typedef struct ossl_crmf_pkipublicationinfo_st OSSL_CRMF_PKIPUBLICATIONINFO;
DECLARE_ASN1_FUNCTIONS(OSSL_CRMF_PKIPUBLICATIONINFO)
typedef struct ossl_crmf_singlepubinfo_st OSSL_CRMF_SINGLEPUBINFO;
DECLARE_ASN1_FUNCTIONS(OSSL_CRMF_SINGLEPUBINFO)
typedef struct ossl_crmf_certtemplate_st OSSL_CRMF_CERTTEMPLATE;
DECLARE_ASN1_FUNCTIONS(OSSL_CRMF_CERTTEMPLATE)
typedef STACK_OF(OSSL_CRMF_MSG) OSSL_CRMF_MSGS;
DECLARE_ASN1_FUNCTIONS(OSSL_CRMF_MSGS)

typedef struct ossl_crmf_optionalvalidity_st OSSL_CRMF_OPTIONALVALIDITY;

/* crmf_pbm.c */
OSSL_CRMF_PBMPARAMETER *OSSL_CRMF_pbmp_new(OSSL_LIB_CTX *libctx, size_t slen,
                                           int owfnid, size_t itercnt,
                                           int macnid);
int OSSL_CRMF_pbm_new(OSSL_LIB_CTX *libctx, const char *propq,
                      const OSSL_CRMF_PBMPARAMETER *pbmp,
                      const unsigned char *msg, size_t msglen,
                      const unsigned char *sec, size_t seclen,
                      unsigned char **mac, size_t *maclen);

/* crmf_lib.c */
int OSSL_CRMF_MSG_set1_regCtrl_regToken(OSSL_CRMF_MSG *msg,
                                        const ASN1_UTF8STRING *tok);
ASN1_UTF8STRING
*OSSL_CRMF_MSG_get0_regCtrl_regToken(const OSSL_CRMF_MSG *msg);
int OSSL_CRMF_MSG_set1_regCtrl_authenticator(OSSL_CRMF_MSG *msg,
                                             const ASN1_UTF8STRING *auth);
ASN1_UTF8STRING
*OSSL_CRMF_MSG_get0_regCtrl_authenticator(const OSSL_CRMF_MSG *msg);
int
OSSL_CRMF_MSG_PKIPublicationInfo_push0_SinglePubInfo(OSSL_CRMF_PKIPUBLICATIONINFO *pi,
                                                     OSSL_CRMF_SINGLEPUBINFO *spi);
#  define OSSL_CRMF_PUB_METHOD_DONTCARE 0
#  define OSSL_CRMF_PUB_METHOD_X500     1
#  define OSSL_CRMF_PUB_METHOD_WEB      2
#  define OSSL_CRMF_PUB_METHOD_LDAP     3
int OSSL_CRMF_MSG_set0_SinglePubInfo(OSSL_CRMF_SINGLEPUBINFO *spi,
                                     int method, GENERAL_NAME *nm);
#  define OSSL_CRMF_PUB_ACTION_DONTPUBLISH   0
#  define OSSL_CRMF_PUB_ACTION_PLEASEPUBLISH 1
int OSSL_CRMF_MSG_set_PKIPublicationInfo_action(OSSL_CRMF_PKIPUBLICATIONINFO *pi,
                                                int action);
int OSSL_CRMF_MSG_set1_regCtrl_pkiPublicationInfo(OSSL_CRMF_MSG *msg,
                                                  const OSSL_CRMF_PKIPUBLICATIONINFO *pi);
OSSL_CRMF_PKIPUBLICATIONINFO
*OSSL_CRMF_MSG_get0_regCtrl_pkiPublicationInfo(const OSSL_CRMF_MSG *msg);
int OSSL_CRMF_MSG_set1_regCtrl_protocolEncrKey(OSSL_CRMF_MSG *msg,
                                               const X509_PUBKEY *pubkey);
X509_PUBKEY
*OSSL_CRMF_MSG_get0_regCtrl_protocolEncrKey(const OSSL_CRMF_MSG *msg);
int OSSL_CRMF_MSG_set1_regCtrl_oldCertID(OSSL_CRMF_MSG *msg,
                                         const OSSL_CRMF_CERTID *cid);
OSSL_CRMF_CERTID
*OSSL_CRMF_MSG_get0_regCtrl_oldCertID(const OSSL_CRMF_MSG *msg);
OSSL_CRMF_CERTID *OSSL_CRMF_CERTID_gen(const X509_NAME *issuer,
                                       const ASN1_INTEGER *serial);

int OSSL_CRMF_MSG_set1_regInfo_utf8Pairs(OSSL_CRMF_MSG *msg,
                                         const ASN1_UTF8STRING *utf8pairs);
ASN1_UTF8STRING
*OSSL_CRMF_MSG_get0_regInfo_utf8Pairs(const OSSL_CRMF_MSG *msg);
int OSSL_CRMF_MSG_set1_regInfo_certReq(OSSL_CRMF_MSG *msg,
                                       const OSSL_CRMF_CERTREQUEST *cr);
OSSL_CRMF_CERTREQUEST
*OSSL_CRMF_MSG_get0_regInfo_certReq(const OSSL_CRMF_MSG *msg);

int OSSL_CRMF_MSG_set0_validity(OSSL_CRMF_MSG *crm,
                                ASN1_TIME *notBefore, ASN1_TIME *notAfter);
int OSSL_CRMF_MSG_set_certReqId(OSSL_CRMF_MSG *crm, int rid);
int OSSL_CRMF_MSG_get_certReqId(const OSSL_CRMF_MSG *crm);
int OSSL_CRMF_MSG_set0_extensions(OSSL_CRMF_MSG *crm, X509_EXTENSIONS *exts);

int OSSL_CRMF_MSG_push0_extension(OSSL_CRMF_MSG *crm, X509_EXTENSION *ext);
#  define OSSL_CRMF_POPO_NONE       -1
#  define OSSL_CRMF_POPO_RAVERIFIED 0
#  define OSSL_CRMF_POPO_SIGNATURE  1
#  define OSSL_CRMF_POPO_KEYENC     2
#  define OSSL_CRMF_POPO_KEYAGREE   3
int OSSL_CRMF_MSG_create_popo(int meth, OSSL_CRMF_MSG *crm,
                              EVP_PKEY *pkey, const EVP_MD *digest,
                              OSSL_LIB_CTX *libctx, const char *propq);
int OSSL_CRMF_MSGS_verify_popo(const OSSL_CRMF_MSGS *reqs,
                               int rid, int acceptRAVerified,
                               OSSL_LIB_CTX *libctx, const char *propq);
OSSL_CRMF_CERTTEMPLATE *OSSL_CRMF_MSG_get0_tmpl(const OSSL_CRMF_MSG *crm);
const ASN1_INTEGER
*OSSL_CRMF_CERTTEMPLATE_get0_serialNumber(const OSSL_CRMF_CERTTEMPLATE *tmpl);
const X509_NAME
*OSSL_CRMF_CERTTEMPLATE_get0_subject(const OSSL_CRMF_CERTTEMPLATE *tmpl);
const X509_NAME
*OSSL_CRMF_CERTTEMPLATE_get0_issuer(const OSSL_CRMF_CERTTEMPLATE *tmpl);
X509_EXTENSIONS
*OSSL_CRMF_CERTTEMPLATE_get0_extensions(const OSSL_CRMF_CERTTEMPLATE *tmpl);
const X509_NAME
*OSSL_CRMF_CERTID_get0_issuer(const OSSL_CRMF_CERTID *cid);
const ASN1_INTEGER
*OSSL_CRMF_CERTID_get0_serialNumber(const OSSL_CRMF_CERTID *cid);
int OSSL_CRMF_CERTTEMPLATE_fill(OSSL_CRMF_CERTTEMPLATE *tmpl,
                                EVP_PKEY *pubkey,
                                const X509_NAME *subject,
                                const X509_NAME *issuer,
                                const ASN1_INTEGER *serial);
X509
*OSSL_CRMF_ENCRYPTEDVALUE_get1_encCert(const OSSL_CRMF_ENCRYPTEDVALUE *ecert,
                                       OSSL_LIB_CTX *libctx, const char *propq,
                                       EVP_PKEY *pkey);

#  ifdef __cplusplus
}
#  endif
# endif /* !defined(OPENSSL_NO_CRMF) */
#endif /* !defined(OPENSSL_CRMF_H) */
                                                                                                                                                                                                            node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/openssl/crypto.h        0000664 0000000 0000000 00000056611 14746647661 0031404 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /*
 * WARNING: do not edit!
 * Generated by Makefile from include/openssl/crypto.h.in
 *
 * Copyright 1995-2022 The OpenSSL Project Authors. All Rights Reserved.
 * Copyright (c) 2002, Oracle and/or its affiliates. All rights reserved
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 */



#ifndef OPENSSL_CRYPTO_H
# define OPENSSL_CRYPTO_H
# pragma once

# include <openssl/macros.h>
# ifndef OPENSSL_NO_DEPRECATED_3_0
#  define HEADER_CRYPTO_H
# endif

# include <stdlib.h>
# include <time.h>

# include <openssl/e_os2.h>

# ifndef OPENSSL_NO_STDIO
#  include <stdio.h>
# endif

# include <openssl/safestack.h>
# include <openssl/opensslv.h>
# include <openssl/types.h>
# include <openssl/opensslconf.h>
# include <openssl/cryptoerr.h>
# include <openssl/core.h>

# ifdef CHARSET_EBCDIC
#  include <openssl/ebcdic.h>
# endif

/*
 * Resolve problems on some operating systems with symbol names that clash
 * one way or another
 */
# include <openssl/symhacks.h>

# ifndef OPENSSL_NO_DEPRECATED_1_1_0
#  include <openssl/opensslv.h>
# endif

#ifdef  __cplusplus
extern "C" {
#endif

# ifndef OPENSSL_NO_DEPRECATED_1_1_0
#  define SSLeay                  OpenSSL_version_num
#  define SSLeay_version          OpenSSL_version
#  define SSLEAY_VERSION_NUMBER   OPENSSL_VERSION_NUMBER
#  define SSLEAY_VERSION          OPENSSL_VERSION
#  define SSLEAY_CFLAGS           OPENSSL_CFLAGS
#  define SSLEAY_BUILT_ON         OPENSSL_BUILT_ON
#  define SSLEAY_PLATFORM         OPENSSL_PLATFORM
#  define SSLEAY_DIR              OPENSSL_DIR

/*
 * Old type for allocating dynamic locks. No longer used. Use the new thread
 * API instead.
 */
typedef struct {
    int dummy;
} CRYPTO_dynlock;

# endif /* OPENSSL_NO_DEPRECATED_1_1_0 */

typedef void CRYPTO_RWLOCK;

CRYPTO_RWLOCK *CRYPTO_THREAD_lock_new(void);
__owur int CRYPTO_THREAD_read_lock(CRYPTO_RWLOCK *lock);
__owur int CRYPTO_THREAD_write_lock(CRYPTO_RWLOCK *lock);
int CRYPTO_THREAD_unlock(CRYPTO_RWLOCK *lock);
void CRYPTO_THREAD_lock_free(CRYPTO_RWLOCK *lock);

int CRYPTO_atomic_add(int *val, int amount, int *ret, CRYPTO_RWLOCK *lock);
int CRYPTO_atomic_or(uint64_t *val, uint64_t op, uint64_t *ret,
                     CRYPTO_RWLOCK *lock);
int CRYPTO_atomic_load(uint64_t *val, uint64_t *ret, CRYPTO_RWLOCK *lock);

/* No longer needed, so this is a no-op */
#define OPENSSL_malloc_init() while(0) continue

# define OPENSSL_malloc(num) \
        CRYPTO_malloc(num, OPENSSL_FILE, OPENSSL_LINE)
# define OPENSSL_zalloc(num) \
        CRYPTO_zalloc(num, OPENSSL_FILE, OPENSSL_LINE)
# define OPENSSL_realloc(addr, num) \
        CRYPTO_realloc(addr, num, OPENSSL_FILE, OPENSSL_LINE)
# define OPENSSL_clear_realloc(addr, old_num, num) \
        CRYPTO_clear_realloc(addr, old_num, num, OPENSSL_FILE, OPENSSL_LINE)
# define OPENSSL_clear_free(addr, num) \
        CRYPTO_clear_free(addr, num, OPENSSL_FILE, OPENSSL_LINE)
# define OPENSSL_free(addr) \
        CRYPTO_free(addr, OPENSSL_FILE, OPENSSL_LINE)
# define OPENSSL_memdup(str, s) \
        CRYPTO_memdup((str), s, OPENSSL_FILE, OPENSSL_LINE)
# define OPENSSL_strdup(str) \
        CRYPTO_strdup(str, OPENSSL_FILE, OPENSSL_LINE)
# define OPENSSL_strndup(str, n) \
        CRYPTO_strndup(str, n, OPENSSL_FILE, OPENSSL_LINE)
# define OPENSSL_secure_malloc(num) \
        CRYPTO_secure_malloc(num, OPENSSL_FILE, OPENSSL_LINE)
# define OPENSSL_secure_zalloc(num) \
        CRYPTO_secure_zalloc(num, OPENSSL_FILE, OPENSSL_LINE)
# define OPENSSL_secure_free(addr) \
        CRYPTO_secure_free(addr, OPENSSL_FILE, OPENSSL_LINE)
# define OPENSSL_secure_clear_free(addr, num) \
        CRYPTO_secure_clear_free(addr, num, OPENSSL_FILE, OPENSSL_LINE)
# define OPENSSL_secure_actual_size(ptr) \
        CRYPTO_secure_actual_size(ptr)

size_t OPENSSL_strlcpy(char *dst, const char *src, size_t siz);
size_t OPENSSL_strlcat(char *dst, const char *src, size_t siz);
size_t OPENSSL_strnlen(const char *str, size_t maxlen);
int OPENSSL_buf2hexstr_ex(char *str, size_t str_n, size_t *strlength,
                          const unsigned char *buf, size_t buflen,
                          const char sep);
char *OPENSSL_buf2hexstr(const unsigned char *buf, long buflen);
int OPENSSL_hexstr2buf_ex(unsigned char *buf, size_t buf_n, size_t *buflen,
                          const char *str, const char sep);
unsigned char *OPENSSL_hexstr2buf(const char *str, long *buflen);
int OPENSSL_hexchar2int(unsigned char c);
int OPENSSL_strcasecmp(const char *s1, const char *s2);
int OPENSSL_strncasecmp(const char *s1, const char *s2, size_t n);

# define OPENSSL_MALLOC_MAX_NELEMS(type)  (((1U<<(sizeof(int)*8-1))-1)/sizeof(type))

/*
 * These functions return the values of OPENSSL_VERSION_MAJOR,
 * OPENSSL_VERSION_MINOR, OPENSSL_VERSION_PATCH, OPENSSL_VERSION_PRE_RELEASE
 * and OPENSSL_VERSION_BUILD_METADATA, respectively.
 */
unsigned int OPENSSL_version_major(void);
unsigned int OPENSSL_version_minor(void);
unsigned int OPENSSL_version_patch(void);
const char *OPENSSL_version_pre_release(void);
const char *OPENSSL_version_build_metadata(void);

unsigned long OpenSSL_version_num(void);
const char *OpenSSL_version(int type);
# define OPENSSL_VERSION                0
# define OPENSSL_CFLAGS                 1
# define OPENSSL_BUILT_ON               2
# define OPENSSL_PLATFORM               3
# define OPENSSL_DIR                    4
# define OPENSSL_ENGINES_DIR            5
# define OPENSSL_VERSION_STRING         6
# define OPENSSL_FULL_VERSION_STRING    7
# define OPENSSL_MODULES_DIR            8
# define OPENSSL_CPU_INFO               9

const char *OPENSSL_info(int type);
/*
 * The series starts at 1001 to avoid confusion with the OpenSSL_version
 * types.
 */
# define OPENSSL_INFO_CONFIG_DIR                1001
# define OPENSSL_INFO_ENGINES_DIR               1002
# define OPENSSL_INFO_MODULES_DIR               1003
# define OPENSSL_INFO_DSO_EXTENSION             1004
# define OPENSSL_INFO_DIR_FILENAME_SEPARATOR    1005
# define OPENSSL_INFO_LIST_SEPARATOR            1006
# define OPENSSL_INFO_SEED_SOURCE               1007
# define OPENSSL_INFO_CPU_SETTINGS              1008

int OPENSSL_issetugid(void);

struct crypto_ex_data_st {
    OSSL_LIB_CTX *ctx;
    STACK_OF(void) *sk;
};

SKM_DEFINE_STACK_OF_INTERNAL(void, void, void)
#define sk_void_num(sk) OPENSSL_sk_num(ossl_check_const_void_sk_type(sk))
#define sk_void_value(sk, idx) ((void *)OPENSSL_sk_value(ossl_check_const_void_sk_type(sk), (idx)))
#define sk_void_new(cmp) ((STACK_OF(void) *)OPENSSL_sk_new(ossl_check_void_compfunc_type(cmp)))
#define sk_void_new_null() ((STACK_OF(void) *)OPENSSL_sk_new_null())
#define sk_void_new_reserve(cmp, n) ((STACK_OF(void) *)OPENSSL_sk_new_reserve(ossl_check_void_compfunc_type(cmp), (n)))
#define sk_void_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_void_sk_type(sk), (n))
#define sk_void_free(sk) OPENSSL_sk_free(ossl_check_void_sk_type(sk))
#define sk_void_zero(sk) OPENSSL_sk_zero(ossl_check_void_sk_type(sk))
#define sk_void_delete(sk, i) ((void *)OPENSSL_sk_delete(ossl_check_void_sk_type(sk), (i)))
#define sk_void_delete_ptr(sk, ptr) ((void *)OPENSSL_sk_delete_ptr(ossl_check_void_sk_type(sk), ossl_check_void_type(ptr)))
#define sk_void_push(sk, ptr) OPENSSL_sk_push(ossl_check_void_sk_type(sk), ossl_check_void_type(ptr))
#define sk_void_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_void_sk_type(sk), ossl_check_void_type(ptr))
#define sk_void_pop(sk) ((void *)OPENSSL_sk_pop(ossl_check_void_sk_type(sk)))
#define sk_void_shift(sk) ((void *)OPENSSL_sk_shift(ossl_check_void_sk_type(sk)))
#define sk_void_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_void_sk_type(sk),ossl_check_void_freefunc_type(freefunc))
#define sk_void_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_void_sk_type(sk), ossl_check_void_type(ptr), (idx))
#define sk_void_set(sk, idx, ptr) ((void *)OPENSSL_sk_set(ossl_check_void_sk_type(sk), (idx), ossl_check_void_type(ptr)))
#define sk_void_find(sk, ptr) OPENSSL_sk_find(ossl_check_void_sk_type(sk), ossl_check_void_type(ptr))
#define sk_void_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_void_sk_type(sk), ossl_check_void_type(ptr))
#define sk_void_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_void_sk_type(sk), ossl_check_void_type(ptr), pnum)
#define sk_void_sort(sk) OPENSSL_sk_sort(ossl_check_void_sk_type(sk))
#define sk_void_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_void_sk_type(sk))
#define sk_void_dup(sk) ((STACK_OF(void) *)OPENSSL_sk_dup(ossl_check_const_void_sk_type(sk)))
#define sk_void_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(void) *)OPENSSL_sk_deep_copy(ossl_check_const_void_sk_type(sk), ossl_check_void_copyfunc_type(copyfunc), ossl_check_void_freefunc_type(freefunc)))
#define sk_void_set_cmp_func(sk, cmp) ((sk_void_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_void_sk_type(sk), ossl_check_void_compfunc_type(cmp)))



/*
 * Per class, we have a STACK of function pointers.
 */
# define CRYPTO_EX_INDEX_SSL              0
# define CRYPTO_EX_INDEX_SSL_CTX          1
# define CRYPTO_EX_INDEX_SSL_SESSION      2
# define CRYPTO_EX_INDEX_X509             3
# define CRYPTO_EX_INDEX_X509_STORE       4
# define CRYPTO_EX_INDEX_X509_STORE_CTX   5
# define CRYPTO_EX_INDEX_DH               6
# define CRYPTO_EX_INDEX_DSA              7
# define CRYPTO_EX_INDEX_EC_KEY           8
# define CRYPTO_EX_INDEX_RSA              9
# define CRYPTO_EX_INDEX_ENGINE          10
# define CRYPTO_EX_INDEX_UI              11
# define CRYPTO_EX_INDEX_BIO             12
# define CRYPTO_EX_INDEX_APP             13
# define CRYPTO_EX_INDEX_UI_METHOD       14
# define CRYPTO_EX_INDEX_RAND_DRBG       15
# define CRYPTO_EX_INDEX_DRBG            CRYPTO_EX_INDEX_RAND_DRBG
# define CRYPTO_EX_INDEX_OSSL_LIB_CTX    16
# define CRYPTO_EX_INDEX_EVP_PKEY        17
# define CRYPTO_EX_INDEX__COUNT          18

typedef void CRYPTO_EX_new (void *parent, void *ptr, CRYPTO_EX_DATA *ad,
                           int idx, long argl, void *argp);
typedef void CRYPTO_EX_free (void *parent, void *ptr, CRYPTO_EX_DATA *ad,
                             int idx, long argl, void *argp);
typedef int CRYPTO_EX_dup (CRYPTO_EX_DATA *to, const CRYPTO_EX_DATA *from,
                           void **from_d, int idx, long argl, void *argp);
__owur int CRYPTO_get_ex_new_index(int class_index, long argl, void *argp,
                                   CRYPTO_EX_new *new_func,
                                   CRYPTO_EX_dup *dup_func,
                                   CRYPTO_EX_free *free_func);
/* No longer use an index. */
int CRYPTO_free_ex_index(int class_index, int idx);

/*
 * Initialise/duplicate/free CRYPTO_EX_DATA variables corresponding to a
 * given class (invokes whatever per-class callbacks are applicable)
 */
int CRYPTO_new_ex_data(int class_index, void *obj, CRYPTO_EX_DATA *ad);
int CRYPTO_dup_ex_data(int class_index, CRYPTO_EX_DATA *to,
                       const CRYPTO_EX_DATA *from);

void CRYPTO_free_ex_data(int class_index, void *obj, CRYPTO_EX_DATA *ad);

/* Allocate a single item in the CRYPTO_EX_DATA variable */
int CRYPTO_alloc_ex_data(int class_index, void *obj, CRYPTO_EX_DATA *ad,
                         int idx);

/*
 * Get/set data in a CRYPTO_EX_DATA variable corresponding to a particular
 * index (relative to the class type involved)
 */
int CRYPTO_set_ex_data(CRYPTO_EX_DATA *ad, int idx, void *val);
void *CRYPTO_get_ex_data(const CRYPTO_EX_DATA *ad, int idx);

# ifndef OPENSSL_NO_DEPRECATED_1_1_0
/*
 * This function cleans up all "ex_data" state. It mustn't be called under
 * potential race-conditions.
 */
# define CRYPTO_cleanup_all_ex_data() while(0) continue

/*
 * The old locking functions have been removed completely without compatibility
 * macros. This is because the old functions either could not properly report
 * errors, or the returned error values were not clearly documented.
 * Replacing the locking functions with no-ops would cause race condition
 * issues in the affected applications. It is far better for them to fail at
 * compile time.
 * On the other hand, the locking callbacks are no longer used.  Consequently,
 * the callback management functions can be safely replaced with no-op macros.
 */
#  define CRYPTO_num_locks()            (1)
#  define CRYPTO_set_locking_callback(func)
#  define CRYPTO_get_locking_callback()         (NULL)
#  define CRYPTO_set_add_lock_callback(func)
#  define CRYPTO_get_add_lock_callback()        (NULL)

/*
 * These defines where used in combination with the old locking callbacks,
 * they are not called anymore, but old code that's not called might still
 * use them.
 */
#  define CRYPTO_LOCK             1
#  define CRYPTO_UNLOCK           2
#  define CRYPTO_READ             4
#  define CRYPTO_WRITE            8

/* This structure is no longer used */
typedef struct crypto_threadid_st {
    int dummy;
} CRYPTO_THREADID;
/* Only use CRYPTO_THREADID_set_[numeric|pointer]() within callbacks */
#  define CRYPTO_THREADID_set_numeric(id, val)
#  define CRYPTO_THREADID_set_pointer(id, ptr)
#  define CRYPTO_THREADID_set_callback(threadid_func)   (0)
#  define CRYPTO_THREADID_get_callback()                (NULL)
#  define CRYPTO_THREADID_current(id)
#  define CRYPTO_THREADID_cmp(a, b)                     (-1)
#  define CRYPTO_THREADID_cpy(dest, src)
#  define CRYPTO_THREADID_hash(id)                      (0UL)

#  ifndef OPENSSL_NO_DEPRECATED_1_0_0
#   define CRYPTO_set_id_callback(func)
#   define CRYPTO_get_id_callback()                     (NULL)
#   define CRYPTO_thread_id()                           (0UL)
#  endif /* OPENSSL_NO_DEPRECATED_1_0_0 */

#  define CRYPTO_set_dynlock_create_callback(dyn_create_function)
#  define CRYPTO_set_dynlock_lock_callback(dyn_lock_function)
#  define CRYPTO_set_dynlock_destroy_callback(dyn_destroy_function)
#  define CRYPTO_get_dynlock_create_callback()          (NULL)
#  define CRYPTO_get_dynlock_lock_callback()            (NULL)
#  define CRYPTO_get_dynlock_destroy_callback()         (NULL)
# endif /* OPENSSL_NO_DEPRECATED_1_1_0 */

typedef void *(*CRYPTO_malloc_fn)(size_t num, const char *file, int line);
typedef void *(*CRYPTO_realloc_fn)(void *addr, size_t num, const char *file,
                                   int line);
typedef void (*CRYPTO_free_fn)(void *addr, const char *file, int line);
int CRYPTO_set_mem_functions(CRYPTO_malloc_fn malloc_fn,
                             CRYPTO_realloc_fn realloc_fn,
                             CRYPTO_free_fn free_fn);
void CRYPTO_get_mem_functions(CRYPTO_malloc_fn *malloc_fn,
                              CRYPTO_realloc_fn *realloc_fn,
                              CRYPTO_free_fn *free_fn);

void *CRYPTO_malloc(size_t num, const char *file, int line);
void *CRYPTO_zalloc(size_t num, const char *file, int line);
void *CRYPTO_memdup(const void *str, size_t siz, const char *file, int line);
char *CRYPTO_strdup(const char *str, const char *file, int line);
char *CRYPTO_strndup(const char *str, size_t s, const char *file, int line);
void CRYPTO_free(void *ptr, const char *file, int line);
void CRYPTO_clear_free(void *ptr, size_t num, const char *file, int line);
void *CRYPTO_realloc(void *addr, size_t num, const char *file, int line);
void *CRYPTO_clear_realloc(void *addr, size_t old_num, size_t num,
                           const char *file, int line);

int CRYPTO_secure_malloc_init(size_t sz, size_t minsize);
int CRYPTO_secure_malloc_done(void);
void *CRYPTO_secure_malloc(size_t num, const char *file, int line);
void *CRYPTO_secure_zalloc(size_t num, const char *file, int line);
void CRYPTO_secure_free(void *ptr, const char *file, int line);
void CRYPTO_secure_clear_free(void *ptr, size_t num,
                              const char *file, int line);
int CRYPTO_secure_allocated(const void *ptr);
int CRYPTO_secure_malloc_initialized(void);
size_t CRYPTO_secure_actual_size(void *ptr);
size_t CRYPTO_secure_used(void);

void OPENSSL_cleanse(void *ptr, size_t len);

# ifndef OPENSSL_NO_CRYPTO_MDEBUG
/*
 * The following can be used to detect memory leaks in the library. If
 * used, it turns on malloc checking
 */
# define CRYPTO_MEM_CHECK_OFF     0x0   /* Control only */
# define CRYPTO_MEM_CHECK_ON      0x1   /* Control and mode bit */
# define CRYPTO_MEM_CHECK_ENABLE  0x2   /* Control and mode bit */
# define CRYPTO_MEM_CHECK_DISABLE 0x3   /* Control only */

void CRYPTO_get_alloc_counts(int *mcount, int *rcount, int *fcount);
#  ifndef OPENSSL_NO_DEPRECATED_3_0
#    define OPENSSL_mem_debug_push(info) \
         CRYPTO_mem_debug_push(info, OPENSSL_FILE, OPENSSL_LINE)
#    define OPENSSL_mem_debug_pop() \
         CRYPTO_mem_debug_pop()
#  endif
#  ifndef OPENSSL_NO_DEPRECATED_3_0
OSSL_DEPRECATEDIN_3_0 int CRYPTO_set_mem_debug(int flag);
OSSL_DEPRECATEDIN_3_0 int CRYPTO_mem_ctrl(int mode);
OSSL_DEPRECATEDIN_3_0 int CRYPTO_mem_debug_push(const char *info,
                                                const char *file, int line);
OSSL_DEPRECATEDIN_3_0 int CRYPTO_mem_debug_pop(void);
OSSL_DEPRECATEDIN_3_0 void CRYPTO_mem_debug_malloc(void *addr, size_t num,
                                                   int flag,
                                                   const char *file, int line);
OSSL_DEPRECATEDIN_3_0 void CRYPTO_mem_debug_realloc(void *addr1, void *addr2,
                                                    size_t num, int flag,
                                                    const char *file, int line);
OSSL_DEPRECATEDIN_3_0 void CRYPTO_mem_debug_free(void *addr, int flag,
                                                 const char *file, int line);
OSSL_DEPRECATEDIN_3_0
int CRYPTO_mem_leaks_cb(int (*cb)(const char *str, size_t len, void *u),
                        void *u);
#  endif
#  ifndef OPENSSL_NO_STDIO
#  ifndef OPENSSL_NO_DEPRECATED_3_0
OSSL_DEPRECATEDIN_3_0 int CRYPTO_mem_leaks_fp(FILE *);
#  endif
#  endif
# ifndef OPENSSL_NO_DEPRECATED_3_0
OSSL_DEPRECATEDIN_3_0 int CRYPTO_mem_leaks(BIO *bio);
# endif
# endif /* OPENSSL_NO_CRYPTO_MDEBUG */

/* die if we have to */
ossl_noreturn void OPENSSL_die(const char *assertion, const char *file, int line);
# ifndef OPENSSL_NO_DEPRECATED_1_1_0
#  define OpenSSLDie(f,l,a) OPENSSL_die((a),(f),(l))
# endif
# define OPENSSL_assert(e) \
    (void)((e) ? 0 : (OPENSSL_die("assertion failed: " #e, OPENSSL_FILE, OPENSSL_LINE), 1))

int OPENSSL_isservice(void);

void OPENSSL_init(void);
# ifdef OPENSSL_SYS_UNIX
#  ifndef OPENSSL_NO_DEPRECATED_3_0
OSSL_DEPRECATEDIN_3_0 void OPENSSL_fork_prepare(void);
OSSL_DEPRECATEDIN_3_0 void OPENSSL_fork_parent(void);
OSSL_DEPRECATEDIN_3_0 void OPENSSL_fork_child(void);
#  endif
# endif

struct tm *OPENSSL_gmtime(const time_t *timer, struct tm *result);
int OPENSSL_gmtime_adj(struct tm *tm, int offset_day, long offset_sec);
int OPENSSL_gmtime_diff(int *pday, int *psec,
                        const struct tm *from, const struct tm *to);

/*
 * CRYPTO_memcmp returns zero iff the |len| bytes at |a| and |b| are equal.
 * It takes an amount of time dependent on |len|, but independent of the
 * contents of |a| and |b|. Unlike memcmp, it cannot be used to put elements
 * into a defined order as the return value when a != b is undefined, other
 * than to be non-zero.
 */
int CRYPTO_memcmp(const void * in_a, const void * in_b, size_t len);

/* Standard initialisation options */
# define OPENSSL_INIT_NO_LOAD_CRYPTO_STRINGS 0x00000001L
# define OPENSSL_INIT_LOAD_CRYPTO_STRINGS    0x00000002L
# define OPENSSL_INIT_ADD_ALL_CIPHERS        0x00000004L
# define OPENSSL_INIT_ADD_ALL_DIGESTS        0x00000008L
# define OPENSSL_INIT_NO_ADD_ALL_CIPHERS     0x00000010L
# define OPENSSL_INIT_NO_ADD_ALL_DIGESTS     0x00000020L
# define OPENSSL_INIT_LOAD_CONFIG            0x00000040L
# define OPENSSL_INIT_NO_LOAD_CONFIG         0x00000080L
# define OPENSSL_INIT_ASYNC                  0x00000100L
# define OPENSSL_INIT_ENGINE_RDRAND          0x00000200L
# define OPENSSL_INIT_ENGINE_DYNAMIC         0x00000400L
# define OPENSSL_INIT_ENGINE_OPENSSL         0x00000800L
# define OPENSSL_INIT_ENGINE_CRYPTODEV       0x00001000L
# define OPENSSL_INIT_ENGINE_CAPI            0x00002000L
# define OPENSSL_INIT_ENGINE_PADLOCK         0x00004000L
# define OPENSSL_INIT_ENGINE_AFALG           0x00008000L
/* FREE:                                     0x00010000L */
# define OPENSSL_INIT_ATFORK                 0x00020000L
/* OPENSSL_INIT_BASE_ONLY                    0x00040000L */
# define OPENSSL_INIT_NO_ATEXIT              0x00080000L
/* OPENSSL_INIT flag range 0x03f00000 reserved for OPENSSL_init_ssl() */
/* FREE: 0x04000000L */
/* FREE: 0x08000000L */
/* FREE: 0x10000000L */
/* FREE: 0x20000000L */
/* FREE: 0x40000000L */
/* FREE: 0x80000000L */
/* Max OPENSSL_INIT flag value is 0x80000000 */

/* openssl and dasync not counted as builtin */
# define OPENSSL_INIT_ENGINE_ALL_BUILTIN \
    (OPENSSL_INIT_ENGINE_RDRAND | OPENSSL_INIT_ENGINE_DYNAMIC \
    | OPENSSL_INIT_ENGINE_CRYPTODEV | OPENSSL_INIT_ENGINE_CAPI | \
    OPENSSL_INIT_ENGINE_PADLOCK)

/* Library initialisation functions */
void OPENSSL_cleanup(void);
int OPENSSL_init_crypto(uint64_t opts, const OPENSSL_INIT_SETTINGS *settings);
int OPENSSL_atexit(void (*handler)(void));
void OPENSSL_thread_stop(void);
void OPENSSL_thread_stop_ex(OSSL_LIB_CTX *ctx);

/* Low-level control of initialization */
OPENSSL_INIT_SETTINGS *OPENSSL_INIT_new(void);
# ifndef OPENSSL_NO_STDIO
int OPENSSL_INIT_set_config_filename(OPENSSL_INIT_SETTINGS *settings,
                                     const char *config_filename);
void OPENSSL_INIT_set_config_file_flags(OPENSSL_INIT_SETTINGS *settings,
                                        unsigned long flags);
int OPENSSL_INIT_set_config_appname(OPENSSL_INIT_SETTINGS *settings,
                                    const char *config_appname);
# endif
void OPENSSL_INIT_free(OPENSSL_INIT_SETTINGS *settings);

# if defined(OPENSSL_THREADS) && !defined(CRYPTO_TDEBUG)
#  if defined(_WIN32)
#   if defined(BASETYPES) || defined(_WINDEF_H)
/* application has to include <windows.h> in order to use this */
typedef DWORD CRYPTO_THREAD_LOCAL;
typedef DWORD CRYPTO_THREAD_ID;

typedef LONG CRYPTO_ONCE;
#    define CRYPTO_ONCE_STATIC_INIT 0
#   endif
#  else
#   if defined(__TANDEM) && defined(_SPT_MODEL_)
#    define  SPT_THREAD_SIGNAL 1
#    define  SPT_THREAD_AWARE 1
#    include <spthread.h>
#   else
#    include <pthread.h>
#   endif
typedef pthread_once_t CRYPTO_ONCE;
typedef pthread_key_t CRYPTO_THREAD_LOCAL;
typedef pthread_t CRYPTO_THREAD_ID;

#   define CRYPTO_ONCE_STATIC_INIT PTHREAD_ONCE_INIT
#  endif
# endif

# if !defined(CRYPTO_ONCE_STATIC_INIT)
typedef unsigned int CRYPTO_ONCE;
typedef unsigned int CRYPTO_THREAD_LOCAL;
typedef unsigned int CRYPTO_THREAD_ID;
#  define CRYPTO_ONCE_STATIC_INIT 0
# endif

int CRYPTO_THREAD_run_once(CRYPTO_ONCE *once, void (*init)(void));

int CRYPTO_THREAD_init_local(CRYPTO_THREAD_LOCAL *key, void (*cleanup)(void *));
void *CRYPTO_THREAD_get_local(CRYPTO_THREAD_LOCAL *key);
int CRYPTO_THREAD_set_local(CRYPTO_THREAD_LOCAL *key, void *val);
int CRYPTO_THREAD_cleanup_local(CRYPTO_THREAD_LOCAL *key);

CRYPTO_THREAD_ID CRYPTO_THREAD_get_current_id(void);
int CRYPTO_THREAD_compare_id(CRYPTO_THREAD_ID a, CRYPTO_THREAD_ID b);

OSSL_LIB_CTX *OSSL_LIB_CTX_new(void);
OSSL_LIB_CTX *OSSL_LIB_CTX_new_from_dispatch(const OSSL_CORE_HANDLE *handle,
                                             const OSSL_DISPATCH *in);
OSSL_LIB_CTX *OSSL_LIB_CTX_new_child(const OSSL_CORE_HANDLE *handle,
                                     const OSSL_DISPATCH *in);
int OSSL_LIB_CTX_load_config(OSSL_LIB_CTX *ctx, const char *config_file);
void OSSL_LIB_CTX_free(OSSL_LIB_CTX *);
OSSL_LIB_CTX *OSSL_LIB_CTX_get0_global_default(void);
OSSL_LIB_CTX *OSSL_LIB_CTX_set0_default(OSSL_LIB_CTX *libctx);

# ifdef  __cplusplus
}
# endif
#endif
                                                                                                                       node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/openssl/ct.h            0000664 0000000 0000000 00000054355 14746647661 0030475 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /*
 * WARNING: do not edit!
 * Generated by Makefile from include/openssl/ct.h.in
 *
 * Copyright 2016-2020 The OpenSSL Project Authors. All Rights Reserved.
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 */



#ifndef OPENSSL_CT_H
# define OPENSSL_CT_H
# pragma once

# include <openssl/macros.h>
# ifndef OPENSSL_NO_DEPRECATED_3_0
#  define HEADER_CT_H
# endif

# include <openssl/opensslconf.h>

# ifndef OPENSSL_NO_CT
# include <openssl/types.h>
# include <openssl/safestack.h>
# include <openssl/x509.h>
# include <openssl/cterr.h>
# ifdef  __cplusplus
extern "C" {
# endif


/* Minimum RSA key size, from RFC6962 */
# define SCT_MIN_RSA_BITS 2048

/* All hashes are SHA256 in v1 of Certificate Transparency */
# define CT_V1_HASHLEN SHA256_DIGEST_LENGTH

SKM_DEFINE_STACK_OF_INTERNAL(SCT, SCT, SCT)
#define sk_SCT_num(sk) OPENSSL_sk_num(ossl_check_const_SCT_sk_type(sk))
#define sk_SCT_value(sk, idx) ((SCT *)OPENSSL_sk_value(ossl_check_const_SCT_sk_type(sk), (idx)))
#define sk_SCT_new(cmp) ((STACK_OF(SCT) *)OPENSSL_sk_new(ossl_check_SCT_compfunc_type(cmp)))
#define sk_SCT_new_null() ((STACK_OF(SCT) *)OPENSSL_sk_new_null())
#define sk_SCT_new_reserve(cmp, n) ((STACK_OF(SCT) *)OPENSSL_sk_new_reserve(ossl_check_SCT_compfunc_type(cmp), (n)))
#define sk_SCT_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_SCT_sk_type(sk), (n))
#define sk_SCT_free(sk) OPENSSL_sk_free(ossl_check_SCT_sk_type(sk))
#define sk_SCT_zero(sk) OPENSSL_sk_zero(ossl_check_SCT_sk_type(sk))
#define sk_SCT_delete(sk, i) ((SCT *)OPENSSL_sk_delete(ossl_check_SCT_sk_type(sk), (i)))
#define sk_SCT_delete_ptr(sk, ptr) ((SCT *)OPENSSL_sk_delete_ptr(ossl_check_SCT_sk_type(sk), ossl_check_SCT_type(ptr)))
#define sk_SCT_push(sk, ptr) OPENSSL_sk_push(ossl_check_SCT_sk_type(sk), ossl_check_SCT_type(ptr))
#define sk_SCT_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_SCT_sk_type(sk), ossl_check_SCT_type(ptr))
#define sk_SCT_pop(sk) ((SCT *)OPENSSL_sk_pop(ossl_check_SCT_sk_type(sk)))
#define sk_SCT_shift(sk) ((SCT *)OPENSSL_sk_shift(ossl_check_SCT_sk_type(sk)))
#define sk_SCT_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_SCT_sk_type(sk),ossl_check_SCT_freefunc_type(freefunc))
#define sk_SCT_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_SCT_sk_type(sk), ossl_check_SCT_type(ptr), (idx))
#define sk_SCT_set(sk, idx, ptr) ((SCT *)OPENSSL_sk_set(ossl_check_SCT_sk_type(sk), (idx), ossl_check_SCT_type(ptr)))
#define sk_SCT_find(sk, ptr) OPENSSL_sk_find(ossl_check_SCT_sk_type(sk), ossl_check_SCT_type(ptr))
#define sk_SCT_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_SCT_sk_type(sk), ossl_check_SCT_type(ptr))
#define sk_SCT_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_SCT_sk_type(sk), ossl_check_SCT_type(ptr), pnum)
#define sk_SCT_sort(sk) OPENSSL_sk_sort(ossl_check_SCT_sk_type(sk))
#define sk_SCT_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_SCT_sk_type(sk))
#define sk_SCT_dup(sk) ((STACK_OF(SCT) *)OPENSSL_sk_dup(ossl_check_const_SCT_sk_type(sk)))
#define sk_SCT_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(SCT) *)OPENSSL_sk_deep_copy(ossl_check_const_SCT_sk_type(sk), ossl_check_SCT_copyfunc_type(copyfunc), ossl_check_SCT_freefunc_type(freefunc)))
#define sk_SCT_set_cmp_func(sk, cmp) ((sk_SCT_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_SCT_sk_type(sk), ossl_check_SCT_compfunc_type(cmp)))
SKM_DEFINE_STACK_OF_INTERNAL(CTLOG, CTLOG, CTLOG)
#define sk_CTLOG_num(sk) OPENSSL_sk_num(ossl_check_const_CTLOG_sk_type(sk))
#define sk_CTLOG_value(sk, idx) ((CTLOG *)OPENSSL_sk_value(ossl_check_const_CTLOG_sk_type(sk), (idx)))
#define sk_CTLOG_new(cmp) ((STACK_OF(CTLOG) *)OPENSSL_sk_new(ossl_check_CTLOG_compfunc_type(cmp)))
#define sk_CTLOG_new_null() ((STACK_OF(CTLOG) *)OPENSSL_sk_new_null())
#define sk_CTLOG_new_reserve(cmp, n) ((STACK_OF(CTLOG) *)OPENSSL_sk_new_reserve(ossl_check_CTLOG_compfunc_type(cmp), (n)))
#define sk_CTLOG_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_CTLOG_sk_type(sk), (n))
#define sk_CTLOG_free(sk) OPENSSL_sk_free(ossl_check_CTLOG_sk_type(sk))
#define sk_CTLOG_zero(sk) OPENSSL_sk_zero(ossl_check_CTLOG_sk_type(sk))
#define sk_CTLOG_delete(sk, i) ((CTLOG *)OPENSSL_sk_delete(ossl_check_CTLOG_sk_type(sk), (i)))
#define sk_CTLOG_delete_ptr(sk, ptr) ((CTLOG *)OPENSSL_sk_delete_ptr(ossl_check_CTLOG_sk_type(sk), ossl_check_CTLOG_type(ptr)))
#define sk_CTLOG_push(sk, ptr) OPENSSL_sk_push(ossl_check_CTLOG_sk_type(sk), ossl_check_CTLOG_type(ptr))
#define sk_CTLOG_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_CTLOG_sk_type(sk), ossl_check_CTLOG_type(ptr))
#define sk_CTLOG_pop(sk) ((CTLOG *)OPENSSL_sk_pop(ossl_check_CTLOG_sk_type(sk)))
#define sk_CTLOG_shift(sk) ((CTLOG *)OPENSSL_sk_shift(ossl_check_CTLOG_sk_type(sk)))
#define sk_CTLOG_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_CTLOG_sk_type(sk),ossl_check_CTLOG_freefunc_type(freefunc))
#define sk_CTLOG_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_CTLOG_sk_type(sk), ossl_check_CTLOG_type(ptr), (idx))
#define sk_CTLOG_set(sk, idx, ptr) ((CTLOG *)OPENSSL_sk_set(ossl_check_CTLOG_sk_type(sk), (idx), ossl_check_CTLOG_type(ptr)))
#define sk_CTLOG_find(sk, ptr) OPENSSL_sk_find(ossl_check_CTLOG_sk_type(sk), ossl_check_CTLOG_type(ptr))
#define sk_CTLOG_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_CTLOG_sk_type(sk), ossl_check_CTLOG_type(ptr))
#define sk_CTLOG_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_CTLOG_sk_type(sk), ossl_check_CTLOG_type(ptr), pnum)
#define sk_CTLOG_sort(sk) OPENSSL_sk_sort(ossl_check_CTLOG_sk_type(sk))
#define sk_CTLOG_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_CTLOG_sk_type(sk))
#define sk_CTLOG_dup(sk) ((STACK_OF(CTLOG) *)OPENSSL_sk_dup(ossl_check_const_CTLOG_sk_type(sk)))
#define sk_CTLOG_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(CTLOG) *)OPENSSL_sk_deep_copy(ossl_check_const_CTLOG_sk_type(sk), ossl_check_CTLOG_copyfunc_type(copyfunc), ossl_check_CTLOG_freefunc_type(freefunc)))
#define sk_CTLOG_set_cmp_func(sk, cmp) ((sk_CTLOG_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_CTLOG_sk_type(sk), ossl_check_CTLOG_compfunc_type(cmp)))



typedef enum {
    CT_LOG_ENTRY_TYPE_NOT_SET = -1,
    CT_LOG_ENTRY_TYPE_X509 = 0,
    CT_LOG_ENTRY_TYPE_PRECERT = 1
} ct_log_entry_type_t;

typedef enum {
    SCT_VERSION_NOT_SET = -1,
    SCT_VERSION_V1 = 0
} sct_version_t;

typedef enum {
    SCT_SOURCE_UNKNOWN,
    SCT_SOURCE_TLS_EXTENSION,
    SCT_SOURCE_X509V3_EXTENSION,
    SCT_SOURCE_OCSP_STAPLED_RESPONSE
} sct_source_t;

typedef enum {
    SCT_VALIDATION_STATUS_NOT_SET,
    SCT_VALIDATION_STATUS_UNKNOWN_LOG,
    SCT_VALIDATION_STATUS_VALID,
    SCT_VALIDATION_STATUS_INVALID,
    SCT_VALIDATION_STATUS_UNVERIFIED,
    SCT_VALIDATION_STATUS_UNKNOWN_VERSION
} sct_validation_status_t;

/******************************************
 * CT policy evaluation context functions *
 ******************************************/

/*
 * Creates a new, empty policy evaluation context associated with the given
 * library context and property query string.
 * The caller is responsible for calling CT_POLICY_EVAL_CTX_free when finished
 * with the CT_POLICY_EVAL_CTX.
 */
CT_POLICY_EVAL_CTX *CT_POLICY_EVAL_CTX_new_ex(OSSL_LIB_CTX *libctx,
                                              const char *propq);
                                                       
/*
 * The same as CT_POLICY_EVAL_CTX_new_ex() but the default library
 * context and property query string is used.
 */
CT_POLICY_EVAL_CTX *CT_POLICY_EVAL_CTX_new(void);

/* Deletes a policy evaluation context and anything it owns. */
void CT_POLICY_EVAL_CTX_free(CT_POLICY_EVAL_CTX *ctx);

/* Gets the peer certificate that the SCTs are for */
X509* CT_POLICY_EVAL_CTX_get0_cert(const CT_POLICY_EVAL_CTX *ctx);

/*
 * Sets the certificate associated with the received SCTs.
 * Increments the reference count of cert.
 * Returns 1 on success, 0 otherwise.
 */
int CT_POLICY_EVAL_CTX_set1_cert(CT_POLICY_EVAL_CTX *ctx, X509 *cert);

/* Gets the issuer of the aforementioned certificate */
X509* CT_POLICY_EVAL_CTX_get0_issuer(const CT_POLICY_EVAL_CTX *ctx);

/*
 * Sets the issuer of the certificate associated with the received SCTs.
 * Increments the reference count of issuer.
 * Returns 1 on success, 0 otherwise.
 */
int CT_POLICY_EVAL_CTX_set1_issuer(CT_POLICY_EVAL_CTX *ctx, X509 *issuer);

/* Gets the CT logs that are trusted sources of SCTs */
const CTLOG_STORE *CT_POLICY_EVAL_CTX_get0_log_store(const CT_POLICY_EVAL_CTX *ctx);

/* Sets the log store that is in use. It must outlive the CT_POLICY_EVAL_CTX. */
void CT_POLICY_EVAL_CTX_set_shared_CTLOG_STORE(CT_POLICY_EVAL_CTX *ctx,
                                               CTLOG_STORE *log_store);

/*
 * Gets the time, in milliseconds since the Unix epoch, that will be used as the
 * current time when checking whether an SCT was issued in the future.
 * Such SCTs will fail validation, as required by RFC6962.
 */
uint64_t CT_POLICY_EVAL_CTX_get_time(const CT_POLICY_EVAL_CTX *ctx);

/*
 * Sets the time to evaluate SCTs against, in milliseconds since the Unix epoch.
 * If an SCT's timestamp is after this time, it will be interpreted as having
 * been issued in the future. RFC6962 states that "TLS clients MUST reject SCTs
 * whose timestamp is in the future", so an SCT will not validate in this case.
 */
void CT_POLICY_EVAL_CTX_set_time(CT_POLICY_EVAL_CTX *ctx, uint64_t time_in_ms);

/*****************
 * SCT functions *
 *****************/

/*
 * Creates a new, blank SCT.
 * The caller is responsible for calling SCT_free when finished with the SCT.
 */
SCT *SCT_new(void);

/*
 * Creates a new SCT from some base64-encoded strings.
 * The caller is responsible for calling SCT_free when finished with the SCT.
 */
SCT *SCT_new_from_base64(unsigned char version,
                         const char *logid_base64,
                         ct_log_entry_type_t entry_type,
                         uint64_t timestamp,
                         const char *extensions_base64,
                         const char *signature_base64);

/*
 * Frees the SCT and the underlying data structures.
 */
void SCT_free(SCT *sct);

/*
 * Free a stack of SCTs, and the underlying SCTs themselves.
 * Intended to be compatible with X509V3_EXT_FREE.
 */
void SCT_LIST_free(STACK_OF(SCT) *a);

/*
 * Returns the version of the SCT.
 */
sct_version_t SCT_get_version(const SCT *sct);

/*
 * Set the version of an SCT.
 * Returns 1 on success, 0 if the version is unrecognized.
 */
__owur int SCT_set_version(SCT *sct, sct_version_t version);

/*
 * Returns the log entry type of the SCT.
 */
ct_log_entry_type_t SCT_get_log_entry_type(const SCT *sct);

/*
 * Set the log entry type of an SCT.
 * Returns 1 on success, 0 otherwise.
 */
__owur int SCT_set_log_entry_type(SCT *sct, ct_log_entry_type_t entry_type);

/*
 * Gets the ID of the log that an SCT came from.
 * Ownership of the log ID remains with the SCT.
 * Returns the length of the log ID.
 */
size_t SCT_get0_log_id(const SCT *sct, unsigned char **log_id);

/*
 * Set the log ID of an SCT to point directly to the *log_id specified.
 * The SCT takes ownership of the specified pointer.
 * Returns 1 on success, 0 otherwise.
 */
__owur int SCT_set0_log_id(SCT *sct, unsigned char *log_id, size_t log_id_len);

/*
 * Set the log ID of an SCT.
 * This makes a copy of the log_id.
 * Returns 1 on success, 0 otherwise.
 */
__owur int SCT_set1_log_id(SCT *sct, const unsigned char *log_id,
                           size_t log_id_len);

/*
 * Returns the timestamp for the SCT (epoch time in milliseconds).
 */
uint64_t SCT_get_timestamp(const SCT *sct);

/*
 * Set the timestamp of an SCT (epoch time in milliseconds).
 */
void SCT_set_timestamp(SCT *sct, uint64_t timestamp);

/*
 * Return the NID for the signature used by the SCT.
 * For CT v1, this will be either NID_sha256WithRSAEncryption or
 * NID_ecdsa_with_SHA256 (or NID_undef if incorrect/unset).
 */
int SCT_get_signature_nid(const SCT *sct);

/*
 * Set the signature type of an SCT
 * For CT v1, this should be either NID_sha256WithRSAEncryption or
 * NID_ecdsa_with_SHA256.
 * Returns 1 on success, 0 otherwise.
 */
__owur int SCT_set_signature_nid(SCT *sct, int nid);

/*
 * Set *ext to point to the extension data for the SCT. ext must not be NULL.
 * The SCT retains ownership of this pointer.
 * Returns length of the data pointed to.
 */
size_t SCT_get0_extensions(const SCT *sct, unsigned char **ext);

/*
 * Set the extensions of an SCT to point directly to the *ext specified.
 * The SCT takes ownership of the specified pointer.
 */
void SCT_set0_extensions(SCT *sct, unsigned char *ext, size_t ext_len);

/*
 * Set the extensions of an SCT.
 * This takes a copy of the ext.
 * Returns 1 on success, 0 otherwise.
 */
__owur int SCT_set1_extensions(SCT *sct, const unsigned char *ext,
                               size_t ext_len);

/*
 * Set *sig to point to the signature for the SCT. sig must not be NULL.
 * The SCT retains ownership of this pointer.
 * Returns length of the data pointed to.
 */
size_t SCT_get0_signature(const SCT *sct, unsigned char **sig);

/*
 * Set the signature of an SCT to point directly to the *sig specified.
 * The SCT takes ownership of the specified pointer.
 */
void SCT_set0_signature(SCT *sct, unsigned char *sig, size_t sig_len);

/*
 * Set the signature of an SCT to be a copy of the *sig specified.
 * Returns 1 on success, 0 otherwise.
 */
__owur int SCT_set1_signature(SCT *sct, const unsigned char *sig,
                              size_t sig_len);

/*
 * The origin of this SCT, e.g. TLS extension, OCSP response, etc.
 */
sct_source_t SCT_get_source(const SCT *sct);

/*
 * Set the origin of this SCT, e.g. TLS extension, OCSP response, etc.
 * Returns 1 on success, 0 otherwise.
 */
__owur int SCT_set_source(SCT *sct, sct_source_t source);

/*
 * Returns a text string describing the validation status of |sct|.
 */
const char *SCT_validation_status_string(const SCT *sct);

/*
 * Pretty-prints an |sct| to |out|.
 * It will be indented by the number of spaces specified by |indent|.
 * If |logs| is not NULL, it will be used to lookup the CT log that the SCT came
 * from, so that the log name can be printed.
 */
void SCT_print(const SCT *sct, BIO *out, int indent, const CTLOG_STORE *logs);

/*
 * Pretty-prints an |sct_list| to |out|.
 * It will be indented by the number of spaces specified by |indent|.
 * SCTs will be delimited by |separator|.
 * If |logs| is not NULL, it will be used to lookup the CT log that each SCT
 * came from, so that the log names can be printed.
 */
void SCT_LIST_print(const STACK_OF(SCT) *sct_list, BIO *out, int indent,
                    const char *separator, const CTLOG_STORE *logs);

/*
 * Gets the last result of validating this SCT.
 * If it has not been validated yet, returns SCT_VALIDATION_STATUS_NOT_SET.
 */
sct_validation_status_t SCT_get_validation_status(const SCT *sct);

/*
 * Validates the given SCT with the provided context.
 * Sets the "validation_status" field of the SCT.
 * Returns 1 if the SCT is valid and the signature verifies.
 * Returns 0 if the SCT is invalid or could not be verified.
 * Returns -1 if an error occurs.
 */
__owur int SCT_validate(SCT *sct, const CT_POLICY_EVAL_CTX *ctx);

/*
 * Validates the given list of SCTs with the provided context.
 * Sets the "validation_status" field of each SCT.
 * Returns 1 if there are no invalid SCTs and all signatures verify.
 * Returns 0 if at least one SCT is invalid or could not be verified.
 * Returns a negative integer if an error occurs.
 */
__owur int SCT_LIST_validate(const STACK_OF(SCT) *scts,
                             CT_POLICY_EVAL_CTX *ctx);


/*********************************
 * SCT parsing and serialization *
 *********************************/

/*
 * Serialize (to TLS format) a stack of SCTs and return the length.
 * "a" must not be NULL.
 * If "pp" is NULL, just return the length of what would have been serialized.
 * If "pp" is not NULL and "*pp" is null, function will allocate a new pointer
 * for data that caller is responsible for freeing (only if function returns
 * successfully).
 * If "pp" is NULL and "*pp" is not NULL, caller is responsible for ensuring
 * that "*pp" is large enough to accept all of the serialized data.
 * Returns < 0 on error, >= 0 indicating bytes written (or would have been)
 * on success.
 */
__owur int i2o_SCT_LIST(const STACK_OF(SCT) *a, unsigned char **pp);

/*
 * Convert TLS format SCT list to a stack of SCTs.
 * If "a" or "*a" is NULL, a new stack will be created that the caller is
 * responsible for freeing (by calling SCT_LIST_free).
 * "**pp" and "*pp" must not be NULL.
 * Upon success, "*pp" will point to after the last bytes read, and a stack
 * will be returned.
 * Upon failure, a NULL pointer will be returned, and the position of "*pp" is
 * not defined.
 */
STACK_OF(SCT) *o2i_SCT_LIST(STACK_OF(SCT) **a, const unsigned char **pp,
                            size_t len);

/*
 * Serialize (to DER format) a stack of SCTs and return the length.
 * "a" must not be NULL.
 * If "pp" is NULL, just returns the length of what would have been serialized.
 * If "pp" is not NULL and "*pp" is null, function will allocate a new pointer
 * for data that caller is responsible for freeing (only if function returns
 * successfully).
 * If "pp" is NULL and "*pp" is not NULL, caller is responsible for ensuring
 * that "*pp" is large enough to accept all of the serialized data.
 * Returns < 0 on error, >= 0 indicating bytes written (or would have been)
 * on success.
 */
__owur int i2d_SCT_LIST(const STACK_OF(SCT) *a, unsigned char **pp);

/*
 * Parses an SCT list in DER format and returns it.
 * If "a" or "*a" is NULL, a new stack will be created that the caller is
 * responsible for freeing (by calling SCT_LIST_free).
 * "**pp" and "*pp" must not be NULL.
 * Upon success, "*pp" will point to after the last bytes read, and a stack
 * will be returned.
 * Upon failure, a NULL pointer will be returned, and the position of "*pp" is
 * not defined.
 */
STACK_OF(SCT) *d2i_SCT_LIST(STACK_OF(SCT) **a, const unsigned char **pp,
                            long len);

/*
 * Serialize (to TLS format) an |sct| and write it to |out|.
 * If |out| is null, no SCT will be output but the length will still be returned.
 * If |out| points to a null pointer, a string will be allocated to hold the
 * TLS-format SCT. It is the responsibility of the caller to free it.
 * If |out| points to an allocated string, the TLS-format SCT will be written
 * to it.
 * The length of the SCT in TLS format will be returned.
 */
__owur int i2o_SCT(const SCT *sct, unsigned char **out);

/*
 * Parses an SCT in TLS format and returns it.
 * If |psct| is not null, it will end up pointing to the parsed SCT. If it
 * already points to a non-null pointer, the pointer will be free'd.
 * |in| should be a pointer to a string containing the TLS-format SCT.
 * |in| will be advanced to the end of the SCT if parsing succeeds.
 * |len| should be the length of the SCT in |in|.
 * Returns NULL if an error occurs.
 * If the SCT is an unsupported version, only the SCT's 'sct' and 'sct_len'
 * fields will be populated (with |in| and |len| respectively).
 */
SCT *o2i_SCT(SCT **psct, const unsigned char **in, size_t len);

/********************
 * CT log functions *
 ********************/

/*
 * Creates a new CT log instance with the given |public_key| and |name| and
 * associates it with the give library context |libctx| and property query
 * string |propq|.
 * Takes ownership of |public_key| but copies |name|.
 * Returns NULL if malloc fails or if |public_key| cannot be converted to DER.
 * Should be deleted by the caller using CTLOG_free when no longer needed.
 */
CTLOG *CTLOG_new_ex(EVP_PKEY *public_key, const char *name, OSSL_LIB_CTX *libctx,
                    const char *propq);

/*
 * The same as CTLOG_new_ex except that the default library context and
 * property query string are used.
 */
CTLOG *CTLOG_new(EVP_PKEY *public_key, const char *name);

/*
 * Creates a new CTLOG instance with the base64-encoded SubjectPublicKeyInfo DER
 * in |pkey_base64| and associated with the given library context |libctx| and
 * property query string |propq|. The |name| is a string to help users identify
 * this log.
 * Returns 1 on success, 0 on failure.
 * Should be deleted by the caller using CTLOG_free when no longer needed.
 */
int CTLOG_new_from_base64_ex(CTLOG **ct_log, const char *pkey_base64,
                             const char *name, OSSL_LIB_CTX *libctx,
                             const char *propq);

/*
 * The same as CTLOG_new_from_base64_ex() except that the default
 * library context and property query string are used.
 * Returns 1 on success, 0 on failure.
 */
int CTLOG_new_from_base64(CTLOG ** ct_log,
                          const char *pkey_base64, const char *name);

/*
 * Deletes a CT log instance and its fields.
 */
void CTLOG_free(CTLOG *log);

/* Gets the name of the CT log */
const char *CTLOG_get0_name(const CTLOG *log);
/* Gets the ID of the CT log */
void CTLOG_get0_log_id(const CTLOG *log, const uint8_t **log_id,
                       size_t *log_id_len);
/* Gets the public key of the CT log */
EVP_PKEY *CTLOG_get0_public_key(const CTLOG *log);

/**************************
 * CT log store functions *
 **************************/

/*
 * Creates a new CT log store and associates it with the given libctx and
 * property query string.
 * Should be deleted by the caller using CTLOG_STORE_free when no longer needed.
 */
CTLOG_STORE *CTLOG_STORE_new_ex(OSSL_LIB_CTX *libctx, const char *propq);

/*
 * Same as CTLOG_STORE_new_ex except that the default libctx and
 * property query string are used.
 * Should be deleted by the caller using CTLOG_STORE_free when no longer needed.
 */
CTLOG_STORE *CTLOG_STORE_new(void);

/*
 * Deletes a CT log store and all of the CT log instances held within.
 */
void CTLOG_STORE_free(CTLOG_STORE *store);

/*
 * Finds a CT log in the store based on its log ID.
 * Returns the CT log, or NULL if no match is found.
 */
const CTLOG *CTLOG_STORE_get0_log_by_id(const CTLOG_STORE *store,
                                        const uint8_t *log_id,
                                        size_t log_id_len);

/*
 * Loads a CT log list into a |store| from a |file|.
 * Returns 1 if loading is successful, or 0 otherwise.
 */
__owur int CTLOG_STORE_load_file(CTLOG_STORE *store, const char *file);

/*
 * Loads the default CT log list into a |store|.
 * Returns 1 if loading is successful, or 0 otherwise.
 */
__owur int CTLOG_STORE_load_default_file(CTLOG_STORE *store);

#  ifdef  __cplusplus
}
#  endif
# endif
#endif
                                                                                                                                                                                                                                                                                   node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/openssl/err.h           0000664 0000000 0000000 00000052732 14746647661 0030654 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /*
 * Copyright 1995-2022 The OpenSSL Project Authors. All Rights Reserved.
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 */



#ifndef OPENSSL_ERR_H
# define OPENSSL_ERR_H
# pragma once

# include <openssl/macros.h>
# ifndef OPENSSL_NO_DEPRECATED_3_0
#  define HEADER_ERR_H
# endif

# include <openssl/e_os2.h>

# ifndef OPENSSL_NO_STDIO
#  include <stdio.h>
#  include <stdlib.h>
# endif

# include <openssl/types.h>
# include <openssl/bio.h>
# include <openssl/lhash.h>
# include <openssl/cryptoerr_legacy.h>

#ifdef  __cplusplus
extern "C" {
#endif

# ifndef OPENSSL_NO_DEPRECATED_3_0
#  ifndef OPENSSL_NO_FILENAMES
#   define ERR_PUT_error(l,f,r,fn,ln)      ERR_put_error(l,f,r,fn,ln)
#  else
#   define ERR_PUT_error(l,f,r,fn,ln)      ERR_put_error(l,f,r,NULL,0)
#  endif
# endif

# include <limits.h>
# include <errno.h>

# define ERR_TXT_MALLOCED        0x01
# define ERR_TXT_STRING          0x02

# if !defined(OPENSSL_NO_DEPRECATED_3_0) || defined(OSSL_FORCE_ERR_STATE)
#  define ERR_FLAG_MARK           0x01
#  define ERR_FLAG_CLEAR          0x02

#  define ERR_NUM_ERRORS  16
struct err_state_st {
    int err_flags[ERR_NUM_ERRORS];
    int err_marks[ERR_NUM_ERRORS];
    unsigned long err_buffer[ERR_NUM_ERRORS];
    char *err_data[ERR_NUM_ERRORS];
    size_t err_data_size[ERR_NUM_ERRORS];
    int err_data_flags[ERR_NUM_ERRORS];
    char *err_file[ERR_NUM_ERRORS];
    int err_line[ERR_NUM_ERRORS];
    char *err_func[ERR_NUM_ERRORS];
    int top, bottom;
};
# endif

/* library */
# define ERR_LIB_NONE            1
# define ERR_LIB_SYS             2
# define ERR_LIB_BN              3
# define ERR_LIB_RSA             4
# define ERR_LIB_DH              5
# define ERR_LIB_EVP             6
# define ERR_LIB_BUF             7
# define ERR_LIB_OBJ             8
# define ERR_LIB_PEM             9
# define ERR_LIB_DSA             10
# define ERR_LIB_X509            11
/* #define ERR_LIB_METH         12 */
# define ERR_LIB_ASN1            13
# define ERR_LIB_CONF            14
# define ERR_LIB_CRYPTO          15
# define ERR_LIB_EC              16
# define ERR_LIB_SSL             20
/* #define ERR_LIB_SSL23        21 */
/* #define ERR_LIB_SSL2         22 */
/* #define ERR_LIB_SSL3         23 */
/* #define ERR_LIB_RSAREF       30 */
/* #define ERR_LIB_PROXY        31 */
# define ERR_LIB_BIO             32
# define ERR_LIB_PKCS7           33
# define ERR_LIB_X509V3          34
# define ERR_LIB_PKCS12          35
# define ERR_LIB_RAND            36
# define ERR_LIB_DSO             37
# define ERR_LIB_ENGINE          38
# define ERR_LIB_OCSP            39
# define ERR_LIB_UI              40
# define ERR_LIB_COMP            41
# define ERR_LIB_ECDSA           42
# define ERR_LIB_ECDH            43
# define ERR_LIB_OSSL_STORE      44
# define ERR_LIB_FIPS            45
# define ERR_LIB_CMS             46
# define ERR_LIB_TS              47
# define ERR_LIB_HMAC            48
/* # define ERR_LIB_JPAKE       49 */
# define ERR_LIB_CT              50
# define ERR_LIB_ASYNC           51
# define ERR_LIB_KDF             52
# define ERR_LIB_SM2             53
# define ERR_LIB_ESS             54
# define ERR_LIB_PROP            55
# define ERR_LIB_CRMF            56
# define ERR_LIB_PROV            57
# define ERR_LIB_CMP             58
# define ERR_LIB_OSSL_ENCODER    59
# define ERR_LIB_OSSL_DECODER    60
# define ERR_LIB_HTTP            61

# define ERR_LIB_USER            128

# ifndef OPENSSL_NO_DEPRECATED_3_0
#  define ASN1err(f, r) ERR_raise_data(ERR_LIB_ASN1, (r), NULL)
#  define ASYNCerr(f, r) ERR_raise_data(ERR_LIB_ASYNC, (r), NULL)
#  define BIOerr(f, r) ERR_raise_data(ERR_LIB_BIO, (r), NULL)
#  define BNerr(f, r)  ERR_raise_data(ERR_LIB_BN, (r), NULL)
#  define BUFerr(f, r) ERR_raise_data(ERR_LIB_BUF, (r), NULL)
#  define CMPerr(f, r) ERR_raise_data(ERR_LIB_CMP, (r), NULL)
#  define CMSerr(f, r) ERR_raise_data(ERR_LIB_CMS, (r), NULL)
#  define COMPerr(f, r) ERR_raise_data(ERR_LIB_COMP, (r), NULL)
#  define CONFerr(f, r) ERR_raise_data(ERR_LIB_CONF, (r), NULL)
#  define CRMFerr(f, r) ERR_raise_data(ERR_LIB_CRMF, (r), NULL)
#  define CRYPTOerr(f, r) ERR_raise_data(ERR_LIB_CRYPTO, (r), NULL)
#  define CTerr(f, r) ERR_raise_data(ERR_LIB_CT, (r), NULL)
#  define DHerr(f, r)  ERR_raise_data(ERR_LIB_DH, (r), NULL)
#  define DSAerr(f, r) ERR_raise_data(ERR_LIB_DSA, (r), NULL)
#  define DSOerr(f, r) ERR_raise_data(ERR_LIB_DSO, (r), NULL)
#  define ECDHerr(f, r) ERR_raise_data(ERR_LIB_ECDH, (r), NULL)
#  define ECDSAerr(f, r) ERR_raise_data(ERR_LIB_ECDSA, (r), NULL)
#  define ECerr(f, r)  ERR_raise_data(ERR_LIB_EC, (r), NULL)
#  define ENGINEerr(f, r) ERR_raise_data(ERR_LIB_ENGINE, (r), NULL)
#  define ESSerr(f, r) ERR_raise_data(ERR_LIB_ESS, (r), NULL)
#  define EVPerr(f, r) ERR_raise_data(ERR_LIB_EVP, (r), NULL)
#  define FIPSerr(f, r) ERR_raise_data(ERR_LIB_FIPS, (r), NULL)
#  define HMACerr(f, r) ERR_raise_data(ERR_LIB_HMAC, (r), NULL)
#  define HTTPerr(f, r) ERR_raise_data(ERR_LIB_HTTP, (r), NULL)
#  define KDFerr(f, r) ERR_raise_data(ERR_LIB_KDF, (r), NULL)
#  define OBJerr(f, r) ERR_raise_data(ERR_LIB_OBJ, (r), NULL)
#  define OCSPerr(f, r) ERR_raise_data(ERR_LIB_OCSP, (r), NULL)
#  define OSSL_STOREerr(f, r) ERR_raise_data(ERR_LIB_OSSL_STORE, (r), NULL)
#  define PEMerr(f, r) ERR_raise_data(ERR_LIB_PEM, (r), NULL)
#  define PKCS12err(f, r) ERR_raise_data(ERR_LIB_PKCS12, (r), NULL)
#  define PKCS7err(f, r) ERR_raise_data(ERR_LIB_PKCS7, (r), NULL)
#  define PROPerr(f, r) ERR_raise_data(ERR_LIB_PROP, (r), NULL)
#  define PROVerr(f, r) ERR_raise_data(ERR_LIB_PROV, (r), NULL)
#  define RANDerr(f, r) ERR_raise_data(ERR_LIB_RAND, (r), NULL)
#  define RSAerr(f, r) ERR_raise_data(ERR_LIB_RSA, (r), NULL)
#  define KDFerr(f, r) ERR_raise_data(ERR_LIB_KDF, (r), NULL)
#  define SM2err(f, r) ERR_raise_data(ERR_LIB_SM2, (r), NULL)
#  define SSLerr(f, r) ERR_raise_data(ERR_LIB_SSL, (r), NULL)
#  define SYSerr(f, r) ERR_raise_data(ERR_LIB_SYS, (r), NULL)
#  define TSerr(f, r) ERR_raise_data(ERR_LIB_TS, (r), NULL)
#  define UIerr(f, r) ERR_raise_data(ERR_LIB_UI, (r), NULL)
#  define X509V3err(f, r) ERR_raise_data(ERR_LIB_X509V3, (r), NULL)
#  define X509err(f, r) ERR_raise_data(ERR_LIB_X509, (r), NULL)
# endif

/*-
 * The error code packs differently depending on if it records a system
 * error or an OpenSSL error.
 *
 * A system error packs like this (we follow POSIX and only allow positive
 * numbers that fit in an |int|):
 *
 * +-+-------------------------------------------------------------+
 * |1|                     system error number                     |
 * +-+-------------------------------------------------------------+
 *
 * An OpenSSL error packs like this:
 *
 * <---------------------------- 32 bits -------------------------->
 *    <--- 8 bits ---><------------------ 23 bits ----------------->
 * +-+---------------+---------------------------------------------+
 * |0|    library    |                    reason                   |
 * +-+---------------+---------------------------------------------+
 *
 * A few of the reason bits are reserved as flags with special meaning:
 *
 *                    <5 bits-<>--------- 19 bits ----------------->
 *                   +-------+-+-----------------------------------+
 *                   | rflags| |          reason                   |
 *                   +-------+-+-----------------------------------+
 *                            ^
 *                            |
 *                           ERR_RFLAG_FATAL = ERR_R_FATAL
 *
 * The reason flags are part of the overall reason code for practical
 * reasons, as they provide an easy way to place different types of
 * reason codes in different numeric ranges.
 *
 * The currently known reason flags are:
 *
 * ERR_RFLAG_FATAL      Flags that the reason code is considered fatal.
 *                      For backward compatibility reasons, this flag
 *                      is also the code for ERR_R_FATAL (that reason
 *                      code served the dual purpose of flag and reason
 *                      code in one in pre-3.0 OpenSSL).
 * ERR_RFLAG_COMMON     Flags that the reason code is common to all
 *                      libraries.  All ERR_R_ macros must use this flag,
 *                      and no other _R_ macro is allowed to use it.
 */

/* Macros to help decode recorded system errors */
# define ERR_SYSTEM_FLAG                ((unsigned int)INT_MAX + 1)
# define ERR_SYSTEM_MASK                ((unsigned int)INT_MAX)

/*
 * Macros to help decode recorded OpenSSL errors
 * As expressed above, RFLAGS and REASON overlap by one bit to allow
 * ERR_R_FATAL to use ERR_RFLAG_FATAL as its reason code.
 */
# define ERR_LIB_OFFSET                 23L
# define ERR_LIB_MASK                   0xFF
# define ERR_RFLAGS_OFFSET              18L
# define ERR_RFLAGS_MASK                0x1F
# define ERR_REASON_MASK                0X7FFFFF

/*
 * Reason flags are defined pre-shifted to easily combine with the reason
 * number.
 */
# define ERR_RFLAG_FATAL                (0x1 << ERR_RFLAGS_OFFSET)
# define ERR_RFLAG_COMMON               (0x2 << ERR_RFLAGS_OFFSET)

# define ERR_SYSTEM_ERROR(errcode)      (((errcode) & ERR_SYSTEM_FLAG) != 0)

static ossl_unused ossl_inline int ERR_GET_LIB(unsigned long errcode)
{
    if (ERR_SYSTEM_ERROR(errcode))
        return ERR_LIB_SYS;
    return (errcode >> ERR_LIB_OFFSET) & ERR_LIB_MASK;
}

static ossl_unused ossl_inline int ERR_GET_RFLAGS(unsigned long errcode)
{
    if (ERR_SYSTEM_ERROR(errcode))
        return 0;
    return errcode & (ERR_RFLAGS_MASK << ERR_RFLAGS_OFFSET);
}

static ossl_unused ossl_inline int ERR_GET_REASON(unsigned long errcode)
{
    if (ERR_SYSTEM_ERROR(errcode))
        return errcode & ERR_SYSTEM_MASK;
    return errcode & ERR_REASON_MASK;
}

static ossl_unused ossl_inline int ERR_FATAL_ERROR(unsigned long errcode)
{
    return (ERR_GET_RFLAGS(errcode) & ERR_RFLAG_FATAL) != 0;
}

static ossl_unused ossl_inline int ERR_COMMON_ERROR(unsigned long errcode)
{
    return (ERR_GET_RFLAGS(errcode) & ERR_RFLAG_COMMON) != 0;
}

/*
 * ERR_PACK is a helper macro to properly pack OpenSSL error codes and may
 * only be used for that purpose.  System errors are packed internally.
 * ERR_PACK takes reason flags and reason code combined in |reason|.
 * ERR_PACK ignores |func|, that parameter is just legacy from pre-3.0 OpenSSL.
 */
# define ERR_PACK(lib,func,reason)                                      \
    ( (((unsigned long)(lib)    & ERR_LIB_MASK   ) << ERR_LIB_OFFSET) | \
      (((unsigned long)(reason) & ERR_REASON_MASK)) )

# ifndef OPENSSL_NO_DEPRECATED_3_0
#  define SYS_F_FOPEN             0
#  define SYS_F_CONNECT           0
#  define SYS_F_GETSERVBYNAME     0
#  define SYS_F_SOCKET            0
#  define SYS_F_IOCTLSOCKET       0
#  define SYS_F_BIND              0
#  define SYS_F_LISTEN            0
#  define SYS_F_ACCEPT            0
#  define SYS_F_WSASTARTUP        0
#  define SYS_F_OPENDIR           0
#  define SYS_F_FREAD             0
#  define SYS_F_GETADDRINFO       0
#  define SYS_F_GETNAMEINFO       0
#  define SYS_F_SETSOCKOPT        0
#  define SYS_F_GETSOCKOPT        0
#  define SYS_F_GETSOCKNAME       0
#  define SYS_F_GETHOSTBYNAME     0
#  define SYS_F_FFLUSH            0
#  define SYS_F_OPEN              0
#  define SYS_F_CLOSE             0
#  define SYS_F_IOCTL             0
#  define SYS_F_STAT              0
#  define SYS_F_FCNTL             0
#  define SYS_F_FSTAT             0
#  define SYS_F_SENDFILE          0
# endif

/*
 * All ERR_R_ codes must be combined with ERR_RFLAG_COMMON.
 */

/* "we came from here" global reason codes, range 1..255 */
# define ERR_R_SYS_LIB          (ERR_LIB_SYS/* 2 */ | ERR_RFLAG_COMMON)
# define ERR_R_BN_LIB           (ERR_LIB_BN/* 3 */ | ERR_RFLAG_COMMON)
# define ERR_R_RSA_LIB          (ERR_LIB_RSA/* 4 */ | ERR_RFLAG_COMMON)
# define ERR_R_DH_LIB           (ERR_LIB_DH/* 5 */ | ERR_RFLAG_COMMON)
# define ERR_R_EVP_LIB          (ERR_LIB_EVP/* 6 */ | ERR_RFLAG_COMMON)
# define ERR_R_BUF_LIB          (ERR_LIB_BUF/* 7 */ | ERR_RFLAG_COMMON)
# define ERR_R_OBJ_LIB          (ERR_LIB_OBJ/* 8 */ | ERR_RFLAG_COMMON)
# define ERR_R_PEM_LIB          (ERR_LIB_PEM/* 9 */ | ERR_RFLAG_COMMON)
# define ERR_R_DSA_LIB          (ERR_LIB_DSA/* 10 */ | ERR_RFLAG_COMMON)
# define ERR_R_X509_LIB         (ERR_LIB_X509/* 11 */ | ERR_RFLAG_COMMON)
# define ERR_R_ASN1_LIB         (ERR_LIB_ASN1/* 13 */ | ERR_RFLAG_COMMON)
# define ERR_R_CONF_LIB         (ERR_LIB_CONF/* 14 */ | ERR_RFLAG_COMMON)
# define ERR_R_CRYPTO_LIB       (ERR_LIB_CRYPTO/* 15 */ | ERR_RFLAG_COMMON)
# define ERR_R_EC_LIB           (ERR_LIB_EC/* 16 */ | ERR_RFLAG_COMMON)
# define ERR_R_SSL_LIB          (ERR_LIB_SSL/* 20 */ | ERR_RFLAG_COMMON)
# define ERR_R_BIO_LIB          (ERR_LIB_BIO/* 32 */ | ERR_RFLAG_COMMON)
# define ERR_R_PKCS7_LIB        (ERR_LIB_PKCS7/* 33 */ | ERR_RFLAG_COMMON)
# define ERR_R_X509V3_LIB       (ERR_LIB_X509V3/* 34 */ | ERR_RFLAG_COMMON)
# define ERR_R_PKCS12_LIB       (ERR_LIB_PKCS12/* 35 */ | ERR_RFLAG_COMMON)
# define ERR_R_RAND_LIB         (ERR_LIB_RAND/* 36 */ | ERR_RFLAG_COMMON)
# define ERR_R_DSO_LIB          (ERR_LIB_DSO/* 37 */ | ERR_RFLAG_COMMON)
# define ERR_R_ENGINE_LIB       (ERR_LIB_ENGINE/* 38 */ | ERR_RFLAG_COMMON)
# define ERR_R_UI_LIB           (ERR_LIB_UI/* 40 */ | ERR_RFLAG_COMMON)
# define ERR_R_ECDSA_LIB        (ERR_LIB_ECDSA/* 42 */ | ERR_RFLAG_COMMON)
# define ERR_R_OSSL_STORE_LIB   (ERR_LIB_OSSL_STORE/* 44 */ | ERR_RFLAG_COMMON)
# define ERR_R_CMS_LIB          (ERR_LIB_CMS/* 46 */ | ERR_RFLAG_COMMON)
# define ERR_R_TS_LIB           (ERR_LIB_TS/* 47 */ | ERR_RFLAG_COMMON)
# define ERR_R_CT_LIB           (ERR_LIB_CT/* 50 */ | ERR_RFLAG_COMMON)
# define ERR_R_PROV_LIB         (ERR_LIB_PROV/* 57 */ | ERR_RFLAG_COMMON)
# define ERR_R_ESS_LIB          (ERR_LIB_ESS/* 54 */ | ERR_RFLAG_COMMON)
# define ERR_R_CMP_LIB          (ERR_LIB_CMP/* 58 */ | ERR_RFLAG_COMMON)
# define ERR_R_OSSL_ENCODER_LIB (ERR_LIB_OSSL_ENCODER/* 59 */ | ERR_RFLAG_COMMON)
# define ERR_R_OSSL_DECODER_LIB (ERR_LIB_OSSL_DECODER/* 60 */ | ERR_RFLAG_COMMON)

/* Other common error codes, range 256..2^ERR_RFLAGS_OFFSET-1 */
# define ERR_R_FATAL                             (ERR_RFLAG_FATAL|ERR_RFLAG_COMMON)
# define ERR_R_MALLOC_FAILURE                    (256|ERR_R_FATAL)
# define ERR_R_SHOULD_NOT_HAVE_BEEN_CALLED       (257|ERR_R_FATAL)
# define ERR_R_PASSED_NULL_PARAMETER             (258|ERR_R_FATAL)
# define ERR_R_INTERNAL_ERROR                    (259|ERR_R_FATAL)
# define ERR_R_DISABLED                          (260|ERR_R_FATAL)
# define ERR_R_INIT_FAIL                         (261|ERR_R_FATAL)
# define ERR_R_PASSED_INVALID_ARGUMENT           (262|ERR_RFLAG_COMMON)
# define ERR_R_OPERATION_FAIL                    (263|ERR_R_FATAL)
# define ERR_R_INVALID_PROVIDER_FUNCTIONS        (264|ERR_R_FATAL)
# define ERR_R_INTERRUPTED_OR_CANCELLED          (265|ERR_RFLAG_COMMON)
# define ERR_R_NESTED_ASN1_ERROR                 (266|ERR_RFLAG_COMMON)
# define ERR_R_MISSING_ASN1_EOS                  (267|ERR_RFLAG_COMMON)
# define ERR_R_UNSUPPORTED                       (268|ERR_RFLAG_COMMON)
# define ERR_R_FETCH_FAILED                      (269|ERR_RFLAG_COMMON)
# define ERR_R_INVALID_PROPERTY_DEFINITION       (270|ERR_RFLAG_COMMON)
# define ERR_R_UNABLE_TO_GET_READ_LOCK           (271|ERR_R_FATAL)
# define ERR_R_UNABLE_TO_GET_WRITE_LOCK          (272|ERR_R_FATAL)

typedef struct ERR_string_data_st {
    unsigned long error;
    const char *string;
} ERR_STRING_DATA;

DEFINE_LHASH_OF_INTERNAL(ERR_STRING_DATA);
#define lh_ERR_STRING_DATA_new(hfn, cmp) ((LHASH_OF(ERR_STRING_DATA) *)OPENSSL_LH_new(ossl_check_ERR_STRING_DATA_lh_hashfunc_type(hfn), ossl_check_ERR_STRING_DATA_lh_compfunc_type(cmp)))
#define lh_ERR_STRING_DATA_free(lh) OPENSSL_LH_free(ossl_check_ERR_STRING_DATA_lh_type(lh))
#define lh_ERR_STRING_DATA_flush(lh) OPENSSL_LH_flush(ossl_check_ERR_STRING_DATA_lh_type(lh))
#define lh_ERR_STRING_DATA_insert(lh, ptr) ((ERR_STRING_DATA *)OPENSSL_LH_insert(ossl_check_ERR_STRING_DATA_lh_type(lh), ossl_check_ERR_STRING_DATA_lh_plain_type(ptr)))
#define lh_ERR_STRING_DATA_delete(lh, ptr) ((ERR_STRING_DATA *)OPENSSL_LH_delete(ossl_check_ERR_STRING_DATA_lh_type(lh), ossl_check_const_ERR_STRING_DATA_lh_plain_type(ptr)))
#define lh_ERR_STRING_DATA_retrieve(lh, ptr) ((ERR_STRING_DATA *)OPENSSL_LH_retrieve(ossl_check_ERR_STRING_DATA_lh_type(lh), ossl_check_const_ERR_STRING_DATA_lh_plain_type(ptr)))
#define lh_ERR_STRING_DATA_error(lh) OPENSSL_LH_error(ossl_check_ERR_STRING_DATA_lh_type(lh))
#define lh_ERR_STRING_DATA_num_items(lh) OPENSSL_LH_num_items(ossl_check_ERR_STRING_DATA_lh_type(lh))
#define lh_ERR_STRING_DATA_node_stats_bio(lh, out) OPENSSL_LH_node_stats_bio(ossl_check_const_ERR_STRING_DATA_lh_type(lh), out)
#define lh_ERR_STRING_DATA_node_usage_stats_bio(lh, out) OPENSSL_LH_node_usage_stats_bio(ossl_check_const_ERR_STRING_DATA_lh_type(lh), out)
#define lh_ERR_STRING_DATA_stats_bio(lh, out) OPENSSL_LH_stats_bio(ossl_check_const_ERR_STRING_DATA_lh_type(lh), out)
#define lh_ERR_STRING_DATA_get_down_load(lh) OPENSSL_LH_get_down_load(ossl_check_ERR_STRING_DATA_lh_type(lh))
#define lh_ERR_STRING_DATA_set_down_load(lh, dl) OPENSSL_LH_set_down_load(ossl_check_ERR_STRING_DATA_lh_type(lh), dl)
#define lh_ERR_STRING_DATA_doall(lh, dfn) OPENSSL_LH_doall(ossl_check_ERR_STRING_DATA_lh_type(lh), ossl_check_ERR_STRING_DATA_lh_doallfunc_type(dfn))


/* 12 lines and some on an 80 column terminal */
#define ERR_MAX_DATA_SIZE       1024

/* Building blocks */
void ERR_new(void);
void ERR_set_debug(const char *file, int line, const char *func);
void ERR_set_error(int lib, int reason, const char *fmt, ...);
void ERR_vset_error(int lib, int reason, const char *fmt, va_list args);

/* Main error raising functions */
# define ERR_raise(lib, reason) ERR_raise_data((lib),(reason),NULL)
# define ERR_raise_data                                         \
    (ERR_new(),                                                 \
     ERR_set_debug(OPENSSL_FILE,OPENSSL_LINE,OPENSSL_FUNC),     \
     ERR_set_error)

# ifndef OPENSSL_NO_DEPRECATED_3_0
/* Backward compatibility */
#  define ERR_put_error(lib, func, reason, file, line)          \
    (ERR_new(),                                                 \
     ERR_set_debug((file), (line), OPENSSL_FUNC),               \
     ERR_set_error((lib), (reason), NULL))
# endif

void ERR_set_error_data(char *data, int flags);

unsigned long ERR_get_error(void);
unsigned long ERR_get_error_all(const char **file, int *line,
                                const char **func,
                                const char **data, int *flags);
# ifndef OPENSSL_NO_DEPRECATED_3_0
OSSL_DEPRECATEDIN_3_0
unsigned long ERR_get_error_line(const char **file, int *line);
OSSL_DEPRECATEDIN_3_0
unsigned long ERR_get_error_line_data(const char **file, int *line,
                                      const char **data, int *flags);
#endif
unsigned long ERR_peek_error(void);
unsigned long ERR_peek_error_line(const char **file, int *line);
unsigned long ERR_peek_error_func(const char **func);
unsigned long ERR_peek_error_data(const char **data, int *flags);
unsigned long ERR_peek_error_all(const char **file, int *line,
                                 const char **func,
                                 const char **data, int *flags);
# ifndef OPENSSL_NO_DEPRECATED_3_0
OSSL_DEPRECATEDIN_3_0
unsigned long ERR_peek_error_line_data(const char **file, int *line,
                                       const char **data, int *flags);
# endif
unsigned long ERR_peek_last_error(void);
unsigned long ERR_peek_last_error_line(const char **file, int *line);
unsigned long ERR_peek_last_error_func(const char **func);
unsigned long ERR_peek_last_error_data(const char **data, int *flags);
unsigned long ERR_peek_last_error_all(const char **file, int *line,
                                      const char **func,
                                      const char **data, int *flags);
# ifndef OPENSSL_NO_DEPRECATED_3_0
OSSL_DEPRECATEDIN_3_0
unsigned long ERR_peek_last_error_line_data(const char **file, int *line,
                                            const char **data, int *flags);
# endif

void ERR_clear_error(void);

char *ERR_error_string(unsigned long e, char *buf);
void ERR_error_string_n(unsigned long e, char *buf, size_t len);
const char *ERR_lib_error_string(unsigned long e);
# ifndef OPENSSL_NO_DEPRECATED_3_0
OSSL_DEPRECATEDIN_3_0 const char *ERR_func_error_string(unsigned long e);
# endif
const char *ERR_reason_error_string(unsigned long e);

void ERR_print_errors_cb(int (*cb) (const char *str, size_t len, void *u),
                         void *u);
# ifndef OPENSSL_NO_STDIO
void ERR_print_errors_fp(FILE *fp);
# endif
void ERR_print_errors(BIO *bp);

void ERR_add_error_data(int num, ...);
void ERR_add_error_vdata(int num, va_list args);
void ERR_add_error_txt(const char *sepr, const char *txt);
void ERR_add_error_mem_bio(const char *sep, BIO *bio);

int ERR_load_strings(int lib, ERR_STRING_DATA *str);
int ERR_load_strings_const(const ERR_STRING_DATA *str);
int ERR_unload_strings(int lib, ERR_STRING_DATA *str);

#ifndef OPENSSL_NO_DEPRECATED_1_1_0
# define ERR_load_crypto_strings() \
    OPENSSL_init_crypto(OPENSSL_INIT_LOAD_CRYPTO_STRINGS, NULL)
# define ERR_free_strings() while(0) continue
#endif
#ifndef OPENSSL_NO_DEPRECATED_1_1_0
OSSL_DEPRECATEDIN_1_1_0 void ERR_remove_thread_state(void *);
#endif
#ifndef OPENSSL_NO_DEPRECATED_1_0_0
OSSL_DEPRECATEDIN_1_0_0 void ERR_remove_state(unsigned long pid);
#endif
#ifndef OPENSSL_NO_DEPRECATED_3_0
OSSL_DEPRECATEDIN_3_0 ERR_STATE *ERR_get_state(void);
#endif

int ERR_get_next_error_library(void);

int ERR_set_mark(void);
int ERR_pop_to_mark(void);
int ERR_clear_last_mark(void);

#ifdef  __cplusplus
}
#endif

#endif
                                      node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/openssl/ess.h           0000664 0000000 0000000 00000021410 14746647661 0030643 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /*
 * WARNING: do not edit!
 * Generated by Makefile from include/openssl/ess.h.in
 *
 * Copyright 2019-2021 The OpenSSL Project Authors. All Rights Reserved.
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 */



#ifndef OPENSSL_ESS_H
# define OPENSSL_ESS_H
# pragma once

# include <openssl/opensslconf.h>

# include <openssl/safestack.h>
# include <openssl/x509.h>
# include <openssl/esserr.h>

# ifdef  __cplusplus
extern "C" {
# endif


typedef struct ESS_issuer_serial ESS_ISSUER_SERIAL;
typedef struct ESS_cert_id ESS_CERT_ID;
typedef struct ESS_signing_cert ESS_SIGNING_CERT;

SKM_DEFINE_STACK_OF_INTERNAL(ESS_CERT_ID, ESS_CERT_ID, ESS_CERT_ID)
#define sk_ESS_CERT_ID_num(sk) OPENSSL_sk_num(ossl_check_const_ESS_CERT_ID_sk_type(sk))
#define sk_ESS_CERT_ID_value(sk, idx) ((ESS_CERT_ID *)OPENSSL_sk_value(ossl_check_const_ESS_CERT_ID_sk_type(sk), (idx)))
#define sk_ESS_CERT_ID_new(cmp) ((STACK_OF(ESS_CERT_ID) *)OPENSSL_sk_new(ossl_check_ESS_CERT_ID_compfunc_type(cmp)))
#define sk_ESS_CERT_ID_new_null() ((STACK_OF(ESS_CERT_ID) *)OPENSSL_sk_new_null())
#define sk_ESS_CERT_ID_new_reserve(cmp, n) ((STACK_OF(ESS_CERT_ID) *)OPENSSL_sk_new_reserve(ossl_check_ESS_CERT_ID_compfunc_type(cmp), (n)))
#define sk_ESS_CERT_ID_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_ESS_CERT_ID_sk_type(sk), (n))
#define sk_ESS_CERT_ID_free(sk) OPENSSL_sk_free(ossl_check_ESS_CERT_ID_sk_type(sk))
#define sk_ESS_CERT_ID_zero(sk) OPENSSL_sk_zero(ossl_check_ESS_CERT_ID_sk_type(sk))
#define sk_ESS_CERT_ID_delete(sk, i) ((ESS_CERT_ID *)OPENSSL_sk_delete(ossl_check_ESS_CERT_ID_sk_type(sk), (i)))
#define sk_ESS_CERT_ID_delete_ptr(sk, ptr) ((ESS_CERT_ID *)OPENSSL_sk_delete_ptr(ossl_check_ESS_CERT_ID_sk_type(sk), ossl_check_ESS_CERT_ID_type(ptr)))
#define sk_ESS_CERT_ID_push(sk, ptr) OPENSSL_sk_push(ossl_check_ESS_CERT_ID_sk_type(sk), ossl_check_ESS_CERT_ID_type(ptr))
#define sk_ESS_CERT_ID_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_ESS_CERT_ID_sk_type(sk), ossl_check_ESS_CERT_ID_type(ptr))
#define sk_ESS_CERT_ID_pop(sk) ((ESS_CERT_ID *)OPENSSL_sk_pop(ossl_check_ESS_CERT_ID_sk_type(sk)))
#define sk_ESS_CERT_ID_shift(sk) ((ESS_CERT_ID *)OPENSSL_sk_shift(ossl_check_ESS_CERT_ID_sk_type(sk)))
#define sk_ESS_CERT_ID_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_ESS_CERT_ID_sk_type(sk),ossl_check_ESS_CERT_ID_freefunc_type(freefunc))
#define sk_ESS_CERT_ID_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_ESS_CERT_ID_sk_type(sk), ossl_check_ESS_CERT_ID_type(ptr), (idx))
#define sk_ESS_CERT_ID_set(sk, idx, ptr) ((ESS_CERT_ID *)OPENSSL_sk_set(ossl_check_ESS_CERT_ID_sk_type(sk), (idx), ossl_check_ESS_CERT_ID_type(ptr)))
#define sk_ESS_CERT_ID_find(sk, ptr) OPENSSL_sk_find(ossl_check_ESS_CERT_ID_sk_type(sk), ossl_check_ESS_CERT_ID_type(ptr))
#define sk_ESS_CERT_ID_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_ESS_CERT_ID_sk_type(sk), ossl_check_ESS_CERT_ID_type(ptr))
#define sk_ESS_CERT_ID_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_ESS_CERT_ID_sk_type(sk), ossl_check_ESS_CERT_ID_type(ptr), pnum)
#define sk_ESS_CERT_ID_sort(sk) OPENSSL_sk_sort(ossl_check_ESS_CERT_ID_sk_type(sk))
#define sk_ESS_CERT_ID_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_ESS_CERT_ID_sk_type(sk))
#define sk_ESS_CERT_ID_dup(sk) ((STACK_OF(ESS_CERT_ID) *)OPENSSL_sk_dup(ossl_check_const_ESS_CERT_ID_sk_type(sk)))
#define sk_ESS_CERT_ID_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(ESS_CERT_ID) *)OPENSSL_sk_deep_copy(ossl_check_const_ESS_CERT_ID_sk_type(sk), ossl_check_ESS_CERT_ID_copyfunc_type(copyfunc), ossl_check_ESS_CERT_ID_freefunc_type(freefunc)))
#define sk_ESS_CERT_ID_set_cmp_func(sk, cmp) ((sk_ESS_CERT_ID_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_ESS_CERT_ID_sk_type(sk), ossl_check_ESS_CERT_ID_compfunc_type(cmp)))



typedef struct ESS_signing_cert_v2_st ESS_SIGNING_CERT_V2;
typedef struct ESS_cert_id_v2_st ESS_CERT_ID_V2;

SKM_DEFINE_STACK_OF_INTERNAL(ESS_CERT_ID_V2, ESS_CERT_ID_V2, ESS_CERT_ID_V2)
#define sk_ESS_CERT_ID_V2_num(sk) OPENSSL_sk_num(ossl_check_const_ESS_CERT_ID_V2_sk_type(sk))
#define sk_ESS_CERT_ID_V2_value(sk, idx) ((ESS_CERT_ID_V2 *)OPENSSL_sk_value(ossl_check_const_ESS_CERT_ID_V2_sk_type(sk), (idx)))
#define sk_ESS_CERT_ID_V2_new(cmp) ((STACK_OF(ESS_CERT_ID_V2) *)OPENSSL_sk_new(ossl_check_ESS_CERT_ID_V2_compfunc_type(cmp)))
#define sk_ESS_CERT_ID_V2_new_null() ((STACK_OF(ESS_CERT_ID_V2) *)OPENSSL_sk_new_null())
#define sk_ESS_CERT_ID_V2_new_reserve(cmp, n) ((STACK_OF(ESS_CERT_ID_V2) *)OPENSSL_sk_new_reserve(ossl_check_ESS_CERT_ID_V2_compfunc_type(cmp), (n)))
#define sk_ESS_CERT_ID_V2_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_ESS_CERT_ID_V2_sk_type(sk), (n))
#define sk_ESS_CERT_ID_V2_free(sk) OPENSSL_sk_free(ossl_check_ESS_CERT_ID_V2_sk_type(sk))
#define sk_ESS_CERT_ID_V2_zero(sk) OPENSSL_sk_zero(ossl_check_ESS_CERT_ID_V2_sk_type(sk))
#define sk_ESS_CERT_ID_V2_delete(sk, i) ((ESS_CERT_ID_V2 *)OPENSSL_sk_delete(ossl_check_ESS_CERT_ID_V2_sk_type(sk), (i)))
#define sk_ESS_CERT_ID_V2_delete_ptr(sk, ptr) ((ESS_CERT_ID_V2 *)OPENSSL_sk_delete_ptr(ossl_check_ESS_CERT_ID_V2_sk_type(sk), ossl_check_ESS_CERT_ID_V2_type(ptr)))
#define sk_ESS_CERT_ID_V2_push(sk, ptr) OPENSSL_sk_push(ossl_check_ESS_CERT_ID_V2_sk_type(sk), ossl_check_ESS_CERT_ID_V2_type(ptr))
#define sk_ESS_CERT_ID_V2_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_ESS_CERT_ID_V2_sk_type(sk), ossl_check_ESS_CERT_ID_V2_type(ptr))
#define sk_ESS_CERT_ID_V2_pop(sk) ((ESS_CERT_ID_V2 *)OPENSSL_sk_pop(ossl_check_ESS_CERT_ID_V2_sk_type(sk)))
#define sk_ESS_CERT_ID_V2_shift(sk) ((ESS_CERT_ID_V2 *)OPENSSL_sk_shift(ossl_check_ESS_CERT_ID_V2_sk_type(sk)))
#define sk_ESS_CERT_ID_V2_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_ESS_CERT_ID_V2_sk_type(sk),ossl_check_ESS_CERT_ID_V2_freefunc_type(freefunc))
#define sk_ESS_CERT_ID_V2_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_ESS_CERT_ID_V2_sk_type(sk), ossl_check_ESS_CERT_ID_V2_type(ptr), (idx))
#define sk_ESS_CERT_ID_V2_set(sk, idx, ptr) ((ESS_CERT_ID_V2 *)OPENSSL_sk_set(ossl_check_ESS_CERT_ID_V2_sk_type(sk), (idx), ossl_check_ESS_CERT_ID_V2_type(ptr)))
#define sk_ESS_CERT_ID_V2_find(sk, ptr) OPENSSL_sk_find(ossl_check_ESS_CERT_ID_V2_sk_type(sk), ossl_check_ESS_CERT_ID_V2_type(ptr))
#define sk_ESS_CERT_ID_V2_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_ESS_CERT_ID_V2_sk_type(sk), ossl_check_ESS_CERT_ID_V2_type(ptr))
#define sk_ESS_CERT_ID_V2_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_ESS_CERT_ID_V2_sk_type(sk), ossl_check_ESS_CERT_ID_V2_type(ptr), pnum)
#define sk_ESS_CERT_ID_V2_sort(sk) OPENSSL_sk_sort(ossl_check_ESS_CERT_ID_V2_sk_type(sk))
#define sk_ESS_CERT_ID_V2_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_ESS_CERT_ID_V2_sk_type(sk))
#define sk_ESS_CERT_ID_V2_dup(sk) ((STACK_OF(ESS_CERT_ID_V2) *)OPENSSL_sk_dup(ossl_check_const_ESS_CERT_ID_V2_sk_type(sk)))
#define sk_ESS_CERT_ID_V2_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(ESS_CERT_ID_V2) *)OPENSSL_sk_deep_copy(ossl_check_const_ESS_CERT_ID_V2_sk_type(sk), ossl_check_ESS_CERT_ID_V2_copyfunc_type(copyfunc), ossl_check_ESS_CERT_ID_V2_freefunc_type(freefunc)))
#define sk_ESS_CERT_ID_V2_set_cmp_func(sk, cmp) ((sk_ESS_CERT_ID_V2_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_ESS_CERT_ID_V2_sk_type(sk), ossl_check_ESS_CERT_ID_V2_compfunc_type(cmp)))


DECLARE_ASN1_ALLOC_FUNCTIONS(ESS_ISSUER_SERIAL)
DECLARE_ASN1_ENCODE_FUNCTIONS_only(ESS_ISSUER_SERIAL, ESS_ISSUER_SERIAL)
DECLARE_ASN1_DUP_FUNCTION(ESS_ISSUER_SERIAL)

DECLARE_ASN1_ALLOC_FUNCTIONS(ESS_CERT_ID)
DECLARE_ASN1_ENCODE_FUNCTIONS_only(ESS_CERT_ID, ESS_CERT_ID)
DECLARE_ASN1_DUP_FUNCTION(ESS_CERT_ID)

DECLARE_ASN1_FUNCTIONS(ESS_SIGNING_CERT)
DECLARE_ASN1_DUP_FUNCTION(ESS_SIGNING_CERT)

DECLARE_ASN1_ALLOC_FUNCTIONS(ESS_CERT_ID_V2)
DECLARE_ASN1_ENCODE_FUNCTIONS_only(ESS_CERT_ID_V2, ESS_CERT_ID_V2)
DECLARE_ASN1_DUP_FUNCTION(ESS_CERT_ID_V2)

DECLARE_ASN1_FUNCTIONS(ESS_SIGNING_CERT_V2)
DECLARE_ASN1_DUP_FUNCTION(ESS_SIGNING_CERT_V2)

ESS_SIGNING_CERT *OSSL_ESS_signing_cert_new_init(const X509 *signcert,
                                                 const STACK_OF(X509) *certs,
                                                 int set_issuer_serial);
ESS_SIGNING_CERT_V2 *OSSL_ESS_signing_cert_v2_new_init(const EVP_MD *hash_alg,
                                                       const X509 *signcert,
                                                       const
                                                       STACK_OF(X509) *certs,
                                                       int set_issuer_serial);
int OSSL_ESS_check_signing_certs(const ESS_SIGNING_CERT *ss,
                                 const ESS_SIGNING_CERT_V2 *ssv2,
                                 const STACK_OF(X509) *chain,
                                 int require_signing_cert);

# ifdef  __cplusplus
}
# endif
#endif
                                                                                                                                                                                                                                                        node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/openssl/fipskey.h       0000664 0000000 0000000 00000001762 14746647661 0031533 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /*
 * WARNING: do not edit!
 * Generated by Makefile from include/openssl/fipskey.h.in
 *
 * Copyright 2020-2021 The OpenSSL Project Authors. All Rights Reserved.
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 */

#ifndef OPENSSL_FIPSKEY_H
# define OPENSSL_FIPSKEY_H
# pragma once

# ifdef  __cplusplus
extern "C" {
# endif

/*
 * The FIPS validation HMAC key, usable as an array initializer.
 */
#define FIPS_KEY_ELEMENTS \
    0xf4, 0x55, 0x66, 0x50, 0xac, 0x31, 0xd3, 0x54, 0x61, 0x61, 0x0b, 0xac, 0x4e, 0xd8, 0x1b, 0x1a, 0x18, 0x1b, 0x2d, 0x8a, 0x43, 0xea, 0x28, 0x54, 0xcb, 0xae, 0x22, 0xca, 0x74, 0x56, 0x08, 0x13

/*
 * The FIPS validation key, as a string.
 */
#define FIPS_KEY_STRING "f4556650ac31d35461610bac4ed81b1a181b2d8a43ea2854cbae22ca74560813"

# ifdef  __cplusplus
}
# endif

#endif
              node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/openssl/lhash.h         0000664 0000000 0000000 00000033355 14746647661 0031163 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /*
 * Copyright 1995-2021 The OpenSSL Project Authors. All Rights Reserved.
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 */



/*
 * Header for dynamic hash table routines Author - Eric Young
 */

#ifndef OPENSSL_LHASH_H
# define OPENSSL_LHASH_H
# pragma once

# include <openssl/macros.h>
# ifndef OPENSSL_NO_DEPRECATED_3_0
#  define HEADER_LHASH_H
# endif

# include <openssl/e_os2.h>
# include <openssl/bio.h>

#ifdef  __cplusplus
extern "C" {
#endif

typedef struct lhash_node_st OPENSSL_LH_NODE;
typedef int (*OPENSSL_LH_COMPFUNC) (const void *, const void *);
typedef unsigned long (*OPENSSL_LH_HASHFUNC) (const void *);
typedef void (*OPENSSL_LH_DOALL_FUNC) (void *);
typedef void (*OPENSSL_LH_DOALL_FUNCARG) (void *, void *);
typedef struct lhash_st OPENSSL_LHASH;

/*
 * Macros for declaring and implementing type-safe wrappers for LHASH
 * callbacks. This way, callbacks can be provided to LHASH structures without
 * function pointer casting and the macro-defined callbacks provide
 * per-variable casting before deferring to the underlying type-specific
 * callbacks. NB: It is possible to place a "static" in front of both the
 * DECLARE and IMPLEMENT macros if the functions are strictly internal.
 */

/* First: "hash" functions */
# define DECLARE_LHASH_HASH_FN(name, o_type) \
        unsigned long name##_LHASH_HASH(const void *);
# define IMPLEMENT_LHASH_HASH_FN(name, o_type) \
        unsigned long name##_LHASH_HASH(const void *arg) { \
                const o_type *a = arg; \
                return name##_hash(a); }
# define LHASH_HASH_FN(name) name##_LHASH_HASH

/* Second: "compare" functions */
# define DECLARE_LHASH_COMP_FN(name, o_type) \
        int name##_LHASH_COMP(const void *, const void *);
# define IMPLEMENT_LHASH_COMP_FN(name, o_type) \
        int name##_LHASH_COMP(const void *arg1, const void *arg2) { \
                const o_type *a = arg1;             \
                const o_type *b = arg2; \
                return name##_cmp(a,b); }
# define LHASH_COMP_FN(name) name##_LHASH_COMP

/* Fourth: "doall_arg" functions */
# define DECLARE_LHASH_DOALL_ARG_FN(name, o_type, a_type) \
        void name##_LHASH_DOALL_ARG(void *, void *);
# define IMPLEMENT_LHASH_DOALL_ARG_FN(name, o_type, a_type) \
        void name##_LHASH_DOALL_ARG(void *arg1, void *arg2) { \
                o_type *a = arg1; \
                a_type *b = arg2; \
                name##_doall_arg(a, b); }
# define LHASH_DOALL_ARG_FN(name) name##_LHASH_DOALL_ARG


# define LH_LOAD_MULT    256

int OPENSSL_LH_error(OPENSSL_LHASH *lh);
OPENSSL_LHASH *OPENSSL_LH_new(OPENSSL_LH_HASHFUNC h, OPENSSL_LH_COMPFUNC c);
void OPENSSL_LH_free(OPENSSL_LHASH *lh);
void OPENSSL_LH_flush(OPENSSL_LHASH *lh);
void *OPENSSL_LH_insert(OPENSSL_LHASH *lh, void *data);
void *OPENSSL_LH_delete(OPENSSL_LHASH *lh, const void *data);
void *OPENSSL_LH_retrieve(OPENSSL_LHASH *lh, const void *data);
void OPENSSL_LH_doall(OPENSSL_LHASH *lh, OPENSSL_LH_DOALL_FUNC func);
void OPENSSL_LH_doall_arg(OPENSSL_LHASH *lh, OPENSSL_LH_DOALL_FUNCARG func, void *arg);
unsigned long OPENSSL_LH_strhash(const char *c);
unsigned long OPENSSL_LH_num_items(const OPENSSL_LHASH *lh);
unsigned long OPENSSL_LH_get_down_load(const OPENSSL_LHASH *lh);
void OPENSSL_LH_set_down_load(OPENSSL_LHASH *lh, unsigned long down_load);

# ifndef OPENSSL_NO_STDIO
void OPENSSL_LH_stats(const OPENSSL_LHASH *lh, FILE *fp);
void OPENSSL_LH_node_stats(const OPENSSL_LHASH *lh, FILE *fp);
void OPENSSL_LH_node_usage_stats(const OPENSSL_LHASH *lh, FILE *fp);
# endif
void OPENSSL_LH_stats_bio(const OPENSSL_LHASH *lh, BIO *out);
void OPENSSL_LH_node_stats_bio(const OPENSSL_LHASH *lh, BIO *out);
void OPENSSL_LH_node_usage_stats_bio(const OPENSSL_LHASH *lh, BIO *out);

# ifndef OPENSSL_NO_DEPRECATED_1_1_0
#  define _LHASH OPENSSL_LHASH
#  define LHASH_NODE OPENSSL_LH_NODE
#  define lh_error OPENSSL_LH_error
#  define lh_new OPENSSL_LH_new
#  define lh_free OPENSSL_LH_free
#  define lh_insert OPENSSL_LH_insert
#  define lh_delete OPENSSL_LH_delete
#  define lh_retrieve OPENSSL_LH_retrieve
#  define lh_doall OPENSSL_LH_doall
#  define lh_doall_arg OPENSSL_LH_doall_arg
#  define lh_strhash OPENSSL_LH_strhash
#  define lh_num_items OPENSSL_LH_num_items
#  ifndef OPENSSL_NO_STDIO
#   define lh_stats OPENSSL_LH_stats
#   define lh_node_stats OPENSSL_LH_node_stats
#   define lh_node_usage_stats OPENSSL_LH_node_usage_stats
#  endif
#  define lh_stats_bio OPENSSL_LH_stats_bio
#  define lh_node_stats_bio OPENSSL_LH_node_stats_bio
#  define lh_node_usage_stats_bio OPENSSL_LH_node_usage_stats_bio
# endif

/* Type checking... */

# define LHASH_OF(type) struct lhash_st_##type

/* Helper macro for internal use */
# define DEFINE_LHASH_OF_INTERNAL(type) \
    LHASH_OF(type) { union lh_##type##_dummy { void* d1; unsigned long d2; int d3; } dummy; }; \
    typedef int (*lh_##type##_compfunc)(const type *a, const type *b); \
    typedef unsigned long (*lh_##type##_hashfunc)(const type *a); \
    typedef void (*lh_##type##_doallfunc)(type *a); \
    static ossl_unused ossl_inline type *ossl_check_##type##_lh_plain_type(type *ptr) \
    { \
        return ptr; \
    } \
    static ossl_unused ossl_inline const type *ossl_check_const_##type##_lh_plain_type(const type *ptr) \
    { \
        return ptr; \
    } \
    static ossl_unused ossl_inline const OPENSSL_LHASH *ossl_check_const_##type##_lh_type(const LHASH_OF(type) *lh) \
    { \
        return (const OPENSSL_LHASH *)lh; \
    } \
    static ossl_unused ossl_inline OPENSSL_LHASH *ossl_check_##type##_lh_type(LHASH_OF(type) *lh) \
    { \
        return (OPENSSL_LHASH *)lh; \
    } \
    static ossl_unused ossl_inline OPENSSL_LH_COMPFUNC ossl_check_##type##_lh_compfunc_type(lh_##type##_compfunc cmp) \
    { \
        return (OPENSSL_LH_COMPFUNC)cmp; \
    } \
    static ossl_unused ossl_inline OPENSSL_LH_HASHFUNC ossl_check_##type##_lh_hashfunc_type(lh_##type##_hashfunc hfn) \
    { \
        return (OPENSSL_LH_HASHFUNC)hfn; \
    } \
    static ossl_unused ossl_inline OPENSSL_LH_DOALL_FUNC ossl_check_##type##_lh_doallfunc_type(lh_##type##_doallfunc dfn) \
    { \
        return (OPENSSL_LH_DOALL_FUNC)dfn; \
    } \
    LHASH_OF(type)

# define DEFINE_LHASH_OF(type) \
    LHASH_OF(type) { union lh_##type##_dummy { void* d1; unsigned long d2; int d3; } dummy; }; \
    static ossl_unused ossl_inline LHASH_OF(type) *lh_##type##_new(unsigned long (*hfn)(const type *), \
                                                                   int (*cfn)(const type *, const type *)) \
    { \
        return (LHASH_OF(type) *) \
            OPENSSL_LH_new((OPENSSL_LH_HASHFUNC)hfn, (OPENSSL_LH_COMPFUNC)cfn); \
    } \
    static ossl_unused ossl_inline void lh_##type##_free(LHASH_OF(type) *lh) \
    { \
        OPENSSL_LH_free((OPENSSL_LHASH *)lh); \
    } \
    static ossl_unused ossl_inline void lh_##type##_flush(LHASH_OF(type) *lh) \
    { \
        OPENSSL_LH_flush((OPENSSL_LHASH *)lh); \
    } \
    static ossl_unused ossl_inline type *lh_##type##_insert(LHASH_OF(type) *lh, type *d) \
    { \
        return (type *)OPENSSL_LH_insert((OPENSSL_LHASH *)lh, d); \
    } \
    static ossl_unused ossl_inline type *lh_##type##_delete(LHASH_OF(type) *lh, const type *d) \
    { \
        return (type *)OPENSSL_LH_delete((OPENSSL_LHASH *)lh, d); \
    } \
    static ossl_unused ossl_inline type *lh_##type##_retrieve(LHASH_OF(type) *lh, const type *d) \
    { \
        return (type *)OPENSSL_LH_retrieve((OPENSSL_LHASH *)lh, d); \
    } \
    static ossl_unused ossl_inline int lh_##type##_error(LHASH_OF(type) *lh) \
    { \
        return OPENSSL_LH_error((OPENSSL_LHASH *)lh); \
    } \
    static ossl_unused ossl_inline unsigned long lh_##type##_num_items(LHASH_OF(type) *lh) \
    { \
        return OPENSSL_LH_num_items((OPENSSL_LHASH *)lh); \
    } \
    static ossl_unused ossl_inline void lh_##type##_node_stats_bio(const LHASH_OF(type) *lh, BIO *out) \
    { \
        OPENSSL_LH_node_stats_bio((const OPENSSL_LHASH *)lh, out); \
    } \
    static ossl_unused ossl_inline void lh_##type##_node_usage_stats_bio(const LHASH_OF(type) *lh, BIO *out) \
    { \
        OPENSSL_LH_node_usage_stats_bio((const OPENSSL_LHASH *)lh, out); \
    } \
    static ossl_unused ossl_inline void lh_##type##_stats_bio(const LHASH_OF(type) *lh, BIO *out) \
    { \
        OPENSSL_LH_stats_bio((const OPENSSL_LHASH *)lh, out); \
    } \
    static ossl_unused ossl_inline unsigned long lh_##type##_get_down_load(LHASH_OF(type) *lh) \
    { \
        return OPENSSL_LH_get_down_load((OPENSSL_LHASH *)lh); \
    } \
    static ossl_unused ossl_inline void lh_##type##_set_down_load(LHASH_OF(type) *lh, unsigned long dl) \
    { \
        OPENSSL_LH_set_down_load((OPENSSL_LHASH *)lh, dl); \
    } \
    static ossl_unused ossl_inline void lh_##type##_doall(LHASH_OF(type) *lh, \
                                                          void (*doall)(type *)) \
    { \
        OPENSSL_LH_doall((OPENSSL_LHASH *)lh, (OPENSSL_LH_DOALL_FUNC)doall); \
    } \
    static ossl_unused ossl_inline void lh_##type##_doall_arg(LHASH_OF(type) *lh, \
                                                              void (*doallarg)(type *, void *), \
                                                              void *arg) \
    { \
        OPENSSL_LH_doall_arg((OPENSSL_LHASH *)lh, \
                             (OPENSSL_LH_DOALL_FUNCARG)doallarg, arg); \
    } \
    LHASH_OF(type)

#define IMPLEMENT_LHASH_DOALL_ARG_CONST(type, argtype) \
    int_implement_lhash_doall(type, argtype, const type)

#define IMPLEMENT_LHASH_DOALL_ARG(type, argtype) \
    int_implement_lhash_doall(type, argtype, type)

#define int_implement_lhash_doall(type, argtype, cbargtype) \
    static ossl_unused ossl_inline void \
        lh_##type##_doall_##argtype(LHASH_OF(type) *lh, \
                                   void (*fn)(cbargtype *, argtype *), \
                                   argtype *arg) \
    { \
        OPENSSL_LH_doall_arg((OPENSSL_LHASH *)lh, (OPENSSL_LH_DOALL_FUNCARG)fn, (void *)arg); \
    } \
    LHASH_OF(type)

DEFINE_LHASH_OF_INTERNAL(OPENSSL_STRING);
#define lh_OPENSSL_STRING_new(hfn, cmp) ((LHASH_OF(OPENSSL_STRING) *)OPENSSL_LH_new(ossl_check_OPENSSL_STRING_lh_hashfunc_type(hfn), ossl_check_OPENSSL_STRING_lh_compfunc_type(cmp)))
#define lh_OPENSSL_STRING_free(lh) OPENSSL_LH_free(ossl_check_OPENSSL_STRING_lh_type(lh))
#define lh_OPENSSL_STRING_flush(lh) OPENSSL_LH_flush(ossl_check_OPENSSL_STRING_lh_type(lh))
#define lh_OPENSSL_STRING_insert(lh, ptr) ((OPENSSL_STRING *)OPENSSL_LH_insert(ossl_check_OPENSSL_STRING_lh_type(lh), ossl_check_OPENSSL_STRING_lh_plain_type(ptr)))
#define lh_OPENSSL_STRING_delete(lh, ptr) ((OPENSSL_STRING *)OPENSSL_LH_delete(ossl_check_OPENSSL_STRING_lh_type(lh), ossl_check_const_OPENSSL_STRING_lh_plain_type(ptr)))
#define lh_OPENSSL_STRING_retrieve(lh, ptr) ((OPENSSL_STRING *)OPENSSL_LH_retrieve(ossl_check_OPENSSL_STRING_lh_type(lh), ossl_check_const_OPENSSL_STRING_lh_plain_type(ptr)))
#define lh_OPENSSL_STRING_error(lh) OPENSSL_LH_error(ossl_check_OPENSSL_STRING_lh_type(lh))
#define lh_OPENSSL_STRING_num_items(lh) OPENSSL_LH_num_items(ossl_check_OPENSSL_STRING_lh_type(lh))
#define lh_OPENSSL_STRING_node_stats_bio(lh, out) OPENSSL_LH_node_stats_bio(ossl_check_const_OPENSSL_STRING_lh_type(lh), out)
#define lh_OPENSSL_STRING_node_usage_stats_bio(lh, out) OPENSSL_LH_node_usage_stats_bio(ossl_check_const_OPENSSL_STRING_lh_type(lh), out)
#define lh_OPENSSL_STRING_stats_bio(lh, out) OPENSSL_LH_stats_bio(ossl_check_const_OPENSSL_STRING_lh_type(lh), out)
#define lh_OPENSSL_STRING_get_down_load(lh) OPENSSL_LH_get_down_load(ossl_check_OPENSSL_STRING_lh_type(lh))
#define lh_OPENSSL_STRING_set_down_load(lh, dl) OPENSSL_LH_set_down_load(ossl_check_OPENSSL_STRING_lh_type(lh), dl)
#define lh_OPENSSL_STRING_doall(lh, dfn) OPENSSL_LH_doall(ossl_check_OPENSSL_STRING_lh_type(lh), ossl_check_OPENSSL_STRING_lh_doallfunc_type(dfn))
DEFINE_LHASH_OF_INTERNAL(OPENSSL_CSTRING);
#define lh_OPENSSL_CSTRING_new(hfn, cmp) ((LHASH_OF(OPENSSL_CSTRING) *)OPENSSL_LH_new(ossl_check_OPENSSL_CSTRING_lh_hashfunc_type(hfn), ossl_check_OPENSSL_CSTRING_lh_compfunc_type(cmp)))
#define lh_OPENSSL_CSTRING_free(lh) OPENSSL_LH_free(ossl_check_OPENSSL_CSTRING_lh_type(lh))
#define lh_OPENSSL_CSTRING_flush(lh) OPENSSL_LH_flush(ossl_check_OPENSSL_CSTRING_lh_type(lh))
#define lh_OPENSSL_CSTRING_insert(lh, ptr) ((OPENSSL_CSTRING *)OPENSSL_LH_insert(ossl_check_OPENSSL_CSTRING_lh_type(lh), ossl_check_OPENSSL_CSTRING_lh_plain_type(ptr)))
#define lh_OPENSSL_CSTRING_delete(lh, ptr) ((OPENSSL_CSTRING *)OPENSSL_LH_delete(ossl_check_OPENSSL_CSTRING_lh_type(lh), ossl_check_const_OPENSSL_CSTRING_lh_plain_type(ptr)))
#define lh_OPENSSL_CSTRING_retrieve(lh, ptr) ((OPENSSL_CSTRING *)OPENSSL_LH_retrieve(ossl_check_OPENSSL_CSTRING_lh_type(lh), ossl_check_const_OPENSSL_CSTRING_lh_plain_type(ptr)))
#define lh_OPENSSL_CSTRING_error(lh) OPENSSL_LH_error(ossl_check_OPENSSL_CSTRING_lh_type(lh))
#define lh_OPENSSL_CSTRING_num_items(lh) OPENSSL_LH_num_items(ossl_check_OPENSSL_CSTRING_lh_type(lh))
#define lh_OPENSSL_CSTRING_node_stats_bio(lh, out) OPENSSL_LH_node_stats_bio(ossl_check_const_OPENSSL_CSTRING_lh_type(lh), out)
#define lh_OPENSSL_CSTRING_node_usage_stats_bio(lh, out) OPENSSL_LH_node_usage_stats_bio(ossl_check_const_OPENSSL_CSTRING_lh_type(lh), out)
#define lh_OPENSSL_CSTRING_stats_bio(lh, out) OPENSSL_LH_stats_bio(ossl_check_const_OPENSSL_CSTRING_lh_type(lh), out)
#define lh_OPENSSL_CSTRING_get_down_load(lh) OPENSSL_LH_get_down_load(ossl_check_OPENSSL_CSTRING_lh_type(lh))
#define lh_OPENSSL_CSTRING_set_down_load(lh, dl) OPENSSL_LH_set_down_load(ossl_check_OPENSSL_CSTRING_lh_type(lh), dl)
#define lh_OPENSSL_CSTRING_doall(lh, dfn) OPENSSL_LH_doall(ossl_check_OPENSSL_CSTRING_lh_type(lh), ossl_check_OPENSSL_CSTRING_lh_doallfunc_type(dfn))


#ifdef  __cplusplus
}
#endif

#endif
                                                                                                                                                                                                                                                                                   node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/openssl/ocsp.h          0000664 0000000 0000000 00000071250 14746647661 0031024 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /*
 * WARNING: do not edit!
 * Generated by Makefile from include/openssl/ocsp.h.in
 *
 * Copyright 2000-2021 The OpenSSL Project Authors. All Rights Reserved.
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 */



#ifndef OPENSSL_OCSP_H
# define OPENSSL_OCSP_H
# pragma once

# include <openssl/macros.h>
# ifndef OPENSSL_NO_DEPRECATED_3_0
#  define HEADER_OCSP_H
# endif

# include <openssl/opensslconf.h>
# include <openssl/http.h>
# include <openssl/asn1.h>

/*
 * These definitions are outside the OPENSSL_NO_OCSP guard because although for
 * historical reasons they have OCSP_* names, they can actually be used
 * independently of OCSP. E.g. see RFC5280
 */
/*-
 *   CRLReason ::= ENUMERATED {
 *        unspecified             (0),
 *        keyCompromise           (1),
 *        cACompromise            (2),
 *        affiliationChanged      (3),
 *        superseded              (4),
 *        cessationOfOperation    (5),
 *        certificateHold         (6),
 *        -- value 7 is not used
 *        removeFromCRL           (8),
 *        privilegeWithdrawn      (9),
 *        aACompromise           (10) }
 */
# define OCSP_REVOKED_STATUS_NOSTATUS                -1
# define OCSP_REVOKED_STATUS_UNSPECIFIED             0
# define OCSP_REVOKED_STATUS_KEYCOMPROMISE           1
# define OCSP_REVOKED_STATUS_CACOMPROMISE            2
# define OCSP_REVOKED_STATUS_AFFILIATIONCHANGED      3
# define OCSP_REVOKED_STATUS_SUPERSEDED              4
# define OCSP_REVOKED_STATUS_CESSATIONOFOPERATION    5
# define OCSP_REVOKED_STATUS_CERTIFICATEHOLD         6
# define OCSP_REVOKED_STATUS_REMOVEFROMCRL           8
# define OCSP_REVOKED_STATUS_PRIVILEGEWITHDRAWN      9
# define OCSP_REVOKED_STATUS_AACOMPROMISE            10


# ifndef OPENSSL_NO_OCSP

#  include <openssl/x509.h>
#  include <openssl/x509v3.h>
#  include <openssl/safestack.h>
#  include <openssl/ocsperr.h>

#  ifdef __cplusplus
extern "C" {
#  endif

/* Various flags and values */

#  define OCSP_DEFAULT_NONCE_LENGTH       16

#  define OCSP_NOCERTS                    0x1
#  define OCSP_NOINTERN                   0x2
#  define OCSP_NOSIGS                     0x4
#  define OCSP_NOCHAIN                    0x8
#  define OCSP_NOVERIFY                   0x10
#  define OCSP_NOEXPLICIT                 0x20
#  define OCSP_NOCASIGN                   0x40
#  define OCSP_NODELEGATED                0x80
#  define OCSP_NOCHECKS                   0x100
#  define OCSP_TRUSTOTHER                 0x200
#  define OCSP_RESPID_KEY                 0x400
#  define OCSP_NOTIME                     0x800
#  define OCSP_PARTIAL_CHAIN              0x1000

typedef struct ocsp_cert_id_st OCSP_CERTID;
typedef struct ocsp_one_request_st OCSP_ONEREQ;
typedef struct ocsp_req_info_st OCSP_REQINFO;
typedef struct ocsp_signature_st OCSP_SIGNATURE;
typedef struct ocsp_request_st OCSP_REQUEST;

SKM_DEFINE_STACK_OF_INTERNAL(OCSP_CERTID, OCSP_CERTID, OCSP_CERTID)
#define sk_OCSP_CERTID_num(sk) OPENSSL_sk_num(ossl_check_const_OCSP_CERTID_sk_type(sk))
#define sk_OCSP_CERTID_value(sk, idx) ((OCSP_CERTID *)OPENSSL_sk_value(ossl_check_const_OCSP_CERTID_sk_type(sk), (idx)))
#define sk_OCSP_CERTID_new(cmp) ((STACK_OF(OCSP_CERTID) *)OPENSSL_sk_new(ossl_check_OCSP_CERTID_compfunc_type(cmp)))
#define sk_OCSP_CERTID_new_null() ((STACK_OF(OCSP_CERTID) *)OPENSSL_sk_new_null())
#define sk_OCSP_CERTID_new_reserve(cmp, n) ((STACK_OF(OCSP_CERTID) *)OPENSSL_sk_new_reserve(ossl_check_OCSP_CERTID_compfunc_type(cmp), (n)))
#define sk_OCSP_CERTID_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_OCSP_CERTID_sk_type(sk), (n))
#define sk_OCSP_CERTID_free(sk) OPENSSL_sk_free(ossl_check_OCSP_CERTID_sk_type(sk))
#define sk_OCSP_CERTID_zero(sk) OPENSSL_sk_zero(ossl_check_OCSP_CERTID_sk_type(sk))
#define sk_OCSP_CERTID_delete(sk, i) ((OCSP_CERTID *)OPENSSL_sk_delete(ossl_check_OCSP_CERTID_sk_type(sk), (i)))
#define sk_OCSP_CERTID_delete_ptr(sk, ptr) ((OCSP_CERTID *)OPENSSL_sk_delete_ptr(ossl_check_OCSP_CERTID_sk_type(sk), ossl_check_OCSP_CERTID_type(ptr)))
#define sk_OCSP_CERTID_push(sk, ptr) OPENSSL_sk_push(ossl_check_OCSP_CERTID_sk_type(sk), ossl_check_OCSP_CERTID_type(ptr))
#define sk_OCSP_CERTID_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_OCSP_CERTID_sk_type(sk), ossl_check_OCSP_CERTID_type(ptr))
#define sk_OCSP_CERTID_pop(sk) ((OCSP_CERTID *)OPENSSL_sk_pop(ossl_check_OCSP_CERTID_sk_type(sk)))
#define sk_OCSP_CERTID_shift(sk) ((OCSP_CERTID *)OPENSSL_sk_shift(ossl_check_OCSP_CERTID_sk_type(sk)))
#define sk_OCSP_CERTID_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_OCSP_CERTID_sk_type(sk),ossl_check_OCSP_CERTID_freefunc_type(freefunc))
#define sk_OCSP_CERTID_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_OCSP_CERTID_sk_type(sk), ossl_check_OCSP_CERTID_type(ptr), (idx))
#define sk_OCSP_CERTID_set(sk, idx, ptr) ((OCSP_CERTID *)OPENSSL_sk_set(ossl_check_OCSP_CERTID_sk_type(sk), (idx), ossl_check_OCSP_CERTID_type(ptr)))
#define sk_OCSP_CERTID_find(sk, ptr) OPENSSL_sk_find(ossl_check_OCSP_CERTID_sk_type(sk), ossl_check_OCSP_CERTID_type(ptr))
#define sk_OCSP_CERTID_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_OCSP_CERTID_sk_type(sk), ossl_check_OCSP_CERTID_type(ptr))
#define sk_OCSP_CERTID_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_OCSP_CERTID_sk_type(sk), ossl_check_OCSP_CERTID_type(ptr), pnum)
#define sk_OCSP_CERTID_sort(sk) OPENSSL_sk_sort(ossl_check_OCSP_CERTID_sk_type(sk))
#define sk_OCSP_CERTID_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_OCSP_CERTID_sk_type(sk))
#define sk_OCSP_CERTID_dup(sk) ((STACK_OF(OCSP_CERTID) *)OPENSSL_sk_dup(ossl_check_const_OCSP_CERTID_sk_type(sk)))
#define sk_OCSP_CERTID_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(OCSP_CERTID) *)OPENSSL_sk_deep_copy(ossl_check_const_OCSP_CERTID_sk_type(sk), ossl_check_OCSP_CERTID_copyfunc_type(copyfunc), ossl_check_OCSP_CERTID_freefunc_type(freefunc)))
#define sk_OCSP_CERTID_set_cmp_func(sk, cmp) ((sk_OCSP_CERTID_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_OCSP_CERTID_sk_type(sk), ossl_check_OCSP_CERTID_compfunc_type(cmp)))
SKM_DEFINE_STACK_OF_INTERNAL(OCSP_ONEREQ, OCSP_ONEREQ, OCSP_ONEREQ)
#define sk_OCSP_ONEREQ_num(sk) OPENSSL_sk_num(ossl_check_const_OCSP_ONEREQ_sk_type(sk))
#define sk_OCSP_ONEREQ_value(sk, idx) ((OCSP_ONEREQ *)OPENSSL_sk_value(ossl_check_const_OCSP_ONEREQ_sk_type(sk), (idx)))
#define sk_OCSP_ONEREQ_new(cmp) ((STACK_OF(OCSP_ONEREQ) *)OPENSSL_sk_new(ossl_check_OCSP_ONEREQ_compfunc_type(cmp)))
#define sk_OCSP_ONEREQ_new_null() ((STACK_OF(OCSP_ONEREQ) *)OPENSSL_sk_new_null())
#define sk_OCSP_ONEREQ_new_reserve(cmp, n) ((STACK_OF(OCSP_ONEREQ) *)OPENSSL_sk_new_reserve(ossl_check_OCSP_ONEREQ_compfunc_type(cmp), (n)))
#define sk_OCSP_ONEREQ_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_OCSP_ONEREQ_sk_type(sk), (n))
#define sk_OCSP_ONEREQ_free(sk) OPENSSL_sk_free(ossl_check_OCSP_ONEREQ_sk_type(sk))
#define sk_OCSP_ONEREQ_zero(sk) OPENSSL_sk_zero(ossl_check_OCSP_ONEREQ_sk_type(sk))
#define sk_OCSP_ONEREQ_delete(sk, i) ((OCSP_ONEREQ *)OPENSSL_sk_delete(ossl_check_OCSP_ONEREQ_sk_type(sk), (i)))
#define sk_OCSP_ONEREQ_delete_ptr(sk, ptr) ((OCSP_ONEREQ *)OPENSSL_sk_delete_ptr(ossl_check_OCSP_ONEREQ_sk_type(sk), ossl_check_OCSP_ONEREQ_type(ptr)))
#define sk_OCSP_ONEREQ_push(sk, ptr) OPENSSL_sk_push(ossl_check_OCSP_ONEREQ_sk_type(sk), ossl_check_OCSP_ONEREQ_type(ptr))
#define sk_OCSP_ONEREQ_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_OCSP_ONEREQ_sk_type(sk), ossl_check_OCSP_ONEREQ_type(ptr))
#define sk_OCSP_ONEREQ_pop(sk) ((OCSP_ONEREQ *)OPENSSL_sk_pop(ossl_check_OCSP_ONEREQ_sk_type(sk)))
#define sk_OCSP_ONEREQ_shift(sk) ((OCSP_ONEREQ *)OPENSSL_sk_shift(ossl_check_OCSP_ONEREQ_sk_type(sk)))
#define sk_OCSP_ONEREQ_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_OCSP_ONEREQ_sk_type(sk),ossl_check_OCSP_ONEREQ_freefunc_type(freefunc))
#define sk_OCSP_ONEREQ_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_OCSP_ONEREQ_sk_type(sk), ossl_check_OCSP_ONEREQ_type(ptr), (idx))
#define sk_OCSP_ONEREQ_set(sk, idx, ptr) ((OCSP_ONEREQ *)OPENSSL_sk_set(ossl_check_OCSP_ONEREQ_sk_type(sk), (idx), ossl_check_OCSP_ONEREQ_type(ptr)))
#define sk_OCSP_ONEREQ_find(sk, ptr) OPENSSL_sk_find(ossl_check_OCSP_ONEREQ_sk_type(sk), ossl_check_OCSP_ONEREQ_type(ptr))
#define sk_OCSP_ONEREQ_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_OCSP_ONEREQ_sk_type(sk), ossl_check_OCSP_ONEREQ_type(ptr))
#define sk_OCSP_ONEREQ_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_OCSP_ONEREQ_sk_type(sk), ossl_check_OCSP_ONEREQ_type(ptr), pnum)
#define sk_OCSP_ONEREQ_sort(sk) OPENSSL_sk_sort(ossl_check_OCSP_ONEREQ_sk_type(sk))
#define sk_OCSP_ONEREQ_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_OCSP_ONEREQ_sk_type(sk))
#define sk_OCSP_ONEREQ_dup(sk) ((STACK_OF(OCSP_ONEREQ) *)OPENSSL_sk_dup(ossl_check_const_OCSP_ONEREQ_sk_type(sk)))
#define sk_OCSP_ONEREQ_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(OCSP_ONEREQ) *)OPENSSL_sk_deep_copy(ossl_check_const_OCSP_ONEREQ_sk_type(sk), ossl_check_OCSP_ONEREQ_copyfunc_type(copyfunc), ossl_check_OCSP_ONEREQ_freefunc_type(freefunc)))
#define sk_OCSP_ONEREQ_set_cmp_func(sk, cmp) ((sk_OCSP_ONEREQ_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_OCSP_ONEREQ_sk_type(sk), ossl_check_OCSP_ONEREQ_compfunc_type(cmp)))


#  define OCSP_RESPONSE_STATUS_SUCCESSFUL           0
#  define OCSP_RESPONSE_STATUS_MALFORMEDREQUEST     1
#  define OCSP_RESPONSE_STATUS_INTERNALERROR        2
#  define OCSP_RESPONSE_STATUS_TRYLATER             3
#  define OCSP_RESPONSE_STATUS_SIGREQUIRED          5
#  define OCSP_RESPONSE_STATUS_UNAUTHORIZED         6

typedef struct ocsp_resp_bytes_st OCSP_RESPBYTES;

#  define V_OCSP_RESPID_NAME 0
#  define V_OCSP_RESPID_KEY  1

SKM_DEFINE_STACK_OF_INTERNAL(OCSP_RESPID, OCSP_RESPID, OCSP_RESPID)
#define sk_OCSP_RESPID_num(sk) OPENSSL_sk_num(ossl_check_const_OCSP_RESPID_sk_type(sk))
#define sk_OCSP_RESPID_value(sk, idx) ((OCSP_RESPID *)OPENSSL_sk_value(ossl_check_const_OCSP_RESPID_sk_type(sk), (idx)))
#define sk_OCSP_RESPID_new(cmp) ((STACK_OF(OCSP_RESPID) *)OPENSSL_sk_new(ossl_check_OCSP_RESPID_compfunc_type(cmp)))
#define sk_OCSP_RESPID_new_null() ((STACK_OF(OCSP_RESPID) *)OPENSSL_sk_new_null())
#define sk_OCSP_RESPID_new_reserve(cmp, n) ((STACK_OF(OCSP_RESPID) *)OPENSSL_sk_new_reserve(ossl_check_OCSP_RESPID_compfunc_type(cmp), (n)))
#define sk_OCSP_RESPID_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_OCSP_RESPID_sk_type(sk), (n))
#define sk_OCSP_RESPID_free(sk) OPENSSL_sk_free(ossl_check_OCSP_RESPID_sk_type(sk))
#define sk_OCSP_RESPID_zero(sk) OPENSSL_sk_zero(ossl_check_OCSP_RESPID_sk_type(sk))
#define sk_OCSP_RESPID_delete(sk, i) ((OCSP_RESPID *)OPENSSL_sk_delete(ossl_check_OCSP_RESPID_sk_type(sk), (i)))
#define sk_OCSP_RESPID_delete_ptr(sk, ptr) ((OCSP_RESPID *)OPENSSL_sk_delete_ptr(ossl_check_OCSP_RESPID_sk_type(sk), ossl_check_OCSP_RESPID_type(ptr)))
#define sk_OCSP_RESPID_push(sk, ptr) OPENSSL_sk_push(ossl_check_OCSP_RESPID_sk_type(sk), ossl_check_OCSP_RESPID_type(ptr))
#define sk_OCSP_RESPID_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_OCSP_RESPID_sk_type(sk), ossl_check_OCSP_RESPID_type(ptr))
#define sk_OCSP_RESPID_pop(sk) ((OCSP_RESPID *)OPENSSL_sk_pop(ossl_check_OCSP_RESPID_sk_type(sk)))
#define sk_OCSP_RESPID_shift(sk) ((OCSP_RESPID *)OPENSSL_sk_shift(ossl_check_OCSP_RESPID_sk_type(sk)))
#define sk_OCSP_RESPID_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_OCSP_RESPID_sk_type(sk),ossl_check_OCSP_RESPID_freefunc_type(freefunc))
#define sk_OCSP_RESPID_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_OCSP_RESPID_sk_type(sk), ossl_check_OCSP_RESPID_type(ptr), (idx))
#define sk_OCSP_RESPID_set(sk, idx, ptr) ((OCSP_RESPID *)OPENSSL_sk_set(ossl_check_OCSP_RESPID_sk_type(sk), (idx), ossl_check_OCSP_RESPID_type(ptr)))
#define sk_OCSP_RESPID_find(sk, ptr) OPENSSL_sk_find(ossl_check_OCSP_RESPID_sk_type(sk), ossl_check_OCSP_RESPID_type(ptr))
#define sk_OCSP_RESPID_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_OCSP_RESPID_sk_type(sk), ossl_check_OCSP_RESPID_type(ptr))
#define sk_OCSP_RESPID_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_OCSP_RESPID_sk_type(sk), ossl_check_OCSP_RESPID_type(ptr), pnum)
#define sk_OCSP_RESPID_sort(sk) OPENSSL_sk_sort(ossl_check_OCSP_RESPID_sk_type(sk))
#define sk_OCSP_RESPID_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_OCSP_RESPID_sk_type(sk))
#define sk_OCSP_RESPID_dup(sk) ((STACK_OF(OCSP_RESPID) *)OPENSSL_sk_dup(ossl_check_const_OCSP_RESPID_sk_type(sk)))
#define sk_OCSP_RESPID_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(OCSP_RESPID) *)OPENSSL_sk_deep_copy(ossl_check_const_OCSP_RESPID_sk_type(sk), ossl_check_OCSP_RESPID_copyfunc_type(copyfunc), ossl_check_OCSP_RESPID_freefunc_type(freefunc)))
#define sk_OCSP_RESPID_set_cmp_func(sk, cmp) ((sk_OCSP_RESPID_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_OCSP_RESPID_sk_type(sk), ossl_check_OCSP_RESPID_compfunc_type(cmp)))


typedef struct ocsp_revoked_info_st OCSP_REVOKEDINFO;

#  define V_OCSP_CERTSTATUS_GOOD    0
#  define V_OCSP_CERTSTATUS_REVOKED 1
#  define V_OCSP_CERTSTATUS_UNKNOWN 2

typedef struct ocsp_cert_status_st OCSP_CERTSTATUS;
typedef struct ocsp_single_response_st OCSP_SINGLERESP;

SKM_DEFINE_STACK_OF_INTERNAL(OCSP_SINGLERESP, OCSP_SINGLERESP, OCSP_SINGLERESP)
#define sk_OCSP_SINGLERESP_num(sk) OPENSSL_sk_num(ossl_check_const_OCSP_SINGLERESP_sk_type(sk))
#define sk_OCSP_SINGLERESP_value(sk, idx) ((OCSP_SINGLERESP *)OPENSSL_sk_value(ossl_check_const_OCSP_SINGLERESP_sk_type(sk), (idx)))
#define sk_OCSP_SINGLERESP_new(cmp) ((STACK_OF(OCSP_SINGLERESP) *)OPENSSL_sk_new(ossl_check_OCSP_SINGLERESP_compfunc_type(cmp)))
#define sk_OCSP_SINGLERESP_new_null() ((STACK_OF(OCSP_SINGLERESP) *)OPENSSL_sk_new_null())
#define sk_OCSP_SINGLERESP_new_reserve(cmp, n) ((STACK_OF(OCSP_SINGLERESP) *)OPENSSL_sk_new_reserve(ossl_check_OCSP_SINGLERESP_compfunc_type(cmp), (n)))
#define sk_OCSP_SINGLERESP_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_OCSP_SINGLERESP_sk_type(sk), (n))
#define sk_OCSP_SINGLERESP_free(sk) OPENSSL_sk_free(ossl_check_OCSP_SINGLERESP_sk_type(sk))
#define sk_OCSP_SINGLERESP_zero(sk) OPENSSL_sk_zero(ossl_check_OCSP_SINGLERESP_sk_type(sk))
#define sk_OCSP_SINGLERESP_delete(sk, i) ((OCSP_SINGLERESP *)OPENSSL_sk_delete(ossl_check_OCSP_SINGLERESP_sk_type(sk), (i)))
#define sk_OCSP_SINGLERESP_delete_ptr(sk, ptr) ((OCSP_SINGLERESP *)OPENSSL_sk_delete_ptr(ossl_check_OCSP_SINGLERESP_sk_type(sk), ossl_check_OCSP_SINGLERESP_type(ptr)))
#define sk_OCSP_SINGLERESP_push(sk, ptr) OPENSSL_sk_push(ossl_check_OCSP_SINGLERESP_sk_type(sk), ossl_check_OCSP_SINGLERESP_type(ptr))
#define sk_OCSP_SINGLERESP_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_OCSP_SINGLERESP_sk_type(sk), ossl_check_OCSP_SINGLERESP_type(ptr))
#define sk_OCSP_SINGLERESP_pop(sk) ((OCSP_SINGLERESP *)OPENSSL_sk_pop(ossl_check_OCSP_SINGLERESP_sk_type(sk)))
#define sk_OCSP_SINGLERESP_shift(sk) ((OCSP_SINGLERESP *)OPENSSL_sk_shift(ossl_check_OCSP_SINGLERESP_sk_type(sk)))
#define sk_OCSP_SINGLERESP_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_OCSP_SINGLERESP_sk_type(sk),ossl_check_OCSP_SINGLERESP_freefunc_type(freefunc))
#define sk_OCSP_SINGLERESP_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_OCSP_SINGLERESP_sk_type(sk), ossl_check_OCSP_SINGLERESP_type(ptr), (idx))
#define sk_OCSP_SINGLERESP_set(sk, idx, ptr) ((OCSP_SINGLERESP *)OPENSSL_sk_set(ossl_check_OCSP_SINGLERESP_sk_type(sk), (idx), ossl_check_OCSP_SINGLERESP_type(ptr)))
#define sk_OCSP_SINGLERESP_find(sk, ptr) OPENSSL_sk_find(ossl_check_OCSP_SINGLERESP_sk_type(sk), ossl_check_OCSP_SINGLERESP_type(ptr))
#define sk_OCSP_SINGLERESP_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_OCSP_SINGLERESP_sk_type(sk), ossl_check_OCSP_SINGLERESP_type(ptr))
#define sk_OCSP_SINGLERESP_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_OCSP_SINGLERESP_sk_type(sk), ossl_check_OCSP_SINGLERESP_type(ptr), pnum)
#define sk_OCSP_SINGLERESP_sort(sk) OPENSSL_sk_sort(ossl_check_OCSP_SINGLERESP_sk_type(sk))
#define sk_OCSP_SINGLERESP_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_OCSP_SINGLERESP_sk_type(sk))
#define sk_OCSP_SINGLERESP_dup(sk) ((STACK_OF(OCSP_SINGLERESP) *)OPENSSL_sk_dup(ossl_check_const_OCSP_SINGLERESP_sk_type(sk)))
#define sk_OCSP_SINGLERESP_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(OCSP_SINGLERESP) *)OPENSSL_sk_deep_copy(ossl_check_const_OCSP_SINGLERESP_sk_type(sk), ossl_check_OCSP_SINGLERESP_copyfunc_type(copyfunc), ossl_check_OCSP_SINGLERESP_freefunc_type(freefunc)))
#define sk_OCSP_SINGLERESP_set_cmp_func(sk, cmp) ((sk_OCSP_SINGLERESP_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_OCSP_SINGLERESP_sk_type(sk), ossl_check_OCSP_SINGLERESP_compfunc_type(cmp)))


typedef struct ocsp_response_data_st OCSP_RESPDATA;

typedef struct ocsp_basic_response_st OCSP_BASICRESP;

typedef struct ocsp_crl_id_st OCSP_CRLID;
typedef struct ocsp_service_locator_st OCSP_SERVICELOC;

#  define PEM_STRING_OCSP_REQUEST "OCSP REQUEST"
#  define PEM_STRING_OCSP_RESPONSE "OCSP RESPONSE"

#  define d2i_OCSP_REQUEST_bio(bp,p) ASN1_d2i_bio_of(OCSP_REQUEST,OCSP_REQUEST_new,d2i_OCSP_REQUEST,bp,p)

#  define d2i_OCSP_RESPONSE_bio(bp,p) ASN1_d2i_bio_of(OCSP_RESPONSE,OCSP_RESPONSE_new,d2i_OCSP_RESPONSE,bp,p)

#  define PEM_read_bio_OCSP_REQUEST(bp,x,cb) (OCSP_REQUEST *)PEM_ASN1_read_bio( \
     (char *(*)())d2i_OCSP_REQUEST,PEM_STRING_OCSP_REQUEST, \
     bp,(char **)(x),cb,NULL)

#  define PEM_read_bio_OCSP_RESPONSE(bp,x,cb) (OCSP_RESPONSE *)PEM_ASN1_read_bio(\
     (char *(*)())d2i_OCSP_RESPONSE,PEM_STRING_OCSP_RESPONSE, \
     bp,(char **)(x),cb,NULL)

#  define PEM_write_bio_OCSP_REQUEST(bp,o) \
    PEM_ASN1_write_bio((int (*)())i2d_OCSP_REQUEST,PEM_STRING_OCSP_REQUEST,\
                        bp,(char *)(o), NULL,NULL,0,NULL,NULL)

#  define PEM_write_bio_OCSP_RESPONSE(bp,o) \
    PEM_ASN1_write_bio((int (*)())i2d_OCSP_RESPONSE,PEM_STRING_OCSP_RESPONSE,\
                        bp,(char *)(o), NULL,NULL,0,NULL,NULL)

#  define i2d_OCSP_RESPONSE_bio(bp,o) ASN1_i2d_bio_of(OCSP_RESPONSE,i2d_OCSP_RESPONSE,bp,o)

#  define i2d_OCSP_REQUEST_bio(bp,o) ASN1_i2d_bio_of(OCSP_REQUEST,i2d_OCSP_REQUEST,bp,o)

#  define ASN1_BIT_STRING_digest(data,type,md,len) \
        ASN1_item_digest(ASN1_ITEM_rptr(ASN1_BIT_STRING),type,data,md,len)

#  define OCSP_CERTSTATUS_dup(cs)\
                (OCSP_CERTSTATUS*)ASN1_dup((i2d_of_void *)i2d_OCSP_CERTSTATUS,\
                (d2i_of_void *)d2i_OCSP_CERTSTATUS,(char *)(cs))

DECLARE_ASN1_DUP_FUNCTION(OCSP_CERTID)

OSSL_HTTP_REQ_CTX *OCSP_sendreq_new(BIO *io, const char *path,
                                    const OCSP_REQUEST *req, int buf_size);
OCSP_RESPONSE *OCSP_sendreq_bio(BIO *b, const char *path, OCSP_REQUEST *req);

#  ifndef OPENSSL_NO_DEPRECATED_3_0
typedef OSSL_HTTP_REQ_CTX OCSP_REQ_CTX;
#   define OCSP_REQ_CTX_new(io, buf_size) \
        OSSL_HTTP_REQ_CTX_new(io, io, buf_size)
#   define OCSP_REQ_CTX_free OSSL_HTTP_REQ_CTX_free
#   define OCSP_REQ_CTX_http(rctx, op, path) \
        (OSSL_HTTP_REQ_CTX_set_expected(rctx, NULL, 1 /* asn1 */, 0, 0) && \
         OSSL_HTTP_REQ_CTX_set_request_line(rctx, strcmp(op, "POST") == 0, \
                                            NULL, NULL, path))
#   define OCSP_REQ_CTX_add1_header OSSL_HTTP_REQ_CTX_add1_header
#   define OCSP_REQ_CTX_i2d(r, it, req) \
        OSSL_HTTP_REQ_CTX_set1_req(r, "application/ocsp-request", it, req)
#   define OCSP_REQ_CTX_set1_req(r, req) \
        OCSP_REQ_CTX_i2d(r, ASN1_ITEM_rptr(OCSP_REQUEST), (ASN1_VALUE *)(req))
#   define OCSP_REQ_CTX_nbio OSSL_HTTP_REQ_CTX_nbio
#   define OCSP_REQ_CTX_nbio_d2i OSSL_HTTP_REQ_CTX_nbio_d2i
#   define OCSP_sendreq_nbio(p, r) \
        OSSL_HTTP_REQ_CTX_nbio_d2i(r, (ASN1_VALUE **)(p), \
                                   ASN1_ITEM_rptr(OCSP_RESPONSE))
#   define OCSP_REQ_CTX_get0_mem_bio OSSL_HTTP_REQ_CTX_get0_mem_bio
#   define OCSP_set_max_response_length OSSL_HTTP_REQ_CTX_set_max_response_length
#  endif

OCSP_CERTID *OCSP_cert_to_id(const EVP_MD *dgst, const X509 *subject,
                             const X509 *issuer);

OCSP_CERTID *OCSP_cert_id_new(const EVP_MD *dgst,
                              const X509_NAME *issuerName,
                              const ASN1_BIT_STRING *issuerKey,
                              const ASN1_INTEGER *serialNumber);

OCSP_ONEREQ *OCSP_request_add0_id(OCSP_REQUEST *req, OCSP_CERTID *cid);

int OCSP_request_add1_nonce(OCSP_REQUEST *req, unsigned char *val, int len);
int OCSP_basic_add1_nonce(OCSP_BASICRESP *resp, unsigned char *val, int len);
int OCSP_check_nonce(OCSP_REQUEST *req, OCSP_BASICRESP *bs);
int OCSP_copy_nonce(OCSP_BASICRESP *resp, OCSP_REQUEST *req);

int OCSP_request_set1_name(OCSP_REQUEST *req, const X509_NAME *nm);
int OCSP_request_add1_cert(OCSP_REQUEST *req, X509 *cert);

int OCSP_request_sign(OCSP_REQUEST *req,
                      X509 *signer,
                      EVP_PKEY *key,
                      const EVP_MD *dgst,
                      STACK_OF(X509) *certs, unsigned long flags);

int OCSP_response_status(OCSP_RESPONSE *resp);
OCSP_BASICRESP *OCSP_response_get1_basic(OCSP_RESPONSE *resp);

const ASN1_OCTET_STRING *OCSP_resp_get0_signature(const OCSP_BASICRESP *bs);
const X509_ALGOR *OCSP_resp_get0_tbs_sigalg(const OCSP_BASICRESP *bs);
const OCSP_RESPDATA *OCSP_resp_get0_respdata(const OCSP_BASICRESP *bs);
int OCSP_resp_get0_signer(OCSP_BASICRESP *bs, X509 **signer,
                          STACK_OF(X509) *extra_certs);

int OCSP_resp_count(OCSP_BASICRESP *bs);
OCSP_SINGLERESP *OCSP_resp_get0(OCSP_BASICRESP *bs, int idx);
const ASN1_GENERALIZEDTIME *OCSP_resp_get0_produced_at(const OCSP_BASICRESP* bs);
const STACK_OF(X509) *OCSP_resp_get0_certs(const OCSP_BASICRESP *bs);
int OCSP_resp_get0_id(const OCSP_BASICRESP *bs,
                      const ASN1_OCTET_STRING **pid,
                      const X509_NAME **pname);
int OCSP_resp_get1_id(const OCSP_BASICRESP *bs,
                      ASN1_OCTET_STRING **pid,
                      X509_NAME **pname);

int OCSP_resp_find(OCSP_BASICRESP *bs, OCSP_CERTID *id, int last);
int OCSP_single_get0_status(OCSP_SINGLERESP *single, int *reason,
                            ASN1_GENERALIZEDTIME **revtime,
                            ASN1_GENERALIZEDTIME **thisupd,
                            ASN1_GENERALIZEDTIME **nextupd);
int OCSP_resp_find_status(OCSP_BASICRESP *bs, OCSP_CERTID *id, int *status,
                          int *reason,
                          ASN1_GENERALIZEDTIME **revtime,
                          ASN1_GENERALIZEDTIME **thisupd,
                          ASN1_GENERALIZEDTIME **nextupd);
int OCSP_check_validity(ASN1_GENERALIZEDTIME *thisupd,
                        ASN1_GENERALIZEDTIME *nextupd, long sec, long maxsec);

int OCSP_request_verify(OCSP_REQUEST *req, STACK_OF(X509) *certs,
                        X509_STORE *store, unsigned long flags);

#  define OCSP_parse_url(url, host, port, path, ssl) \
    OSSL_HTTP_parse_url(url, ssl, NULL, host, port, NULL, path, NULL, NULL)

int OCSP_id_issuer_cmp(const OCSP_CERTID *a, const OCSP_CERTID *b);
int OCSP_id_cmp(const OCSP_CERTID *a, const OCSP_CERTID *b);

int OCSP_request_onereq_count(OCSP_REQUEST *req);
OCSP_ONEREQ *OCSP_request_onereq_get0(OCSP_REQUEST *req, int i);
OCSP_CERTID *OCSP_onereq_get0_id(OCSP_ONEREQ *one);
int OCSP_id_get0_info(ASN1_OCTET_STRING **piNameHash, ASN1_OBJECT **pmd,
                      ASN1_OCTET_STRING **pikeyHash,
                      ASN1_INTEGER **pserial, OCSP_CERTID *cid);
int OCSP_request_is_signed(OCSP_REQUEST *req);
OCSP_RESPONSE *OCSP_response_create(int status, OCSP_BASICRESP *bs);
OCSP_SINGLERESP *OCSP_basic_add1_status(OCSP_BASICRESP *rsp,
                                        OCSP_CERTID *cid,
                                        int status, int reason,
                                        ASN1_TIME *revtime,
                                        ASN1_TIME *thisupd,
                                        ASN1_TIME *nextupd);
int OCSP_basic_add1_cert(OCSP_BASICRESP *resp, X509 *cert);
int OCSP_basic_sign(OCSP_BASICRESP *brsp,
                    X509 *signer, EVP_PKEY *key, const EVP_MD *dgst,
                    STACK_OF(X509) *certs, unsigned long flags);
int OCSP_basic_sign_ctx(OCSP_BASICRESP *brsp,
                        X509 *signer, EVP_MD_CTX *ctx,
                        STACK_OF(X509) *certs, unsigned long flags);
int OCSP_RESPID_set_by_name(OCSP_RESPID *respid, X509 *cert);
int OCSP_RESPID_set_by_key_ex(OCSP_RESPID *respid, X509 *cert,
                              OSSL_LIB_CTX *libctx, const char *propq);
int OCSP_RESPID_set_by_key(OCSP_RESPID *respid, X509 *cert);
int OCSP_RESPID_match_ex(OCSP_RESPID *respid, X509 *cert, OSSL_LIB_CTX *libctx,
                         const char *propq);
int OCSP_RESPID_match(OCSP_RESPID *respid, X509 *cert);

X509_EXTENSION *OCSP_crlID_new(const char *url, long *n, char *tim);

X509_EXTENSION *OCSP_accept_responses_new(char **oids);

X509_EXTENSION *OCSP_archive_cutoff_new(char *tim);

X509_EXTENSION *OCSP_url_svcloc_new(const X509_NAME *issuer, const char **urls);

int OCSP_REQUEST_get_ext_count(OCSP_REQUEST *x);
int OCSP_REQUEST_get_ext_by_NID(OCSP_REQUEST *x, int nid, int lastpos);
int OCSP_REQUEST_get_ext_by_OBJ(OCSP_REQUEST *x, const ASN1_OBJECT *obj,
                                int lastpos);
int OCSP_REQUEST_get_ext_by_critical(OCSP_REQUEST *x, int crit, int lastpos);
X509_EXTENSION *OCSP_REQUEST_get_ext(OCSP_REQUEST *x, int loc);
X509_EXTENSION *OCSP_REQUEST_delete_ext(OCSP_REQUEST *x, int loc);
void *OCSP_REQUEST_get1_ext_d2i(OCSP_REQUEST *x, int nid, int *crit,
                                int *idx);
int OCSP_REQUEST_add1_ext_i2d(OCSP_REQUEST *x, int nid, void *value, int crit,
                              unsigned long flags);
int OCSP_REQUEST_add_ext(OCSP_REQUEST *x, X509_EXTENSION *ex, int loc);

int OCSP_ONEREQ_get_ext_count(OCSP_ONEREQ *x);
int OCSP_ONEREQ_get_ext_by_NID(OCSP_ONEREQ *x, int nid, int lastpos);
int OCSP_ONEREQ_get_ext_by_OBJ(OCSP_ONEREQ *x, const ASN1_OBJECT *obj, int lastpos);
int OCSP_ONEREQ_get_ext_by_critical(OCSP_ONEREQ *x, int crit, int lastpos);
X509_EXTENSION *OCSP_ONEREQ_get_ext(OCSP_ONEREQ *x, int loc);
X509_EXTENSION *OCSP_ONEREQ_delete_ext(OCSP_ONEREQ *x, int loc);
void *OCSP_ONEREQ_get1_ext_d2i(OCSP_ONEREQ *x, int nid, int *crit, int *idx);
int OCSP_ONEREQ_add1_ext_i2d(OCSP_ONEREQ *x, int nid, void *value, int crit,
                             unsigned long flags);
int OCSP_ONEREQ_add_ext(OCSP_ONEREQ *x, X509_EXTENSION *ex, int loc);

int OCSP_BASICRESP_get_ext_count(OCSP_BASICRESP *x);
int OCSP_BASICRESP_get_ext_by_NID(OCSP_BASICRESP *x, int nid, int lastpos);
int OCSP_BASICRESP_get_ext_by_OBJ(OCSP_BASICRESP *x, const ASN1_OBJECT *obj,
                                  int lastpos);
int OCSP_BASICRESP_get_ext_by_critical(OCSP_BASICRESP *x, int crit,
                                       int lastpos);
X509_EXTENSION *OCSP_BASICRESP_get_ext(OCSP_BASICRESP *x, int loc);
X509_EXTENSION *OCSP_BASICRESP_delete_ext(OCSP_BASICRESP *x, int loc);
void *OCSP_BASICRESP_get1_ext_d2i(OCSP_BASICRESP *x, int nid, int *crit,
                                  int *idx);
int OCSP_BASICRESP_add1_ext_i2d(OCSP_BASICRESP *x, int nid, void *value,
                                int crit, unsigned long flags);
int OCSP_BASICRESP_add_ext(OCSP_BASICRESP *x, X509_EXTENSION *ex, int loc);

int OCSP_SINGLERESP_get_ext_count(OCSP_SINGLERESP *x);
int OCSP_SINGLERESP_get_ext_by_NID(OCSP_SINGLERESP *x, int nid, int lastpos);
int OCSP_SINGLERESP_get_ext_by_OBJ(OCSP_SINGLERESP *x, const ASN1_OBJECT *obj,
                                   int lastpos);
int OCSP_SINGLERESP_get_ext_by_critical(OCSP_SINGLERESP *x, int crit,
                                        int lastpos);
X509_EXTENSION *OCSP_SINGLERESP_get_ext(OCSP_SINGLERESP *x, int loc);
X509_EXTENSION *OCSP_SINGLERESP_delete_ext(OCSP_SINGLERESP *x, int loc);
void *OCSP_SINGLERESP_get1_ext_d2i(OCSP_SINGLERESP *x, int nid, int *crit,
                                   int *idx);
int OCSP_SINGLERESP_add1_ext_i2d(OCSP_SINGLERESP *x, int nid, void *value,
                                 int crit, unsigned long flags);
int OCSP_SINGLERESP_add_ext(OCSP_SINGLERESP *x, X509_EXTENSION *ex, int loc);
const OCSP_CERTID *OCSP_SINGLERESP_get0_id(const OCSP_SINGLERESP *x);

DECLARE_ASN1_FUNCTIONS(OCSP_SINGLERESP)
DECLARE_ASN1_FUNCTIONS(OCSP_CERTSTATUS)
DECLARE_ASN1_FUNCTIONS(OCSP_REVOKEDINFO)
DECLARE_ASN1_FUNCTIONS(OCSP_BASICRESP)
DECLARE_ASN1_FUNCTIONS(OCSP_RESPDATA)
DECLARE_ASN1_FUNCTIONS(OCSP_RESPID)
DECLARE_ASN1_FUNCTIONS(OCSP_RESPONSE)
DECLARE_ASN1_FUNCTIONS(OCSP_RESPBYTES)
DECLARE_ASN1_FUNCTIONS(OCSP_ONEREQ)
DECLARE_ASN1_FUNCTIONS(OCSP_CERTID)
DECLARE_ASN1_FUNCTIONS(OCSP_REQUEST)
DECLARE_ASN1_FUNCTIONS(OCSP_SIGNATURE)
DECLARE_ASN1_FUNCTIONS(OCSP_REQINFO)
DECLARE_ASN1_FUNCTIONS(OCSP_CRLID)
DECLARE_ASN1_FUNCTIONS(OCSP_SERVICELOC)

const char *OCSP_response_status_str(long s);
const char *OCSP_cert_status_str(long s);
const char *OCSP_crl_reason_str(long s);

int OCSP_REQUEST_print(BIO *bp, OCSP_REQUEST *a, unsigned long flags);
int OCSP_RESPONSE_print(BIO *bp, OCSP_RESPONSE *o, unsigned long flags);

int OCSP_basic_verify(OCSP_BASICRESP *bs, STACK_OF(X509) *certs,
                      X509_STORE *st, unsigned long flags);


#  ifdef  __cplusplus
}
#  endif
# endif /* !defined(OPENSSL_NO_OCSP) */
#endif
                                                                                                                                                                                                                                                                                                                                                        node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/openssl/opensslv.h      0000664 0000000 0000000 00000006206 14746647661 0031730 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /*
 * WARNING: do not edit!
 * Generated by Makefile from include/openssl/opensslv.h.in
 *
 * Copyright 1999-2020 The OpenSSL Project Authors. All Rights Reserved.
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 */

#ifndef OPENSSL_OPENSSLV_H
# define OPENSSL_OPENSSLV_H
# pragma once

# ifdef  __cplusplus
extern "C" {
# endif

/*
 * SECTION 1: VERSION DATA.  These will change for each release
 */

/*
 * Base version macros
 *
 * These macros express version number MAJOR.MINOR.PATCH exactly
 */
# define OPENSSL_VERSION_MAJOR  3
# define OPENSSL_VERSION_MINOR  0
# define OPENSSL_VERSION_PATCH  15

/*
 * Additional version information
 *
 * These are also part of the new version scheme, but aren't part
 * of the version number itself.
 */

/* Could be: #define OPENSSL_VERSION_PRE_RELEASE "-alpha.1" */
# define OPENSSL_VERSION_PRE_RELEASE ""
/* Could be: #define OPENSSL_VERSION_BUILD_METADATA "+fips" */
/* Could be: #define OPENSSL_VERSION_BUILD_METADATA "+vendor.1" */
# define OPENSSL_VERSION_BUILD_METADATA "+quic"

/*
 * Note: The OpenSSL Project will never define OPENSSL_VERSION_BUILD_METADATA
 * to be anything but the empty string.  Its use is entirely reserved for
 * others
 */

/*
 * Shared library version
 *
 * This is strictly to express ABI version, which may or may not
 * be related to the API version expressed with the macros above.
 * This is defined in free form.
 */
# define OPENSSL_SHLIB_VERSION 81.3

/*
 * SECTION 2: USEFUL MACROS
 */

/* For checking general API compatibility when preprocessing */
# define OPENSSL_VERSION_PREREQ(maj,min)                                \
    ((OPENSSL_VERSION_MAJOR << 16) + OPENSSL_VERSION_MINOR >= ((maj) << 16) + (min))

/*
 * Macros to get the version in easily digested string form, both the short
 * "MAJOR.MINOR.PATCH" variant (where MAJOR, MINOR and PATCH are replaced
 * with the values from the corresponding OPENSSL_VERSION_ macros) and the
 * longer variant with OPENSSL_VERSION_PRE_RELEASE_STR and
 * OPENSSL_VERSION_BUILD_METADATA_STR appended.
 */
# define OPENSSL_VERSION_STR "3.0.15"
# define OPENSSL_FULL_VERSION_STR "3.0.15+quic"

/*
 * SECTION 3: ADDITIONAL METADATA
 *
 * These strings are defined separately to allow them to be parsable.
 */
# define OPENSSL_RELEASE_DATE "3 Sep 2024"

/*
 * SECTION 4: BACKWARD COMPATIBILITY
 */

# define OPENSSL_VERSION_TEXT "OpenSSL 3.0.15+quic 3 Sep 2024"

/* Synthesize OPENSSL_VERSION_NUMBER with the layout 0xMNN00PPSL */
# ifdef OPENSSL_VERSION_PRE_RELEASE
#  define _OPENSSL_VERSION_PRE_RELEASE 0x0L
# else
#  define _OPENSSL_VERSION_PRE_RELEASE 0xfL
# endif
# define OPENSSL_VERSION_NUMBER          \
    ( (OPENSSL_VERSION_MAJOR<<28)        \
      |(OPENSSL_VERSION_MINOR<<20)       \
      |(OPENSSL_VERSION_PATCH<<4)        \
      |_OPENSSL_VERSION_PRE_RELEASE )

# ifdef  __cplusplus
}
# endif

# include <openssl/macros.h>
# ifndef OPENSSL_NO_DEPRECATED_3_0
#  define HEADER_OPENSSLV_H
# endif

#endif                          /* OPENSSL_OPENSSLV_H */
                                                                                                                                                                                                                                                                                                                                                                                          node-23.7.0/deps/openssl/config/archs/solaris64-x86_64-gcc/asm_avx2/include/openssl/pkcs12.h        0000664 0000000 0000000 00000045564 14746647661 0031174 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        /*
 * WARNING: do not edit!
 * Generated by Makefile from include/openssl/pkcs12.h.in
 *
 * Copyright 1999-2021 The OpenSSL Project Authors. All Rights Reserved.
 *
 * Licensed under the Apache License 2.0 (the "License").  You may not use
 * this file except in compliance with the License.  You can obtain a copy
 * in the file LICENSE in the source distribution or at
 * https://www.openssl.org/source/license.html
 */



#ifndef OPENSSL_PKCS12_H
# define OPENSSL_PKCS12_H
# pragma once

# include <openssl/macros.h>
# ifndef OPENSSL_NO_DEPRECATED_3_0
#  define HEADER_PKCS12_H
# endif

# include <openssl/bio.h>
# include <openssl/core.h>
# include <openssl/x509.h>
# include <openssl/pkcs12err.h>

#ifdef __cplusplus
extern "C" {
#endif

# define PKCS12_KEY_ID   1
# define PKCS12_IV_ID    2
# define PKCS12_MAC_ID   3

/* Default iteration count */
# ifndef PKCS12_DEFAULT_ITER
#  define PKCS12_DEFAULT_ITER     PKCS5_DEFAULT_ITER
# endif

# define PKCS12_MAC_KEY_LENGTH 20

# define PKCS12_SALT_LEN 8

/* It's not clear if these are actually needed... */
# define PKCS12_key_gen PKCS12_key_gen_utf8
# define PKCS12_add_friendlyname PKCS12_add_friendlyname_utf8

/* MS key usage constants */

# define KEY_EX  0x10
# define KEY_SIG 0x80

typedef struct PKCS12_MAC_DATA_st PKCS12_MAC_DATA;

typedef struct PKCS12_st PKCS12;

typedef struct PKCS12_SAFEBAG_st PKCS12_SAFEBAG;

SKM_DEFINE_STACK_OF_INTERNAL(PKCS12_SAFEBAG, PKCS12_SAFEBAG, PKCS12_SAFEBAG)
#define sk_PKCS12_SAFEBAG_num(sk) OPENSSL_sk_num(ossl_check_const_PKCS12_SAFEBAG_sk_type(sk))
#define sk_PKCS12_SAFEBAG_value(sk, idx) ((PKCS12_SAFEBAG *)OPENSSL_sk_value(ossl_check_const_PKCS12_SAFEBAG_sk_type(sk), (idx)))
#define sk_PKCS12_SAFEBAG_new(cmp) ((STACK_OF(PKCS12_SAFEBAG) *)OPENSSL_sk_new(ossl_check_PKCS12_SAFEBAG_compfunc_type(cmp)))
#define sk_PKCS12_SAFEBAG_new_null() ((STACK_OF(PKCS12_SAFEBAG) *)OPENSSL_sk_new_null())
#define sk_PKCS12_SAFEBAG_new_reserve(cmp, n) ((STACK_OF(PKCS12_SAFEBAG) *)OPENSSL_sk_new_reserve(ossl_check_PKCS12_SAFEBAG_compfunc_type(cmp), (n)))
#define sk_PKCS12_SAFEBAG_reserve(sk, n) OPENSSL_sk_reserve(ossl_check_PKCS12_SAFEBAG_sk_type(sk), (n))
#define sk_PKCS12_SAFEBAG_free(sk) OPENSSL_sk_free(ossl_check_PKCS12_SAFEBAG_sk_type(sk))
#define sk_PKCS12_SAFEBAG_zero(sk) OPENSSL_sk_zero(ossl_check_PKCS12_SAFEBAG_sk_type(sk))
#define sk_PKCS12_SAFEBAG_delete(sk, i) ((PKCS12_SAFEBAG *)OPENSSL_sk_delete(ossl_check_PKCS12_SAFEBAG_sk_type(sk), (i)))
#define sk_PKCS12_SAFEBAG_delete_ptr(sk, ptr) ((PKCS12_SAFEBAG *)OPENSSL_sk_delete_ptr(ossl_check_PKCS12_SAFEBAG_sk_type(sk), ossl_check_PKCS12_SAFEBAG_type(ptr)))
#define sk_PKCS12_SAFEBAG_push(sk, ptr) OPENSSL_sk_push(ossl_check_PKCS12_SAFEBAG_sk_type(sk), ossl_check_PKCS12_SAFEBAG_type(ptr))
#define sk_PKCS12_SAFEBAG_unshift(sk, ptr) OPENSSL_sk_unshift(ossl_check_PKCS12_SAFEBAG_sk_type(sk), ossl_check_PKCS12_SAFEBAG_type(ptr))
#define sk_PKCS12_SAFEBAG_pop(sk) ((PKCS12_SAFEBAG *)OPENSSL_sk_pop(ossl_check_PKCS12_SAFEBAG_sk_type(sk)))
#define sk_PKCS12_SAFEBAG_shift(sk) ((PKCS12_SAFEBAG *)OPENSSL_sk_shift(ossl_check_PKCS12_SAFEBAG_sk_type(sk)))
#define sk_PKCS12_SAFEBAG_pop_free(sk, freefunc) OPENSSL_sk_pop_free(ossl_check_PKCS12_SAFEBAG_sk_type(sk),ossl_check_PKCS12_SAFEBAG_freefunc_type(freefunc))
#define sk_PKCS12_SAFEBAG_insert(sk, ptr, idx) OPENSSL_sk_insert(ossl_check_PKCS12_SAFEBAG_sk_type(sk), ossl_check_PKCS12_SAFEBAG_type(ptr), (idx))
#define sk_PKCS12_SAFEBAG_set(sk, idx, ptr) ((PKCS12_SAFEBAG *)OPENSSL_sk_set(ossl_check_PKCS12_SAFEBAG_sk_type(sk), (idx), ossl_check_PKCS12_SAFEBAG_type(ptr)))
#define sk_PKCS12_SAFEBAG_find(sk, ptr) OPENSSL_sk_find(ossl_check_PKCS12_SAFEBAG_sk_type(sk), ossl_check_PKCS12_SAFEBAG_type(ptr))
#define sk_PKCS12_SAFEBAG_find_ex(sk, ptr) OPENSSL_sk_find_ex(ossl_check_PKCS12_SAFEBAG_sk_type(sk), ossl_check_PKCS12_SAFEBAG_type(ptr))
#define sk_PKCS12_SAFEBAG_find_all(sk, ptr, pnum) OPENSSL_sk_find_all(ossl_check_PKCS12_SAFEBAG_sk_type(sk), ossl_check_PKCS12_SAFEBAG_type(ptr), pnum)
#define sk_PKCS12_SAFEBAG_sort(sk) OPENSSL_sk_sort(ossl_check_PKCS12_SAFEBAG_sk_type(sk))
#define sk_PKCS12_SAFEBAG_is_sorted(sk) OPENSSL_sk_is_sorted(ossl_check_const_PKCS12_SAFEBAG_sk_type(sk))
#define sk_PKCS12_SAFEBAG_dup(sk) ((STACK_OF(PKCS12_SAFEBAG) *)OPENSSL_sk_dup(ossl_check_const_PKCS12_SAFEBAG_sk_type(sk)))
#define sk_PKCS12_SAFEBAG_deep_copy(sk, copyfunc, freefunc) ((STACK_OF(PKCS12_SAFEBAG) *)OPENSSL_sk_deep_copy(ossl_check_const_PKCS12_SAFEBAG_sk_type(sk), ossl_check_PKCS12_SAFEBAG_copyfunc_type(copyfunc), ossl_check_PKCS12_SAFEBAG_freefunc_type(freefunc)))
#define sk_PKCS12_SAFEBAG_set_cmp_func(sk, cmp) ((sk_PKCS12_SAFEBAG_compfunc)OPENSSL_sk_set_cmp_func(ossl_check_PKCS12_SAFEBAG_sk_type(sk), ossl_check_PKCS12_SAFEBAG_compfunc_type(cmp)))


typedef struct pkcs12_bag_st PKCS12_BAGS;

# define PKCS12_ERROR    0
# define PKCS12_OK       1

/* Compatibility macros */

#ifndef OPENSSL_NO_DEPRECATED_1_1_0

# define M_PKCS12_bag_type PKCS12_bag_type
# define M_PKCS12_cert_bag_type PKCS12_cert_bag_type
# define M_PKCS12_crl_bag_type PKCS12_cert_bag_type

# define PKCS12_certbag2x509 PKCS12_SAFEBAG_get1_cert
# define PKCS12_certbag2scrl PKCS12_SAFEBAG_get1_crl
# define PKCS12_bag_type PKCS12_SAFEBAG_get_nid
# define PKCS12_cert_bag_type PKCS12_SAFEBAG_get_bag_nid
# define PKCS12_x5092certbag PKCS12_SAFEBAG_create_cert
# define PKCS12_x509crl2certbag PKCS12_SAFEBAG_create_crl
# define PKCS12_MAKE_KEYBAG PKCS12_SAFEBAG_create0_p8inf
# define PKCS12_MAKE_SHKEYBAG PKCS12_SAFEBAG_create_pkcs8_encrypt

#endif
#ifndef OPENSSL_NO_DEPRECATED_1_1_0
OSSL_DEPRECATEDIN_1_1_0 ASN1_TYPE *PKCS12_get_attr(const PKCS12_SAFEBAG *bag,
                                                   int attr_nid);
#endif

ASN1_TYPE *PKCS8_get_attr(PKCS8_PRIV_KEY_INFO *p8, int attr_nid);
int PKCS12_mac_present(const PKCS12 *p12);
void PKCS12_get0_mac(const ASN1_OCTET_STRING **pmac,
                     const X509_ALGOR **pmacalg,
                     const ASN1_OCTET_STRING **psalt,
                     const ASN1_INTEGER **piter,
                     const PKCS12 *p12);

const ASN1_TYPE *PKCS12_SAFEBAG_get0_attr(const PKCS12_SAFEBAG *bag,
                                          int attr_nid);
const ASN1_OBJECT *PKCS12_SAFEBAG_get0_type(const PKCS12_SAFEBAG *bag);
int PKCS12_SAFEBAG_get_nid(const PKCS12_SAFEBAG *bag);
int PKCS12_SAFEBAG_get_bag_nid(const PKCS12_SAFEBAG *bag);
const ASN1_TYPE *PKCS12_SAFEBAG_get0_bag_obj(const PKCS12_SAFEBAG *bag);
const ASN1_OBJECT *PKCS12_SAFEBAG_get0_bag_type(const PKCS12_SAFEBAG *bag);

X509 *PKCS12_SAFEBAG_get1_cert(const PKCS12_SAFEBAG *bag);
X509_CRL *PKCS12_SAFEBAG_get1_crl(const PKCS12_SAFEBAG *bag);
const STACK_OF(PKCS12_SAFEBAG) *
PKCS12_SAFEBAG_get0_safes(const PKCS12_SAFEBAG *bag);
const PKCS8_PRIV_KEY_INFO *PKCS12_SAFEBAG_get0_p8inf(const PKCS12_SAFEBAG *bag);
const X509_SIG *PKCS12_SAFEBAG_get0_pkcs8(const PKCS12_SAFEBAG *bag);

PKCS12_SAFEBAG *PKCS12_SAFEBAG_create_cert(X509 *x509);
PKCS12_SAFEBAG *PKCS12_SAFEBAG_create_crl(X509_CRL *crl);
PKCS12_SAFEBAG *PKCS12_SAFEBAG_create_secret(int type, int vtype, const unsigned char *value, int len);
PKCS12_SAFEBAG *PKCS12_SAFEBAG_create0_p8inf(PKCS8_PRIV_KEY_INFO *p8);
PKCS12_SAFEBAG *PKCS12_SAFEBAG_create0_pkcs8(X509_SIG *p8);
PKCS12_SAFEBAG *PKCS12_SAFEBAG_create_pkcs8_encrypt(int pbe_nid,
                                                    const char *pass,
                                                    int passlen,
                                                    unsigned char *salt,
                                                    int saltlen, int iter,
                                                    PKCS8_PRIV_KEY_INFO *p8inf);
PKCS12_SAFEBAG *PKCS12_SAFEBAG_create_pkcs8_encrypt_ex(int pbe_nid,
                                                       const char *pass,
                                                       int passlen,
                                                       unsigned char *salt,
                                                       int saltlen, int iter,
                                                       PKCS8_PRIV_KEY_INFO *p8inf,
                                                       OSSL_LIB_CTX *ctx,
                                                       const char *propq);

PKCS12_SAFEBAG *PKCS12_item_pack_safebag(void *obj, const ASN1_ITEM *it,
                                         int nid1, int nid2);
PKCS8_PRIV_KEY_INFO *PKCS8_decrypt(const X509_SIG *p8, const char *pass,
                                   int passlen);
PKCS8_PRIV_KEY_INFO *PKCS8_decrypt_ex(const X509_SIG *p8, const char *pass,
                                      int passlen, OSSL_LIB_CTX *ctx,
                                      const char *propq);
PKCS8_PRIV_KEY_INFO *PKCS12_decrypt_skey(const PKCS12_SAFEBAG *bag,
                                         const char *pass, int passlen);
PKCS8_PRIV_KEY_INFO *PKCS12_decrypt_skey_ex(const PKCS12_SAFEBAG *bag,
                                            const char *pass, int passlen,
                                            OSSL_LIB_CTX *ctx,
                                            const char *propq);
X509_SIG *PKCS8_encrypt(int pbe_nid, const EVP_CIPHER *cipher,
      