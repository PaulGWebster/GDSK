       disclaimer in the documentation and/or other materials provided
#       with the distribution.
#     * Neither the name of Google Inc. nor the names of its
#       contributors may be used to endorse or promote products derived
#       from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#

#
# This is an utility for plotting charts based on GC traces produced by V8 when
# run with flags --trace-gc --trace-gc-nvp. Relies on gnuplot for actual
# plotting.
#
# Usage: gc-nvp-trace-processor.py <GC-trace-filename>
#


# for py2/py3 compatibility
from __future__ import with_statement
from __future__ import print_function
from functools import reduce

import sys, types, subprocess, math
import gc_nvp_common


try:
  long        # Python 2
except NameError:
  long = int  # Python 3


def flatten(l):
  flat = []
  for i in l: flat.extend(i)
  return flat

def gnuplot(script):
  gnuplot = subprocess.Popen(["gnuplot"], stdin=subprocess.PIPE)
  gnuplot.stdin.write(script)
  gnuplot.stdin.close()
  gnuplot.wait()

x1y1 = 'x1y1'
x1y2 = 'x1y2'
x2y1 = 'x2y1'
x2y2 = 'x2y2'

class Item(object):
  def __init__(self, title, field, axis = x1y1, **keywords):
    self.title = title
    self.axis = axis
    self.props = keywords
    if type(field) is list:
      self.field = field
    else:
      self.field = [field]

  def fieldrefs(self):
    return self.field

  def to_gnuplot(self, context):
    args = ['"%s"' % context.datafile,
            'using %s' % context.format_fieldref(self.field),
            'title "%s"' % self.title,
            'axis %s' % self.axis]
    if 'style' in self.props:
      args.append('with %s' % self.props['style'])
    if 'lc' in self.props:
      args.append('lc rgb "%s"' % self.props['lc'])
    if 'fs' in self.props:
      args.append('fs %s' % self.props['fs'])
    return ' '.join(args)

class Plot(object):
  def __init__(self, *items):
    self.items = items

  def fieldrefs(self):
    return flatten([item.fieldrefs() for item in self.items])

  def to_gnuplot(self, ctx):
    return 'plot ' + ', '.join([item.to_gnuplot(ctx) for item in self.items])

class Set(object):
  def __init__(self, value):
    self.value = value

  def to_gnuplot(self, ctx):
    return 'set ' + self.value

  def fieldrefs(self):
    return []

class Context(object):
  def __init__(self, datafile, field_to_index):
    self.datafile = datafile
    self.field_to_index = field_to_index

  def format_fieldref(self, fieldref):
    return ':'.join([str(self.field_to_index[field]) for field in fieldref])

def collect_fields(plot):
  field_to_index = {}
  fields = []

  def add_field(field):
    if field not in field_to_index:
      fields.append(field)
      field_to_index[field] = len(fields)

  for field in flatten([item.fieldrefs() for item in plot]):
    add_field(field)

  return (fields, field_to_index)

def is_y2_used(plot):
  for subplot in plot:
    if isinstance(subplot, Plot):
      for item in subplot.items:
        if item.axis == x1y2 or item.axis == x2y2:
          return True
  return False

def get_field(trace_line, field):
  t = type(field)
  if t is bytes:
    return trace_line[field]
  elif t is types.FunctionType:
    return field(trace_line)

def generate_datafile(datafile_name, trace, fields):
  with open(datafile_name, 'w') as datafile:
    for line in trace:
      data_line = [str(get_field(line, field)) for field in fields]
      datafile.write('\t'.join(data_line))
      datafile.write('\n')

def generate_script_and_datafile(plot, trace, datafile, output):
  (fields, field_to_index) = collect_fields(plot)
  generate_datafile(datafile, trace, fields)
  script = [
      'set terminal png',
      'set output "%s"' % output,
      'set autoscale',
      'set ytics nomirror',
      'set xtics nomirror',
      'set key below'
  ]

  if is_y2_used(plot):
    script.append('set autoscale y2')
    script.append('set y2tics')

  context = Context(datafile, field_to_index)

  for item in plot:
    script.append(item.to_gnuplot(context))

  return '\n'.join(script)

def plot_all(plots, trace, prefix):
  charts = []

  for plot in plots:
    outfilename = "%s_%d.png" % (prefix, len(charts))
    charts.append(outfilename)
    script = generate_script_and_datafile(plot, trace, '~datafile', outfilename)
    print('Plotting %s...' % outfilename)
    gnuplot(script)

  return charts

def reclaimed_bytes(row):
  return row['total_size_before'] - row['total_size_after']

def other_scope(r):
  if r['gc'] == 's':
    # there is no 'other' scope for scavenging collections.
    return 0
  return r['pause'] - r['mark'] - r['sweep'] - r['external']

def scavenge_scope(r):
  if r['gc'] == 's':
    return r['pause'] - r['external']
  return 0


def real_mutator(r):
  return r['mutator'] - r['steps_took']

plots = [
  [
    Set('style fill solid 0.5 noborder'),
    Set('style histogram rowstacked'),
    Set('style data histograms'),
    Plot(Item('Scavenge', scavenge_scope, lc = 'green'),
         Item('Marking', 'mark', lc = 'purple'),
         Item('Sweep', 'sweep', lc = 'blue'),
         Item('External', 'external', lc = '#489D43'),
         Item('Other', other_scope, lc = 'grey'),
         Item('IGC Steps', 'steps_took', lc = '#FF6347'))
  ],
  [
    Set('style fill solid 0.5 noborder'),
    Set('style histogram rowstacked'),
    Set('style data histograms'),
    Plot(Item('Scavenge', scavenge_scope, lc = 'green'),
         Item('Marking', 'mark', lc = 'purple'),
         Item('Sweep', 'sweep', lc = 'blue'),
         Item('External', 'external', lc = '#489D43'),
         Item('Other', other_scope, lc = '#ADD8E6'),
         Item('External', 'external', lc = '#D3D3D3'))
  ],

  [
    Plot(Item('Mutator', real_mutator, lc = 'black', style = 'lines'))
  ],
  [
    Set('style histogram rowstacked'),
    Set('style data histograms'),
    Plot(Item('Heap Size (before GC)', 'total_size_before', x1y2,
              fs = 'solid 0.4 noborder',
              lc = 'green'),
         Item('Total holes (after GC)', 'holes_size_before', x1y2,
              fs = 'solid 0.4 noborder',
              lc = 'red'),
         Item('GC Time', ['i', 'pause'], style = 'lines', lc = 'red'))
  ],
  [
    Set('style histogram rowstacked'),
    Set('style data histograms'),
    Plot(Item('Heap Size (after GC)', 'total_size_after', x1y2,
              fs = 'solid 0.4 noborder',
              lc = 'green'),
         Item('Total holes (after GC)', 'holes_size_after', x1y2,
              fs = 'solid 0.4 noborder',
              lc = 'red'),
         Item('GC Time', ['i', 'pause'],
              style = 'lines',
              lc = 'red'))
  ],
  [
    Set('style fill solid 0.5 noborder'),
    Set('style data histograms'),
    Plot(Item('Allocated', 'allocated'),
         Item('Reclaimed', reclaimed_bytes),
         Item('Promoted', 'promoted', style = 'lines', lc = 'black'))
  ],
]

def freduce(f, field, trace, init):
  return reduce(lambda t,r: f(t, r[field]), trace, init)

def calc_total(trace, field):
  return freduce(lambda t,v: t + long(v), field, trace, long(0))

def calc_max(trace, field):
  return freduce(lambda t,r: max(t, r), field, trace, 0)

def count_nonzero(trace, field):
  return freduce(lambda t,r: t if r == 0 else t + 1, field, trace, 0)


def process_trace(filename):
  trace = gc_nvp_common.parse_gc_trace(filename)

  marksweeps = filter(lambda r: r['gc'] == 'ms', trace)
  scavenges = filter(lambda r: r['gc'] == 's', trace)
  globalgcs = filter(lambda r: r['gc'] != 's', trace)


  charts = plot_all(plots, trace, filename)

  def stats(out, prefix, trace, field):
    n = len(trace)
    total = calc_total(trace, field)
    max = calc_max(trace, field)
    if n > 0:
      avg = total / n
    else:
      avg = 0
    if n > 1:
      dev = math.sqrt(freduce(lambda t,r: t + (r - avg) ** 2, field, trace, 0) /
                      (n - 1))
    else:
      dev = 0

    out.write('<tr><td>%s</td><td>%d</td><td>%d</td>'
              '<td>%d</td><td>%d [dev %f]</td></tr>' %
              (prefix, n, total, max, avg, dev))

  def HumanReadable(size):
    suffixes = ['bytes', 'kB', 'MB', 'GB']
    power = 1
    for i in range(len(suffixes)):
      if size < power*1024:
        return "%.1f" % (float(size) / power) + " " + suffixes[i]
      power *= 1024

  def throughput(name, trace):
    total_live_after = calc_total(trace, 'total_size_after')
    total_live_before = calc_total(trace, 'total_size_before')
    total_gc = calc_total(trace, 'pause')
    if total_gc == 0:
      return
    out.write('GC %s Throughput (after): %s / %s ms = %s/ms<br/>' %
              (name,
               HumanReadable(total_live_after),
               total_gc,
               HumanReadable(total_live_after / total_gc)))
    out.write('GC %s Throughput (before): %s / %s ms = %s/ms<br/>' %
              (name,
               HumanReadable(total_live_before),
               total_gc,
               HumanReadable(total_live_before / total_gc)))


  with open(filename + '.html', 'w') as out:
    out.write('<html><body>')
    out.write('<table>')
    out.write('<tr><td>Phase</td><td>Count</td><td>Time (ms)</td>')
    out.write('<td>Max</td><td>Avg</td></tr>')
    stats(out, 'Total in GC', trace, 'pause')
    stats(out, 'Scavenge', scavenges, 'pause')
    stats(out, 'MarkSweep', marksweeps, 'pause')
    stats(out, 'Mark', filter(lambda r: r['mark'] != 0, trace), 'mark')
    stats(out, 'Sweep', filter(lambda r: r['sweep'] != 0, trace), 'sweep')
    stats(out,
          'External',
          filter(lambda r: r['external'] != 0, trace),
          'external')
    out.write('</table>')
    throughput('TOTAL', trace)
    throughput('MS', marksweeps)
    throughput('OLDSPACE', globalgcs)
    out.write('<br/>')
    for chart in charts:
      out.write('<img src="%s">' % chart)
      out.write('</body></html>')

  print("%s generated." % (filename + '.html'))

if len(sys.argv) != 2:
  print("Usage: %s <GC-trace-filename>" % sys.argv[0])
  sys.exit(1)

process_trace(sys.argv[1])
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      node-23.7.0/deps/v8/tools/gc_nvp_common.py                                                          0000664 0000000 0000000 00000003335 14746647661 0020407 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # Copyright 2015 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

#
# Common code for parsing --trace-gc-nvp output.
#


from __future__ import with_statement
import re


def split_nvp(s):
  t = {}
  for name, value in re.findall(r"([._\w]+)=([-\w]+(?:\.[0-9]+)?)", s):
    try:
      t[name] = float(value)
    except ValueError:
      t[name] = value
  return t


def split_nvp_with_keys(s):
  t, k = {}, []
  for name, value in re.findall(r"([._\w]+)=([-\w]+(?:\.[0-9]+)?)", s):
    try:
      t[name] = float(value)
    except ValueError:
      t[name] = value
    k.append(name)
  return t, k


def parse_gc_trace(input):
  # If input is string, treat it as a filename and open the file for reading.
  if isinstance(input, str):
    with open(input, 'rt') as f:
      return parse_gc_trace(f)
  # Otherwise, treat it as a file-like object.
  trace = []
  for line in input:
    info = split_nvp(line)
    if info and 'pause' in info and info['pause'] > 0:
      info['i'] = len(trace)
      trace.append(info)
  return trace


def parse_gc_trace_with_keys(input):
  # If input is string, treat it as a filename and open the file for reading.
  if isinstance(input, str):
    with open(input, 'rt') as f:
      return parse_gc_trace_with_keys(f)
  # Otherwise, treat it as a file-like object.
  trace = []
  keys = {'i'}
  key_list = ['i']
  for line in input:
    info, info_keys = split_nvp_with_keys(line)
    if info and 'pause' in info and info['pause'] > 0:
      info['i'] = len(trace)
      trace.append(info)
      for key in info_keys:
        if key not in keys:
          keys.add(key)
          key_list.append(key)
  return trace, key_list
                                                                                                                                                                                                                                                                                                   node-23.7.0/deps/v8/tools/gcmole/                                                                   0000775 0000000 0000000 00000000000 14746647661 0016453 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/gcmole/BUILD.gn                                                           0000664 0000000 0000000 00000004053 14746647661 0017642 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # Copyright 2018 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

import("//build/config/sysroot.gni")
import("../../gni/v8.gni")

if (v8_gcmole) {
  group("v8_gcmole_files") {
    testonly = true
    data_deps = [
      ":v8_gcmole_args",
      "../../:v8_dump_build_config",
      "../../:v8_generated_cc_files",
    ]
    data = [
      "gcmole.py",
      "gcmole-test.cc",
      "gcmole-tools/",
      "run-gcmole.py",
      "suspects.allowlist",
      "ignored_files",
      "test-expectations.txt",

      # The following contains all relevant source and build files.
      "../debug_helper/debug-helper.h",
      "../../BUILD.gn",
      "../../include/",
      "../../src/",
      "../../test/cctest/",
      "../../test/common/",
      "../../testing/gtest/include/gtest/gtest_prod.h",
      "../../third_party/abseil-cpp/",
      "../../third_party/glibc/",
      "../../third_party/googletest/src/googletest/include/gtest/gtest_prod.h",
      "../../third_party/icu/source/common/",
      "../../third_party/icu/source/i18n/",
      "../../third_party/wasm-api/wasm.h",
      "../../third_party/wasm-api/wasm.hh",
      "../../third_party/zlib/",
      "../../third_party/inspector_protocol/",
      "../../third_party/fp16/",
      "../../third_party/v8/codegen/",
      "$target_gen_dir/../../",
      "$target_gen_dir/../../torque-generated/",

      # This assumes gcmole tools have been fetched by a hook
      # into v8/tools/gcmole/gcmole_tools.
      "gcmole-tools/",

      # We use the bundled sysroot with gcmole.
      sysroot,
    ]
  }

  # Only prepare gcmole args if gcmole is activated by a gn arg.
  action("v8_gcmole_args") {
    script = "gcmole_args.py"
    outputs = [ "$root_out_dir/v8_gcmole.args" ]
    args = [ sysroot ]

    # We use an arbitrary v8 target as proxy for calculating globally used
    # gcmole plugin arguments. Should be a target that's early in the chain
    # and that enables icu.
    deps = [ "../../:v8_base_without_compiler" ]
  }
}
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     node-23.7.0/deps/v8/tools/gcmole/Makefile                                                           0000664 0000000 0000000 00000004723 14746647661 0020121 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # Copyright 2011 the V8 project authors. All rights reserved.
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are
# met:
#
#     * Redistributions of source code must retain the above copyright
#       notice, this list of conditions and the following disclaimer.
#     * Redistributions in binary form must reproduce the above
#       copyright notice, this list of conditions and the following
#       disclaimer in the documentation and/or other materials provided
#       with the distribution.
#     * Neither the name of Google Inc. nor the names of its
#       contributors may be used to endorse or promote products derived
#       from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

# This is Makefile for clang plugin part of gcmole tool. See README.

LLVM_SRC_INCLUDE:=$(LLVM_SRC_ROOT)/include
LLVM_BUILD_INCLUDE:=$(BUILD_ROOT)/include
CLANG_SRC_INCLUDE:=$(CLANG_SRC_ROOT)/include
CLANG_BUILD_INCLUDE:=$(BUILD_ROOT)/tools/clang/include

CXXFLAGS = -O3 -g3
all: libgcmole.so
Release: libgcmole.so

Debug: CXXFLAGS = -O1 -DDEBUG -g
Debug: libgcmole.so

libgcmole.so: gcmole.cc
	$(CXX) -I$(LLVM_BUILD_INCLUDE) -I$(LLVM_SRC_INCLUDE)                  \
	-I$(CLANG_BUILD_INCLUDE) -I$(CLANG_SRC_INCLUDE) -I. ${CXXFLAGS}          \
	-D_GNU_SOURCE -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS         \
	-D__STDC_LIMIT_MACROS -fomit-frame-pointer -fno-exceptions        \
	-fno-rtti -fPIC -Woverloaded-virtual -Wcast-qual -fno-strict-aliasing \
	-pedantic -Wno-long-long -Wall -W -Wno-unused-parameter               \
	-Wwrite-strings -static-libstdc++ -std=c++17 -shared -o libgcmole.so  \
	gcmole.cc

clean:
	$(RM) libgcmole.so
                                             node-23.7.0/deps/v8/tools/gcmole/OWNERS                                                             0000664 0000000 0000000 00000000102 14746647661 0017404 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        clemensb@chromium.org
leszeks@chromium.org
machenbach@chromium.org                                                                                                                                                                                                                                                                                                                                                                                                                                                              node-23.7.0/deps/v8/tools/gcmole/PRESUBMIT.py                                                       0000664 0000000 0000000 00000001500 14746647661 0020373 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # Copyright 2022 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

USE_PYTHON3 = True


def _RunTests(input_api, output_api):
  return input_api.RunTests(
      input_api.canned_checks.GetUnitTestsInDirectory(
          input_api,
          output_api,
          '.',
          files_to_check=[r'.+_test\.py$'],
          run_on_python2=False))


def _CommonChecks(input_api, output_api):
  """Checks common to both upload and commit."""
  checks = [
      _RunTests,
  ]

  return sum([check(input_api, output_api) for check in checks], [])


def CheckChangeOnCommit(input_api, output_api):
  return _CommonChecks(input_api, output_api)


def CheckChangeOnUpload(input_api, output_api):
  return _CommonChecks(input_api, output_api)
                                                                                                                                                                                                node-23.7.0/deps/v8/tools/gcmole/README                                                             0000664 0000000 0000000 00000012360 14746647661 0017335 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        DESCRIPTION -------------------------------------------------------------------

gcmole is a simple static analysis tool used to find possible evaluation order
dependent GC-unsafe places in the V8 codebase and "stale" pointers to the heap
(ones whose addresses got invalidated by the GC).

For example the following code is GC-unsafe:

    Handle<Object> Foo();  // Assume Foo can trigger a GC.
    void Bar(Object, Object);

    Handle<Object> baz;
    baz->Qux(*Foo());  // (a)
    Bar(*Foo(), *baz); // (b)

Both in cases (a) and (b) compiler is free to evaluate call arguments (that
includes receiver) in any order. That means it can dereference baz before
calling to Foo and save a raw pointer to a heap object in the register or
on the stack.

In terms of the AST analysis that gcmole does, it warns about places in the
code which result in 2 subtrees, the order of execution of which is undefined
by C++, one of which causes a GC and the other dereferences a Handle to a raw
Object (or its subclasses).

The following code triggers a stale variable warning (assuming that the Foo
function was detected as potentially allocating, as in the previous example):

    JSObject raw_obj = ...;
    Foo();
    Print(raw_obj);

Since Foo can trigger a GC, it might have moved the raw_obj. The solution is
simply to store it as a Handle.

PREREQUISITES -----------------------------------------------------------------

(1) Install Python

    $ sudo apt-get install python

(2) Get LLVM 8.0 and Clang 8.0 sources and build them.

    Follow the instructions on http://clang.llvm.org/get_started.html.

    Make sure to pass -DCMAKE_BUILD_TYPE=Release to cmake to get Release build
    instead of a Debug one.

(3) Build gcmole Clang plugin (libgcmole.so)

    In the tools/gcmole directory execute the following command:

    $ BUILD_ROOT=<path> LLVM_SRC_ROOT=<path> CLANG_SRC_ROOT=<path> make

(*) Note that steps (2) and (3) can also be achieved by just using the included
    bootstrapping script in this directory:

    $ ./tools/gcmole/bootstrap.sh

    This will use "third_party/llvm+clang-build" as a build directory and checkout
    required sources in the "third_party" directory.

USING GCMOLE ------------------------------------------------------------------

gcmole consists of driver script written in Python and Clang plugin that does
C++ AST processing. Plugin (libgcmole.so) is expected to be in the same
folder as driver (gcmole.py).

To start analysis cd into the root of v8 checkout and execute the following
command:

CLANG_BIN=<path-to-clang-bin-folder> python tools/gcmole/gcmole.py [<arch>]

where arch should be one of architectures supported by V8 (arm, ia32, x64).

Analysis will be performed in 2 stages:

- on the first stage driver will parse all files and build a global callgraph
approximation to find all functions that might potentially cause GC, list
of this functions will be written into gcsuspects file.

- on the second stage driver will parse all files again and will locate all
callsites that might be GC-unsafe based on the list of functions causing GC.
Such places are marked with a "Possible problem with evaluation order."
warning. Messages "Failed to resolve v8::internal::Object" are benign and
can be ignored.

If any errors were found driver exits with non-zero status.

TESTING -----------------------------------------------------------------------

Tests are automatically run by the main python runner. Expectations are in
test-expectations.txt and need to be updated whenever the sources of the tests
in gcmole-test.cc are modified (line numbers also count).

PACKAGING ---------------------------------------------------------------------

gcmole is deployed on V8's buildbot infrastructure to run it as part of the
continuous integration. A pre-built package of gcmole together with Clang is
hosted on Google Cloud Storage for this purpose. To update this package to a
newer version, use the provided packaging script:

    $ ./tools/gcmole/package.sh

This will create a new "tools/gcmole/gcmole-tools.tar.gz" package with the
corresponding SHA1 sum suitable to be used for this purpose. It assumes that
Clang was built in "third_party/llvm+clang-build" (e.g. by the bootstrapping
script "bootstrap.sh" mentioned above).

TROUBLESHOOTING ---------------------------------------------------------------

gcmole is tightly coupled with the AST structure that Clang produces. Therefore
when upgrading to a newer Clang version, it might start producing bogus output
or completely stop outputting warnings. In such occasion, one might start the
debugging process by checking weather a new AST node type is introduced which
is currently not supported by gcmole. Insert the following code at the end of
the FunctionAnalyzer::VisitExpr method to see the unsupported AST class(es)
and the source position which generates them:

    if (expr) {
      clang::Stmt::StmtClass stmtClass = expr->getStmtClass();
      d_.Report(clang::FullSourceLoc(expr->getExprLoc(), sm_),
        d_.getCustomDiagID(clang::DiagnosticsEngine::Remark, "%0")) << stmtClass;
    }

For instance, gcmole currently doesn't support AtomicExprClass statements
introduced for atomic operations.

A convenient way to observe the AST generated by Clang is to pass the following
flags when invoking clang++

    -Xclang -ast-dump -fsyntax-only
                                                                                                                                                                                                                                                                                node-23.7.0/deps/v8/tools/gcmole/bootstrap.sh                                                       0000775 0000000 0000000 00000011676 14746647661 0021042 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env bash

# Copyright 2013 the V8 project authors. All rights reserved.
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are
# met:
#
#     * Redistributions of source code must retain the above copyright
#       notice, this list of conditions and the following disclaimer.
#     * Redistributions in binary form must reproduce the above
#       copyright notice, this list of conditions and the following
#       disclaimer in the documentation and/or other materials provided
#       with the distribution.
#     * Neither the name of Google Inc. nor the names of its
#       contributors may be used to endorse or promote products derived
#       from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

# This script will build libgcmole.so as well as a corresponding recent
# version of Clang and LLVM. The Clang will be built with the locally
# installed compiler and statically link against the local libstdc++ so
# that the resulting binary is easier transferable between different
# environments.

LLVM_RELEASE=16.0.2

BUILD_TYPE="Release"
# BUILD_TYPE="Debug"
THIS_DIR="$(readlink -f "$(dirname "${0}")")"
LLVM_PROJECT_DIR="${THIS_DIR}/bootstrap/llvm"
BUILD_DIR="${THIS_DIR}/bootstrap/build"

# Die if any command dies.
set -e

OS="$(uname -s)"

# Xcode and clang don't get along when predictive compilation is enabled.
# http://crbug.com/96315
if [[ "${OS}" = "Darwin" ]] && xcodebuild -version | grep -q 'Xcode 3.2' ; then
  XCONF=com.apple.Xcode
  if [[ "${GYP_GENERATORS}" != "make" ]] && \
     [ "$(defaults read "${XCONF}" EnablePredictiveCompilation)" != "0" ]; then
    echo
    echo "          HEARKEN!"
    echo "You're using Xcode3 and you have 'Predictive Compilation' enabled."
    echo "This does not work well with clang (http://crbug.com/96315)."
    echo "Disable it in Preferences->Building (lower right), or run"
    echo "    defaults write ${XCONF} EnablePredictiveCompilation -boolean NO"
    echo "while Xcode is not running."
    echo
  fi

  SUB_VERSION=$(xcodebuild -version | sed -Ene 's/Xcode 3\.2\.([0-9]+)/\1/p')
  if [[ "${SUB_VERSION}" < 6 ]]; then
    echo
    echo "          YOUR LD IS BUGGY!"
    echo "Please upgrade Xcode to at least 3.2.6."
    echo
  fi
fi

echo Getting LLVM release "${LLVM_RELEASE}" in "${LLVM_PROJECT_DIR}"
if ! [ -d "${LLVM_PROJECT_DIR}" ] || ! git -C "${LLVM_PROJECT_DIR}" remote get-url origin | grep -q -F "https://github.com/llvm/llvm-project.git" ; then
  rm -rf "${LLVM_PROJECT_DIR}"
  git clone --depth=1 --branch "llvmorg-${LLVM_RELEASE}" "https://github.com/llvm/llvm-project.git" "${LLVM_PROJECT_DIR}"
else
  git -C "${LLVM_PROJECT_DIR}" fetch --depth=1 origin "llvmorg-${LLVM_RELEASE}"
  git -C "${LLVM_PROJECT_DIR}" checkout FETCH_HEAD
fi

# Echo all commands
set -x

NUM_JOBS=3
if [[ "${OS}" = "Linux" ]]; then
  if [[ -e "/proc/cpuinfo" ]]; then
    NUM_JOBS="$(grep -c "^processor" /proc/cpuinfo)"
  else
    # Hack when running in chroot
    NUM_JOBS="32"
  fi
elif [ "${OS}" = "Darwin" ]; then
  NUM_JOBS="$(sysctl -n hw.ncpu)"
fi

# Build clang.
if [ ! -e "${BUILD_DIR}" ]; then
  mkdir "${BUILD_DIR}"
fi
cd "${BUILD_DIR}"
cmake -GNinja -DCMAKE_CXX_FLAGS="-static-libstdc++" -DLLVM_ENABLE_TERMINFO=OFF \
    -DCMAKE_BUILD_TYPE=$BUILD_TYPE -DLLVM_ENABLE_PROJECTS=clang \
    -DLLVM_ENABLE_Z3_SOLVER=OFF "${LLVM_PROJECT_DIR}/llvm"
MACOSX_DEPLOYMENT_TARGET=10.5 ninja -j"${NUM_JOBS}" clang

if [[ "${BUILD_TYPE}" = "Release" ]]; then
  # Strip the clang binary.
  STRIP_FLAGS=
  if [ "${OS}" = "Darwin" ]; then
    # See http://crbug.com/256342
    STRIP_FLAGS=-x
  fi
  strip ${STRIP_FLAGS} bin/clang
fi
cd -

# Build libgcmole.so
make -C "${THIS_DIR}" clean
make -C "${THIS_DIR}" LLVM_SRC_ROOT="${LLVM_PROJECT_DIR}/llvm" \
    CLANG_SRC_ROOT="${LLVM_PROJECT_DIR}/clang" \
    BUILD_ROOT="${BUILD_DIR}" $BUILD_TYPE

set +x

echo '#########################################################################'
echo 'Congratulations you compiled clang and libgcmole.so'
echo
echo '# You can now run gcmole:'
echo 'tools/gcmole/gcmole.py \'
echo '   --clang-bin-dir="tools/gcmole/bootstrap/build/bin" \'
echo '   --clang-plugins-dir="tools/gcmole" \'
echo '   --v8-target-cpu=$CPU'
echo
                                                                  node-23.7.0/deps/v8/tools/gcmole/gcmole-test.cc                                                     0000664 0000000 0000000 00000025753 14746647661 0021221 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2019 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

#include "src/execution/isolate.h"
#include "src/handles/handles-inl.h"
#include "src/handles/handles.h"
#include "src/heap/local-heap.h"
#include "src/objects/foreign-inl.h"
#include "src/objects/managed.h"
#include "src/objects/maybe-object.h"
#include "src/objects/object-macros.h"

namespace v8 {
namespace internal {

// ------- Test simple argument evaluation order problems ---------

void Safepoint() { LocalHeap::Current()->Safepoint(); }

Handle<Object> CauseGC(Handle<Object> obj, Isolate* isolate) {
  isolate->heap()->CollectGarbage(OLD_SPACE, GarbageCollectionReason::kTesting);

  return obj;
}

Tagged<Object> CauseGCRaw(Tagged<Object> obj, Isolate* isolate) {
  isolate->heap()->CollectGarbage(OLD_SPACE, GarbageCollectionReason::kTesting);

  return obj;
}

Tagged<Managed<int>> CauseGCManaged(int i, Isolate* isolate) {
  isolate->heap()->CollectGarbage(OLD_SPACE, GarbageCollectionReason::kTesting);

  return Cast<Managed<int>>(Smi::FromInt(i));
}

void TwoArgumentsFunction(Tagged<Object> a, Tagged<Object> b) {
  Print(a);
  Print(b);
}

void TestTwoArguments(Isolate* isolate) {
  Handle<JSObject> obj1 = isolate->factory()->NewJSObjectWithNullProto();
  Handle<JSObject> obj2 = isolate->factory()->NewJSObjectWithNullProto();
  // Should cause warning.
  TwoArgumentsFunction(*CauseGC(obj1, isolate), *CauseGC(obj2, isolate));
}

void TwoSizeTArgumentsFunction(size_t a, size_t b) {
  USE(a);
  USE(b);
}

void TestTwoSizeTArguments(Isolate* isolate) {
  Handle<JSObject> obj1 = isolate->factory()->NewJSObjectWithNullProto();
  Handle<JSObject> obj2 = isolate->factory()->NewJSObjectWithNullProto();
  // Should cause warning.
  TwoSizeTArgumentsFunction(sizeof(*CauseGC(obj1, isolate)),
                            sizeof(*CauseGC(obj2, isolate)));
}

// --------- Test problFems with method arguments ----------

class SomeObject : public HeapObject {
 public:
  void Method(Tagged<Object> a) { Print(a); }

  OBJECT_CONSTRUCTORS(SomeObject, HeapObject);
};

void TestMethodCall(Isolate* isolate) {
  Tagged<SomeObject> obj;
  Handle<SomeObject> so = handle(obj, isolate);
  Handle<JSObject> obj1 = isolate->factory()->NewJSObjectWithNullProto();
  // Should cause warning.
  so->Method(*CauseGC(obj1, isolate));
  // Should cause warning.
  so->Method(CauseGCRaw(*obj1, isolate));
}

void TestOperatorCall(Isolate* isolate) {
  Tagged<SomeObject> obj;
  Handle<JSObject> obj1 = isolate->factory()->NewJSObjectWithNullProto();
  // Should not cause warning.
  obj = UncheckedCast<SomeObject>(*CauseGC(obj1, isolate));
}

// --------- Test for templated sub-classes of Object ----------

void TestFollowingTemplates(Isolate* isolate) {
  // Should cause warning.
  CauseGCManaged(42, isolate);
}

// --------- Test for correctly resolving virtual methods ----------

class BaseObject {
 public:
  virtual Handle<Object> VirtualCauseGC(Handle<Object> obj, Isolate* isolate) {
    return obj;
  }
};

class DerivedObject : public BaseObject {
 public:
  Handle<Object> VirtualCauseGC(Handle<Object> obj, Isolate* isolate) override {
    isolate->heap()->CollectGarbage(OLD_SPACE,
                                    GarbageCollectionReason::kTesting);

    return obj;
  }
};

void TestFollowingVirtualFunctions(Isolate* isolate) {
  DerivedObject derived;
  BaseObject* base = &derived;
  Handle<JSObject> obj1 = isolate->factory()->NewJSObjectWithNullProto();

  Tagged<SomeObject> so;
  Handle<SomeObject> so_handle = handle(so, isolate);
  // Should cause warning.
  so_handle->Method(*derived.VirtualCauseGC(obj1, isolate));
  // Should cause warning.
  so_handle->Method(*base->VirtualCauseGC(obj1, isolate));
}

// --------- Test for correctly resolving static methods ----------

class SomeClass {
 public:
  static Handle<Object> StaticCauseGC(Handle<Object> obj, Isolate* isolate) {
    isolate->heap()->CollectGarbage(OLD_SPACE,
                                    GarbageCollectionReason::kTesting);

    return obj;
  }
};

void TestFollowingStaticFunctions(Isolate* isolate) {
  Tagged<SomeObject> so;
  Handle<SomeObject> so_handle = handle(so, isolate);

  Handle<JSObject> obj1 = isolate->factory()->NewJSObjectWithNullProto();
  // Should cause warning.
  so_handle->Method(*SomeClass::StaticCauseGC(obj1, isolate));
}

// --------- Test basic dead variable analysis ----------

void TestDeadVarAnalysis(Isolate* isolate) {
  Tagged<JSObject> raw_obj = *isolate->factory()->NewJSObjectWithNullProto();
  CauseGCRaw(raw_obj, isolate);

  // Should cause warning.
  Print(raw_obj);
}

void TestDeadVarBecauseOfSafepointAnalysis(Isolate* isolate) {
  Tagged<JSObject> raw_obj = *isolate->factory()->NewJSObjectWithNullProto();
  Safepoint();

  // Should cause warning.
  Print(raw_obj);
}

void TestGuardedDeadVarAnalysis(Isolate* isolate) {
  Tagged<JSObject> raw_obj = *isolate->factory()->NewJSObjectWithNullProto();

  // Note: having DisableGCMole with the same function as CauseGC
  // normally doesn't make sense, but we want to test whether the guards
  // are recognized by GCMole.
  DisableGCMole no_gc_mole;
  CauseGCRaw(raw_obj, isolate);

  // Shouldn't cause warning.
  Print(raw_obj);
}

void TestGuardedDeadVarAnalysis2(Isolate* isolate) {
  Tagged<JSObject> raw_obj = *isolate->factory()->NewJSObjectWithNullProto();

  // Note: having DisallowGarbageCollection with the same function as CauseGC
  // normally doesn't make sense, but we want to test whether the guards
  // are recognized by GCMole.
  DisallowGarbageCollection no_gc;
  CauseGCRaw(raw_obj, isolate);

  // Should cause warning.
  Print(raw_obj);
}

void TestGuardedAgainstSafepointDeadVarAnalysis(Isolate* isolate) {
  Tagged<JSObject> raw_obj = *isolate->factory()->NewJSObjectWithNullProto();

  // Note: having DisableGCMole with the same function as CauseGC
  // normally doesn't make sense, but we want to test whether the guards
  // are recognized by GCMole.
  DisableGCMole no_gc_mole;
  Safepoint();

  // Shouldn't cause warning.
  Print(raw_obj);
}

void TestGuardedAgainstSafepointDeadVarAnalysis2(Isolate* isolate) {
  Tagged<JSObject> raw_obj = *isolate->factory()->NewJSObjectWithNullProto();

  // Note: having DisallowGarbageCollection with the same function as CauseGC
  // normally doesn't make sense, but we want to test whether the guards
  // are recognized by GCMole.
  DisallowGarbageCollection no_gc;
  Safepoint();

  // Should cause warning.
  Print(raw_obj);
}

void TestGuardedAgainstSafepointDeadVarAnalysis3(Isolate* isolate) {
  Tagged<JSObject> raw_obj = *isolate->factory()->NewJSObjectWithNullProto();
  // Note: having DisallowGarbageCollection with the same function as CauseGC
  // normally doesn't make sense, but we want to test whether the guards
  // are recognized by GCMole.
  DisallowGarbageCollection no_gc;
  Safepoint();
  // Should cause warning.
  Print(raw_obj);
  {
    DisableGCMole no_gc_mole;
    // Shouldn't cause warning.
    Print(raw_obj);
  }
  // Should cause warning.
  Print(raw_obj);
}

void TestOnlyHeapGuardedDeadVarAnalysisInCompound(Isolate* isolate) {
  Tagged<JSObject> raw_obj = *isolate->factory()->NewJSObjectWithNullProto();
  // {DisallowHeapAccess} has a {DisallowHeapAllocation}, but no
  // {DisallowSafepoints}, so it could see objects move due to safepoints.
  DisallowHeapAccess no_gc;
  CauseGCRaw(raw_obj, isolate);
  // Should cause warning.
  Print(raw_obj);
}

void TestOnlyHeapGuardedDeadVarAnalysisInCompound2(Isolate* isolate) {
  Tagged<JSObject> raw_obj = *isolate->factory()->NewJSObjectWithNullProto();
  // {DisallowHeapAccess} has a {DisallowHeapAllocation}, but no
  // {DisallowSafepoints}, so it could see objects move due to safepoints.
  DisallowHeapAccess no_gc;
  CauseGCRaw(raw_obj, isolate);
  // Should cause warning.
  Print(raw_obj);
  DisableGCMole no_gc_mole;
  // Should cause warning.
  Print(raw_obj);
}

void TestGuardedDeadVarAnalysisNested(Tagged<JSObject> raw_obj,
                                      Isolate* isolate) {
  CauseGCRaw(raw_obj, isolate);
  // Should cause warning.
  Print(raw_obj);
}

void TestGuardedDeadVarAnalysisCaller(Isolate* isolate) {
  DisableGCMole no_gc_mole;
  Tagged<JSObject> raw_obj = *isolate->factory()->NewJSObjectWithNullProto();
  TestGuardedDeadVarAnalysisNested(raw_obj, isolate);
  // Shouldn't cause warning.
  Print(raw_obj);
}

void TestGuardedDeadVarAnalysisCaller2(Isolate* isolate) {
  DisallowGarbageCollection no_gc;
  Tagged<JSObject> raw_obj = *isolate->factory()->NewJSObjectWithNullProto();
  TestGuardedDeadVarAnalysisNested(raw_obj, isolate);
  // Should cause warning.
  Print(raw_obj);
}

void TestGuardedDeadVarAnalysisCaller3(Isolate* isolate) {
  DisallowHeapAccess no_gc;
  Tagged<JSObject> raw_obj = *isolate->factory()->NewJSObjectWithNullProto();
  TestGuardedDeadVarAnalysisNested(raw_obj, isolate);
  // Should cause warning.
  Print(raw_obj);
}

void TestGuardedDeadVarAnalysisCaller4(Isolate* isolate) {
  Tagged<JSObject> raw_obj = *isolate->factory()->NewJSObjectWithNullProto();
  TestGuardedDeadVarAnalysisNested(raw_obj, isolate);
  // Should cause warning.
  Print(raw_obj);
}

Tagged<JSObject> GuardedAllocation(Isolate* isolate) {
  DisallowGarbageCollection no_gc;
  return *isolate->factory()->NewJSObjectWithNullProto();
}

Tagged<JSObject> GuardedAllocation2(Isolate* isolate) {
  DisableGCMole no_gc_mole;
  return *isolate->factory()->NewJSObjectWithNullProto();
}

void TestNestedDeadVarAnalysis(Isolate* isolate) {
  Tagged<JSObject> raw_obj = GuardedAllocation(isolate);
  CauseGCRaw(raw_obj, isolate);
  // Should cause warning.
  Print(raw_obj);
}

void TestNestedDeadVarAnalysis2(Isolate* isolate) {
  DisableGCMole no_gc_mole;
  Tagged<JSObject> raw_obj = GuardedAllocation(isolate);
  CauseGCRaw(raw_obj, isolate);
  // Shouldn't cause warning.
  Print(raw_obj);
}

// Test that putting a guard in the middle of the function doesn't
// mistakenly cover the whole scope of the raw variable.
void TestGuardedDeadVarAnalysisMidFunction(Isolate* isolate) {
  Tagged<JSObject> raw_obj = *isolate->factory()->NewJSObjectWithNullProto();
  CauseGCRaw(raw_obj, isolate);
  // Guarding the rest of the function from triggering a GC.
  DisallowGarbageCollection no_gc;
  // Should cause warning.
  Print(raw_obj);
}

// Test that putting a guard in the middle of the function doesn't
// mistakenly cover the whole scope of the raw variable.
void TestGuardedDeadVarAnalysisMidFunction2(Isolate* isolate) {
  Tagged<JSObject> raw_obj = *isolate->factory()->NewJSObjectWithNullProto();
  CauseGCRaw(raw_obj, isolate);
  // Guarding the rest of the function from triggering a GC.
  DisableGCMole no_gc_mole;
  // Should cause warning.
  Print(raw_obj);
}

void TestGuardedDeadVarAnalysisMultipleSafepoints(Isolate* isolate) {
  // TODO(https://crbug.com/v8/13536): The analysis points to this safepoint,
  // while it should point to the one below.
  Safepoint();
  Tagged<JSObject> raw_obj = *isolate->factory()->NewJSObjectWithNullProto();
  DisallowGarbageCollection no_gc;
  Safepoint();
  Print(raw_obj);
}

}  // namespace internal
}  // namespace v8
                     node-23.7.0/deps/v8/tools/gcmole/gcmole-tools.tar.gz.sha1                                           0000664 0000000 0000000 00000000050 14746647661 0023034 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        0be05484ed9eabf19204bea0d4ceda1598b914e4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        node-23.7.0/deps/v8/tools/gcmole/gcmole.cc                                                          0000664 0000000 0000000 00000150063 14746647661 0020235 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2011 the V8 project authors. All rights reserved.
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met:
//
//     * Redistributions of source code must retain the above copyright
//       notice, this list of conditions and the following disclaimer.
//     * Redistributions in binary form must reproduce the above
//       copyright notice, this list of conditions and the following
//       disclaimer in the documentation and/or other materials provided
//       with the distribution.
//     * Neither the name of Google Inc. nor the names of its
//       contributors may be used to endorse or promote products derived
//       from this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

// This is clang plugin used by gcmole tool. See README for more details.

#include <bitset>
#include <fstream>
#include <iostream>
#include <map>
#include <set>
#include <stack>

#include "clang/AST/APValue.h"
#include "clang/AST/AST.h"
#include "clang/AST/ASTConsumer.h"
#include "clang/AST/DeclCXX.h"
#include "clang/AST/DeclTemplate.h"
#include "clang/AST/Mangle.h"
#include "clang/AST/RecursiveASTVisitor.h"
#include "clang/AST/StmtVisitor.h"
#include "clang/AST/TemplateBase.h"
#include "clang/Basic/FileManager.h"
#include "clang/Frontend/CompilerInstance.h"
#include "clang/Frontend/FrontendPluginRegistry.h"
#include "llvm/Support/Casting.h"
#include "llvm/Support/raw_ostream.h"

namespace {

bool g_tracing_enabled = false;
bool g_dead_vars_analysis = false;
bool g_verbose = false;
bool g_print_gc_call_chain = false;

#define TRACE(str)                   \
  do {                               \
    if (g_tracing_enabled) {         \
      std::cout << str << std::endl; \
    }                                \
  } while (false)

#define TRACE_LLVM_TYPE(str, type)                                \
  do {                                                            \
    if (g_tracing_enabled) {                                      \
      std::cout << str << " " << type.getAsString() << std::endl; \
    }                                                             \
  } while (false)

// Node: The following is used when tracing --dead-vars
// to provide extra info for the GC suspect.
#define TRACE_LLVM_DECL(str, decl)                   \
  do {                                               \
    if (g_tracing_enabled && g_dead_vars_analysis) { \
      std::cout << str << std::endl;                 \
      decl->dump();                                  \
    }                                                \
  } while (false)

typedef std::string MangledName;
typedef std::set<MangledName> CalleesSet;
typedef std::map<MangledName, MangledName> CalleesMap;

static bool GetMangledName(clang::MangleContext* ctx,
                           const clang::NamedDecl* decl, MangledName* result) {
  if (llvm::isa<clang::CXXConstructorDecl>(decl)) return false;
  if (llvm::isa<clang::CXXDestructorDecl>(decl)) return false;
  if (llvm::isa<clang::CXXDeductionGuideDecl>(decl)) return false;
  llvm::SmallVector<char, 512> output;
  llvm::raw_svector_ostream out(output);
  ctx->mangleName(decl, out);
  *result = out.str().str();
  return true;
}

static bool InV8Namespace(const clang::NamedDecl* decl) {
  return decl->getQualifiedNameAsString().compare(0, 4, "v8::") == 0;
}

static std::string EXTERNAL("EXTERNAL");
static std::string STATE_TAG("enum v8::internal::StateTag");

static bool IsExternalVMState(const clang::ValueDecl* var) {
  const clang::EnumConstantDecl* enum_constant =
      llvm::dyn_cast<clang::EnumConstantDecl>(var);
  if (enum_constant != nullptr &&
      enum_constant->getNameAsString() == EXTERNAL) {
    clang::QualType type = enum_constant->getType();
    return (type.getAsString() == STATE_TAG);
  }

  return false;
}

struct Resolver {
  explicit Resolver(clang::ASTContext& ctx)
      : ctx_(ctx), decl_ctx_(ctx.getTranslationUnitDecl()) {}

  Resolver(clang::ASTContext& ctx, clang::DeclContext* decl_ctx)
      : ctx_(ctx), decl_ctx_(decl_ctx) {}

  clang::DeclarationName ResolveName(const char* n) {
    clang::IdentifierInfo* ident = &ctx_.Idents.get(n);
    return ctx_.DeclarationNames.getIdentifier(ident);
  }

  Resolver ResolveNamespace(const char* n) {
    return Resolver(ctx_, Resolve<clang::NamespaceDecl>(n));
  }

  template <typename T>
  T* Resolve(const char* n) {
    if (decl_ctx_ == nullptr) return nullptr;

    clang::DeclContext::lookup_result result =
        decl_ctx_->lookup(ResolveName(n));

    clang::DeclContext::lookup_iterator end = result.end();
    for (clang::DeclContext::lookup_iterator i = result.begin(); i != end;
         i++) {
      clang::NamedDecl* decl = *i;

      // Try to strip off any type aliases.
      const clang::TypeAliasDecl* type_alias_decl =
          llvm::dyn_cast_or_null<clang::TypeAliasDecl>(decl);
      if (type_alias_decl) {
        clang::QualType underlying_type = type_alias_decl->getUnderlyingType();
        clang::QualType desugared_type = underlying_type.getDesugaredType(ctx_);
        clang::TagDecl* tag_decl = desugared_type->getAsTagDecl();
        if (!tag_decl) {
          llvm::errs() << "Couldn't resolve target decl of type alias "
                       << decl->getNameAsString() << "\n";
          decl->dump();
          return nullptr;
        }
        decl = tag_decl;
      }

      if (llvm::isa<T>(decl)) {
        return Cast<llvm><T>(decl);
      }

      llvm::errs() << "Didn't match declaration template for " << n
                   << " against " << decl->getNameAsString() << "\n";
      decl->dump();
    }

    return nullptr;
  }

 private:
  clang::ASTContext& ctx_;
  clang::DeclContext* decl_ctx_;
};

class CalleesPrinter : public clang::RecursiveASTVisitor<CalleesPrinter> {
 public:
  explicit CalleesPrinter(clang::MangleContext* ctx) : ctx_(ctx) {}

  virtual bool VisitCallExpr(clang::CallExpr* expr) {
    const clang::FunctionDecl* callee = expr->getDirectCallee();
    if (callee != nullptr) AnalyzeFunction(callee);
    return true;
  }

  virtual bool VisitDeclRefExpr(clang::DeclRefExpr* expr) {
    // If function mentions EXTERNAL VMState add artificial garbage collection
    // mark.
    if (IsExternalVMState(expr->getDecl())) {
      AddCallee("CollectGarbage", "CollectGarbage");
    }
    return true;
  }

  void AnalyzeFunction(const clang::FunctionDecl* f) {
    if (!InV8Namespace(f)) return;
    MangledName name;
    if (!GetMangledName(ctx_, f, &name)) return;
    const std::string& function = f->getNameAsString();
    AddCallee(name, function);

    const clang::FunctionDecl* body = nullptr;
    if (f->hasBody(body) && !Analyzed(name)) {
      EnterScope(name);
      TraverseStmt(body->getBody());
      LeaveScope();
    }
  }

  typedef std::map<MangledName, CalleesSet*> Callgraph;

  bool Analyzed(const MangledName& name) { return callgraph_[name] != nullptr; }

  void EnterScope(const MangledName& name) {
    CalleesSet* callees = callgraph_[name];

    if (callees == nullptr) {
      callgraph_[name] = callees = new CalleesSet();
    }

    scopes_.push(callees);
  }

  void LeaveScope() { scopes_.pop(); }

  void AddCallee(const MangledName& name, const MangledName& function) {
    if (!scopes_.empty()) scopes_.top()->insert(name);
    mangled_to_function_[name] = function;
  }

  void PrintCallGraph() {
    for (Callgraph::const_iterator i = callgraph_.begin(), e = callgraph_.end();
         i != e; ++i) {
      std::cout << i->first << "," << mangled_to_function_[i->first] << "\n";

      CalleesSet* callees = i->second;
      for (CalleesSet::const_iterator j = callees->begin(), e = callees->end();
           j != e; ++j) {
        std::cout << "\t" << *j << "," << mangled_to_function_[*j] << "\n";
      }
    }
  }

 private:
  clang::MangleContext* ctx_;

  std::stack<CalleesSet*> scopes_;
  Callgraph callgraph_;
  CalleesMap mangled_to_function_;
};

class FunctionDeclarationFinder
    : public clang::ASTConsumer,
      public clang::RecursiveASTVisitor<FunctionDeclarationFinder> {
 public:
  explicit FunctionDeclarationFinder(
      clang::DiagnosticsEngine& diagnostics_engine,
      clang::SourceManager& source_manager,
      const std::vector<std::string>& args)
      : diagnostics_engine_(diagnostics_engine),
        source_manager_(source_manager) {}

  void HandleTranslationUnit(clang::ASTContext& ctx) override {
    mangle_context_ =
        clang::ItaniumMangleContext::create(ctx, diagnostics_engine_);
    callees_printer_ = new CalleesPrinter(mangle_context_);
    TraverseDecl(ctx.getTranslationUnitDecl());
    callees_printer_->PrintCallGraph();
  }

  virtual bool VisitFunctionDecl(clang::FunctionDecl* decl) {
    callees_printer_->AnalyzeFunction(decl);
    return true;
  }

 private:
  clang::DiagnosticsEngine& diagnostics_engine_;
  clang::SourceManager& source_manager_;
  clang::MangleContext* mangle_context_;

  CalleesPrinter* callees_printer_;
};

static bool gc_suspects_loaded = false;
static CalleesSet gc_suspects;
static CalleesSet gc_functions;

static bool allowlist_loaded = false;
static CalleesSet suspects_allowlist;

static bool gc_causes_loaded = false;
static std::map<MangledName, std::vector<MangledName>> gc_causes;

static void LoadGCCauses() {
  if (gc_causes_loaded) return;
  std::ifstream fin("gccauses");
  std::string mangled, function;
  while (!fin.eof()) {
    std::getline(fin, mangled, ',');
    std::getline(fin, function);
    if (mangled.empty()) break;
    std::string parent = mangled;
    // start,nested
    std::getline(fin, mangled, ',');
    assert(mangled.compare("start") == 0);
    std::getline(fin, function);
    assert(function.compare("nested") == 0);
    while (true) {
      std::getline(fin, mangled, ',');
      std::getline(fin, function);
      if (mangled.compare("end") == 0) {
        assert(function.compare("nested") == 0);
        break;
      }
      gc_causes[parent].push_back(mangled);
    }
  }
  gc_causes_loaded = true;
}

static void LoadGCSuspects() {
  if (gc_suspects_loaded) return;

  std::ifstream fin("gcsuspects");
  std::string mangled, function;

  while (!fin.eof()) {
    std::getline(fin, mangled, ',');
    gc_suspects.insert(mangled);
    std::getline(fin, function);
    gc_functions.insert(function);
  }

  gc_suspects_loaded = true;
}

static void LoadSuspectsAllowList() {
  if (allowlist_loaded) return;

  // TODO(cbruni): clean up once fully migrated
  std::ifstream fin("tools/gcmole/suspects.allowlist");
  std::string s;

  while (fin >> s) suspects_allowlist.insert(s);

  allowlist_loaded = true;
}

// Looks for exact match of the mangled name.
static bool IsKnownToCauseGC(clang::MangleContext* ctx,
                             const clang::FunctionDecl* decl) {
  LoadGCSuspects();
  if (!InV8Namespace(decl)) return false;
  if (suspects_allowlist.find(decl->getNameAsString()) !=
      suspects_allowlist.end()) {
    return false;
  }
  MangledName name;
  if (GetMangledName(ctx, decl, &name)) {
    return gc_suspects.find(name) != gc_suspects.end();
  }
  return false;
}

// Looks for partial match of only the function name.
static bool IsSuspectedToCauseGC(clang::MangleContext* ctx,
                                 const clang::FunctionDecl* decl) {
  LoadGCSuspects();
  if (!InV8Namespace(decl)) return false;
  LoadSuspectsAllowList();
  if (suspects_allowlist.find(decl->getNameAsString()) !=
      suspects_allowlist.end()) {
    return false;
  }
  if (gc_functions.find(decl->getNameAsString()) != gc_functions.end()) {
    TRACE_LLVM_DECL("Suspected by ", decl);
    return true;
  }
  return false;
}

static const int kNoEffect = 0;
static const int kCausesGC = 1;
static const int kRawDef = 2;
static const int kRawUse = 4;
static const int kAllEffects = kCausesGC | kRawDef | kRawUse;

class Environment;

class ExprEffect {
 public:
  bool hasGC() { return (effect_ & kCausesGC) != 0; }
  void setGC() { effect_ |= kCausesGC; }

  bool hasRawDef() { return (effect_ & kRawDef) != 0; }
  void setRawDef() { effect_ |= kRawDef; }

  bool hasRawUse() { return (effect_ & kRawUse) != 0; }
  void setRawUse() { effect_ |= kRawUse; }

  static ExprEffect None() { return ExprEffect(kNoEffect, nullptr); }
  static ExprEffect NoneWithEnv(Environment* env) {
    return ExprEffect(kNoEffect, env);
  }
  static ExprEffect RawUse() { return ExprEffect(kRawUse, nullptr); }

  static ExprEffect Merge(ExprEffect a, ExprEffect b);
  static ExprEffect MergeSeq(ExprEffect a, ExprEffect b);
  ExprEffect Define(const std::string& name);

  Environment* env() {
    return reinterpret_cast<Environment*>(effect_ & ~kAllEffects);
  }

  static ExprEffect GC() { return ExprEffect(kCausesGC, nullptr); }

 private:
  ExprEffect(int effect, Environment* env)
      : effect_((effect & kAllEffects) | reinterpret_cast<intptr_t>(env)) {}

  intptr_t effect_;
};

const std::string BAD_EXPR_MSG(
    "Possible problem with evaluation order with interleaved GCs.");
const std::string DEAD_VAR_MSG("Possibly stale variable due to GCs.");

class Environment {
 public:
  Environment() = default;

  static Environment Unreachable() {
    Environment env;
    env.unreachable_ = true;
    return env;
  }

  static Environment Merge(const Environment& l, const Environment& r) {
    Environment out(l);
    out &= r;
    return out;
  }

  Environment ApplyEffect(ExprEffect effect) const {
    Environment out = effect.hasGC() ? Environment() : Environment(*this);
    if (effect.env()) out |= *effect.env();
    return out;
  }

  typedef std::map<std::string, int> SymbolTable;

  bool IsAlive(const std::string& name) const {
    SymbolTable::iterator code = symbol_table_.find(name);
    if (code == symbol_table_.end()) return false;
    return is_live(code->second);
  }

  bool Equal(const Environment& env) {
    if (unreachable_ && env.unreachable_) return true;
    size_t size = std::max(live_.size(), env.live_.size());
    for (size_t i = 0; i < size; ++i) {
      if (is_live(i) != env.is_live(i)) return false;
    }
    return true;
  }

  Environment Define(const std::string& name) const {
    return Environment(*this, SymbolToCode(name));
  }

  void MDefine(const std::string& name) { set_live(SymbolToCode(name)); }

  static int SymbolToCode(const std::string& name) {
    SymbolTable::iterator code = symbol_table_.find(name);

    if (code == symbol_table_.end()) {
      int new_code = symbol_table_.size();
      symbol_table_.insert(std::make_pair(name, new_code));
      return new_code;
    }

    return code->second;
  }

  static void ClearSymbolTable() {
    for (Environment* e : envs_) delete e;
    envs_.clear();
    symbol_table_.clear();
  }

  void Print() const {
    bool comma = false;
    std::cout << "{";
    for (auto& e : symbol_table_) {
      if (!is_live(e.second)) continue;
      if (comma) std::cout << ", ";
      std::cout << e.first;
      comma = true;
    }
    std::cout << "}" << std::endl;
  }

  static Environment* Allocate(const Environment& env) {
    Environment* allocated_env = new Environment(env);
    envs_.push_back(allocated_env);
    return allocated_env;
  }

 private:
  Environment(const Environment& l, int code) : live_(l.live_) {
    set_live(code);
  }

  void set_live(size_t pos) {
    if (unreachable_) return;
    if (pos >= live_.size()) live_.resize(pos + 1);
    live_[pos] = true;
  }

  bool is_live(size_t pos) const {
    return unreachable_ || (live_.size() > pos && live_[pos]);
  }

  Environment& operator|=(const Environment& o) {
    if (o.unreachable_) {
      unreachable_ = true;
      live_.clear();
    } else if (!unreachable_) {
      for (size_t i = 0, e = o.live_.size(); i < e; ++i) {
        if (o.live_[i]) set_live(i);
      }
    }
    return *this;
  }

  Environment& operator&=(const Environment& o) {
    if (o.unreachable_) return *this;
    if (unreachable_) return *this = o;

    // Carry over false bits from the tail of o.live_, and reset all bits that
    // are not set in o.live_.
    size_t size = std::max(live_.size(), o.live_.size());
    if (size > live_.size()) live_.resize(size);
    for (size_t i = 0; i < size; ++i) {
      if (live_[i] && (i >= o.live_.size() || !o.live_[i])) live_[i] = false;
    }
    return *this;
  }

  static SymbolTable symbol_table_;
  static std::vector<Environment*> envs_;

  std::vector<bool> live_;
  // unreachable_ == true implies live_.empty(), but still is_live(i) returns
  // true for all i.
  bool unreachable_ = false;

  friend class ExprEffect;
  friend class CallProps;
};

class CallProps {
 public:
  CallProps() : env_(nullptr) {}

  void SetEffect(int arg, ExprEffect in) {
    if (in.hasGC()) {
      gc_.set(arg);
    }
    if (in.hasRawDef()) raw_def_.set(arg);
    if (in.hasRawUse()) raw_use_.set(arg);
    if (in.env() != nullptr) {
      if (env_ == nullptr) {
        env_ = in.env();
      } else {
        *env_ |= *in.env();
      }
    }
  }

  ExprEffect ComputeCumulativeEffect(bool result_is_raw) {
    ExprEffect out = ExprEffect::NoneWithEnv(env_);
    if (gc_.any()) out.setGC();
    if (raw_use_.any()) out.setRawUse();
    if (result_is_raw) out.setRawDef();
    return out;
  }

  bool IsSafe() {
    if (!gc_.any()) return true;
    std::bitset<kMaxNumberOfArguments> raw = (raw_def_ | raw_use_);
    if (!raw.any()) return true;
    bool result = gc_.count() == 1 && !((raw ^ gc_).any());
    return result;
  }

 private:
  static const int kMaxNumberOfArguments = 64;
  std::bitset<kMaxNumberOfArguments> raw_def_;
  std::bitset<kMaxNumberOfArguments> raw_use_;
  std::bitset<kMaxNumberOfArguments> gc_;
  Environment* env_;
};

Environment::SymbolTable Environment::symbol_table_;
std::vector<Environment*> Environment::envs_;

ExprEffect ExprEffect::Merge(ExprEffect a, ExprEffect b) {
  Environment* a_env = a.env();
  Environment* b_env = b.env();
  Environment* out = nullptr;
  if (a_env != nullptr && b_env != nullptr) {
    out = Environment::Allocate(*a_env);
    *out &= *b_env;
  }
  return ExprEffect(a.effect_ | b.effect_, out);
}

ExprEffect ExprEffect::MergeSeq(ExprEffect a, ExprEffect b) {
  Environment* a_env = b.hasGC() ? nullptr : a.env();
  Environment* b_env = b.env();
  Environment* out = (b_env == nullptr) ? a_env : b_env;
  if (a_env != nullptr && b_env != nullptr) {
    out = Environment::Allocate(*b_env);
    *out |= *a_env;
  }
  return ExprEffect(a.effect_ | b.effect_, out);
}

ExprEffect ExprEffect::Define(const std::string& name) {
  Environment* e = env();
  if (e == nullptr) {
    e = Environment::Allocate(Environment());
  }
  e->MDefine(name);
  return ExprEffect(effect_, e);
}

static std::string THIS("this");

class FunctionAnalyzer {
 public:
  FunctionAnalyzer(clang::MangleContext* ctx,
                   clang::CXXRecordDecl* heap_object_decl,
                   clang::CXXRecordDecl* smi_decl,
                   clang::CXXRecordDecl* tagged_index_decl,
                   clang::ClassTemplateDecl* tagged_decl,
                   clang::CXXRecordDecl* no_gc_mole_decl,
                   clang::DiagnosticsEngine& d, clang::SourceManager& sm)
      : ctx_(ctx),
        heap_object_decl_(heap_object_decl),
        smi_decl_(smi_decl),
        tagged_index_decl_(tagged_index_decl),
        tagged_decl_(tagged_decl),
        no_gc_mole_decl_(no_gc_mole_decl),
        d_(d),
        sm_(sm),
        block_(nullptr) {}

  // --------------------------------------------------------------------------
  // Expressions
  // --------------------------------------------------------------------------

  ExprEffect VisitExpr(clang::Expr* expr, const Environment& env) {
#define VISIT(type)                                                         \
  do {                                                                      \
    clang::type* concrete_expr = llvm::dyn_cast_or_null<clang::type>(expr); \
    if (concrete_expr != nullptr) {                                         \
      return Visit##type(concrete_expr, env);                               \
    }                                                                       \
  } while (0);

    VISIT(AbstractConditionalOperator);
    VISIT(AddrLabelExpr);
    VISIT(ArraySubscriptExpr);
    VISIT(BinaryOperator);
    VISIT(BlockExpr);
    VISIT(CallExpr);
    VISIT(CastExpr);
    VISIT(CharacterLiteral);
    VISIT(ChooseExpr);
    VISIT(CompoundLiteralExpr);
    VISIT(ConstantExpr);
    VISIT(CXXBindTemporaryExpr);
    VISIT(CXXBoolLiteralExpr);
    VISIT(CXXConstructExpr);
    VISIT(CXXDefaultArgExpr);
    VISIT(CXXDeleteExpr);
    VISIT(CXXDependentScopeMemberExpr);
    VISIT(CXXNewExpr);
    VISIT(CXXNoexceptExpr);
    VISIT(CXXNullPtrLiteralExpr);
    VISIT(CXXPseudoDestructorExpr);
    VISIT(CXXScalarValueInitExpr);
    VISIT(CXXThisExpr);
    VISIT(CXXThrowExpr);
    VISIT(CXXTypeidExpr);
    VISIT(CXXUnresolvedConstructExpr);
    VISIT(CXXUuidofExpr);
    VISIT(DeclRefExpr);
    VISIT(DependentScopeDeclRefExpr);
    VISIT(DesignatedInitExpr);
    VISIT(ExprWithCleanups);
    VISIT(ExtVectorElementExpr);
    VISIT(FloatingLiteral);
    VISIT(GNUNullExpr);
    VISIT(ImaginaryLiteral);
    VISIT(ImplicitCastExpr);
    VISIT(ImplicitValueInitExpr);
    VISIT(InitListExpr);
    VISIT(IntegerLiteral);
    VISIT(MaterializeTemporaryExpr);
    VISIT(MemberExpr);
    VISIT(OffsetOfExpr);
    VISIT(OpaqueValueExpr);
    VISIT(OverloadExpr);
    VISIT(PackExpansionExpr);
    VISIT(ParenExpr);
    VISIT(ParenListExpr);
    VISIT(PredefinedExpr);
    VISIT(ShuffleVectorExpr);
    VISIT(SizeOfPackExpr);
    VISIT(StmtExpr);
    VISIT(StringLiteral);
    VISIT(SubstNonTypeTemplateParmPackExpr);
    VISIT(TypeTraitExpr);
    VISIT(UnaryOperator);
    VISIT(UnaryExprOrTypeTraitExpr);
    VISIT(VAArgExpr);
#undef VISIT

    return ExprEffect::None();
  }

#define DECL_VISIT_EXPR(type) \
  ExprEffect Visit##type(clang::type* expr, const Environment& env)

#define IGNORE_EXPR(type)                                             \
  ExprEffect Visit##type(clang::type* expr, const Environment& env) { \
    return ExprEffect::None();                                        \
  }

  IGNORE_EXPR(AddrLabelExpr);
  IGNORE_EXPR(BlockExpr);
  IGNORE_EXPR(CharacterLiteral);
  IGNORE_EXPR(ChooseExpr);
  IGNORE_EXPR(CompoundLiteralExpr);
  IGNORE_EXPR(CXXBoolLiteralExpr);
  IGNORE_EXPR(CXXDependentScopeMemberExpr);
  IGNORE_EXPR(CXXNullPtrLiteralExpr);
  IGNORE_EXPR(CXXPseudoDestructorExpr);
  IGNORE_EXPR(CXXScalarValueInitExpr);
  IGNORE_EXPR(CXXNoexceptExpr);
  IGNORE_EXPR(CXXTypeidExpr);
  IGNORE_EXPR(CXXUnresolvedConstructExpr);
  IGNORE_EXPR(CXXUuidofExpr);
  IGNORE_EXPR(DependentScopeDeclRefExpr);
  IGNORE_EXPR(DesignatedInitExpr);
  IGNORE_EXPR(ExtVectorElementExpr);
  IGNORE_EXPR(FloatingLiteral);
  IGNORE_EXPR(ImaginaryLiteral);
  IGNORE_EXPR(IntegerLiteral);
  IGNORE_EXPR(OffsetOfExpr);
  IGNORE_EXPR(ImplicitValueInitExpr);
  IGNORE_EXPR(PackExpansionExpr);
  IGNORE_EXPR(PredefinedExpr);
  IGNORE_EXPR(ShuffleVectorExpr);
  IGNORE_EXPR(SizeOfPackExpr);
  IGNORE_EXPR(StmtExpr);
  IGNORE_EXPR(StringLiteral);
  IGNORE_EXPR(SubstNonTypeTemplateParmPackExpr);
  IGNORE_EXPR(TypeTraitExpr);
  IGNORE_EXPR(VAArgExpr);
  IGNORE_EXPR(GNUNullExpr);
  IGNORE_EXPR(OverloadExpr);

  DECL_VISIT_EXPR(CXXThisExpr) { return Use(expr, expr->getType(), THIS, env); }

  DECL_VISIT_EXPR(AbstractConditionalOperator) {
    Environment after_cond = env.ApplyEffect(VisitExpr(expr->getCond(), env));
    return ExprEffect::Merge(VisitExpr(expr->getTrueExpr(), after_cond),
                             VisitExpr(expr->getFalseExpr(), after_cond));
  }

  DECL_VISIT_EXPR(ArraySubscriptExpr) {
    clang::Expr* exprs[2] = {expr->getBase(), expr->getIdx()};
    return Parallel(expr, 2, exprs, env);
  }

  bool IsRawPointerVar(clang::Expr* expr, std::string* var_name) {
    if (llvm::isa<clang::DeclRefExpr>(expr)) {
      *var_name =
          Cast<llvm><clang::DeclRefExpr>(expr)->getDecl()->getNameAsString();
      return true;
    }

    return false;
  }

  DECL_VISIT_EXPR(BinaryOperator) {
    clang::Expr* lhs = expr->getLHS();
    clang::Expr* rhs = expr->getRHS();
    clang::Expr* exprs[2] = {lhs, rhs};

    switch (expr->getOpcode()) {
      case clang::BO_Comma:
        return Sequential(expr, 2, exprs, env);

      case clang::BO_LAnd:
      case clang::BO_LOr:
        return ExprEffect::Merge(VisitExpr(lhs, env), VisitExpr(rhs, env));

      default:
        return Parallel(expr, 2, exprs, env);
    }
  }

  DECL_VISIT_EXPR(CXXBindTemporaryExpr) {
    return VisitExpr(expr->getSubExpr(), env);
  }

  DECL_VISIT_EXPR(MaterializeTemporaryExpr) {
    return VisitExpr(expr->getSubExpr(), env);
  }

  DECL_VISIT_EXPR(CXXConstructExpr) { return VisitArguments<>(expr, env); }

  DECL_VISIT_EXPR(CXXDefaultArgExpr) { return VisitExpr(expr->getExpr(), env); }

  DECL_VISIT_EXPR(CXXDeleteExpr) { return VisitExpr(expr->getArgument(), env); }

  DECL_VISIT_EXPR(CXXNewExpr) { return VisitExpr(expr->getInitializer(), env); }

  DECL_VISIT_EXPR(ExprWithCleanups) {
    return VisitExpr(expr->getSubExpr(), env);
  }

  DECL_VISIT_EXPR(CXXThrowExpr) { return VisitExpr(expr->getSubExpr(), env); }

  DECL_VISIT_EXPR(ImplicitCastExpr) {
    return VisitExpr(expr->getSubExpr(), env);
  }

  DECL_VISIT_EXPR(ConstantExpr) { return VisitExpr(expr->getSubExpr(), env); }

  DECL_VISIT_EXPR(InitListExpr) {
    return Sequential(expr, expr->getNumInits(), expr->getInits(), env);
  }

  DECL_VISIT_EXPR(MemberExpr) { return VisitExpr(expr->getBase(), env); }

  DECL_VISIT_EXPR(OpaqueValueExpr) {
    return VisitExpr(expr->getSourceExpr(), env);
  }

  DECL_VISIT_EXPR(ParenExpr) { return VisitExpr(expr->getSubExpr(), env); }

  DECL_VISIT_EXPR(ParenListExpr) {
    return Parallel(expr, expr->getNumExprs(), expr->getExprs(), env);
  }

  DECL_VISIT_EXPR(UnaryOperator) {
    // TODO(gcmole): We are treating all expressions that look like
    // {&raw_pointer_var} as definitions of {raw_pointer_var}. This should be
    // changed to recognize less generic pattern:
    //
    //   if (maybe_object->ToObject(&obj)) return maybe_object;
    //
    if (expr->getOpcode() == clang::UO_AddrOf) {
      std::string var_name;
      if (IsRawPointerVar(expr->getSubExpr(), &var_name)) {
        return ExprEffect::None().Define(var_name);
      }
    }
    return VisitExpr(expr->getSubExpr(), env);
  }

  DECL_VISIT_EXPR(UnaryExprOrTypeTraitExpr) {
    if (expr->isArgumentType()) {
      return ExprEffect::None();
    }

    return VisitExpr(expr->getArgumentExpr(), env);
  }

  DECL_VISIT_EXPR(CastExpr) { return VisitExpr(expr->getSubExpr(), env); }

  DECL_VISIT_EXPR(DeclRefExpr) { return Use(expr, expr->getDecl(), env); }

  // Represents a node in the AST {parent} whose children {exprs} have
  // undefined order of evaluation, e.g. array subscript or a binary operator.
  ExprEffect Parallel(clang::Expr* parent, int n, clang::Expr** exprs,
                      const Environment& env) {
    CallProps props;
    for (int i = 0; i < n; ++i) {
      props.SetEffect(i, VisitExpr(exprs[i], env));
    }
    if (!props.IsSafe()) ReportUnsafe(parent, BAD_EXPR_MSG);
    return props.ComputeCumulativeEffect(
        RepresentsRawPointerType(parent->getType()));
  }

  // Represents a node in the AST {parent} whose children {exprs} are
  // executed in sequence, e.g. a switch statement or an initializer list.
  ExprEffect Sequential(clang::Stmt* parent, int n, clang::Expr** exprs,
                        const Environment& env) {
    ExprEffect out = ExprEffect::None();
    Environment out_env = env;
    for (int i = 0; i < n; ++i) {
      out = ExprEffect::MergeSeq(out, VisitExpr(exprs[i], out_env));
      out_env = out_env.ApplyEffect(out);
    }
    return out;
  }

  // Represents a node in the AST {parent} which uses the variable {var_name},
  // e.g. this expression or operator&.
  // Here we observe the type in {var_type} of a previously declared variable
  // and if it's a raw heap object type, we do the following:
  // 1. If it got stale due to GC since its declaration, we report it as such.
  // 2. Mark its raw usage in the ExprEffect returned by this function.
  ExprEffect Use(const clang::Expr* parent, const clang::QualType& var_type,
                 const std::string& var_name, const Environment& env) {
    if (!g_dead_vars_analysis) return ExprEffect::None();
    if (!RepresentsRawPointerType(var_type)) return ExprEffect::None();
    // We currently care only about our internal pointer types and not about
    // raw C++ pointers, because normally special care is taken when storing
    // raw pointers to the managed heap. Furthermore, checking for raw
    // pointers produces too many false positives in the dead variable
    // analysis.
    if (!IsInternalPointerType(var_type)) return ExprEffect::None();
    if (env.IsAlive(var_name)) return ExprEffect::None();
    if (HasActiveGuard()) return ExprEffect::None();
    ReportUnsafe(parent, DEAD_VAR_MSG);
    return ExprEffect::RawUse();
  }

  ExprEffect Use(const clang::Expr* parent, const clang::ValueDecl* var,
                 const Environment& env) {
    if (IsExternalVMState(var)) return ExprEffect::GC();
    return Use(parent, var->getType(), var->getNameAsString(), env);
  }

  template <typename ExprType>
  ExprEffect VisitArguments(ExprType* call, const Environment& env) {
    CallProps props;
    VisitArguments<>(call, &props, env);
    if (!props.IsSafe()) ReportUnsafe(call, BAD_EXPR_MSG);
    return props.ComputeCumulativeEffect(
        RepresentsRawPointerType(call->getType()));
  }

  template <typename ExprType>
  void VisitArguments(ExprType* call, CallProps* props,
                      const Environment& env) {
    for (unsigned arg = 0; arg < call->getNumArgs(); arg++) {
      props->SetEffect(arg + 1, VisitExpr(call->getArg(arg), env));
    }
  }

  // After visiting the receiver and the arguments of the {call} node, this
  // function might report a GC-unsafe usage (due to the undefined evaluation
  // order of the receiver and the rest of the arguments).
  ExprEffect VisitCallExpr(clang::CallExpr* call, const Environment& env) {
    CallProps props;

    clang::CXXMemberCallExpr* memcall =
        llvm::dyn_cast_or_null<clang::CXXMemberCallExpr>(call);
    if (memcall != nullptr) {
      clang::Expr* receiver = memcall->getImplicitObjectArgument();
      props.SetEffect(0, VisitExpr(receiver, env));
    }

    std::string var_name;
    clang::CXXOperatorCallExpr* opcall =
        llvm::dyn_cast_or_null<clang::CXXOperatorCallExpr>(call);
    if (opcall != nullptr && opcall->isAssignmentOp() &&
        IsRawPointerVar(opcall->getArg(0), &var_name)) {
      // TODO(gcmole): We are treating all assignment operator calls with
      // the left hand side looking like {raw_pointer_var} as safe independent
      // of the concrete assignment operator implementation. This should be
      // changed to be more narrow only if the assignment operator of the base
      // {Object} or {HeapObject} class was used, which we know to be safe.
      props.SetEffect(1, VisitExpr(call->getArg(1), env).Define(var_name));
    } else {
      VisitArguments<>(call, &props, env);
    }

    if (!props.IsSafe()) ReportUnsafe(call, BAD_EXPR_MSG);

    ExprEffect out = props.ComputeCumulativeEffect(
        RepresentsRawPointerType(call->getType()));

    clang::FunctionDecl* callee = call->getDirectCallee();
    if (callee == nullptr) return out;

    if (IsKnownToCauseGC(ctx_, callee)) {
      out.setGC();
      scopes_.back().SetGCCauseLocation(
          clang::FullSourceLoc(call->getExprLoc(), sm_), callee);
    }

    // Support for virtual methods that might be GC suspects.
    if (memcall == nullptr) return out;
    clang::CXXMethodDecl* method =
        llvm::dyn_cast_or_null<clang::CXXMethodDecl>(callee);
    if (method == nullptr) return out;
    if (!method->isVirtual()) return out;

    clang::CXXMethodDecl* target = method->getDevirtualizedMethod(
        memcall->getImplicitObjectArgument(), false);
    if (target != nullptr) {
      if (IsKnownToCauseGC(ctx_, target)) {
        out.setGC();
        scopes_.back().SetGCCauseLocation(
            clang::FullSourceLoc(call->getExprLoc(), sm_), target);
      }
    } else {
      // According to the documentation, {getDevirtualizedMethod} might
      // return nullptr, in which case we still want to use the partial
      // match of the {method}'s name against the GC suspects in order
      // to increase coverage.
      if (IsSuspectedToCauseGC(ctx_, method)) {
        out.setGC();
        scopes_.back().SetGCCauseLocation(
            clang::FullSourceLoc(call->getExprLoc(), sm_), method);
      }
    }
    return out;
  }

  // --------------------------------------------------------------------------
  // Statements
  // --------------------------------------------------------------------------

  Environment VisitStmt(clang::Stmt* stmt, const Environment& env) {
#define VISIT(type)                                                         \
  do {                                                                      \
    clang::type* concrete_stmt = llvm::dyn_cast_or_null<clang::type>(stmt); \
    if (concrete_stmt != nullptr) {                                         \
      return Visit##type(concrete_stmt, env);                               \
    }                                                                       \
  } while (0);

    if (clang::Expr* expr = llvm::dyn_cast_or_null<clang::Expr>(stmt)) {
      return env.ApplyEffect(VisitExpr(expr, env));
    }

    VISIT(AsmStmt);
    VISIT(BreakStmt);
    VISIT(CompoundStmt);
    VISIT(ContinueStmt);
    VISIT(CXXCatchStmt);
    VISIT(CXXTryStmt);
    VISIT(DeclStmt);
    VISIT(DoStmt);
    VISIT(ForStmt);
    VISIT(GotoStmt);
    VISIT(IfStmt);
    VISIT(IndirectGotoStmt);
    VISIT(LabelStmt);
    VISIT(NullStmt);
    VISIT(ReturnStmt);
    VISIT(CaseStmt);
    VISIT(DefaultStmt);
    VISIT(SwitchStmt);
    VISIT(WhileStmt);
#undef VISIT

    return env;
  }

#define DECL_VISIT_STMT(type) \
  Environment Visit##type(clang::type* stmt, const Environment& env)

#define IGNORE_STMT(type)                                              \
  Environment Visit##type(clang::type* stmt, const Environment& env) { \
    return env;                                                        \
  }

  IGNORE_STMT(IndirectGotoStmt);
  IGNORE_STMT(NullStmt);
  IGNORE_STMT(AsmStmt);

  // We are ignoring control flow for simplicity.
  IGNORE_STMT(GotoStmt);
  IGNORE_STMT(LabelStmt);

  // We are ignoring try/catch because V8 does not use them.
  IGNORE_STMT(CXXCatchStmt);
  IGNORE_STMT(CXXTryStmt);

  class Block {
   public:
    Block(const Environment& in, FunctionAnalyzer* owner)
        : in_(in),
          out_(Environment::Unreachable()),
          changed_(false),
          owner_(owner) {
      parent_ = owner_->EnterBlock(this);
    }

    ~Block() { owner_->LeaveBlock(parent_); }

    void MergeIn(const Environment& env) {
      Environment old_in = in_;
      in_ = Environment::Merge(in_, env);
      changed_ = !old_in.Equal(in_);
    }

    bool changed() {
      if (!changed_) return false;
      changed_ = false;
      return true;
    }

    const Environment& in() { return in_; }

    const Environment& out() { return out_; }

    void MergeOut(const Environment& env) {
      out_ = Environment::Merge(out_, env);
    }

    void Sequential(clang::Stmt* a, clang::Stmt* b, clang::Stmt* c) {
      Environment a_out = owner_->VisitStmt(a, in());
      Environment b_out = owner_->VisitStmt(b, a_out);
      Environment c_out = owner_->VisitStmt(c, b_out);
      MergeOut(c_out);
    }

    void Sequential(clang::Stmt* a, clang::Stmt* b) {
      Environment a_out = owner_->VisitStmt(a, in());
      Environment b_out = owner_->VisitStmt(b, a_out);
      MergeOut(b_out);
    }

    void Loop(clang::Stmt* a, clang::Stmt* b, clang::Stmt* c) {
      Sequential(a, b, c);
      MergeIn(out());
    }

    void Loop(clang::Stmt* a, clang::Stmt* b) {
      Sequential(a, b);
      MergeIn(out());
    }

   private:
    Environment in_;
    Environment out_;
    bool changed_;
    FunctionAnalyzer* owner_;
    Block* parent_;
  };

  DECL_VISIT_STMT(BreakStmt) {
    block_->MergeOut(env);
    return Environment::Unreachable();
  }

  DECL_VISIT_STMT(ContinueStmt) {
    block_->MergeIn(env);
    return Environment::Unreachable();
  }

  DECL_VISIT_STMT(CompoundStmt) {
    scopes_.push_back(GCScope());
    Environment out = env;
    clang::CompoundStmt::body_iterator end = stmt->body_end();
    for (clang::CompoundStmt::body_iterator s = stmt->body_begin(); s != end;
         ++s) {
      out = VisitStmt(*s, out);
    }
    scopes_.pop_back();
    return out;
  }

  DECL_VISIT_STMT(WhileStmt) {
    Block block(env, this);
    do {
      block.Loop(stmt->getCond(), stmt->getBody());
    } while (block.changed());
    return block.out();
  }

  DECL_VISIT_STMT(DoStmt) {
    Block block(env, this);

    // Special case `do { ... } while (false);`, which is known to only run
    // once, and is used in our (D)CHECK macros.
    if (auto* literal_cond =
            llvm::dyn_cast<clang::CXXBoolLiteralExpr>(stmt->getCond())) {
      if (literal_cond->getValue() == false) {
        block.Loop(stmt->getBody(), stmt->getCond());
        return block.out();
      }
    }

    do {
      block.Loop(stmt->getBody(), stmt->getCond());
    } while (block.changed());
    return block.out();
  }

  DECL_VISIT_STMT(ForStmt) {
    Block block(VisitStmt(stmt->getInit(), env), this);
    do {
      block.Loop(stmt->getCond(), stmt->getBody(), stmt->getInc());
    } while (block.changed());
    return block.out();
  }

  DECL_VISIT_STMT(IfStmt) {
    Environment cond_out = VisitStmt(stmt->getCond(), env);
    Environment then_out = VisitStmt(stmt->getThen(), cond_out);
    Environment else_out = VisitStmt(stmt->getElse(), cond_out);
    return Environment::Merge(then_out, else_out);
  }

  DECL_VISIT_STMT(SwitchStmt) {
    Block block(env, this);
    block.Sequential(stmt->getCond(), stmt->getBody());
    return block.out();
  }

  DECL_VISIT_STMT(CaseStmt) {
    Environment in = Environment::Merge(env, block_->in());
    Environment after_lhs = VisitStmt(stmt->getLHS(), in);
    return VisitStmt(stmt->getSubStmt(), after_lhs);
  }

  DECL_VISIT_STMT(DefaultStmt) {
    Environment in = Environment::Merge(env, block_->in());
    return VisitStmt(stmt->getSubStmt(), in);
  }

  DECL_VISIT_STMT(ReturnStmt) {
    VisitExpr(stmt->getRetValue(), env);
    return Environment::Unreachable();
  }

  const clang::TagType* ToTagType(const clang::Type* t) {
    if (t == nullptr) {
      return nullptr;
    } else if (llvm::isa<clang::TagType>(t)) {
      return Cast<llvm><clang::TagType>(t);
    } else if (llvm::isa<clang::SubstTemplateTypeParmType>(t)) {
      return ToTagType(Cast<llvm><clang::SubstTemplateTypeParmType>(t)
                           ->getReplacementType()
                           .getTypePtr());
    } else {
      return nullptr;
    }
  }

  bool IsDerivedFrom(const clang::CXXRecordDecl* record,
                     const clang::CXXRecordDecl* base) {
    return (record == base) || record->isDerivedFrom(base);
  }

  const clang::CXXRecordDecl* GetDefinitionOrNull(
      const clang::CXXRecordDecl* record) {
    if (record == nullptr) return nullptr;
    if (!InV8Namespace(record)) return nullptr;
    if (!record->hasDefinition()) return nullptr;
    return record->getDefinition();
  }

  bool IsDerivedFromInternalPointer(const clang::CXXRecordDecl* record) {
    if (record == nullptr) return false;
    if (!InV8Namespace(record)) return false;
    auto* specialization =
        llvm::dyn_cast<clang::ClassTemplateSpecializationDecl>(record);
    if (specialization) {
      auto* template_decl =
          specialization->getSpecializedTemplate()->getCanonicalDecl();
      if (template_decl == tagged_decl_) {
        auto& template_args = specialization->getTemplateArgs();
        if (template_args.size() != 1) {
          llvm::errs() << "v8::internal::Tagged<T> should have exactly one "
                          "template argument\n";
          specialization->dump(llvm::errs());
          return false;
        }
        if (template_args[0].getKind() != clang::TemplateArgument::Type) {
          llvm::errs()
              << "v8::internal::Tagged<T>, T should be a type argument\n";
          specialization->dump(llvm::errs());
          return false;
        }

        auto* tagged_type_record =
            template_args[0].getAsType()->getAsCXXRecordDecl();
        return tagged_type_record != smi_decl_ &&
               tagged_type_record != tagged_index_decl_;
      }
    }

    const clang::CXXRecordDecl* definition = GetDefinitionOrNull(record);
    if (!definition) return false;
    if (IsDerivedFrom(record, heap_object_decl_)) {
      return true;
    }
    return false;
  }

  bool IsRawPointerType(const clang::PointerType* type) {
    const clang::CXXRecordDecl* record = type->getPointeeCXXRecordDecl();
    bool result = IsDerivedFromInternalPointer(record);
    TRACE("is raw " << result << " "
                    << (record ? record->getNameAsString() : "nullptr"));
    return result;
  }

  bool IsInternalPointerType(clang::QualType qtype) {
    const clang::CXXRecordDecl* record = qtype->getAsCXXRecordDecl();
    bool result = IsDerivedFromInternalPointer(record);
    TRACE_LLVM_TYPE("is internal " << result, qtype);
    return result;
  }

  // Returns weather the given type is a raw pointer or a wrapper around
  // such. For V8 that means Object and MaybeObject instances.
  bool RepresentsRawPointerType(clang::QualType qtype) {
    // Not yet assigned pointers can't get moved by the GC.
    if (qtype.isNull()) return false;
    // nullptr can't get moved by the GC.
    if (qtype->isNullPtrType()) return false;

    const clang::PointerType* pointer_type =
        llvm::dyn_cast_or_null<clang::PointerType>(qtype.getTypePtrOrNull());
    if (pointer_type != nullptr) {
      return IsRawPointerType(pointer_type);
    } else {
      return IsInternalPointerType(qtype);
    }
  }

  bool IsGCGuard(clang::QualType qtype) {
    if (!no_gc_mole_decl_) return false;
    if (qtype.isNull()) return false;
    if (qtype->isNullPtrType()) return false;

    const clang::CXXRecordDecl* record = qtype->getAsCXXRecordDecl();
    const clang::CXXRecordDecl* definition = GetDefinitionOrNull(record);

    if (!definition) return false;
    return no_gc_mole_decl_ == definition;
  }

  Environment VisitDecl(clang::Decl* decl, Environment& env) {
    if (clang::VarDecl* var = llvm::dyn_cast<clang::VarDecl>(decl)) {
      Environment out = var->hasInit() ? VisitStmt(var->getInit(), env) : env;

      if (RepresentsRawPointerType(var->getType())) {
        out = out.Define(var->getNameAsString());
      }
      if (IsGCGuard(var->getType())) {
        scopes_.back().guard_location =
            clang::FullSourceLoc(decl->getLocation(), sm_);
      }

      return out;
    }
    // TODO(gcmole): handle other declarations?
    return env;
  }

  DECL_VISIT_STMT(DeclStmt) {
    Environment out = env;
    clang::DeclStmt::decl_iterator end = stmt->decl_end();
    for (clang::DeclStmt::decl_iterator decl = stmt->decl_begin(); decl != end;
         ++decl) {
      out = VisitDecl(*decl, out);
    }
    return out;
  }

  void DefineParameters(const clang::FunctionDecl* f, Environment* env) {
    env->MDefine(THIS);
    clang::FunctionDecl::param_const_iterator end = f->param_end();
    for (clang::FunctionDecl::param_const_iterator p = f->param_begin();
         p != end; ++p) {
      env->MDefine((*p)->getNameAsString());
    }
  }

  void AnalyzeFunction(const clang::FunctionDecl* f) {
    const clang::FunctionDecl* body = nullptr;
    if (f->hasBody(body)) {
      Environment env;
      DefineParameters(body, &env);
      VisitStmt(body->getBody(), env);
      Environment::ClearSymbolTable();
    }
  }

  Block* EnterBlock(Block* block) {
    Block* parent = block_;
    block_ = block;
    return parent;
  }

  void LeaveBlock(Block* block) { block_ = block; }

  bool HasActiveGuard() {
    for (const auto& s : scopes_) {
      if (s.IsBeforeGCCause()) return true;
    }
    return false;
  }

 private:
  void ReportUnsafe(const clang::Expr* expr, const std::string& msg) {
    clang::SourceLocation error_loc =
        clang::FullSourceLoc(expr->getExprLoc(), sm_);
    d_.Report(error_loc,
              d_.getCustomDiagID(clang::DiagnosticsEngine::Warning, "%0"))
        << msg;
    // Find the relevant GC scope (see HasActiveGuard).
    const GCScope* pscope = nullptr;
    for (const auto& s : scopes_) {
      if (!s.IsBeforeGCCause() && s.gccause_location.isValid()) {
        pscope = &s;
        break;
      }
    }
    if (!pscope) {
      d_.Report(error_loc,
                d_.getCustomDiagID(clang::DiagnosticsEngine::Note,
                                   "Could not find GC source location."));
      return;
    }
    const GCScope& scope = *pscope;
    d_.Report(scope.gccause_location,
              d_.getCustomDiagID(clang::DiagnosticsEngine::Note,
                                 "Call might cause unexpected GC."));
    clang::FunctionDecl* gccause_decl = scope.gccause_decl;
    d_.Report(
        clang::FullSourceLoc(gccause_decl->getBeginLoc(), sm_),
        d_.getCustomDiagID(clang::DiagnosticsEngine::Note, "GC call here."));

    if (!g_print_gc_call_chain) return;
    // TODO(cbruni, v8::10009): print call-chain to gc with proper source
    // positions.
    LoadGCCauses();
    MangledName name;
    if (!GetMangledName(ctx_, gccause_decl, &name)) return;
    std::cout << "Potential GC call chain:\n";
    std::set<MangledName> stack;
    while (true) {
      if (!stack.insert(name).second) break;
      std::cout << "\t" << name << "\n";
      auto next = gc_causes.find(name);
      if (next == gc_causes.end()) break;
      std::vector<MangledName> calls = next->second;
      for (MangledName call : calls) {
        name = call;
        if (stack.find(call) != stack.end()) break;
      }
    }
  }

  clang::MangleContext* ctx_;
  clang::CXXRecordDecl* heap_object_decl_;
  clang::CXXRecordDecl* smi_decl_;
  clang::CXXRecordDecl* tagged_index_decl_;
  clang::ClassTemplateDecl* tagged_decl_;
  clang::CXXRecordDecl* no_gc_mole_decl_;

  clang::DiagnosticsEngine& d_;
  clang::SourceManager& sm_;

  Block* block_;

  struct GCScope {
    clang::FullSourceLoc guard_location;
    clang::FullSourceLoc gccause_location;
    clang::FunctionDecl* gccause_decl;

    // We're only interested in guards that are declared before any further GC
    // causing calls (see TestGuardedDeadVarAnalysisMidFunction for example).
    bool IsBeforeGCCause() const {
      if (!guard_location.isValid()) return false;
      if (!gccause_location.isValid()) return true;
      return guard_location.isBeforeInTranslationUnitThan(gccause_location);
    }

    // After we set the first GC cause in the scope, we don't need the later
    // ones.
    void SetGCCauseLocation(clang::FullSourceLoc gccause_location_,
                            clang::FunctionDecl* decl) {
      if (gccause_location.isValid()) return;
      gccause_location = gccause_location_;
      gccause_decl = decl;
    }
  };
  std::vector<GCScope> scopes_;
};

class ProblemsFinder : public clang::ASTConsumer,
                       public clang::RecursiveASTVisitor<ProblemsFinder> {
 public:
  ProblemsFinder(clang::DiagnosticsEngine& d, clang::SourceManager& sm,
                 const std::vector<std::string>& args)
      : d_(d), sm_(sm) {
    for (unsigned i = 0; i < args.size(); ++i) {
      if (args[i] == "--dead-vars") {
        g_dead_vars_analysis = true;
      }
      if (args[i] == "--verbose-trace") g_tracing_enabled = true;
      if (args[i] == "--verbose") g_verbose = true;
    }
  }

  bool TranslationUnitIgnored() {
    if (!ignored_files_loaded_) {
      std::ifstream fin("tools/gcmole/ignored_files");
      std::string s;
      while (fin >> s) ignored_files_.insert(s);
      ignored_files_loaded_ = true;
    }

    clang::FileID main_file_id = sm_.getMainFileID();
    std::string filename = sm_.getFileEntryForID(main_file_id)->getName().str();

    bool result = ignored_files_.find(filename) != ignored_files_.end();
    if (result) {
      llvm::outs() << "Ignoring file " << filename << "\n";
    }
    return result;
  }

  void HandleTranslationUnit(clang::ASTContext& ctx) override {
    if (TranslationUnitIgnored()) return;

    Resolver r(ctx);

    // It is a valid situation that no_gc_mole_decl == nullptr when
    // DisableGCMole is not included and can't be resolved. This is gracefully
    // handled in the FunctionAnalyzer later.
    auto v8_internal = r.ResolveNamespace("v8").ResolveNamespace("internal");
    clang::CXXRecordDecl* no_gc_mole_decl =
        v8_internal.Resolve<clang::CXXRecordDecl>("DisableGCMole");

    clang::CXXRecordDecl* heap_object_decl =
        v8_internal.Resolve<clang::CXXRecordDecl>("HeapObject");

    clang::CXXRecordDecl* smi_decl =
        v8_internal.Resolve<clang::CXXRecordDecl>("Smi");

    clang::CXXRecordDecl* tagged_index_decl =
        v8_internal.Resolve<clang::CXXRecordDecl>("TaggedIndex");

    clang::ClassTemplateDecl* tagged_decl =
        v8_internal.Resolve<clang::ClassTemplateDecl>("Tagged");

    if (heap_object_decl != nullptr) {
      heap_object_decl = heap_object_decl->getDefinition();
    }

    if (smi_decl != nullptr) {
      smi_decl = smi_decl->getDefinition();
    }

    if (tagged_index_decl != nullptr) {
      tagged_index_decl = tagged_index_decl->getDefinition();
    }

    if (tagged_decl != nullptr) {
      tagged_decl = tagged_decl->getCanonicalDecl();
    }

    if (heap_object_decl != nullptr && smi_decl != nullptr &&
        tagged_index_decl != nullptr && tagged_decl != nullptr) {
      function_analyzer_ = new FunctionAnalyzer(
          clang::ItaniumMangleContext::create(ctx, d_), heap_object_decl,
          smi_decl, tagged_index_decl, tagged_decl, no_gc_mole_decl, d_, sm_);
      TraverseDecl(ctx.getTranslationUnitDecl());
    } else if (g_verbose) {
      if (heap_object_decl == nullptr) {
        llvm::errs() << "Failed to resolve v8::internal::HeapObject\n";
      }
      if (smi_decl == nullptr) {
        llvm::errs() << "Failed to resolve v8::internal::Smi\n";
      }
      if (tagged_index_decl == nullptr) {
        llvm::errs() << "Failed to resolve v8::internal::TaggedIndex\n";
      }
      if (tagged_decl == nullptr) {
        llvm::errs() << "Failed to resolve v8::internal::Tagged<T>\n";
      }
    }
  }

  virtual bool VisitFunctionDecl(clang::FunctionDecl* decl) {
    // Don't print tracing from includes, otherwise the output is too big.
    bool tracing = g_tracing_enabled;
    const auto& fileID = sm_.getFileID(decl->getLocation());
    if (fileID != sm_.getMainFileID()) {
      g_tracing_enabled = false;
    }

    TRACE("Visiting function " << decl->getNameAsString());
    function_analyzer_->AnalyzeFunction(decl);

    g_tracing_enabled = tracing;
    return true;
  }

 private:
  clang::DiagnosticsEngine& d_;
  clang::SourceManager& sm_;

  bool ignored_files_loaded_ = false;
  std::set<std::string> ignored_files_;

  FunctionAnalyzer* function_analyzer_;
};

template <typename ConsumerType>
class Action : public clang::PluginASTAction {
 protected:
  std::unique_ptr<clang::ASTConsumer> CreateASTConsumer(
      clang::CompilerInstance& CI, llvm::StringRef InFile) override {
    return std::unique_ptr<clang::ASTConsumer>(
        new ConsumerType(CI.getDiagnostics(), CI.getSourceManager(), args_));
  }

  bool ParseArgs(const clang::CompilerInstance& CI,
                 const std::vector<std::string>& args) override {
    args_ = args;
    return true;
  }

  void PrintHelp(llvm::raw_ostream& ros) {}

 private:
  std::vector<std::string> args_;
};

}  // namespace

static clang::FrontendPluginRegistry::Add<Action<ProblemsFinder>> FindProblems(
    "find-problems", "Find GC-unsafe places.");

static clang::FrontendPluginRegistry::Add<Action<FunctionDeclarationFinder>>
    DumpCallees("dump-callees", "Dump callees for each function.");

#undef TRACE
#undef TRACE_LLVM_TYPE
#undef TRACE_LLVM_DECL
#undef DECL_VISIT_EXPR
#undef IGNORE_EXPR
#undef DECL_VISIT_STMT
#undef IGNORE_STMT
                                                                                                                                                                                                                                                                                                                                                                                                                                                                             node-23.7.0/deps/v8/tools/gcmole/gcmole.py                                                          0000775 0000000 0000000 00000064251 14746647661 0020306 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3
# Copyright 2020 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

# This is main driver for gcmole tool. See README for more details.
# Usage: CLANG_BIN=clang-bin-dir python tools/gcmole/gcmole.py [arm|arm64|ia32|x64]

from contextlib import contextmanager
from contextlib import redirect_stderr
from multiprocessing import cpu_count
from pathlib import Path

import argparse
import collections
import difflib
import io
import json
import os
import pickle
import re
import subprocess
import sys
import threading
import queue


ArchCfg = collections.namedtuple("ArchCfg",
                                 ["name", "cpu", "triple", "arch_options"])

ARCHITECTURES = {
    "ia32":
        ArchCfg(
            name="ia32",
            cpu="x86",
            triple="i586-unknown-linux",
            arch_options=["-m32"],
        ),
    "arm":
        ArchCfg(
            name="arm",
            cpu="arm",
            triple="i586-unknown-linux",
            arch_options=["-m32"],
        ),
    "x64":
        ArchCfg(
            name="x64",
            cpu="x64",
            triple="x86_64-unknown-linux",
            arch_options=[]),
    "arm64":
        ArchCfg(
            name="arm64",
            cpu="arm64",
            triple="x86_64-unknown-linux",
            arch_options=[],
        ),
}
ARCHITECTURES['x86'] = ARCHITECTURES['ia32']


def log(format, *args, **kwargs):
  mark = ("#", "=", "-", ".")[kwargs.get("level", 0)]
  print(mark * 2, str(format).format(*list(map(str, args))))


def fatal(format):
  log(format)
  sys.exit(1)


# -----------------------------------------------------------------------------
# Clang invocation


def make_clang_command_line(plugin, plugin_args, options):
  with open(options.v8_build_dir / 'v8_gcmole.args') as f:
    generated_args = f.read().strip().split()

  arch_cfg = ARCHITECTURES[options.v8_target_cpu]
  prefixed_plugin_args = []
  if plugin_args:
    for arg in plugin_args:
      prefixed_plugin_args += [
          "-Xclang",
          "-plugin-arg-" + plugin,
          "-Xclang",
          arg,
      ]
  log("Using generated files in {}", options.v8_build_dir / 'gen')
  return ([
      options.clang_bin_dir / "clang++",
      "-std=c++20",
      "-c",
      "-Xclang",
      "-load",
      "-Xclang",
      options.clang_plugins_dir / "libgcmole.so",
      "-Xclang",
      "-plugin",
      "-Xclang",
      plugin,
  ] + prefixed_plugin_args + [
      "-Xclang",
      "-triple",
      "-Xclang",
      arch_cfg.triple,
      "-fno-exceptions",
      "-Wno-everything",
      "-DV8_GC_MOLE",
  ] + generated_args + arch_cfg.arch_options)


def invoke_clang_plugin_for_file(filename, cmd_line, verbose):
  args = cmd_line + [filename]
  args = list(map(str, args))
  if verbose:
    print("popen ", " ".join(args))
  p = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
  stdout, stderr = p.communicate()
  return p.returncode, stdout.decode("utf-8"), stderr.decode("utf-8")


def invoke_clang_plugin_for_files_in_queue(i, input_queue, output_queue,
                                           cancel_event, cmd_line, verbose):
  success = False
  try:
    while not cancel_event.is_set():
      filename = input_queue.get_nowait()
      ret, stdout, stderr = invoke_clang_plugin_for_file(
          filename, cmd_line, verbose)
      output_queue.put_nowait((filename, ret, stdout, stderr))
      if ret != 0:
        break
  except KeyboardInterrupt:
    log("[{}] Interrupting", i, level=1)
  except queue.Empty:
    success = True
  finally:
    # Emit a success bool so that the reader knows that there was either an
    # error or all files were processed.
    output_queue.put_nowait(success)


def invoke_clang_plugin_for_each_file(filenames, plugin, plugin_args, options):
  cmd_line = make_clang_command_line(plugin, plugin_args, options)
  verbose = options.verbose
  if options.sequential:
    log("Sequential execution.")
    for filename in filenames:
      log(filename, level=1)
      returncode, stdout, stderr = invoke_clang_plugin_for_file(
          filename, cmd_line, verbose)
      if returncode != 0:
        sys.stderr.write(stderr)
        sys.exit(returncode)
      yield filename, stdout, stderr
  else:
    log("Parallel execution.")
    cpus = cpu_count()
    input_queue = queue.Queue()
    output_queue = queue.Queue()
    threads = []
    try:
      for filename in filenames:
        input_queue.put(filename)

      cancel_event = threading.Event()

      for i in range(min(len(filenames), cpus)):
        threads.append(
            threading.Thread(
                target=invoke_clang_plugin_for_files_in_queue,
                args=(i, input_queue, output_queue, cancel_event, cmd_line,
                      verbose)))

      for t in threads:
        t.start()

      num_finished = 0
      while num_finished < len(threads):
        output = output_queue.get()
        if type(output) == bool:
          if output:
            num_finished += 1
            continue
          else:
            break
        filename, returncode, stdout, stderr = output
        log(filename, level=2)
        if returncode != 0:
          sys.stderr.write(stderr)
          sys.exit(returncode)
        yield filename, stdout, stderr

    finally:
      cancel_event.set()
      for t in threads:
        t.join()


# -----------------------------------------------------------------------------


def build_file_list(options):
  """Calculates the list of source files to be checked with gcmole.

  The list comprises all files from marked source sections in the
  listed BUILD.gn files. All files preceeded by the following comment and
  until the end of the source section are used:
  ### gcmole(arch) ###
  Where arch can either be all (all architectures) or one of the supported V8
  architectures.

  The structure of these directives is also checked by presubmit via:
  tools/v8_presubmit.py::GCMoleProcessor.

  Returns: List of file paths (of type Path).
  """
  if options.test_run:
    return [options.v8_root_dir / "tools/gcmole/gcmole-test.cc"]
  result = []
  gn_files = [
      ("BUILD.gn", re.compile('"([^"]*?\.cc)"'), ""),
      ("test/cctest/BUILD.gn", re.compile('"(test-[^"]*?\.cc)"'),
       Path("test/cctest/")),
  ]
  gn_re = re.compile(f"### gcmole\((all|{options.v8_target_cpu})\) ###(.*?)\]",
                     re.MULTILINE | re.DOTALL)
  for filename, file_pattern, prefix in gn_files:
    path = options.v8_root_dir / filename
    with open(path) as gn_file:
      gn = gn_file.read()
      for _, sources in gn_re.findall(gn):
        for file in file_pattern.findall(sources):
          result.append(options.v8_root_dir / prefix / file)

  # Filter files of current shard if running on multiple hosts.
  def is_in_shard(index):
    return (index % options.shard_count) == options.shard_index

  return [f for i, f in enumerate(result) if is_in_shard(i)]


# -----------------------------------------------------------------------------
# GCSuspects Generation

# Note that the gcsuspects file lists functions in the form:
#  mangled_name,unmangled_function_name
#
# This means that we can match just the function name by matching only
# after a comma.
ALLOWLIST = [
    # The following functions call CEntryStub which is always present.
    "MacroAssembler.*,CallRuntime",
    "CompileCallLoadPropertyWithInterceptor",
    "CallIC.*,GenerateMiss",
    # DirectCEntryStub is a special stub used on ARM.
    # It is pinned and always present.
    "DirectCEntryStub.*,GenerateCall",
    # TODO GCMole currently is sensitive enough to understand that certain
    #    functions only cause GC and return Failure simulataneously.
    #    Callsites of such functions are safe as long as they are properly
    #    check return value and propagate the Failure to the caller.
    #    It should be possible to extend GCMole to understand this.
    "Heap.*,TryEvacuateObject",
    # Ignore all StateTag methods.
    "StateTag",
    # Ignore printing of elements transition.
    "PrintElementsTransition",
    # CodeCreateEvent receives AbstractCode (a raw ptr) as an argument.
    "CodeCreateEvent",
    "WriteField",
]

GC_PATTERN = ",.*Collect.*Garbage"
SAFEPOINT_PATTERN = ",SafepointSlowPath"
ALLOWLIST_PATTERN = "|".join("(?:{})".format(p) for p in ALLOWLIST)


def merge_regexp(pattern_dict):
  return re.compile("|".join("(?P<{}>{})".format(key, value)
                             for (key, value) in list(pattern_dict.items())))


IS_SPECIAL_WITHOUT_ALLOW_LIST = merge_regexp({
    "gc": GC_PATTERN,
    "safepoint": SAFEPOINT_PATTERN
})
IS_SPECIAL_WITH_ALLOW_LIST = merge_regexp({
    "gc": GC_PATTERN,
    "safepoint": SAFEPOINT_PATTERN,
    "allow": ALLOWLIST_PATTERN
})


class CallGraph:

  def __init__(self):
    self.funcs = collections.defaultdict(set)
    self.current_caller = None

  def parse(self, lines):
    for funcname in lines:
      if not funcname:
        continue

      if funcname[0] != "\t":
        # Always inserting the current caller makes the serialized version
        # more compact.
        self.funcs[funcname]
        self.current_caller = funcname
      else:
        self.funcs[funcname[1:]].add(self.current_caller)

  def to_file(self, file_name):
    """Store call graph in file 'file_name'."""
    log(f"Writing serialized callgraph to {file_name}")
    with open(file_name, 'wb') as f:
      pickle.dump(self, f)

  @staticmethod
  def from_file(file_name):
    """Restore call graph from file 'file_name'."""
    log(f"Reading serialized callgraph from {file_name}")
    with open(file_name, 'rb') as f:
      return pickle.load(f)

  @staticmethod
  def from_files(*file_names):
    """Merge multiple call graphs from a list of files."""
    callgraph = CallGraph()
    for file_name in file_names:
      funcs = CallGraph.from_file(file_name).funcs
      for callee, callers in funcs.items():
        callgraph.funcs[callee].update(callers)
    return callgraph


class GCSuspectsCollector:

  def __init__(self, options, funcs):
    self.gc = {}
    self.gc_caused = collections.defaultdict(set)
    self.funcs = funcs
    if options.allowlist:
      self.is_special = IS_SPECIAL_WITH_ALLOW_LIST
    else:
      self.is_special = IS_SPECIAL_WITHOUT_ALLOW_LIST

  def add_cause(self, name, cause):
    self.gc_caused[name].add(cause)

  def resolve(self, name):
    m = self.is_special.search(name)
    if not m:
      return

    if m.group("gc"):
      self.gc[name] = True
      self.add_cause(name, "<GC>")
    elif m.group("safepoint"):
      self.gc[name] = True
      self.add_cause(name, "<Safepoint>")
    elif m.group("allow"):
      self.gc[name] = False

  def propagate(self):
    log("Propagating GC information")

    def mark(funcname):
      for caller in self.funcs[funcname]:
        if caller not in self.gc:
          self.gc[caller] = True
          mark(caller)
        self.add_cause(caller, funcname)

    for funcname in self.funcs:
      self.resolve(funcname)

    for funcname in self.funcs:
      if self.gc.get(funcname, False):
        mark(funcname)


def generate_callgraph(files, options):
  """Construct a (potentially partial) call graph from a subset of
  source files.
  """
  callgraph = CallGraph()

  log(f"Building call graph for {options.v8_target_cpu}")
  for _, stdout, _ in invoke_clang_plugin_for_each_file(
      files, "dump-callees", [], options):
    callgraph.parse(stdout.splitlines())

  return callgraph


def generate_gc_suspects_from_callgraph(callgraph, options):
  """Calculate and store gc-suspect information from a given call graph."""
  collector = GCSuspectsCollector(options, callgraph.funcs)
  collector.propagate()
  # TODO(cbruni): remove once gcmole.cc is migrated
  write_gcmole_results(collector, options, options.v8_root_dir)
  write_gcmole_results(collector, options, options.out_dir)


def generate_gc_suspects_from_files(options):
  """Generate file list and corresponding gc-suspect information."""
  files = build_file_list(options)
  call_graph = generate_callgraph(files, options)
  generate_gc_suspects_from_callgraph(call_graph, options)
  return files


def write_gcmole_results(collector, options, dst):
  # gcsuspects contains a list("mangled_full_name,name") of all functions that
  # could cause a gc (directly or indirectly).
  #
  # EXAMPLE
  # _ZN2v88internal4Heap16CreateApiObjectsEv,CreateApiObjects
  # _ZN2v88internal4Heap17CreateInitialMapsEv,CreateInitialMaps
  # ...
  with open(dst / "gcsuspects", "w") as out:
    for name, value in list(collector.gc.items()):
      if value:
        out.write(name + "\n")
  # gccauses contains a map["mangled_full_name,name"] => list(inner gcsuspects)
  # Where the inner gcsuspects are functions directly called in the outer
  # function that can cause a gc. The format is encoded for simplified
  # deserialization in gcmole.cc.
  #
  # EXAMPLE:
  # _ZN2v88internal4Heap17CreateHeapObjectsEv,CreateHeapObjects
  # start,nested
  # _ZN2v88internal4Heap16CreateApiObjectsEv,CreateApiObjects
  # _ZN2v88internal4Heap17CreateInitialMapsEv,CreateInitialMaps
  # ...
  # end,nested
  # ...
  with open(dst / "gccauses", "w") as out:
    for name, causes in list(collector.gc_caused.items()):
      out.write("{}\n".format(name))
      out.write("start,nested\n")
      for cause in causes:
        out.write("{}\n".format(cause))
      out.write("end,nested\n")
  log("GCSuspects and gccauses generated for {} in '{}'", options.v8_target_cpu,
      dst)


# ------------------------------------------------------------------------------
# Analysis


def check_correctness_for_arch(files, options):
  processed_files = 0
  errors_found = False

  log("Searching for evaluation order problems " +
      ("and dead variables " if options.dead_vars else "") + "for " +
      options.v8_target_cpu)
  plugin_args = []
  if options.dead_vars:
    plugin_args.append("--dead-vars")
  if options.verbose:
    plugin_args.append("--verbose")
  if options.verbose_trace:
    plugin_args.append("--verbose-trace")
  for _, _, stderr in invoke_clang_plugin_for_each_file(files, "find-problems",
                                                        plugin_args, options):
    processed_files = processed_files + 1
    if not errors_found:
      errors_found = re.search("^[^:]+:\d+:\d+: (warning|error)", stderr,
                               re.MULTILINE) is not None
    sys.stderr.write(stderr)

  log("Done processing {} files.", processed_files)
  log("Errors found" if errors_found else "No errors found")

  return errors_found


def clean_test_output(output):
  """Substitute line number patterns for files except gcmole-test.cc, as
  otherwise unrelated code changes require a rebaseline of test expectations.
  """
  return re.sub(
      r'(?<!gcmole-test\.cc):\d*:\d*:',
      ':<number>:<number>:',
      output)


def has_unexpected_errors(options, errors_found, file_io):
  """Returns True if error state isn't as expected, False otherwise.

  In test-run mode, we expect certain errors and return False if expectations
  are met.
  """
  if not options.test_run:
    return errors_found

  log("Test Run")
  output = clean_test_output(file_io.getvalue())
  if not errors_found:
    log("Test file should produce errors, but none were found. Output:")
    print(output)
    return True

  new_file = options.out_dir / "test-expectations-gen.txt"
  with open(new_file, "w") as f:
    f.write(output)
  log("Wrote test-results: {}", new_file)

  expected_file = options.v8_root_dir / "tools/gcmole/test-expectations.txt"
  with open(expected_file) as exp_file:
    expectations = exp_file.read()

  if output != expectations:
    diff_file = options.out_dir / "test_output.diff"
    print("#" * 79)
    log("Output mismatch from running tests.")
    log("Please run gcmole manually with --test-run --verbose.")
    log(f"Expected: {expected_file}")
    log(f"New:      {new_file}")
    log(f"*Diff:*   {diff_file}")
    print("#" * 79)
    for line in difflib.unified_diff(
        expectations.splitlines(),
        output.splitlines(),
        fromfile=str(new_file),
        tofile=str(diff_file),
        lineterm="",
    ):
      print(line)

    print("#" * 79)
    log("Full output")
    log(f"Expected: {expected_file}")
    log(f"Diff:     {diff_file}")
    log(f"*New*:    {new_file}")
    print("#" * 79)
    print(output)
    print("#" * 79)

    return True

  log("Tests ran successfully")
  return False


# =============================================================================
def relative_parents(path, level=0):
  return Path(os.path.relpath(str(path.resolve().parents[level])))


def main(argv):
  # Get a clean parent path relative to PWD
  default_root_dir = relative_parents(Path(__file__), level=2)
  if len(argv) >= 1:
    default_gcmole_dir = relative_parents(Path(argv[0]))
  if default_gcmole_dir or not default_gcmole_dir.exists():
    default_gcmole_dir = default_root_dir / 'tools' / 'gcmole'
  default_clang_bin_dir = default_gcmole_dir / 'gcmole-tools/bin'

  def add_common_args(parser):
    archs = list(ARCHITECTURES.keys())
    parser.add_argument(
        "--v8-root-dir",
        metavar="DIR",
        default=default_root_dir,
        help="V8 checkout directory. Default: '{}'".format(
            default_root_dir.absolute()))
    parser.add_argument(
        "--v8-target-cpu",
        default="x64",
        choices=archs,
        help="Tested CPU architecture. Choices: {}".format(archs),
        metavar="CPU")
    parser.add_argument(
        "--clang-bin-dir",
        metavar="DIR",
        help="Build dir of the custom clang version for gcmole." + \
        "Default: env['CLANG_DIR'] or '{}'".format(default_clang_bin_dir))
    parser.add_argument(
        "--clang-plugins-dir",
        metavar="DIR",
        help="Containing dir for libgcmole.so."
        "Default: env['CLANG_PLUGINS'] or '{}'".format(default_gcmole_dir))
    parser.add_argument(
        "--v8-build-dir",
        metavar="BUILD_DIR",
        help="GN build dir for v8. Default: 'out/CPU.Release'. "
        "Config must match cpu specified by --v8-target-cpu")
    parser.add_argument(
        "--out-dir",
        metavar="DIR",
        help="Output location for the gcsuspect and gcauses file."
        "Default: BUILD_DIR/gen/tools/gcmole")
    parser.add_argument(
        "--is-bot",
        action="store_true",
        default=False,
        help="Flag for setting build bot specific settings.")
    parser.add_argument(
        "--shard-count",
        default=1,
        type=int,
        help="Number of tasks the current action (e.g. collect or check) "
             "is distributed to.")
    parser.add_argument(
        "--shard-index",
        default=0,
        type=int,
        help="Index of the current task (in [0..shard-count-1]) if the "
             "overall action is distributed (shard-count > 1).")

    group = parser.add_argument_group("GCMOLE options")
    group.add_argument(
        "--sequential",
        action="store_true",
        default=False,
        help="Don't use parallel python runner.")
    group.add_argument(
        "--verbose",
        action="store_true",
        default=False,
        help="Print commands to console before executing them.")
    group.add_argument(
        "--no-dead-vars",
        action="store_false",
        dest="dead_vars",
        default=True,
        help="Don't perform dead variable analysis.")
    group.add_argument(
        "--verbose-trace",
        action="store_true",
        default=False,
        help="Enable verbose tracing from the plugin itself."
        "This can be useful to debug finding dead variable.")
    group.add_argument(
        "--no-allowlist",
        action="store_true",
        default=True,
        dest="allowlist",
        help="When building gcsuspects allowlist certain functions as if they can be "
        "causing GC. Currently used to reduce number of false positives in dead "
        "variables analysis. See TODO for ALLOWLIST in gcmole.py")
    group.add_argument(
        "--test-run",
        action="store_true",
        default=False,
        help="Test gcmole on tools/gcmole/gcmole-test.cc")

  parser = argparse.ArgumentParser()
  subps = parser.add_subparsers()

  subp = subps.add_parser(
      "full", description="Run both gcmole analysis passes.")
  add_common_args(subp)
  subp.set_defaults(func=full_run)

  subp = subps.add_parser(
      "collect",
      description="Construct call graph from source files. "
                  "The action can be distributed using --shard-count and "
                  "--shard-index.")
  add_common_args(subp)
  subp.set_defaults(func=collect_run)
  subp.add_argument(
      "--output",
      required=True,
      help="Path to a file where to store the constructed call graph")

  subp = subps.add_parser(
      "merge",
      description="Merge partial call graphs and propagate gc suspects.")
  add_common_args(subp)
  subp.set_defaults(func=merge_run)
  subp.add_argument(
      "--input",
      action='append',
      required=True,
      help="Path to a file containing a partial call graph stored by "
           "'collect'. Repeat for multiple files.")

  subp = subps.add_parser(
      "check",
      description="Check for problems using previously collected gc-suspect "
                  "information. The action can be distributed using "
                  "--shard-count and --shard-index.")
  add_common_args(subp)
  subp.set_defaults(func=check_run)

  options = parser.parse_args(argv[1:])

  verify_and_convert_dirs(parser, options, default_gcmole_dir,
                          default_clang_bin_dir)
  verify_clang_plugin(parser, options)
  prepare_gcmole_files(options)
  verify_build_config(parser, options)
  override_env_options(options)

  options.func(options)


@contextmanager
def maybe_redirect_stderr(options):
  file_io = io.StringIO() if options.test_run else sys.stderr
  with redirect_stderr(file_io) as f:
    yield f


def check_files(options, files):
  with maybe_redirect_stderr(options) as file_io:
    errors_found = check_correctness_for_arch(files, options)
  sys.exit(has_unexpected_errors(options, errors_found, file_io))


def full_run(options):
  check_files(options, generate_gc_suspects_from_files(options))


def collect_run(options):
  files = build_file_list(options)
  callgraph = generate_callgraph(files, options)
  callgraph.to_file(options.output)


def merge_run(options):
  generate_gc_suspects_from_callgraph(
      CallGraph.from_files(*options.input), options)


def check_run(options):
  check_files(options, build_file_list(options))


def verify_and_convert_dirs(parser, options, default_tools_gcmole_dir,
                            default_clang_bin_dir):
  # Verify options for setting directors and convert the input strings to Path
  # objects.
  options.v8_root_dir = Path(options.v8_root_dir)

  if not options.clang_bin_dir:
    # Backwards compatibility
    if os.getenv("CLANG_BIN"):
      options.clang_bin_dir = Path(os.getenv("CLANG_BIN"))
      options.is_bot = True
    else:
      options.clang_bin_dir = default_clang_bin_dir
      if not (options.clang_bin_dir / 'clang++').exists():
        options.clang_bin_dir = Path(options.v8_root_dir,
                                     "tools/gcmole/bootstrap/build/bin")
    log("Using --clang-bin-dir={}", options.clang_bin_dir)
  else:
    options.clang_bin_dir = Path(options.clang_bin_dir)

  if not options.clang_plugins_dir:
    # Backwards compatibility
    if os.getenv("CLANG_PLUGINS"):
      options.clang_plugins_dir = Path(os.getenv("CLANG_PLUGINS"))
    else:
      options.clang_plugins_dir = default_tools_gcmole_dir.resolve()
    log("Using --clang-plugins-dir={}", options.clang_plugins_dir)
  else:
    options.clang_plugins_dir = Path(options.clang_plugins_dir)

  if not options.v8_build_dir:
    config = ARCHITECTURES[options.v8_target_cpu]
    options.v8_build_dir = options.v8_root_dir / ('out/%s.release' %
                                                  config.name)
    # Fallback for build bots.
    if not options.v8_build_dir.exists() and os.getenv("CLANG_BIN"):
      options.v8_build_dir = options.v8_root_dir / 'out/build'
    log("Using --v8-build-dir={}", options.v8_build_dir)
  else:
    options.v8_build_dir = Path(options.v8_build_dir)

  if not options.out_dir:
    options.out_dir = options.v8_build_dir / 'gen/tools/gcmole'
    if options.v8_build_dir.exists():
      options.out_dir.mkdir(parents=True, exist_ok=True)
  else:
    options.out_dir = Path(options.out_dir)

  for flag, path in [
      ("--v8-root-dir", options.v8_root_dir),
      ("--v8-build-dir", options.v8_build_dir),
      ("--clang-bin-dir", options.clang_bin_dir),
      ("--clang-plugins-dir", options.clang_plugins_dir),
      ("--out-dir", options.out_dir),
  ]:
    if not path.is_dir():
      parser.error(f"{flag}='{path}' does not exist!")


def verify_clang_plugin(parser, options):
  libgcmole_path = options.clang_plugins_dir / "libgcmole.so"
  if not libgcmole_path.is_file():
    parser.error("'{}' does not exist. Please build gcmole first.".format(
        libgcmole_path))
  clang_path = options.clang_bin_dir / "clang++"
  if not clang_path.is_file():
    parser.error(
        "'{}' does not exist. Please build gcmole first.".format(clang_path))


def prepare_gcmole_files(options):
  cmd = [
      "ninja", "-C", options.v8_build_dir, "v8_gcmole_files",
      "v8_dump_build_config"
  ]
  cmd = list(map(str, cmd))
  log("Preparing files: {}", " ".join(cmd))
  try:
    subprocess.check_call(cmd)
  except:
    # Ignore ninja task errors on the bots
    if options.is_bot:
      log("Ninja command failed, ignoring errors.")
    else:
      raise


def verify_build_config(parser, options):
  if options.is_bot:
    #TODO(cbruni): Fix, currently not supported on the bots
    return
  config_file = options.v8_build_dir / 'v8_build_config.json'
  with open(config_file) as f:
    config = json.load(f)
  found_cpu = None
  for key in ('v8_target_cpu', 'target_cpu', 'current_cpu'):
    found_cpu = config.get('v8_target_cpu')
    if found_cpu == options.v8_target_cpu:
      return
  parser.error("Build dir '{}' config doesn't match request cpu. {}: {}".format(
      options.v8_build_dir, options.v8_target_cpu, found_cpu))


def override_env_options(options):
  """Set shard options if passed as gtest environment vars on bots."""
  options.shard_count = int(
    os.environ.get('GTEST_TOTAL_SHARDS', options.shard_count))
  options.shard_index = int(
    os.environ.get('GTEST_SHARD_INDEX', options.shard_index))


if __name__ == "__main__":
  main(sys.argv)
                                                                                                                                                                                                                                                                                                                                                       node-23.7.0/deps/v8/tools/gcmole/gcmole_args.py                                                     0000664 0000000 0000000 00000003521 14746647661 0021310 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # Copyright 2023 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.
"""Calculate arguments for the gcmole plugin based on flags passed to the
compiler for a typical target in V8.
"""

from pathlib import Path

import os
import re
import sys

DEFINES_RE = re.compile(r'^defines = (.*)$', re.M)
INCLUDES_RE = re.compile(r'^include_dirs = (.*)$', re.M)

BASE_DIR = Path(__file__).resolve().parents[2].absolute()

# This script is always called relative to the build directory root
# by ninja.
BUILD_DIR_ABS = Path.cwd()
BUILD_DIR_REL = BUILD_DIR_ABS.relative_to(BASE_DIR)


def search_flags(regexp, ninja_config):
  match = regexp.search(ninja_config)
  assert match
  result = match.group(1)
  assert result
  return result


def main():
  assert len(sys.argv) == 2, 'Expecting sysroot arg'
  gn_sysroot_var = sys.argv[1]
  assert gn_sysroot_var.startswith('//'), 'Expecting root-dir gn path'
  rel_sysroot = gn_sysroot_var[len('//'):]

  assert BUILD_DIR_ABS.exists()

  ninja_file = BUILD_DIR_ABS / 'obj' / 'v8_base_without_compiler.ninja'
  assert ninja_file.exists()

  with ninja_file.open() as f:
    ninja_config = f.read()

  defines = search_flags(DEFINES_RE, ninja_config)
  includes = search_flags(INCLUDES_RE, ninja_config)

  # Include flags are relative to the build root. Make them relative to the
  # base directory for gcmole.
  # E.g. BUILD_DIR_REL = out/build and -I../../include gives -Iinclude.
  include_flags = []
  for flag in includes.strip().split():
    prefix, suffix = flag[:2], flag[2:]
    assert prefix == '-I'
    include_flags.append(prefix + os.path.normpath(BUILD_DIR_REL / suffix))

  with open('v8_gcmole.args', 'w') as f:
    f.write(' '.join([defines] + include_flags + [f'--sysroot={rel_sysroot}']))


if __name__ == '__main__':
  main()
                                                                                                                                                                               node-23.7.0/deps/v8/tools/gcmole/gcmole_test.py                                                     0000664 0000000 0000000 00000033030 14746647661 0021331 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3
# Copyright 2022 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

from pathlib import Path

import collections
import os
import re
import shutil
import subprocess
import sys
import tempfile
import textwrap
import unittest

import gcmole

GCMOLE_PATH = Path(__file__).parent.absolute()
TESTDATA_PATH = GCMOLE_PATH / 'testdata' / 'v8'

Options = collections.namedtuple(
    'Options', ['v8_root_dir', 'v8_target_cpu', 'shard_count', 'shard_index',
                'test_run'])


def abs_test_file(f):
  return TESTDATA_PATH / f


class FilesTest(unittest.TestCase):

  def testFileList_for_testing(self):
    options = Options(TESTDATA_PATH, 'x64', 1, 0, True)
    self.assertEqual(
        gcmole.build_file_list(options),
        list(map(abs_test_file, ['tools/gcmole/gcmole-test.cc'])))

  def testFileList_x64(self):
    options = Options(TESTDATA_PATH, 'x64', 1, 0, False)
    expected = [
        'file1.cc',
        'file2.cc',
        'x64/file1.cc',
        'x64/file2.cc',
        'file3.cc',
        'file4.cc',
        'test/cctest/test-x64-file1.cc',
        'test/cctest/test-x64-file2.cc',
    ]
    self.assertEqual(
        gcmole.build_file_list(options),
        list(map(abs_test_file, expected)))

  def testFileList_x64_shard0(self):
    options = Options(TESTDATA_PATH, 'x64', 2, 0, False)
    expected = [
        'file1.cc',
        'x64/file1.cc',
        'file3.cc',
        'test/cctest/test-x64-file1.cc',
    ]
    self.assertEqual(
        gcmole.build_file_list(options),
        list(map(abs_test_file, expected)))

  def testFileList_x64_shard1(self):
    options = Options(TESTDATA_PATH, 'x64', 2, 1, False)
    expected = [
        'file2.cc',
        'x64/file2.cc',
        'file4.cc',
        'test/cctest/test-x64-file2.cc',
    ]
    self.assertEqual(
        gcmole.build_file_list(options),
        list(map(abs_test_file, expected)))

  def testFileList_arm(self):
    options = Options(TESTDATA_PATH, 'arm', 1, 0, False)
    expected = [
        'file1.cc',
        'file2.cc',
        'file3.cc',
        'file4.cc',
        'arm/file1.cc',
        'arm/file2.cc',
    ]
    self.assertEqual(
        gcmole.build_file_list(options),
        list(map(abs_test_file, expected)))


GC = 'Foo,NowCollectAllTheGarbage'
SP = 'Bar,SafepointSlowPath'
WF = 'Baz,WriteField'


class OutputLines:
  CALLERS_RE = re.compile(r'([\w,]+)\s*\s*(.*)')

  def __init__(self, *callee_list):
    """Construct a test data placeholder for output lines of one invocation of
    the GCMole plugin.

    Args:
        callee_list: Strings, each containing a caller/calle relationship
            formatted as "A  B C", meaning A calls B and C. For GC,
            Safepoint and a allow-listed function use GC, SP and WF
            constants above respectivly.
            Methods not calling anything are formatted as "A ".
    """
    self.callee_list = callee_list

  def lines(self):
    result = []
    for str_rep in self.callee_list:
      match = self.CALLERS_RE.match(str_rep)
      assert match
      result.append(match.group(1))
      for callee in (match.group(2) or '').split():
        result.append('\t' + callee)
    return result


class SuspectCollectorTest(unittest.TestCase):

  def create_callgraph(self, *outputs):
    call_graph = gcmole.CallGraph()
    for output in outputs:
      call_graph.parse(output.lines())
    return call_graph

  def testCallGraph(self):
    call_graph = self.create_callgraph(OutputLines())
    self.assertDictEqual(call_graph.funcs, {})

    call_graph = self.create_callgraph(OutputLines('A '))
    self.assertDictEqual(call_graph.funcs, {'A': set()})

    call_graph = self.create_callgraph(OutputLines('A  B'))
    self.assertDictEqual(call_graph.funcs, {'A': set(), 'B': set('A')})

    call_graph = self.create_callgraph(
        OutputLines('A  B C', 'B  C D', 'D '))
    self.assertDictEqual(
        call_graph.funcs,
        {'A': set(), 'B': set('A'), 'C': set(['A', 'B']), 'D': set('B')})

    call_graph = self.create_callgraph(
        OutputLines('B  C D', 'D '), OutputLines('A  B C'))
    self.assertDictEqual(
        call_graph.funcs,
        {'A': set(), 'B': set('A'), 'C': set(['A', 'B']), 'D': set('B')})

  def testCallGraphMerge(self):
    """Test serializing, deserializing and merging call graphs."""
    temp_dir = Path(tempfile.mkdtemp('gcmole_test'))

    call_graph1 = self.create_callgraph(
        OutputLines('B  C D E', 'D '), OutputLines('A  B C'))
    self.assertDictEqual(
        call_graph1.funcs,
        {'A': set(), 'B': set('A'), 'C': set(['A', 'B']), 'D': set('B'),
         'E': set('B')})

    call_graph2 = self.create_callgraph(
        OutputLines('E  A'), OutputLines('C  D F'))
    self.assertDictEqual(
        call_graph2.funcs,
        {'A': set('E'), 'C': set(), 'D': set('C'), 'E': set(), 'F': set('C')})

    file1 = temp_dir / 'file1.bin'
    file2 = temp_dir / 'file2.bin'
    call_graph1.to_file(file1)
    call_graph2.to_file(file2)

    expected = {'A': set(['E']), 'B': set('A'), 'C': set(['A', 'B']),
                'D': set(['B', 'C']), 'E': set(['B']), 'F': set(['C'])}

    call_graph = gcmole.CallGraph.from_files(file1, file2)
    self.assertDictEqual(call_graph.funcs, expected)

    call_graph = gcmole.CallGraph.from_files(file2, file1)
    self.assertDictEqual(call_graph.funcs, expected)

    call_graph3 = self.create_callgraph(
        OutputLines('F  G'), OutputLines('G '))
    self.assertDictEqual(
        call_graph3.funcs,
        {'G': set('F'), 'F': set()})

    file3 = temp_dir / 'file3.bin'
    call_graph3.to_file(file3)

    call_graph = gcmole.CallGraph.from_files(file1, file2, file3)
    self.assertDictEqual(call_graph.funcs, dict(G=set('F'), **expected))

  def create_collector(self, outputs):
    Options = collections.namedtuple('OptionsForCollector', ['allowlist'])
    options = Options(True)
    call_graph = self.create_callgraph(*outputs)
    collector = gcmole.GCSuspectsCollector(options, call_graph.funcs)
    collector.propagate()
    return collector

  def check(self, outputs, expected_gc, expected_gc_caused):
    """Verify the GCSuspectsCollector propagation and outputs against test
    data.

    Args:
      outputs: List of OutputLines object simulating the lines returned by
          the GCMole plugin in drop-callees mode. Each output lines object
          represents one plugin invocation.
      expected_gc: Mapping as expected by GCSuspectsCollector.gc.
      expected_gc_caused: Mapping as expected by GCSuspectsCollector.gc_caused.
    """
    collector = self.create_collector(outputs)
    self.assertDictEqual(collector.gc, expected_gc)
    self.assertDictEqual(collector.gc_caused, expected_gc_caused)

  def testNoGC(self):
    self.check(
        outputs=[OutputLines()],
        expected_gc={},
        expected_gc_caused={},
    )
    self.check(
        outputs=[OutputLines('A ')],
        expected_gc={},
        expected_gc_caused={},
    )
    self.check(
        outputs=[OutputLines('A ', 'B ')],
        expected_gc={},
        expected_gc_caused={},
    )
    self.check(
        outputs=[OutputLines('A  B C')],
        expected_gc={},
        expected_gc_caused={},
    )
    self.check(
        outputs=[OutputLines('A  B', 'B  C')],
        expected_gc={},
        expected_gc_caused={},
    )
    self.check(
        outputs=[OutputLines('A  B C', 'B  D', 'D  A', 'C ')],
        expected_gc={},
        expected_gc_caused={},
    )
    self.check(
        outputs=[OutputLines('A '), OutputLines('B ')],
        expected_gc={},
        expected_gc_caused={},
    )
    self.check(
        outputs=[OutputLines('A  B'), OutputLines('B  C')],
        expected_gc={},
        expected_gc_caused={},
    )
    self.check(
        outputs=[OutputLines('A  B C'),
                 OutputLines('B  D', 'D  A'),
                 OutputLines('C ')],
        expected_gc={},
        expected_gc_caused={},
    )

  def testGCOneFile(self):
    self.check(
        outputs=[OutputLines(f'{GC} ')],
        expected_gc={GC: True},
        expected_gc_caused={GC: {'<GC>'}},
    )
    self.check(
        outputs=[OutputLines(f'A  {GC}')],
        expected_gc={GC: True, 'A': True},
        expected_gc_caused={'A': {GC}, GC: {'<GC>'}},
    )
    self.check(
        outputs=[OutputLines(f'A  {GC}', 'B  A')],
        expected_gc={GC: True, 'A': True, 'B': True},
        expected_gc_caused={'B': {'A'}, 'A': {GC}, GC: {'<GC>'}},
    )
    self.check(
        outputs=[OutputLines('B  A', f'A  {GC}')],
        expected_gc={GC: True, 'A': True, 'B': True},
        expected_gc_caused={'B': {'A'}, 'A': {GC}, GC: {'<GC>'}},
    )
    self.check(
        outputs=[OutputLines(f'A  B {GC}', 'B ', 'C  B A')],
        expected_gc={GC: True, 'A': True, 'C': True},
        expected_gc_caused={'C': {'A'}, 'A': {GC}, GC: {'<GC>'}},
    )
    self.check(
        outputs=[OutputLines(f'A  {GC}', 'B  A', 'C  A', 'D  B C')],
        expected_gc={GC: True, 'A': True, 'B': True, 'C': True, 'D': True},
        expected_gc_caused={'C': {'A'}, 'A': {GC}, 'B': {'A'}, 'D': {'B', 'C'},
                            GC: {'<GC>'}},
    )

  def testAllowListOneFile(self):
    self.check(
        outputs=[OutputLines(f'{WF} ')],
        expected_gc={WF: False},
        expected_gc_caused={},
    )
    self.check(
        outputs=[OutputLines(f'{WF}  {GC}')],
        expected_gc={GC: True, WF: False},
        expected_gc_caused={WF: {GC}, GC: {'<GC>'}},
    )
    self.check(
        outputs=[OutputLines(f'A  {GC}', f'{WF}  A B', 'D  A B',
                             f'E  {WF}')],
        expected_gc={GC: True, WF: False, 'A': True, 'D': True},
        expected_gc_caused={'A': {GC}, WF: {'A'}, 'D': {'A'}, GC: {'<GC>'}},
    )

  def testSafepointOneFile(self):
    self.check(
        outputs=[OutputLines(f'{SP} ')],
        expected_gc={SP: True},
        expected_gc_caused={SP: {'<Safepoint>'}},
    )
    self.check(
        outputs=[OutputLines('B  A', f'A  {SP}')],
        expected_gc={SP: True, 'A': True, 'B': True},
        expected_gc_caused={'B': {'A'}, 'A': {SP}, SP: {'<Safepoint>'}},
    )

  def testCombinedOneFile(self):
    self.check(
        outputs=[OutputLines(f'{GC} ', f'{SP} ')],
        expected_gc={SP: True, GC: True},
        expected_gc_caused={SP: {'<Safepoint>'}, GC: {'<GC>'}},
    )
    self.check(
        outputs=[OutputLines(f'A  {GC}', f'B  {SP}')],
        expected_gc={GC: True, SP: True, 'A': True, 'B': True},
        expected_gc_caused={'B': {SP}, 'A': {GC}, SP: {'<Safepoint>'},
                            GC: {'<GC>'}},
    )
    self.check(
        outputs=[OutputLines(f'A  {GC}', f'B  {SP}', 'C  D A B')],
        expected_gc={GC: True, SP: True, 'A': True, 'B': True, 'C': True},
        expected_gc_caused={'B': {SP}, 'A': {GC}, 'C': {'A', 'B'},
                            SP: {'<Safepoint>'}, GC: {'<GC>'}},
    )

  def testCombinedMoreFiles(self):
    self.check(
        outputs=[OutputLines(f'A  {GC}'), OutputLines(f'B  {SP}')],
        expected_gc={GC: True, SP: True, 'A': True, 'B': True},
        expected_gc_caused={'B': {SP}, 'A': {GC}, SP: {'<Safepoint>'},
                            GC: {'<GC>'}},
    )
    self.check(
        outputs=[OutputLines(f'A  {GC}'), OutputLines(f'B  {SP}'),
                 OutputLines('C  D A B')],
        expected_gc={GC: True, SP: True, 'A': True, 'B': True, 'C': True},
        expected_gc_caused={'B': {SP}, 'A': {GC}, 'C': {'A', 'B'},
                            SP: {'<Safepoint>'}, GC: {'<GC>'}},
    )

  def testWriteGCMoleResults(self):
    temp_dir = Path(tempfile.mkdtemp('gcmole_test'))
    Options = collections.namedtuple('OptionsForWriting', ['v8_target_cpu'])
    collector = self.create_collector(
        [OutputLines(f'A  {GC}'), OutputLines(f'B  {SP}')])
    gcmole.write_gcmole_results(collector, Options('x64'), temp_dir)

    gcsuspects_expected = textwrap.dedent(f"""\
      {GC}
      {SP}
      A
      B
    """)

    with open(temp_dir / 'gcsuspects') as f:
      self.assertEqual(f.read(), gcsuspects_expected)

    gccauses_expected = textwrap.dedent(f"""
      {GC}
      start,nested
      <GC>
      end,nested
      {SP}
      start,nested
      <Safepoint>
      end,nested
      A
      start,nested
      {GC}
      end,nested
      B
      start,nested
      {SP}
      end,nested
    """).strip()

    with open(temp_dir / 'gccauses') as f:
      self.assertEqual(f.read().strip(), gccauses_expected)


class ArgsTest(unittest.TestCase):

  def testArgs(self):
    """Test argument retrieval using a fake v8 file system and build dir."""
    with tempfile.TemporaryDirectory('gcmole_args_test') as temp_dir:
      temp_dir = Path(temp_dir)
      temp_out = temp_dir / 'out'
      temp_gcmole = temp_dir / 'tools' / 'gcmole' / 'gcmole_args.py'

      shutil.copytree(abs_test_file('out'), temp_out)
      os.makedirs(temp_gcmole.parent)
      shutil.copy(GCMOLE_PATH / 'gcmole_args.py', temp_gcmole)

      # Simulate a ninja call relative to the build dir.
      gn_sysroot = '//build/linux/debian_bullseye_amd64-sysroot'
      subprocess.check_call(
          [sys.executable, temp_gcmole, gn_sysroot], cwd=temp_out)

      with open(temp_dir / 'out' / 'v8_gcmole.args') as f:
        self.assertEqual(f.read().split(), [
            '-DUSE_GLIB=1', '-DV8_TARGET_ARCH_X64', '-I.', '-Iout/gen',
            '-Iinclude', '-Iout/gen/include',
            '--sysroot=build/linux/debian_bullseye_amd64-sysroot',
        ])


if __name__ == '__main__':
  unittest.main()
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        node-23.7.0/deps/v8/tools/gcmole/ignored_files                                                      0000664 0000000 0000000 00000000101 14746647661 0021177 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        src/profiler/heap-snapshot-generator.cc
src/execution/isolate.cc
                                                                                                                                                                                                                                                                                                                                                                                                                                                               node-23.7.0/deps/v8/tools/gcmole/package.sh                                                         0000775 0000000 0000000 00000005010 14746647661 0020401 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env bash

# Copyright 2019 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

# This script will package a built gcmole plugin together with the
# corresponding clang binary into an archive which can be used on the
# buildbot infrastructure to be run against V8 checkouts.

THIS_DIR="$(readlink -f "$(dirname "${0}")")"

PACKAGE_DIR="${THIS_DIR}/gcmole-tools"
PACKAGE_FILE="${THIS_DIR}/gcmole-tools.tar.gz"
PACKAGE_SUM="${THIS_DIR}/gcmole-tools.tar.gz.sha1"
BUILD_DIR="${THIS_DIR}/bootstrap/build"
V8_ROOT_DIR= `realpath "${THIS_DIR}/../.."`

# Echo all commands
set -x

# Clean out any old files
if [ -e "${PACKAGE_DIR:?}/bin" ] ; then
  rm -rf "${PACKAGE_DIR:?}/bin"
fi
if [ -e "${PACKAGE_DIR:?}/lib" ] ; then
  rm -rf "${PACKAGE_DIR:?}/lib"
fi

# Copy all required files
mkdir -p "${PACKAGE_DIR}/bin"
cp "${BUILD_DIR}/bin/clang++" "${PACKAGE_DIR}/bin"
mkdir -p "${PACKAGE_DIR}/lib"
cp -r "${BUILD_DIR}/lib/clang" "${PACKAGE_DIR}/lib"
cp "${THIS_DIR}/libgcmole.so" "${PACKAGE_DIR}"

# Generate the archive. Set some flags on tar to make the output more
# deterministic (e.g. not dependent on timestamps).
cd "$(dirname "${PACKAGE_DIR}")"
tar \
  --sort=name \
  --owner=root:0 \
  --group=root:0 \
  --mtime="UTC 1970-01-01" \
  --create \
  "$(basename "${PACKAGE_DIR}")" | gzip --no-name >"${PACKAGE_FILE}"

# Generate checksum
sha1sum "${PACKAGE_FILE}" | awk '{print $1}' > "${PACKAGE_SUM}"

set +x

echo
echo You can find a packaged version of gcmole here:
echo
echo $(readlink -f "${PACKAGE_FILE}")
echo
echo Upload the update package to the chrome infra:
echo
echo 'gsutil.py cp tools/gcmole/gcmole-tools.tar.gz gs://chrome-v8-gcmole/$(cat tools/gcmole/gcmole-tools.tar.gz.sha1)'
echo
echo Run bootstrap.sh in chroot if glibc versions mismatch with bots:
echo '# Create chroot'
echo 'mkdir -p $CHROOT_DIR'
echo 'sudo debootstrap $DEBIAN_VERSION $CHROOT_DIR'
echo 'sudo chroot $CHROOT_DIR apt install g++ cmake python git'
echo '# Mount ./depot_tools and ./v8 dirs in the chroot:'
echo 'sudo chroot $CHROOT_DIR mkdir /docs'
echo 'sudo mount --bind /path/to/workspace /docs'
echo '# Build gcmole'
echo "sudo chroot \$CHROOT_DIR bash -c 'PATH=/docs/depot_tools:\$PATH; /docs/v8/v8/tools/gcmole/bootstrap.sh'"
echo
echo You can now run gcmole using this command:
echo
echo 'tools/gcmole/gcmole.py \'
echo '   --clang-bin-dir="tools/gcmole/gcmole-tools/bin" \'
echo '   --clang-plugins-dir="tools/gcmole/gcmole-tools" \'
echo '   --v8-target-cpu=$CPU'
echo
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        node-23.7.0/deps/v8/tools/gcmole/run-gcmole.py                                                      0000775 0000000 0000000 00000003447 14746647661 0021110 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3
# Copyright 2016 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

import os
import os.path
import signal
import subprocess
import sys

GCMOLE_PATH = os.path.dirname(os.path.abspath(__file__))
CLANG_BIN = os.path.join(GCMOLE_PATH, 'gcmole-tools', 'bin')
CLANG_PLUGINS = os.path.join(GCMOLE_PATH, 'gcmole-tools')
GCMOLE_PY = os.path.join(GCMOLE_PATH, 'gcmole.py')
V8_ROOT_DIR = os.path.dirname(os.path.dirname(GCMOLE_PATH))


def print_help():
  print(
      """Usage: ./run-gcmole.py [MODE] V8_TARGET_CPU [gcmole.py OPTION]...

Helper script to run gcmole.py on the bots.""")

args = sys.argv[1:]
if "--help" in args:
  print_help()
  exit(0)


# Different modes of running gcmole. Optional to stay backwards-compatible.
mode = 'full'
if args and args[0] in ['check', 'collect', 'full', 'merge']:
  mode = args[0]
  args = args[1:]


if not args:
  print("Missing arguments!")
  print_help()
  exit(1)


if not os.path.isfile("out/build/gen/torque-generated/builtin-definitions.h"):
  print("Expected generated headers in out/build/gen.")
  print("Either build v8 in out/build or change the 'out/build/gen' location in gcmole.py")
  sys.exit(-1)

gcmole_py_options = args[1:]
proc = subprocess.Popen(
    [
        sys.executable,
        GCMOLE_PY,
        mode,
        "--v8-build-dir=%s" % os.path.join(V8_ROOT_DIR, 'out', 'build'),
        "--v8-target-cpu=%s" % args[0],
        "--clang-plugins-dir=%s" % CLANG_PLUGINS,
        "--clang-bin-dir=%s" % CLANG_BIN,
        "--is-bot",
    ] + gcmole_py_options,
    cwd=V8_ROOT_DIR,
)

def handle_sigterm(*args):
  try:
    proc.kill()
  except OSError:
    pass

signal.signal(signal.SIGTERM, handle_sigterm)

proc.communicate()
sys.exit(proc.returncode)
                                                                                                                                                                                                                         node-23.7.0/deps/v8/tools/gcmole/suspects.allowlist                                                 0000664 0000000 0000000 00000000111 14746647661 0022251 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        IsConstructor
IsEval
IsAsync
IsPromiseAll
IsPromiseAny
VisitRootPointers
                                                                                                                                                                                                                                                                                                                                                                                                                                                       node-23.7.0/deps/v8/tools/gcmole/test-expectations.txt                                              0000664 0000000 0000000 00000022126 14746647661 0022702 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        tools/gcmole/gcmole-test.cc:30:10: warning: Possibly stale variable due to GCs.
  return obj;
         ^
tools/gcmole/gcmole-test.cc:28:20: note: Call might cause unexpected GC.
  isolate->heap()->CollectGarbage(OLD_SPACE, GarbageCollectionReason::kTesting);
                   ^
./src/heap/heap.h:<number>:<number>: note: GC call here.
  V8_EXPORT_PRIVATE void CollectGarbage(
                    ^
tools/gcmole/gcmole-test.cc:48:3: warning: Possible problem with evaluation order with interleaved GCs.
  TwoArgumentsFunction(*CauseGC(obj1, isolate), *CauseGC(obj2, isolate));
  ^
tools/gcmole/gcmole-test.cc:48:25: note: Call might cause unexpected GC.
  TwoArgumentsFunction(*CauseGC(obj1, isolate), *CauseGC(obj2, isolate));
                        ^
tools/gcmole/gcmole-test.cc:21:1: note: GC call here.
Handle<Object> CauseGC(Handle<Object> obj, Isolate* isolate) {
^
tools/gcmole/gcmole-test.cc:60:3: warning: Possible problem with evaluation order with interleaved GCs.
  TwoSizeTArgumentsFunction(sizeof(*CauseGC(obj1, isolate)),
  ^
tools/gcmole/gcmole-test.cc:60:37: note: Call might cause unexpected GC.
  TwoSizeTArgumentsFunction(sizeof(*CauseGC(obj1, isolate)),
                                    ^
tools/gcmole/gcmole-test.cc:21:1: note: GC call here.
Handle<Object> CauseGC(Handle<Object> obj, Isolate* isolate) {
^
tools/gcmole/gcmole-test.cc:78:7: warning: Possible problem with evaluation order with interleaved GCs.
  so->Method(*CauseGC(obj1, isolate));
      ^
tools/gcmole/gcmole-test.cc:78:15: note: Call might cause unexpected GC.
  so->Method(*CauseGC(obj1, isolate));
              ^
tools/gcmole/gcmole-test.cc:21:1: note: GC call here.
Handle<Object> CauseGC(Handle<Object> obj, Isolate* isolate) {
^
tools/gcmole/gcmole-test.cc:80:7: warning: Possible problem with evaluation order with interleaved GCs.
  so->Method(CauseGCRaw(*obj1, isolate));
      ^
tools/gcmole/gcmole-test.cc:78:15: note: Call might cause unexpected GC.
  so->Method(*CauseGC(obj1, isolate));
              ^
tools/gcmole/gcmole-test.cc:21:1: note: GC call here.
Handle<Object> CauseGC(Handle<Object> obj, Isolate* isolate) {
^
tools/gcmole/gcmole-test.cc:124:14: warning: Possible problem with evaluation order with interleaved GCs.
  so_handle->Method(*derived.VirtualCauseGC(obj1, isolate));
             ^
tools/gcmole/gcmole-test.cc:124:30: note: Call might cause unexpected GC.
  so_handle->Method(*derived.VirtualCauseGC(obj1, isolate));
                             ^
tools/gcmole/gcmole-test.cc:108:3: note: GC call here.
  Handle<Object> VirtualCauseGC(Handle<Object> obj, Isolate* isolate) override {
  ^
tools/gcmole/gcmole-test.cc:126:14: warning: Possible problem with evaluation order with interleaved GCs.
  so_handle->Method(*base->VirtualCauseGC(obj1, isolate));
             ^
tools/gcmole/gcmole-test.cc:124:30: note: Call might cause unexpected GC.
  so_handle->Method(*derived.VirtualCauseGC(obj1, isolate));
                             ^
tools/gcmole/gcmole-test.cc:108:3: note: GC call here.
  Handle<Object> VirtualCauseGC(Handle<Object> obj, Isolate* isolate) override {
  ^
tools/gcmole/gcmole-test.cc:147:14: warning: Possible problem with evaluation order with interleaved GCs.
  so_handle->Method(*SomeClass::StaticCauseGC(obj1, isolate));
             ^
tools/gcmole/gcmole-test.cc:147:22: note: Call might cause unexpected GC.
  so_handle->Method(*SomeClass::StaticCauseGC(obj1, isolate));
                     ^
tools/gcmole/gcmole-test.cc:133:3: note: GC call here.
  static Handle<Object> StaticCauseGC(Handle<Object> obj, Isolate* isolate) {
  ^
tools/gcmole/gcmole-test.cc:157:9: warning: Possibly stale variable due to GCs.
  Print(raw_obj);
        ^
tools/gcmole/gcmole-test.cc:154:3: note: Call might cause unexpected GC.
  CauseGCRaw(raw_obj, isolate);
  ^
tools/gcmole/gcmole-test.cc:27:1: note: GC call here.
Tagged<Object> CauseGCRaw(Tagged<Object> obj, Isolate* isolate) {
^
tools/gcmole/gcmole-test.cc:165:9: warning: Possibly stale variable due to GCs.
  Print(raw_obj);
        ^
tools/gcmole/gcmole-test.cc:162:3: note: Call might cause unexpected GC.
  Safepoint();
  ^
tools/gcmole/gcmole-test.cc:19:1: note: GC call here.
void Safepoint() { LocalHeap::Current()->Safepoint(); }
^
tools/gcmole/gcmole-test.cc:191:9: warning: Possibly stale variable due to GCs.
  Print(raw_obj);
        ^
tools/gcmole/gcmole-test.cc:188:3: note: Call might cause unexpected GC.
  CauseGCRaw(raw_obj, isolate);
  ^
tools/gcmole/gcmole-test.cc:27:1: note: GC call here.
Tagged<Object> CauseGCRaw(Tagged<Object> obj, Isolate* isolate) {
^
tools/gcmole/gcmole-test.cc:217:9: warning: Possibly stale variable due to GCs.
  Print(raw_obj);
        ^
tools/gcmole/gcmole-test.cc:214:3: note: Call might cause unexpected GC.
  Safepoint();
  ^
tools/gcmole/gcmole-test.cc:19:1: note: GC call here.
void Safepoint() { LocalHeap::Current()->Safepoint(); }
^
tools/gcmole/gcmole-test.cc:228:9: warning: Possibly stale variable due to GCs.
  Print(raw_obj);
        ^
tools/gcmole/gcmole-test.cc:226:3: note: Call might cause unexpected GC.
  Safepoint();
  ^
tools/gcmole/gcmole-test.cc:19:1: note: GC call here.
void Safepoint() { LocalHeap::Current()->Safepoint(); }
^
tools/gcmole/gcmole-test.cc:235:9: warning: Possibly stale variable due to GCs.
  Print(raw_obj);
        ^
tools/gcmole/gcmole-test.cc:226:3: note: Call might cause unexpected GC.
  Safepoint();
  ^
tools/gcmole/gcmole-test.cc:19:1: note: GC call here.
void Safepoint() { LocalHeap::Current()->Safepoint(); }
^
tools/gcmole/gcmole-test.cc:245:9: warning: Possibly stale variable due to GCs.
  Print(raw_obj);
        ^
tools/gcmole/gcmole-test.cc:243:3: note: Call might cause unexpected GC.
  CauseGCRaw(raw_obj, isolate);
  ^
tools/gcmole/gcmole-test.cc:27:1: note: GC call here.
Tagged<Object> CauseGCRaw(Tagged<Object> obj, Isolate* isolate) {
^
tools/gcmole/gcmole-test.cc:255:9: warning: Possibly stale variable due to GCs.
  Print(raw_obj);
        ^
tools/gcmole/gcmole-test.cc:253:3: note: Call might cause unexpected GC.
  CauseGCRaw(raw_obj, isolate);
  ^
tools/gcmole/gcmole-test.cc:27:1: note: GC call here.
Tagged<Object> CauseGCRaw(Tagged<Object> obj, Isolate* isolate) {
^
tools/gcmole/gcmole-test.cc:258:9: warning: Possibly stale variable due to GCs.
  Print(raw_obj);
        ^
tools/gcmole/gcmole-test.cc:253:3: note: Call might cause unexpected GC.
  CauseGCRaw(raw_obj, isolate);
  ^
tools/gcmole/gcmole-test.cc:27:1: note: GC call here.
Tagged<Object> CauseGCRaw(Tagged<Object> obj, Isolate* isolate) {
^
tools/gcmole/gcmole-test.cc:265:9: warning: Possibly stale variable due to GCs.
  Print(raw_obj);
        ^
tools/gcmole/gcmole-test.cc:263:3: note: Call might cause unexpected GC.
  CauseGCRaw(raw_obj, isolate);
  ^
tools/gcmole/gcmole-test.cc:27:1: note: GC call here.
Tagged<Object> CauseGCRaw(Tagged<Object> obj, Isolate* isolate) {
^
tools/gcmole/gcmole-test.cc:281:9: warning: Possibly stale variable due to GCs.
  Print(raw_obj);
        ^
tools/gcmole/gcmole-test.cc:279:3: note: Call might cause unexpected GC.
  TestGuardedDeadVarAnalysisNested(raw_obj, isolate);
  ^
tools/gcmole/gcmole-test.cc:261:1: note: GC call here.
void TestGuardedDeadVarAnalysisNested(Tagged<JSObject> raw_obj,
^
tools/gcmole/gcmole-test.cc:289:9: warning: Possibly stale variable due to GCs.
  Print(raw_obj);
        ^
tools/gcmole/gcmole-test.cc:287:3: note: Call might cause unexpected GC.
  TestGuardedDeadVarAnalysisNested(raw_obj, isolate);
  ^
tools/gcmole/gcmole-test.cc:261:1: note: GC call here.
void TestGuardedDeadVarAnalysisNested(Tagged<JSObject> raw_obj,
^
tools/gcmole/gcmole-test.cc:296:9: warning: Possibly stale variable due to GCs.
  Print(raw_obj);
        ^
tools/gcmole/gcmole-test.cc:294:3: note: Call might cause unexpected GC.
  TestGuardedDeadVarAnalysisNested(raw_obj, isolate);
  ^
tools/gcmole/gcmole-test.cc:261:1: note: GC call here.
void TestGuardedDeadVarAnalysisNested(Tagged<JSObject> raw_obj,
^
tools/gcmole/gcmole-test.cc:313:9: warning: Possibly stale variable due to GCs.
  Print(raw_obj);
        ^
tools/gcmole/gcmole-test.cc:311:3: note: Call might cause unexpected GC.
  CauseGCRaw(raw_obj, isolate);
  ^
tools/gcmole/gcmole-test.cc:27:1: note: GC call here.
Tagged<Object> CauseGCRaw(Tagged<Object> obj, Isolate* isolate) {
^
tools/gcmole/gcmole-test.cc:332:9: warning: Possibly stale variable due to GCs.
  Print(raw_obj);
        ^
tools/gcmole/gcmole-test.cc:328:3: note: Call might cause unexpected GC.
  CauseGCRaw(raw_obj, isolate);
  ^
tools/gcmole/gcmole-test.cc:27:1: note: GC call here.
Tagged<Object> CauseGCRaw(Tagged<Object> obj, Isolate* isolate) {
^
tools/gcmole/gcmole-test.cc:343:9: warning: Possibly stale variable due to GCs.
  Print(raw_obj);
        ^
tools/gcmole/gcmole-test.cc:339:3: note: Call might cause unexpected GC.
  CauseGCRaw(raw_obj, isolate);
  ^
tools/gcmole/gcmole-test.cc:27:1: note: GC call here.
Tagged<Object> CauseGCRaw(Tagged<Object> obj, Isolate* isolate) {
^
tools/gcmole/gcmole-test.cc:353:9: warning: Possibly stale variable due to GCs.
  Print(raw_obj);
        ^
tools/gcmole/gcmole-test.cc:349:3: note: Call might cause unexpected GC.
  Safepoint();
  ^
tools/gcmole/gcmole-test.cc:19:1: note: GC call here.
void Safepoint() { LocalHeap::Current()->Safepoint(); }
^
25 warnings generated.
                                                                                                                                                                                                                                                                                                                                                                                                                                          node-23.7.0/deps/v8/tools/gcmole/testdata/                                                          0000775 0000000 0000000 00000000000 14746647661 0020264 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/gcmole/testdata/v8/                                                       0000775 0000000 0000000 00000000000 14746647661 0020621 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/gcmole/testdata/v8/BUILD.gn                                               0000664 0000000 0000000 00000001103 14746647661 0022001 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # Copyright 2022 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

# Test data for gcmole.

some_sources = [
  ### gcmole(all) ###
  "file1.cc",
  "file1.h",
  "file2.cc",
]

other_sources = [
  ### gcmole(x64) ###
  "x64/file1.cc",
  "x64/file1.h",
  "x64/file2.cc",
]

yet_more_sources = [
  ### gcmole(all) ###
  "file3.cc",

  # Some other comment.
  "file4.cc",
  "file4.h",
]

the_last_sources = [
  ### gcmole(arm) ###
  "arm/file1.cc",
  "arm/file1.h",
  "arm/file2.cc",
]
                                                                                                                                                                                                                                                                                                                                                                                                                                                             node-23.7.0/deps/v8/tools/gcmole/testdata/v8/out/                                                   0000775 0000000 0000000 00000000000 14746647661 0021430 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/gcmole/testdata/v8/out/obj/                                               0000775 0000000 0000000 00000000000 14746647661 0022202 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/gcmole/testdata/v8/out/obj/v8_base_without_compiler.ninja                 0000664 0000000 0000000 00000000446 14746647661 0030233 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        defines = -DUSE_GLIB=1 -DV8_TARGET_ARCH_X64
include_dirs = -I.. -Igen -I../include -Igen/include
cflags = -Wall -Werror
cflags_cc = -isystem../../buildtools/third_party/libc++/trunk/include
label_name = v8_base_without_compiler
target_out_dir = obj
target_output_name = v8_base_without_compiler                                                                                                                                                                                                                          node-23.7.0/deps/v8/tools/gcmole/testdata/v8/test/                                                  0000775 0000000 0000000 00000000000 14746647661 0021600 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/gcmole/testdata/v8/test/cctest/                                           0000775 0000000 0000000 00000000000 14746647661 0023065 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/gcmole/testdata/v8/test/cctest/BUILD.gn                                   0000664 0000000 0000000 00000000453 14746647661 0024254 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # Copyright 2022 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

# Test data for gcmole.

some_sources = [
  ### gcmole(x64) ###
  "foo-x64-file1.cc",
  "test-x64-file1.cc",
  "test-x64-file2.cc",
]
                                                                                                                                                                                                                     node-23.7.0/deps/v8/tools/gdb-v8-support.py                                                         0000664 0000000 0000000 00000016134 14746647661 0020365 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # Copyright 2011 the V8 project authors. All rights reserved.
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are
# met:
#
#     * Redistributions of source code must retain the above copyright
#       notice, this list of conditions and the following disclaimer.
#     * Redistributions in binary form must reproduce the above
#       copyright notice, this list of conditions and the following
#       disclaimer in the documentation and/or other materials provided
#       with the distribution.
#     * Neither the name of Google Inc. nor the names of its
#       contributors may be used to endorse or promote products derived
#       from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

# for py2/py3 compatibility
from __future__ import print_function

import re
import tempfile
import os
import subprocess
import time
import gdb

kSmiTag = 0
kSmiTagSize = 1
kSmiTagMask = (1 << kSmiTagSize) - 1

kHeapObjectTag = 1
kHeapObjectTagSize = 2
kHeapObjectTagMask = (1 << kHeapObjectTagSize) - 1

kFailureTag = 3
kFailureTagSize = 2
kFailureTagMask = (1 << kFailureTagSize) - 1

kSmiShiftSize32 = 0
kSmiValueSize32 = 31
kSmiShiftBits32 = kSmiTagSize + kSmiShiftSize32

kSmiShiftSize64 = 31
kSmiValueSize64 = 32
kSmiShiftBits64 = kSmiTagSize + kSmiShiftSize64

kAllBits = 0xFFFFFFFF
kTopBit32 = 0x80000000
kTopBit64 = 0x8000000000000000

t_u32 = gdb.lookup_type('unsigned int')
t_u64 = gdb.lookup_type('unsigned long long')


def has_smi_tag(v):
  return v & kSmiTagMask == kSmiTag


def has_failure_tag(v):
  return v & kFailureTagMask == kFailureTag


def has_heap_object_tag(v):
  return v & kHeapObjectTagMask == kHeapObjectTag


def raw_heap_object(v):
  return v - kHeapObjectTag


def smi_to_int_32(v):
  v = v & kAllBits
  if (v & kTopBit32) == kTopBit32:
    return ((v & kAllBits) >> kSmiShiftBits32) - 2147483648
  else:
    return (v & kAllBits) >> kSmiShiftBits32


def smi_to_int_64(v):
  return (v >> kSmiShiftBits64)


def decode_v8_value(v, bitness):
  base_str = 'v8[%x]' % v
  if has_smi_tag(v):
    if bitness == 32:
      return base_str + (" SMI(%d)" % smi_to_int_32(v))
    else:
      return base_str + (" SMI(%d)" % smi_to_int_64(v))
  elif has_failure_tag(v):
    return base_str + " (failure)"
  elif has_heap_object_tag(v):
    return base_str + (" H(0x%x)" % raw_heap_object(v))
  else:
    return base_str


class V8ValuePrinter(object):
  "Print a v8value."

  def __init__(self, val):
    self.val = val

  def to_string(self):
    if self.val.type.sizeof == 4:
      v_u32 = self.val.cast(t_u32)
      return decode_v8_value(int(v_u32), 32)
    elif self.val.type.sizeof == 8:
      v_u64 = self.val.cast(t_u64)
      return decode_v8_value(int(v_u64), 64)
    else:
      return 'v8value?'

  def display_hint(self):
    return 'v8value'


def v8_pretty_printers(val):
  lookup_tag = val.type.tag
  if lookup_tag is None:
    return None
  elif lookup_tag == 'v8value':
    return V8ValuePrinter(val)
  return None


gdb.pretty_printers.append(v8_pretty_printers)


def v8_to_int(v):
  if v.type.sizeof == 4:
    return int(v.cast(t_u32))
  elif v.type.sizeof == 8:
    return int(v.cast(t_u64))
  else:
    return '?'


def v8_get_value(vstring):
  v = gdb.parse_and_eval(vstring)
  return v8_to_int(v)


class V8PrintObject(gdb.Command):
  """Prints a v8 object."""
  def __init__(self):
    super(V8PrintObject, self).__init__("v8print", gdb.COMMAND_DATA)

  def invoke(self, arg, from_tty):
    v = v8_get_value(arg)
    gdb.execute('call __gdb_print_v8_object(%d)' % v)


V8PrintObject()


class FindAnywhere(gdb.Command):
  """Search memory for the given pattern."""
  MAPPING_RE = re.compile(r"^\s*\[\d+\]\s+0x([0-9A-Fa-f]+)->0x([0-9A-Fa-f]+)")
  LIVE_MAPPING_RE = re.compile(r"^\s+0x([0-9A-Fa-f]+)\s+0x([0-9A-Fa-f]+)")

  def __init__(self):
    super(FindAnywhere, self).__init__("find-anywhere", gdb.COMMAND_DATA)

  def find(self, startAddr, endAddr, value):
    try:
      result = gdb.execute("find 0x%s, 0x%s, %s" % (startAddr, endAddr, value),
                           to_string=True)
      if result.find("not found") == -1:
        print(result)
    except:
      pass

  def invoke(self, value, from_tty):
    for l in gdb.execute("maint info sections", to_string=True).split('\n'):
      m = FindAnywhere.MAPPING_RE.match(l)
      if m is None:
        continue
      self.find(m.group(1), m.group(2), value)
    for l in gdb.execute("info proc mappings", to_string=True).split('\n'):
      m = FindAnywhere.LIVE_MAPPING_RE.match(l)
      if m is None:
        continue
      self.find(m.group(1), m.group(2), value)


FindAnywhere()


class Redirect(gdb.Command):
  """Redirect the subcommand's stdout  to a temporary file.

Usage:   redirect subcommand...
Example:
  redirect job 0x123456789
  redirect x/1024xg 0x12345678

If provided, the generated temporary file is directly openend with the
GDB_EXTERNAL_EDITOR environment variable.
  """
  def __init__(self):
    super(Redirect, self).__init__("redirect", gdb.COMMAND_USER)

  def invoke(self, subcommand, from_tty):
    old_stdout = gdb.execute("p (int)dup(1)",
                             to_string=True).split("=")[-1].strip()
    try:
      time_suffix = time.strftime("%Y%m%d-%H%M%S")
      fd, file = tempfile.mkstemp(suffix="-%s.gdbout" % time_suffix)
      try:
        # Temporarily redirect stdout to the created tmp file for the
        # duration of the subcommand.
        gdb.execute('p (int)dup2((int)open("%s", 1), 1)' % file,
                    to_string=True)
        # Execute subcommand non interactively.
        result = gdb.execute(subcommand, from_tty=False, to_string=True)
        # Write returned string results to the temporary file as well.
        with open(file, 'a') as f:
          f.write(result)
        # Open generated result.
        if 'GDB_EXTERNAL_EDITOR' in os.environ:
          open_cmd = os.environ['GDB_EXTERNAL_EDITOR']
          print("Opening '%s' with %s" % (file, open_cmd))
          subprocess.call([open_cmd, file])
        else:
          print("Output written to:\n '%s'" % file)
      finally:
        # Restore original stdout.
        gdb.execute("p (int)dup2(%s, 1)" % old_stdout, to_string=True)
        # Close the temporary file.
        os.close(fd)
    finally:
      # Close the originally duplicated stdout descriptor.
      gdb.execute("p (int)close(%s)" % old_stdout, to_string=True)


Redirect()
                                                                                                                                                                                                                                                                                                                                                                                                                                    node-23.7.0/deps/v8/tools/gdbinit                                                                   0000664 0000000 0000000 00000032120 14746647661 0016546 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # Copyright 2014 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

# Print tagged object.
define job
call (void) _v8_internal_Print_Object((void*)($arg0))
end
document job
Print a v8 JavaScript object
Usage: job tagged_ptr
end

# Print content of V8 handles.
python
import gdb

class PrintV8HandleCommand(gdb.Command):
  """Print content of a V8 object, accessed through a handle."""

  def __init__(self, command_name):
    self.command_name = command_name
    super(PrintV8HandleCommand, self).__init__(command_name, gdb.COMMAND_DATA)

  @staticmethod
  def print_direct(value, from_tty):
    CMD = "call (void) _v8_internal_Print_Object((v8::internal::Address*)({}))"
    gdb.execute(CMD.format(value.format_string()), from_tty)
    return True

  @staticmethod
  def print_indirect(value, from_tty):
    CMD = "call (void) _v8_internal_Print_Object(*(v8::internal::Address**)({}))"
    gdb.execute(CMD.format(value.format_string()), from_tty)
    return True

  def invoke(self, arg, from_tty):
    argv = gdb.string_to_argv(arg)
    if len(argv) != 1:
      raise gdb.GdbError("{} takes exactly one argument.".format(
          self.command_name))
    value = gdb.parse_and_eval(argv[0])
    if not self.print_handle(value, from_tty):
      raise gdb.GdbError("{} cannot print a value of type {}".format(
        self.command_name, value.type))


class PrintV8LocalCommand(PrintV8HandleCommand):
  """Print content of v8::(Maybe)?Local."""

  def __init__(self):
    super(PrintV8LocalCommand, self).__init__("print-v8-local")

  def print_handle(self, value, from_tty):
    if gdb.types.get_basic_type(value.type).code != gdb.TYPE_CODE_STRUCT:
      return False
    # After https://crrev.com/c/4335544, v8::MaybeLocal contains a local_.
    if gdb.types.has_field(value.type, "local_"):
      value = value["local_"]
    # After https://crrev.com/c/4335544, v8::Local contains a location_.
    if gdb.types.has_field(value.type, "location_"):
      return self.print_indirect(value["location_"], from_tty)
    # Before https://crrev.com/c/4335544, v8::Local contained a val_.
    if gdb.types.has_field(value.type, "val_"):
      return self.print_indirect(value["val_"], from_tty)
    # With v8_enable_direct_handle=true, v8::Local contains a ptr_.
    if gdb.types.has_field(value.type, "ptr_"):
      return self.print_direct(value["ptr_"], from_tty)
    # We don't know how to print this...
    return False

class PrintV8InternalHandleCommand(PrintV8HandleCommand):
  """Print content of v8::internal::(Maybe)?(Direct|Indirect)?Handle."""

  def __init__(self):
    super(PrintV8InternalHandleCommand, self).__init__("print-v8-internal-handle")

  def print_handle(self, value, from_tty):
    if gdb.types.get_basic_type(value.type).code != gdb.TYPE_CODE_STRUCT:
      return False
    # Indirect handles contain a location_.
    if gdb.types.has_field(value.type, "location_"):
      return self.print_indirect(value["location_"], from_tty)
    # Direct handles contain a obj_.
    if gdb.types.has_field(value.type, "obj_"):
      return self.print_direct(value["obj_"], from_tty)
    # We don't know how to print this...
    return False

PrintV8LocalCommand()
PrintV8InternalHandleCommand()
end

alias jlh = print-v8-local
alias jl = print-v8-local
alias jh = print-v8-internal-handle

# Print Code objects containing given PC.
define jco
  if $argc == 0
    call (void) _v8_internal_Print_Code((void*)($pc))
  else
    call (void) _v8_internal_Print_Code((void*)($arg0))
  end
end
document jco
Print a v8 Code object from an internal code address
Usage: jco pc
end

# Print Code objects assembly code surrounding given PC.
define jca
  if $argc == 0
    call (void) _v8_internal_Print_OnlyCode((void*)($pc), 30)
  else
    if $argc == 0
      call (void) _v8_internal_Print_OnlyCode((void*)($arg0), 30)
    else
      call (void) _v8_internal_Print_OnlyCode((void*)($arg0), (size_t)($arg1))
    end
  end
end
document jca
Print a v8 Code object assembly code from an internal code address
Usage: jca pc
end

# Print TransitionTree.
define jtt
call (void) _v8_internal_Print_TransitionTree((void*)($arg0), false)
end
document jtt
Print the complete transition tree starting at the given v8 map.
Usage: jtt tagged_ptr
end

# Print TransitionTree starting from the root map.
define jttr
call (void) _v8_internal_Print_TransitionTree((void*)($arg0), true)
end
document jttr
Print the complete transition tree starting at the root map of the given v8 map.
Usage: jttr tagged_ptr
end

# Print JavaScript stack trace.
define jst
call (void) _v8_internal_Print_StackTrace()
end
document jst
Print the current JavaScript stack trace
Usage: jst
end

# Print TurboFan graph node.
define pn
call _v8_internal_Node_Print((void*)($arg0))
end
document pn
Print a v8 TurboFan graph node
Usage: pn node_address
end

# Skip the JavaScript stack.
define jss
set $js_entry_sp=v8::internal::Isolate::Current()->thread_local_top()->js_entry_sp_
set $rbp=*(void**)$js_entry_sp
set $rsp=$js_entry_sp + 2*sizeof(void*)
set $pc=*(void**)($js_entry_sp+sizeof(void*))
end
document jss
Skip the jitted stack on x64 to where we entered JS last.
Usage: jss
end

# Print v8::FunctionCallbackInfo<T>& info.
define jfci
call _v8_internal_Print_FunctionCallbackInfo((void*)(&$arg0))
end
document jfci
Print v8::FunctionCallbackInfo<T>& info.
Usage: jfci info
end

# Print v8::PropertyCallbackInfo<T>& info.
define jpci
call _v8_internal_Print_PropertyCallbackInfo((void*)(&$arg0))
end
document jpci
Print v8::PropertyCallbackInfo<T>& info.
Usage: jpci info
end

# Print whether the object is marked, the mark-bit cell and index. The address
# of the cell is handy for reverse debugging to check when the object was
# marked/unmarked.
define jomb
call _v8_internal_Print_Object_MarkBit((void*)($arg0))
end
document jomb
Print whether the object is marked, the markbit cell and index.
Usage: jomb tagged_ptr
end

# Execute a simulator command.
python
import gdb

class SimCommand(gdb.Command):
  """Sim the current program."""

  def __init__ (self):
    super (SimCommand, self).__init__ ("sim", gdb.COMMAND_SUPPORT)

  def invoke (self, arg, from_tty):
    arg_bytes = arg.encode("utf-8") + b'\0'
    arg_c_string = gdb.Value(arg_bytes, gdb.lookup_type('char').array(len(arg_bytes) - 1))
    cmd_func = gdb.selected_frame().read_var("_v8_internal_Simulator_ExecDebugCommand")
    cmd_func(arg_c_string)

SimCommand()
end

# Print stack trace with assertion scopes.
define bta
python
import re
frame_re = re.compile("^#(\d+)\s*(?:0x[a-f\d]+ in )?(.+) \(.+ at (.+)")
assert_re = re.compile("^\s*(\S+) = .+<v8::internal::Per\w+AssertScope<v8::internal::(\S*), (false|true)>")
btl = gdb.execute("backtrace full", to_string = True).splitlines()
for l in btl:
  match = frame_re.match(l)
  if match:
    print("[%-2s] %-60s %-40s" % (match.group(1), match.group(2), match.group(3)))
  match = assert_re.match(l)
  if match:
    if match.group(3) == "false":
      prefix = "Disallow"
      color = "\033[91m"
    else:
      prefix = "Allow"
      color = "\033[92m"
    print("%s -> %s %s (%s)\033[0m" % (color, prefix, match.group(2), match.group(1)))
end
end
document bta
Print stack trace with assertion scopes
Usage: bta
end

# Search for a pointer inside all valid pages.
define space_find
  set $space = $arg0
  set $current_page = $space->first_page()
  while ($current_page != 0)
    printf "#   Searching in %p - %p\n", $current_page->area_start(), $current_page->area_end()-1
    find $current_page->area_start(), $current_page->area_end()-1, $arg1
    set $current_page = $current_page->next_page()
  end
end

define heap_find
  set $heap = v8::internal::Isolate::Current()->heap()
  printf "# Searching for %p in old_space  ===============================\n", $arg0
  space_find $heap->old_space() ($arg0)
  printf "# Searching for %p in map_space  ===============================\n", $arg0
  space_find $heap->map_space() $arg0
  printf "# Searching for %p in code_space ===============================\n", $arg0
  space_find $heap->code_space() $arg0
end
document heap_find
Find the location of a given address in V8 pages.
Usage: heap_find address
end

# The 'disassembly-flavor' command is only available on i386 and x84_64.
python
try:
  gdb.execute("set disassembly-flavor intel")
except gdb.error:
  pass
end

# Configuring ASLR may not be possible on some platforms, such running via the
# `rr` debuggger.
python
try:
  gdb.execute("set disable-randomization off")
except gdb.error:
  pass
end

# Install a handler whenever the debugger stops due to a signal. It walks up the
# stack looking for V8_Dcheck / V8_Fatal / OS::DebugBreak frame and moves the
# frame to the one above it so it's immediately at the line of code that
# triggered the stop condition.
python
def v8_stop_handler(event):
  frame = gdb.selected_frame()
  select_frame = None
  message = None
  count = 0
  # Limit stack scanning since the frames we look for are near the top anyway,
  # and otherwise stack overflows can be very slow.
  while frame is not None and count < 10:
    count += 1
    # If we are in a frame created by gdb (e.g. for `(gdb) call foo()`), gdb
    # emits a dummy frame between its stack and the program's stack. Abort the
    # walk if we see this frame.
    if frame.type() == gdb.DUMMY_FRAME: break

    if frame.name() == 'V8_Dcheck':
      frame_message = gdb.lookup_symbol('message', frame.block())[0]
      if frame_message:
        message = frame_message.value(frame).string()
      select_frame = frame.older()
      break
    if frame.name() is not None and frame.name().startswith('V8_Fatal'):
      select_frame = frame.older()
    if frame.name() == 'v8::base::OS::DebugBreak':
      select_frame = frame.older()
    frame = frame.older()

  if select_frame is not None:
    select_frame.select()
    gdb.execute('frame')
    if message:
      print('DCHECK error: {}'.format(message))

gdb.events.stop.connect(v8_stop_handler)
end

# Code imported from chromium/src/tools/gdb/gdbinit
python

import os
import subprocess
import sys

compile_dirs = set()


def get_current_debug_file_directories():
  dir = gdb.execute("show debug-file-directory", to_string=True)
  dir = dir[
      len('The directory where separate debug symbols are searched for is "'
         ):-len('".') - 1]
  return set(dir.split(":"))


def add_debug_file_directory(dir):
  # gdb has no function to add debug-file-directory, simulates that by using
  # `show debug-file-directory` and `set debug-file-directory <directories>`.
  current_dirs = get_current_debug_file_directories()
  current_dirs.add(dir)
  gdb.execute(
      "set debug-file-directory %s" % ":".join(current_dirs), to_string=True)


def newobj_handler(event):
  global compile_dirs
  compile_dir = os.path.dirname(event.new_objfile.filename)
  if not compile_dir:
    return
  if compile_dir in compile_dirs:
    return
  compile_dirs.add(compile_dir)

  # Add source path
  gdb.execute("dir %s" % compile_dir)

  # Need to tell the location of .dwo files.
  # https://sourceware.org/gdb/onlinedocs/gdb/Separate-Debug-Files.html
  # https://crbug.com/603286#c35
  add_debug_file_directory(compile_dir)

# Event hook for newly loaded objfiles.
# https://sourceware.org/gdb/onlinedocs/gdb/Events-In-Python.html
gdb.events.new_objfile.connect(newobj_handler)

gdb.execute("set environment V8_GDBINIT_SOURCED=1")

end

### CppGC helpers.

# Print compressed pointer.
define cpcp
call _cppgc_internal_Decompress_Compressed_Pointer((unsigned)($arg0))
end
document cpcp
Prints compressed pointer (raw value) after decompression.
Usage: cpcp compressed_pointer
end

# Print member.
define cpm
call _cppgc_internal_Print_Member((cppgc::internal::MemberBase*)(&$arg0))
end
document cpm
Prints member, compressed or not.
Usage: cpm member
end

# Pretty printer for cppgc::Member.
python

import re


class CppGCMemberPrinter(object):
  """Print cppgc Member types."""

  def __init__(self, val, category, pointee_type):
    self.val = val
    self.category = category
    self.pointee_type = pointee_type

  def to_string(self):
    pointer = gdb.parse_and_eval(
        "_cppgc_internal_Uncompress_Member((void*){})".format(
            self.val.address))
    return "{}Member<{}> pointing to {}".format(
        '' if self.category is None else self.category, self.pointee_type,
        pointer)

  def display_hint(self):
    return "{}Member<{}>".format('' if self.category is None else self.category,
                                 self.pointee_type)


def cppgc_pretty_printers(val):
  typename = val.type.name or val.type.tag or str(val.type)
  regex = re.compile("^(cppgc|blink)::(Weak|Untraced)?Member<(.*)>$")
  match = regex.match(typename)
  if match is not None:
    return CppGCMemberPrinter(
        val, category=match.group(2), pointee_type=match.group(3))

  # The member type might have been obscured by typedefs and template
  # arguments. Fallback to using the underlying type.
  real_type = val.type.strip_typedefs()
  if (real_type.name is not None and
      real_type.name.startswith('cppgc::internal::BasicMember')):
    inner_type = real_type.template_argument(0)
    return CppGCMemberPrinter(
        val, category='Basic', pointee_type=inner_type.name)

  return None


gdb.pretty_printers.append(cppgc_pretty_printers)

end
                                                                                                                                                                                                                                                                                                                                                                                                                                                node-23.7.0/deps/v8/tools/gen-inlining-tests.py                                                     0000664 0000000 0000000 00000036610 14746647661 0021303 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3

# Copyright 2016 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

# for py2/py3 compatibility
from __future__ import print_function

from collections import namedtuple
import textwrap
import sys

SHARD_FILENAME_TEMPLATE = "test/mjsunit/compiler/inline-exception-{shard}.js"
# Generates 2 files. Found by trial and error.
SHARD_SIZE = 97

PREAMBLE = """

// Copyright 2016 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

// Flags: --allow-natives-syntax --no-always-turbofan

// This test file was generated by tools/gen-inlining-tests.py .

// Global variables
var deopt = undefined; // either true or false
var counter = 0;

function resetState() {
  counter = 0;
}

function warmUp(f) {
  try {
    f();
  } catch (ex) {
    // ok
  }
  try {
    f();
  } catch (ex) {
    // ok
  }
}

function resetOptAndAssertResultEquals(expected, f) {
  warmUp(f);
  resetState();
  // %DebugPrint(f);
  eval("'dont optimize this function itself please, but do optimize f'");
  %OptimizeFunctionOnNextCall(f);
  assertEquals(expected, f());
}

function resetOptAndAssertThrowsWith(expected, f) {
  warmUp(f);
  resetState();
  // %DebugPrint(f);
  eval("'dont optimize this function itself please, but do optimize f'");
  %OptimizeFunctionOnNextCall(f);
  try {
    var result = f();
    fail("resetOptAndAssertThrowsWith",
        "exception: " + expected,
        "result: " + result);
  } catch (ex) {
    assertEquals(expected, ex);
  }
}

function increaseAndReturn15() {
  if (deopt) %DeoptimizeFunction(f);
  counter++;
  return 15;
}

function increaseAndThrow42() {
  if (deopt) %DeoptimizeFunction(f);
  counter++;
  throw 42;
}

function increaseAndReturn15_noopt_inner() {
  if (deopt) %DeoptimizeFunction(f);
  counter++;
  return 15;
}

%NeverOptimizeFunction(increaseAndReturn15_noopt_inner);

function increaseAndThrow42_noopt_inner() {
  if (deopt) %DeoptimizeFunction(f);
  counter++;
  throw 42;
}

%NeverOptimizeFunction(increaseAndThrow42_noopt_inner);

// Alternative 1

function returnOrThrow(doReturn) {
  if (doReturn) {
    return increaseAndReturn15();
  } else {
    return increaseAndThrow42();
  }
}

// Alternative 2

function increaseAndReturn15_calls_noopt() {
  return increaseAndReturn15_noopt_inner();
}

function increaseAndThrow42_calls_noopt() {
  return increaseAndThrow42_noopt_inner();
}

// Alternative 3.
// When passed either {increaseAndReturn15} or {increaseAndThrow42}, it acts
// as the other one.
function invertFunctionCall(f) {
  var result;
  try {
    result = f();
  } catch (ex) {
    return ex - 27;
  }
  throw result + 27;
}

// Alternative 4: constructor
function increaseAndStore15Constructor() {
  if (deopt) %DeoptimizeFunction(f);
  ++counter;
  this.x = 15;
}

function increaseAndThrow42Constructor() {
  if (deopt) %DeoptimizeFunction(f);
  ++counter;
  this.x = 42;
  throw this.x;
}

// Alternative 5: property
var magic = {};
Object.defineProperty(magic, 'prop', {
  get: function () {
    if (deopt) %DeoptimizeFunction(f);
    return 15 + 0 * ++counter;
  },

  set: function(x) {
    // argument should be 37
    if (deopt) %DeoptimizeFunction(f);
    counter -= 36 - x; // increments counter
    throw 42;
  }
})

// Generate type feedback.

assertEquals(15, increaseAndReturn15_calls_noopt());
assertThrowsEquals(function() { return increaseAndThrow42_noopt_inner() }, 42);

assertEquals(15, (new increaseAndStore15Constructor()).x);
assertThrowsEquals(function() {
        return (new increaseAndThrow42Constructor()).x;
    },
    42);

function runThisShard() {

""".strip()

def booltuples(n):
  """booltuples(2) yields 4 tuples: (False, False), (False, True),
  (True, False), (True, True)."""

  assert isinstance(n, int)
  if n <= 0:
    yield ()
  else:
    for initial in booltuples(n-1):
      yield initial + (False,)
      yield initial + (True,)

def fnname(flags):
  assert len(FLAGLETTERS) == len(flags)

  return "f_" + ''.join(
      FLAGLETTERS[i] if b else '_' for (i, b) in enumerate(flags))


NUM_TESTS_PRINTED = 0
NUM_TESTS_IN_SHARD = 0

def printtest(flags):
  """Print a test case. Takes a couple of boolean flags, on which the
  printed Javascript code depends."""

  assert all(isinstance(flag, bool) for flag in flags)

  # The alternative flags are in reverse order so that if we take all possible
  # tuples, ordered lexicographically from false to true, we get first the
  # default, then alternative 1, then 2, etc.
  (
    alternativeFn5,      # use alternative #5 for returning/throwing:
                         #   return/throw using property
    alternativeFn4,      # use alternative #4 for returning/throwing:
                         #   return/throw using constructor
    alternativeFn3,      # use alternative #3 for returning/throwing:
                         #   return/throw indirectly, based on function argument
    alternativeFn2,      # use alternative #2 for returning/throwing:
                         #   return/throw indirectly in unoptimized code,
                         #   no branching
    alternativeFn1,      # use alternative #1 for returning/throwing:
                         #   return/throw indirectly, based on boolean arg
    tryThrows,           # in try block, call throwing function
    tryReturns,          # in try block, call returning function
    tryFirstReturns,     # in try block, returning goes before throwing
    tryResultToLocal,    # in try block, result goes to local variable
    doCatch,             # include catch block
    catchReturns,        # in catch block, return
    catchWithLocal,      # in catch block, modify or return the local variable
    catchThrows,         # in catch block, throw
    doFinally,           # include finally block
    finallyReturns,      # in finally block, return local variable
    finallyThrows,       # in finally block, throw
    endReturnLocal,      # at very end, return variable local
    deopt,               # deopt inside inlined function
  ) = flags

  # BASIC RULES

  # Only one alternative can be applied at any time.
  if (alternativeFn1 + alternativeFn2 + alternativeFn3 + alternativeFn4
      + alternativeFn5 > 1):
    return

  # In try, return or throw, or both.
  if not (tryReturns or tryThrows): return

  # Either doCatch or doFinally.
  if not doCatch and not doFinally: return

  # Catch flags only make sense when catching
  if not doCatch and (catchReturns or catchWithLocal or catchThrows):
    return

  # Finally flags only make sense when finallying
  if not doFinally and (finallyReturns or finallyThrows):
    return

  # tryFirstReturns is only relevant when both tryReturns and tryThrows are
  # true.
  if tryFirstReturns and not (tryReturns and tryThrows): return

  # From the try and finally block, we can return or throw, but not both.
  if catchReturns and catchThrows: return
  if finallyReturns and finallyThrows: return

  # If at the end we return the local, we need to have touched it.
  if endReturnLocal and not (tryResultToLocal or catchWithLocal): return

  # PRUNING

  anyAlternative = any([alternativeFn1, alternativeFn2, alternativeFn3,
      alternativeFn4, alternativeFn5])
  specificAlternative = any([alternativeFn2, alternativeFn3])

  # If try returns and throws, then don't catchWithLocal, endReturnLocal, or
  # deopt, or do any alternative.
  if (tryReturns and tryThrows and
      (catchWithLocal or endReturnLocal or deopt or anyAlternative)):
    return
  # We don't do any alternative if we do a finally.
  if doFinally and anyAlternative: return
  # We only use the local variable if we do alternative #2 or #3.
  if ((tryResultToLocal or catchWithLocal or endReturnLocal) and
      not specificAlternative):
    return
  # We don't need to test deopting into a finally.
  if doFinally and deopt: return

  # We're only interested in alternative #2 if we have endReturnLocal, no
  # catchReturns, and no catchThrows, and deopt.
  if (alternativeFn2 and
      (not endReturnLocal or catchReturns or catchThrows or not deopt)):
    return


  # Flag check succeeded.

  trueFlagNames = [name for (name, value) in flags._asdict().items() if value]
  flagsMsgLine = "  // Variant flags: [{}]".format(', '.join(trueFlagNames))
  write(textwrap.fill(flagsMsgLine, subsequent_indent='  //   '))
  write("")

  if not anyAlternative:
    fragments = {
      'increaseAndReturn15': 'increaseAndReturn15()',
      'increaseAndThrow42': 'increaseAndThrow42()',
    }
  elif alternativeFn1:
    fragments = {
      'increaseAndReturn15': 'returnOrThrow(true)',
      'increaseAndThrow42': 'returnOrThrow(false)',
    }
  elif alternativeFn2:
    fragments = {
      'increaseAndReturn15': 'increaseAndReturn15_calls_noopt()',
      'increaseAndThrow42': 'increaseAndThrow42_calls_noopt()',
    }
  elif alternativeFn3:
    fragments = {
      'increaseAndReturn15': 'invertFunctionCall(increaseAndThrow42)',
      'increaseAndThrow42': 'invertFunctionCall(increaseAndReturn15)',
    }
  elif alternativeFn4:
    fragments = {
      'increaseAndReturn15': '(new increaseAndStore15Constructor()).x',
      'increaseAndThrow42': '(new increaseAndThrow42Constructor()).x',
    }
  else:
    assert alternativeFn5
    fragments = {
      'increaseAndReturn15': 'magic.prop /* returns 15 */',
      'increaseAndThrow42': '(magic.prop = 37 /* throws 42 */)',
    }

  # As we print code, we also maintain what the result should be. Variable
  # {result} can be one of three things:
  #
  # - None, indicating returning JS null
  # - ("return", n) with n an integer
  # - ("throw", n), with n an integer

  result = None
  # We also maintain what the counter should be at the end.
  # The counter is reset just before f is called.
  counter = 0

  write(    "  f = function {} () {{".format(fnname(flags)))
  write(    "    var local = 888;")
  write(    "    deopt = {};".format("true" if deopt else "false"))
  local = 888
  write(    "    try {")
  write(    "      counter++;")
  counter += 1
  resultTo = "local +=" if tryResultToLocal else "return"
  if tryReturns and not (tryThrows and not tryFirstReturns):
    write(  "      {} 4 + {increaseAndReturn15};".format(resultTo, **fragments))
    if result is None:
      counter += 1
      if tryResultToLocal:
        local += 19
      else:
        result = ("return", 19)
  if tryThrows:
    write(  "      {} 4 + {increaseAndThrow42};".format(resultTo, **fragments))
    if result is None:
      counter += 1
      result = ("throw", 42)
  if tryReturns and tryThrows and not tryFirstReturns:
    write(  "      {} 4 + {increaseAndReturn15};".format(resultTo, **fragments))
    if result is None:
      counter += 1
      if tryResultToLocal:
        local += 19
      else:
        result = ("return", 19)
  write(    "      counter++;")
  if result is None:
    counter += 1

  if doCatch:
    write(  "    } catch (ex) {")
    write(  "      counter++;")
    if isinstance(result, tuple) and result[0] == 'throw':
      counter += 1
    if catchThrows:
      write("      throw 2 + ex;")
      if isinstance(result, tuple) and result[0] == "throw":
        result = ('throw', 2 + result[1])
    elif catchReturns and catchWithLocal:
      write("      return 2 + local;")
      if isinstance(result, tuple) and result[0] == "throw":
        result = ('return', 2 + local)
    elif catchReturns and not catchWithLocal:
      write("      return 2 + ex;");
      if isinstance(result, tuple) and result[0] == "throw":
        result = ('return', 2 + result[1])
    elif catchWithLocal:
      write("      local += ex;");
      if isinstance(result, tuple) and result[0] == "throw":
        local += result[1]
        result = None
        counter += 1
    else:
      if isinstance(result, tuple) and result[0] == "throw":
        result = None
        counter += 1
    write(  "      counter++;")

  if doFinally:
    write(  "    } finally {")
    write(  "      counter++;")
    counter += 1
    if finallyThrows:
      write("      throw 25;")
      result = ('throw', 25)
    elif finallyReturns:
      write("      return 3 + local;")
      result = ('return', 3 + local)
    elif not finallyReturns and not finallyThrows:
      write("      local += 2;")
      local += 2
      counter += 1
    else: assert False # unreachable
    write(  "      counter++;")

  write(    "    }")
  write(    "    counter++;")
  if result is None:
    counter += 1
  if endReturnLocal:
    write(  "    return 5 + local;")
    if result is None:
      result = ('return', 5 + local)
  write(    "  }")

  if result is None:
    write(  "  resetOptAndAssertResultEquals(undefined, f);")
  else:
    tag, value = result
    if tag == "return":
      write(  "  resetOptAndAssertResultEquals({}, f);".format(value))
    else:
      assert tag == "throw"
      write(  "  resetOptAndAssertThrowsWith({}, f);".format(value))

  write(  "  assertEquals({}, counter);".format(counter))
  write(  "")

  global NUM_TESTS_PRINTED, NUM_TESTS_IN_SHARD
  NUM_TESTS_PRINTED += 1
  NUM_TESTS_IN_SHARD += 1

FILE = None # to be initialised to an open file
SHARD_NUM = 1

def write(*args):
  return print(*args, file=FILE)



def rotateshard():
  global FILE, NUM_TESTS_IN_SHARD, SHARD_SIZE
  if MODE != 'shard':
    return
  if FILE is not None and NUM_TESTS_IN_SHARD < SHARD_SIZE:
    return
  if FILE is not None:
    finishshard()
    assert FILE is None
  FILE = open(SHARD_FILENAME_TEMPLATE.format(shard=SHARD_NUM), 'w')
  write_shard_header()
  NUM_TESTS_IN_SHARD = 0

def finishshard():
  global FILE, SHARD_NUM, MODE
  assert FILE
  write_shard_footer()
  if MODE == 'shard':
    print("Wrote shard {}.".format(SHARD_NUM))
    FILE.close()
    FILE = None
    SHARD_NUM += 1


def write_shard_header():
  if MODE == 'shard':
    write("// Shard {}.".format(SHARD_NUM))
    write("")
  write(PREAMBLE)
  write("")

def write_shard_footer():
  write("}")
  write("%NeverOptimizeFunction(runThisShard);")
  write("")
  write("// {} tests in this shard.".format(NUM_TESTS_IN_SHARD))
  write("// {} tests up to here.".format(NUM_TESTS_PRINTED))
  write("")
  write("runThisShard();")

FLAGLETTERS="54321trflcrltfrtld"

flagtuple = namedtuple('flagtuple', (
  "alternativeFn5",
  "alternativeFn4",
  "alternativeFn3",
  "alternativeFn2",
  "alternativeFn1",
  "tryThrows",
  "tryReturns",
  "tryFirstReturns",
  "tryResultToLocal",
  "doCatch",
  "catchReturns",
  "catchWithLocal",
  "catchThrows",
  "doFinally",
  "finallyReturns",
  "finallyThrows",
  "endReturnLocal",
  "deopt"
  ))

emptyflags = flagtuple(*((False,) * len(flagtuple._fields)))
f1 = emptyflags._replace(tryReturns=True, doCatch=True)

# You can test function printtest with f1.

allFlagCombinations = [
    flagtuple(*bools)
    for bools in booltuples(len(flagtuple._fields))
]

if __name__ == '__main__':
  if sys.argv[1:] == []:
    MODE = 'stdout'
    print("// Printing all shards together to stdout.")
    print("")
    write_shard_header()
    FILE = sys.stdout
  elif sys.argv[1:] == ['--shard-and-overwrite']:
    MODE = 'shard'
  else:
    print("Usage:")
    print("")
    print("  python {}".format(sys.argv[0]))
    print("      print all tests to standard output")
    print("  python {} --shard-and-overwrite".format(sys.argv[0]))
    print("      print all tests to {}".format(SHARD_FILENAME_TEMPLATE))

    print("")
    print(sys.argv[1:])
    print("")
    sys.exit(1)

  rotateshard()

  for flags in allFlagCombinations:
    printtest(flags)
    rotateshard()

  finishshard()

  if MODE == 'shard':
    print("Total: {} tests.".format(NUM_TESTS_PRINTED))
                                                                                                                        node-23.7.0/deps/v8/tools/gen-keywords-gen-h.py                                                     0000775 0000000 0000000 00000020240 14746647661 0021172 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3
# Copyright 2018 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

from __future__ import annotations

import sys
import subprocess
import re
import math
from pathlib import Path
from typing import List, Union

INPUT_PATH = Path("src/parsing/keywords.txt")
OUTPUT_PATH = Path("src/parsing/keywords-gen.h")

# TODO(leszeks): Trimming seems to regress performance, investigate.
TRIM_CHAR_TABLE: bool = False


def next_power_of_2(x):
  return 1 if x == 0 else 2**int(math.ceil(math.log(x, 2)))


def call_with_input(cmd: List[Union[str, Path]], input_string: str = "") -> str:
  p = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE)
  stdout, _ = p.communicate(input_string.encode())
  retcode = p.wait()
  if retcode != 0:
    raise subprocess.CalledProcessError(retcode, cmd)
  return stdout.decode()


def checked_sub(pattern: Union[str, re.Pattern[str]],
                sub: str,
                out: str,
                count: int = 1,
                flags: int = 0) -> str:
  out, n = re.subn(pattern, sub, out, flags=flags)
  if n != count:
    raise Exception("Expected %d and got %d replacement(s) for pattern: %s" %
                    (count, n, pattern))
  return out


def change_sizet_to_int(out: str) -> str:
  # Literal buffer lengths are given as ints, not size_t
  return checked_sub(r'\bsize_t\b', 'int', out, count=4)


def drop_line_directives(out: str) -> str:
  # #line causes gcov issue, so drop it
  return re.sub(r'^#\s*line .*$\n', '', out, flags=re.MULTILINE)


def trim_and_dcheck_char_table(out: str) -> str:
  # Potential keyword strings are known to be lowercase ascii, so chop off the
  # rest of the table and mask out the char

  reads_re = re.compile(
      r'asso_values\[static_cast<unsigned char>\((str\[\w+\](\+\d)?)\)\]')

  dchecks = []
  for str_read in reads_re.finditer(out):
    dchecks.append("DCHECK_LT(%s, 129);" % str_read.group(1))

  if TRIM_CHAR_TABLE:
    out = checked_sub(
        r'static const unsigned char asso_values\[\]\s*=\s*\{(\s*\d+\s*,){96}',
        "".join(dchecks) + r'static const unsigned char asso_values[32] = {',
        out,
        flags=re.MULTILINE)
    out = checked_sub(
        reads_re.pattern,
        r'asso_values[static_cast<unsigned char>(str[(\1)]&31)]',
        out,
        count=len(dchecks),
        flags=re.MULTILINE)
  else:
    out = checked_sub(
        r'static const unsigned char asso_values\[\]\s*=\s*\{',
        "".join(dchecks) + r'static const unsigned char asso_values[129] = {',
        out,
        flags=re.MULTILINE)

  return out


def use_isinrange(out: str) -> str:
  # Our IsInRange method is more efficient than checking for min/max length
  return checked_sub(r'if \(len <= MAX_WORD_LENGTH && len >= MIN_WORD_LENGTH\)',
                     r'if (base::IsInRange(len, MIN_WORD_LENGTH, '
                     + r'MAX_WORD_LENGTH))',
                     out)


def pad_tables(out: str) -> str:
  # We don't want to compare against the max hash value, so pad the tables up
  # to a power of two and mask the hash.

  # First get the new size
  max_hash_value = int(re.search(r'MAX_HASH_VALUE\s*=\s*(\d+)', out).group(1))
  old_table_length = max_hash_value + 1
  new_table_length = next_power_of_2(old_table_length)
  table_padding_len = new_table_length - old_table_length

  # Pad the length table.
  single_lengthtable_entry = r'\d+'
  out = checked_sub(
      r"""
      static\ const\ unsigned\ char\ kPerfectKeywordLengthTable\[\]\s*=\s*\{
        (
          \s*%(single_lengthtable_entry)s\s*
          (?:,\s*%(single_lengthtable_entry)s\s*)*
        )
      \}
    """ % {'single_lengthtable_entry': single_lengthtable_entry},
      r'static const unsigned char kPerfectKeywordLengthTable[%d] = { \1 %s }'
      % (new_table_length, "".join([',0'] * table_padding_len)),
      out,
      flags=re.MULTILINE | re.VERBOSE)

  # Pad the word list.
  single_wordlist_entry = r"""
      (?:\#line\ \d+\ ".*"$\s*)?
      \{\s*"[a-z]*"\s*,\s*Token::[a-zA-Z_]+\}
    """
  out = checked_sub(
      r"""
      static\ const\ struct\ PerfectKeywordHashTableEntry\ kPerfectKeywordHashTable\[\]\s*=\s*\{
        (
          \s*%(single_wordlist_entry)s\s*
          (?:,\s*%(single_wordlist_entry)s\s*)*
        )
      \}
    """ % {'single_wordlist_entry': single_wordlist_entry},
      r'static const struct PerfectKeywordHashTableEntry kPerfectKeywordHashTable[%d] = {\1 %s }'
      % (new_table_length, "".join(
          [',{"",Token::kIdentifier}'] * table_padding_len)),
      out,
      flags=re.MULTILINE | re.VERBOSE)

  # Mask the hash and replace the range check with DCHECKs.
  out = checked_sub(r'Hash\s*\(\s*str,\s*len\s*\)',
                    r'Hash(str, len)&0x%x' % (new_table_length - 1), out)
  out = checked_sub(
      r'if \(key <= MAX_HASH_VALUE\)',
      r'DCHECK_LT(key, arraysize(kPerfectKeywordLengthTable));DCHECK_LT(key, arraysize(kPerfectKeywordHashTable));',
      out)

  return out


def return_token(out: str) -> str:
  # We want to return the actual token rather than the table entry.

  # Change the return type of the function. Make it inline too.
  out = checked_sub(
      r'const\s*struct\s*PerfectKeywordHashTableEntry\s*\*\s*((?:PerfectKeywordHash::)?GetToken)',
      r'inline Token::Value \1',
      out,
      count=2)

  # Change the return value when the keyword is found
  out = checked_sub(r'return &kPerfectKeywordHashTable\[key\];',
                    r'return kPerfectKeywordHashTable[key].value;', out)

  # Change the return value when the keyword is not found
  out = checked_sub(r'return 0;', r'return Token::kIdentifier;', out)

  return out


def memcmp_to_while(out: str) -> str:
  # It's faster to loop over the keyword with a while loop than calling memcmp.
  # Careful, this replacement is quite flaky, because otherwise the regex is
  # unreadable.
  return checked_sub(
      re.escape("if (*str == *s && !memcmp (str + 1, s + 1, len - 1))") +
      r"\s*" + re.escape("return kPerfectKeywordHashTable[key].value;"),
      """
      while(*s!=0) {
        if (*s++ != *str++) return Token::kIdentifier;
      }
      return kPerfectKeywordHashTable[key].value;
      """,
      out,
      flags=re.MULTILINE)


def wrap_namespace(out):
  return """// Copyright 2018 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

// This file is automatically generated by gen-keywords-gen-h.py and should not
// be modified manually.

#ifndef V8_PARSING_KEYWORDS_GEN_H_
#define V8_PARSING_KEYWORDS_GEN_H_

#include "src/parsing/token.h"

namespace v8 {
namespace internal {

%s

}  // namespace internal
}  // namespace v8

#endif  // V8_PARSING_KEYWORDS_GEN_H_
""" % (out)


def trim_character_set_warning(out: str) -> str:
  # gperf generates an error message that is too large, trim it

  return out.replace(
      '"gperf generated tables don\'t work with this execution character set. Please report a bug to <bug-gperf@gnu.org>."',
      '"gperf generated tables don\'t work with this execution character set."\\\n// If you see this error, please report a bug to <bug-gperf@gnu.org>.'
  )


def main():
  try:
    script_dir = Path(sys.argv[0]).parent
    root_dir = script_dir.parent

    out: str = subprocess.check_output(["gperf", "-m100", INPUT_PATH],
                                       cwd=root_dir,
                                       encoding="UTF-8")

    # And now some munging of the generated file.
    out = change_sizet_to_int(out)
    out = drop_line_directives(out)
    out = trim_and_dcheck_char_table(out)
    out = use_isinrange(out)
    out = pad_tables(out)
    out = return_token(out)
    out = memcmp_to_while(out)
    out = wrap_namespace(out)
    out = trim_character_set_warning(out)

    # Final formatting.
    clang_format_path = root_dir / 'third_party/depot_tools/clang-format'
    out = call_with_input([clang_format_path], out)

    with (root_dir / OUTPUT_PATH).open('w') as f:
      f.write(out)

    return 0

  except subprocess.CalledProcessError as e:
    sys.stderr.write("Error calling '{}'\n".format(" ".join(e.cmd)))
    return e.returncode


if __name__ == '__main__':
  sys.exit(main())
                                                                                                                                                                                                                                                                                                                                                                node-23.7.0/deps/v8/tools/gen-postmortem-metadata.py                                                0000664 0000000 0000000 00000071702 14746647661 0022324 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3

#
# Copyright 2012 the V8 project authors. All rights reserved.
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are
# met:
#
#     * Redistributions of source code must retain the above copyright
#       notice, this list of conditions and the following disclaimer.
#     * Redistributions in binary form must reproduce the above
#       copyright notice, this list of conditions and the following
#       disclaimer in the documentation and/or other materials provided
#       with the distribution.
#     * Neither the name of Google Inc. nor the names of its
#       contributors may be used to endorse or promote products derived
#       from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#

#
# Emits a C++ file to be compiled and linked into libv8 to support postmortem
# debugging tools.  Most importantly, this tool emits constants describing V8
# internals:
#
#    v8dbg_type_CLASS__TYPE = VALUE             Describes class type values
#    v8dbg_class_CLASS__FIELD__TYPE = OFFSET    Describes class fields
#    v8dbg_parent_CLASS__PARENT                 Describes class hierarchy
#    v8dbg_frametype_NAME = VALUE               Describes stack frame values
#    v8dbg_off_fp_NAME = OFFSET                 Frame pointer offsets
#    v8dbg_prop_NAME = OFFSET                   Object property offsets
#    v8dbg_NAME = VALUE                         Miscellaneous values
#
# These constants are declared as global integers so that they'll be present in
# the generated libv8 binary.
#

# for py2/py3 compatibility
from __future__ import print_function

import io
import re
import sys

#
# Miscellaneous constants such as tags and masks used for object identification,
# enumeration values used as indexes in internal tables, etc..
#
consts_misc = [
    {
        'name': 'FirstNonstringType',
        'value': 'FIRST_NONSTRING_TYPE'
    },
    {
        'name': 'APIObjectType',
        'value': 'JS_API_OBJECT_TYPE'
    },
    {
        'name': 'SpecialAPIObjectType',
        'value': 'JS_SPECIAL_API_OBJECT_TYPE'
    },
    {
        'name': 'FirstContextType',
        'value': 'FIRST_CONTEXT_TYPE'
    },
    {
        'name': 'LastContextType',
        'value': 'LAST_CONTEXT_TYPE'
    },
    {
        'name': 'FirstJSFunctionType',
        'value': 'FIRST_JS_FUNCTION_TYPE'
    },
    {
        'name': 'LastJSFunctionType',
        'value': 'LAST_JS_FUNCTION_TYPE'
    },
    {
        'name': 'IsNotStringMask',
        'value': 'kIsNotStringMask'
    },
    {
        'name': 'StringTag',
        'value': 'kStringTag'
    },
    {
        'name': 'StringEncodingMask',
        'value': 'kStringEncodingMask'
    },
    {
        'name': 'TwoByteStringTag',
        'value': 'kTwoByteStringTag'
    },
    {
        'name': 'OneByteStringTag',
        'value': 'kOneByteStringTag'
    },
    {
        'name': 'StringRepresentationMask',
        'value': 'kStringRepresentationMask'
    },
    {
        'name': 'SeqStringTag',
        'value': 'kSeqStringTag'
    },
    {
        'name': 'ConsStringTag',
        'value': 'kConsStringTag'
    },
    {
        'name': 'ExternalStringTag',
        'value': 'kExternalStringTag'
    },
    {
        'name': 'SlicedStringTag',
        'value': 'kSlicedStringTag'
    },
    {
        'name': 'ThinStringTag',
        'value': 'kThinStringTag'
    },
    {
        'name': 'HeapObjectTag',
        'value': 'kHeapObjectTag'
    },
    {
        'name': 'HeapObjectTagMask',
        'value': 'kHeapObjectTagMask'
    },
    {
        'name': 'SmiTag',
        'value': 'kSmiTag'
    },
    {
        'name': 'SmiTagMask',
        'value': 'kSmiTagMask'
    },
    {
        'name': 'SmiValueShift',
        'value': 'kSmiTagSize'
    },
    {
        'name': 'SmiShiftSize',
        'value': 'kSmiShiftSize'
    },
    {
        'name': 'SystemPointerSize',
        'value': 'kSystemPointerSize'
    },
    {
        'name': 'SystemPointerSizeLog2',
        'value': 'kSystemPointerSizeLog2'
    },
    {
        'name': 'TaggedSize',
        'value': 'kTaggedSize'
    },
    {
        'name': 'TaggedSizeLog2',
        'value': 'kTaggedSizeLog2'
    },
    {
        'name': 'CodeKindFieldMask',
        'value': 'Code::KindField::kMask'
    },
    {
        'name': 'CodeKindFieldShift',
        'value': 'Code::KindField::kShift'
    },
    {
        'name': 'DeoptimizationDataInlinedFunctionCountIndex',
        'value': 'DeoptimizationData::kInlinedFunctionCountIndex'
    },
    {
        'name': 'DeoptimizationDataLiteralArrayIndex',
        'value': 'DeoptimizationData::kLiteralArrayIndex'
    },
    {
        'name': 'DeoptimizationDataOptimizationIdIndex',
        'value': 'DeoptimizationData::kOptimizationIdIndex'
    },
    {
        'name': 'DeoptimizationDataSharedFunctionInfoWrapperIndex',
        'value': 'DeoptimizationData::kSharedFunctionInfoWrapperIndex'
    },
    {
        'name': 'DeoptimizationDataInliningPositionsIndex',
        'value': 'DeoptimizationData::kInliningPositionsIndex'
    },
    {
        'name': 'CodeKindBytecodeHandler',
        'value': 'static_cast<int>(CodeKind::BYTECODE_HANDLER)'
    },
    {
        'name': 'CodeKindInterpretedFunction',
        'value': 'static_cast<int>(CodeKind::INTERPRETED_FUNCTION)'
    },
    {
        'name': 'CodeKindBaseline',
        'value': 'static_cast<int>(CodeKind::BASELINE)'
    },
    {
        'name': 'OddballFalse',
        'value': 'Oddball::kFalse'
    },
    {
        'name': 'OddballTrue',
        'value': 'Oddball::kTrue'
    },
    {
        'name': 'OddballNull',
        'value': 'Oddball::kNull'
    },
    {
        'name': 'OddballUndefined',
        'value': 'Oddball::kUndefined'
    },
    {
        'name': 'ContextRegister',
        'value': 'kContextRegister.code()'
    },
    {
        'name': 'ReturnRegister0',
        'value': 'kReturnRegister0.code()'
    },
    {
        'name': 'JSFunctionRegister',
        'value': 'kJSFunctionRegister.code()'
    },
    {
        'name': 'InterpreterBytecodeOffsetRegister',
        'value': 'kInterpreterBytecodeOffsetRegister.code()'
    },
    {
        'name': 'InterpreterBytecodeArrayRegister',
        'value': 'kInterpreterBytecodeArrayRegister.code()'
    },
    {
        'name': 'RuntimeCallFunctionRegister',
        'value': 'kRuntimeCallFunctionRegister.code()'
    },
    {
        'name': 'prop_kind_Data',
        'value': 'static_cast<int>(PropertyKind::kData)'
    },
    {
        'name': 'prop_kind_Accessor',
        'value': 'static_cast<int>(PropertyKind::kAccessor)'
    },
    {
        'name': 'prop_kind_mask',
        'value': 'PropertyDetails::KindField::kMask'
    },
    {
        'name': 'prop_location_Descriptor',
        'value': 'static_cast<int>(PropertyLocation::kDescriptor)'
    },
    {
        'name': 'prop_location_Field',
        'value': 'static_cast<int>(PropertyLocation::kField)'
    },
    {
        'name': 'prop_location_mask',
        'value': 'PropertyDetails::LocationField::kMask'
    },
    {
        'name': 'prop_location_shift',
        'value': 'PropertyDetails::LocationField::kShift'
    },
    {
        'name': 'prop_attributes_NONE',
        'value': 'NONE'
    },
    {
        'name': 'prop_attributes_READ_ONLY',
        'value': 'READ_ONLY'
    },
    {
        'name': 'prop_attributes_DONT_ENUM',
        'value': 'DONT_ENUM'
    },
    {
        'name': 'prop_attributes_DONT_DELETE',
        'value': 'DONT_DELETE'
    },
    {
        'name': 'prop_attributes_mask',
        'value': 'PropertyDetails::AttributesField::kMask'
    },
    {
        'name': 'prop_attributes_shift',
        'value': 'PropertyDetails::AttributesField::kShift'
    },
    {
        'name': 'prop_index_mask',
        'value': 'PropertyDetails::FieldIndexField::kMask'
    },
    {
        'name': 'prop_index_shift',
        'value': 'PropertyDetails::FieldIndexField::kShift'
    },
    {
        'name': 'prop_representation_mask',
        'value': 'PropertyDetails::RepresentationField::kMask'
    },
    {
        'name': 'prop_representation_shift',
        'value': 'PropertyDetails::RepresentationField::kShift'
    },
    {
        'name': 'prop_representation_smi',
        'value': 'Representation::Kind::kSmi'
    },
    {
        'name': 'prop_representation_double',
        'value': 'Representation::Kind::kDouble'
    },
    {
        'name': 'prop_representation_heapobject',
        'value': 'Representation::Kind::kHeapObject'
    },
    {
        'name': 'prop_representation_tagged',
        'value': 'Representation::Kind::kTagged'
    },
    {
        'name': 'prop_desc_key',
        'value': 'DescriptorArray::kEntryKeyIndex'
    },
    {
        'name': 'prop_desc_details',
        'value': 'DescriptorArray::kEntryDetailsIndex'
    },
    {
        'name': 'prop_desc_value',
        'value': 'DescriptorArray::kEntryValueIndex'
    },
    {
        'name': 'prop_desc_size',
        'value': 'DescriptorArray::kEntrySize'
    },
    {
        'name': 'elements_fast_holey_elements',
        'value': 'HOLEY_ELEMENTS'
    },
    {
        'name': 'elements_fast_elements',
        'value': 'PACKED_ELEMENTS'
    },
    {
        'name': 'elements_dictionary_elements',
        'value': 'DICTIONARY_ELEMENTS'
    },
    {
        'name': 'bit_field2_elements_kind_mask',
        'value': 'Map::Bits2::ElementsKindBits::kMask'
    },
    {
        'name': 'bit_field2_elements_kind_shift',
        'value': 'Map::Bits2::ElementsKindBits::kShift'
    },
    {
        'name': 'bit_field3_is_dictionary_map_shift',
        'value': 'Map::Bits3::IsDictionaryMapBit::kShift'
    },
    {
        'name': 'bit_field3_number_of_own_descriptors_mask',
        'value': 'Map::Bits3::NumberOfOwnDescriptorsBits::kMask'
    },
    {
        'name': 'bit_field3_number_of_own_descriptors_shift',
        'value': 'Map::Bits3::NumberOfOwnDescriptorsBits::kShift'
    },
    {
        'name': 'class_Map__instance_descriptors_offset',
        'value': 'Map::kInstanceDescriptorsOffset'
    },
    {
        'name': 'off_fp_context_or_frame_type',
        'value': 'CommonFrameConstants::kContextOrFrameTypeOffset'
    },
    {
        'name': 'off_fp_context',
        'value': 'StandardFrameConstants::kContextOffset'
    },
    {
        'name': 'off_fp_constant_pool',
        'value': 'StandardFrameConstants::kConstantPoolOffset'
    },
    {
        'name': 'off_fp_function',
        'value': 'StandardFrameConstants::kFunctionOffset'
    },
    {
        'name': 'off_fp_args',
        'value': 'StandardFrameConstants::kFixedFrameSizeAboveFp'
    },
    {
        'name': 'off_fp_bytecode_array',
        'value': 'InterpreterFrameConstants::kBytecodeArrayFromFp'
    },
    {
        'name': 'off_fp_bytecode_offset',
        'value': 'InterpreterFrameConstants::kBytecodeOffsetFromFp'
    },
    {
        'name': 'scopeinfo_idx_nparams',
        'value': 'ScopeInfo::kParameterCount'
    },
    {
        'name': 'scopeinfo_idx_ncontextlocals',
        'value': 'ScopeInfo::kContextLocalCount'
    },
    {
        'name': 'scopeinfo_idx_first_vars',
        'value': 'ScopeInfo::kVariablePartIndex'
    },
    {
        'name': 'jsarray_buffer_was_detached_mask',
        'value': 'JSArrayBuffer::WasDetachedBit::kMask'
    },
    {
        'name': 'jsarray_buffer_was_detached_shift',
        'value': 'JSArrayBuffer::WasDetachedBit::kShift'
    },
    {
        'name': 'context_idx_scope_info',
        'value': 'Context::SCOPE_INFO_INDEX'
    },
    {
        'name': 'context_idx_prev',
        'value': 'Context::PREVIOUS_INDEX'
    },
    {
        'name': 'context_min_slots',
        'value': 'Context::MIN_CONTEXT_SLOTS'
    },
    {
        'name': 'native_context_embedder_data_offset',
        'value': 'Internals::kNativeContextEmbedderDataOffset'
    },
    {
        'name': 'namedictionaryshape_prefix_size',
        'value': 'NameDictionaryShape::kPrefixSize'
    },
    {
        'name': 'namedictionaryshape_entry_size',
        'value': 'NameDictionaryShape::kEntrySize'
    },
    {
        'name': 'globaldictionaryshape_entry_size',
        'value': 'GlobalDictionaryShape::kEntrySize'
    },
    {
        'name': 'namedictionary_prefix_start_index',
        'value': 'NameDictionary::kPrefixStartIndex'
    },
    {
        'name': 'numberdictionaryshape_prefix_size',
        'value': 'NumberDictionaryShape::kPrefixSize'
    },
    {
        'name': 'numberdictionaryshape_entry_size',
        'value': 'NumberDictionaryShape::kEntrySize'
    },
    {
        'name': 'simplenumberdictionaryshape_prefix_size',
        'value': 'SimpleNumberDictionaryShape::kPrefixSize'
    },
    {
        'name': 'simplenumberdictionaryshape_entry_size',
        'value': 'SimpleNumberDictionaryShape::kEntrySize'
    },
    {
        'name': 'type_JSError__JS_ERROR_TYPE',
        'value': 'JS_ERROR_TYPE'
    },
]

#
# The following useful fields are missing accessors, so we define fake ones.
# Please note that extra accessors should _only_ be added to expose offsets that
# can be used to access actual V8 objects' properties. They should not be added
# for exposing other values. For instance, enumeration values or class'
# constants should be exposed by adding an entry in the "consts_misc" table, not
# in this "extras_accessors" table.
#
extras_accessors = [
    'JSFunction, code, Tagged<Code>, kCodeOffset',
    'JSFunction, context, Context, kContextOffset',
    'JSFunction, shared, SharedFunctionInfo, kSharedFunctionInfoOffset',
    'HeapObject, map, Map, kMapOffset',
    'JSObject, elements, Object, kElementsOffset',
    'JSObject, internal_fields, uintptr_t, kHeaderSize',
    'FixedArray, data, uintptr_t, kHeaderSize',
    'BytecodeArray, data, uintptr_t, kHeaderSize',
    'JSArrayBuffer, backing_store, uintptr_t, kBackingStoreOffset',
    'JSArrayBuffer, byte_length, size_t, kRawByteLengthOffset',
    'JSArrayBufferView, byte_length, size_t, kRawByteLengthOffset',
    'JSArrayBufferView, byte_offset, size_t, kRawByteOffsetOffset',
    'JSDate, value, Object, kValueOffset',
    'JSRegExp, source, Object, kSourceOffset',
    'JSTypedArray, external_pointer, uintptr_t, kExternalPointerOffset',
    'JSTypedArray, length, Object, kRawLengthOffset',
    'Map, instance_size_in_words, char, kInstanceSizeInWordsOffset',
    'Map, inobject_properties_start_or_constructor_function_index, char, kInobjectPropertiesStartOrConstructorFunctionIndexOffset',
    'Map, instance_type, uint16_t, kInstanceTypeOffset',
    'Map, bit_field, char, kBitFieldOffset',
    'Map, bit_field2, char, kBitField2Offset',
    'Map, bit_field3, int, kBitField3Offset',
    'Map, prototype, Object, kPrototypeOffset',
    'Oddball, kind, int, offsetof(Oddball, kind_)',
    'HeapNumber, value, double, offsetof(HeapNumber, value_)',
    'ExternalString, resource, Object, offsetof(ExternalString, resource_)',
    'SeqOneByteString, chars, char, OFFSET_OF_DATA_START(SeqOneByteString)',
    'SeqTwoByteString, chars, char, OFFSET_OF_DATA_START(SeqTwoByteString)',
    'UncompiledData, inferred_name, String, kInferredNameOffset',
    'UncompiledData, start_position, int32_t, kStartPositionOffset',
    'UncompiledData, end_position, int32_t, kEndPositionOffset',
    'Script, source, Object, kSourceOffset',
    'Script, name, Object, kNameOffset',
    'Script, line_ends, Object, kLineEndsOffset',
    'SharedFunctionInfo, raw_function_token_offset, int16_t, kFunctionTokenOffsetOffset',
    'SharedFunctionInfo, internal_formal_parameter_count, uint16_t, kFormalParameterCountOffset',
    'SharedFunctionInfo, flags, int, kFlagsOffset',
    'SharedFunctionInfo, length, uint16_t, kLengthOffset',
    'SlicedString, parent, String, offsetof(SlicedString, parent_)',
    'Code, flags, uint32_t, kFlagsOffset',
    'Code, instruction_start, Address, kInstructionStartOffset',
    'Code, instruction_stream, Tagged<InstructionStream>, kInstructionStreamOffset',
    'Code, instruction_size, int, kInstructionSizeOffset',
    'InstructionStream, instruction_start, uintptr_t, kHeaderSize',
    'String, length, int32_t, offsetof(String, length_)',
    'DescriptorArray, header_size, uintptr_t, kHeaderSize',
    'ConsString, first, String, offsetof(ConsString, first_)',
    'ConsString, second, String, offsetof(ConsString, second_)',
    'SlicedString, offset, SMI, offsetof(SlicedString, offset_)',
    'ThinString, actual, String, offsetof(ThinString, actual_)',
    'Symbol, name, Object, offsetof(Symbol, description_)',
    'FixedArrayBase, length, SMI, kLengthOffset',
]

#
# The following is a whitelist of classes we expect to find when scanning the
# source code. This list is not exhaustive, but it's still useful to identify
# when this script gets out of sync with the source. See load_objects().
#
expected_classes = [
    'ConsString', 'FixedArray', 'HeapNumber', 'JSArray', 'JSFunction',
    'JSObject', 'JSRegExp', 'JSPrimitiveWrapper', 'Map', 'Oddball', 'Script',
    'SeqOneByteString', 'SharedFunctionInfo', 'ScopeInfo', 'JSPromise',
    'DescriptorArray'
];


#
# The following structures store high-level representations of the structures
# for which we're going to emit descriptive constants.
#
types = {}  # set of all type names
typeclasses = {}  # maps type names to corresponding class names
klasses = {}  # known classes, including parents
fields = []  # field declarations
offsetof_fields = []  # field declarations using offsetof

header = '''
/*
 * This file is generated by %s.  Do not edit directly.
 */

#include "src/init/v8.h"
#include "src/codegen/register.h"
#include "src/execution/frames.h"
#include "src/execution/frames-inl.h" /* for architecture-specific frame constants */
#include "src/objects/contexts.h"
#include "src/objects/objects.h"
#include "src/objects/data-handler.h"
#include "src/objects/js-promise.h"
#include "src/objects/js-regexp-string-iterator.h"
#include "src/objects/megadom-handler.h"

namespace v8 {
namespace internal {

extern "C" {

/* stack frame constants */
#define FRAME_CONST(value, klass)       \
    V8_EXPORT int v8dbg_frametype_##klass = StackFrame::value;

STACK_FRAME_TYPE_LIST(FRAME_CONST)

#undef FRAME_CONST

''' % sys.argv[0]

footer = '''
}

}
}
'''

#
# Get the base class
#
def get_base_class(klass):
  if (klass == 'Object'):
    return klass;

  if (not (klass in klasses)):
    return None;

  k = klasses[klass];

  return get_base_class(k['parent']);

#
# Loads class hierarchy and type information from "objects.h" etc.
#
def load_objects():
  #
  # Construct a dictionary for the classes we're sure should be present.
  #
  checktypes = {};
  for klass in expected_classes:
    checktypes[klass] = True;


  for filename in sys.argv[2:]:
    if not filename.endswith("-inl.h"):
      load_objects_from_file(filename, checktypes)

  if (len(checktypes) > 0):
    for klass in checktypes:
      print('error: expected class \"%s\" not found' % klass);

    sys.exit(1);


def load_objects_from_file(objfilename, checktypes):
  objfile = io.open(objfilename, 'r', encoding='utf-8');
  in_insttype = False;
  in_torque_insttype = False
  in_torque_fulldef = False

  typestr = '';
  torque_typestr = ''
  torque_fulldefstr = ''
  uncommented_file = ''

  #
  # Iterate the header file line-by-line to collect type and class
  # information. For types, we accumulate a string representing the entire
  # InstanceType enum definition and parse it later because it's easier to
  # do so without the embedded newlines.
  #
  for line in objfile:
    if (line.startswith('enum InstanceType : uint16_t {')):
      in_insttype = True;
      continue;

    if (line.startswith('#define TORQUE_ASSIGNED_INSTANCE_TYPE_LIST')):
      in_torque_insttype = True
      continue

    if (line.startswith('#define TORQUE_INSTANCE_CHECKERS_SINGLE_FULLY_DEFINED')):
      in_torque_fulldef = True
      continue

    if (in_insttype and line.startswith('};')):
      in_insttype = False;
      continue;

    if (in_torque_insttype and (not line or line.isspace())):
      in_torque_insttype = False
      continue

    if (in_torque_fulldef and (not line or line.isspace())):
      in_torque_fulldef = False
      continue

    pre = line.strip()
    line = re.sub('// .*', '', line.strip());

    if (in_insttype):
      typestr += line;
      continue;

    if (in_torque_insttype):
      torque_typestr += line
      continue

    if (in_torque_fulldef):
      torque_fulldefstr += line
      continue

    uncommented_file += '\n' + line

  for match in re.finditer(
      r'\n(?:V8_OBJECT\s+)?class(?:\s+V8_EXPORT(?:_PRIVATE)?)?'
      r'\s+(\w[^:;]*)'
      r'(?:: public (\w[^{]*))?\s*{\s*', uncommented_file):
    klass = match.group(1).strip();
    pklass = match.group(2);
    if (pklass):
      # Check for generated Torque class.
      gen_match = re.match(
          r'TorqueGenerated\w+\s*<\s*\w+,\s*(\w+)\s*>',
          pklass)
      if (gen_match):
        pklass = gen_match.group(1)
      # Strip potential template arguments from parent
      # class.
      match = re.match(r'(\w+)(<.*>)?', pklass.strip());
      pklass = match.group(1).strip();
    klasses[klass] = { 'parent': pklass };

  #
  # Process the instance type declaration.
  #
  entries = typestr.split(',');
  for entry in entries:
    types[re.sub(r'\s*=.*', '', entry).lstrip()] = True
  entries = torque_typestr.split('\\')
  for entry in entries:
    name = re.sub(r' *V\(|\).*', '', entry)
    types[name] = True
  entries = torque_fulldefstr.split('\\')
  for entry in entries:
    entry = entry.strip()
    if not entry:
      continue
    start = entry.find('(');
    end = entry.find(')', start);
    rest = entry[start + 1: end];
    args = re.split(r'\s*,\s*', rest)
    typename = args[0]
    typeconst = args[1]
    types[typeconst] = True
    typeclasses[typeconst] = typename
  #
  # Infer class names for each type based on a systematic transformation.
  # For example, "JS_FUNCTION_TYPE" becomes "JSFunction".  We find the
  # class for each type rather than the other way around because there are
  # fewer cases where one type maps to more than one class than the other
  # way around.
  #
  for type in types:
    usetype = type

    #
    # Remove the "_TYPE" suffix and then convert to camel case,
    # except that a "JS" prefix remains uppercase (as in
    # "JS_FUNCTION_TYPE" => "JSFunction").
    #
    if (not usetype.endswith('_TYPE')):
      continue;

    usetype = usetype[0:len(usetype) - len('_TYPE')];
    parts = usetype.split('_');
    cctype = '';

    if (parts[0] == 'JS'):
      cctype = 'JS';
      start = 1;
    else:
      cctype = '';
      start = 0;

    for ii in range(start, len(parts)):
      part = parts[ii];
      cctype += part[0].upper() + part[1:].lower();

    #
    # Mapping string types is more complicated.  Both types and
    # class names for Strings specify a representation (e.g., Seq,
    # Cons, External, or Sliced) and an encoding (TwoByte/OneByte),
    # In the simplest case, both of these are explicit in both
    # names, as in:
    #
    #       EXTERNAL_ONE_BYTE_STRING_TYPE => ExternalOneByteString
    #
    # However, sometimes the type name has more information
    # than the class, as in:
    #
    #       CONS_ONE_BYTE_STRING_TYPE => ConsString
    #
    # To figure this out dynamically, we first check for a
    # representation and encoding.
    # If that doesn't yield a valid class name, we strip out the
    # representation.
    #
    if (cctype.endswith('String')):
      if (not (cctype in klasses)):
        cctype = re.sub('OneByte', '', cctype);
        cctype = re.sub('TwoByte', '', cctype);

    #
    # Despite all that, some types have no corresponding class.
    #
    if (cctype in klasses):
      typeclasses[type] = cctype;
      if (cctype in checktypes):
        del checktypes[cctype];

#
# For a given macro call, pick apart the arguments and return an object
# describing the corresponding output constant.  See load_fields().
#
def parse_field(call):
  # Replace newlines with spaces.
  for ii in range(0, len(call)):
    if (call[ii] == '\n'):
      call[ii] == ' ';

  idx = call.find('(');
  kind = call[0:idx];
  rest = call[idx + 1: len(call) - 1];
  args = re.findall(r'[^\s,][^(),]*(?:\([^()]*\))?(?=\s*(?:,|$))', rest)

  klass = args[0];
  field = args[1];
  dtype = None
  offset = None
  if kind.startswith('WEAK_ACCESSORS'):
    dtype = 'weak'
    offset = args[2];
  elif not (kind.startswith('SMI_ACCESSORS') or kind.startswith('ACCESSORS_TO_SMI')):
    dtype = args[2].replace('<', '_').replace('>', '_')
    offset = args[3];
  else:
    offset = args[2];
    dtype = 'SMI'

  if offset.startswith("offsetof(") or offset.startswith(
      "OFFSET_OF_DATA_START("):
    offsetof_fields.append((klass, field, offset))
    value = 'OffsetsForDebug::%s_%s' % (klass, field)
  else:
    value = '%s::%s' % (klass, offset)

  assert(offset is not None and dtype is not None);
  return ({'name': 'class_%s__%s__%s' % (klass, field, dtype), 'value': value})

#
# Load field offset information from objects-inl.h etc.
#
def load_fields():
  for filename in sys.argv[2:]:
    if filename.endswith("-inl.h"):
      load_fields_from_file(filename)

  for body in extras_accessors:
    fields.append(parse_field('ACCESSORS(%s)' % body));


def load_fields_from_file(filename):
  inlfile = io.open(filename, 'r', encoding='utf-8');

  #
  # Each class's fields and the corresponding offsets are described in the
  # source by calls to macros like "ACCESSORS" (and friends).  All we do
  # here is extract these macro invocations, taking into account that they
  # may span multiple lines and may contain nested parentheses.  We also
  # call parse_field() to pick apart the invocation.
  #
  prefixes = [ 'ACCESSORS', 'ACCESSORS2', 'ACCESSORS_GCSAFE',
         'SMI_ACCESSORS', 'ACCESSORS_TO_SMI',
         'RELEASE_ACQUIRE_ACCESSORS', 'WEAK_ACCESSORS' ];
  prefixes += ([ prefix + "_CHECKED" for prefix in prefixes ] +
         [ prefix + "_CHECKED2" for prefix in prefixes ])
  current = '';
  opens = 0;

  for line in inlfile:
    if (opens > 0):
      # Continuation line
      for ii in range(0, len(line)):
        if (line[ii] == '('):
          opens += 1;
        elif (line[ii] == ')'):
          opens -= 1;

        if (opens == 0):
          break;

      current += line[0:ii + 1];
      continue;

    for prefix in prefixes:
      if (not line.startswith(prefix + '(')):
        continue;

      if (len(current) > 0):
        fields.append(parse_field(current));
        current = '';

      for ii in range(len(prefix), len(line)):
        if (line[ii] == '('):
          opens += 1;
        elif (line[ii] == ')'):
          opens -= 1;

        if (opens == 0):
          break;

      current += line[0:ii + 1];

  if (len(current) > 0):
    fields.append(parse_field(current));
    current = '';

#
# Emit a block of constants.
#
def emit_constants(out, consts):
  lines = []

  # Fix up overzealous parses.  This could be done inside the
  # parsers but as there are several, it's easiest to do it here.
  ws = re.compile(r'\s+')
  for const in consts:
    name = ws.sub('', const['name'])
    value = ws.sub('', str(const['value']))  # Can be a number.
    lines.append('V8_EXPORT int v8dbg_%s = %s;' % (name, value))

  # Generate without duplicates and with preserved order.
  out.write('\n'.join(dict.fromkeys(lines)))
  out.write('\n');

#
# Emit the whole output file.
#
def emit_config():
  out = open(sys.argv[1], 'w');

  out.write(header);

  out.write("struct OffsetsForDebug {\n")
  for (klass, field, offset) in offsetof_fields:
    out.write("  static const int %s_%s = %s;\n" % (klass, field, offset))
  out.write("};\n")

  out.write('/* miscellaneous constants */\n');
  emit_constants(out, consts_misc);

  out.write('/* class type information */\n');
  consts = [];
  for typename in sorted(typeclasses):
    klass = typeclasses[typename];
    consts.append({
        'name': 'type_%s__%s' % (klass, typename),
        'value': typename
    });

  emit_constants(out, consts);

  out.write('/* class hierarchy information */\n');
  consts = [];
  for klassname in sorted(klasses):
    pklass = klasses[klassname]['parent'];
    if (klassname == pklass):
      continue
    bklass = get_base_class(klassname);
    if (bklass != 'Object'):
      continue;
    if (pklass is None):
      continue;

    consts.append({
        'name': 'parent_%s__%s' % (klassname, pklass),
        'value': 0
    });

  emit_constants(out, consts);

  out.write('/* field information */\n');
  emit_constants(out, fields);

  out.write(footer);

if (len(sys.argv) < 4):
  print('usage: %s output.cc objects.h objects-inl.h' % sys.argv[0]);
  sys.exit(2);

load_objects();
load_fields();
emit_config();
                                                              node-23.7.0/deps/v8/tools/gen-v8-gn.py                                                              0000775 0000000 0000000 00000005107 14746647661 0017273 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3

# Copyright 2021 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

import argparse
import os
import sys

if (sys.version_info >= (3, 0)):
  from io import StringIO
else:
  from io import BytesIO as StringIO


def parse_args():
  global args
  parser = argparse.ArgumentParser()
  parser.add_argument('-o', '--output', type=str, action='store',
                      help='Location of header file to generate')
  parser.add_argument('-p', '--positive-define', type=str, action='append',
                      help='Externally visibile positive definition')
  parser.add_argument('-n', '--negative-define', type=str, action='append',
                      help='Externally visibile negative definition')
  args = parser.parse_args()

def generate_positive_definition(out, define):
  out.write('''
#ifndef {define}
#define {define} 1
#else
#if {define} != 1
#error "{define} defined but not set to 1"
#endif
#endif  // {define}
'''.format(define=define))

def generate_negative_definition(out, define):
  out.write('''
#ifdef {define}
#error "{define} is defined but is disabled by V8's GN build arguments"
#endif  // {define}
'''.format(define=define))

def generate_header(out):
  out.write('''// AUTOMATICALLY GENERATED. DO NOT EDIT.

// The following definitions were used when V8 itself was built, but also appear
// in the externally-visible header files and so must be included by any
// embedder. This will be done automatically if V8_GN_HEADER is defined.
// Ready-compiled distributions of V8 will need to provide this generated header
// along with the other headers in include.

// This header must be stand-alone because it is used across targets without
// introducing dependencies. It should only be included via v8config.h.
''')
  if args.positive_define:
    for define in args.positive_define:
      generate_positive_definition(out, define)

  if args.negative_define:
    for define in args.negative_define:
      generate_negative_definition(out, define)

def main():
  parse_args()
  header_stream = StringIO("")
  generate_header(header_stream)
  contents = header_stream.getvalue()
  if args.output:
    # Check if the contents has changed before writing so we don't cause build
    # churn.
    old_contents = None
    if os.path.exists(args.output):
      with open(args.output, 'r') as f:
        old_contents = f.read()
    if old_contents != contents:
      with open(args.output, 'w') as f:
        f.write(contents)
  else:
    print(contents)

if __name__ == '__main__':
  main()
                                                                                                                                                                                                                                                                                                                                                                                                                                                         node-23.7.0/deps/v8/tools/generate-builtins-tests.py                                                0000775 0000000 0000000 00000011033 14746647661 0022341 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3
# Copyright 2014 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

# for py2/py3 compatibility
from __future__ import print_function

import json
import optparse
import os
import random
import shutil
import subprocess
import sys


SKIPLIST = [
  # Skip special d8 functions.
  "load", "os", "print", "read", "readline", "quit"
]


def GetRandomObject():
  return random.choice([
    "0", "1", "2.5", "0x1000", "\"string\"", "{foo: \"bar\"}", "[1, 2, 3]",
    "function() { return 0; }"
  ])


g_var_index = 0


def GetVars(result, num, first = []):
  global g_var_index
  variables = []
  for i in range(num):
    variables.append("__v_%d" % g_var_index)
    g_var_index += 1
  for var in variables:
    result.append("var %s = %s;" % (var, GetRandomObject()))
  return ", ".join(first + variables)


# Wraps |string| in try..catch.
def TryCatch(result, string, exception_behavior = ""):
  result.append("try { %s } catch(e) { %s }" % (string, exception_behavior))


def BuildTests(function, full_name, options):
  assert function["type"] == "function"
  global g_var_index
  g_var_index = 0
  result = ["// AUTO-GENERATED BY tools/generate-builtins-tests.py.\n"]
  result.append("// Function call test:")
  length = function["length"]
  TryCatch(result, "%s(%s);" % (full_name, GetVars(result, length)))

  if "prototype" in function:
    proto = function["prototype"]
    result.append("\n// Constructor test:")
    TryCatch(result,
             "var recv = new %s(%s);" % (full_name, GetVars(result, length)),
             "var recv = new Object();")

    getters = []
    methods = []
    for prop in proto:
      proto_property = proto[prop]
      proto_property_type = proto_property["type"]
      if proto_property_type == "getter":
        getters.append(proto_property)
        result.append("recv.__defineGetter__(\"%s\", "
                      "function() { return %s; });" %
                      (proto_property["name"], GetVars(result, 1)))
      if proto_property_type == "number":
        result.append("recv.__defineGetter__(\"%s\", "
                      "function() { return %s; });" %
                      (proto_property["name"], GetVars(result, 1)))
      if proto_property_type == "function":
        methods.append(proto_property)
    if getters:
      result.append("\n// Getter tests:")
      for getter in getters:
        result.append("print(recv.%s);" % getter["name"])
    if methods:
      result.append("\n// Method tests:")
      for method in methods:
        args = GetVars(result, method["length"], ["recv"])
        call = "%s.prototype.%s.call(%s)" % (full_name, method["name"], args)
        TryCatch(result, call)

  filename = os.path.join(options.outdir, "%s.js" % (full_name))
  with open(filename, "w") as f:
    f.write("\n".join(result))
    f.write("\n")


def VisitObject(obj, path, options):
  obj_type = obj["type"]
  obj_name = "%s%s" % (path, obj["name"])
  if obj_type == "function":
    BuildTests(obj, obj_name, options)
  if "properties" in obj:
    for prop_name in obj["properties"]:
      prop = obj["properties"][prop_name]
      VisitObject(prop, "%s." % (obj_name), options)


def ClearGeneratedFiles(options):
  if os.path.exists(options.outdir):
    shutil.rmtree(options.outdir)


def GenerateTests(options):
  ClearGeneratedFiles(options)  # Re-generate everything.
  output = subprocess.check_output(
      "%s %s" % (options.d8, options.script), shell=True).strip()
  objects = json.loads(output)

  os.makedirs(options.outdir)
  for obj_name in objects:
    if obj_name in SKIPLIST: continue
    obj = objects[obj_name]
    VisitObject(obj, "", options)


def BuildOptions():
  result = optparse.OptionParser()
  result.add_option("--d8", help="d8 binary to use",
                    default="out/ia32.release/d8")
  result.add_option("--outdir", help="directory where to place generated tests",
                    default="test/mjsunit/builtins-gen")
  result.add_option("--script", help="builtins detector script to run in d8",
                    default="tools/detect-builtins.js")
  return result


def Main():
  parser = BuildOptions()
  (options, args) = parser.parse_args()
  if len(args) != 1 or args[0] == "help":
    parser.print_help()
    return 1
  action = args[0]

  if action == "generate":
    GenerateTests(options)
    return 0

  if action == "clear":
    ClearGeneratedFiles(options)
    return 0

  print("Unknown action: %s" % action)
  parser.print_help()
  return 1


if __name__ == "__main__":
  sys.exit(Main())
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     node-23.7.0/deps/v8/tools/generate-header-include-checks.py                                         0000775 0000000 0000000 00000013450 14746647661 0023464 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3
# vim:fenc=utf-8:shiftwidth=2

# Copyright 2018 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

"""Check that each header can be included in isolation.

For each header we generate one .cc file which only includes this one header.
All these .cc files are then added to a sources.gni file which is included in
BUILD.gn. Just compile to check whether there are any violations to the rule
that each header must be includable in isolation.
"""

# for py2/py3 compatibility
from __future__ import print_function

import argparse
import os
import os.path
import re
import sys

# TODO(clemensb): Extend to tests.
DEFAULT_INPUT = ['include', 'src']
DEFAULT_GN_FILE = 'BUILD.gn'
MY_DIR = os.path.dirname(os.path.realpath(__file__))
V8_DIR = os.path.dirname(MY_DIR)
OUT_DIR = os.path.join(V8_DIR, 'check-header-includes')
AUTO_EXCLUDE = [
    # Platform specific for iOS.
    'src/base/ios-headers.h',
    # flag-definitions.h needs a mode set for being included.
    'src/flags/flag-definitions.h',
    # recorder.h should only be included conditionally.
    'src/libplatform/tracing/recorder.h',
    # trap-handler-simulator.h can only be included in simulator builds.
    'src/trap-handler/trap-handler-simulator.h',
    # The src/wasm/*-impl.h coding pattern is generally at odds with the rule
    # being enforced here: they are meant to provide possibly-incomplete
    # templates, and their users must provide their prerequisites.
    'src/wasm/function-body-decoder-impl.h',
    'src/wasm/module-decoder-impl.h',
    # TODO(carlscab): Enable once Perfetto is built by default.
    'src/tracing/code-data-source.h',
    'src/tracing/code-trace-context.h',
    'src/tracing/perfetto-logger.h',
    'src/tracing/perfetto-utils.h',
]
AUTO_EXCLUDE_PATTERNS = [
    'src/base/atomicops_internals_.*',
    # TODO(petermarshall): Enable once Perfetto is built by default.
    'src/libplatform/tracing/perfetto*',
    # TODO(v8:7700): Enable once Maglev is built by default.
    'src/maglev/.*',
] + [
    # platform-specific headers
    '\\b{}\\b'.format(p)
    for p in ('win', 'win32', 'ia32', 'x64', 'arm', 'arm64', 'mips64', 's390',
              'ppc', 'riscv', 'riscv64', 'riscv32', 'loong64')
]

args = None
def parse_args():
  global args
  parser = argparse.ArgumentParser()
  parser.add_argument('-i', '--input', type=str, action='append',
                      help='Headers or directories to check (directories '
                           'are scanned for headers recursively); default: ' +
                           ','.join(DEFAULT_INPUT))
  parser.add_argument('-x', '--exclude', type=str, action='append',
                      help='Add an exclude pattern (regex)')
  parser.add_argument('-v', '--verbose', action='store_true',
                      help='Be verbose')
  args = parser.parse_args()
  args.exclude = (args.exclude or []) + AUTO_EXCLUDE_PATTERNS
  args.exclude += ['^' + re.escape(x) + '$' for x in AUTO_EXCLUDE]
  if not args.input:
    args.input=DEFAULT_INPUT


def printv(line):
  if args.verbose:
    print(line)


def find_all_headers():
  printv('Searching for headers...')
  header_files = []
  exclude_patterns = [re.compile(x) for x in args.exclude]
  def add_recursively(filename):
    full_name = os.path.join(V8_DIR, filename)
    if not os.path.exists(full_name):
      sys.exit('File does not exist: {}'.format(full_name))
    if os.path.isdir(full_name):
      for subfile in os.listdir(full_name):
        full_name = os.path.join(filename, subfile)
        printv('Scanning {}'.format(full_name))
        add_recursively(full_name)
    elif filename.endswith('.h'):
      printv('--> Found header file {}'.format(filename))
      for p in exclude_patterns:
        if p.search(filename):
          printv('--> EXCLUDED (matches {})'.format(p.pattern))
          return
      header_files.append(filename)

  for filename in args.input:
    add_recursively(filename)

  return header_files


def get_cc_file_name(header):
  split = os.path.split(header)
  header_dir = os.path.relpath(split[0], V8_DIR)
  # Prefix with the directory name, to avoid collisions in the object files.
  prefix = header_dir.replace(os.path.sep, '-')
  cc_file_name = 'test-include-' + prefix + '-' + split[1][:-1] + 'cc'
  return os.path.join(OUT_DIR, cc_file_name)


def create_including_cc_files(header_files):
  comment = 'check including this header in isolation'
  for header in header_files:
    cc_file_name = get_cc_file_name(header)
    rel_cc_file_name = os.path.relpath(cc_file_name, V8_DIR)
    content = '#include "{}"  // {}\n'.format(header, comment)
    if os.path.exists(cc_file_name):
      with open(cc_file_name) as cc_file:
        if cc_file.read() == content:
          printv('File {} is up to date'.format(rel_cc_file_name))
          continue
    printv('Creating file {}'.format(rel_cc_file_name))
    with open(cc_file_name, 'w') as cc_file:
      cc_file.write(content)


def generate_gni(header_files):
  gni_file = os.path.join(OUT_DIR, 'sources.gni')
  printv('Generating file "{}"'.format(os.path.relpath(gni_file, V8_DIR)))
  with open(gni_file, 'w') as gn:
    gn.write("""\
# Copyright 2018 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

# This list is filled automatically by tools/check_header_includes.py.
check_header_includes_sources = [
""");
    for header in header_files:
      cc_file_name = get_cc_file_name(header)
      gn.write('    "{}",\n'.format(os.path.relpath(cc_file_name, V8_DIR)))
    gn.write(']\n')


def main():
  parse_args()
  header_files = find_all_headers()
  if not os.path.exists(OUT_DIR):
    os.mkdir(OUT_DIR)
  create_including_cc_files(header_files)
  generate_gni(header_files)

if __name__ == '__main__':
  main()
                                                                                                                                                                                                                        node-23.7.0/deps/v8/tools/generate-runtime-call-stats.py                                            0000775 0000000 0000000 00000033500 14746647661 0023103 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/python3
# Copyright 2019 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

# Runs chromium/src/run_benchmark for a given story and extracts the generated
# runtime call stats.

import argparse
import csv
import json
import glob
import os
import pathlib
import re
import tabulate
import shutil
import statistics
import subprocess
import sys
import tempfile

from callstats_groups import RUNTIME_CALL_STATS_GROUPS


JSON_FILE_EXTENSION=".pb_converted.json"

def parse_args():
  parser = argparse.ArgumentParser(
      description="Run story and collect runtime call stats.")
  parser.add_argument("story", metavar="story", nargs=1, help="story to run")
  parser.add_argument(
      "--group",
      dest="group",
      action="store_true",
      help="group common stats together into buckets")
  parser.add_argument(
      "-r",
      "--repeats",
      dest="repeats",
      metavar="N",
      action="store",
      type=int,
      default=1,
      help="number of times to run the story")
  parser.add_argument(
      "-v",
      "--verbose",
      dest="verbose",
      action="store_true",
      help="output benchmark runs to stdout")
  parser.add_argument(
      "--device",
      dest="device",
      action="store",
      help="device to run the test on. Passed directly to run_benchmark")
  parser.add_argument(
      "-d",
      "--dir",
      dest="dir",
      action="store",
      help=("directory to look for already generated output in. This must "
            "already exists and it won't re-run the benchmark"))
  parser.add_argument(
      "-f",
      "--format",
      dest="format",
      action="store",
      choices=["csv", "table"],
      help="output as CSV")
  parser.add_argument(
      "-o",
      "--output",
      metavar="FILE",
      dest="out_file",
      action="store",
      help="write table to FILE rather stdout")
  parser.add_argument(
      "--browser",
      dest="browser",
      metavar="BROWSER_TYPE",
      action="store",
      default="release",
      help=("Passed directly to --browser option of run_benchmark. Ignored if "
            "-executable is used"))
  parser.add_argument(
      "-e",
      "--executable",
      dest="executable",
      metavar="EXECUTABLE",
      action="store",
      help=("path to executable to run. If not given it will pass '--browser "
            "release' to run_benchmark"))
  parser.add_argument(
      "--chromium-dir",
      dest="chromium_dir",
      metavar="DIR",
      action="store",
      default=".",
      help=("path to chromium directory. If not given, the script must be run "
            "inside the chromium/src directory"))
  parser.add_argument(
      "--js-flags", dest="js_flags", action="store", help="flags to pass to v8")
  parser.add_argument(
      "--extra-browser-args",
      dest="browser_args",
      action="store",
      help="flags to pass to chrome")
  parser.add_argument(
      "--benchmark",
      dest="benchmark",
      action="store",
      default="v8.browsing_desktop",
      help="benchmark to run")
  parser.add_argument(
      "--stdev",
      dest="stdev",
      action="store_true",
      help="adds columns for the standard deviation")
  parser.add_argument(
      "--filter",
      dest="filter",
      action="append",
      help="useable with --group to only show buckets specified by filter")
  parser.add_argument(
      "--retain",
      dest="retain",
      action="store",
      default="json",
      choices=["none", "json", "all"],
      help=("controls artifacts to be retained after run. With none, all files "
            "are deleted; only the json.gz file is retained for each run; and "
            "all keep all files"))

  return parser.parse_args()


def process_trace(trace_file):
  text_string = pathlib.Path(trace_file).read_text()
  result = json.loads(text_string)

  output = {}
  result = result["traceEvents"]
  for o in result:
    o = o["args"]
    if "runtime-call-stats" in o:
      r = o["runtime-call-stats"]
      for name in r:
        count = r[name][0]
        duration = r[name][1]
        if name in output:
          output[name]["count"] += count
          output[name]["duration"] += duration
        else:
          output[name] = {"count": count, "duration": duration}

  return output


def run_benchmark(story,
                  repeats=1,
                  output_dir=".",
                  verbose=False,
                  js_flags=None,
                  browser_args=None,
                  chromium_dir=".",
                  executable=None,
                  benchmark="v8.browsing_desktop",
                  device=None,
                  browser="release"):

  orig_chromium_dir = chromium_dir
  xvfb = os.path.join(chromium_dir, "testing", "xvfb.py")
  if not os.path.isfile(xvfb):
    chromium_dir = os.path(chromium_dir, "src")
    xvfb = os.path.join(chromium_dir, "testing", "xvfb.py")
    if not os.path.isfile(xvfb):
      print(("chromium_dir does not point to a valid chromium checkout: " +
             orig_chromium_dir))
      sys.exit(1)

  command = [
      xvfb,
      os.path.join(chromium_dir, "tools", "perf", "run_benchmark"),
      "run",
      "--story",
      story,
      "--pageset-repeat",
      str(repeats),
      "--output-dir",
      output_dir,
      "--intermediate-dir",
      os.path.join(output_dir, "artifacts"),
      benchmark,
  ]

  if executable:
    command += ["--browser-executable", executable]
  else:
    command += ["--browser", browser]

  if device:
    command += ["--device", device]
  if browser_args:
    command += ["--extra-browser-args", browser_args]
  if js_flags:
    command += ["--js-flags", js_flags]

  if not benchmark.startswith("v8."):
    # Most benchmarks by default don't collect runtime call stats so enable them
    # manually.
    categories = [
        "v8",
        "disabled-by-default-v8.runtime_stats",
    ]

    command += ["--extra-chrome-categories", ",".join(categories)]

  print("Output directory: %s" % output_dir)
  stdout = ""
  print(f"Running: {' '.join(command)}\n")
  proc = subprocess.Popen(
      command,
      stdout=subprocess.PIPE,
      stderr=subprocess.PIPE,
      universal_newlines=True)
  proc.stderr.close()
  status_matcher = re.compile(r"\[ +(\w+) +\]")
  for line in iter(proc.stdout.readline, ""):
    stdout += line
    match = status_matcher.match(line)
    if verbose or match:
      print(line, end="")

  proc.stdout.close()

  if proc.wait() != 0:
    print("\nrun_benchmark failed:")
    # If verbose then everything has already been printed.
    if not verbose:
      print(stdout)
    sys.exit(1)

  print("\nrun_benchmark completed")


def write_output(f, table, headers, run_count, format="table"):
  if format == "csv":
    # strip new lines from CSV output
    headers = [h.replace("\n", " ") for h in headers]
    writer = csv.writer(f)
    writer.writerow(headers)
    writer.writerows(table)
  else:
    # First column is name, and then they alternate between counts and durations
    summary_count = len(headers) - 2 * run_count - 1
    floatfmt = ("",) + (".0f", ".2f") * run_count + (".2f",) * summary_count
    f.write(tabulate.tabulate(table, headers=headers, floatfmt=floatfmt))
    f.write("\n")


class Row:

  def __init__(self, name, run_count):
    self.name = name
    self.durations = [0] * run_count
    self.counts = [0] * run_count
    self.mean_duration = None
    self.mean_count = None
    self.stdev_duration = None
    self.stdev_count = None

  def __repr__(self):
    data_str = ", ".join(
        str((c, d)) for (c, d) in zip(self.counts, self.durations))
    return (f"{self.name}: {data_str}, mean_count: {self.mean_count}, " +
            f"mean_duration: {self.mean_duration}")

  def add_data(self, counts, durations):
    self.counts = counts
    self.durations = durations

  def add_data_point(self, run, count, duration):
    self.counts[run] = count
    self.durations[run] = duration

  def prepare(self, stdev=False):
    if len(self.durations) > 1:
      self.mean_duration = statistics.mean(self.durations)
      self.mean_count = statistics.mean(self.counts)
      if stdev:
        self.stdev_duration = statistics.stdev(self.durations)
        self.stdev_count = statistics.stdev(self.counts)

  def as_list(self):
    l = [self.name]
    for (c, d) in zip(self.counts, self.durations):
      l += [c, d]
    if self.mean_duration is not None:
      l += [self.mean_count]
      if self.stdev_count is not None:
        l += [self.stdev_count]
      l += [self.mean_duration]
      if self.stdev_duration is not None:
        l += [self.stdev_duration]
    return l

  def key(self):
    if self.mean_duration is not None:
      return self.mean_duration
    else:
      return self.durations[0]


class Bucket:

  def __init__(self, name, run_count):
    self.name = name
    self.run_count = run_count
    self.data = {}
    self.table = None
    self.total_row = None

  def __repr__(self):
    s = "Bucket: " + self.name + " {\n"
    if self.table:
      s += "\n  ".join(str(row) for row in self.table) + "\n"
    elif self.data:
      s += "\n  ".join(str(row) for row in self.data.values()) + "\n"
    if self.total_row:
      s += "  " + str(self.total_row) + "\n"
    return s + "}"

  def add_data_point(self, name, run, count, duration):
    if name not in self.data:
      self.data[name] = Row(name, self.run_count)

    self.data[name].add_data_point(run, count, duration)

  def prepare(self, stdev=False):
    if self.data:
      for row in self.data.values():
        row.prepare(stdev)

      self.table = sorted(self.data.values(), key=Row.key)
      self.total_row = Row("Total", self.run_count)
      self.total_row.add_data([
          sum(r.counts[i]
              for r in self.data.values())
          for i in range(0, self.run_count)
      ], [
          sum(r.durations[i]
              for r in self.data.values())
          for i in range(0, self.run_count)
      ])
      self.total_row.prepare(stdev)

  def as_list(self, add_bucket_titles=True, filter=None):
    t = []
    if filter is None or self.name in filter:
      if add_bucket_titles:
        t += [["\n"], [self.name]]
      t += [r.as_list() for r in self.table]
      t += [self.total_row.as_list()]
    return t


def collect_buckets(story, group=True, repeats=1, output_dir="."):
  if group:
    groups = RUNTIME_CALL_STATS_GROUPS
  else:
    groups = []

  buckets = {}

  for i in range(0, repeats):
    story_dir = f"{story.replace(':', '_')}_{i + 1}"
    trace_dir = os.path.join(output_dir, "artifacts", story_dir, "trace",
                             "traceEvents")

    # run_benchmark now dumps two files: a .pb.gz file and a .pb_converted.json
    # file. We only need the latter.
    trace_file_glob = os.path.join(trace_dir, "*" + JSON_FILE_EXTENSION)
    trace_files = glob.glob(trace_file_glob)
    if not trace_files:
      print("Could not find *%s file in %s" % (JSON_FILE_EXTENSION, trace_dir))
      sys.exit(1)
    if len(trace_files) > 1:
      print("Expecting one file but got: %s" % trace_files)
      sys.exit(1)

    trace_file = trace_files[0]

    output = process_trace(trace_file)
    for name in output:
      bucket_name = "Other"
      for group in groups:
        if group[1].match(name):
          bucket_name = group[0]
          break

      value = output[name]
      if bucket_name not in buckets:
        bucket = Bucket(bucket_name, repeats)
        buckets[bucket_name] = bucket
      else:
        bucket = buckets[bucket_name]

      bucket.add_data_point(name, i, value["count"], value["duration"] / 1000.0)
  return buckets


def create_table(buckets, record_bucket_names=True, filter=None):
  table = []
  for bucket in buckets.values():
    table += bucket.as_list(
        add_bucket_titles=record_bucket_names, filter=filter)
  return table


def main():
  args = parse_args()
  story = args.story[0]

  retain = args.retain
  if args.dir is not None:
    output_dir = args.dir
    if not os.path.isdir(output_dir):
      print("Specified output directory does not exist: " % output_dir)
      sys.exit(1)
  else:
    output_dir = tempfile.mkdtemp(prefix="runtime_call_stats_")
    run_benchmark(
        story,
        repeats=args.repeats,
        output_dir=output_dir,
        verbose=args.verbose,
        js_flags=args.js_flags,
        browser_args=args.browser_args,
        chromium_dir=args.chromium_dir,
        benchmark=args.benchmark,
        executable=args.executable,
        browser=args.browser,
        device=args.device)

  try:
    buckets = collect_buckets(
        story, group=args.group, repeats=args.repeats, output_dir=output_dir)

    for b in buckets.values():
      b.prepare(args.stdev)

    table = create_table(
        buckets, record_bucket_names=args.group, filter=args.filter)

    headers = [""] + ["Count", "Duration\n(ms)"] * args.repeats
    if args.repeats > 1:
      if args.stdev:
        headers += [
            "Count\nMean", "Count\nStdev", "Duration\nMean (ms)",
            "Duration\nStdev (ms)"
        ]
      else:
        headers += ["Count\nMean", "Duration\nMean (ms)"]

    if args.out_file:
      with open(args.out_file, "w", newline="") as f:
        write_output(f, table, headers, args.repeats, args.format)
    else:
      write_output(sys.stdout, table, headers, args.repeats, args.format)
  finally:
    if retain == "none":
      shutil.rmtree(output_dir)
    elif retain == "json":
      # Delete all files bottom up except ones ending in JSON_FILE_EXTENSION and
      # attempt to delete subdirectories (ignoring errors).
      for dir_name, subdir_list, file_list in os.walk(
          output_dir, topdown=False):
        for file_name in file_list:
          if not file_name.endswith(JSON_FILE_EXTENSION):
            os.remove(os.path.join(dir_name, file_name))
        for subdir in subdir_list:
          try:
            os.rmdir(os.path.join(dir_name, subdir))
          except OSError:
            pass


if __name__ == "__main__":
  sys.exit(main())
                                                                                                                                                                                                node-23.7.0/deps/v8/tools/generate-ten-powers.scm                                                   0000664 0000000 0000000 00000024554 14746647661 0021616 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        ;; Copyright 2010 the V8 project authors. All rights reserved.
;; Redistribution and use in source and binary forms, with or without
;; modification, are permitted provided that the following conditions are
;; met:
;;
;;     * Redistributions of source code must retain the above copyright
;;       notice, this list of conditions and the following disclaimer.
;;     * Redistributions in binary form must reproduce the above
;;       copyright notice, this list of conditions and the following
;;       disclaimer in the documentation and/or other materials provided
;;       with the distribution.
;;     * Neither the name of Google Inc. nor the names of its
;;       contributors may be used to endorse or promote products derived
;;       from this software without specific prior written permission.
;;
;; THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
;; "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
;; LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
;; A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
;; OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
;; SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
;; LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
;; DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
;; THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
;; (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
;; OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

;; This is a Scheme script for the Bigloo compiler. Bigloo must be compiled with
;; support for bignums. The compilation of the script can be done as follows:
;;   bigloo -static-bigloo -o generate-ten-powers generate-ten-powers.scm
;;  
;; Generate approximations of 10^k.

(module gen-ten-powers
   (static (class Cached-Fast
	      v::bignum
	      e::bint
	      exact?::bool))
   (main my-main))


;;----------------bignum shifts -----------------------------------------------
(define (bit-lshbx::bignum x::bignum by::bint)
   (if (<fx by 0)
       #z0
       (*bx x (exptbx #z2 (fixnum->bignum by)))))

(define (bit-rshbx::bignum x::bignum by::bint)
   (if (<fx by 0)
       #z0
       (/bx x (exptbx #z2 (fixnum->bignum by)))))

;;----------------the actual power generation -------------------------------

;; e should be an indication. it might be too small.
(define (round-n-cut n e nb-bits)
   (define max-container (- (bit-lshbx #z1 nb-bits) 1))
   (define (round n)
      (case *round*
	 ((down) n)
	 ((up)
	  (+bx n
	       ;; with the -1 it will only round up if the cut off part is
	       ;; non-zero
	       (-bx (bit-lshbx #z1
			       (-fx (+fx e nb-bits) 1))
		    #z1)))
	 ((round)
	  (+bx n
	       (bit-lshbx #z1
			  (-fx (+fx e nb-bits) 2))))))
   (let* ((shift (-fx (+fx e nb-bits) 1))
	  (cut (bit-rshbx (round n) shift))
	  (exact? (=bx n (bit-lshbx cut shift))))
      (if (<=bx cut max-container)
	  (values cut e exact?)
	  (round-n-cut n (+fx e 1) nb-bits))))

(define (rounded-/bx x y)
   (case *round*
      ((down)  (/bx x y))
      ((up)    (+bx (/bx x y) #z1))
      ((round) (let ((tmp (/bx (*bx #z2 x) y)))
		  (if (zerobx? (remainderbx tmp #z2))
		      (/bx tmp #z2)
		      (+bx (/bx tmp #z2) #z1))))))

(define (generate-powers from to mantissa-size)
   (let* ((nb-bits mantissa-size)
	  (offset (- from))
	  (nb-elements (+ (- from) to 1))
	  (vec (make-vector nb-elements))
	  (max-container (- (bit-lshbx #z1 nb-bits) 1)))
      ;; the negative ones. 10^-1, 10^-2, etc.
      ;; We already know, that we can't be exact, so exact? will always be #f.
      ;; Basically we will have a ten^i that we will *10 at each iteration. We
      ;; want to create the matissa of 1/ten^i. However the mantissa must be
      ;; normalized (start with a 1). -> we have to shift the number.
      ;; We shift by multiplying with two^e. -> We encode two^e*(1/ten^i) ==
      ;;  two^e/ten^i.
      (let loop ((i 1)
		 (ten^i #z10)
		 (two^e #z1)
		 (e 0))
	 (unless (< (- i) from)
	    (if (>bx (/bx (*bx #z2 two^e) ten^i) max-container)
		;; another shift would make the number too big. We are
		;; hence normalized now.
		(begin
		   (vector-set! vec (-fx offset i)
				(instantiate::Cached-Fast
				   (v (rounded-/bx two^e ten^i))
				   (e (negfx e))
				   (exact? #f)))
		   (loop (+fx i 1) (*bx ten^i #z10) two^e e))
		(loop i ten^i (bit-lshbx two^e 1) (+fx e 1)))))
      ;; the positive ones 10^0, 10^1, etc.
      ;; start with 1.0. mantissa: 10...0 (1 followed by nb-bits-1 bits)
      ;;      -> e = -(nb-bits-1)
      ;; exact? is true when the container can still hold the complete 10^i
      (let loop ((i 0)
		 (n (bit-lshbx #z1 (-fx nb-bits 1)))
		 (e (-fx 1 nb-bits)))
	 (when (<= i to)
	    (receive (cut e exact?)
	       (round-n-cut n e nb-bits)
	       (vector-set! vec (+fx i offset)
			    (instantiate::Cached-Fast
			       (v cut)
			       (e e)
			       (exact? exact?)))
	       (loop (+fx i 1) (*bx n #z10) e))))
      vec))

(define (print-c powers from to struct-type
		 cache-name max-distance-name offset-name macro64)
   (define (display-power power k)
      (with-access::Cached-Fast power (v e exact?)
	 (let ((tmp-p (open-output-string)))
	    ;; really hackish way of getting the digits
	    (display (format "~x" v) tmp-p)
	    (let ((str (close-output-port tmp-p)))
	       (printf "  {~a(0x~a, ~a), ~a, ~a},\n"
		       macro64
		       (substring str 0 8)
		       (substring str 8 16)
		       e
		       k)))))
   (define (print-powers-reduced n)
      (print "static const " struct-type " " cache-name
	     "(" n ")"
	     "[] = {")
      (let loop ((i 0)
		 (nb-elements 0)
		 (last-e 0)
		 (max-distance 0))
	 (cond
	    ((>= i (vector-length powers))
	     (print "  };")
	     (print "static const int " max-distance-name "(" n ") = "
		 max-distance ";")
	     (print "// nb elements (" n "): " nb-elements))
	    (else
	     (let* ((power (vector-ref powers i))
		    (e (Cached-Fast-e power)))
	     (display-power power (+ i from))
	     (loop (+ i n)
		   (+ nb-elements 1)
		   e
		   (cond
		      ((=fx i 0) max-distance)
		      ((> (- e last-e) max-distance) (- e last-e))
		      (else max-distance))))))))
   (print "// Copyright 2010 the V8 project authors. All rights reserved.")
   (print "// ------------ GENERATED FILE ----------------")
   (print "// command used:")
   (print "// "
	  (apply string-append (map (lambda (str)
				       (string-append " " str))
				    *main-args*))
	  "  // NOLINT")
   (print)
   (print
    "// This file is intended to be included inside another .h or .cc files\n"
    "// with the following defines set:\n"
    "//  GRISU_CACHE_STRUCT: should expand to the name of a struct that will\n"
    "//   hold the cached powers of ten. Each entry will hold a 64-bit\n"
    "//   significand, a 16-bit signed binary exponent, and a 16-bit\n"
    "//   signed decimal exponent. Each entry will be constructed as follows:\n"
    "//      { significand, binary_exponent, decimal_exponent }.\n"
    "//  GRISU_CACHE_NAME(i): generates the name for the different caches.\n"
    "//   The parameter i will be a number in the range 1-20. A cache will\n"
    "//   hold every i'th element of a full cache. GRISU_CACHE_NAME(1) will\n"
    "//   thus hold all elements. The higher i the fewer elements it has.\n"
    "//   Ideally the user should only reference one cache and let the\n"
    "//   compiler remove the unused ones.\n"
    "//  GRISU_CACHE_MAX_DISTANCE(i): generates the name for the maximum\n"
    "//   binary exponent distance between all elements of a given cache.\n"
    "//  GRISU_CACHE_OFFSET: is used as variable name for the decimal\n"
    "//   exponent offset. It is equal to -cache[0].decimal_exponent.\n"
    "//  GRISU_UINT64_C: used to construct 64-bit values in a platform\n"
    "//   independent way. In order to encode 0x123456789ABCDEF0 the macro\n"
    "//   will be invoked as follows: GRISU_UINT64_C(0x12345678,9ABCDEF0).\n")
   (print)
   (print-powers-reduced 1)
   (print-powers-reduced 2)
   (print-powers-reduced 3)
   (print-powers-reduced 4)
   (print-powers-reduced 5)
   (print-powers-reduced 6)
   (print-powers-reduced 7)
   (print-powers-reduced 8)
   (print-powers-reduced 9)
   (print-powers-reduced 10)
   (print-powers-reduced 11)
   (print-powers-reduced 12)
   (print-powers-reduced 13)
   (print-powers-reduced 14)
   (print-powers-reduced 15)
   (print-powers-reduced 16)
   (print-powers-reduced 17)
   (print-powers-reduced 18)
   (print-powers-reduced 19)
   (print-powers-reduced 20)
   (print "static const int GRISU_CACHE_OFFSET = " (- from) ";"))

;;----------------main --------------------------------------------------------
(define *main-args* #f)
(define *mantissa-size* #f)
(define *dest* #f)
(define *round* #f)
(define *from* #f)
(define *to* #f)

(define (my-main args)
   (set! *main-args* args)
   (args-parse (cdr args)
      (section "Help")
      (("?") (args-parse-usage #f))
      ((("-h" "--help") (help "?, -h, --help" "This help message"))
       (args-parse-usage #f))
      (section "Misc")
      (("-o" ?file (help "The output file"))
       (set! *dest* file))
      (("--mantissa-size" ?size (help "Container-size in bits"))
       (set! *mantissa-size* (string->number size)))
      (("--round" ?direction (help "Round bignums (down, round or up)"))
       (set! *round* (string->symbol direction)))
      (("--from" ?from (help "start at 10^from"))
       (set! *from* (string->number from)))
      (("--to" ?to (help "go up to 10^to"))
       (set! *to* (string->number to)))
      (else
       (print "Illegal argument `" else "'. Usage:")
       (args-parse-usage #f)))
   (when (not *from*)
      (error "generate-ten-powers"
	     "Missing from"
	     #f))
   (when (not *to*)
      (error "generate-ten-powers"
	     "Missing to"
	     #f))
   (when (not *mantissa-size*)
      (error "generate-ten-powers"
	     "Missing mantissa size"
	     #f))
   (when (not (memv *round* '(up down round)))
      (error "generate-ten-powers"
	     "Missing round-method"
	     *round*))

   (let ((dividers (generate-powers *from* *to* *mantissa-size*))
	 (p (if (not *dest*)
		(current-output-port)
		(open-output-file *dest*))))
      (unwind-protect
	 (with-output-to-port p
	    (lambda ()
	       (print-c dividers *from* *to*
			"GRISU_CACHE_STRUCT" "GRISU_CACHE_NAME"
			"GRISU_CACHE_MAX_DISTANCE" "GRISU_CACHE_OFFSET"
			"GRISU_UINT64_C"
			)))
	 (if *dest*
	     (close-output-port p)))))
                                                                                                                                                    node-23.7.0/deps/v8/tools/generate_shim_headers/                                                    0000775 0000000 0000000 00000000000 14746647661 0021512 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/generate_shim_headers/generate_shim_headers.py                            0000775 0000000 0000000 00000011122 14746647661 0026371 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3
#
# Copyright 2013 the V8 project authors. All rights reserved.
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are
# met:
#
#     * Redistributions of source code must retain the above copyright
#       notice, this list of conditions and the following disclaimer.
#     * Redistributions in binary form must reproduce the above
#       copyright notice, this list of conditions and the following
#       disclaimer in the documentation and/or other materials provided
#       with the distribution.
#     * Neither the name of Google Inc. nor the names of its
#       contributors may be used to endorse or promote products derived
#       from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

"""
Generates shim headers that mirror the directory structure of bundled headers,
but just forward to the system ones.

This allows seamless compilation against system headers with no changes
to our source code.
"""


import optparse
import os.path
import sys


def GeneratorMain(argv):
  parser = optparse.OptionParser()
  parser.add_option('--headers-root', action='append')
  parser.add_option('--define', action='append')
  parser.add_option('--output-directory')
  parser.add_option('--prefix', default='')
  parser.add_option('--use-include-next', action='store_true')
  parser.add_option('--outputs', action='store_true')
  parser.add_option('--generate', action='store_true')

  options, args = parser.parse_args(argv)

  if not options.headers_root:
    parser.error('Missing --headers-root parameter.')
  if not options.output_directory:
    parser.error('Missing --output-directory parameter.')
  if not args:
    parser.error('Missing arguments - header file names.')

  source_tree_root = os.path.abspath(
    os.path.join(os.path.dirname(__file__), '..', '..'))

  for root in options.headers_root:
    target_directory = os.path.join(
      options.output_directory,
      os.path.relpath(root, source_tree_root))
    if options.generate and not os.path.exists(target_directory):
      os.makedirs(target_directory)

    for header_spec in args:
      if ';' in header_spec:
        (header_filename,
         include_before,
         include_after) = header_spec.split(';', 2)
      else:
        header_filename = header_spec
        include_before = ''
        include_after = ''
      if options.outputs:
        yield os.path.join(target_directory, header_filename)
      if options.generate:
        with open(os.path.join(target_directory, header_filename), 'w') as f:
          if options.define:
            for define in options.define:
              key, value = define.split('=', 1)
              # This non-standard push_macro extension is supported
              # by compilers we support (GCC, clang).
              f.write('#pragma push_macro("%s")\n' % key)
              f.write('#undef %s\n' % key)
              f.write('#define %s %s\n' % (key, value))

          if include_before:
            for header in include_before.split(':'):
              f.write('#include %s\n' % header)

          include_target = options.prefix + header_filename
          if options.use_include_next:
            f.write('#include_next <%s>\n' % include_target)
          else:
            f.write('#include <%s>\n' % include_target)

          if include_after:
            for header in include_after.split(':'):
              f.write('#include %s\n' % header)

          if options.define:
            for define in options.define:
              key, value = define.split('=', 1)
              # This non-standard pop_macro extension is supported
              # by compilers we support (GCC, clang).
              f.write('#pragma pop_macro("%s")\n' % key)


def DoMain(argv):
  return '\n'.join(GeneratorMain(argv))


if __name__ == '__main__':
  DoMain(sys.argv[1:])
                                                                                                                                                                                                                                                                                                                                                                                                                                              node-23.7.0/deps/v8/tools/get_landmines.py                                                          0000775 0000000 0000000 00000003627 14746647661 0020403 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3
# Copyright 2014 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

"""
This file emits the list of reasons why a particular build needs to be clobbered
(or a list of 'landmines').
"""

import os
import sys

sys.path.insert(0, os.path.abspath(
  os.path.join(os.path.dirname(__file__), '..', 'build')))

import get_landmines as build_get_landmines


def print_landmines():  # pylint: disable=invalid-name
  """
  ALL LANDMINES ARE EMITTED FROM HERE.
  """
  # DO NOT add landmines as part of a regular CL. Landmines are a last-effort
  # bandaid fix if a CL that got landed has a build dependency bug and all bots
  # need to be cleaned up. If you're writing a new CL that causes build
  # dependency problems, fix the dependency problems instead of adding a
  # landmine.
  # See the Chromium version in src/build/get_landmines.py for usage examples.
  print('Need to clobber after ICU52 roll.')
  print('Landmines test.')
  print('Activating MSVS 2013.')
  print('Revert activation of MSVS 2013.')
  print('Activating MSVS 2013 again.')
  print('Clobber after ICU roll.')
  print('Moar clobbering...')
  print('Remove build/android.gypi')
  print('Cleanup after windows ninja switch attempt.')
  print('Switching to pinned msvs toolchain.')
  print('Clobbering to hopefully resolve problem with mksnapshot')
  print('Clobber after ICU roll.')
  print('Clobber after Android NDK update.')
  print('Clober to fix windows build problems.')
  print('Clober again to fix windows build problems.')
  print('Clobber to possibly resolve failure on win-32 bot.')
  print('Clobber for http://crbug.com/668958.')
  print('Clobber to possibly resolve build failure on Misc V8 Linux gcc.')
  build_get_landmines.print_landmines()
  return 0


def main():
  print_landmines()
  return 0


if __name__ == '__main__':
  sys.exit(main())
                                                                                                         node-23.7.0/deps/v8/tools/grokdump.py                                                               0000775 0000000 0000000 00000434015 14746647661 0017421 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3
#
# Copyright 2012 the V8 project authors. All rights reserved.
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are
# met:
#
#     * Redistributions of source code must retain the above copyright
#       notice, this list of conditions and the following disclaimer.
#     * Redistributions in binary form must reproduce the above
#       copyright notice, this list of conditions and the following
#       disclaimer in the documentation and/or other materials provided
#       with the distribution.
#     * Neither the name of Google Inc. nor the names of its
#       contributors may be used to endorse or promote products derived
#       from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

# flake8: noqa  # https://bugs.chromium.org/p/v8/issues/detail?id=8784


import http.server as http_server
import bisect
import html
import cmd
import codecs
import ctypes
import datetime
import disasm
import inspect
import mmap
import optparse
import os
import re
import io
import sys
import types
import urllib.parse
import webbrowser

try:
  import v8heapconst
except ImportError:
  print("Importing v8heapconst.py failed. "
        "Run `tools/dev/gm.py mkgrokdump` to regenerate it.")
  sys.exit(1)

PORT_NUMBER = 8081


USAGE="""usage: %prog [OPTIONS] [DUMP-FILE]

Minidump analyzer.

Shows the processor state at the point of exception including the
stack of the active thread and the referenced objects in the V8
heap. Code objects are disassembled and the addresses linked from the
stack (e.g. pushed return addresses) are marked with "=>".

Examples:
  $ %prog 12345678-1234-1234-1234-123456789abcd-full.dmp"""


DEBUG=False


def DebugPrint(s):
  if not DEBUG: return
  print(s)


class Descriptor(object):
  """Descriptor of a structure in a memory."""

  def __init__(self, fields):
    self.fields = fields
    self.is_flexible = False
    for _, type_or_func in fields:
      if isinstance(type_or_func, types.FunctionType):
        self.is_flexible = True
        break
    if not self.is_flexible:
      self.ctype = Descriptor._GetCtype(fields)
      self.size = ctypes.sizeof(self.ctype)

  def Read(self, memory, offset):
    if self.is_flexible:
      fields_copy = self.fields[:]
      last = 0
      for name, type_or_func in fields_copy:
        if isinstance(type_or_func, types.FunctionType):
          partial_ctype = Descriptor._GetCtype(fields_copy[:last])
          partial_object = partial_ctype.from_buffer(memory, offset)
          type = type_or_func(partial_object)
          if type is not None:
            fields_copy[last] = (name, type)
            last += 1
        else:
          last += 1
      complete_ctype = Descriptor._GetCtype(fields_copy[:last])
    else:
      complete_ctype = self.ctype
    return complete_ctype.from_buffer(memory, offset)

  @staticmethod
  def _GetCtype(fields):
    class Raw(ctypes.Structure):
      _fields_ = fields
      _pack_ = 1

      def __str__(self):
        return "{" + ", ".join("%s: %s" % (field, self.__getattribute__(field))
                               for field, _ in Raw._fields_) + "}"
    return Raw


def FullDump(reader, heap):
  """Dump all available memory regions."""
  def dump_region(reader, start, size, location):
    print()
    while start & 3 != 0:
      start += 1
      size -= 1
      location += 1
    is_executable = reader.IsProbableExecutableRegion(location, size)
    is_ascii = reader.IsProbableASCIIRegion(location, size)

    if is_executable is not False:
      lines = reader.GetDisasmLines(start, size)
      for line in lines:
        print(FormatDisasmLine(start, heap, line))
      print()

    if is_ascii is not False:
      # Output in the same format as the Unix hd command
      addr = start
      for i in range(0, size, 16):
        slot = i + location
        hex_line = ""
        asc_line = ""
        for i in range(16):
          if slot + i < location + size:
            byte = ctypes.c_uint8.from_buffer(reader.minidump, slot + i).value
            if byte >= 0x20 and byte < 0x7f:
              asc_line += chr(byte)
            else:
              asc_line += "."
            hex_line += " %02x" % (byte)
          else:
            hex_line += "   "
          if i == 7:
            hex_line += " "
        print("%s  %s |%s|" % (reader.FormatIntPtr(addr),
                               hex_line,
                               asc_line))
        addr += 16

    if is_executable is not True and is_ascii is not True:
      print("%s - %s" % (reader.FormatIntPtr(start),
                         reader.FormatIntPtr(start + size)))
      print(start + size + 1);
      for i in range(0, size, reader.MachinePointerSize()):
        slot = start + i
        maybe_address = reader.ReadUIntPtr(slot)
        heap_object = heap.FindObject(maybe_address)
        print("%s: %s" % (reader.FormatIntPtr(slot),
                          reader.FormatIntPtr(maybe_address)))
        if heap_object:
          heap_object.Print(Printer())
          print()

  reader.ForEachMemoryRegion(dump_region)

# Heap constants generated by 'make grokdump' in v8heapconst module.
INSTANCE_TYPES = v8heapconst.INSTANCE_TYPES
KNOWN_MAPS = v8heapconst.KNOWN_MAPS
KNOWN_OBJECTS = v8heapconst.KNOWN_OBJECTS
FRAME_MARKERS = v8heapconst.FRAME_MARKERS

# Markers pushed on the stack by PushStackTraceAndDie
MAGIC_MARKER_PAIRS = (
    (0xbbbbbbbb, 0xbbbbbbbb),
    (0xfefefefe, 0xfefefeff),
)
# See StackTraceFailureMessage in isolate.h
STACK_TRACE_MARKER = 0xdecade30
# See FailureMessage in logging.cc
ERROR_MESSAGE_MARKER = 0xdecade10

# Set of structures and constants that describe the layout of minidump
# files. Based on MSDN and Google Breakpad.

MINIDUMP_HEADER = Descriptor([
  ("signature", ctypes.c_uint32),
  ("version", ctypes.c_uint32),
  ("stream_count", ctypes.c_uint32),
  ("stream_directories_rva", ctypes.c_uint32),
  ("checksum", ctypes.c_uint32),
  ("time_date_stampt", ctypes.c_uint32),
  ("flags", ctypes.c_uint64)
])

MINIDUMP_LOCATION_DESCRIPTOR = Descriptor([
  ("data_size", ctypes.c_uint32),
  ("rva", ctypes.c_uint32)
])

MINIDUMP_STRING = Descriptor([
  ("length", ctypes.c_uint32),
  ("buffer", lambda t: ctypes.c_uint8 * (t.length + 2))
])

MINIDUMP_DIRECTORY = Descriptor([
  ("stream_type", ctypes.c_uint32),
  ("location", MINIDUMP_LOCATION_DESCRIPTOR.ctype)
])

MD_EXCEPTION_MAXIMUM_PARAMETERS = 15

MINIDUMP_EXCEPTION = Descriptor([
  ("code", ctypes.c_uint32),
  ("flags", ctypes.c_uint32),
  ("record", ctypes.c_uint64),
  ("address", ctypes.c_uint64),
  ("parameter_count", ctypes.c_uint32),
  ("unused_alignment", ctypes.c_uint32),
  ("information", ctypes.c_uint64 * MD_EXCEPTION_MAXIMUM_PARAMETERS)
])

MINIDUMP_EXCEPTION_STREAM = Descriptor([
  ("thread_id", ctypes.c_uint32),
  ("unused_alignment", ctypes.c_uint32),
  ("exception", MINIDUMP_EXCEPTION.ctype),
  ("thread_context", MINIDUMP_LOCATION_DESCRIPTOR.ctype)
])

# Stream types.
MD_UNUSED_STREAM = 0
MD_RESERVED_STREAM_0 = 1
MD_RESERVED_STREAM_1 = 2
MD_THREAD_LIST_STREAM = 3
MD_MODULE_LIST_STREAM = 4
MD_MEMORY_LIST_STREAM = 5
MD_EXCEPTION_STREAM = 6
MD_SYSTEM_INFO_STREAM = 7
MD_THREAD_EX_LIST_STREAM = 8
MD_MEMORY_64_LIST_STREAM = 9
MD_COMMENT_STREAM_A = 10
MD_COMMENT_STREAM_W = 11
MD_HANDLE_DATA_STREAM = 12
MD_FUNCTION_TABLE_STREAM = 13
MD_UNLOADED_MODULE_LIST_STREAM = 14
MD_MISC_INFO_STREAM = 15
MD_MEMORY_INFO_LIST_STREAM = 16
MD_THREAD_INFO_LIST_STREAM = 17
MD_HANDLE_OPERATION_LIST_STREAM = 18

MD_FLOATINGSAVEAREA_X86_REGISTERAREA_SIZE = 80

MINIDUMP_FLOATING_SAVE_AREA_X86 = Descriptor([
  ("control_word", ctypes.c_uint32),
  ("status_word", ctypes.c_uint32),
  ("tag_word", ctypes.c_uint32),
  ("error_offset", ctypes.c_uint32),
  ("error_selector", ctypes.c_uint32),
  ("data_offset", ctypes.c_uint32),
  ("data_selector", ctypes.c_uint32),
  ("register_area", ctypes.c_uint8 * MD_FLOATINGSAVEAREA_X86_REGISTERAREA_SIZE),
  ("cr0_npx_state", ctypes.c_uint32)
])

MD_CONTEXT_X86_EXTENDED_REGISTERS_SIZE = 512

# Context flags.
MD_CONTEXT_X86 = 0x00010000
MD_CONTEXT_X86_CONTROL = (MD_CONTEXT_X86 | 0x00000001)
MD_CONTEXT_X86_INTEGER = (MD_CONTEXT_X86 | 0x00000002)
MD_CONTEXT_X86_SEGMENTS = (MD_CONTEXT_X86 | 0x00000004)
MD_CONTEXT_X86_FLOATING_POINT = (MD_CONTEXT_X86 | 0x00000008)
MD_CONTEXT_X86_DEBUG_REGISTERS = (MD_CONTEXT_X86 | 0x00000010)
MD_CONTEXT_X86_EXTENDED_REGISTERS = (MD_CONTEXT_X86 | 0x00000020)

def EnableOnFlag(type, flag):
  return lambda o: [None, type][int((o.context_flags & flag) != 0)]

MINIDUMP_CONTEXT_X86 = Descriptor([
  ("context_flags", ctypes.c_uint32),
  # MD_CONTEXT_X86_DEBUG_REGISTERS.
  ("dr0", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_DEBUG_REGISTERS)),
  ("dr1", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_DEBUG_REGISTERS)),
  ("dr2", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_DEBUG_REGISTERS)),
  ("dr3", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_DEBUG_REGISTERS)),
  ("dr6", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_DEBUG_REGISTERS)),
  ("dr7", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_DEBUG_REGISTERS)),
  # MD_CONTEXT_X86_FLOATING_POINT.
  ("float_save", EnableOnFlag(MINIDUMP_FLOATING_SAVE_AREA_X86.ctype,
                              MD_CONTEXT_X86_FLOATING_POINT)),
  # MD_CONTEXT_X86_SEGMENTS.
  ("gs", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_SEGMENTS)),
  ("fs", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_SEGMENTS)),
  ("es", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_SEGMENTS)),
  ("ds", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_SEGMENTS)),
  # MD_CONTEXT_X86_INTEGER.
  ("edi", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_INTEGER)),
  ("esi", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_INTEGER)),
  ("ebx", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_INTEGER)),
  ("edx", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_INTEGER)),
  ("ecx", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_INTEGER)),
  ("eax", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_INTEGER)),
  # MD_CONTEXT_X86_CONTROL.
  ("ebp", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_CONTROL)),
  ("eip", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_CONTROL)),
  ("cs", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_CONTROL)),
  ("eflags", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_CONTROL)),
  ("esp", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_CONTROL)),
  ("ss", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_X86_CONTROL)),
  # MD_CONTEXT_X86_EXTENDED_REGISTERS.
  ("extended_registers",
   EnableOnFlag(ctypes.c_uint8 * MD_CONTEXT_X86_EXTENDED_REGISTERS_SIZE,
                MD_CONTEXT_X86_EXTENDED_REGISTERS))
])

MD_CONTEXT_ARM = 0x40000000
MD_CONTEXT_ARM_INTEGER = (MD_CONTEXT_ARM | 0x00000002)
MD_CONTEXT_ARM_FLOATING_POINT = (MD_CONTEXT_ARM | 0x00000004)
MD_FLOATINGSAVEAREA_ARM_FPR_COUNT = 32
MD_FLOATINGSAVEAREA_ARM_FPEXTRA_COUNT = 8

MINIDUMP_FLOATING_SAVE_AREA_ARM = Descriptor([
  ("fpscr", ctypes.c_uint64),
  ("regs", ctypes.c_uint64 * MD_FLOATINGSAVEAREA_ARM_FPR_COUNT),
  ("extra", ctypes.c_uint64 * MD_FLOATINGSAVEAREA_ARM_FPEXTRA_COUNT)
])

MINIDUMP_CONTEXT_ARM = Descriptor([
  ("context_flags", ctypes.c_uint32),
  # MD_CONTEXT_ARM_INTEGER.
  ("r0", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_ARM_INTEGER)),
  ("r1", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_ARM_INTEGER)),
  ("r2", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_ARM_INTEGER)),
  ("r3", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_ARM_INTEGER)),
  ("r4", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_ARM_INTEGER)),
  ("r5", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_ARM_INTEGER)),
  ("r6", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_ARM_INTEGER)),
  ("r7", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_ARM_INTEGER)),
  ("r8", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_ARM_INTEGER)),
  ("r9", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_ARM_INTEGER)),
  ("r10", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_ARM_INTEGER)),
  ("r11", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_ARM_INTEGER)),
  ("r12", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_ARM_INTEGER)),
  ("sp", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_ARM_INTEGER)),
  ("lr", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_ARM_INTEGER)),
  ("pc", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_ARM_INTEGER)),
  ("cpsr", ctypes.c_uint32),
  ("float_save", EnableOnFlag(MINIDUMP_FLOATING_SAVE_AREA_ARM.ctype,
                              MD_CONTEXT_ARM_FLOATING_POINT))
])


MD_CONTEXT_ARM64 =  0x80000000
MD_CONTEXT_ARM64_INTEGER = (MD_CONTEXT_ARM64 | 0x00000002)
MD_CONTEXT_ARM64_FLOATING_POINT = (MD_CONTEXT_ARM64 | 0x00000004)
MD_FLOATINGSAVEAREA_ARM64_FPR_COUNT = 64

MINIDUMP_FLOATING_SAVE_AREA_ARM = Descriptor([
  ("fpscr", ctypes.c_uint64),
  ("regs", ctypes.c_uint64 * MD_FLOATINGSAVEAREA_ARM64_FPR_COUNT),
])

MINIDUMP_CONTEXT_ARM64 = Descriptor([
  ("context_flags", ctypes.c_uint64),
  # MD_CONTEXT_ARM64_INTEGER.
  ("r0", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r1", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r2", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r3", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r4", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r5", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r6", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r7", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r8", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r9", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r10", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r11", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r12", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r13", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r14", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r15", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r16", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r17", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r18", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r19", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r20", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r21", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r22", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r23", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r24", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r25", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r26", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r27", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("r28", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("fp", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("lr", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("sp", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("pc", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_ARM64_INTEGER)),
  ("cpsr", ctypes.c_uint32),
  ("float_save", EnableOnFlag(MINIDUMP_FLOATING_SAVE_AREA_ARM.ctype,
                              MD_CONTEXT_ARM64_FLOATING_POINT))
])


MD_CONTEXT_AMD64 = 0x00100000
MD_CONTEXT_AMD64_CONTROL = (MD_CONTEXT_AMD64 | 0x00000001)
MD_CONTEXT_AMD64_INTEGER = (MD_CONTEXT_AMD64 | 0x00000002)
MD_CONTEXT_AMD64_SEGMENTS = (MD_CONTEXT_AMD64 | 0x00000004)
MD_CONTEXT_AMD64_FLOATING_POINT = (MD_CONTEXT_AMD64 | 0x00000008)
MD_CONTEXT_AMD64_DEBUG_REGISTERS = (MD_CONTEXT_AMD64 | 0x00000010)

MINIDUMP_CONTEXT_AMD64 = Descriptor([
  ("p1_home", ctypes.c_uint64),
  ("p2_home", ctypes.c_uint64),
  ("p3_home", ctypes.c_uint64),
  ("p4_home", ctypes.c_uint64),
  ("p5_home", ctypes.c_uint64),
  ("p6_home", ctypes.c_uint64),
  ("context_flags", ctypes.c_uint32),
  ("mx_csr", ctypes.c_uint32),
  # MD_CONTEXT_AMD64_CONTROL.
  ("cs", EnableOnFlag(ctypes.c_uint16, MD_CONTEXT_AMD64_CONTROL)),
  # MD_CONTEXT_AMD64_SEGMENTS
  ("ds", EnableOnFlag(ctypes.c_uint16, MD_CONTEXT_AMD64_SEGMENTS)),
  ("es", EnableOnFlag(ctypes.c_uint16, MD_CONTEXT_AMD64_SEGMENTS)),
  ("fs", EnableOnFlag(ctypes.c_uint16, MD_CONTEXT_AMD64_SEGMENTS)),
  ("gs", EnableOnFlag(ctypes.c_uint16, MD_CONTEXT_AMD64_SEGMENTS)),
  # MD_CONTEXT_AMD64_CONTROL.
  ("ss", EnableOnFlag(ctypes.c_uint16, MD_CONTEXT_AMD64_CONTROL)),
  ("eflags", EnableOnFlag(ctypes.c_uint32, MD_CONTEXT_AMD64_CONTROL)),
  # MD_CONTEXT_AMD64_DEBUG_REGISTERS.
  ("dr0", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_DEBUG_REGISTERS)),
  ("dr1", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_DEBUG_REGISTERS)),
  ("dr2", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_DEBUG_REGISTERS)),
  ("dr3", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_DEBUG_REGISTERS)),
  ("dr6", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_DEBUG_REGISTERS)),
  ("dr7", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_DEBUG_REGISTERS)),
  # MD_CONTEXT_AMD64_INTEGER.
  ("rax", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_INTEGER)),
  ("rcx", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_INTEGER)),
  ("rdx", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_INTEGER)),
  ("rbx", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_INTEGER)),
  # MD_CONTEXT_AMD64_CONTROL.
  ("rsp", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_CONTROL)),
  # MD_CONTEXT_AMD64_INTEGER.
  ("rbp", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_INTEGER)),
  ("rsi", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_INTEGER)),
  ("rdi", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_INTEGER)),
  ("r8", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_INTEGER)),
  ("r9", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_INTEGER)),
  ("r10", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_INTEGER)),
  ("r11", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_INTEGER)),
  ("r12", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_INTEGER)),
  ("r13", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_INTEGER)),
  ("r14", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_INTEGER)),
  ("r15", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_INTEGER)),
  # MD_CONTEXT_AMD64_CONTROL.
  ("rip", EnableOnFlag(ctypes.c_uint64, MD_CONTEXT_AMD64_CONTROL)),
  # MD_CONTEXT_AMD64_FLOATING_POINT
  ("sse_registers", EnableOnFlag(ctypes.c_uint8 * (16 * 26),
                                 MD_CONTEXT_AMD64_FLOATING_POINT)),
  ("vector_registers", EnableOnFlag(ctypes.c_uint8 * (16 * 26),
                                    MD_CONTEXT_AMD64_FLOATING_POINT)),
  ("vector_control", EnableOnFlag(ctypes.c_uint64,
                                  MD_CONTEXT_AMD64_FLOATING_POINT)),
  # MD_CONTEXT_AMD64_DEBUG_REGISTERS.
  ("debug_control", EnableOnFlag(ctypes.c_uint64,
                                 MD_CONTEXT_AMD64_DEBUG_REGISTERS)),
  ("last_branch_to_rip", EnableOnFlag(ctypes.c_uint64,
                                      MD_CONTEXT_AMD64_DEBUG_REGISTERS)),
  ("last_branch_from_rip", EnableOnFlag(ctypes.c_uint64,
                                        MD_CONTEXT_AMD64_DEBUG_REGISTERS)),
  ("last_exception_to_rip", EnableOnFlag(ctypes.c_uint64,
                                         MD_CONTEXT_AMD64_DEBUG_REGISTERS)),
  ("last_exception_from_rip", EnableOnFlag(ctypes.c_uint64,
                                           MD_CONTEXT_AMD64_DEBUG_REGISTERS))
])

MINIDUMP_MEMORY_DESCRIPTOR = Descriptor([
  ("start", ctypes.c_uint64),
  ("memory", MINIDUMP_LOCATION_DESCRIPTOR.ctype)
])

MINIDUMP_MEMORY_DESCRIPTOR64 = Descriptor([
  ("start", ctypes.c_uint64),
  ("size", ctypes.c_uint64)
])

MINIDUMP_MEMORY_LIST = Descriptor([
  ("range_count", ctypes.c_uint32),
  ("ranges", lambda m: MINIDUMP_MEMORY_DESCRIPTOR.ctype * m.range_count)
])

MINIDUMP_MEMORY_LIST_Mac = Descriptor([
  ("range_count", ctypes.c_uint32),
  ("junk", ctypes.c_uint32),
  ("ranges", lambda m: MINIDUMP_MEMORY_DESCRIPTOR.ctype * m.range_count)
])

MINIDUMP_MEMORY_LIST64 = Descriptor([
  ("range_count", ctypes.c_uint64),
  ("base_rva", ctypes.c_uint64),
  ("ranges", lambda m: MINIDUMP_MEMORY_DESCRIPTOR64.ctype * m.range_count)
])

MINIDUMP_THREAD = Descriptor([
  ("id", ctypes.c_uint32),
  ("suspend_count", ctypes.c_uint32),
  ("priority_class", ctypes.c_uint32),
  ("priority", ctypes.c_uint32),
  ("ted", ctypes.c_uint64),
  ("stack", MINIDUMP_MEMORY_DESCRIPTOR.ctype),
  ("context", MINIDUMP_LOCATION_DESCRIPTOR.ctype)
])

MINIDUMP_THREAD_LIST = Descriptor([
  ("thread_count", ctypes.c_uint32),
  ("threads", lambda t: MINIDUMP_THREAD.ctype * t.thread_count)
])

MINIDUMP_THREAD_LIST_Mac = Descriptor([
  ("thread_count", ctypes.c_uint32),
  ("junk", ctypes.c_uint32),
  ("threads", lambda t: MINIDUMP_THREAD.ctype * t.thread_count)
])

MINIDUMP_VS_FIXEDFILEINFO = Descriptor([
  ("dwSignature", ctypes.c_uint32),
  ("dwStrucVersion", ctypes.c_uint32),
  ("dwFileVersionMS", ctypes.c_uint32),
  ("dwFileVersionLS", ctypes.c_uint32),
  ("dwProductVersionMS", ctypes.c_uint32),
  ("dwProductVersionLS", ctypes.c_uint32),
  ("dwFileFlagsMask", ctypes.c_uint32),
  ("dwFileFlags", ctypes.c_uint32),
  ("dwFileOS", ctypes.c_uint32),
  ("dwFileType", ctypes.c_uint32),
  ("dwFileSubtype", ctypes.c_uint32),
  ("dwFileDateMS", ctypes.c_uint32),
  ("dwFileDateLS", ctypes.c_uint32)
])

MINIDUMP_RAW_MODULE = Descriptor([
  ("base_of_image", ctypes.c_uint64),
  ("size_of_image", ctypes.c_uint32),
  ("checksum", ctypes.c_uint32),
  ("time_date_stamp", ctypes.c_uint32),
  ("module_name_rva", ctypes.c_uint32),
  ("version_info", MINIDUMP_VS_FIXEDFILEINFO.ctype),
  ("cv_record", MINIDUMP_LOCATION_DESCRIPTOR.ctype),
  ("misc_record", MINIDUMP_LOCATION_DESCRIPTOR.ctype),
  ("reserved0", ctypes.c_uint32 * 2),
  ("reserved1", ctypes.c_uint32 * 2)
])

MINIDUMP_MODULE_LIST = Descriptor([
  ("number_of_modules", ctypes.c_uint32),
  ("modules", lambda t: MINIDUMP_RAW_MODULE.ctype * t.number_of_modules)
])

MINIDUMP_MODULE_LIST_Mac = Descriptor([
  ("number_of_modules", ctypes.c_uint32),
  ("junk", ctypes.c_uint32),
  ("modules", lambda t: MINIDUMP_RAW_MODULE.ctype * t.number_of_modules)
])

MINIDUMP_RAW_SYSTEM_INFO = Descriptor([
  ("processor_architecture", ctypes.c_uint16)
])

MD_CPU_ARCHITECTURE_X86 = 0
MD_CPU_ARCHITECTURE_ARM = 5
# Breakpad used a custom value of 0x8003 here; Crashpad uses the new
# standardized value 12.
MD_CPU_ARCHITECTURE_ARM64 = 12
MD_CPU_ARCHITECTURE_ARM64_BREAKPAD_LEGACY = 0x8003
MD_CPU_ARCHITECTURE_AMD64 = 9

OBJDUMP_BIN = None
DEFAULT_OBJDUMP_BIN = '/usr/bin/objdump'

class FuncSymbol:
  def __init__(self, start, size, name):
    self.start = start
    self.end = self.start + size
    self.name = name

  def __cmp__(self, other):
    if isinstance(other, FuncSymbol):
      return self.start - other.start
    return self.start - other

  def Covers(self, addr):
    return (self.start <= addr) and (addr < self.end)


class MinidumpReader(object):
  """Minidump (.dmp) reader."""

  _HEADER_MAGIC = 0x504d444d

  def __init__(self, options, minidump_name):
    self._reset()
    self.minidump_name = minidump_name
    if sys.platform == 'win32':
      self.minidump_file = open(minidump_name, "a+")
      self.minidump = mmap.mmap(self.minidump_file.fileno(), 0)
    else:
      self.minidump_file = open(minidump_name, "r")
      self.minidump = mmap.mmap(self.minidump_file.fileno(), 0, mmap.MAP_PRIVATE)
    self.header = MINIDUMP_HEADER.Read(self.minidump, 0)
    if self.header.signature != MinidumpReader._HEADER_MAGIC:
      print("Warning: Unsupported minidump header magic!", file=sys.stderr)
    DebugPrint(self.header)
    offset = self.header.stream_directories_rva
    directories = []
    for _ in range(self.header.stream_count):
      directories.append(MINIDUMP_DIRECTORY.Read(self.minidump, offset))
      offset += MINIDUMP_DIRECTORY.size

    self.symdir = options.symdir
    self._ReadArchitecture(directories)
    self._ReadDirectories(directories)
    self._FindObjdump(options)

  def _reset(self):
    self.header = None
    self.arch = None
    self.exception = None
    self.exception_context = None
    self.memory_list = None
    self.memory_list64 = None
    self.module_list = None
    self.thread_map = {}

    self.modules_with_symbols = []
    self.symbols = []


  def _ReadArchitecture(self, directories):
    # Find MDRawSystemInfo stream and determine arch.
    for d in directories:
      if d.stream_type == MD_SYSTEM_INFO_STREAM:
        system_info = MINIDUMP_RAW_SYSTEM_INFO.Read(
            self.minidump, d.location.rva)
        self.arch = system_info.processor_architecture
        if self.arch == MD_CPU_ARCHITECTURE_ARM64_BREAKPAD_LEGACY:
          self.arch = MD_CPU_ARCHITECTURE_ARM64
        assert self.arch in [MD_CPU_ARCHITECTURE_AMD64,
                             MD_CPU_ARCHITECTURE_ARM,
                             MD_CPU_ARCHITECTURE_ARM64,
                             MD_CPU_ARCHITECTURE_X86]
    assert not self.arch is None

  def _ReadDirectories(self, directories):
    for d in directories:
      DebugPrint(d)
      if d.stream_type == MD_EXCEPTION_STREAM:
        self.exception = MINIDUMP_EXCEPTION_STREAM.Read(
          self.minidump, d.location.rva)
        DebugPrint(self.exception)
        self.exception_context = self.ContextDescriptor().Read(
            self.minidump, self.exception.thread_context.rva)
        DebugPrint(self.exception_context)
      elif d.stream_type == MD_THREAD_LIST_STREAM:
        thread_list = MINIDUMP_THREAD_LIST.Read(self.minidump, d.location.rva)
        if ctypes.sizeof(thread_list) + 4 == d.location.data_size:
          thread_list = MINIDUMP_THREAD_LIST_Mac.Read(
              self.minidump, d.location.rva)
        assert ctypes.sizeof(thread_list) == d.location.data_size
        DebugPrint(thread_list)
        for thread in thread_list.threads:
          DebugPrint(thread)
          self.thread_map[thread.id] = thread
      elif d.stream_type == MD_MODULE_LIST_STREAM:
        assert self.module_list is None
        self.module_list = MINIDUMP_MODULE_LIST.Read(
          self.minidump, d.location.rva)
        if ctypes.sizeof(self.module_list) + 4 == d.location.data_size:
          self.module_list = MINIDUMP_MODULE_LIST_Mac.Read(
              self.minidump, d.location.rva)
        assert ctypes.sizeof(self.module_list) == d.location.data_size
        DebugPrint(self.module_list)
      elif d.stream_type == MD_MEMORY_LIST_STREAM:
        print("Warning: This is not a full minidump!", file=sys.stderr)
        assert self.memory_list is None
        self.memory_list = MINIDUMP_MEMORY_LIST.Read(
          self.minidump, d.location.rva)
        if ctypes.sizeof(self.memory_list) + 4 == d.location.data_size:
          self.memory_list = MINIDUMP_MEMORY_LIST_Mac.Read(
              self.minidump, d.location.rva)
        assert ctypes.sizeof(self.memory_list) == d.location.data_size
        DebugPrint(self.memory_list)
      elif d.stream_type == MD_MEMORY_64_LIST_STREAM:
        assert self.memory_list64 is None
        self.memory_list64 = MINIDUMP_MEMORY_LIST64.Read(
          self.minidump, d.location.rva)
        assert ctypes.sizeof(self.memory_list64) == d.location.data_size
        DebugPrint(self.memory_list64)

  def _FindObjdump(self, options):
    if options.objdump:
      objdump_bin = options.objdump
    else:
      objdump_bin = self._FindThirdPartyObjdump()
    if not objdump_bin or not os.path.exists(objdump_bin):
      print("# Cannot find '%s', falling back to default objdump '%s'" % (
          objdump_bin, DEFAULT_OBJDUMP_BIN))
      objdump_bin  = DEFAULT_OBJDUMP_BIN
    global OBJDUMP_BIN
    OBJDUMP_BIN = objdump_bin
    disasm.OBJDUMP_BIN = objdump_bin

  def _FindThirdPartyObjdump(self):
    # Try to find the platform specific objdump.
    if self.arch == MD_CPU_ARCHITECTURE_ARM:
      platform_filter = 'arm-linux'
    elif self.arch == MD_CPU_ARCHITECTURE_ARM64:
      platform_filter = 'aarch64'
    else:
      # Use default otherwise.
      return None
    print(("# Looking for platform specific (%s) objdump in "
           "third_party directory.") % platform_filter)
    third_party_dir = os.path.join(
        os.path.dirname(os.path.dirname(__file__)), 'third_party')
    for root, dirs, files in os.walk(third_party_dir):
      for file in files:
        if file.endswith("objdump") and platform_filter in file:
          return os.path.join(root, file)
    print("# Could not find platform specific objdump in third_party.")
    print("# Make sure you installed the correct SDK.")
    return None

  def ContextDescriptor(self):
    if self.arch == MD_CPU_ARCHITECTURE_X86:
      return MINIDUMP_CONTEXT_X86
    elif self.arch == MD_CPU_ARCHITECTURE_AMD64:
      return MINIDUMP_CONTEXT_AMD64
    elif self.arch == MD_CPU_ARCHITECTURE_ARM:
      return MINIDUMP_CONTEXT_ARM
    elif self.arch == MD_CPU_ARCHITECTURE_ARM64:
      return MINIDUMP_CONTEXT_ARM64
    else:
      return None

  def IsValidAlignedAddress(self, address):
    return self.IsAlignedAddress(address) and self.IsValidAddress(address)

  def IsValidAddress(self, address):
    return self.FindLocation(address) is not None

  def IsAlignedAddress(self, address):
    return (address % self.MachinePointerSize()) == 0

  def IsExceptionStackAddress(self, address):
    if not self.IsAlignedAddress(address): return False
    return self.IsAnyExceptionStackAddress(address)

  def IsAnyExceptionStackAddress(self, address):
    return self.StackTop() <= address <= self.StackBottom()

  def IsValidExceptionStackAddress(self, address):
    if not self.IsValidAddress(address): return False
    return self.IsExceptionStackAddress(address)

  def IsModuleAddress(self, address):
    return self.GetModuleForAddress(address) is not None

  def GetModuleForAddress(self, address):
    for module in self.module_list.modules:
      start = module.base_of_image
      end = start + module.size_of_image
      if start <= address < end: return module
    return None

  def ReadU8(self, address):
    location = self.FindLocation(address)
    return ctypes.c_uint8.from_buffer(self.minidump, location).value

  def ReadU32(self, address):
    location = self.FindLocation(address)
    return ctypes.c_uint32.from_buffer(self.minidump, location).value

  def ReadU64(self, address):
    location = self.FindLocation(address)
    return ctypes.c_uint64.from_buffer(self.minidump, location).value

  def Is64(self):
    return (self.arch == MD_CPU_ARCHITECTURE_ARM64 or
            self.arch == MD_CPU_ARCHITECTURE_AMD64)

  def IsPointerCompressed(self):
    # Assume all 64-bit builds are pointer compressed.
    return self.Is64()

  def Is32BitTagged(self):
    return not self.Is64() or self.IsPointerCompressed()

  def ReadTagged(self, address):
    if self.Is32BitTagged():
      tagged = self.ReadU32(address)
      if self.IsPointerCompressed():
        # Uncompress using the slot address.
        return (address & (0xFFFFFFFF << 32)) | (tagged & 0xFFFFFFFF)
      else:
        return tagged
    return self.ReadU64(address)

  def ReadUIntPtr(self, address):
    if self.Is64():
      return self.ReadU64(address)
    return self.ReadU32(address)

  def ReadSized(self, address, size):
    if size == 8:
      return self.ReadU64(address)
    assert (size == 4)
    return self.ReadU32(address)

  def ReadBytes(self, address, size):
    location = self.FindLocation(address)
    return self.minidump[location:location + size]

  def _ReadWord(self, location):
    if self.Is64():
      return ctypes.c_uint64.from_buffer(self.minidump, location).value
    return ctypes.c_uint32.from_buffer(self.minidump, location).value

  def ReadAsciiPtr(self, address):
    ascii_content = [
        chr(c) if c >= 0x20 and c < 0x7f else '.'
        for c in self.ReadBytes(address, self.MachinePointerSize())
    ]
    return ''.join(ascii_content)

  def ReadAsciiString(self, address):
    string = ""
    while self.IsValidAddress(address):
      code = self.ReadU8(address)
      if 0 < code < 128:
        string += chr(code)
      else:
        break
      address += 1
    return string

  def IsProbableASCIIRegion(self, location, length):
    ascii_bytes = 0
    non_ascii_bytes = 0
    for i in range(length):
      loc = location + i
      byte = ctypes.c_uint8.from_buffer(self.minidump, loc).value
      if byte >= 0x7f:
        non_ascii_bytes += 1
      if byte < 0x20 and byte != 0:
        non_ascii_bytes += 1
      if byte < 0x7f and byte >= 0x20:
        ascii_bytes += 1
      if byte == 0xa:  # newline
        ascii_bytes += 1
    if ascii_bytes * 10 <= length:
      return False
    if length > 0 and ascii_bytes > non_ascii_bytes * 7:
      return True
    if ascii_bytes > non_ascii_bytes * 3:
      return None  # Maybe
    return False

  def IsProbableExecutableRegion(self, location, length):
    opcode_bytes = 0
    sixty_four = self.Is64()
    for i in range(length):
      loc = location + i
      byte = ctypes.c_uint8.from_buffer(self.minidump, loc).value
      if (byte == 0x8b or           # mov
          byte == 0x89 or           # mov reg-reg
          (byte & 0xf0) == 0x50 or  # push/pop
          (sixty_four and (byte & 0xf0) == 0x40) or  # rex prefix
          byte == 0xc3 or           # return
          byte == 0x74 or           # jeq
          byte == 0x84 or           # jeq far
          byte == 0x75 or           # jne
          byte == 0x85 or           # jne far
          byte == 0xe8 or           # call
          byte == 0xe9 or           # jmp far
          byte == 0xeb):            # jmp near
        opcode_bytes += 1
    opcode_percent = (opcode_bytes * 100) / length
    threshold = 20
    if opcode_percent > threshold + 2:
      return True
    if opcode_percent > threshold - 2:
      return None  # Maybe
    return False

  def FindRegion(self, addr):
    answer = [-1, -1]
    def is_in(reader, start, size, location):
      if addr >= start and addr < start + size:
        answer[0] = start
        answer[1] = size
    self.ForEachMemoryRegion(is_in)
    if answer[0] == -1:
      return None
    return answer

  def ForEachMemoryRegion(self, cb):
    if self.memory_list64 is not None:
      for r in self.memory_list64.ranges:
        location = self.memory_list64.base_rva + offset
        cb(self, r.start, r.size, location)
        offset += r.size

    if self.memory_list is not None:
      for r in self.memory_list.ranges:
        cb(self, r.start, r.memory.data_size, r.memory.rva)

  def FindWord(self, word, alignment=0):
    def search_inside_region(reader, start, size, location):
      location = (location + alignment) & ~alignment
      for i in range(size - self.MachinePointerSize()):
        loc = location + i
        if reader._ReadWord(loc) == word:
          slot = start + (loc - location)
          print("%s: %s" % (reader.FormatIntPtr(slot),
                            reader.FormatIntPtr(word)))
    self.ForEachMemoryRegion(search_inside_region)

  def FindPtr(self, expected_value, start, end):
    ptr_size = self.MachinePointerSize()
    for slot in range(start, end, ptr_size):
      if not self.IsValidAddress(slot):
        return None
      value = self.ReadUIntPtr(slot)
      if value == expected_value:
        return slot
    return None

  def FindWordList(self, word):
    aligned_res = []
    unaligned_res = []
    def search_inside_region(reader, start, size, location):
      for i in range(size - self.MachinePointerSize()):
        loc = location + i
        if reader._ReadWord(loc) == word:
          slot = start + (loc - location)
          if self.IsAlignedAddress(slot):
            aligned_res.append(slot)
          else:
            unaligned_res.append(slot)
    self.ForEachMemoryRegion(search_inside_region)
    return (aligned_res, unaligned_res)

  def FindLocation(self, address):
    offset = 0
    if self.memory_list64 is not None:
      for r in self.memory_list64.ranges:
        if r.start <= address < r.start + r.size:
          return self.memory_list64.base_rva + offset + address - r.start
        offset += r.size
    if self.memory_list is not None:
      for r in self.memory_list.ranges:
        if r.start <= address < r.start + r.memory.data_size:
          return r.memory.rva + address - r.start
    return None

  def GetDisasmLines(self, address, size):
    def CountUndefinedInstructions(lines):
      pattern = "<UNDEFINED>"
      return sum([line.count(pattern) for (ignore, line) in lines])

    location = self.FindLocation(address)
    if location is None: return []
    arch = None
    possible_objdump_flags = [""]
    if self.arch == MD_CPU_ARCHITECTURE_X86:
      arch = "ia32"
    elif self.arch == MD_CPU_ARCHITECTURE_ARM:
      arch = "arm"
      possible_objdump_flags = ["", "--disassembler-options=force-thumb"]
    elif self.arch == MD_CPU_ARCHITECTURE_ARM64:
      arch = "arm64"
      possible_objdump_flags = ["", "--disassembler-options=force-thumb"]
    elif self.arch == MD_CPU_ARCHITECTURE_AMD64:
      arch = "x64"
    results = [ disasm.GetDisasmLines(self.minidump_name,
                                     location,
                                     size,
                                     arch,
                                     False,
                                     objdump_flags)
                for objdump_flags in possible_objdump_flags ]
    return min(results, key=CountUndefinedInstructions)


  def Dispose(self):
    self._reset()
    self.minidump.close()
    self.minidump_file.close()

  def ExceptionIP(self):
    if self.arch == MD_CPU_ARCHITECTURE_AMD64:
      return self.exception_context.rip
    elif self.arch == MD_CPU_ARCHITECTURE_ARM:
      return self.exception_context.pc
    elif self.arch == MD_CPU_ARCHITECTURE_ARM64:
      return self.exception_context.pc
    elif self.arch == MD_CPU_ARCHITECTURE_X86:
      return self.exception_context.eip

  def ExceptionSP(self):
    if self.arch == MD_CPU_ARCHITECTURE_AMD64:
      return self.exception_context.rsp
    elif self.arch == MD_CPU_ARCHITECTURE_ARM:
      return self.exception_context.sp
    elif self.arch == MD_CPU_ARCHITECTURE_ARM64:
      return self.exception_context.sp
    elif self.arch == MD_CPU_ARCHITECTURE_X86:
      return self.exception_context.esp

  def ExceptionFP(self):
    if self.arch == MD_CPU_ARCHITECTURE_AMD64:
      return self.exception_context.rbp
    elif self.arch == MD_CPU_ARCHITECTURE_ARM:
      return None
    elif self.arch == MD_CPU_ARCHITECTURE_ARM64:
      return self.exception_context.fp
    elif self.arch == MD_CPU_ARCHITECTURE_X86:
      return self.exception_context.ebp

  def ExceptionThread(self):
    return self.thread_map[self.exception.thread_id]

  def StackTop(self):
    return self.ExceptionSP()

  def StackBottom(self):
    exception_thread = self.ExceptionThread()
    return exception_thread.stack.start + \
        exception_thread.stack.memory.data_size

  def FormatIntPtr(self, value):
    if self.Is64():
      return "%016x" % value
    return "%08x" % value

  def FormatTagged(self, value):
    if self.Is64() and not self.IsPointerCompressed():
      return "%016x" % value
    return "%08x" % value

  def MachinePointerSize(self):
    if self.Is64():
      return 8
    return 4

  def TaggedPointerSize(self):
    if self.IsPointerCompressed():
      return 4
    return self.MachinePointerSize()

  def Register(self, name):
    return self.exception_context.__getattribute__(name)

  def ReadMinidumpString(self, rva):
    string = bytearray(MINIDUMP_STRING.Read(self.minidump, rva).buffer)
    string = string.decode("utf16")
    return string[0:len(string) - 1]

  # Load FUNC records from a BreakPad symbol file
  #
  #    http://code.google.com/p/google-breakpad/wiki/SymbolFiles
  #
  def _LoadSymbolsFrom(self, symfile, baseaddr):
    print("Loading symbols from %s" % (symfile))
    with open(symfile) as f:
      for line in f:
        result = re.match(
            r"^FUNC ([a-f0-9]+) ([a-f0-9]+) ([a-f0-9]+) (.*)$", line)
        if result is not None:
          start = int(result.group(1), 16)
          size = int(result.group(2), 16)
          name = result.group(4).rstrip()
          bisect.insort_left(self.symbols,
                             FuncSymbol(baseaddr + start, size, name))
    print(" ... done")

  def TryLoadSymbolsFor(self, modulename, module):
    try:
      symfile = os.path.join(self.symdir,
                             modulename.replace('.', '_') + ".pdb.sym")
      if os.path.isfile(symfile):
        self._LoadSymbolsFrom(symfile, module.base_of_image)
        self.modules_with_symbols.append(module)
    except Exception as e:
      print("  ... failure (%s)" % (e))

  # Returns true if address is covered by some module that has loaded symbols.
  def _IsInModuleWithSymbols(self, addr):
    for module in self.modules_with_symbols:
      start = module.base_of_image
      end = start + module.size_of_image
      if (start <= addr) and (addr < end):
        return True
    return False

  # Find symbol covering the given address and return its name in format
  #     <symbol name>+<offset from the start>
  def FindSymbol(self, addr):
    if not self._IsInModuleWithSymbols(addr):
      return None

    i = bisect.bisect_left(self.symbols, addr)
    symbol = None
    if (0 < i) and self.symbols[i - 1].Covers(addr):
      symbol = self.symbols[i - 1]
    elif (i < len(self.symbols)) and self.symbols[i].Covers(addr):
      symbol = self.symbols[i]
    else:
      return None
    diff = addr - symbol.start
    return "%s+0x%x" % (symbol.name, diff)


class Printer(object):
  """Printer with indentation support."""

  def __init__(self):
    self.indent = 0

  def Indent(self):
    self.indent += 2

  def Dedent(self):
    self.indent -= 2

  def Print(self, string):
    print("%s%s" % (self._IndentString(), string))

  def PrintLines(self, lines):
    indent = self._IndentString()
    print("\n".join("%s%s" % (indent, line) for line in lines))

  def _IndentString(self):
    return self.indent * " "


ADDRESS_RE = re.compile(r"0x[0-9a-fA-F]+")


def FormatDisasmLine(start, heap, line):
  line_address = start + line[0]
  stack_slot = heap.stack_map.get(line_address)
  marker = "  "
  if stack_slot:
    marker = "=>"
  code = AnnotateAddresses(heap, line[1])

  # Compute the actual call target which the disassembler is too stupid
  # to figure out (it adds the call offset to the disassembly offset rather
  # than the absolute instruction address).
  if heap.reader.arch == MD_CPU_ARCHITECTURE_X86:
    if code.startswith("e8"):
      words = code.split()
      if len(words) > 6 and words[5] == "call":
        offset = int(words[4] + words[3] + words[2] + words[1], 16)
        target = (line_address + offset + 5) & 0xFFFFFFFF
        code = code.replace(words[6], "0x%08x" % target)
  # TODO(jkummerow): port this hack to ARM and x64.

  return "%s%08x %08x: %s" % (marker, line_address, line[0], code)


def AnnotateAddresses(heap, line):
  extra = []
  for m in ADDRESS_RE.finditer(line):
    maybe_address = int(m.group(0), 16)
    object = heap.FindObject(maybe_address)
    if not object: continue
    extra.append(str(object))
  if len(extra) == 0: return line
  return "%s  ;; %s" % (line, ", ".join(extra))


class HeapObject(object):
  def __init__(self, heap, map, address):
    self.heap = heap
    self.map = map
    self.address = address

  def Is(self, cls):
    return isinstance(self, cls)

  def Print(self, p):
    p.Print(str(self))

  def __str__(self):
    instance_type = "???"
    if self.map is not None:
      instance_type = INSTANCE_TYPES[self.map.instance_type]
    return "%s(%s, %s)" % (self.__class__.__name__,
                           self.heap.reader.FormatIntPtr(self.address),
                           instance_type)

  def ObjectField(self, offset):
    field_value = self.heap.reader.ReadTagged(self.address + offset)
    return self.heap.FindObjectOrSmi(field_value)

  def SmiField(self, offset):
    field_value = self.heap.reader.ReadTagged(self.address + offset)
    if self.heap.IsSmi(field_value):
      return self.heap.SmiUntag(field_value)
    return None


class Map(HeapObject):
  def Decode(self, offset, size, value):
    return (value >> offset) & ((1 << size) - 1)

  # Instance Sizes
  def InstanceSizesOffset(self):
    return self.heap.TaggedPointerSize()

  def InstanceSizeOffset(self):
    return self.InstanceSizesOffset()

  def InObjectProperties(self):
    return self.InstanceSizeOffset() + 1

  def UnusedByte(self):
    return self.InObjectProperties() + 1

  def VisitorId(self):
    return self.UnusedByte() + 1

  # Instance Attributes
  def InstanceAttributesOffset(self):
    return self.InstanceSizesOffset() + self.heap.IntSize()

  def InstanceTypeOffset(self):
    return self.InstanceAttributesOffset()

  def BitFieldOffset(self):
    return self.InstanceTypeOffset() + 1

  def BitField2Offset(self):
    return self.BitFieldOffset() + 1

  def UnusedPropertyFieldsOffset(self):
    return self.BitField2Offset() + 1

  # Other fields
  def BitField3Offset(self):
    return self.InstanceAttributesOffset() + self.heap.IntSize()

  def PrototypeOffset(self):
    return self.BitField3Offset() + self.heap.TaggedPointerSize()

  def ConstructorOrBackPointerOffset(self):
    return self.PrototypeOffset() + self.heap.TaggedPointerSize()

  def TransitionsOrPrototypeInfoOffset(self):
    return self.ConstructorOrBackPointerOffset() + self.heap.TaggedPointerSize()

  def DescriptorsOffset(self):
    return (self.TransitionsOrPrototypeInfoOffset() +
            self.heap.TaggedPointerSize())

  def CodeCacheOffset(self):
    return self.DescriptorsOffset() + self.heap.TaggedPointerSize()

  def DependentCodeOffset(self):
    return self.CodeCacheOffset() + self.heap.TaggedPointerSize()

  def ReadByte(self, offset):
    return self.heap.reader.ReadU8(self.address + offset)

  def ReadSlot(self, offset):
    return self.heap.reader.ReadTagged(self.address + offset)

  def Print(self, p):
    p.Print("Map(%08x)" % (self.address))
    p.Print("  - size: %d, inobject: %d, (unused: %d), visitor: %d" % (
        self.ReadByte(self.InstanceSizeOffset()),
        self.ReadByte(self.InObjectProperties()),
        self.ReadByte(self.UnusedByte()),
        self.VisitorId()))

    instance_type = INSTANCE_TYPES[self.ReadByte(self.InstanceTypeOffset())]
    bitfield = self.ReadByte(self.BitFieldOffset())
    bitfield2 = self.ReadByte(self.BitField2Offset())
    unused = self.ReadByte(self.UnusedPropertyFieldsOffset())
    p.Print("  - %s, bf: %d, bf2: %d, unused: %d" % (
        instance_type, bitfield, bitfield2, unused))

    p.Print("  - kind: %s" % (self.Decode(3, 5, bitfield2)))

    bitfield3 = self.ReadSlot(self.BitField3Offset())

    p.Print(
        "  - EnumLength: %d NumberOfOwnDescriptors: %d OwnsDescriptors: %s" % (
            self.Decode(0, 10, bitfield3),
            self.Decode(10, 10, bitfield3),
            self.Decode(21, 1, bitfield3)))
    p.Print("  - DictionaryMap: %s" % (self.Decode(20, 1, bitfield3)))
    p.Print("  - Deprecated: %s" % (self.Decode(23, 1, bitfield3)))
    p.Print("  - IsUnstable: %s" % (self.Decode(24, 1, bitfield3)))
    p.Print("  - NewTargetIsBase: %s" % (self.Decode(27, 1, bitfield3)))

    descriptors = self.ObjectField(self.DescriptorsOffset())
    if descriptors.__class__ == FixedArray:
      DescriptorArray(descriptors).Print(p)
    else:
      p.Print("  - Descriptors: %s" % (descriptors))

    transitions = self.ObjectField(self.TransitionsOrPrototypeInfoOffset())
    if transitions.__class__ == FixedArray:
      TransitionArray(transitions).Print(p)
    else:
      p.Print("  - TransitionsOrPrototypeInfo: %s" % (transitions))

    p.Print("  - Prototype: %s" % self.ObjectField(self.PrototypeOffset()))

  def __init__(self, heap, map, address):
    HeapObject.__init__(self, heap, map, address)
    self.instance_type = \
        heap.reader.ReadU8(self.address + self.InstanceTypeOffset())


class String(HeapObject):
  def LengthOffset(self):
    # First word after the map is the hash, the second is the length.
    return self.heap.TaggedPointerSize() * 2

  def __init__(self, heap, map, address):
    HeapObject.__init__(self, heap, map, address)
    self.length = self.SmiField(self.LengthOffset())

  def GetChars(self):
    return "?string?"

  def Print(self, p):
    p.Print(str(self))

  def __str__(self):
    return "\"%s\"" % self.GetChars()


class SeqString(String):
  def CharsOffset(self):
    return self.heap.TaggedPointerSize() * 3

  def __init__(self, heap, map, address):
    String.__init__(self, heap, map, address)
    self.chars = heap.reader.ReadBytes(self.address + self.CharsOffset(),
                                       self.length).decode('utf8')

  def GetChars(self):
    return self.chars


class ExternalString(String):
  # TODO(vegorov) fix ExternalString for X64 architecture
  RESOURCE_OFFSET = 12

  WEBKIT_RESOUCE_STRING_IMPL_OFFSET = 4
  WEBKIT_STRING_IMPL_CHARS_OFFSET = 8

  def __init__(self, heap, map, address):
    String.__init__(self, heap, map, address)
    reader = heap.reader
    self.resource = \
        reader.ReadU32(self.address + ExternalString.RESOURCE_OFFSET)
    self.chars = "?external string?"
    if not reader.IsValidAddress(self.resource): return
    string_impl_address = self.resource + \
        ExternalString.WEBKIT_RESOUCE_STRING_IMPL_OFFSET
    if not reader.IsValidAddress(string_impl_address): return
    string_impl = reader.ReadU32(string_impl_address)
    chars_ptr_address = string_impl + \
        ExternalString.WEBKIT_STRING_IMPL_CHARS_OFFSET
    if not reader.IsValidAddress(chars_ptr_address): return
    chars_ptr = reader.ReadU32(chars_ptr_address)
    if not reader.IsValidAddress(chars_ptr): return
    raw_chars = reader.ReadBytes(chars_ptr, 2 * self.length)
    self.chars = codecs.getdecoder("utf16")(raw_chars)[0]

  def GetChars(self):
    return self.chars


class ConsString(String):
  def LeftOffset(self):
    return self.heap.TaggedPointerSize() * 3

  def RightOffset(self):
    return self.heap.TaggedPointerSize() * 4

  def __init__(self, heap, map, address):
    String.__init__(self, heap, map, address)
    self.left = self.ObjectField(self.LeftOffset())
    self.right = self.ObjectField(self.RightOffset())

  def GetChars(self):
    try:
      return self.left.GetChars() + self.right.GetChars()
    except Exception as e:
      return "***CAUGHT EXCEPTION IN GROKDUMP***: " + str(e)


class Oddball(HeapObject):
  #Should match declarations in objects.h
  KINDS = [
    "False",
    "True",
    "TheHole",
    "Null",
    "ArgumentMarker",
    "Undefined",
    "Other"
  ]

  def ToStringOffset(self):
    return self.heap.TaggedPointerSize()

  def ToNumberOffset(self):
    return self.ToStringOffset() + self.heap.TaggedPointerSize()

  def KindOffset(self):
    return self.ToNumberOffset() + self.heap.TaggedPointerSize()

  def __init__(self, heap, map, address):
    HeapObject.__init__(self, heap, map, address)
    self.to_string = self.ObjectField(self.ToStringOffset())
    self.kind = self.SmiField(self.KindOffset())

  def Print(self, p):
    p.Print(str(self))

  def __str__(self):
    if self.to_string:
      return "Oddball(%08x, <%s>)" % (self.address, str(self.to_string))
    else:
      kind = "???"
      if 0 <= self.kind < len(Oddball.KINDS):
        kind = Oddball.KINDS[self.kind]
      return "Oddball(%08x, kind=%s)" % (self.address, kind)


class FixedArray(HeapObject):
  def LengthOffset(self):
    return self.heap.TaggedPointerSize()

  def ElementsOffset(self):
    return self.heap.TaggedPointerSize() * 2

  def MemberOffset(self, i):
    return self.ElementsOffset() + self.heap.TaggedPointerSize() * i

  def Get(self, i):
    return self.ObjectField(self.MemberOffset(i))

  def __init__(self, heap, map, address):
    HeapObject.__init__(self, heap, map, address)
    self.length = self.SmiField(self.LengthOffset())

  def Print(self, p):
    p.Print("FixedArray(%s) {" % self.heap.reader.FormatIntPtr(self.address))
    p.Indent()
    p.Print("length: %d" % self.length)
    base_offset = self.ElementsOffset()
    for i in range(self.length):
      offset = base_offset + 4 * i
      try:
        p.Print("[%08d] = %s" % (i, self.ObjectField(offset)))
      except TypeError:
        p.Dedent()
        p.Print("...")
        p.Print("}")
        return
    p.Dedent()
    p.Print("}")

  def __str__(self):
    return "FixedArray(%08x, length=%d)" % (self.address, self.length)


class DescriptorArray(object):
  def __init__(self, array):
    self.array = array

  def Length(self):
    return self.array.Get(0)

  def Decode(self, offset, size, value):
    return (value >> offset) & ((1 << size) - 1)

  TYPES = [
      "normal",
      "field",
      "function",
      "callbacks"
  ]

  def Type(self, value):
    return DescriptorArray.TYPES[self.Decode(0, 3, value)]

  def Attributes(self, value):
    attributes = self.Decode(3, 3, value)
    result = []
    if (attributes & 0): result += ["ReadOnly"]
    if (attributes & 1): result += ["DontEnum"]
    if (attributes & 2): result += ["DontDelete"]
    return "[" + (",".join(result)) + "]"

  def Deleted(self, value):
    return self.Decode(6, 1, value) == 1

  def FieldIndex(self, value):
    return self.Decode(20, 11, value)

  def Pointer(self, value):
    return self.Decode(6, 11, value)

  def Details(self, di, value):
    return (
        di,
        self.Type(value),
        self.Attributes(value),
        self.FieldIndex(value),
        self.Pointer(value)
    )


  def Print(self, p):
    length = self.Length()
    array = self.array

    p.Print("Descriptors(%08x, length=%d)" % (array.address, length))
    p.Print("[et] %s" % (array.Get(1)))

    for di in range(length):
      i = 2 + di * 3
      p.Print("0x%x" % (array.address + array.MemberOffset(i)))
      p.Print("[%i] name:    %s" % (di, array.Get(i + 0)))
      p.Print("[%i] details: %s %s field-index %i pointer %i" % \
              self.Details(di, array.Get(i + 1)))
      p.Print("[%i] value:   %s" % (di, array.Get(i + 2)))

    end = self.array.length // 3
    if length != end:
      p.Print("[%i-%i] slack descriptors" % (length, end))


class TransitionArray(object):
  def __init__(self, array):
    self.array = array

  def IsSimpleTransition(self):
    return self.array.length <= 2

  def Length(self):
    # SimpleTransition cases
    if self.IsSimpleTransition():
      return self.array.length - 1
    return (self.array.length - 3) // 2

  def Print(self, p):
    length = self.Length()
    array = self.array

    p.Print("Transitions(%08x, length=%d)" % (array.address, length))
    p.Print("[backpointer] %s" % (array.Get(0)))
    if self.IsSimpleTransition():
      if length == 1:
        p.Print("[simple target] %s" % (array.Get(1)))
      return

    elements = array.Get(1)
    if elements is not None:
      p.Print("[elements   ] %s" % (elements))

    prototype = array.Get(2)
    if prototype is not None:
      p.Print("[prototype  ] %s" % (prototype))

    for di in range(length):
      i = 3 + di * 2
      p.Print("[%i] symbol: %s" % (di, array.Get(i + 0)))
      p.Print("[%i] target: %s" % (di, array.Get(i + 1)))


class JSFunction(HeapObject):
  def CodeEntryOffset(self):
    return 3 * self.heap.TaggedPointerSize()

  def SharedOffset(self):
    return 5 * self.heap.TaggedPointerSize()

  def __init__(self, heap, map, address):
    HeapObject.__init__(self, heap, map, address)
    code_entry = \
        heap.reader.ReadU32(self.address + self.CodeEntryOffset())
    self.code = heap.FindObject(code_entry - Code.HeaderSize(heap) + 1)
    self.shared = self.ObjectField(self.SharedOffset())

  def Print(self, p):
    source = "\n".join("  %s" % line for line in self._GetSource().split("\n"))
    p.Print("JSFunction(%s) {" % self.heap.reader.FormatIntPtr(self.address))
    p.Indent()
    p.Print("inferred name: %s" % self.shared.inferred_name)
    if self.shared.script.Is(Script) and self.shared.script.name.Is(String):
      p.Print("script name: %s" % self.shared.script.name)
    p.Print("source:")
    p.Print(source)
    p.Print("code:")
    self.code.Print(p)
    if self.code != self.shared.code:
      p.Print("unoptimized code:")
      self.shared.code.Print(p)
    p.Dedent()
    p.Print("}")

  def __str__(self):
    inferred_name = ""
    if self.shared is not None and self.shared.Is(SharedFunctionInfo):
      inferred_name = self.shared.inferred_name
    return "JSFunction(%s, %s) " % \
          (self.heap.reader.FormatIntPtr(self.address), inferred_name)

  def _GetSource(self):
    source = "?source?"
    start = self.shared.start_position
    end = self.shared.end_position
    if not self.shared.script.Is(Script): return source
    script_source = self.shared.script.source
    if not script_source.Is(String): return source
    if start and end:
      source = script_source.GetChars()[start:end]
    return source


class SharedFunctionInfo(HeapObject):
  def CodeOffset(self):
    return 2 * self.heap.TaggedPointerSize()

  def ScriptOffset(self):
    return 7 * self.heap.TaggedPointerSize()

  def InferredNameOffset(self):
    return 9 * self.heap.TaggedPointerSize()

  def EndPositionOffset(self):
    return 12 * self.heap.TaggedPointerSize() + 4 * self.heap.IntSize()

  def StartPositionAndTypeOffset(self):
    return 12 * self.heap.TaggedPointerSize() + 5 * self.heap.IntSize()

  def __init__(self, heap, map, address):
    HeapObject.__init__(self, heap, map, address)
    try:
      self.code = self.ObjectField(self.CodeOffset())
      self.script = self.ObjectField(self.ScriptOffset())
      self.inferred_name = self.ObjectField(self.InferredNameOffset())
      if heap.TaggedPointerSize() == 8:
        start_position_and_type = \
            heap.reader.ReadU32(self.StartPositionAndTypeOffset())
        self.start_position = start_position_and_type >> 2
        pseudo_smi_end_position = \
            heap.reader.ReadU32(self.EndPositionOffset())
        self.end_position = pseudo_smi_end_position >> 2
      else:
        start_position_and_type = \
            self.SmiField(self.StartPositionAndTypeOffset())
        if start_position_and_type:
          self.start_position = start_position_and_type >> 2
        else:
          self.start_position = None
        self.end_position = \
            self.SmiField(self.EndPositionOffset())
    except:
      print("*** Error while reading SharedFunctionInfo")


class Script(HeapObject):
  def SourceOffset(self):
    return self.heap.TaggedPointerSize()

  def NameOffset(self):
    return self.SourceOffset() + self.heap.TaggedPointerSize()

  def __init__(self, heap, map, address):
    HeapObject.__init__(self, heap, map, address)
    self.source = self.ObjectField(self.SourceOffset())
    self.name = self.ObjectField(self.NameOffset())


class CodeCache(HeapObject):
  def DefaultCacheOffset(self):
    return self.heap.TaggedPointerSize()

  def NormalTypeCacheOffset(self):
    return self.DefaultCacheOffset() + self.heap.TaggedPointerSize()

  def __init__(self, heap, map, address):
    HeapObject.__init__(self, heap, map, address)
    self.default_cache = self.ObjectField(self.DefaultCacheOffset())
    self.normal_type_cache = self.ObjectField(self.NormalTypeCacheOffset())

  def Print(self, p):
    p.Print("CodeCache(%s) {" % self.heap.reader.FormatIntPtr(self.address))
    p.Indent()
    p.Print("default cache: %s" % self.default_cache)
    p.Print("normal type cache: %s" % self.normal_type_cache)
    p.Dedent()
    p.Print("}")


class Code(HeapObject):
  CODE_ALIGNMENT_MASK = (1 << 5) - 1

  def InstructionSizeOffset(self):
    return self.heap.TaggedPointerSize()

  @staticmethod
  def HeaderSize(heap):
    return (heap.TaggedPointerSize() + heap.IntSize() + \
        4 * heap.TaggedPointerSize() + 3 * heap.IntSize() + \
        Code.CODE_ALIGNMENT_MASK) & ~Code.CODE_ALIGNMENT_MASK

  def __init__(self, heap, map, address):
    HeapObject.__init__(self, heap, map, address)
    self.entry = self.address + Code.HeaderSize(heap)
    self.instruction_size = \
        heap.reader.ReadU32(self.address + self.InstructionSizeOffset())

  def Print(self, p):
    lines = self.heap.reader.GetDisasmLines(self.entry, self.instruction_size)
    p.Print("Code(%s) {" % self.heap.reader.FormatIntPtr(self.address))
    p.Indent()
    p.Print("instruction_size: %d" % self.instruction_size)
    p.PrintLines(self._FormatLine(line) for line in lines)
    p.Dedent()
    p.Print("}")

  def _FormatLine(self, line):
    return FormatDisasmLine(self.entry, self.heap, line)


class V8Heap(object):
  CLASS_MAP = {
      "SYMBOL_TYPE": SeqString,
      "SEQ_TWO_BYTE_STRING_TYPE": SeqString,
      "SEQ_ONE_BYTE_STRING_TYPE": SeqString,
      "INTERNALIZED_TWO_BYTE_STRING_TYPE": SeqString,
      "INTERNALIZED_ONE_BYTE_STRING_TYPE": SeqString,
      "CONS_TWO_BYTE_STRING_TYPE": ConsString,
      "CONS_ONE_BYTE_STRING_TYPE": ConsString,
      "EXTERNAL_TWO_BYTE_STRING_TYPE": ExternalString,
      "EXTERNAL_ONE_BYTE_STRING_TYPE": ExternalString,
      "EXTERNAL_INTERNALIZED_TWO_BYTE_STRING_TYPE": ExternalString,
      "EXTERNAL_INTERNALIZED_ONE_BYTE_STRING_TYPE": ExternalString,
      "MAP_TYPE": Map,
      "ODDBALL_TYPE": Oddball,
      "FIXED_ARRAY_TYPE": FixedArray,
      "HASH_TABLE_TYPE": FixedArray,
      "OBJECT_BOILERPLATE_DESCRIPTION_TYPE": FixedArray,
      "SCOPE_INFO_TYPE": FixedArray,
      "JS_FUNCTION_TYPE": JSFunction,
      "SHARED_FUNCTION_INFO_TYPE": SharedFunctionInfo,
      "SCRIPT_TYPE": Script,
      "CODE_CACHE_TYPE": CodeCache,
      "CODE_TYPE": Code,
  }

  def __init__(self, reader, stack_map):
    self.reader = reader
    self.stack_map = stack_map
    self.objects = {}

  def FindObjectOrSmi(self, tagged_address):
    if self.IsSmi(tagged_address): return self.SmiUntag(tagged_address)
    return self.FindObject(tagged_address)

  def FindObject(self, tagged_address):
    if tagged_address in self.objects:
      return self.objects[tagged_address]
    if not self.IsTaggedObjectAddress(tagged_address): return None
    address = tagged_address - 1
    if not self.reader.IsValidAddress(address): return None
    map_tagged_address = self.reader.ReadTagged(address)
    if tagged_address == map_tagged_address:
      # Meta map?
      meta_map = Map(self, None, address)
      instance_type_name = INSTANCE_TYPES.get(meta_map.instance_type)
      if instance_type_name != "MAP_TYPE": return None
      meta_map.map = meta_map
      object = meta_map
    else:
      map = self.FindMap(map_tagged_address)
      if map is None: return None
      instance_type_name = INSTANCE_TYPES.get(map.instance_type)
      if instance_type_name is None: return None
      cls = V8Heap.CLASS_MAP.get(instance_type_name, HeapObject)
      object = cls(self, map, address)
    self.objects[tagged_address] = object
    return object

  def FindMap(self, tagged_address):
    address = self.FindMapAddress(tagged_address)
    if not address: return None
    object = Map(self, None, address)
    return object

  def FindMapAddress(self, tagged_address):
    if not self.IsTaggedMapAddress(tagged_address): return None
    address = tagged_address - 1
    if not self.reader.IsValidAddress(address): return None
    return address

  def IntSize(self):
    return 4

  def MachinePointerSize(self):
    return self.reader.MachinePointerSize()

  def TaggedPointerSize(self):
    return self.reader.TaggedPointerSize()

  def IsPointerCompressed(self):
    return self.reader.IsPointerCompressed()

  def ObjectAlignmentMask(self):
    return self.TaggedPointerSize() - 1

  def IsTaggedObjectAddress(self, address):
    return (address & self.ObjectAlignmentMask()) == 1

  def IsWeakTaggedObjectAddress(self, address):
    return (address & self.ObjectAlignmentMask()) == 3

  def IsValidTaggedObjectAddress(self, address):
    if not self.IsTaggedObjectAddress(address): return False
    return self.reader.IsValidAddress(address)

  def IsTaggedMapAddress(self, address):
    return (address & self.MapAlignmentMask()) == 1

  def MapAlignmentMask(self):
    if self.reader.arch == MD_CPU_ARCHITECTURE_AMD64:
      return (1 << 4) - 1
    elif self.reader.arch == MD_CPU_ARCHITECTURE_ARM:
      return (1 << 4) - 1
    elif self.reader.arch == MD_CPU_ARCHITECTURE_ARM64:
      return (1 << 4) - 1
    elif self.reader.arch == MD_CPU_ARCHITECTURE_X86:
      return (1 << 5) - 1

  def PageAlignmentMask(self):
    return (1 << 19) - 1

  def IsTaggedAddress(self, address):
    return (address & self.ObjectAlignmentMask()) == 1

  def IsWeakTaggedAddress(self, address):
    return (address & self.ObjectAlignmentMask()) == 3

  def IsMaybeWeakTaggedAddress(self, address):
    return (address & 1) == 1

  def IsSmi(self, tagged_address):
    if self.reader.Is64() and not self.reader.IsPointerCompressed():
      return (tagged_address & 0xFFFFFFFF) == 0
    return (tagged_address & 1) == 0

  def SmiUntag(self, tagged_address):
    if self.reader.Is64() and not self.reader.IsPointerCompressed():
      return tagged_address >> 32
    return (tagged_address >> 1) & 0xFFFFFFFF

  def AddressTypeMarker(self, address):
    if not self.reader.IsValidAddress(address): return " "
    if self.reader.IsExceptionStackAddress(address): return "S"
    if self.reader.IsModuleAddress(address): return "C"
    if self.IsTaggedAddress(address):
      # Cannot have an tagged pointer into the stack
      if self.reader.IsAnyExceptionStackAddress(address): return "s"
      return "T"
    return "*"

  def FormatIntPtr(self, address):
    marker = self.AddressTypeMarker(address)
    address = self.reader.FormatIntPtr(address)
    if marker == " ": return address
    return "%s %s" % (address, marker)

  def RelativeOffset(self, slot, address):
    if not self.reader.IsValidAlignedAddress(slot): return None
    if self.IsTaggedObjectAddress(address):
      address -= 1
    if not self.reader.IsValidAlignedAddress(address): return None
    offset = (address - slot) / self.MachinePointerSize()

    lower_limit = -32
    upper_limit = 128
    if self.reader.IsExceptionStackAddress(address):
      upper_limit = 0xFFFFFF

    if offset < lower_limit or upper_limit < offset: return None
    target_address = self.reader.ReadUIntPtr(address)
    return "[%+02d]=%s %s" % (offset, self.reader.FormatIntPtr(target_address),
                             self.AddressTypeMarker(target_address))

  def FindObjectPointers(self, start=0, end=0):
    objects = set()
    def find_object_in_region(reader, start, size, location):
      for slot in range(start, start + size, self.reader.TaggedPointerSize()):
        if not self.reader.IsValidAddress(slot): break
        # Collect only tagged pointers (object) to tagged pointers (map)
        tagged_address = self.reader.ReadTagged(slot)
        if not self.IsValidTaggedObjectAddress(tagged_address): continue
        map_address = self.reader.ReadTagged(tagged_address - 1)
        if not self.IsTaggedMapAddress(map_address): continue
        objects.add(tagged_address)

    if not start and not end:
      self.reader.ForEachMemoryRegion(find_object_in_region)
    else:
      find_object_in_region(self.reader, start, end-start, None)

    return objects


for instance_type in V8Heap.CLASS_MAP.keys():
  if instance_type not in set(INSTANCE_TYPES.values()):
    print(
        f"Warning: No instance type {instance_type} in"
        "v8heapconst.INSTANCE_TYPES, you may need to regenerate v8heapconst.py")


class UnknownObject(HeapObject):

  def __init__(self, heap, address):
    HeapObject.__init__(self, heap, None, None)
    self.address = address

  def GetChars(self):
    return "<???>"

  def __str__(self):
    return "<0x%x>" % self.address


class KnownObject(HeapObject):
  def __init__(self, heap, known_name):
    HeapObject.__init__(self, heap, None, None)
    self.known_name = known_name

  def __str__(self):
    return "<%s>" % self.known_name


class KnownMap(HeapObject):
  def __init__(self, heap, known_name, instance_type):
    HeapObject.__init__(self, heap, None, None)
    self.instance_type = instance_type
    self.known_name = known_name

  def __str__(self):
    return "<%s>" % self.known_name


COMMENT_RE = re.compile(r"^C (0x[0-9a-fA-F]+) (.*)$")
PAGEADDRESS_RE = re.compile(
    r"^P (mappage|oldpage) (0x[0-9a-fA-F]+)$")


class InspectionInfo(object):
  def __init__(self, minidump_name, reader):
    self.comment_file = minidump_name + ".comments"
    self.address_comments = {}
    self.page_address = {}
    if os.path.exists(self.comment_file):
      with open(self.comment_file, "r") as f:
        lines = f.readlines()
        f.close()

        for l in lines:
          m = COMMENT_RE.match(l)
          if m:
            self.address_comments[int(m.group(1), 0)] = m.group(2)
          m = PAGEADDRESS_RE.match(l)
          if m:
            self.page_address[m.group(1)] = int(m.group(2), 0)
    self.reader = reader
    self.styles = {}
    self.color_addresses()
    return

  def get_page_address(self, page_kind):
    return self.page_address.get(page_kind, 0)

  def save_page_address(self, page_kind, address):
    with open(self.comment_file, "a") as f:
      f.write("P %s 0x%x\n" % (page_kind, address))
      f.close()

  def color_addresses(self):
    # Color all stack addresses.
    exception_thread = self.reader.thread_map[self.reader.exception.thread_id]
    stack_top = self.reader.ExceptionSP()
    stack_bottom = exception_thread.stack.start + \
        exception_thread.stack.memory.data_size
    frame_pointer = self.reader.ExceptionFP()
    self.styles[frame_pointer] = "frame"
    for slot in range(stack_top, stack_bottom,
                      self.reader.MachinePointerSize()):
      # stack address
      self.styles[slot] = "sa"
    for slot in range(stack_top, stack_bottom,
                      self.reader.MachinePointerSize()):
      maybe_address = self.reader.ReadUIntPtr(slot)
      # stack value
      self.styles[maybe_address] = "sv"
      if slot == frame_pointer:
        self.styles[slot] = "frame"
        frame_pointer = maybe_address
    self.styles[self.reader.ExceptionIP()] = "pc"

  def get_style_class(self, address):
    return self.styles.get(address, None)

  def get_style_class_string(self, address):
    style = self.get_style_class(address)
    if style is not None:
      return " class=%s " % style
    else:
      return ""

  def set_comment(self, address, comment):
    self.address_comments[address] = comment
    with open(self.comment_file, "a") as f:
      f.write("C 0x%x %s\n" % (address, comment))
      f.close()

  def get_comment(self, address):
    return self.address_comments.get(address, "")


class InspectionPadawan(object):
  """The padawan can improve annotations by sensing well-known objects."""

  def __init__(self, reader, heap):
    self.reader = reader
    self.heap = heap
    self.known_first_map_page = 0
    self.known_first_old_page = 0
    self.context = None

  def __getattr__(self, name):
    """An InspectionPadawan can be used instead of V8Heap, even though
       it does not inherit from V8Heap (aka. mixin)."""
    return getattr(self.heap, name)

  def GetPageAddress(self, tagged_address):
    return tagged_address & ~self.heap.PageAlignmentMask()

  def GetPageOffset(self, tagged_address):
    return tagged_address & self.heap.PageAlignmentMask()

  def IsInKnownMapSpace(self, tagged_address):
    page_address = tagged_address & ~self.heap.PageAlignmentMask()
    return page_address == self.known_first_map_page

  def IsInKnownOldSpace(self, tagged_address):
    page_address = tagged_address & ~self.heap.PageAlignmentMask()
    return page_address == self.known_first_old_page

  def ContainingKnownOldSpaceName(self, tagged_address):
    page_address = tagged_address & ~self.heap.PageAlignmentMask()
    if page_address == self.known_first_old_page: return "OLD_SPACE"
    return None

  def FrameMarkerName(self, value):
    # The frame marker is Smi-tagged but not Smi encoded and 0 is not a valid
    # frame type.
    value = (value >> 1) - 1
    if 0 <= value < len(FRAME_MARKERS):
      return "Possibly %s frame marker" % FRAME_MARKERS[value]
    return None

  def IsFrameMarker(self, slot, address):
    if not slot: return False
    # Frame markers only occur directly after a frame pointer and only on the
    # stack.
    if not self.reader.IsExceptionStackAddress(slot): return False
    next_slot = slot + self.reader.MachinePointerSize()
    if not self.reader.IsValidAddress(next_slot): return False
    next_address = self.reader.ReadUIntPtr(next_slot)
    return self.reader.IsExceptionStackAddress(next_address)

  def FormatSmi(self, address):
    value = self.heap.SmiUntag(address)
    # On 32-bit systems almost everything looks like a Smi.
    if not self.reader.Is64() or value == 0: return None
    return "Tagged<Smi>(%d)" % value

  def SenseObject(self, address, slot=None):
    if self.IsFrameMarker(slot, address):
      return self.FrameMarkerName(address)
    if self.heap.IsSmi(address):
      return self.FormatSmi(address)
    if not self.heap.IsMaybeWeakTaggedAddress(address):
      return None
    tagged_address = address
    is_weak = self.heap.IsWeakTaggedAddress(address)
    if is_weak:
      tagged_address &= ~2
    if self.heap.IsPointerCompressed():
      # Interpret the first page as the read-only space in pointer-compression.
      page = self.GetPageAddress(tagged_address)
      tagged_page = page & 0xFFFFFFFF
      if tagged_page == 0:
        offset = self.GetPageOffset(tagged_address)
        if offset == 1 and is_weak:
          return "<cleared>"
        lookup_key = ("read_only_space", offset)
        known_obj_name = KNOWN_OBJECTS.get(lookup_key)
        if known_obj_name:
          return KnownObject(self, known_obj_name)
        known_map_info = KNOWN_MAPS.get(lookup_key)
        if known_map_info:
          known_map_type, known_map_name = known_map_info
          return KnownObject(self, known_map_name)

    if self.IsInKnownOldSpace(tagged_address):
      offset = self.GetPageOffset(tagged_address)
      lookup_key = (self.ContainingKnownOldSpaceName(tagged_address), offset)
      known_obj_name = KNOWN_OBJECTS.get(lookup_key)
      if known_obj_name:
        return KnownObject(self, known_obj_name)
      known_map_info = KNOWN_MAPS.get(lookup_key)
      if known_map_info:
        known_map_type, known_map_name = known_map_info
        return KnownObject(self, known_map_name)

    if self.IsInKnownMapSpace(tagged_address):
      known_map = self.SenseMap(tagged_address)
      if known_map:
        return known_map

    found_obj = self.heap.FindObject(tagged_address)
    if found_obj:
      return found_obj
    address = tagged_address - 1
    if self.reader.IsValidAddress(address):
      map_tagged_address = self.reader.ReadTagged(address)
      map = self.SenseMap(map_tagged_address)
      if map is None:
        return None
      instance_type_name = INSTANCE_TYPES.get(map.instance_type)
      if instance_type_name is None:
        return None
      cls = V8Heap.CLASS_MAP.get(instance_type_name, HeapObject)
      return cls(self, map, address)
    return None

  def SenseMap(self, tagged_address):
    if self.heap.IsPointerCompressed():
      # Interpret the first page as the read-only space in pointer-compression.
      page = self.GetPageAddress(tagged_address)
      tagged_page = page & 0xFFFFFFFF
      if tagged_page == 0:
        offset = self.GetPageOffset(tagged_address)
        lookup_key = ("read_only_space", offset)
        known_map_info = KNOWN_MAPS.get(lookup_key)
        if known_map_info:
          known_map_type, known_map_name = known_map_info
          return KnownMap(self, known_map_name, known_map_type)
    if self.IsInKnownMapSpace(tagged_address):
      offset = self.GetPageOffset(tagged_address)
      lookup_key = ("old_space", offset)
      known_map_info = KNOWN_MAPS.get(lookup_key)
      if known_map_info:
        known_map_type, known_map_name = known_map_info
        return KnownMap(self, known_map_name, known_map_type)
    found_map = self.heap.FindMap(tagged_address)
    if found_map:
      return found_map
    return None

  def FindObjectOrSmi(self, tagged_address):
    """When used as a mixin in place of V8Heap."""
    found_obj = self.SenseObject(tagged_address)
    if found_obj:
      return found_obj
    if self.IsSmi(tagged_address):
      return self.FormatSmi(tagged_address)
    else:
      return UnknownObject(self, tagged_address)

  def FindObject(self, tagged_address):
    """When used as a mixin in place of V8Heap."""
    raise NotImplementedError

  def FindMap(self, tagged_address):
    """When used as a mixin in place of V8Heap."""
    raise NotImplementedError

  def PrintKnowledge(self):
    print("  known_first_map_page = %s\n"\
          "  known_first_old_page = %s" % (
          self.reader.FormatIntPtr(self.known_first_map_page),
          self.reader.FormatIntPtr(self.known_first_old_page)))

  def FindFirstAsciiString(self, start, end=None, min_length=32):
    """ Walk the memory until we find a large string """
    if not end:
      end = start + 64
    for slot in range(start, end):
      if not self.reader.IsValidAddress(slot):
        break
      message = self.reader.ReadAsciiString(slot)
      if len(message) > min_length:
        return (slot, message)
    return (None,None)

  def PrintStackTraceMessage(self, start=None, print_message=True):
    """
    Try to print a possible message from PushStackTraceAndDie.
    Returns the first address where the normal stack starts again.
    """
    # Only look at the first 1k words on the stack
    ptr_size = self.reader.MachinePointerSize()
    if start is None:
      start = self.reader.ExceptionSP()
    if not self.reader.IsValidAddress(start):
      return start
    end = start + ptr_size * 1024 * 4
    magic1 = None
    for slot in range(start, end, ptr_size):
      if not self.reader.IsValidAddress(slot + ptr_size):
        break
      magic1 = self.reader.ReadUIntPtr(slot)
      magic2 = self.reader.ReadUIntPtr(slot + ptr_size)
      pair = (magic1 & 0xFFFFFFFF, magic2 & 0xFFFFFFFF)
      if pair in MAGIC_MARKER_PAIRS:
        return self.TryExtractOldStyleStackTrace(slot, start, end,
                                                 print_message)
      if pair[0] == STACK_TRACE_MARKER:
        return self.TryExtractStackTrace(slot, start, end, print_message)
      elif pair[0] == ERROR_MESSAGE_MARKER:
        return self.TryExtractErrorMessage(slot, start, end, print_message)
    # Simple fallback in case not stack trace object was found
    return self.TryExtractOldStyleStackTrace(0, start, end, print_message)

  def TryExtractStackTrace(self, slot, start, end, print_message):
    ptr_size = self.reader.MachinePointerSize()
    assert self.reader.ReadUIntPtr(slot) & 0xFFFFFFFF == STACK_TRACE_MARKER
    end_marker = STACK_TRACE_MARKER + 1
    header_size = 10
    # Look for the end marker after the fields and the message buffer.
    end_search = start + (32 * 1024) + (header_size * ptr_size)
    end_slot = self.reader.FindPtr(end_marker, end_search,
                                   end_search + ptr_size * 512)
    if not end_slot:
      return start
    print("Stack Message (start=%s):" % self.heap.FormatIntPtr(slot))
    slot += ptr_size
    for name in ("isolate", "ptr1", "ptr2", "ptr3", "ptr4", "ptr5", "ptr6",
                 "codeObject1", "codeObject2", "codeObject3", "codeObject4"):
      value = self.reader.ReadUIntPtr(slot)
      print(" %s: %s" % (name.rjust(14), self.heap.FormatIntPtr(value)))
      slot += ptr_size
    print("  message start: %s" % self.heap.FormatIntPtr(slot))
    stack_start = end_slot + ptr_size
    print("  stack_start:   %s" % self.heap.FormatIntPtr(stack_start))
    (message_start, message) = self.FindFirstAsciiString(slot)
    self.FormatStackTrace(message, print_message)
    return stack_start

  def TryExtractErrorMessage(self, slot, start, end, print_message):
    ptr_size = self.reader.MachinePointerSize()
    end_marker = ERROR_MESSAGE_MARKER + 1
    header_size = 1
    end_search = start + 1024 + (header_size * ptr_size)
    end_slot = self.reader.FindPtr(end_marker, end_search,
                                   end_search + ptr_size * 512)
    if not end_slot:
      return start
    print("Error Message (start=%s):" % self.heap.FormatIntPtr(slot))
    slot += ptr_size
    (message_start, message) = self.FindFirstAsciiString(slot)
    self.FormatStackTrace(message, print_message)
    stack_start = end_slot + ptr_size
    return stack_start

  def TryExtractOldStyleStackTrace(self, message_slot, start, end,
                                   print_message):
    ptr_size = self.reader.MachinePointerSize()
    if message_slot == 0:
      """
      On Mac we don't always get proper magic markers, so just try printing
      the first long ascii string found on the stack.
      """
      magic1 = None
      magic2 = None
      message_start, message = self.FindFirstAsciiString(start, end, 128)
      if message_start is None:
        return start
    else:
      message_start = self.reader.ReadUIntPtr(message_slot + ptr_size * 4)
      message = self.reader.ReadAsciiString(message_start)
    stack_start = message_start + len(message) + 1
    # Make sure the address is word aligned
    stack_start =  stack_start - (stack_start % ptr_size)
    if magic1 is None:
      print("Stack Message:")
      print("  message start: %s" % self.heap.FormatIntPtr(message_start))
      print("  stack_start:   %s" % self.heap.FormatIntPtr(stack_start ))
    else:
      ptr1 = self.reader.ReadUIntPtr(slot + ptr_size * 2)
      ptr2 = self.reader.ReadUIntPtr(slot + ptr_size * 3)
      print("Stack Message:")
      print("  magic1:        %s" % self.heap.FormatIntPtr(magic1))
      print("  magic2:        %s" % self.heap.FormatIntPtr(magic2))
      print("  ptr1:          %s" % self.heap.FormatIntPtr(ptr1))
      print("  ptr2:          %s" % self.heap.FormatIntPtr(ptr2))
      print("  message start: %s" % self.heap.FormatIntPtr(message_start))
      print("  stack_start:   %s" % self.heap.FormatIntPtr(stack_start ))
      print("")
    self.FormatStackTrace(message, print_message)
    return stack_start

  def FormatStackTrace(self, message, print_message):
    if not print_message:
      print("  Use `dsa` to print the message with annotated addresses.")
      print("")
      return
    ptr_size = self.reader.MachinePointerSize()
    # Annotate all addresses in the dumped message
    prog = re.compile("[0-9a-fA-F]{%s}" % ptr_size*2)
    addresses = list(set(prog.findall(message)))
    for i in range(len(addresses)):
      address_org = addresses[i]
      address = self.heap.FormatIntPtr(int(address_org, 16))
      if address_org != address:
        message = message.replace(address_org, address)
    print("Message:")
    print("="*80)
    print(message)
    print("="*80)
    print("")

  def TryInferFramePointer(self, slot, address):
    """ Assume we have a framepointer if we find 4 consecutive links """
    for i in range(0, 4):
      if not self.reader.IsExceptionStackAddress(address):
        return 0
      next_address = self.reader.ReadUIntPtr(address)
      if next_address == address:
        return 0
      address = next_address
    return slot

  def TryInferContext(self, address):
    if self.context:
      return
    ptr_size = self.reader.MachinePointerSize()
    possible_context = dict()
    count = 0
    while self.reader.IsExceptionStackAddress(address):
      prev_addr = self.reader.ReadUIntPtr(address-ptr_size)
      if self.heap.IsTaggedObjectAddress(prev_addr):
        if prev_addr in possible_context:
          possible_context[prev_addr] += 1
        else:
          possible_context[prev_addr] = 1
      address = self.reader.ReadUIntPtr(address)
      count += 1
    if count <= 5 or len(possible_context) == 0:
      return
    # Find entry with highest count
    possible_context = list(possible_context.items())
    possible_context.sort(key=lambda pair: pair[1])
    address,count = possible_context[-1]
    if count <= 4:
      return
    self.context = address

  def InterpretMemory(self, start, end):
    # On 64 bit we omit frame pointers, so we have to do some more guesswork.
    frame_pointer = 0
    if not self.reader.Is64():
      frame_pointer = self.reader.ExceptionFP()
      # Follow the framepointer into the address range
      while frame_pointer and frame_pointer < start:
        frame_pointer = self.reader.ReadUIntPtr(frame_pointer)
        if not self.reader.IsExceptionStackAddress(frame_pointer) or \
            not frame_pointer:
          frame_pointer = 0
          break
    in_oom_dump_area  = False
    is_stack = self.reader.IsExceptionStackAddress(start)
    free_space_end = 0
    ptr_size = self.reader.TaggedPointerSize()

    for slot in range(start, end, ptr_size):
      if not self.reader.IsValidAddress(slot):
        print("%s: Address is not contained within the minidump!" % slot)
        return
      maybe_address = self.reader.ReadUIntPtr(slot)
      address_info = []
      # Mark continuous free space objects
      if slot == free_space_end:
        address_info.append("+")
      elif slot <= free_space_end:
        address_info.append("|")
      else:
        free_space_end = 0

      heap_object = self.SenseObject(maybe_address, slot)
      if heap_object:
        # Detect Free-space ranges
        if isinstance(heap_object, KnownMap) and \
            heap_object.known_name == "FreeSpaceMap":
          # The free-space length is is stored as a Smi in the next slot.
          length = self.reader.ReadTagged(slot + ptr_size)
          if self.heap.IsSmi(length):
            length = self.heap.SmiUntag(length)
            free_space_end = slot + length - ptr_size
        address_info.append(str(heap_object))
      relative_offset = self.heap.RelativeOffset(slot, maybe_address)
      if relative_offset:
        address_info.append(relative_offset)
      if maybe_address == self.context:
        address_info.append("CONTEXT")

      maybe_address_contents = None
      if is_stack:
        if self.reader.IsExceptionStackAddress(maybe_address):
          maybe_address_contents = \
              self.reader.ReadUIntPtr(maybe_address) & 0xFFFFFFFF
          if maybe_address_contents == 0xdecade00:
            in_oom_dump_area = True
          if frame_pointer == 0:
            frame_pointer = self.TryInferFramePointer(slot, maybe_address)
            if frame_pointer != 0:
              self.TryInferContext(slot)
        maybe_symbol = self.reader.FindSymbol(maybe_address)
        if in_oom_dump_area:
          if maybe_address_contents == 0xdecade00:
            address_info = ["<==== HeapStats start marker"]
          elif maybe_address_contents == 0xdecade01:
            address_info = ["<==== HeapStats end marker"]
          elif maybe_address_contents is not None:
            address_info = [
                " %d (%d Mbytes)" %
                (maybe_address_contents, maybe_address_contents >> 20)
            ]
        if slot == frame_pointer:
          if not self.reader.IsExceptionStackAddress(maybe_address):
            address_info.append("<==== BAD frame pointer")
            frame_pointer = 0
          else:
            address_info.append("<==== Frame pointer")
          frame_pointer = maybe_address
      address_type_marker = self.heap.AddressTypeMarker(maybe_address)
      string_value = self.reader.ReadAsciiPtr(slot)
      print("%s: %s %s %s %s" %
            (self.reader.FormatIntPtr(slot),
             self.reader.FormatIntPtr(maybe_address), address_type_marker,
             string_value, ' | '.join(address_info)))
      if maybe_address_contents == 0xdecade01:
        in_oom_dump_area = False
      heap_object = self.heap.FindObject(maybe_address)
      if heap_object:
        heap_object.Print(Printer())
        print("")

WEB_HEADER = """
<!DOCTYPE html>
<html>
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type">
<style media="screen" type="text/css">

.code {
  font-family: monospace;
}

.dmptable {
  border-collapse : collapse;
  border-spacing : 0px;
  table-layout: fixed;
}

.codedump {
  border-collapse : collapse;
  border-spacing : 0px;
  table-layout: fixed;
}

.addrcomments {
  border : 0px;
}

.register {
  padding-right : 1em;
}

.header {
  clear : both;
}

.header .navigation {
  float : left;
}

.header .dumpname {
  float : right;
}

tr.highlight-line {
  background-color : yellow;
}

.highlight {
  background-color : magenta;
}

tr.inexact-highlight-line {
  background-color : pink;
}

input {
  background-color: inherit;
  border: 1px solid LightGray;
}

.dumpcomments {
  border : 1px solid LightGray;
  width : 32em;
}

.regions td {
  padding:0 15px 0 15px;
}

.stackframe td {
  background-color : cyan;
}

.stackaddress, .sa {
  background-color : LightGray;
}

.stackval, .sv {
  background-color : LightCyan;
}

.frame {
  background-color : cyan;
}

.commentinput, .ci {
  width : 20em;
}

/* a.nodump */
a.nd:visited {
  color : black;
  text-decoration : none;
}

a.nd:link {
  color : black;
  text-decoration : none;
}

a:visited {
  color : blueviolet;
}

a:link {
  color : blue;
}

.disasmcomment {
  color : DarkGreen;
}

</style>

<script type="application/javascript">

var address_str = "address-";
var address_len = address_str.length;

function comment() {
  var s = event.srcElement.id;
  var index = s.indexOf(address_str);
  if (index >= 0) {
    send_comment(s.substring(index + address_len), event.srcElement.value);
  }
}
var c = comment;

function send_comment(address, comment) {
  xmlhttp = new XMLHttpRequest();
  address = encodeURIComponent(address)
  comment = encodeURIComponent(comment)
  xmlhttp.open("GET",
      "setcomment?%(query_dump)s&address=" + address +
      "&comment=" + comment, true);
  xmlhttp.send();
}

var dump_str = "dump-";
var dump_len = dump_str.length;

function dump_comment() {
  var s = event.srcElement.id;
  var index = s.indexOf(dump_str);
  if (index >= 0) {
    send_dump_desc(s.substring(index + dump_len), event.srcElement.value);
  }
}

function send_dump_desc(name, desc) {
  xmlhttp = new XMLHttpRequest();
  name = encodeURIComponent(name)
  desc = encodeURIComponent(desc)
  xmlhttp.open("GET",
      "setdumpdesc?dump=" + name +
      "&description=" + desc, true);
  xmlhttp.send();
}

function onpage(kind, address) {
  xmlhttp = new XMLHttpRequest();
  kind = encodeURIComponent(kind)
  address = encodeURIComponent(address)
  xmlhttp.onreadystatechange = function() {
    if (xmlhttp.readyState==4 && xmlhttp.status==200) {
      location.reload(true)
    }
  };
  xmlhttp.open("GET",
      "setpageaddress?%(query_dump)s&kind=" + kind +
      "&address=" + address);
  xmlhttp.send();
}

</script>

<title>Dump %(dump_name)s</title>
</head>

<body>
  <div class="header">
    <form class="navigation" action="search.html">
      <a href="summary.html?%(query_dump)s">Context info</a>&nbsp;&nbsp;&nbsp;
      <a href="info.html?%(query_dump)s">Dump info</a>&nbsp;&nbsp;&nbsp;
      <a href="modules.html?%(query_dump)s">Modules</a>&nbsp;&nbsp;&nbsp;
      &nbsp;
      <input type="search" name="val">
      <input type="submit" name="search" value="Search">
      <input type="hidden" name="dump" value="%(dump_name)s">
    </form>
    <form class="navigation" action="disasm.html#highlight">
      &nbsp;
      &nbsp;
      &nbsp;
      <input type="search" name="val">
      <input type="submit" name="disasm" value="Disasm">
      &nbsp;
      &nbsp;
      &nbsp;
      <a href="dumps.html">Dumps...</a>
    </form>
  </div>
  <br>
  <hr>
"""


WEB_FOOTER = """
</body>
</html>
"""


class WebParameterError(Exception):
  pass


class InspectionWebHandler(http_server.BaseHTTPRequestHandler):

  def formatter(self, query_components):
    name = query_components.get("dump", [None])[0]
    return self.server.get_dump_formatter(name)

  def send_success_html_headers(self):
    self.send_response(200)
    self.send_header("Cache-Control", "no-cache, no-store, must-revalidate")
    self.send_header("Pragma", "no-cache")
    self.send_header("Expires", "0")
    self.send_header('Content-type','text/html')
    self.end_headers()
    return

  def write(self, string):
    self.wfile.write(string.encode('utf-8'))

  def do_GET(self):
    try:
      parsedurl = urllib.parse.urlparse(self.path)
      query_components = urllib.parse.parse_qs(parsedurl.query)
      out_buffer = io.StringIO()
      if parsedurl.path == "/dumps.html":
        self.send_success_html_headers()
        self.server.output_dumps(out_buffer)
        self.write(out_buffer.getvalue())
      elif parsedurl.path == "/summary.html":
        self.send_success_html_headers()
        self.formatter(query_components).output_summary(out_buffer)
        self.write(out_buffer.getvalue())
      elif parsedurl.path == "/info.html":
        self.send_success_html_headers()
        self.formatter(query_components).output_info(out_buffer)
        self.write(out_buffer.getvalue())
      elif parsedurl.path == "/modules.html":
        self.send_success_html_headers()
        self.formatter(query_components).output_modules(out_buffer)
        self.write(out_buffer.getvalue())
      elif parsedurl.path == "/search.html" or parsedurl.path == "/s":
        address = query_components.get("val", [])
        if len(address) != 1:
          self.send_error(404, "Invalid params")
          return
        self.send_success_html_headers()
        self.formatter(query_components).output_search_res(
            out_buffer, address[0])
        self.write(out_buffer.getvalue())
      elif parsedurl.path == "/disasm.html":
        address = query_components.get("val", [])
        exact = query_components.get("exact", ["on"])
        if len(address) != 1:
          self.send_error(404, "Invalid params")
          return
        self.send_success_html_headers()
        self.formatter(query_components).output_disasm(
            out_buffer, address[0], exact[0])
        self.write(out_buffer.getvalue())
      elif parsedurl.path == "/data.html":
        address = query_components.get("val", [])
        datakind = query_components.get("type", ["address"])
        if len(address) == 1 and len(datakind) == 1:
          self.send_success_html_headers()
          self.formatter(query_components).output_data(
              out_buffer, address[0], datakind[0])
          self.write(out_buffer.getvalue())
        else:
          self.send_error(404,'Invalid params')
      elif parsedurl.path == "/setdumpdesc":
        name = query_components.get("dump", [""])
        description = query_components.get("description", [""])
        if len(name) == 1 and len(description) == 1:
          name = name[0]
          description = description[0]
          if self.server.set_dump_desc(name, description):
            self.send_success_html_headers()
            self.write("OK")
            return
        self.send_error(404,'Invalid params')
      elif parsedurl.path == "/setcomment":
        address = query_components.get("address", [])
        comment = query_components.get("comment", [""])
        if len(address) == 1 and len(comment) == 1:
          address = address[0]
          comment = comment[0]
          self.formatter(query_components).set_comment(address, comment)
          self.send_success_html_headers()
          self.write("OK")
        else:
          self.send_error(404,'Invalid params')
      elif parsedurl.path == "/setpageaddress":
        kind = query_components.get("kind", [])
        address = query_components.get("address", [""])
        if len(kind) == 1 and len(address) == 1:
          kind = kind[0]
          address = address[0]
          self.formatter(query_components).set_page_address(kind, address)
          self.send_success_html_headers()
          self.write("OK")
        else:
          self.send_error(404,'Invalid params')
      else:
        self.send_error(404,'File Not Found: %s' % self.path)

    except IOError:
      self.send_error(404,'File Not Found: %s' % self.path)

    except WebParameterError as e:
      self.send_error(404, 'Web parameter error: %s' % e.message)


HTML_REG_FORMAT = "<span class=\"register\"><b>%s</b>:&nbsp;%s</span><br/>\n"


class InspectionWebFormatter(object):
  CONTEXT_FULL = 0
  CONTEXT_SHORT = 1

  def __init__(self, switches, minidump_name, http_server):
    self.dumpfilename = os.path.split(minidump_name)[1]
    self.encfilename = urllib.parse.urlencode({'dump': self.dumpfilename})
    self.reader = MinidumpReader(switches, minidump_name)
    self.server = http_server

    # Set up the heap
    exception_thread = self.reader.thread_map[self.reader.exception.thread_id]
    stack_top = self.reader.ExceptionSP()
    stack_bottom = exception_thread.stack.start + \
        exception_thread.stack.memory.data_size
    stack_map = {self.reader.ExceptionIP(): -1}
    for slot in range(stack_top, stack_bottom,
                      self.reader.MachinePointerSize()):
      maybe_address = self.reader.ReadUIntPtr(slot)
      if not maybe_address in stack_map:
        stack_map[maybe_address] = slot
    self.heap = V8Heap(self.reader, stack_map)

    self.padawan = InspectionPadawan(self.reader, self.heap)
    self.comments = InspectionInfo(minidump_name, self.reader)
    self.padawan.known_first_old_page = (
        self.comments.get_page_address("oldpage"))
    self.padawan.known_first_map_page = (
        self.comments.get_page_address("mappage"))

  def set_comment(self, straddress, comment):
    try:
      address = int(straddress, 0)
      self.comments.set_comment(address, comment)
    except ValueError:
      print("Invalid address")

  def set_page_address(self, kind, straddress):
    try:
      address = int(straddress, 0)
      if kind == "oldpage":
        self.padawan.known_first_old_page = address
      elif kind == "mappage":
        self.padawan.known_first_map_page = address
      self.comments.save_page_address(kind, address)
    except ValueError:
      print("Invalid address")

  def td_from_address(self, f, address):
    f.write("<td %s>" % self.comments.get_style_class_string(address))

  def format_address(self, maybeaddress, straddress = None):
    if maybeaddress is None:
      return "not in dump"
    else:
      if straddress is None:
        straddress = "0x" + self.reader.FormatIntPtr(maybeaddress)
      style_class = ""
      if not self.reader.IsValidAddress(maybeaddress):
        style_class = "class=nd"
      return ("<a %s href=s?%s&amp;val=%s>%s</a>" %
              (style_class, self.encfilename, straddress, straddress))

  def format_onheap_address(self, size, maybeaddress, uncompressed):
    if maybeaddress is None:
      return "not in dump"
    else:
      straddress = "0x" + self.reader.FormatTagged(maybeaddress)
      struncompressed = "0x" + self.reader.FormatIntPtr(uncompressed)
      style_class = ""
      if not self.reader.IsValidAddress(uncompressed):
        style_class = "class=nd"
      return ("<a %s href=s?%s&amp;val=%s>%s</a>" %
              (style_class, self.encfilename, struncompressed, straddress))

  def output_header(self, f):
    f.write(WEB_HEADER % {
        "query_dump": self.encfilename,
        "dump_name": html.escape(self.dumpfilename)
    })

  def output_footer(self, f):
    f.write(WEB_FOOTER)

  MAX_CONTEXT_STACK = 2048

  def output_summary(self, f):
    self.output_header(f)
    f.write('<div class="code">')
    self.output_context(f, InspectionWebFormatter.CONTEXT_SHORT)
    self.output_disasm_pc(f)
    # Output stack, trying to also output the stack trace if dumped.
    stack_top = self.try_output_stack_trace(f)

    exception_thread = self.reader.thread_map[self.reader.exception.thread_id]
    stack_bottom = min(exception_thread.stack.start + \
        exception_thread.stack.memory.data_size,
        stack_top + self.MAX_CONTEXT_STACK)

    self.output_words(f, stack_top - 16, stack_bottom, stack_top, "Stack",
                      self.heap.MachinePointerSize())

    f.write('</div>')
    self.output_footer(f)
    return

  def try_output_stack_trace(self, f, start=None, print_message=True):
    """
    Try to print a possible message from PushStackTraceAndDie.
    Returns the first address where the normal stack starts again.
    """
    # Only look at the first 1k words on the stack
    ptr_size = self.reader.MachinePointerSize()
    if start is None:
      start = self.reader.ExceptionSP()
    if not self.reader.IsValidAddress(start):
      return start
    end = start + ptr_size * 1024 * 4
    for slot in range(start, end, ptr_size):
      if not self.reader.IsValidAddress(slot + ptr_size):
        break
      magic = self.reader.ReadUIntPtr(slot)
      if magic == STACK_TRACE_MARKER:
        return self.output_stack_trace(f, slot, start, end, print_message)
    return start

  def output_stack_trace(self, f, slot, start, end, print_message):
    ptr_size = self.reader.MachinePointerSize()
    assert self.reader.ReadUIntPtr(slot) & 0xFFFFFFFF == STACK_TRACE_MARKER
    end_marker = STACK_TRACE_MARKER + 1
    header_size = 10
    # Look for the end marker after the fields and the message buffer.
    end_search = start + (32 * 1024) + (header_size * ptr_size)
    end_slot = self.reader.FindPtr(end_marker, end_search,
                                   end_search + ptr_size * 512)
    if not end_slot:
      return start
    f.write("<h3>PushStackTraceAndDie Stack Message (start=%s):</h3>" %
            self.format_address(slot))
    slot += ptr_size
    for name in ("isolate", "ptr1", "ptr2", "ptr3", "ptr4", "ptr5", "ptr6",
                 "codeObject1", "codeObject2", "codeObject3", "codeObject4"):
      value = self.reader.ReadUIntPtr(slot)
      f.write("<b>%s</b>: %s %s<br>" %
              (name.rjust(14), self.format_address(value),
               "" if name == "isolate" else self.format_object(value)))
      slot += ptr_size
    f.write("<b>message start</b>: %s<br>" % self.format_address(slot))
    stack_start = end_slot + ptr_size
    f.write("<b>stack_start</b>:   %s<br>" % self.format_address(stack_start))
    (message_start, message) = self.padawan.FindFirstAsciiString(slot)
    if print_message and message is not None:
      f.write("<a href='#eom'>Scroll to end of message...</a><br>")
      self.output_stack_trace_message(f, message)
      f.write("<span id=eom></span>")
    return stack_start

  def output_stack_trace_message(self, f, message):
    ptr_size = self.reader.MachinePointerSize()
    # Annotate all addresses in the dumped message
    prog = re.compile("0x[0-9a-fA-F]+")

    message = html.escape(message)
    message = message.replace("\n", "<br>")

    addresses = list(set(prog.findall(message)))
    for i in range(len(addresses)):
      address_org = addresses[i]
      address = int(address_org, 16)
      formatted_address = self.format_address(address, address_org)
      message = message.replace(address_org, formatted_address)

    f.write(message)

  def output_info(self, f):
    self.output_header(f)
    f.write("<h3>Dump info</h3>")
    f.write("Description: ")
    self.server.output_dump_desc_field(f, self.dumpfilename)
    f.write("<br>")
    f.write("Filename: ")
    f.write("<span class=\"code\">%s</span><br>" % (self.dumpfilename))
    dt = datetime.datetime.fromtimestamp(self.reader.header.time_date_stampt)
    f.write("Timestamp: %s<br>" % dt.strftime('%Y-%m-%d %H:%M:%S'))
    self.output_context(f, InspectionWebFormatter.CONTEXT_FULL)
    self.output_address_ranges(f)
    self.output_footer(f)
    return

  def output_address_ranges(self, f):
    regions = {}
    def print_region(_reader, start, size, _location):
      regions[start] = size
    self.reader.ForEachMemoryRegion(print_region)
    f.write("<h3>Available memory regions</h3>")
    f.write('<div class="code">')
    f.write("<table class=\"regions\">")
    f.write("<thead><tr>")
    f.write("<th>Start address</th>")
    f.write("<th>End address</th>")
    f.write("<th>Number of bytes</th>")
    f.write("</tr></thead>")
    for start in sorted(regions):
      size = regions[start]
      f.write("<tr>")
      f.write("<td>%s</td>" % self.format_address(start))
      f.write("<td>&nbsp;%s</td>" % self.format_address(start + size))
      f.write("<td>&nbsp;%d</td>" % size)
      f.write("</tr>")
    f.write("</table>")
    f.write('</div>')
    return

  def output_module_details(self, f, module):
    f.write("<b>%s</b>" % GetModuleName(self.reader, module))
    file_version = GetVersionString(module.version_info.dwFileVersionMS,
                                    module.version_info.dwFileVersionLS)
    product_version = GetVersionString(module.version_info.dwProductVersionMS,
                                       module.version_info.dwProductVersionLS)
    f.write("<br>&nbsp;&nbsp;")
    f.write("base: %s" % self.reader.FormatIntPtr(module.base_of_image))
    f.write("<br>&nbsp;&nbsp;")
    f.write("  end: %s" % self.reader.FormatIntPtr(module.base_of_image +
                                            module.size_of_image))
    f.write("<br>&nbsp;&nbsp;")
    f.write("  file version: %s" % file_version)
    f.write("<br>&nbsp;&nbsp;")
    f.write("  product version: %s" % product_version)
    f.write("<br>&nbsp;&nbsp;")
    time_date_stamp = datetime.datetime.fromtimestamp(module.time_date_stamp)
    f.write("  timestamp: %s" % time_date_stamp)
    f.write("<br>");

  def output_modules(self, f):
    self.output_header(f)
    f.write('<div class="code">')
    for module in self.reader.module_list.modules:
      self.output_module_details(f, module)
    f.write("</div>")
    self.output_footer(f)
    return

  def output_context(self, f, details):
    exception_thread = self.reader.thread_map[self.reader.exception.thread_id]
    f.write("<h3>Exception context</h3>")
    f.write('<div class="code">')
    f.write("Thread id: %d" % exception_thread.id)
    f.write("&nbsp;&nbsp; Exception code: %08X<br/>" %
            self.reader.exception.exception.code)
    if details == InspectionWebFormatter.CONTEXT_FULL:
      if self.reader.exception.exception.parameter_count > 0:
        f.write("&nbsp;&nbsp; Exception parameters: ")
        for i in range(0, self.reader.exception.exception.parameter_count):
          f.write("%08x" % self.reader.exception.exception.information[i])
        f.write("<br><br>")

    for r in CONTEXT_FOR_ARCH[self.reader.arch]:
      f.write(HTML_REG_FORMAT %
              (r, self.format_address(self.reader.Register(r))))
    # TODO(vitalyr): decode eflags.
    if self.reader.arch in [MD_CPU_ARCHITECTURE_ARM, MD_CPU_ARCHITECTURE_ARM64]:
      f.write("<b>cpsr</b>: %s" % bin(self.reader.exception_context.cpsr)[2:])
    else:
      f.write("<b>eflags</b>: %s" %
              bin(self.reader.exception_context.eflags)[2:])
    f.write('</div>')
    return

  def align_down(self, a, size):
    alignment_correction = a % size
    return a - alignment_correction

  def align_up(self, a, size):
    alignment_correction = (size - 1) - ((a + size - 1) % size)
    return a + alignment_correction

  def format_object(self, address):
    heap_object = self.padawan.SenseObject(address)
    return html.escape(str(heap_object or ""))

  def output_data(self, f, straddress, datakind):
    try:
      self.output_header(f)
      address = int(straddress, 0)
      if not self.reader.IsValidAddress(address):
        f.write("<h3>Address 0x%x not found in the dump.</h3>" % address)
        return
      region = self.reader.FindRegion(address)
      if datakind == "address":
        self.output_words(f, region[0], region[0] + region[1], address, "Dump",
                          self.heap.MachinePointerSize())
      if datakind == "tagged":
        self.output_words(f, region[0], region[0] + region[1], address,
                          "Tagged Dump", self.heap.TaggedPointerSize())
      elif datakind == "ascii":
        self.output_ascii(f, region[0], region[0] + region[1], address)
      self.output_footer(f)

    except ValueError:
      f.write("<h3>Unrecognized address format \"%s\".</h3>" % straddress)
    return

  def output_words(self, f, start_address, end_address, highlight_address, desc,
                   size):
    region = self.reader.FindRegion(highlight_address)
    if region is None:
      f.write("<h3>Address 0x%x not found in the dump.</h3>" %
              (highlight_address))
      return
    start_address = self.align_down(start_address, size)
    low = self.align_down(region[0], size)
    high = self.align_up(region[0] + region[1], size)
    if start_address < low:
      start_address = low
    end_address = self.align_up(end_address, size)
    if end_address > high:
      end_address = high

    expand = ""
    if start_address != low or end_address != high:
      additional_query = ""
      if self.heap.IsPointerCompressed(
      ) and size == self.reader.TaggedPointerSize():
        additional_query = "&amp;type=tagged"

      expand = ("(<a href=\"data.html?%s&amp;val=0x%x%s#highlight\">"
                " more..."
                " </a>)" %
                (self.encfilename, highlight_address, additional_query))

    f.write("<h3>%s 0x%x - 0x%x, "
            "highlighting <a href=\"#highlight\">0x%x</a> %s</h3>" %
            (desc, start_address, end_address, highlight_address, expand))
    f.write('<div class="code">')
    f.write("<table class=codedump>")

    for j in range(0, end_address - start_address, size):
      slot = start_address + j
      heap_object = ""
      maybe_address = None
      maybe_uncompressed_address = None
      end_region = region[0] + region[1]
      if slot < region[0] or slot + size > end_region:
        straddress = "0x"
        for i in range(end_region, slot + size):
          straddress += "??"
        for i in reversed(
            range(max(slot, region[0]), min(slot + size, end_region))):
          straddress += "%02x" % self.reader.ReadU8(i)
        for i in range(slot, region[0]):
          straddress += "??"
      else:
        maybe_address = self.reader.ReadSized(slot, size)
        if size == self.reader.MachinePointerSize():
          maybe_uncompressed_address = maybe_address
        else:
          maybe_uncompressed_address = (slot & (0xFFFFFFFF << 32)) | (
              maybe_address & 0xFFFFFFFF)

        if size == self.reader.TaggedPointerSize():
          straddress = self.format_onheap_address(size, maybe_address,
                                                  maybe_uncompressed_address)
          if maybe_address:
            heap_object = self.format_object(maybe_uncompressed_address)
        else:
          straddress = self.format_address(maybe_address)

      address_fmt = "%s&nbsp;</td>"
      if slot == highlight_address:
        f.write("<tr class=highlight-line>")
        address_fmt = "<a id=highlight></a>%s&nbsp;</td>"
      elif slot < highlight_address and highlight_address < slot + size:
        f.write("<tr class=inexact-highlight-line>")
        address_fmt = "<a id=highlight></a>%s&nbsp;</td>"
      else:
        f.write("<tr>")

      f.write("<td>")
      self.output_comment_box(f, "da-", slot)
      f.write("</td>")
      self.td_from_address(f, slot)
      f.write(address_fmt % self.format_address(slot))
      self.td_from_address(f, maybe_uncompressed_address)
      f.write(":&nbsp;%s&nbsp;</td>" % straddress)
      f.write("<td>")
      if maybe_uncompressed_address is not None:
        self.output_comment_box(f, "sv-" + self.reader.FormatIntPtr(slot),
                                maybe_uncompressed_address)
      f.write("</td>")
      f.write("<td>%s</td>" % (heap_object or ''))
      f.write("</tr>")
    f.write("</table>")
    f.write("</div>")
    return

  def output_ascii(self, f, start_address, end_address, highlight_address):
    region = self.reader.FindRegion(highlight_address)
    if region is None:
      f.write("<h3>Address %x not found in the dump.</h3>" %
          highlight_address)
      return
    if start_address < region[0]:
      start_address = region[0]
    if end_address > region[0] + region[1]:
      end_address = region[0] + region[1]

    expand = ""
    if start_address != region[0] or end_address != region[0] + region[1]:
      link = ("data.html?%s&amp;val=0x%x&amp;type=ascii#highlight" %
              (self.encfilename, highlight_address))
      expand = "(<a href=\"%s\">more...</a>)" % link

    f.write("<h3>ASCII dump 0x%x - 0x%x, highlighting 0x%x %s</h3>" %
            (start_address, end_address, highlight_address, expand))

    line_width = 64

    f.write('<div class="code">')

    start = self.align_down(start_address, line_width)

    for i in range(end_address - start):
      address = start + i
      if address % 64 == 0:
        if address != start:
          f.write("<br>")
        f.write("0x%08x:&nbsp;" % address)
      if address < start_address:
        f.write("&nbsp;")
      else:
        if address == highlight_address:
          f.write("<span class=\"highlight\">")
        code = self.reader.ReadU8(address)
        if code < 127 and code >= 32:
          f.write("&#")
          f.write(str(code))
          f.write(";")
        else:
          f.write("&middot;")
        if address == highlight_address:
          f.write("</span>")
    f.write("</div>")
    return

  def output_disasm(self, f, straddress, strexact):
    try:
      self.output_header(f)
      address = int(straddress, 0)
      if not self.reader.IsValidAddress(address):
        f.write("<h3>Address 0x%x not found in the dump.</h3>" % address)
        return
      region = self.reader.FindRegion(address)
      self.output_disasm_range(
          f, region[0], region[0] + region[1], address, strexact == "on")
      self.output_footer(f)
    except ValueError:
      f.write("<h3>Unrecognized address format \"%s\".</h3>" % straddress)
    return

  def output_disasm_range(
      self, f, start_address, end_address, highlight_address, exact):
    region = self.reader.FindRegion(highlight_address)
    if start_address < region[0]:
      start_address = region[0]
    if end_address > region[0] + region[1]:
      end_address = region[0] + region[1]
    count = end_address - start_address
    lines = self.reader.GetDisasmLines(start_address, count)
    found = False
    if exact:
      for line in lines:
        if line[0] + start_address == highlight_address:
          found = True
          break
      if not found:
        start_address = highlight_address
        count = end_address - start_address
        lines = self.reader.GetDisasmLines(highlight_address, count)
    expand = ""
    if start_address != region[0] or end_address != region[0] + region[1]:
      exactness = ""
      if exact and not found and end_address == region[0] + region[1]:
        exactness = "&amp;exact=off"
      expand = ("(<a href=\"disasm.html?%s%s"
                "&amp;val=0x%x#highlight\">more...</a>)" %
                (self.encfilename, exactness, highlight_address))

    f.write("<h3>Disassembling 0x%x - 0x%x, highlighting 0x%x %s</h3>" %
            (start_address, end_address, highlight_address, expand))
    f.write('<div class="code">')
    f.write("<table class=\"codedump\">");
    for i in range(len(lines)):
      line = lines[i]
      next_address = count
      if i + 1 < len(lines):
        next_line = lines[i + 1]
        next_address = next_line[0]
      self.format_disasm_line(
          f, start_address, line, next_address, highlight_address)
    f.write("</table>")
    f.write("</div>")
    return

  def annotate_disasm_addresses(self, line):
    extra = []
    for m in ADDRESS_RE.finditer(line):
      maybe_address = int(m.group(0), 16)
      formatted_address = self.format_address(maybe_address, m.group(0))
      line = line.replace(m.group(0), formatted_address)
      object_info = self.padawan.SenseObject(maybe_address)
      if not object_info:
        continue
        extra.append(html.escape(str(object_info)))
    if len(extra) == 0:
      return line
    return ("%s <span class=disasmcomment>;; %s</span>" %
            (line, ", ".join(extra)))

  def format_disasm_line(
      self, f, start, line, next_address, highlight_address):
    line_address = start + line[0]
    address_fmt = "  <td>%s</td>"
    if line_address == highlight_address:
      f.write("<tr class=highlight-line>")
      address_fmt = "  <td><a id=highlight>%s</a></td>"
    elif (line_address < highlight_address and
          highlight_address < next_address + start):
      f.write("<tr class=inexact-highlight-line>")
      address_fmt = "  <td><a id=highlight>%s</a></td>"
    else:
      f.write("<tr>")
    num_bytes = next_address - line[0]
    stack_slot = self.heap.stack_map.get(line_address)
    marker = ""
    if stack_slot:
      marker = "=>"

    code = line[1]

    # Some disassemblers insert spaces between each byte,
    # while some do not.
    if code[2] == " ":
      op_offset = 3 * num_bytes - 1
    else:
      op_offset = 2 * num_bytes

    # Compute the actual call target which the disassembler is too stupid
    # to figure out (it adds the call offset to the disassembly offset rather
    # than the absolute instruction address).
    if self.heap.reader.arch == MD_CPU_ARCHITECTURE_X86:
      if code.startswith("e8"):
        words = code.split()
        if len(words) > 6 and words[5] == "call":
          offset = int(words[4] + words[3] + words[2] + words[1], 16)
          target = (line_address + offset + 5) & 0xFFFFFFFF
          code = code.replace(words[6], "0x%08x" % target)
    # TODO(jkummerow): port this hack to ARM and x64.

    opcodes = code[:op_offset]
    code = self.annotate_disasm_addresses(code[op_offset:])
    f.write("  <td>")
    self.output_comment_box(f, "codel-", line_address)
    f.write("</td>")
    f.write(address_fmt % marker)
    f.write("  ")
    self.td_from_address(f, line_address)
    f.write(self.format_address(line_address))
    f.write(" (+0x%x)</td>" % line[0])
    f.write("<td>:&nbsp;%s&nbsp;</td>" % opcodes)
    f.write("<td>%s</td>" % code)
    f.write("</tr>")

  def output_comment_box(self, f, prefix, address):
    comment = self.comments.get_comment(address)
    value = ""
    if comment:
      value = " value=\"%s\"" % html.escape(comment)
    f.write("<input type=text class=ci "
            "id=%s-address-0x%s onchange=c()%s>" %
            (prefix,
             self.reader.FormatIntPtr(address),
             value))

  MAX_FOUND_RESULTS = 100

  def output_find_results(self, f, results):
    f.write("Addresses")
    toomany = len(results) > self.MAX_FOUND_RESULTS
    if toomany:
      f.write("(found %i results, displaying only first %i)" %
              (len(results), self.MAX_FOUND_RESULTS))
    f.write(": ")
    results = sorted(results)
    results = results[:min(len(results), self.MAX_FOUND_RESULTS)]
    for address in results:
      f.write("<span %s>%s</span>" %
              (self.comments.get_style_class_string(address),
               self.format_address(address)))
    if toomany:
      f.write("...")


  def output_page_info(self, f, page_kind, page_address, my_page_address):
    if my_page_address == page_address and page_address != 0:
      f.write("Marked first %s page." % page_kind)
    else:
      f.write("<span id=\"%spage\" style=\"display:none\">" % page_kind)
      f.write("Marked first %s page." % page_kind)
      f.write("</span>\n")
      f.write("<button onclick=\"onpage('%spage', '0x%x')\">" %
              (page_kind, my_page_address))
      f.write("Mark as first %s page</button>" % page_kind)
    return

  def output_search_res(self, f, straddress):
    try:
      self.output_header(f)
      f.write("<h3>Search results for %s</h3>" % straddress)

      address = int(straddress, 0)

      f.write("Comment: ")
      self.output_comment_box(f, "search-", address)
      f.write("<br>")

      page_address = address & ~self.heap.PageAlignmentMask()

      f.write("Page info: ")
      self.output_page_info(f, "old", self.padawan.known_first_old_page, \
                            page_address)
      self.output_page_info(f, "map", self.padawan.known_first_map_page, \
                            page_address)

      if not self.reader.IsValidAddress(address):
        f.write("<h3>The contents at address %s not found in the dump.</h3>" % \
                straddress)
      else:
        # Print as words
        self.output_words(f, address - 8, address + 32, address, "Dump",
                          self.heap.MachinePointerSize())

        if self.heap.IsPointerCompressed():
          self.output_words(f, address - 8, address + 32, address,
                            "Tagged Dump", self.heap.TaggedPointerSize())

        # Print as ASCII
        f.write("<hr>")
        self.output_ascii(f, address, address + 256, address)

        # Print as code
        f.write("<hr>")
        self.output_disasm_range(f, address - 16, address + 16, address, True)

      aligned_res, unaligned_res = self.reader.FindWordList(address)

      if len(aligned_res) > 0:
        f.write("<h3>Occurrences of 0x%x at aligned addresses</h3>" %
                address)
        self.output_find_results(f, aligned_res)

      if len(unaligned_res) > 0:
        f.write("<h3>Occurrences of 0x%x at unaligned addresses</h3>" % \
                address)
        self.output_find_results(f, unaligned_res)

      if len(aligned_res) + len(unaligned_res) == 0:
        f.write("<h3>No occurrences of 0x%x found in the dump</h3>" % address)

      self.output_footer(f)

    except ValueError:
      f.write("<h3>Unrecognized address format \"%s\".</h3>" % straddress)
    return

  def output_disasm_pc(self, f):
    address = self.reader.ExceptionIP()
    if not self.reader.IsValidAddress(address):
      return
    self.output_disasm_range(f, address - 16, address + 16, address, True)


WEB_DUMPS_HEADER = """
<!DOCTYPE html>
<html>
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type">
<style media="screen" type="text/css">

.dumplist {
  border-collapse : collapse;
  border-spacing : 0px;
  font-family: monospace;
}

.dumpcomments {
  border : 1px solid LightGray;
  width : 32em;
}

</style>

<script type="application/javascript">

var dump_str = "dump-";
var dump_len = dump_str.length;

function dump_comment() {
  var s = event.srcElement.id;
  var index = s.indexOf(dump_str);
  if (index >= 0) {
    send_dump_desc(s.substring(index + dump_len), event.srcElement.value);
  }
}

function send_dump_desc(name, desc) {
  xmlhttp = new XMLHttpRequest();
  name = encodeURIComponent(name)
  desc = encodeURIComponent(desc)
  xmlhttp.open("GET",
      "setdumpdesc?dump=" + name +
      "&description=" + desc, true);
  xmlhttp.send();
}

</script>

<title>Dump list</title>
</head>

<body>
"""

WEB_DUMPS_FOOTER = """
</body>
</html>
"""

DUMP_FILE_RE = re.compile(r"[-_0-9a-zA-Z][-\._0-9a-zA-Z]*\.dmp$")


class InspectionWebServer(http_server.HTTPServer):

  def __init__(self, port_number, switches, minidump_name):
    super().__init__(('localhost', port_number), InspectionWebHandler)
    splitpath = os.path.split(minidump_name)
    self.dumppath = splitpath[0]
    self.dumpfilename = splitpath[1]
    self.default_formatter = InspectionWebFormatter(
        switches, minidump_name, self)
    self.formatters = { self.dumpfilename : self.default_formatter }
    self.switches = switches

  def output_dump_desc_field(self, f, name):
    try:
      descfile = open(os.path.join(self.dumppath, name + ".desc"), "r")
      desc = descfile.readline()
      descfile.close()
    except IOError:
      desc = ""
    f.write("<input type=\"text\" class=\"dumpcomments\" "
            "id=\"dump-%s\" onchange=\"dump_comment()\" value=\"%s\">\n" %
            (html.escape(name), desc))

  def set_dump_desc(self, name, description):
    if not DUMP_FILE_RE.match(name):
      return False
    fname = os.path.join(self.dumppath, name)
    if not os.path.isfile(fname):
      return False
    fname = fname + ".desc"
    descfile = open(fname, "w")
    descfile.write(description)
    descfile.close()
    return True

  def get_dump_formatter(self, name):
    if name is None:
      return self.default_formatter
    else:
      if not DUMP_FILE_RE.match(name):
        raise WebParameterError("Invalid name '%s'" % name)
      formatter = self.formatters.get(name, None)
      if formatter is None:
        try:
          formatter = InspectionWebFormatter(
              self.switches, os.path.join(self.dumppath, name), self)
          self.formatters[name] = formatter
        except IOError:
          raise WebParameterError("Could not open dump '%s'" % name)
      return formatter

  def output_dumps(self, f):
    f.write(WEB_DUMPS_HEADER)
    f.write("<h3>List of available dumps</h3>")
    f.write("<table class=\"dumplist\">\n")
    f.write("<thead><tr>")
    f.write("<th>Name</th>")
    f.write("<th>File time</th>")
    f.write("<th>Comment</th>")
    f.write("</tr></thead>")
    dumps_by_time = {}
    for fname in os.listdir(self.dumppath):
      if DUMP_FILE_RE.match(fname):
        mtime = os.stat(os.path.join(self.dumppath, fname)).st_mtime
        fnames = dumps_by_time.get(mtime, [])
        fnames.append(fname)
        dumps_by_time[mtime] = fnames

    for mtime in sorted(dumps_by_time, reverse=True):
      fnames = dumps_by_time[mtime]
      for fname in fnames:
        f.write("<tr>\n")
        f.write("<td><a href=\"summary.html?%s\">%s</a></td>\n" %
                ((urllib.parse.urlencode({'dump': fname}), fname)))
        f.write("<td>&nbsp;&nbsp;&nbsp;")
        f.write(datetime.datetime.fromtimestamp(mtime))
        f.write("</td>")
        f.write("<td>&nbsp;&nbsp;&nbsp;")
        self.output_dump_desc_field(f, fname)
        f.write("</td>")
        f.write("</tr>\n")
    f.write("</table>\n")
    f.write(WEB_DUMPS_FOOTER)
    return

class InspectionShell(cmd.Cmd):
  def __init__(self, reader, heap):
    cmd.Cmd.__init__(self)
    self.reader = reader
    self.heap = heap
    self.padawan = InspectionPadawan(reader, heap)
    self.prompt = "(grok) "

    self.dd_start = 0
    self.dd_num = 0x10
    self.u_start = 0
    self.u_num = 0

  def EvalExpression(self, expr):
    # Auto convert hex numbers to a python compatible format
    if expr[:2] == "00":
      expr = "0x"+expr
    result = None
    try:
      # Ugly hack to patch in register values.
      registers = [register
                   for register,value in self.reader.ContextDescriptor().fields]
      registers.sort(key=lambda r: len(r))
      registers.reverse()
      for register in registers:
        expr = expr.replace("$"+register, str(self.reader.Register(register)))
      result = eval(expr)
    except Exception as e:
      print("**** Could not evaluate '%s': %s" % (expr, e))
      raise e
    return result

  def ParseAddressExpr(self, expr):
    address = 0;
    try:
      result = self.EvalExpression(expr)
    except:
      return 0
    try:
      address = int(result)
    except Exception as e:
      print("**** Could not convert '%s' => %s to valid address: %s" % (
          expr, result , e))
    return address

  def do_help(self, cmd=None):
    if len(cmd) == 0:
      print("Available commands")
      print("=" * 79)
      prefix = "do_"
      methods = inspect.getmembers(InspectionShell, predicate=inspect.ismethod)
      for name,method in methods:
        if not name.startswith(prefix): continue
        doc = inspect.getdoc(method)
        if not doc: continue
        name = prefix.join(name.split(prefix)[1:])
        description = doc.splitlines()[0]
        print((name + ": ").ljust(16) + description)
      print("=" * 79)
    else:
      return super(InspectionShell, self).do_help(cmd)

  def do_p(self, cmd):
    """ see print """
    return self.do_print(cmd)

  def do_print(self, cmd):
    """
    Evaluate an arbitrary python command.
    """
    try:
      print(self.EvalExpression(cmd))
    except:
      pass

  def do_da(self, address):
    """ see display_ascii"""
    return self.do_display_ascii(address)

  def do_display_ascii(self, address):
    """
     Print ASCII string starting at specified address.
    """
    address = self.ParseAddressExpr(address)
    string = self.reader.ReadAsciiString(address)
    if string == "":
      print("Not an ASCII string at %s" % self.reader.FormatIntPtr(address))
    else:
      print("%s\n" % string)

  def do_dsa(self, address):
    """ see display_stack_ascii"""
    return self.do_display_stack_ascii(address)

  def do_display_stack_ascii(self, address):
    """
    Print ASCII stack error message.
    """
    if self.reader.exception is None:
      print("Minidump has no exception info")
      return
    if len(address) == 0:
      address = None
    else:
      address = self.ParseAddressExpr(address)
    self.padawan.PrintStackTraceMessage(address)

  def do_dd(self, args):
    """
     Interpret memory in the given region [address, address + num * word_size)

     (if available) as a sequence of words. Automatic alignment is not performed.
     If the num is not specified, a default value of 16 words is usif not self.Is
     If no address is given, dd continues printing at the next word.

     Synopsis: dd 0x<address>|$register [0x<num>]
    """
    if len(args) != 0:
      args = args.split(' ')
      self.dd_start = self.ParseAddressExpr(args[0])
      self.dd_num = int(args[1], 16) if len(args) > 1 else 0x10
    else:
      self.dd_start += self.dd_num * self.reader.MachinePointerSize()
    if not self.reader.IsAlignedAddress(self.dd_start):
      print("Warning: Dumping un-aligned memory, is this what you had in mind?")
    end = self.dd_start + self.reader.MachinePointerSize() * self.dd_num
    self.padawan.InterpretMemory(self.dd_start, end)

  def do_do(self, address):
    """ see display_object """
    return self.do_display_object(address)

  def do_display_object(self, address):
    """
     Interpret memory at the given address as a V8 object.

     Automatic alignment makes sure that you can pass tagged as well as
     un-tagged addresses.
    """
    address = self.ParseAddressExpr(address)
    if self.reader.IsAlignedAddress(address):
      address = address + 1
    elif not self.heap.IsTaggedObjectAddress(address):
      print("Address doesn't look like a valid pointer!")
      return
    heap_object = self.padawan.SenseObject(address)
    if heap_object:
      heap_object.Print(Printer())
    else:
      print("Address cannot be interpreted as object!")

  def do_dso(self, args):
    """ see display_stack_objects """
    return self.do_display_stack_objects(args)

  def do_display_stack_objects(self, args):
    """
    Find and Print object pointers in the given range.

    Print all possible object pointers that are on the stack or in the given
    address range.

    Usage: dso [START_ADDR,[END_ADDR]]
    """
    start = self.reader.StackTop()
    end = self.reader.StackBottom()
    if len(args) != 0:
      args = args.split(' ')
      start = self.ParseAddressExpr(args[0])
      end = self.ParseAddressExpr(args[1]) if len(args) > 1 else end
    objects = self.heap.FindObjectPointers(start, end)
    for address in objects:
      heap_object = self.padawan.SenseObject(address)
      info = ""
      if heap_object:
        info = str(heap_object)
      print("%s %s" % (self.padawan.FormatIntPtr(address), info))

  def do_do_desc(self, address):
    """
      Print a descriptor array in a readable format.
    """
    start = self.ParseAddressExpr(address)
    if ((start & 1) == 1): start = start - 1
    DescriptorArray(FixedArray(self.heap, None, start)).Print(Printer())

  def do_do_map(self, address):
    """
      Print a Map in a readable format.
    """
    start = self.ParseAddressExpr(address)
    if ((start & 1) == 1): start = start - 1
    Map(self.heap, None, start).Print(Printer())

  def do_do_trans(self, address):
    """
      Print a transition array in a readable format.
    """
    start = self.ParseAddressExpr(address)
    if ((start & 1) == 1): start = start - 1
    TransitionArray(FixedArray(self.heap, None, start)).Print(Printer())

  def do_dp(self, address):
    """ see display_page """
    return self.do_display_page(address)

  def do_display_page(self, address):
    """
     Prints details about the V8 heap page of the given address.

     Interpret memory at the given address as being on a V8 heap page
     and print information about the page header (if available).
    """
    address = self.ParseAddressExpr(address)
    page_address = address & ~self.heap.PageAlignmentMask()
    if self.reader.IsValidAddress(page_address):
      print("**** Not Implemented")
      return
    else:
      print("Page header is not available!")

  def do_k(self, arguments):
    """
     Teach V8 heap layout information to the inspector.

     This increases the amount of annotations the inspector can produce while
     dumping data. The first page of each heap space is of particular interest
     because it contains known objects that do not move.
    """
    self.padawan.PrintKnowledge()

  def do_ko(self, address):
    """ see known_oldspace """
    return self.do_known_oldspace(address)

  def do_known_oldspace(self, address):
    """
     Teach V8 heap layout information to the inspector.

     Set the first old space page by passing any pointer into that page.
    """
    address = self.ParseAddressExpr(address)
    page_address = address & ~self.heap.PageAlignmentMask()
    self.padawan.known_first_old_page = page_address

  def do_km(self, address):
    """ see known_map """
    return self.do_known_map(address)

  def do_known_map(self, address):
    """
     Teach V8 heap layout information to the inspector.

     Set the first map-space page by passing any pointer into that page.
    """
    address = self.ParseAddressExpr(address)
    page_address = address & ~self.heap.PageAlignmentMask()
    self.padawan.known_first_map_page = page_address

  def do_list(self, smth):
    """
     List all available memory regions.
    """
    def print_region(reader, start, size, location):
      print("  %s - %s (%d bytes)" % (reader.FormatIntPtr(start),
                                      reader.FormatIntPtr(start + size),
                                      size))
    print("Available memory regions:")
    self.reader.ForEachMemoryRegion(print_region)

  def do_lm(self, arg):
    """ see list_modules """
    return self.do_list_modules(arg)

  def do_list_modules(self, arg):
    """
     List details for all loaded modules in the minidump.

     An argument can be passed to limit the output to only those modules that
     contain the argument as a substring (case insensitive match).
    """
    for module in self.reader.module_list.modules:
      if arg:
        name = GetModuleName(self.reader, module).lower()
        if name.find(arg.lower()) >= 0:
          PrintModuleDetails(self.reader, module)
      else:
        PrintModuleDetails(self.reader, module)
    print()

  def do_s(self, word):
    """ see search """
    return self.do_search(word)

  def do_search(self, word):
    """
     Search for a given word in available memory regions.

     The given word is expanded to full pointer size and searched at aligned
     as well as un-aligned memory locations. Use 'sa' to search aligned locations
     only.
    """
    try:
      word = self.ParseAddressExpr(word)
    except ValueError:
      print("Malformed word, prefix with '0x' to use hexadecimal format.")
      return
    print(
      "Searching for word %d/0x%s:" % (word, self.reader.FormatIntPtr(word)))
    self.reader.FindWord(word)

  def do_sh(self, none):
    """
     Search for the V8 Heap object in all available memory regions.

     You might get lucky and find this rare treasure full of invaluable
     information.
    """
    print("**** Not Implemented")

  def do_u(self, args):
    """ see disassemble """
    return self.do_disassemble(args)

  def do_disassemble(self, args):
    """
     Unassemble memory in the region [address, address + size).

     If the size is not specified, a default value of 32 bytes is used.
     Synopsis: u 0x<address> 0x<size>
    """
    if len(args) != 0:
      args = args.split(' ')
      self.u_start = self.ParseAddressExpr(args[0])
      self.u_size = self.ParseAddressExpr(args[1]) if len(args) > 1 else 0x20
      skip = False
    else:
      # Skip the first instruction if we reuse the last address.
      skip = True

    if not self.reader.IsValidAddress(self.u_start):
      print("Address %s is not contained within the minidump!" % (
          self.reader.FormatIntPtr(self.u_start)))
      return
    lines = self.reader.GetDisasmLines(self.u_start, self.u_size)
    if len(lines) == 0:
      print("Address %s could not be disassembled!" % (
          self.reader.FormatIntPtr(self.u_start)))
      print("    Could not disassemble using %s." % OBJDUMP_BIN)
      print("    Pass path to architecture specific objdump via --objdump?")
      return
    for line in lines:
      if skip:
        skip = False
        continue
      print(FormatDisasmLine(self.u_start, self.heap, line))
    # Set the next start address = last line
    self.u_start += lines[-1][0]
    print()

  def do_EOF(self, none):
    raise KeyboardInterrupt

EIP_PROXIMITY = 64

CONTEXT_FOR_ARCH = {
    MD_CPU_ARCHITECTURE_AMD64:
      ['rax', 'rbx', 'rcx', 'rdx', 'rdi', 'rsi', 'rbp', 'rsp', 'rip',
       'r8', 'r9', 'r10', 'r11', 'r12', 'r13', 'r14', 'r15'],
    MD_CPU_ARCHITECTURE_ARM:
      ['r0', 'r1', 'r2', 'r3', 'r4', 'r5', 'r6', 'r7', 'r8', 'r9',
       'r10', 'r11', 'r12', 'sp', 'lr', 'pc'],
    MD_CPU_ARCHITECTURE_ARM64:
      ['r0', 'r1', 'r2', 'r3', 'r4', 'r5', 'r6', 'r7', 'r8', 'r9',
       'r10', 'r11', 'r12', 'r13', 'r14', 'r15', 'r16', 'r17', 'r18', 'r19',
       'r20', 'r21', 'r22', 'r23', 'r24', 'r25', 'r26', 'r27', 'r28',
       'fp', 'lr', 'sp', 'pc'],
    MD_CPU_ARCHITECTURE_X86:
      ['eax', 'ebx', 'ecx', 'edx', 'edi', 'esi', 'ebp', 'esp', 'eip']
}

KNOWN_MODULES = {'chrome.exe', 'chrome.dll'}

def GetVersionString(ms, ls):
  return "%d.%d.%d.%d" % (ms >> 16, ms & 0xffff, ls >> 16, ls & 0xffff)


def GetModuleName(reader, module):
  name = reader.ReadMinidumpString(module.module_name_rva)
  # simplify for path manipulation
  name = name.encode('utf-8')
  return str(os.path.basename(str(name).replace("\\", "/")))


def PrintModuleDetails(reader, module):
  print("%s" % GetModuleName(reader, module))
  file_version = GetVersionString(module.version_info.dwFileVersionMS,
                                  module.version_info.dwFileVersionLS);
  product_version = GetVersionString(module.version_info.dwProductVersionMS,
                                     module.version_info.dwProductVersionLS)
  print("  base: %s" % reader.FormatIntPtr(module.base_of_image))
  print("  end: %s" % reader.FormatIntPtr(module.base_of_image +
                                          module.size_of_image))
  print("  file version: %s" % file_version)
  print("  product version: %s" % product_version)
  time_date_stamp = datetime.datetime.fromtimestamp(module.time_date_stamp)
  print("  timestamp: %s" % time_date_stamp)


def AnalyzeMinidump(options, minidump_name):
  reader = MinidumpReader(options, minidump_name)
  # Use a separate function to prevent leaking the minidump buffer through
  # ctypes in local variables.
  _AnalyzeMinidump(options, reader)
  reader.Dispose()


def _AnalyzeMinidump(options, reader):
  heap = None

  stack_top = reader.ExceptionSP()
  stack_bottom = reader.StackBottom()
  stack_map = {reader.ExceptionIP(): -1}
  for slot in range(stack_top, stack_bottom, reader.MachinePointerSize()):
    maybe_address = reader.ReadUIntPtr(slot)
    if not maybe_address in stack_map:
      stack_map[maybe_address] = slot

  heap = V8Heap(reader, stack_map)
  padawan = InspectionPadawan(reader, heap)

  DebugPrint("========================================")
  if reader.exception is None:
    print("Minidump has no exception info")
  else:
    print("Address markers:")
    print("  T = valid tagged pointer in the minidump")
    print("  S = address on the exception stack")
    print("  C = address in loaded C/C++ module")
    print("  * = address in the minidump")
    print("")
    print("Exception info:")
    exception_thread = reader.ExceptionThread()
    print("  thread id: %d" % exception_thread.id)
    print("  code:      %08X" % reader.exception.exception.code)
    print("  context:")
    context = CONTEXT_FOR_ARCH[reader.arch]
    maxWidth = max(map(lambda s: len(s), context))
    for r in context:
      register_value = reader.Register(r)
      print("    %s: %s" % (r.rjust(maxWidth),
                            heap.FormatIntPtr(register_value)))
    # TODO(vitalyr): decode eflags.
    if reader.arch in [MD_CPU_ARCHITECTURE_ARM, MD_CPU_ARCHITECTURE_ARM64]:
      print("    cpsr: %s" % bin(reader.exception_context.cpsr)[2:])
    else:
      print("    eflags: %s" % bin(reader.exception_context.eflags)[2:])

    print()
    print("  modules:")
    for module in reader.module_list.modules:
      name = GetModuleName(reader, module)
      if name in KNOWN_MODULES:
        print("    %s at %08X" % (name, module.base_of_image))
        reader.TryLoadSymbolsFor(name, module)
    print()

    print("  stack-top:    %s" % heap.FormatIntPtr(reader.StackTop()))
    print("  stack-bottom: %s" % heap.FormatIntPtr(reader.StackBottom()))
    print("")

    if options.shell:
      padawan.PrintStackTraceMessage(print_message=False)

    print("Disassembly around exception.eip:")
    eip_symbol = reader.FindSymbol(reader.ExceptionIP())
    if eip_symbol is not None:
      print(eip_symbol)
    disasm_start = reader.ExceptionIP() - EIP_PROXIMITY
    disasm_bytes = 2 * EIP_PROXIMITY
    if (options.full):
      full_range = reader.FindRegion(reader.ExceptionIP())
      if full_range is not None:
        disasm_start = full_range[0]
        disasm_bytes = full_range[1]

    lines = reader.GetDisasmLines(disasm_start, disasm_bytes)

    if not lines:
      print("Could not disassemble using %s." % OBJDUMP_BIN)
      print("Pass path to architecture specific objdump via --objdump?")

    for line in lines:
      print(FormatDisasmLine(disasm_start, heap, line))
    print()

  if heap is None:
    heap = V8Heap(reader, None)

  if options.full:
    FullDump(reader, heap)

  if options.command:
    InspectionShell(reader, heap).onecmd(options.command)

  if options.shell:
    try:
      InspectionShell(reader, heap).cmdloop("type help to get help")
    except KeyboardInterrupt:
      print("Kthxbye.")
  elif not options.command:
    if reader.exception is not None:
      print("Annotated stack (from exception.esp to bottom):")
      stack_start = padawan.PrintStackTraceMessage()
      padawan.InterpretMemory(stack_start, stack_bottom)


if __name__ == "__main__":
  parser = optparse.OptionParser(USAGE)
  parser.add_option("-s", "--shell", dest="shell", action="store_true",
                    help="start an interactive inspector shell")
  parser.add_option("-w", "--web", dest="web", action="store_true",
                    help="start a web server on localhost:%i" % PORT_NUMBER)
  parser.add_option("-c", "--command", dest="command", default="",
                    help="run an interactive inspector shell command and exit")
  parser.add_option("-f", "--full", dest="full", action="store_true",
                    help="dump all information contained in the minidump")
  parser.add_option("--symdir", dest="symdir", default=".",
                    help="directory containing *.pdb.sym file with symbols")
  parser.add_option("--objdump", default="",
                    help="objdump tool to use [default: %s]" % (
                        DEFAULT_OBJDUMP_BIN))
  options, args = parser.parse_args()
  if len(args) != 1:
    parser.print_help()
    sys.exit(1)
  if options.web:
    try:
      server = InspectionWebServer(PORT_NUMBER, options, args[0])
      print('Started httpserver on port ' , PORT_NUMBER)
      webbrowser.open('http://localhost:%i/summary.html' % PORT_NUMBER)
      server.serve_forever()
    except KeyboardInterrupt:
      print('^C received, shutting down the web server')
      server.socket.close()
  else:
    AnalyzeMinidump(options, args[0])
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   node-23.7.0/deps/v8/tools/heap-layout/                                                              0000775 0000000 0000000 00000000000 14746647661 0017435 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/heap-layout/heap-layout-viewer-template.html                              0000664 0000000 0000000 00000000541 14746647661 0025663 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        <!-- Copyright 2021 the V8 project authors. All rights reserved.
Use of this source code is governed by a BSD-style license that can be
found in the LICENSE file. -->

<style>
    #chart {
        width: 100%;
        height: 600px;
    }
</style>
<div id="container" style="display: none;">
    <h2>V8 Heap Layout</h2>
    <div id="chart"></div>
</div>                                                                                                                                                               node-23.7.0/deps/v8/tools/heap-layout/heap-layout-viewer.mjs                                        0000664 0000000 0000000 00000013264 14746647661 0023705 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2021 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

import {GB, MB} from '../js/helper.mjs';
import {DOM} from '../js/web-api-helper.mjs';

import {getColorFromSpaceName, kSpaceNames} from './space-categories.mjs';

DOM.defineCustomElement('heap-layout-viewer',
                        (templateText) =>
                            class HeapLayoutViewer extends HTMLElement {
  constructor() {
    super();
    const shadowRoot = this.attachShadow({mode: 'open'});
    shadowRoot.innerHTML = templateText;
    this.chart = echarts.init(this.$('#chart'), null, {
      renderer: 'canvas',
    });
    window.addEventListener('resize', () => {
      this.chart.resize();
    });
    this.currentIndex = 0;
  }

  $(id) {
    return this.shadowRoot.querySelector(id);
  }

  set data(value) {
    this._data = value;
    this.stateChanged();
  }

  get data() {
    return this._data;
  }

  hide() {
    this.$('#container').style.display = 'none';
  }

  show() {
    this.$('#container').style.display = 'block';
  }

  stateChanged() {
    this.drawChart(0);
  }

  getChartTitle(index) {
    return this.data[index].header;
  }

  getSeriesData(pageinfos) {
    let ret = [];
    for (let pageinfo of pageinfos) {
      ret.push({value: pageinfo});
    }
    return ret;
  }

  getChartSeries(index) {
    const snapshot = this.data[index];
    let series = [];
    for (const [space_name, pageinfos] of Object.entries(snapshot.data)) {
      let space_series = {
        name: space_name,
        type: 'custom',
        renderItem(params, api) {
          const addressBegin = api.value(1);
          const addressEnd = api.value(2);
          const allocated = api.value(3);
          const start = api.coord([addressBegin, 0]);
          const end = api.coord([addressEnd, 0]);

          const allocatedRate = allocated / (addressEnd - addressBegin);
          const unAllocatedRate = 1 - allocatedRate;

          const standardH = api.size([0, 1])[1];
          const standardY = start[1] - standardH / 2;

          const allocatedY = standardY + standardH * unAllocatedRate;
          const allocatedH = standardH * allocatedRate;

          const unAllocatedY = standardY;
          const unAllocatedH = standardH - allocatedH;

          const allocatedShape = echarts.graphic.clipRectByRect(
              {
                x: start[0],
                y: allocatedY,
                width: end[0] - start[0],
                height: allocatedH,
              },
              {
                x: params.coordSys.x,
                y: params.coordSys.y,
                width: params.coordSys.width,
                height: params.coordSys.height,
              });

          const unAllocatedShape = echarts.graphic.clipRectByRect(
              {
                x: start[0],
                y: unAllocatedY,
                width: end[0] - start[0],
                height: unAllocatedH,
              },
              {
                x: params.coordSys.x,
                y: params.coordSys.y,
                width: params.coordSys.width,
                height: params.coordSys.height,
              });

          const ret = {
            type: 'group',
            children: [
              {
                type: 'rect',
                shape: allocatedShape,
                style: api.style(),
              },
              {
                type: 'rect',
                shape: unAllocatedShape,
                style: {
                  fill: '#000000',
                },
              },
            ],
          };
          return ret;
        },
        data: this.getSeriesData(pageinfos),
        encode: {
          x: [1, 2],
        },
        itemStyle: {
          color: getColorFromSpaceName(space_name),
        },
      };
      series.push(space_series);
    }
    return series;
  }

  drawChart(index) {
    if (index >= this.data.length || index < 0) {
      console.error('Invalid index:', index);
      return;
    }
    const option = {
      tooltip: {
        formatter(params) {
          const ret = params.marker + params.value[0] + '<br>' +
              'address:' + (params.value[1] / MB).toFixed(3) + 'MB' +
              '<br>' +
              'size:' + ((params.value[2] - params.value[1]) / MB).toFixed(3) +
              'MB' +
              '<br>' +
              'allocated:' + (params.value[3] / MB).toFixed(3) + 'MB' +
              '<br>' +
              'wasted:' + params.value[4] + 'B';
          return ret;
        },
      },
      grid: {
        bottom: 120,
        top: 120,
      },
      dataZoom: [
        {
          type: 'slider',
          filterMode: 'weakFilter',
          showDataShadow: true,
          labelFormatter: '',
        },
        {
          type: 'inside',
          filterMode: 'weakFilter',
        },
      ],
      legend: {
        show: true,
        data: kSpaceNames,
        top: '6%',
        type: 'scroll',
      },
      title: {
        text: this.getChartTitle(index),
        left: 'center',
      },
      xAxis: {
        name: 'Address offset in heap(MB)',
        nameLocation: 'center',
        nameTextStyle: {
          fontSize: 25,
          padding: [30, 0, 50, 0],
        },
        type: 'value',
        min: 0,
        max: 4 * GB,
        axisLabel: {
          rotate: 0,
          formatter(value, index) {
            value = value / MB;
            value = value.toFixed(3);
            return value;
          },
        },
      },
      yAxis: {
        data: ['Page'],
      },
      series: this.getChartSeries(index),
    };

    this.show();
    this.chart.resize();
    this.chart.setOption(option);
    this.currentIndex = index;
  }
});
                                                                                                                                                                                                                                                                                                                                            node-23.7.0/deps/v8/tools/heap-layout/heap-size-trend-viewer-template.html                          0000664 0000000 0000000 00000000553 14746647661 0026435 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        <!-- Copyright 2021 the V8 project authors. All rights reserved.
Use of this source code is governed by a BSD-style license that can be
found in the LICENSE file. -->

<style>
    #chart {
        width: 100%;
        height: 400px;
    }
</style>
<div id="container" style="display: none;">
    <h2>V8 Heap Space Size Trend</h2>
    <div id="chart"></div>
</div>                                                                                                                                                     node-23.7.0/deps/v8/tools/heap-layout/heap-size-trend-viewer.mjs                                    0000664 0000000 0000000 00000016202 14746647661 0024447 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2021 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

import {MB} from '../js/helper.mjs';
import {DOM} from '../js/web-api-helper.mjs';

import {getColorFromSpaceName, kSpaceNames} from './space-categories.mjs';

class TrendLineHelper {
  static re_gc_count = /(?<=(Before|After) GC:)\d+(?=,)/;
  static re_allocated = /allocated/;
  static re_space_name = /^[a-z_]+_space/;

  static snapshotHeaderToXLabel(header) {
    const gc_count = this.re_gc_count.exec(header)[0];
    const alpha = header[0];
    return alpha + gc_count;
  }

  static getLineSymbolFromTrendLineName(trend_line_name) {
    const is_allocated_line = this.re_allocated.test(trend_line_name);
    if (is_allocated_line) {
      return 'emptyTriangle';
    }
    return 'emptyCircle';
  }

  static getSizeTrendLineName(space_name) {
    return space_name + ' size';
  }

  static getAllocatedTrendSizeName(space_name) {
    return space_name + ' allocated';
  }

  static getSpaceNameFromTrendLineName(trend_line_name) {
    const space_name = this.re_space_name.exec(trend_line_name)[0];
    return space_name;
  }
}

DOM.defineCustomElement('heap-size-trend-viewer',
                        (templateText) =>
                            class HeapSizeTrendViewer extends HTMLElement {
  constructor() {
    super();
    const shadowRoot = this.attachShadow({mode: 'open'});
    shadowRoot.innerHTML = templateText;
    this.chart = echarts.init(this.$('#chart'), null, {
      renderer: 'canvas',
    });
    this.chart.getZr().on('click', 'series.line', (params) => {
      const pointInPixel = [params.offsetX, params.offsetY];
      const pointInGrid =
          this.chart.convertFromPixel({seriesIndex: 0}, pointInPixel);
      const xIndex = pointInGrid[0];
      this.dispatchEvent(new CustomEvent('change', {
        bubbles: true,
        composed: true,
        detail: xIndex,
      }));
      this.setXMarkLine(xIndex);
    });
    this.chartXAxisData = null;
    this.chartSeriesData = null;
    this.currentIndex = 0;
    window.addEventListener('resize', () => {
      this.chart.resize();
    });
  }

  $(id) {
    return this.shadowRoot.querySelector(id);
  }

  set data(value) {
    this._data = value;
    this.stateChanged();
  }

  get data() {
    return this._data;
  }

  hide() {
    this.$('#container').style.display = 'none';
  }

  show() {
    this.$('#container').style.display = 'block';
  }

  stateChanged() {
    this.initTrendLineNames();
    this.initXAxisDataAndSeries();
    this.drawChart();
  }

  initTrendLineNames() {
    this.trend_line_names = [];
    for (const space_name of kSpaceNames) {
      this.trend_line_names.push(
          TrendLineHelper.getSizeTrendLineName(space_name));
      this.trend_line_names.push(
          TrendLineHelper.getAllocatedTrendSizeName(space_name));
    }
  }

  // X axis represent the moment before or after nth GC : [B1,A1,...Bn,An].
  initXAxisDataAndSeries() {
    this.chartXAxisData = [];
    this.chartSeriesData = [];
    let trend_line_name_data_dict = {};

    for (const trend_line_name of this.trend_line_names) {
      trend_line_name_data_dict[trend_line_name] = [];
    }

    // Init x axis data and trend line series.
    for (const snapshot of this.data) {
      this.chartXAxisData.push(
          TrendLineHelper.snapshotHeaderToXLabel(snapshot.header));
      for (const [space_name, pageinfos] of Object.entries(snapshot.data)) {
        const size_trend_line_name =
            TrendLineHelper.getSizeTrendLineName(space_name);
        const allocated_trend_line_name =
            TrendLineHelper.getAllocatedTrendSizeName(space_name);
        let size_sum = 0;
        let allocated_sum = 0;
        for (const pageinfo of pageinfos) {
          size_sum += pageinfo[2] - pageinfo[1];
          allocated_sum += pageinfo[3];
        }
        trend_line_name_data_dict[size_trend_line_name].push(size_sum);
        trend_line_name_data_dict[allocated_trend_line_name].push(
            allocated_sum);
      }
    }

    // Init mark line series as the first series
    const markline_series = {
      name: 'mark-line',
      type: 'line',

      markLine: {
        silent: true,
        symbol: 'none',
        label: {
          show: false,
        },
        lineStyle: {
          color: '#333',
        },
        data: [
          {
            xAxis: 0,
          },
        ],
      },
    };
    this.chartSeriesData.push(markline_series);

    for (const [trend_line_name, trend_line_data] of Object.entries(
             trend_line_name_data_dict)) {
      const color = getColorFromSpaceName(
          TrendLineHelper.getSpaceNameFromTrendLineName(trend_line_name));
      const trend_line_series = {
        name: trend_line_name,
        type: 'line',
        data: trend_line_data,
        lineStyle: {
          color: color,
        },
        itemStyle: {
          color: color,
        },
        symbol: TrendLineHelper.getLineSymbolFromTrendLineName(trend_line_name),
        symbolSize: 8,
      };
      this.chartSeriesData.push(trend_line_series);
    }
  }

  setXMarkLine(index) {
    if (index < 0 || index >= this.data.length) {
      console.error('Invalid index:', index);
      return;
    }
    // Set the mark-line series
    this.chartSeriesData[0].markLine.data[0].xAxis = index;
    this.chart.setOption({
      series: this.chartSeriesData,
    });
    this.currentIndex = index;
  }

  drawChart() {
    const option = {
      dataZoom: [
        {
          type: 'inside',
          filterMode: 'weakFilter',
        },
        {
          type: 'slider',
          filterMode: 'weakFilter',
          labelFormatter: '',
        },
      ],
      title: {
        text: 'Size Trend',
        left: 'center',
      },
      tooltip: {
        trigger: 'axis',
        position(point, params, dom, rect, size) {
          let ret_x = point[0] + 10;
          if (point[0] > size.viewSize[0] * 0.7) {
            ret_x = point[0] - dom.clientWidth - 10;
          }
          return [ret_x, '85%'];
        },
        formatter(params) {
          const colorSpan = (color) =>
              '<span style="display:inline-block;margin-right:1px;border-radius:5px;width:9px;height:9px;background-color:' +
              color + '"></span>';
          let result = '<p>' + params[0].axisValue + '</p>';
          params.forEach((item) => {
            const xx = '<p style="margin:0;">' + colorSpan(item.color) + ' ' +
                item.seriesName + ': ' + (item.data / MB).toFixed(2) + 'MB' +
                '</p>';
            result += xx;
          });

          return result;
        },
      },
      legend: {
        data: this.trend_line_names,
        top: '6%',
        type: 'scroll',
      },

      xAxis: {
        minInterval: 1,
        type: 'category',
        boundaryGap: false,
        data: this.chartXAxisData,
      },
      yAxis: {
        type: 'value',
        axisLabel: {
          formatter(value, index) {
            return (value / MB).toFixed(3) + 'MB';
          },
        },
      },

      series: this.chartSeriesData,
    };
    this.show();
    this.chart.resize();
    this.chart.setOption(option);
  }
});
                                                                                                                                                                                                                                                                                                                                                                                              node-23.7.0/deps/v8/tools/heap-layout/index.css                                                     0000664 0000000 0000000 00000000617 14746647661 0021262 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        :root {
  --surface-color: #ffffff;
  --primary-color: #bb86fc;
  --on-primary-color: #000000;
  --error-color: #cf6679;
  --file-reader-background-color: #ffffff80;
  --file-reader-border-color: #000000;
}

body {
  font-family: "Roboto", sans-serif;
  margin-left: 5%;
  margin-right: 5%;
}

.button-container {
  text-align: center;
  display: none;
}

button {
  height: 50px;
  width: 100px;
}
                                                                                                                 node-23.7.0/deps/v8/tools/heap-layout/index.html                                                    0000664 0000000 0000000 00000004727 14746647661 0021444 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        <!DOCTYPE html>
<!-- Copyright 2021 the V8 project authors. All rights reserved.
Use of this source code is governed by a BSD-style license that can be
found in the LICENSE file. -->
<html lang="en">
<head>
  <!-- This will be overwritten by the v8.dev/tools exporter -->
<!-- ANALYTICS_PLACEHOLDER -->
  <meta charset="UTF-8">
  <title>V8 Heap Layout</title>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/echarts/5.2.2/echarts.min.js"></script>

  <script type="module" src="heap-layout-viewer.mjs"></script>
  <script type="module" src="heap-size-trend-viewer.mjs"></script>
  <script type="module" src="trace-file-reader.mjs"></script>

  <link rel="stylesheet" type="text/css" href="./index.css">

  <script>
    'use strict';
    function $(id) { return document.querySelector(id); }

    function globalDataChanged(e) {
      $('#heap-layout-viewer').data = e.detail;
      $('#heap-size-trend-viewer').data = e.detail;
      $('.button-container').style.display = 'block';
    }

    function selectSnapshotAtIndex(e) {
      const index = e.detail;
      $('#heap-layout-viewer').drawChart(index);
    }


    function OnPrevClick() {
      const heap_size_trend_viewer = $('#heap-size-trend-viewer');
      const heap_layout_viewer = $('#heap-layout-viewer');
      heap_size_trend_viewer.setXMarkLine(heap_size_trend_viewer.currentIndex - 1);
      heap_layout_viewer.drawChart(heap_layout_viewer.currentIndex - 1);
    }

    function OnNextClick() {
      const heap_size_trend_viewer = $('#heap-size-trend-viewer');
      const heap_layout_viewer = $('#heap-layout-viewer');
      heap_size_trend_viewer.setXMarkLine(heap_size_trend_viewer.currentIndex + 1);
      heap_layout_viewer.drawChart(heap_layout_viewer.currentIndex + 1);
    }

  </script>
</head>

<body>
  <h1>V8 Heap Layout</h1>
  <trace-file-reader onchange="globalDataChanged(event)"></trace-file-reader>
  <heap-size-trend-viewer id="heap-size-trend-viewer" onchange="selectSnapshotAtIndex(event)"></heap-size-trend-viewer>
  <heap-layout-viewer id="heap-layout-viewer"></heap-layout-viewer>
  <div class="button-container">
    <button id="button_prev" type="button" onclick="OnPrevClick()">Prev</button>
    <button id="button_next" type="button" onclick="OnNextClick()">Next</button>
  </div>

  <p>Heap layout is a HTML-based tool for visualizing V8-internal heap layout.</p>
  <p>Visualize heap layout that have been gathered using</p>
  <ul>
    <li><code>--trace-gc-heap-layout</code> on V8</li>

  </ul>

</body>

</html>
                                         node-23.7.0/deps/v8/tools/heap-layout/space-categories.mjs                                          0000664 0000000 0000000 00000001211 14746647661 0023361 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2021 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

export const kSpaceNames = [
  'to_space',
  'from_space',
  'old_space',
  'map_space',
  'code_space',
  'large_object_space',
  'new_large_object_space',
  'code_large_object_space',
  'ro_space',
];

const kSpaceColors = [
  '#5b8ff9',
  '#5ad8a6',
  '#5d7092',
  '#f6bd16',
  '#e8684a',
  '#6dc8ec',
  '#9270ca',
  '#ff9d4d',
  '#269a99',
];

export function getColorFromSpaceName(space_name) {
  const index = kSpaceNames.indexOf(space_name);
  return kSpaceColors[index];
}
                                                                                                                                                                                                                                                                                                                                                                                       node-23.7.0/deps/v8/tools/heap-layout/trace-file-reader.mjs                                         0000664 0000000 0000000 00000006340 14746647661 0023426 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2021 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

import {calcOffsetInVMCage} from '../js/helper.mjs';
import {DOM, FileReader,} from '../js/web-api-helper.mjs';

import {kSpaceNames} from './space-categories.mjs';

class TraceLogParseHelper {
  static re_gc_header = /(Before|After) GC:\d/;
  static re_page_info =
      /\{owner:.+,address:.+,size:.+,allocated_bytes:.+,wasted_memory:.+\}/;
  static re_owner = /(?<=owner:)[a-z_]+_space/;
  static re_address = /(?<=address:)0x[a-f0-9]+(?=,)/;
  static re_size = /(?<=size:)\d+(?=,)/;
  static re_allocated_bytes = /(?<=allocated_bytes:)\d+(?=,)/;
  static re_wasted_memory = /(?<=wasted_memory:)\d+(?=})/;

  static matchGCHeader(content) {
    return this.re_gc_header.test(content);
  }

  static matchPageInfo(content) {
    return this.re_page_info.test(content);
  }

  static parsePageInfo(content) {
    const owner = this.re_owner.exec(content)[0];
    const address =
        calcOffsetInVMCage(BigInt(this.re_address.exec(content)[0], 16));
    const size = parseInt(this.re_size.exec(content)[0]);
    const allocated_bytes = parseInt(this.re_allocated_bytes.exec(content)[0]);
    const wasted_memory = parseInt(this.re_wasted_memory.exec(content)[0]);
    const info = [
      owner,
      address,
      address + size,
      allocated_bytes,
      wasted_memory,
    ];
    return info;
  }

  // Create a empty snapshot.
  static createSnapShotData() {
    let snapshot = {header: null, data: {}};
    for (let space_name of kSpaceNames) {
      snapshot.data[space_name] = [];
    }
    return snapshot;
  }

  static createModelFromV8TraceFile(contents) {
    let snapshots = [];
    let snapshot = this.createSnapShotData();

    // Fill data info a snapshot, then push it into snapshots.
    for (let content of contents) {
      if (this.matchGCHeader(content)) {
        if (snapshot.header != null) {
          snapshots.push(snapshot);
        }
        snapshot = this.createSnapShotData();
        snapshot.header = content;
        continue;
      }

      if (this.matchPageInfo(content)) {
        let pageinfo = this.parsePageInfo(content);
        try {
          snapshot.data[pageinfo[0]].push(pageinfo);
        } catch (e) {
          console.error(e);
        }
      }
    }
    // EOL, push the last.
    if (snapshot.header != null) {
      snapshots.push(snapshot);
    }
    return snapshots;
  }
}

DOM.defineCustomElement('../js/log-file-reader', 'trace-file-reader',
                        (templateText) =>
                            class TraceFileReader extends FileReader {
  constructor() {
    super(templateText);
    this.fullDataFromFile = '';
    this.addEventListener('fileuploadchunk', (e) => this.handleLoadChunk(e));

    this.addEventListener('fileuploadend', (e) => this.handleLoadEnd(e));
  }

  handleLoadChunk(event) {
    this.fullDataFromFile += event.detail;
  }

  handleLoadEnd(event) {
    let contents = this.fullDataFromFile.split('\n');
    let snapshots = TraceLogParseHelper.createModelFromV8TraceFile(contents);
    this.dispatchEvent(new CustomEvent('change', {
      bubbles: true,
      composed: true,
      detail: snapshots,
    }));
  }
});
                                                                                                                                                                                                                                                                                                node-23.7.0/deps/v8/tools/heap-snapshot-processor.py                                                0000664 0000000 0000000 00000007131 14746647661 0022350 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/python3
# Copyright 2023 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

import json
import sys


# Implement this to process the data.
def process_nodes(nodes):
  pass


class Node:

  def __init__(self, id, type, name):
    self.id = id

    assert isinstance(type, str)
    self.type = type

    assert isinstance(name, str)
    self.name = name

    self.edges_from = []
    self.edges_to = []


class Edge:

  def __init__(self, type, from_node, name, to_node):
    assert isinstance(type, str)
    self.type = type

    assert isinstance(from_node, Node)
    self.from_node = from_node

    assert isinstance(name, str)
    self.name = name

    assert isinstance(to_node, Node)
    self.to_node = to_node


def main():
  if len(sys.argv) != 2:
    print("Usage: python3 heap-snapshot-processor.py snapshot.heapsnapshot")
    exit(1)

  f = open(sys.argv[1])
  data = json.load(f)

  # Documentation of the format (caveat: documentation for name_or_index is
  # wrong):
  # https://learn.microsoft.com/en-us/microsoft-edge/devtools-guide-chromium/memory-problems/heap-snapshot-schema
  snapshot = data['snapshot']
  meta = snapshot['meta']

  node_fields = meta['node_fields']
  node_field_count = len(node_fields)
  node_type_ix = node_fields.index('type')
  node_name_ix = node_fields.index('name')
  node_id_ix = node_fields.index('id')
  node_edge_count_ix = node_fields.index('edge_count')

  node_types = meta['node_types']
  node_type_strings = node_types[node_type_ix]

  edge_fields = meta['edge_fields']
  edge_field_count = len(edge_fields)
  edge_type_ix = edge_fields.index('type')
  edge_name_or_index_ix = edge_fields.index('name_or_index')
  edge_to_node_ix = edge_fields.index('to_node')

  edge_types = meta['edge_types']
  edge_type_strings = edge_types[edge_type_ix]

  nodes = data['nodes']
  edges = data['edges']
  strings = data['strings']

  node_objects = dict()

  for node_ix in range(0, len(nodes), node_field_count):
    node_data = nodes[node_ix:(node_ix + node_field_count)]
    node_type = node_type_strings[node_data[node_type_ix]]
    node_name = strings[node_data[node_name_ix]]
    node_id = node_data[node_id_ix]
    node = Node(node_id, node_type, node_name)
    node_objects[node_id] = node

  edge_ix = 0
  for node_ix in range(0, len(nodes), node_field_count):
    node_data = nodes[node_ix:(node_ix + node_field_count)]
    edge_count = node_data[node_edge_count_ix]
    from_node_id = node_data[node_id_ix]
    from_node = node_objects[from_node_id]

    for e in range(edge_count):
      edge_data = edges[edge_ix:(edge_ix + edge_field_count)]
      edge_type = edge_type_strings[edge_data[edge_type_ix]]

      # The interpretation of edge_name_or_index depends on the edge type.
      edge_name_or_index = edge_data[edge_name_or_index_ix]
      if edge_type == 'element' or edge_type == 'hidden':
        edge_name = str(edge_name_or_index)
      elif isinstance(edge_name_or_index, str):
        edge_name = edge_name_or_index
      else:
        edge_name = strings[edge_name_or_index]

      # "The index within the nodes array that this edge is connected to."
      to_node_ix = edge_data[edge_to_node_ix]
      to_node_data = nodes[to_node_ix:(to_node_ix + node_field_count)]
      to_node_id = to_node_data[node_id_ix]

      to_node = node_objects[to_node_id]

      edge = Edge(edge_type, from_node, edge_name, to_node)

      from_node.edges_from.append(edge)
      to_node.edges_to.append(edge)

      edge_ix += edge_field_count

  process_nodes(node_objects)


if __name__ == '__main__':
  main()
                                                                                                                                                                                                                                                                                                                                                                                                                                       node-23.7.0/deps/v8/tools/heap-stats/                                                               0000775 0000000 0000000 00000000000 14746647661 0017256 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/heap-stats/README.md                                                      0000664 0000000 0000000 00000001063 14746647661 0020535 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # Heap Stats

Heap stats is a HTML-based tool for visualizing V8-internal object statistics.
For example, the tool can be used to visualize how much heap memory is used for
maintaining internal state versus actually allocated by the user.

The tool consumes log files produced by d8 (or Chromium) by passing
`--trace-gc-object-stats` or a trace captured using Chrome's tracing
infrastructure. Chrome trace files can either be processed as gzip or raw text
files.


Hosting requires a web server, e.g.:

    cd tools/heap-stats
    python -m SimpleHTTPServer 8000
                                                                                                                                                                                                                                                                                                                                                                                                                                                                             node-23.7.0/deps/v8/tools/heap-stats/categories.js                                                  0000664 0000000 0000000 00000015541 14746647661 0021747 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2018 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

// Categories for instance types.
export const CATEGORIES = new Map([
  [
    'user', new Set([
      'CONS_ONE_BYTE_STRING_TYPE',
      'CONS_TWO_BYTE_STRING_TYPE',
      'DESCRIPTOR_ARRAY_TYPE',
      'ELEMENTS_TYPE',
      'EXTERNAL_INTERNALIZED_TWO_BYTE_STRING_TYPE',
      'EXTERNAL_INTERNALIZED_ONE_BYTE_STRING_TYPE',
      'EXTERNAL_ONE_BYTE_STRING_TYPE',
      'EXTERNAL_TWO_BYTE_STRING_TYPE',
      'EXTERNAL_STRING_WITH_ONE_BYTE_DATA_TYPE',
      'FIXED_BIGINT64_ARRAY_TYPE',
      'FIXED_BIGUINT64_ARRAY_TYPE',
      'FIXED_DOUBLE_ARRAY_TYPE',
      'FIXED_FLOAT32_ARRAY_TYPE',
      'FIXED_FLOAT64_ARRAY_TYPE',
      'FIXED_INT16_ARRAY_TYPE',
      'FIXED_INT32_ARRAY_TYPE',
      'FIXED_INT8_ARRAY_TYPE',
      'FIXED_UINT16_ARRAY_TYPE',
      'FIXED_UINT32_ARRAY_TYPE',
      'FIXED_UINT8_ARRAY_TYPE',
      'FIXED_UINT8_CLAMPED_ARRAY_TYPE',
      'FUNCTION_CONTEXT_TYPE',
      'GLOBAL_ELEMENTS_TYPE',
      'GLOBAL_PROPERTIES_TYPE',
      'HEAP_NUMBER_TYPE',
      'INTERNALIZED_TWO_BYTE_STRING_TYPE',
      'JS_ARGUMENTS_OBJECT_TYPE',
      'JS_ARRAY_BUFFER_TYPE',
      'JS_ARRAY_ITERATOR_TYPE',
      'JS_ARRAY_TYPE',
      'JS_BOUND_FUNCTION_TYPE',
      'JS_DATE_TYPE',
      'JS_ERROR_TYPE',
      'JS_FAST_ARRAY_KEY_ITERATOR_TYPE',
      'JS_FAST_ARRAY_VALUE_ITERATOR_TYPE',
      'JS_FAST_HOLEY_ARRAY_VALUE_ITERATOR_TYPE',
      'JS_FAST_HOLEY_SMI_ARRAY_VALUE_ITERATOR_TYPE',
      'JS_FAST_SMI_ARRAY_KEY_VALUE_ITERATOR_TYPE',
      'JS_FAST_SMI_ARRAY_VALUE_ITERATOR_TYPE',
      'JS_FUNCTION_TYPE',
      'JS_GENERATOR_OBJECT_TYPE',
      'JS_GENERIC_ARRAY_VALUE_ITERATOR_TYPE',
      'JS_GLOBAL_OBJECT_TYPE',
      'JS_GLOBAL_PROXY_TYPE',
      'JS_COLLATOR_TYPE',
      'JS_DATE_TIME_FORMAT_TYPE',
      'JS_DISPLAY_NAMES_TYPE',
      'JS_DURATION_FORMAT_TYPE',
      'JS_LIST_FORMAT_TYPE',
      'JS_LOCALE_TYPE',
      'JS_NUMBER_FORMAT_TYPE',
      'JS_PLURAL_RULES_TYPE',
      'JS_RELATIVE_TIME_FORMAT_TYPE',
      'JS_SEGMENT_ITERATOR_TYPE',
      'JS_SEGMENTER_TYPE',
      'JS_SEGMENTS_TYPE',
      'JS_V8_BREAK_ITERATOR_TYPE',
      'JS_MAP_KEY_ITERATOR_TYPE',
      'JS_MAP_KEY_VALUE_ITERATOR_TYPE',
      'JS_MAP_TYPE',
      'JS_MAP_VALUE_ITERATOR_TYPE',
      'JS_MESSAGE_OBJECT_TYPE',
      'JS_OBJECT_TYPE',
      'JS_PRIMITIVE_WRAPPER_TYPE',
      'JS_PROMISE_TYPE',
      'JS_PROXY_TYPE',
      'JS_REG_EXP_TYPE',
      'JS_SET_KEY_VALUE_ITERATOR_TYPE',
      'JS_SET_TYPE',
      'JS_SET_VALUE_ITERATOR_TYPE',
      'JS_STRING_ITERATOR_TYPE',
      'JS_TO_WASM_FUNCTION',
      'JS_TYPED_ARRAY_TYPE',
      'JS_WEAK_MAP_TYPE',
      'HEAP_NUMBER_TYPE',
      'NATIVE_CONTEXT_TYPE',
      'OBJECT_PROPERTY_DICTIONARY_TYPE',
      'INTERNALIZED_ONE_BYTE_STRING_TYPE',
      'SEQ_ONE_BYTE_STRING_TYPE',
      'OTHER_CONTEXT_TYPE',
      'PROPERTY_ARRAY_TYPE',
      'SLICED_ONE_BYTE_STRING_TYPE',
      'SLICED_TWO_BYTE_STRING_TYPE',
      'STRING_EXTERNAL_RESOURCE_ONE_BYTE_TYPE',
      'STRING_EXTERNAL_RESOURCE_TWO_BYTE_TYPE',
      'SEQ_TWO_BYTE_STRING_TYPE',
      'SYMBOL_TYPE',
      'THIN_ONE_BYTE_STRING_TYPE',
      'THIN_TWO_BYTE_STRING_TYPE',
      'UNCACHED_EXTERNAL_INTERNALIZED_TWO_BYTE_STRING_TYPE',
      'UNCACHED_EXTERNAL_INTERNALIZED_ONE_BYTE_STRING_TYPE',
      'UNCACHED_EXTERNAL_ONE_BYTE_STRING_TYPE',
      'UNCACHED_EXTERNAL_TWO_BYTE_STRING_TYPE',
      'WASM_INSTANCE_OBJECT_TYPE',
      'WASM_MEMORY_OBJECT_TYPE',
      'WASM_MODULE_OBJECT_TYPE',
    ])
  ],
  [
    'system', new Set([
      'ACCESS_CHECK_INFO_TYPE',
      'ACCESSOR_INFO_TYPE',
      'ACCESSOR_PAIR_TYPE',
      'ALLOCATION_MEMENTO_TYPE',
      'ALLOCATION_SITE_TYPE',
      'ARRAY_BOILERPLATE_DESCRIPTION_TYPE',
      'ARRAY_BOILERPLATE_DESCRIPTION_ELEMENTS_TYPE',
      'BOILERPLATE_ELEMENTS_TYPE',
      'BOILERPLATE_PROPERTY_ARRAY_TYPE',
      'BOILERPLATE_PROPERTY_DICTIONARY_TYPE',
      'BYTE_ARRAY_TYPE',
      'CALL_HANDLER_INFO_TYPE',
      'CALL_SITE_INFO_TYPE',
      'CELL_TYPE',
      'CODE_STUBS_TABLE_TYPE',
      'CONTEXT_EXTENSION_TYPE',
      'ENUM_CACHE_TYPE',
      'ENUM_INDICES_CACHE_TYPE',
      'FOREIGN_TYPE',
      'FUNCTION_TEMPLATE_INFO_ENTRIES_TYPE',
      'FUNCTION_TEMPLATE_INFO_TYPE',
      'INTERCEPTOR_INFO_TYPE',
      'JS_API_OBJECT_TYPE',
      'JS_ARRAY_BOILERPLATE_TYPE',
      'JS_OBJECT_BOILERPLATE_TYPE',
      'JS_SPECIAL_API_OBJECT_TYPE',
      'MAP_TYPE',
      'NUMBER_STRING_CACHE_TYPE',
      'OBJECT_BOILERPLATE_DESCRIPTION_TYPE',
      'OBJECT_TEMPLATE_INFO_TYPE',
      'OBJECT_TO_CODE_TYPE',
      'ODDBALL_TYPE',
      'PROMISE_REACTION_JOB_INFO_TYPE',
      'PROMISE_RESOLVE_THENABLE_JOB_INFO_TYPE',
      'PROPERTY_CELL_TYPE',
      'PROTOTYPE_INFO_TYPE',
      'PROTOTYPE_USERS_TYPE',
      'REGEXP_MULTIPLE_CACHE_TYPE',
      'RETAINED_MAPS_TYPE',
      'SCOPE_INFO_TYPE',
      'SCRIPT_LIST_TYPE',
      'SCRIPT_SHARED_FUNCTION_INFOS_TYPE',
      'SERIALIZED_OBJECTS_TYPE',
      'SINGLE_CHARACTER_STRING_CACHE_TYPE',
      'STRING_SPLIT_CACHE_TYPE',
      'STRING_TABLE_TYPE',
      'TRANSITION_ARRAY_TYPE',
      'WEAK_NEW_SPACE_OBJECT_TO_CODE_TYPE',
    ])
  ],
  [
    'code', new Set([
      'BUILTIN',
      'BYTECODE_ARRAY_CONSTANT_POOL_TYPE',
      'BYTECODE_ARRAY_HANDLER_TABLE_TYPE',
      'BYTECODE_ARRAY_TYPE',
      'BYTECODE_HANDLER',
      'CODE_TYPE',
      'DEOPTIMIZATION_DATA_TYPE',
      'EMBEDDED_OBJECT_TYPE',
      'FEEDBACK_CELL_TYPE',
      'FEEDBACK_METADATA_TYPE',
      'FEEDBACK_VECTOR_ENTRY_TYPE',
      'FEEDBACK_VECTOR_HEADER_TYPE',
      'FEEDBACK_VECTOR_SLOT_CALL_TYPE',
      'FEEDBACK_VECTOR_SLOT_CALL_UNUSED_TYPE',
      'FEEDBACK_VECTOR_SLOT_ENUM_TYPE',
      'FEEDBACK_VECTOR_SLOT_LOAD_TYPE',
      'FEEDBACK_VECTOR_SLOT_LOAD_UNUSED_TYPE',
      'FEEDBACK_VECTOR_SLOT_OTHER_TYPE',
      'FEEDBACK_VECTOR_SLOT_STORE_TYPE',
      'FEEDBACK_VECTOR_SLOT_STORE_UNUSED_TYPE',
      'FEEDBACK_VECTOR_TYPE',
      'LOAD_HANDLER_TYPE',
      'NOSCRIPT_SHARED_FUNCTION_INFOS_TYPE',
      'OPTIMIZED_CODE_LITERALS_TYPE',
      'OPTIMIZED_FUNCTION',
      'PREPARSE_DATA_TYPE',
      'REGEXP',
      'RELOC_INFO_TYPE',
      'SCRIPT_SOURCE_EXTERNAL_ONE_BYTE_TYPE',
      'SCRIPT_SOURCE_EXTERNAL_TWO_BYTE_TYPE',
      'SCRIPT_SOURCE_EXTERNAL_TYPE',
      'SCRIPT_SOURCE_NON_EXTERNAL_ONE_BYTE_TYPE',
      'SCRIPT_SOURCE_NON_EXTERNAL_TWO_BYTE_TYPE',
      'SCRIPT_TYPE',
      'SHARED_FUNCTION_INFO_TYPE',
      'SOURCE_POSITION_TABLE_TYPE',
      'STORE_HANDLER_TYPE',
      'STUB',
      'UNCOMPILED_DATA_WITHOUT_PREPARSE_DATA_TYPE',
      'UNCOMPILED_DATA_WITH_PREPARSE_DATA_TYPE',
      'UNCOMPILED_JS_FUNCTION_TYPE',
      'UNCOMPILED_SHARED_FUNCTION_INFO_TYPE'
    ])
  ],
  ['unclassified', new Set()],
]);

// Maps category to description text that is shown in html.
export const CATEGORY_NAMES = new Map([
  ['user', 'JS'],
  ['system', 'Metadata'],
  ['code', 'Code'],
  ['unclassified', 'Unclassified'],
]);
                                                                                                                                                               node-23.7.0/deps/v8/tools/heap-stats/details-selection-template.html                                0000664 0000000 0000000 00000005561 14746647661 0025374 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        <!-- Copyright 2018 the V8 project authors. All rights reserved.
Use of this source code is governed by a BSD-style license that can be
found in the LICENSE file. -->
<style>
#dataSelectionSection {
  display: none;
}

.box {
  border-left: dashed 1px #666666;
  border-right: dashed 1px #666666;
  border-bottom: dashed 1px #666666;
  padding: 10px;
  overflow: hidden;
  position: relative;
}

.box:nth-of-type(1) {
  border-top: dashed 1px #666666;
  border-radius: 5px 5px 0px 0px;
}

.box:last-of-type {
    border-radius: 0px 0px 5px 5px;
}

.box > ul {
  margin: 0px;
  padding: 0px;
}

.box > ul > li {
  display: inline-block;
}

.box > ul > li:not(:first-child) {
  margin-left: 10px;
}

.box > ul > li:first-child {
  font-weight: bold;
}

.instanceTypeSelectBox {
  position: relative;
  overflow: hidden;
  float: left;
  padding: 0px 5px 2px 0px;
  margin: 3px;
  border-radius: 3px;
}

.instanceTypeSelectBox > label {
  font-size: xx-small;
}

.instanceTypeSelectBox > input {
  vertical-align: middle;
}

.percentBackground {
  position: absolute;
  width: 200%;
  height: 100%;
  left: 0%;
  top: 0px;
  margin-left: -100%;
  transition: all 1s ease-in-out;
}

.instanceTypeSelectBox > .percentBackground  {
  background: linear-gradient(90deg, #68b0f7 50%, #b3d9ff 50%);
  z-index: -1;
}
.box > .percentBackground  {
  background: linear-gradient(90deg, #e0edfe 50%, #fff 50%);
  z-index: -2;
}

#categories {
  margin-top: 10px;
}

#category-filter {
  text-align: right;
  width: 50px;
}

.categorySelectionButtons {
  float: right;
}
.categoryLabels {
  float: left;
  min-wdith: 200px;
}
.categoryContent {
  clear: both;
}

</style>
<section id="dataSelectionSection">
  <h2>Data selection</h2>
  <ul>
    <li>
      <label for="isolate-select">
        Isolate
      </label>
      <select id="isolate-select">
        <option>No data</option>
      </select>
    </li>
    <li>
      <label for="data-view-select">
        Data view
      </label>
      <select id="data-view-select">
        <option>No data</option>
      </select>
    </li>
    <li>
      <label for="dataset-select">
        Data set
      </label>
      <select id="dataset-select">
        <option>No data</option>
      </select>
    </li>
    <li>
      <label for="gc-select">
        Garbage collection (at a specific time in ms)
      </label>
      <select id="gc-select">
        <option>No data</option>
      </select>
    </li>
    <li>
      <input id="category-filter" type="text" value="0" disabled="disabled" />KB
      <button id="category-filter-btn" disabled="disabled">
        Filter categories with less memory
      </button>
      <button id="category-auto-filter-btn" disabled="disabled">
        Show top 20 categories only
      </button>
    </li>
    <li>
      <button id="csv-export-btn" disabled="disabled">Export selection as CSV</button>
    </li>
  </ul>

  <div id="categories"></div>
</section>
                                                                                                                                               node-23.7.0/deps/v8/tools/heap-stats/details-selection.js                                           0000664 0000000 0000000 00000034650 14746647661 0023234 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2018 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

'use strict';

import {CATEGORIES, CATEGORY_NAMES} from './categories.js';

export const VIEW_BY_INSTANCE_TYPE = 'by-instance-type';
export const VIEW_BY_INSTANCE_CATEGORY = 'by-instance-category';
export const VIEW_BY_FIELD_TYPE = 'by-field-type';

defineCustomElement('details-selection', (templateText) =>
 class DetailsSelection extends HTMLElement {
  constructor() {
    super();
    const shadowRoot = this.attachShadow({mode: 'open'});
    shadowRoot.innerHTML = templateText;
    this.isolateSelect.addEventListener(
        'change', e => this.handleIsolateChange(e));
    this.dataViewSelect.addEventListener(
        'change', e => this.notifySelectionChanged(e));
    this.datasetSelect.addEventListener(
        'change', e => this.notifySelectionChanged(e));
    this.gcSelect.addEventListener(
      'change', e => this.notifySelectionChanged(e));
    this.$('#csv-export-btn')
        .addEventListener('click', e => this.exportCurrentSelection(e));
    this.$('#category-filter-btn')
        .addEventListener('click', e => this.filterCurrentSelection(e));
    this.$('#category-auto-filter-btn')
        .addEventListener('click', e => this.filterTop20Categories(e));
    this._data = undefined;
    this.selection = undefined;
  }

  connectedCallback() {
    for (let category of CATEGORIES.keys()) {
      this.$('#categories').appendChild(this.buildCategory(category));
    }
  }

  dataChanged() {
    this.selection = {categories: {}};
    this.resetUI(true);
    this.populateIsolateSelect();
    this.handleIsolateChange();
    this.$('#dataSelectionSection').style.display = 'block';
  }

  set data(value) {
    this._data = value;
    this.dataChanged();
  }

  get data() {
    return this._data;
  }

  get selectedIsolate() {
    return this._data[this.selection.isolate];
  }

  get selectedData() {
    console.assert(this.data, 'invalid data');
    console.assert(this.selection, 'invalid selection');
    return this.selectedIsolate.gcs[this.selection.gc][this.selection.data_set];
  }

  $(id) {
    return this.shadowRoot.querySelector(id);
  }

  querySelectorAll(query) {
    return this.shadowRoot.querySelectorAll(query);
  }

  get dataViewSelect() {
    return this.$('#data-view-select');
  }

  get datasetSelect() {
    return this.$('#dataset-select');
  }

  get isolateSelect() {
    return this.$('#isolate-select');
  }

  get gcSelect() {
    return this.$('#gc-select');
  }

  buildCategory(name) {
    const div = document.createElement('div');
    div.id = name;
    div.classList.add('box');

    let ul = document.createElement('ul');
    ul.className = 'categoryLabels'
    {
      const name_li = document.createElement('li');
      name_li.textContent = CATEGORY_NAMES.get(name);
      ul.appendChild(name_li);

      const percent_li = document.createElement('li');
      percent_li.textContent = '0%';
      percent_li.id = name + 'PercentContent';
      ul.appendChild(percent_li);
    }
    div.appendChild(ul);

    ul = document.createElement('ul');
    ul.className = 'categorySelectionButtons'
    {
      const all_li = document.createElement('li');
      const all_button = document.createElement('button');
      all_button.textContent = 'All';
      all_button.addEventListener('click', e => this.selectCategory(name));
      all_li.appendChild(all_button);
      ul.appendChild(all_li);

      const top_li = document.createElement('li');
      const top_button = document.createElement('button');
      top_button.textContent = 'Top 10';
      top_button.addEventListener(
          'click', e => this.selectCategoryTopEntries(name));
      top_li.appendChild(top_button);
      ul.appendChild(top_li);

      const none_li = document.createElement('li');
      const none_button = document.createElement('button');
      none_button.textContent = 'None';
      none_button.addEventListener('click', e => this.unselectCategory(name));
      none_li.appendChild(none_button);
      ul.appendChild(none_li);
    }
    div.appendChild(ul);

    const innerDiv = document.createElement('div');
    innerDiv.id = name + 'Content';
    innerDiv.className = 'categoryContent';
    div.appendChild(innerDiv);

    const percentDiv = document.createElement('div');
    percentDiv.className = 'percentBackground';
    percentDiv.id = name + 'PercentBackground';
    div.appendChild(percentDiv);
    return div;
  }

  populateIsolateSelect() {
    let isolates = Object.entries(this.data);
    // Sorty by peak heap memory consumption.
    isolates.sort((a, b) => b[1].peakMemory - a[1].peakMemory);
    this.populateSelect(
        '#isolate-select', isolates, (key, isolate) => isolate.getLabel());
  }

  resetUI(resetIsolateSelect) {
    if (resetIsolateSelect) removeAllChildren(this.isolateSelect);

    removeAllChildren(this.dataViewSelect);
    removeAllChildren(this.datasetSelect);
    removeAllChildren(this.gcSelect);
    this.clearCategories();
    this.setButtonState('disabled');
  }

  setButtonState(disabled) {
    this.$('#csv-export-btn').disabled = disabled;
    this.$('#category-filter').disabled = disabled;
    this.$('#category-filter-btn').disabled = disabled;
    this.$('#category-auto-filter-btn').disabled = disabled;
  }

  handleIsolateChange(e) {
    this.selection.isolate = this.isolateSelect.value;
    if (this.selection.isolate.length === 0) {
      this.selection.isolate = null;
      return;
    }
    this.resetUI(false);
    this.populateSelect(
        '#data-view-select', [
          [VIEW_BY_INSTANCE_TYPE, 'Selected instance types'],
          [VIEW_BY_INSTANCE_CATEGORY, 'Selected type categories'],
          [VIEW_BY_FIELD_TYPE, 'Field type statistics']
        ],
        (key, label) => label, VIEW_BY_INSTANCE_TYPE);
    this.populateSelect(
        '#dataset-select', this.selectedIsolate.data_sets.entries(), null,
        'live');
    this.populateSelect(
        '#gc-select',
        Object.keys(this.selectedIsolate.gcs)
            .map(id => [id, this.selectedIsolate.gcs[id].time]),
        (key, time, index) => {
          return (index + ': ').padStart(4, '0') +
              formatSeconds(time).padStart(6, '0') + ' ' +
              formatBytes(this.selectedIsolate.gcs[key].live.overall)
                  .padStart(9, '0');
        });
    this.populateCategories();
    this.notifySelectionChanged();
  }

  notifySelectionChanged(e) {
    if (!this.selection.isolate) return;

    this.selection.data_view = this.dataViewSelect.value;
    this.selection.categories = {};
    if (this.selection.data_view === VIEW_BY_FIELD_TYPE) {
      this.$('#categories').style.display = 'none';
    } else {
      for (let category of CATEGORIES.keys()) {
        const selected = this.selectedInCategory(category);
        if (selected.length > 0) this.selection.categories[category] = selected;
      }
      this.$('#categories').style.display = 'block';
    }
    this.selection.category_names = CATEGORY_NAMES;
    this.selection.data_set = this.datasetSelect.value;
    this.selection.gc = this.gcSelect.value;
    this.setButtonState(false);
    this.updatePercentagesInCategory();
    this.updatePercentagesInInstanceTypes();
    this.dispatchEvent(new CustomEvent(
        'change', {bubbles: true, composed: true, detail: this.selection}));
  }

  filterCurrentSelection(e) {
    const minSize = this.$('#category-filter').value * KB;
    this.filterCurrentSelectionWithThresold(minSize);
  }

  filterTop20Categories(e) {
    // Limit to show top 20 categories only.
    let minSize = 0;
    let count = 0;
    let sizes = this.selectedIsolate.instanceTypePeakMemory;
    for (let key in sizes) {
      if (count == 20) break;
      minSize = sizes[key];
      count++;
    }
    this.filterCurrentSelectionWithThresold(minSize);
  }

  filterCurrentSelectionWithThresold(minSize) {
    if (minSize === 0) return;

    this.selection.category_names.forEach((_, category) => {
      for (let checkbox of this.querySelectorAll(
               'input[name=' + category + 'Checkbox]')) {
        checkbox.checked =
            this.selectedData.instance_type_data[checkbox.instance_type]
                .overall > minSize;
        console.log(
            checkbox.instance_type, checkbox.checked,
            this.selectedData.instance_type_data[checkbox.instance_type]
                .overall);
      }
    });
    this.notifySelectionChanged();
  }

  updatePercentagesInCategory() {
    const overalls = {};
    let overall = 0;
    // Reset all categories.
    this.selection.category_names.forEach((_, category) => {
      overalls[category] = 0;
    });
    // Only update categories that have selections.
    Object.entries(this.selection.categories).forEach(([category, value]) => {
      overalls[category] =
          Object.values(value).reduce(
              (accu, current) =>
                  accu + this.selectedData.instance_type_data[current].overall,
              0) /
          KB;
      overall += overalls[category];
    });
    Object.entries(overalls).forEach(([category, category_overall]) => {
      let percents = category_overall / overall * 100;
      this.$(`#${category}PercentContent`).textContent =
          `${percents.toFixed(1)}%`;
      this.$('#' + category + 'PercentBackground').style.left = percents + '%';
    });
  }

  updatePercentagesInInstanceTypes() {
    const instanceTypeData = this.selectedData.instance_type_data;
    const maxInstanceType = this.selectedData.singleInstancePeakMemory;
    this.querySelectorAll('.instanceTypeSelectBox  input').forEach(checkbox => {
      let instanceType = checkbox.value;
      let instanceTypeSize = instanceTypeData[instanceType].overall;
      let percents = instanceTypeSize / maxInstanceType;
      let percentDiv = checkbox.parentNode.querySelector('.percentBackground');
      percentDiv.style.left = (percents * 100) + '%';

    });
  }

  selectedInCategory(category) {
    let tmp = [];
    this.querySelectorAll('input[name=' + category + 'Checkbox]:checked')
        .forEach(checkbox => tmp.push(checkbox.value));
    return tmp;
  }

  categoryForType(instance_type) {
    for (let [key, value] of CATEGORIES.entries()) {
      if (value.has(instance_type)) return key;
    }
    return 'unclassified';
  }

  createOption(value, text) {
    const option = document.createElement('option');
    option.value = value;
    option.text = text;
    return option;
  }

  populateSelect(id, iterable, labelFn = null, autoselect = null) {
    if (labelFn == null) labelFn = e => e;
    let index = 0;
    for (let [key, value] of iterable) {
      index++;
      const label = labelFn(key, value, index);
      const option = this.createOption(key, label);
      if (autoselect === key) {
        option.selected = 'selected';
      }
      this.$(id).appendChild(option);
    }
  }

  clearCategories() {
    for (const category of CATEGORIES.keys()) {
      let f = this.$('#' + category + 'Content');
      while (f.firstChild) {
        f.removeChild(f.firstChild);
      }
    }
  }

  populateCategories() {
    this.clearCategories();
    const categories = {__proto__:null};
    for (let cat of CATEGORIES.keys()) {
      categories[cat] = [];
    }

    for (let instance_type of this.selectedIsolate.non_empty_instance_types) {
      const category = this.categoryForType(instance_type);
      categories[category].push(instance_type);
    }
    for (let category of Object.keys(categories)) {
      categories[category].sort();
      for (let instance_type of categories[category]) {
        this.$('#' + category + 'Content')
            .appendChild(this.createCheckBox(instance_type, category));
      }
    }
  }

  unselectCategory(category) {
    this.querySelectorAll('input[name=' + category + 'Checkbox]')
        .forEach(checkbox => checkbox.checked = false);
    this.notifySelectionChanged();
  }

  selectCategory(category) {
    this.querySelectorAll('input[name=' + category + 'Checkbox]')
        .forEach(checkbox => checkbox.checked = true);
    this.notifySelectionChanged();
  }

  selectCategoryTopEntries(category) {
    // unselect all checkboxes in this category.
    this.querySelectorAll('input[name=' + category + 'Checkbox]')
        .forEach(checkbox => checkbox.checked = false);
    const data = this.selectedData.instance_type_data;

    // Get the max values for instance_types in this category
    const categoryInstanceTypes = Array.from(CATEGORIES.get(category));
    categoryInstanceTypes.filter(each => each in data)
      .sort((a,b) => {
        return data[b].overall - data[a].overall;
      }).slice(0, 10).forEach((category) => {
        this.$('#' + category + 'Checkbox').checked = true;
      });
    this.notifySelectionChanged();
  }

  createCheckBox(instance_type, category) {
    const div = document.createElement('div');
    div.classList.add('instanceTypeSelectBox');
    const input = document.createElement('input');
    div.appendChild(input);
    input.type = 'checkbox';
    input.name = category + 'Checkbox';
    input.checked = 'checked';
    input.id = instance_type + 'Checkbox';
    input.instance_type = instance_type;
    input.value = instance_type;
    input.addEventListener('change', e => this.notifySelectionChanged(e));
    const label = document.createElement('label');
    div.appendChild(label);
    label.innerText = instance_type;
    label.htmlFor = instance_type + 'Checkbox';
    const percentDiv = document.createElement('div');
    percentDiv.className = 'percentBackground';
    div.appendChild(percentDiv);
    return div;
  }

  exportCurrentSelection(e) {
    const data = [];
    const selected_data =
        this.selectedIsolate.gcs[this.selection.gc][this.selection.data_set]
            .instance_type_data;
    Object.values(this.selection.categories).forEach(instance_types => {
      instance_types.forEach(instance_type => {
        data.push([instance_type, selected_data[instance_type].overall / KB]);
      });
    });
    const createInlineContent = arrayOfRows => {
      const content = arrayOfRows.reduce(
          (accu, rowAsArray) => {return accu + `${rowAsArray.join(',')}\n`},
          '');
      return `data:text/csv;charset=utf-8,${content}`;
    };
    const encodedUri = encodeURI(createInlineContent(data));
    const link = document.createElement('a');
    link.setAttribute('href', encodedUri);
    link.setAttribute(
        'download',
        `heap_objects_data_${this.selection.isolate}_${this.selection.gc}.csv`);
    this.shadowRoot.appendChild(link);
    link.click();
    this.shadowRoot.removeChild(link);
  }
});
                                                                                        node-23.7.0/deps/v8/tools/heap-stats/global-timeline-template.html                                  0000664 0000000 0000000 00000000503 14746647661 0025017 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        <!-- Copyright 2018 the V8 project authors. All rights reserved.
Use of this source code is governed by a BSD-style license that can be
found in the LICENSE file. -->
<style>
#chart {
  width: 100%;
  height: 500px;
}
</style>
<div id="container" style="display: none;">
  <h2>Timeline</h2>
  <div id="chart"></div>
</div>
                                                                                                                                                                                             node-23.7.0/deps/v8/tools/heap-stats/global-timeline.js                                             0000664 0000000 0000000 00000015774 14746647661 0022676 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2018 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

'use strict';

import {
  VIEW_BY_INSTANCE_TYPE,
  VIEW_BY_INSTANCE_CATEGORY,
  VIEW_BY_FIELD_TYPE
} from './details-selection.js';

defineCustomElement('global-timeline', (templateText) =>
 class GlobalTimeline extends HTMLElement {
  constructor() {
    super();
    const shadowRoot = this.attachShadow({mode: 'open'});
    shadowRoot.innerHTML = templateText;
  }

  $(id) {
    return this.shadowRoot.querySelector(id);
  }

  set data(value) {
    this._data = value;
    this.stateChanged();
  }

  get data() {
    return this._data;
  }

  set selection(value) {
    this._selection = value;
    this.stateChanged();
  }

  get selection() {
    return this._selection;
  }

  isValid() {
    return this.data && this.selection;
  }

  hide() {
    this.$('#container').style.display = 'none';
  }

  show() {
    this.$('#container').style.display = 'block';
  }

  stateChanged() {
    if (this.isValid()) {
      this.drawChart();
    } else {
      this.hide();
    }
  }

  getFieldData() {
    const labels = [
      {type: 'number', label: 'Time'},
      {type: 'number', label: 'Ptr compression benefit'},
      {type: 'string', role: 'tooltip'},
      {type: 'number', label: 'Embedder fields'},
      {type: 'number', label: 'Tagged fields (excl. in-object Smis)'},
      {type: 'number', label: 'In-object Smi-only fields'},
      {type: 'number', label: 'Other raw fields'},
      {type: 'number', label: 'Unboxed doubles'},
      {type: 'number', label: 'Boxed doubles'},
      {type: 'number', label: 'String data'}
    ];
    const chart_data = [labels];
    const isolate_data = this.data[this.selection.isolate];
    let sum_total = 0;
    let sum_ptr_compr_benefit_perc = 0;
    let count = 0;
    Object.keys(isolate_data.gcs).forEach(gc_key => {
      const gc_data = isolate_data.gcs[gc_key];
      const data_set = gc_data[this.selection.data_set].field_data;
      const data = [];
      data.push(gc_data.time * kMillis2Seconds);
      const total = data_set.tagged_fields +
                    data_set.inobject_smi_fields +
                    data_set.embedder_fields +
                    data_set.other_raw_fields +
                    data_set.unboxed_double_fields +
                    data_set.boxed_double_fields +
                    data_set.string_data;
      const ptr_compr_benefit =
          (data_set.inobject_smi_fields + data_set.tagged_fields) / 2;
      const ptr_compr_benefit_perc = ptr_compr_benefit / total * 100;
      sum_total += total;
      sum_ptr_compr_benefit_perc += ptr_compr_benefit_perc;
      count++;
      const tooltip = "Ptr compression benefit: " +
                      (ptr_compr_benefit / KB).toFixed(2) + "KB " +
                      " (" + ptr_compr_benefit_perc.toFixed(2) + "%)";
      data.push(ptr_compr_benefit / KB);
      data.push(tooltip);
      data.push(data_set.embedder_fields / KB);
      data.push(data_set.tagged_fields / KB);
      data.push(data_set.inobject_smi_fields / KB);
      data.push(data_set.other_raw_fields / KB);
      data.push(data_set.unboxed_double_fields / KB);
      data.push(data_set.boxed_double_fields / KB);
      data.push(data_set.string_data / KB);
      chart_data.push(data);
    });
    const avg_ptr_compr_benefit_perc =
        count ? sum_ptr_compr_benefit_perc / count : 0;
    console.log("==================================================");
    console.log("= Average ptr compression benefit is " +
                avg_ptr_compr_benefit_perc.toFixed(2) + "%");
    console.log("= Average V8 heap size " +
                (sum_total / count / KB).toFixed(2) + " KB");
    console.log("==================================================");
    return chart_data;
  }

  getCategoryData() {
    const categories = Object.keys(this.selection.categories)
                           .map(k => this.selection.category_names.get(k));
    const labels = ['Time', ...categories];
    const chart_data = [labels];
    const isolate_data = this.data[this.selection.isolate];
    Object.keys(isolate_data.gcs).forEach(gc_key => {
      const gc_data = isolate_data.gcs[gc_key];
      const data_set = gc_data[this.selection.data_set].instance_type_data;
      const data = [];
      data.push(gc_data.time * kMillis2Seconds);
      Object.values(this.selection.categories).forEach(instance_types => {
        data.push(
            instance_types
                .map(instance_type => {
                  return data_set[instance_type].overall;
                })
                .reduce((accu, current) => accu + current, 0) /
            KB);
      });
      chart_data.push(data);
    });
    return chart_data;
  }

  getInstanceTypeData() {
    const instance_types =
        Object.values(this.selection.categories)
            .reduce((accu, current) => accu.concat(current), []);
    const labels = ['Time', ...instance_types];
    const chart_data = [labels];
    const isolate_data = this.data[this.selection.isolate];
    Object.keys(isolate_data.gcs).forEach(gc_key => {
      const gc_data = isolate_data.gcs[gc_key];
      const data_set = gc_data[this.selection.data_set].instance_type_data;
      const data = [];
      data.push(gc_data.time * kMillis2Seconds);
      instance_types.forEach(instance_type => {
        data.push(data_set[instance_type].overall / KB);
      });
      chart_data.push(data);
    });
    return chart_data;
  }

  getChartData() {
    switch (this.selection.data_view) {
      case VIEW_BY_FIELD_TYPE:
        return this.getFieldData();
      case VIEW_BY_INSTANCE_CATEGORY:
        return this.getCategoryData();
      case VIEW_BY_INSTANCE_TYPE:
      default:
        return this.getInstanceTypeData();
    }
  }

  getChartOptions() {
    const options = {
      isStacked: true,
      hAxis: {
        format: '###.##s',
        title: 'Time [s]',
      },
      vAxis: {
        format: '#,###KB',
        title: 'Memory consumption [KBytes]'
      },
      chartArea: {left:100, width: '85%', height: '70%'},
      legend: {position: 'top', maxLines: '1'},
      pointsVisible: true,
      pointSize: 5,
      explorer: {},
    };
    switch (this.selection.data_view) {
      case VIEW_BY_FIELD_TYPE:
        // Overlay pointer compression benefit on top of the graph
        return Object.assign(options, {
          series: {0: {type: 'line', lineDashStyle: [13, 13]}},
        });
      case VIEW_BY_INSTANCE_CATEGORY:
      case VIEW_BY_INSTANCE_TYPE:
      default:
        return options;
    }
  }

  drawChart() {
    setTimeout(() => this._drawChart(), 10);
  }

  _drawChart() {
    console.assert(this.data, 'invalid data');
    console.assert(this.selection, 'invalid selection');

    const chart_data = this.getChartData();

    const data = google.visualization.arrayToDataTable(chart_data);
    const options = this.getChartOptions();
    const chart = new google.visualization.AreaChart(this.$('#chart'));
    this.show();
    chart.draw(data, google.charts.Line.convertOptions(options));
  }
});
    node-23.7.0/deps/v8/tools/heap-stats/helper.js                                                      0000664 0000000 0000000 00000001514 14746647661 0021074 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2018 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

const KB = 1024;
const MB = KB * KB;
const GB = MB * KB;
const kMillis2Seconds = 1 / 1000;

function formatBytes(bytes) {
  const units = ['B', 'KiB', 'MiB', 'GiB'];
  const divisor = 1024;
  let index = 0;
  while (index < units.length && bytes >= divisor) {
    index++;
    bytes /= divisor;
  }
  return bytes.toFixed(2) + units[index];
}

function formatSeconds(millis) {
  return (millis * kMillis2Seconds).toFixed(2) + 's';
}

function defineCustomElement(name, generator) {
  let htmlTemplatePath = name + '-template.html';
  fetch(htmlTemplatePath)
    .then(stream => stream.text())
    .then(templateText => customElements.define(name, generator(templateText)));
}
                                                                                                                                                                                    node-23.7.0/deps/v8/tools/heap-stats/histogram-viewer-template.html                                 0000664 0000000 0000000 00000000571 14746647661 0025254 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        <!-- Copyright 2018 the V8 project authors. All rights reserved.
Use of this source code is governed by a BSD-style license that can be
found in the LICENSE file. -->
<style>
#chart {
  width: 100%;
  height: 800px;
}
</style>
<div id="container" style="display: none;">
  <h2>Details</h2>
  <ul>
    <li><span id="overall"></span></li>
  </ul>
  <div id="chart"></div>
</div>
                                                                                                                                       node-23.7.0/deps/v8/tools/heap-stats/histogram-viewer.js                                            0000664 0000000 0000000 00000012411 14746647661 0023107 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2018 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

'use strict';

import {
  VIEW_BY_INSTANCE_TYPE,
  VIEW_BY_INSTANCE_CATEGORY,
  VIEW_BY_FIELD_TYPE
} from './details-selection.js';

defineCustomElement('histogram-viewer', (templateText) =>
 class HistogramViewer extends HTMLElement {
  constructor() {
    super();
    const shadowRoot = this.attachShadow({mode: 'open'});
    shadowRoot.innerHTML = templateText;
  }

  $(id) {
    return this.shadowRoot.querySelector(id);
  }

  set data(value) {
    this._data = value;
    this.stateChanged();
  }

  get data() {
    return this._data;
  }

  set selection(value) {
    this._selection = value;
    this.stateChanged();
  }

  get selection() {
    return this._selection;
  }

  isValid() {
    return this.data && this.selection &&
           (this.selection.data_view === VIEW_BY_INSTANCE_CATEGORY ||
            this.selection.data_view === VIEW_BY_INSTANCE_TYPE);
    ;
  }

  hide() {
    this.$('#container').style.display = 'none';
  }

  show() {
    this.$('#container').style.display = 'block';
  }

  getOverallValue() {
    switch (this.selection.data_view) {
      case VIEW_BY_FIELD_TYPE:
        return NaN;
      case VIEW_BY_INSTANCE_CATEGORY:
        return this.getPropertyForCategory('overall');
      case VIEW_BY_INSTANCE_TYPE:
      default:
        return this.getPropertyForInstanceTypes('overall');
    }
  }

  stateChanged() {
    if (this.isValid()) {
      const overall_bytes = this.getOverallValue();
      this.$('#overall').innerHTML = `Overall: ${overall_bytes / KB} KB`;
      this.drawChart();
    } else {
      this.hide();
    }
  }

  get selectedData() {
    console.assert(this.data, 'invalid data');
    console.assert(this.selection, 'invalid selection');
    return this.data[this.selection.isolate]
        .gcs[this.selection.gc][this.selection.data_set];
  }

  get selectedInstanceTypes() {
    console.assert(this.selection, 'invalid selection');
    return Object.values(this.selection.categories)
        .reduce((accu, current) => accu.concat(current), []);
  }

  getPropertyForCategory(property) {
    return Object.values(this.selection.categories)
        .reduce(
            (outer_accu, instance_types) => outer_accu +
                instance_types.reduce(
                    (inner_accu, instance_type) => inner_accu +
                        this.selectedData
                            .instance_type_data[instance_type][property],
                    0),
            0);
  }

  getPropertyForInstanceTypes(property) {
    return this.selectedInstanceTypes.reduce(
        (accu, instance_type) => accu +
            this.selectedData.instance_type_data[instance_type][property],
        0);
  }

  formatBytes(bytes) {
    const units = ['B', 'KiB', 'MiB'];
    const divisor = 1024;
    let index = 0;
    while (index < units.length && bytes >= divisor) {
      index++;
      bytes /= divisor;
    }
    return bytes + units[index];
  }

  getCategoryData() {
    const labels = [
      'Bucket',
      ...Object.keys(this.selection.categories)
          .map(k => this.selection.category_names.get(k))
    ];
    const data = this.selectedData.bucket_sizes.map(
        (bucket_size, index) =>
            [`<${this.formatBytes(bucket_size)}`,
             ...Object.values(this.selection.categories)
                 .map(
                     instance_types =>
                         instance_types
                             .map(
                                 instance_type =>
                                     this.selectedData
                                         .instance_type_data[instance_type]
                                         .histogram[index])
                             .reduce((accu, current) => accu + current, 0))]);
    // Adjust last histogram bucket label.
    data[data.length - 1][0] = 'rest';
    return [labels, ...data];
  }

  getInstanceTypeData() {
    const instance_types = this.selectedInstanceTypes;
    const labels = ['Bucket', ...instance_types];
    const data = this.selectedData.bucket_sizes.map(
        (bucket_size, index) =>
            [`<${bucket_size}`,
             ...instance_types.map(
                 instance_type =>
                     this.selectedData.instance_type_data[instance_type]
                         .histogram[index])]);
    // Adjust last histogram bucket label.
    data[data.length - 1][0] = 'rest';
    return [labels, ...data];
  }

  getChartData() {
    switch (this.selection.data_view) {
      case VIEW_BY_FIELD_TYPE:
        return this.getFieldData();
      case VIEW_BY_INSTANCE_CATEGORY:
        return this.getCategoryData();
      case VIEW_BY_INSTANCE_TYPE:
      default:
        return this.getInstanceTypeData();
    }
  }

  drawChart() {
    const chart_data = this.getChartData();
    const data = google.visualization.arrayToDataTable(chart_data);
    const options = {
      legend: {position: 'top', maxLines: '1'},
      chartArea: {width: '85%', height: '85%'},
      bar: {groupWidth: '80%'},
      hAxis: {
        title: 'Count',
        minValue: 0
      },
      explorer: {},
    };
    const chart = new google.visualization.BarChart(this.$('#chart'));
    this.show();
    chart.draw(data, options);
  }
});
                                                                                                                                                                                                                                                       node-23.7.0/deps/v8/tools/heap-stats/index.html                                                     0000664 0000000 0000000 00000006740 14746647661 0021262 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        <!DOCTYPE html>
<!-- Copyright 2018 the V8 project authors. All rights reserved.
Use of this source code is governed by a BSD-style license that can be
found in the LICENSE file. -->
<html lang="en">
<head>
  <!-- This will be overwritten by the v8.dev/tools exporter -->
<!-- ANALYTICS_PLACEHOLDER -->
  <meta charset="UTF-8">
  <title>V8 Heap Statistics</title>
  <link href='https://fonts.googleapis.com/css?family=Roboto' rel='stylesheet'>
  <script
          src="https://www.gstatic.com/charts/loader.js"></script>
  <script
          src="https://cdnjs.cloudflare.com/ajax/libs/pako/1.0.6/pako_inflate.min.js"
          integrity="sha256-N1z6ddQzX83fjw8v7uSNe7/MgOmMKdwFUv1+AJMDqNM="
          crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/oboe.js/2.1.5/oboe-browser.min.js"
          crossorigin="anonymous"></script>
  <script src="helper.js"></script>

  <script type="module" src="details-selection.js"></script>
  <script type="module" src="global-timeline.js"></script>
  <script type="module" src="histogram-viewer.js"></script>
  <script type="module" src="trace-file-reader.js"></script>

  <style>
body {
  font-family: 'Roboto', sans-serif;
  margin-left: 5%;
  margin-right: 5%;
}

  </style>
  <script>
'use strict';

google.charts.load('current', {'packages':['line', 'corechart', 'bar']});

function $(id) { return document.querySelector(id); }

function removeAllChildren(node) {
  while (node.firstChild) {
    node.removeChild(node.firstChild);
  }
}

let state = Object.create(null);

function globalDataChanged(e) {
  state.data = e.detail;
  // Emit one entry with the whole model for debugging purposes.
  console.log(state.data);
  state.selection = null;
  $('#global-timeline').selection = state.selection;
  $('#global-timeline').data = state.data;
  $('#histogram-viewer').selection = state.selection;
  $('#histogram-viewer').data = state.data;
  $('#details-selection').data = state.data;
}

function globalSelectionChangedA(e) {
  state.selection = e.detail;
  console.log(state.selection);
  $('#global-timeline').selection = state.selection;
  $('#histogram-viewer').selection = state.selection;
}

  </script>
</head>

<body>
  <h1>V8 Heap Statistics</h1>
  <trace-file-reader onchange="globalDataChanged(event)"></trace-file-reader>

  <details-selection id="details-selection" onchange="globalSelectionChangedA(event)"></details-selection>
  <global-timeline id="global-timeline"></global-timeline>
  <histogram-viewer id="histogram-viewer"></histogram-viewer>

  <p>Visualize object statistics that have been gathered using</p>
  <ul>
    <li>Use <code>--trace-gc-object-stats</code> for V8 and load the contents of stdout</li>
    <li>
      <a
        href="https://www.chromium.org/developers/how-tos/trace-event-profiling-tool">Chrome's
        tracing infrastructure</a> collecting data for the category
      <code>disabled-by-default-v8.gc_stats</code> and directly load the
      results.html or trace.json.gzip file.
    </li>
  </ul>

  Additional information:
  <ul>
    <li>
      You only get a data point on major GCs. You can enforce this by
      using the <code>--gc-global</code> V8 flag.
    </li>
    <li>
      For more frequent data points you can also the
      <code>--gc-interval=$AFTER_N_ALLOCATIONS</code> V8.
    </li>
    <li>
      The visualizer needs to run on a web server due to HTML imports
      requiring <a
          href="https://en.wikipedia.org/wiki/Cross-origin_resource_sharing">CORS</a>.
    </li>
  <ul>
</body>

</html>
                                node-23.7.0/deps/v8/tools/heap-stats/model.js                                                       0000664 0000000 0000000 00000006717 14746647661 0020727 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2018 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

'use strict';

export class Isolate {
  constructor(address) {
    this.address = address;
    this.start = null;
    this.end = null;
    this.samples = Object.create(null);
    this.non_empty_instance_types = new Set();
    this.gcs = Object.create(null);
    this.zonetags = [];
    this.samples = {zone: {}};
    this.data_sets = new Set();
    this.peakMemory = 0;
    // Maps instance_types to their max memory consumption over all gcs.
    this.instanceTypePeakMemory = Object.create(null);
    // Peak memory consumed by any single instance type.
    this.singleInstanceTypePeakMemory = 0;
  }

  finalize() {
    Object.values(this.gcs).forEach(gc => this.finalizeGC(gc));
    this.sortInstanceTypePeakMemory();
  }

  getLabel() {
    let label = `${this.address}: gc=#${Object.keys(this.gcs).length}`;
    label += ` peak=${formatBytes(this.peakMemory)}`
    return label;
  }

  finalizeGC(gc_data) {
    this.data_sets.forEach(key => this.finalizeDataSet(gc_data[key]));
    if (!('live' in gc_data)) return;
    let liveData = gc_data.live;
    this.peakMemory = Math.max(this.peakMemory, liveData.overall);
    let data = liveData.instance_type_data;
    for (let name in data) {
      let prev = this.instanceTypePeakMemory[name] || 0;
      this.instanceTypePeakMemory[name] = Math.max(prev, data[name].overall);
    }
  }

  finalizeDataSet(data_set) {
    // Create a ranked instance type array that sorts instance types by
    // memory size (overall).
    let data = data_set.instance_type_data;
    let ranked_instance_types =
        [...data_set.non_empty_instance_types].sort((a, b) => {
          return data[a].overall - data[b].overall;
        });
    // Reassemble the instance_type list sorted by size.
    let sorted_data = Object.create(null);
    let max = 0;
    ranked_instance_types.forEach((name) => {
      let entry = sorted_data[name] = data[name];
      max = Math.max(max, entry.overall);
    });
    data_set.instance_type_data = data;
    data_set.singleInstancePeakMemory = max;

    Object.entries(data_set.instance_type_data).forEach(([name, entry]) => {
      this.checkHistogram(
          name, entry, data_set.bucket_sizes, 'histogram', ' overall');
      this.checkHistogram(
          name, entry, data_set.bucket_sizes, 'over_allocated_histogram',
          ' over_allocated');
    });
  }

  // Check that a lower bound for histogram memory does not exceed the
  // overall counter.
  checkHistogram(type, entry, bucket_sizes, histogram, overallProperty) {
    let sum = 0;
    for (let i = 1; i < entry[histogram].length; i++) {
      sum += entry[histogram][i] * bucket_sizes[i - 1];
    }
    const overall = entry[overallProperty];
    if (sum >= overall) {
      console.error(
          `${type}: sum('${histogram}') > overall (${sum} > ${overall})`);
    }
  }

  sortInstanceTypePeakMemory() {
    let entries = Object.entries(this.instanceTypePeakMemory);
    entries.sort((a, b) => {return b[1] - a[1]});
    this.instanceTypePeakMemory = Object.create(null);
    let max = 0;
    for (let [key, value] of entries) {
      this.instanceTypePeakMemory[key] = value;
      max = Math.max(max, value);
    }
    this.singleInstanceTypePeakMemory = max;
  }

  getInstanceTypePeakMemory(type) {
    if (!(type in this.instanceTypePeakMemory)) return 0;
    return this.instanceTypePeakMemory[type];
  }
}
                                                 node-23.7.0/deps/v8/tools/heap-stats/trace-file-reader-template.html                                0000664 0000000 0000000 00000002620 14746647661 0025230 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        <!-- Copyright 2018 the V8 project authors. All rights reserved.
Use of this source code is governed by a BSD-style license that can be
found in the LICENSE file. -->
<style>
#fileReader {
  width: 100%;
  height: 100px;
  line-height: 100px;
  text-align: center;
  border: solid 1px #000000;
  border-radius: 5px;
  cursor: pointer;
  transition: all 0.5s ease-in-out;
}

#fileReader.done {
    height: 20px;
    line-height: 20px;
}

#fileReader:hover {
  background-color: #e0edfe ;
}

.loading #fileReader {
  cursor: wait;
}

#fileReader > input {
  display: none;
}


#loader {
  display: none;
}

.loading #loader {
  display: block;
  position: fixed;
  top: 0px;
  left: 0px;
  width: 100%;
  height: 100%;
  background-color: rgba(255, 255, 255, 0.5);
}

#spinner {
  position: absolute;
  width: 100px;
  height: 100px;
  top: 40%;
  left: 50%;
  margin-left: -50px;
  border: 30px solid #000;
  border-top: 30px solid #36E;
  border-radius: 50%;
  animation: spin 1s ease-in-out infinite;
}

@keyframes spin {
 0% {
    transform: rotate(0deg);
 }
 100% {
    transform: rotate(360deg);
 }
}
</style>

<section id="fileReaderSection">
  <div id="fileReader" tabindex=1 >
    <span id="label">
      Drag and drop a trace file into this area, or click to choose from disk.
     </span>
    <input id="file" type="file" name="file" />
  </div>
  <div id="loader">
    <div id="spinner"></div>
  </div>
</section>
                                                                                                                node-23.7.0/deps/v8/tools/heap-stats/trace-file-reader.js                                           0000664 0000000 0000000 00000026533 14746647661 0023100 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2018 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

'use strict';

import {Isolate} from './model.js';

defineCustomElement('trace-file-reader', (templateText) =>
 class TraceFileReader extends HTMLElement {
  constructor() {
    super();
    const shadowRoot = this.attachShadow({mode: 'open'});
    shadowRoot.innerHTML = templateText;
    this.addEventListener('click', e => this.handleClick(e));
    this.addEventListener('dragover', e => this.handleDragOver(e));
    this.addEventListener('drop', e => this.handleChange(e));
    this.$('#file').addEventListener('change', e => this.handleChange(e));
    this.$('#fileReader').addEventListener('keydown', e => this.handleKeyEvent(e));
  }

  $(id) {
    return this.shadowRoot.querySelector(id);
  }

  get section() {
    return this.$('#fileReaderSection');
  }

  updateLabel(text) {
    this.$('#label').innerText = text;
  }

  handleKeyEvent(event) {
    if (event.key == "Enter") this.handleClick(event);
  }

  handleClick(event) {
    this.$('#file').click();
  }

  handleChange(event) {
    // Used for drop and file change.
    event.preventDefault();
    var host = event.dataTransfer ? event.dataTransfer : event.target;
    this.readFile(host.files[0]);
  }

  handleDragOver(event) {
    event.preventDefault();
  }

  connectedCallback() {
    this.$('#fileReader').focus();
  }

  readFile(file) {
    if (!file) {
      this.updateLabel('Failed to load file.');
      return;
    }
    this.$('#fileReader').blur();

    this.section.className = 'loading';
    const reader = new FileReader();

    if (['application/gzip', 'application/x-gzip'].includes(file.type)) {
      reader.onload = (e) => {
        try {
          const textResult = pako.inflate(e.target.result, {to: 'string'});
          this.processRawText(file, textResult);
          this.section.className = 'success';
          this.$('#fileReader').classList.add('done');
        } catch (err) {
          console.error(err);
          this.section.className = 'failure';
        }
      };
      // Delay the loading a bit to allow for CSS animations to happen.
      setTimeout(() => reader.readAsArrayBuffer(file), 0);
    } else if (file.type == 'text/html') {
      // try extracting the data from a results.html file
      reader.onload = (e) => {
        try {
          let html = document.createElement('html');
          html.innerHTML = e.target.result;
          for (let dataScript of html.querySelectorAll('#viewer-data')) {
            const base64 = dataScript.innerText.slice(1,-1);
            const binary = globalThis.atob(base64);
            const textResult = pako.inflate(binary, {to: 'string'});
            this.processRawText(file, textResult);
          }
          this.section.className = 'success';
          this.$('#fileReader').classList.add('done');
        } catch (err) {
          console.error(err);
          this.section.className = 'failure';
        }
      };
      // Delay the loading a bit to allow for CSS animations to happen.
      setTimeout(() => reader.readAsText(file), 0);
    } else {
      reader.onload = (e) => {
        try {
          this.processRawText(file, e.target.result);
          this.section.className = 'success';
          this.$('#fileReader').classList.add('done');
        } catch (err) {
          console.error(err);
          this.section.className = 'failure';
        }
      };
      // Delay the loading a bit to allow for CSS animations to happen.
      setTimeout(() => reader.readAsText(file), 0);
    }
  }

  processRawText(file, result) {
    let return_data;
    if (result.includes('V8.GC_Objects_Stats')) {
      return_data = this.createModelFromChromeTraceFile(result);
    } else {
      let contents = result.split('\n');
      return_data = this.createModelFromV8TraceFile(contents);
    }
    this.extendAndSanitizeModel(return_data);
    this.updateLabel('Finished loading \'' + file.name + '\'.');
    this.dispatchEvent(new CustomEvent(
        'change', {bubbles: true, composed: true, detail: return_data}));
  }

  createOrUpdateEntryIfNeeded(data, entry) {
    console.assert(entry.isolate, 'entry should have an isolate');
    if (!(entry.isolate in data)) {
      data[entry.isolate] = new Isolate(entry.isolate);
    }
    const data_object = data[entry.isolate];
    if (('id' in entry) && !(entry.id in data_object.gcs)) {
      data_object.gcs[entry.id] = {non_empty_instance_types: new Set()};
    }
    if ('time' in entry) {
      if (data_object.end === null || data_object.end < entry.time) {
        data_object.end = entry.time;
      }
      if (data_object.start === null || data_object.start > entry.time) {
        data_object.start = entry.time;
      }
    }
  }

  createDatasetIfNeeded(data, entry, data_set) {
    if (!(data_set in data[entry.isolate].gcs[entry.id])) {
      data[entry.isolate].gcs[entry.id][data_set] = {
        instance_type_data: {},
        non_empty_instance_types: new Set(),
        overall: 0
      };
      data[entry.isolate].data_sets.add(data_set);
    }
  }

  addFieldTypeData(data, isolate, gc_id, data_set, tagged_fields,
                   inobject_smi_fields, embedder_fields, unboxed_double_fields,
                   boxed_double_fields, string_data, other_raw_fields) {
    data[isolate].gcs[gc_id][data_set].field_data = {
      tagged_fields,
      inobject_smi_fields,
      embedder_fields,
      unboxed_double_fields,
      boxed_double_fields,
      string_data,
      other_raw_fields
    };
  }

  addInstanceTypeData(data, isolate, gc_id, data_set, instance_type, entry) {
    data[isolate].gcs[gc_id][data_set].instance_type_data[instance_type] = {
      overall: entry.overall,
      count: entry.count,
      histogram: entry.histogram,
      over_allocated: entry.over_allocated,
      over_allocated_histogram: entry.over_allocated_histogram
    };
    data[isolate].gcs[gc_id][data_set].overall += entry.overall;
    if (entry.overall !== 0) {
      data[isolate].gcs[gc_id][data_set].non_empty_instance_types.add(
          instance_type);
      data[isolate].gcs[gc_id].non_empty_instance_types.add(instance_type);
      data[isolate].non_empty_instance_types.add(instance_type);
    }
  }

  extendAndSanitizeModel(data) {
    const checkNonNegativeProperty = (obj, property) => {
      console.assert(obj[property] >= 0, 'negative property', obj, property);
    };

    Object.values(data).forEach(isolate => isolate.finalize());
  }

  createModelFromChromeTraceFile(contents) {
    const data = Object.create(null);  // Final data container.
    const parseOneGCEvent = (actual_data) => {
      Object.keys(actual_data).forEach(data_set => {
        const string_entry = actual_data[data_set];
        try {
          const entry = JSON.parse(string_entry);
          this.createOrUpdateEntryIfNeeded(data, entry);
          this.createDatasetIfNeeded(data, entry, data_set);
          const isolate = entry.isolate;
          const time = entry.time;
          const gc_id = entry.id;
          data[isolate].gcs[gc_id].time = time;

          const field_data = entry.field_data;
          this.addFieldTypeData(data, isolate, gc_id, data_set,
            field_data.tagged_fields,
            field_data.inobject_smi_fields,
            field_data.embedder_fields,
            field_data.unboxed_double_fields,
            field_data.boxed_double_fields,
            field_data.string_data,
            field_data.other_raw_fields);

          data[isolate].gcs[gc_id][data_set].bucket_sizes =
              entry.bucket_sizes;
          for (let [instance_type, value] of Object.entries(
                   entry.type_data)) {
            // Trace file format uses markers that do not have actual
            // properties.
            if (!('overall' in value)) continue;
            this.addInstanceTypeData(
                data, isolate, gc_id, data_set, instance_type, value);
          }
        } catch (e) {
          console.error('Unable to parse data set entry', e);
        }
      });
    };
    console.log(`Processing log as chrome trace file.`);
    try {
      let gc_events_filter = (event) => {
        if (event.name == 'V8.GC_Objects_Stats') {
          parseOneGCEvent(event.args);
        }
        return oboe.drop;
      };

      let oboe_stream = oboe();
      // Trace files support two formats.
      oboe_stream
          // 1) {traceEvents: [ data ]}
          .node('traceEvents.*', gc_events_filter)
          // 2) [ data ]
          .node('!.*', gc_events_filter)
          .fail(() => { throw new Error("Trace data parse failed!"); });
      oboe_stream.emit('data', contents);
    } catch (e) {
      console.error('Unable to parse chrome trace file.', e);
    }
    return data;
  }

  createModelFromV8TraceFile(contents) {
    console.log('Processing log as V8 trace file.');
    contents = contents.map(function(line) {
      try {
        // Strip away a potentially present adb logcat prefix.
        line = line.replace(/^I\/v8\s*\(\d+\):\s+/g, '');
        return JSON.parse(line);
      } catch (e) {
        console.log('Unable to parse line: \'' + line + '\' (' + e + ')');
      }
      return null;
    });

    const data = Object.create(null);  // Final data container.
    for (var entry of contents) {
      if (entry === null || entry.type === undefined) {
        continue;
      }
      if (entry.type === 'zone') {
        this.createOrUpdateEntryIfNeeded(data, entry);
        const stacktrace = ('stacktrace' in entry) ? entry.stacktrace : [];
        data[entry.isolate].samples.zone[entry.time] = {
          allocated: entry.allocated,
          pooled: entry.pooled,
          stacktrace: stacktrace
        };
      } else if (
          entry.type === 'zonecreation' || entry.type === 'zonedestruction') {
        this.createOrUpdateEntryIfNeeded(data, entry);
        data[entry.isolate].zonetags.push(
            Object.assign({opening: entry.type === 'zonecreation'}, entry));
      } else if (entry.type === 'gc_descriptor') {
        this.createOrUpdateEntryIfNeeded(data, entry);
        data[entry.isolate].gcs[entry.id].time = entry.time;
        if ('zone' in entry)
          data[entry.isolate].gcs[entry.id].malloced = entry.zone;
      } else if (entry.type === 'field_data') {
        this.createOrUpdateEntryIfNeeded(data, entry);
        this.createDatasetIfNeeded(data, entry, entry.key);
        this.addFieldTypeData(data, entry.isolate, entry.id, entry.key,
          entry.tagged_fields, entry.embedder_fields, entry.inobject_smi_fields,
          entry.unboxed_double_fields, entry.boxed_double_fields,
          entry.string_data, entry.other_raw_fields);
      } else if (entry.type === 'instance_type_data') {
        if (entry.id in data[entry.isolate].gcs) {
          this.createOrUpdateEntryIfNeeded(data, entry);
          this.createDatasetIfNeeded(data, entry, entry.key);
          this.addInstanceTypeData(
              data, entry.isolate, entry.id, entry.key,
              entry.instance_type_name, entry);
        }
      } else if (entry.type === 'bucket_sizes') {
        if (entry.id in data[entry.isolate].gcs) {
          this.createOrUpdateEntryIfNeeded(data, entry);
          this.createDatasetIfNeeded(data, entry, entry.key);
          data[entry.isolate].gcs[entry.id][entry.key].bucket_sizes =
              entry.sizes;
        }
      } else {
        console.log('Unknown entry type: ' + entry.type);
      }
    }
    return data;
  }
});
                                                                                                                                                                     node-23.7.0/deps/v8/tools/ic-processor                                                              0000775 0000000 0000000 00000002076 14746647661 0017550 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/bin/sh

# find the name of the log file to process, it must not start with a dash.
log_file="v8.log"
for arg in "$@"
do
  if ! expr "X${arg}" : "^X-" > /dev/null; then
    log_file=${arg}
  fi
done

tools_path=`cd $(dirname "$0");pwd`
if [ ! "$D8_PATH" ]; then
  d8_public=`which d8`
  if [ -x "$d8_public" ]; then
    D8_PATH=$(dirname "$d8_public");
  fi
fi
if [ -z ${D8_PATH##*/d8} ]; then
  d8_exec=$D8_PATH
else
  d8_exec=$D8_PATH/d8
fi

if [ ! -x "$d8_exec" ]; then
  for platform in x64 arm64 ia32; do
    for release in release optdebug debug; do
      if [ -x "$d8_exec" ]; then
        continue
      fi
      d8_exec="${tools_path}/../out/${platform}.${release}/d8";
    done
  done
fi

if [ ! -x "$d8_exec" ]; then
  d8_exec=`grep -m 1 -o '".*/d8"' $log_file | sed 's/"//g'`;
fi

if [ ! -x "$d8_exec" ]; then
  echo "d8 shell not found in $D8_PATH"
  echo "To build, execute 'make native' from the V8 directory"
  exit 1
fi

# nm spits out 'no symbols found' messages to stderr.
cat $log_file | $d8_exec \
  --module $tools_path/ic-processor-driver.mjs -- $@ 2>/dev/null
                                                                                                                                                                                                                                                                                                                                                                                                                                                                  node-23.7.0/deps/v8/tools/ic-processor-driver.mjs                                                   0000664 0000000 0000000 00000002306 14746647661 0021622 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2017 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

import { Processor } from "./system-analyzer/processor.mjs";
import { BaseArgumentsProcessor} from "./arguments.mjs";

class ArgumentsProcessor extends BaseArgumentsProcessor {
  getArgsDispatch() {
    return {
      '--range': [
          'range', 'auto,auto',
          'Specify the range limit as [start],[end]'
        ],
    };
  }
  getDefaultResults() {
   return {
      logFileName: 'v8.log',
      range: 'auto,auto',
    };
  }
}

const params = ArgumentsProcessor.process(arguments);
const processor = new Processor();
await processor.processLogFile(params.logFileName);

const typeAccumulator = new Map();

const accumulator = {
  __proto__: null,
  LoadGlobalIC: 0,
  StoreGlobalIC: 0,
  LoadIC: 0,
  StoreIC: 0,
  KeyedLoadIC: 0,
  KeyedStoreIC: 0,
  StoreInArrayLiteralIC: 0,
}
for (const ic of processor.icTimeline.all) {
  console.log(Object.values(ic));
  accumulator[ic.type]++;
}

console.log("========================================");
for (const key of Object.keys(accumulator)) {
  console.log(key + ": " + accumulator[key]);
}
                                                                                                                                                                                                                                                                                                                          node-23.7.0/deps/v8/tools/index.html                                                                0000664 0000000 0000000 00000005334 14746647661 0017207 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        <!DOCTYPE html>
<!-- Copyright 2020 the V8 project authors. All rights reserved.
Use of this source code is governed by a BSD-style license that can be
found in the LICENSE file. -->
<html lang="en" class="js dark">
<head>
<!-- This will be overwritten by the v8.dev/tools exporter -->
<!-- ANALYTICS_PLACEHOLDER -->
<meta charset="UTF-8">
<title>V8 Tools Landing Page</title>
<link href="//v8.dev/_css/main.css" rel="stylesheet">
<style>
.title {
  padding-left: 4em;
  line-height: 3em;
}
.grid-container {
  display: grid;
  grid-template-columns: auto auto auto;
  padding: auto;
  grid-gap: 15px;
}
.grid-2{
  grid-template-columns: auto auto;
}
.card {
  text-align: center;
  padding: 10px;
  background-color: #121212;
  width: auto;
  border-radius: 2px;
}
.card:hover {
  box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);
}
dd, dt {
  padding: 10px;
  margin: auto;
}
</style>
</head>
<body>
  <header id=header>
    <h1>
      <a class=v8 href="//v8.dev">V8</a>
    </h1>
    <nav>
      <ul>
        <li class=current><a href="">Tools</a></li>
        <li><a href="//v8.dev/tools/versions">Tools Versions</a></li>
        <li><a href="//v8.dev">Main Page</a></li>
      </ul>
    </nav>
  </header>
  <main id=main>
    <dl class="grid-container">
      <div class="card">
        <dt><a href="./system-analyzer/index.html">System Analyzer</a></dt>
        <dd>A unified web interface to trace, debug and analyse patterns of how Maps/ICs are created in the real world applications.</dd>
      </div>
      <div class="card">
        <dt><a href="./callstats.html">Callstats</a></dt>
        <dd>Visualize and compare runtime call stats.</dd>
      </div>
      <div class="card">
        <dt><a href="./heap-stats/index.html">Heap Stats</a></dt>
        <dd>Visualize heap memory usage.</dd>
      </div>
      <div class="card">
        <dt><a href="./heap-layout/index.html">Heap Layout</a></dt>
        <dd>Visualize heap memory layout.</dd>
      </div>
      <div class="card">
        <dt><a href="./parse-processor.html">Parse Processor</a></dt>
        <dd>Analyse parse, compile and first-execution.</dd>
      </div>
      <div class="card">
        <dt><a href="./profview/index.html">Profview</a></dt>
        <dd>Fancy sampling profile viewer.</dd>
      </div>
      <div class="card">
        <dt><a href="./turbolizer/index.html">Turbolizer</a></dt>
        <dd>Visualise the sea of nodes graph generated by TurboFan.</dd>
      </div>
      <div class="card">
        <dt><a href="./zone-stats/index.html">Zone Stats</a></dt>
        <dd>Analyse zone memory usage.</dd>
      </div>
    </dl>
    </main>
  <footer id=footer>
    <p>
    The sources of this page live on <a href="https://github.com/v8/tools">github</a>.
    </p>
  </footer>
 </body>
</html>
                                                                                                                                                                                                                                                                                                    node-23.7.0/deps/v8/tools/js/                                                                       0000775 0000000 0000000 00000000000 14746647661 0015621 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/js/helper.mjs                                                             0000664 0000000 0000000 00000004327 14746647661 0017621 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2021 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

export const KB = 1024;
export const MB = KB * KB;
export const GB = MB * KB;
export const kMillis2Seconds = 1 / 1000;
export const kMicro2Milli = 1 / 1000;

export function formatBytes(bytes, digits = 2) {
  const units = ['B', 'KiB', 'MiB', 'GiB'];
  const divisor = 1024;
  let index = 0;
  while (index < units.length && bytes >= divisor) {
    index++;
    bytes /= divisor;
  }
  return bytes.toFixed(digits) + units[index];
}

export function formatMicroSeconds(micro) {
  return (micro * kMicro2Milli).toFixed(1) + 'ms';
}

export function formatDurationMicros(micros, digits = 3) {
  return formatDurationMillis(micros * kMicro2Milli, digits);
}

export function formatMillis(millis, digits = 3) {
  return formatDurationMillis(millis, digits);
}

export function formatDurationMillis(millis, digits = 3) {
  if (millis < 1000) {
    if (millis < 1) {
      if (millis == 0) return (0).toFixed(digits) + 's';
      return (millis / kMicro2Milli).toFixed(digits) + 'ns';
    }
    return millis.toFixed(digits) + 'ms';
  }
  let seconds = millis / 1000;
  const hours = Math.floor(seconds / 3600);
  const minutes = Math.floor((seconds % 3600) / 60);
  seconds = seconds % 60;
  let buffer = '';
  if (hours > 0) buffer += hours + 'h ';
  if (hours > 0 || minutes > 0) buffer += minutes + 'm ';
  buffer += seconds.toFixed(digits) + 's';
  return buffer;
}

// Get the offset in the 4GB virtual memory cage.
export function calcOffsetInVMCage(address) {
  let mask = (1n << 32n) - 1n;
  let ret = Number(address & mask);
  return ret;
}

export function delay(time) {
  return new Promise(resolver => setTimeout(resolver, time));
}

export function defer() {
  let resolve_func, reject_func;
  const p = new Promise((resolve, reject) => {
    resolve_func = resolve;
    reject_func = resolve;
  });
  p.resolve = resolve_func;
  p.reject = reject_func;
  return p;
}

const kSimpleHtmlEscapeRegexp = /[\&\n><]/g;
function escaperFn(char) {
  return `&#${char.charCodeAt(0)};`;
}

export function simpleHtmlEscape(string) {
  return string.replace(kSimpleHtmlEscapeRegexp, escaperFn);
}
                                                                                                                                                                                                                                                                                                         node-23.7.0/deps/v8/tools/js/log-file-reader-template.html                                          0000664 0000000 0000000 00000004440 14746647661 0023260 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        <!-- Copyright 2021 the V8 project authors. All rights reserved.
Use of this source code is governed by a BSD-style license that can be
found in the LICENSE file. -->

<head>
  <link href="./index.css" rel="stylesheet" />
</head>
<style>
  #fileReader {
    height: 100px;
    line-height: 100px;
    text-align: center;
    cursor: pointer;
    transition: all 0.5s ease-in-out;
    background-color: var(--surface-color);
    border: solid 1px var(--file-reader-border-color);
    border-radius: 5px;
  }

  #fileReader:hover {
    background-color: var(--primary-color);
    color: var(--on-primary-color);
  }

  .done #fileReader {
    display: none;
  }

  .fail #fileReader {
    background-color: var(--error-color);
  }

  .loading #fileReader {
    cursor: wait;
  }

  #fileReader > input {
    display: none;
  }

  #loader {
    display: none;
    will-change: rotate;
  }

  .loading #loader {
    display: block;
    position: fixed;
    z-index: 9999;
    top: 0px;
    left: 0px;
    width: 100%;
    height: 100%;
    background-color: var(--file-reader-background-color);
  }

  #spinner, #progress, #progressText {
    position: absolute;
    width: 120px;
    height: 120px;
    top: 40%;
    left: 50%;
    margin-left: calc(-60px - 10px);
    border-radius: 50%;
  }
  #spinner {
    border: 20px solid var(--surface-color);
    border-top: 20px solid var(--primary-color);
    animation: spin 1s linear infinite;
    will-change: transform;
    transform: scale(1.1);
  }

  #progress, #progressText {
    padding: 20px;
  }

  #progress {
    transition: all 0.5s ease-in-out;
  }

  #progressText {
    line-height: 120px;
    font-size: 28px;
    transform: scale(0.55);
    text-align: center;
    vertical-align: middle;
    background-color:  var(--surface-color);
  }

  #label {
    user-select: none;
  }

  @keyframes spin {
    0% {
      transform: rotate(0deg);
    }

    100% {
      transform: rotate(360deg);
    }
  }
</style>
<div id="root">
  <div id="fileReader" class="panel" tabindex="1">
    <span id="label">
      Drag and drop a v8.log file into this area, or click to choose from disk.
    </span>
    <input id="file" type="file" name="file" />
  </div>
  <div id="loader">
    <div id="progress"></div>
    <div id="spinner"></div>
    <div id="progressText"></div>
  </div>
</div>
                                                                                                                                                                                                                                node-23.7.0/deps/v8/tools/js/web-api-helper.mjs                                                     0000664 0000000 0000000 00000017600 14746647661 0021141 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2021 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

import {delay, formatBytes} from './helper.mjs';

export class V8CustomElement extends HTMLElement {
  _updateTimeoutId;
  _updateCallback = this.forceUpdate.bind(this);

  constructor(templateText) {
    super();
    const shadowRoot = this.attachShadow({mode: 'open'});
    shadowRoot.innerHTML = templateText;
  }

  $(id) {
    return this.shadowRoot.querySelector(id);
  }

  querySelectorAll(query) {
    return this.shadowRoot.querySelectorAll(query);
  }

  requestUpdate(useAnimation = false) {
    if (useAnimation) {
      window.cancelAnimationFrame(this._updateTimeoutId);
      this._updateTimeoutId =
          window.requestAnimationFrame(this._updateCallback);
    } else {
      // Use timeout tasks to asynchronously update the UI without blocking.
      clearTimeout(this._updateTimeoutId);
      const kDelayMs = 5;
      this._updateTimeoutId = setTimeout(this._updateCallback, kDelayMs);
    }
  }

  forceUpdate() {
    this._updateTimeoutId = undefined;
    this._update();
  }

  _update() {
    throw Error('Subclass responsibility');
  }

  get isFocused() {
    return document.activeElement === this;
  }
}

export class FileReader extends V8CustomElement {
  constructor(templateText) {
    super(templateText);
    this.addEventListener('click', this.handleClick.bind(this));
    this.addEventListener('dragover', this.handleDragOver.bind(this));
    this.addEventListener('drop', this.handleChange.bind(this));
    this.$('#file').addEventListener('change', this.handleChange.bind(this));
    this.fileReader = this.$('#fileReader');
    this.fileReader.addEventListener('keydown', this.handleKeyEvent.bind(this));
    this.progressNode = this.$('#progress');
    this.progressTextNode = this.$('#progressText');
  }

  set error(message) {
    this._updateLabel(message);
    this.root.className = 'fail';
  }

  _updateLabel(text) {
    this.$('#label').innerText = text;
  }

  handleKeyEvent(event) {
    if (event.key == 'Enter') this.handleClick(event);
  }

  handleClick(event) {
    this.$('#file').click();
  }

  handleChange(event) {
    // Used for drop and file change.
    event.preventDefault();
    const host = event.dataTransfer ? event.dataTransfer : event.target;
    this.readFile(host.files[0]);
  }

  handleDragOver(event) {
    event.preventDefault();
  }

  connectedCallback() {
    this.fileReader.focus();
  }

  get root() {
    return this.$('#root');
  }

  setProgress(progress, processedBytes = 0) {
    this.progress = Math.max(0, Math.min(progress, 1));
    this.processedBytes = processedBytes;
  }

  updateProgressBar() {
    // Create a circular progress bar, starting at 12 o'clock.
    this.progressNode.style.backgroundImage = `conic-gradient(
          var(--primary-color) 0%,
          var(--primary-color) ${this.progress * 100}%,
          var(--surface-color) ${this.progress * 100}%)`;
    this.progressTextNode.innerText =
        this.processedBytes ? formatBytes(this.processedBytes, 1) : '';
    if (this.root.className == 'loading') {
      window.requestAnimationFrame(() => this.updateProgressBar());
    }
  }

  readFile(file) {
    this.dispatchEvent(new CustomEvent('fileuploadstart', {
      bubbles: true,
      composed: true,
      detail: {
        progressCallback: this.setProgress.bind(this),
        totalSize: file.size,
      }
    }));
    if (!file) {
      this.error = 'Failed to load file.';
      return;
    }
    this.fileReader.blur();
    this.setProgress(0);
    this.root.className = 'loading';
    // Delay the loading a bit to allow for CSS animations to happen.
    window.requestAnimationFrame(() => this.asyncReadFile(file));
  }

  async asyncReadFile(file) {
    this.updateProgressBar();
    const decoder = globalThis.TextDecoderStream;
    if (decoder) {
      await this._streamFile(file, decoder);
    } else {
      await this._readFullFile(file);
    }
    this._updateLabel(`Finished loading '${file.name}'.`);
    this.dispatchEvent(
        new CustomEvent('fileuploadend', {bubbles: true, composed: true}));
    this.root.className = 'done';
  }

  async _readFullFile(file) {
    const text = await file.text();
    this._handleFileChunk(text);
  }

  async _streamFile(file, decoder) {
    const stream = file.stream().pipeThrough(new decoder());
    const reader = stream.getReader();
    let chunk, readerDone;
    do {
      const readResult = await reader.read();
      chunk = readResult.value;
      readerDone = readResult.done;
      if (!chunk) break;
      this._handleFileChunk(chunk);
      // Artificial delay to allow for layout updates.
      await delay(5);
    } while (!readerDone);
  }

  _handleFileChunk(chunk) {
    this.dispatchEvent(new CustomEvent('fileuploadchunk', {
      bubbles: true,
      composed: true,
      detail: chunk,
    }));
  }
}

export class DOM {
  static element(type, options) {
    const node = document.createElement(type);
    if (options === undefined) return node;
    if (typeof options === 'string') {
      // Old behaviour: options = class string
      node.className = options;
    } else if (Array.isArray(options)) {
      // Old behaviour: options = class array
      DOM.addClasses(node, options);
    } else {
      // New behaviour: options = attribute dict
      for (const [key, value] of Object.entries(options)) {
        if (key == 'className') {
          node.className = value;
        } else if (key == 'classList') {
          DOM.addClasses(node, value);
        } else if (key == 'textContent') {
          node.textContent = value;
        } else if (key == 'children') {
          for (const child of value) {
            node.appendChild(child);
          }
        } else {
          node.setAttribute(key, value);
        }
      }
    }
    return node;
  }

  static addClasses(node, classes) {
    const classList = node.classList;
    if (typeof classes === 'string') {
      classList.add(classes);
    } else {
      for (let i = 0; i < classes.length; i++) {
        classList.add(classes[i]);
      }
    }
    return node;
  }

  static text(string) {
    return document.createTextNode(string);
  }

  static button(label, clickHandler) {
    const button = DOM.element('button');
    button.innerText = label;
    if (typeof clickHandler != 'function') {
      throw new Error(
          `DOM.button: Expected function but got clickHandler=${clickHandler}`);
    }
    button.onclick = clickHandler;
    return button;
  }

  static div(options) {
    return this.element('div', options);
  }

  static span(options) {
    return this.element('span', options);
  }

  static table(options) {
    return this.element('table', options);
  }

  static tbody(options) {
    return this.element('tbody', options);
  }

  static td(textOrNode, className) {
    const node = this.element('td');
    if (typeof textOrNode === 'object') {
      node.appendChild(textOrNode);
    } else if (textOrNode) {
      node.innerText = textOrNode;
    }
    if (className) node.className = className;
    return node;
  }

  static tr(classes) {
    return this.element('tr', classes);
  }

  static removeAllChildren(node) {
    let range = document.createRange();
    range.selectNodeContents(node);
    range.deleteContents();
  }

  static defineCustomElement(
      path, nameOrGenerator, maybeGenerator = undefined) {
    let generator = nameOrGenerator;
    let name = nameOrGenerator;
    if (typeof nameOrGenerator == 'function') {
      console.assert(maybeGenerator === undefined);
      name = path.substring(path.lastIndexOf('/') + 1, path.length);
    } else {
      console.assert(typeof nameOrGenerator == 'string');
      generator = maybeGenerator;
    }
    path = path + '-template.html';
    fetch(path)
        .then(stream => stream.text())
        .then(
            templateText =>
                customElements.define(name, generator(templateText)));
  }
}
                                                                                                                                node-23.7.0/deps/v8/tools/jsfunfuzz/                                                                0000775 0000000 0000000 00000000000 14746647661 0017251 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/jsfunfuzz/BUILD.gn                                                        0000664 0000000 0000000 00000000643 14746647661 0020441 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # Copyright 2018 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

import("../../gni/v8.gni")

group("v8_jsfunfuzz") {
  testonly = true

  data_deps = [
    "../..:d8",
  ]

  data = [
    # Grab current directory. This avoids adding logic for checking the
    # existence of the jsfunfuzz subdirectory.
    "./",
  ]
}
                                                                                             node-23.7.0/deps/v8/tools/jsfunfuzz/fuzz-harness.sh                                                 0000775 0000000 0000000 00000005462 14746647661 0022256 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/bin/bash
# Copyright 2016 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

# A simple harness that downloads and runs 'jsfunfuzz' against d8. This
# takes a long time because it runs many iterations and is intended for
# automated usage. The package containing 'jsfunfuzz' can be found as an
# attachment to this bug:
# https://bugzilla.mozilla.org/show_bug.cgi?id=jsfunfuzz

JSFUNFUZZ_URL="https://bugzilla.mozilla.org/attachment.cgi?id=310631"
JSFUNFUZZ_MD5="d0e497201c5cd7bffbb1cdc1574f4e32"

v8_root=$(readlink -f $(dirname $BASH_SOURCE)/../../)
jsfunfuzz_dir="$v8_root/tools/jsfunfuzz"
cd "$jsfunfuzz_dir"

if [ -n "$1" ]; then
  d8="${v8_root}/$1"
else
  d8="${v8_root}/d8"
fi

if [ ! -f "$d8" ]; then
  echo "Failed to find d8 binary: $d8"
  exit 1
fi

# Deprecated download method. A prepatched archive is downloaded as a hook
# if jsfunfuzz=1 is specified as a gyp flag. Requires google.com authentication
# for google storage.
if [ "$3" == "--download" ]; then

  jsfunfuzz_file="$v8_root/tools/jsfunfuzz.zip"
  if [ ! -f "$jsfunfuzz_file" ]; then
    echo "Downloading $jsfunfuzz_file ..."
    wget -q -O "$jsfunfuzz_file" $JSFUNFUZZ_URL || exit 1
  fi

  jsfunfuzz_sum=$(md5sum "$jsfunfuzz_file" | awk '{ print $1 }')
  if [ $jsfunfuzz_sum != $JSFUNFUZZ_MD5 ]; then
    echo "Failed to verify checksum!"
    exit 1
  fi

  if [ ! -d "$jsfunfuzz_dir" ]; then
    echo "Unpacking into $jsfunfuzz_dir ..."
    unzip "$jsfunfuzz_file" -d "$jsfunfuzz_dir" || exit 1
    echo "Patching runner ..."
    cat << EOF | patch -s -p0 -d "$v8_root"
--- tools/jsfunfuzz/jsfunfuzz/multi_timed_run.py~
+++ tools/jsfunfuzz/jsfunfuzz/multi_timed_run.py
@@ -118,19 +118,19 @@
-def showtail(logfilename):
+def showtail(logfilename, method="tail"):
-   cmd = "tail -n 20 %s" % logfilename
+   cmd = "%s -n 20 %s" % (method, logfilename)
    print cmd
    print ""
    os.system(cmd)
    print ""
    print ""

 def many_timed_runs():
     iteration = 0
-    while True:
+    while iteration < 100:
         iteration += 1
         logfilename = "w%d" % iteration
         one_timed_run(logfilename)
         if not succeeded(logfilename):
             showtail(logfilename)
-            showtail("err-" + logfilename)
+            showtail("err-" + logfilename, method="head")

             many_timed_runs()
EOF
  fi

fi

flags='--expose-gc --verify-gc'
python -u "$jsfunfuzz_dir/jsfunfuzz/multi_timed_run.py" 300 \
    "$d8" $flags "$jsfunfuzz_dir/jsfunfuzz/jsfunfuzz.js"
exit_code=$(cat w* | grep " looking good" -c)
exit_code=$((100-exit_code))

if [ -n "$2" ]; then
  archive="$2"
else
  archive=fuzz-results-$(date +%Y%m%d%H%M%S).tar.bz2
fi
echo "Creating archive $archive"
tar -cjf $archive err-* w*
rm -f err-* w*

echo "Total failures: $exit_code"
exit $exit_code
                                                                                                                                                                                                              node-23.7.0/deps/v8/tools/jsfunfuzz/jsfunfuzz.tar.gz.sha1                                           0000664 0000000 0000000 00000000050 14746647661 0023272 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        936f3baf5a24313da5eb98195d5e01d76fe602fb                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        node-23.7.0/deps/v8/tools/link_clicker.extension/                                                   0000775 0000000 0000000 00000000000 14746647661 0021651 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/link_clicker.extension/README.txt                                         0000664 0000000 0000000 00000001141 14746647661 0023344 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        This extension can be used to repro infrequent crashers on an unclear url-set
for a given domain. It follows a random link that matches a predefined pattern,
imitating something like real user interaction on a page.

Usage:
1. Open chrome://extensions
2. Enable developer mode
3. Click "Load unpacked extension"
4. Click the orange link-clicker extension button in the toolbar
5. Set the parameters and click "Enable" to start following links on all tabs
   open in the current window. Beware, this extension will follow arbitrary
   links. You probably don't want to be logged in with any important account.
                                                                                                                                                                                                                                                                                                                                                                                                                               node-23.7.0/deps/v8/tools/link_clicker.extension/background.js                                      0000664 0000000 0000000 00000004052 14746647661 0024327 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2017 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

(function linkClickerBackgroundScript() {

  // time in ms.
  let minInterval = 1*1000;
  let maxInterval = 20*1000;
  let pattern = /.*/;
  let enabled = false;

  let animateIconIntervalId;

  // ===========================================================================

  chrome.runtime.onMessage.addListener(function(msg, sender, response) {
    let result;
    if (msg.type == 'update') result = updateFromMessage(msg);
    if (msg.type == 'get') result = getValues();
    response(result);
  });

  // ===========================================================================
  function updateFromMessage(msg) {
    console.log(msg);
    minInterval = Number(msg.minInterval)
    maxInterval = Number(msg.maxInterval);
    if (maxInterval < minInterval) {
      let tmpMin = Math.min(minInterval, maxInterval);
      maxInterval = Math.max(minInterval, maxInterval);
      minInterval = tmpMin;
    }
    pattern = new RegExp(msg.pattern);
    enabled = Boolean(msg.enabled);
    updateTabs();
    scheduleIconAnimation();
    return getValues();
  }

  function getValues() {
    return {
      type: 'update',
      minInterval: minInterval,
      maxInterval: maxInterval,
      pattern: pattern.source,
      enabled: enabled
    }
  }

  function updateTabs() {
    chrome.tabs.query({active: true, currentWindow: true}, function(tabs) {
      let message = getValues();
      for (let i = 0; i < tabs.length; ++i) {
        chrome.tabs.sendMessage(tabs[i].id, message);
      }
    });
  }

  let animationIndex = 0;
  function animateIcon() {
    animationIndex = (animationIndex + 1) % 4;
    chrome.browserAction.setBadgeText( { text: ".".repeat(animationIndex) } );
  }

  function scheduleIconAnimation() {
    chrome.browserAction.setBadgeText( { text: "" } );
    clearInterval(animateIconIntervalId);
    if (enabled) {
      animateIconIntervalId = setInterval(animateIcon, 500);
    }
  }

})();
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      node-23.7.0/deps/v8/tools/link_clicker.extension/content.js                                         0000664 0000000 0000000 00000003471 14746647661 0023666 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2017 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

(function linkClickerContentScript() {
  // time in ms
  let minInterval;
  let maxInterval;
  let pattern;
  let enabled;
  let timeoutId;

  // Initialize variables.
  chrome.runtime.sendMessage({type:'get'}, function(msg) {
    if (msg.type == 'update') updateFromMessage(msg);
  });

  chrome.runtime.onMessage.addListener(
    function(msg, sender, sendResponse) {
      if (msg.type == 'update') updateFromMessage(msg);
    });

  function findAllLinks() {
    let links = document.links;
    let results = new Set();
    for (let i = 0; i < links.length; i++) {
      let href = links[i].href;
      if (!href) continue;
      if (href && href.match(pattern)) results.add(href);
    }
    return Array.from(results);
  }

  function updateFromMessage(msg) {
    console.log(msg);
    minInterval = Number(msg.minInterval)
    maxInterval = Number(msg.maxInterval);
    pattern = new RegExp(msg.pattern);
    enabled = Boolean(msg.enabled);
    if (enabled) schedule();
  }

  function followLink() {
    if (!enabled) return;
    let links = findAllLinks();
    if (links.length <= 5) {
      // navigate back if the page has not enough links
      window.history.back()
      console.log("navigate back");
    } else {
      let link = links[Math.round(Math.random() * (links.length-1))];
      console.log(link);
      window.location.href = link;
      // Schedule in case we just followed an anchor.
      schedule();
    }
  }

  function schedule() {
    clearTimeout(timeoutId);
    let delta = maxInterval - minInterval;
    let duration = minInterval + (Math.random() * delta);
    console.log(duration);
    timeoutId = setTimeout(followLink, duration);
  }
})();
                                                                                                                                                                                                       node-23.7.0/deps/v8/tools/link_clicker.extension/icon.png                                           0000664 0000000 0000000 00000000346 14746647661 0023312 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        PNG

   IHDR         a   bKGD      IDAT80E}4bQ(; :@W`rw1R["3c(=Llk].F3Id{lbk;"E(QzFUN(zLcv
bbx2u~t>}*    IENDB`                                                                                                                                                                                                                                                                                          node-23.7.0/deps/v8/tools/link_clicker.extension/manifest.json                                      0000664 0000000 0000000 00000001034 14746647661 0024350 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        {
  "name": "A browser action with a popup that automatically clicks links matching a regexp",
  "description": "Follow links",
  "version": "1.0",
  "permissions": [
    "tabs", "http://*/*", "https://*/*"
  ],
  "background": { "scripts": ["background.js"] },
  "browser_action": {
      "default_title": "Follow links.",
      "default_icon": "icon.png",
      "default_popup": "popup.html"
  },
  "content_scripts": [
    {
      "matches": ["http://*/*", "https://*/*"],
      "js": ["content.js"]
    }
  ],
  "manifest_version": 2
}
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    node-23.7.0/deps/v8/tools/link_clicker.extension/popup.html                                         0000664 0000000 0000000 00000002154 14746647661 0023704 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        <!doctype html>
<!--
Copyright 2017 the V8 project authors. All rights reserved.
Use of this source code is governed by a BSD-style license that can be
found in the LICENSE file.
-->
<html>
  <head>
    <style>
    body {
      overflow: hidden;
      padding: 5px;
      width: 310px;
    }
    input, textarea, select, button {
      width : 300px;
      margin: 0;
      box-sizing: border-box;
    }
    label {
      clear: both;
    }
    </style>
    <script src="popup.js"></script>
  </head>
  <body>
    <form>
      <p>
        <label>Min click-interval <span id="minIntervalValue"></span>:
          <input type="range" id="minInterval" min="1000" max="60000">
        </label>
      </p>
      <p>
        <label> Max click-interval <span id="maxIntervalValue"></span>:
          <input type="range" id="maxInterval" min="1000" max="60000">
        </label>
      </p>
      <p>
        <label>Link regexp:
          <input type="input" id="pattern" >
        </label>
      </p>
      <p>
        <label>Enable:
          <input type="checkbox" id="enabled" >
        </label>
      </p>
    </form>
  </body>
</html>
                                                                                                                                                                                                                                                                                                                                                                                                                    node-23.7.0/deps/v8/tools/link_clicker.extension/popup.js                                           0000664 0000000 0000000 00000002750 14746647661 0023356 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2017 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

function $(id) {
  return document.querySelector(id);
}

// ===========================================================================
document.addEventListener('DOMContentLoaded', function () {
  installFormChangeHandler()
});


function installFormChangeHandler() {
  initForm();
  let inputs = document.getElementsByTagName("input");
  for (let i = 0; i < inputs.length; i++){
     inputs[i].onchange = onFormChange;
  }
}

function initForm() {
  chrome.runtime.sendMessage({type:'get'}, function(response) {
    updateFromMessage(response);
  });
}
// ===========================================================================

function updateFromMessage(msg) {
  $("#minInterval").value = msg.minInterval;
  $("#maxInterval").value = msg.maxInterval;
  $("#pattern").value = msg.pattern;
  $("#enabled").checked = msg.enabled;
  $("#minIntervalValue").innerText = msg.minInterval+"ms";
  $("#maxIntervalValue").innerText = msg.maxInterval+"ms";
}

function onFormChange() {
  let minInterval = $("#minInterval").value;
  let maxInterval = $("#maxInterval").value;

  let message = {
    type: 'update',
    minInterval: minInterval,
    maxInterval: maxInterval,
    pattern: $("#pattern").value,
    enabled: $("#enabled").checked
  }
  chrome.runtime.sendMessage(message, function(response) {
    updateFromMessage(response);
  });
}
                        node-23.7.0/deps/v8/tools/linux-tick-processor                                                      0000775 0000000 0000000 00000002113 14746647661 0021234 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/bin/sh

# find the name of the log file to process, it must not start with a dash.
log_file="v8.log"
for arg in "$@"
do
  if ! expr "X${arg}" : "^X-" > /dev/null; then
    log_file=${arg}
  fi
done

tools_path=`cd $(dirname "$0");pwd`
if [ ! "$D8_PATH" ]; then
  d8_public=`which d8`
  if [ -x "$d8_public" ]; then
    D8_PATH=$(dirname "$d8_public");
  fi
fi
if [ -z ${D8_PATH##*/d8} ]; then
  d8_exec=$D8_PATH
else
  d8_exec=$D8_PATH/d8
fi

if [ ! -x "$d8_exec" ]; then
  for platform in x64 arm64 ia32; do
    for release in release optdebug debug; do
      if [ -x "$d8_exec" ]; then
        continue
      fi
      d8_exec="${tools_path}/../out/${platform}.${release}/d8";
    done
  done
fi

if [ ! -x "$d8_exec" ]; then
  d8_exec=`grep -m 1 -o '".*/d8"' $log_file | sed 's/"//g'`;
fi

if [ ! -x "$d8_exec" ]; then
  echo "d8 shell not found in $D8_PATH" >&2;
  echo "Please provide path to d8 as env var in D8_PATH" >&2;
  exit 1;
fi

# nm spits out 'no symbols found' messages to stderr.
cat $log_file | $d8_exec --enable-os-system \
  --module $tools_path/tickprocessor-driver.mjs -- $@
                                                                                                                                                                                                                                                                                                                                                                                                                                                     node-23.7.0/deps/v8/tools/lldb_commands.py                                                          0000664 0000000 0000000 00000016633 14746647661 0020366 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # Copyright 2017 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

# Load this file by adding this to your ~/.lldbinit:
# command script import <this_dir>/lldb_commands.py

# for py2/py3 compatibility
from __future__ import print_function

import os
import re

import lldb

#####################
# Helper functions. #
#####################

def current_thread(debugger):
  return debugger.GetSelectedTarget().GetProcess().GetSelectedThread()

def current_frame(debugger):
  return current_thread(debugger).GetSelectedFrame()


def no_arg_cmd(debugger, cmd, print_error=True):
  cast_to_void_expr = '(void) {}'.format(cmd)
  evaluate_result = current_frame(debugger).EvaluateExpression(cast_to_void_expr)
  # When a void function is called the return value type is 0x1001 which
  # is specified in http://tiny.cc/bigskz. This does not indicate
  # an error so we check for that value below.
  kNoResult = 0x1001
  result = evaluate_result.GetError()
  is_success = not result.fail or result.value == kNoResult
  if not is_success:
    if print_error:
      print("Failed to evaluate command {} :".format(cmd))
      print(result.description)
  else:
    print("")
  return (is_success, result, cmd)


def ptr_arg_cmd(debugger, name, param, cmd, print_error=True):
  if not param:
    print("'{}' requires an argument".format(name))
    return (False, None, "")
  param = '(void*)({})'.format(param)
  return no_arg_cmd(debugger, cmd.format(param), print_error)


def print_handle(debugger, command_name, param, print_func):
  value = current_frame(debugger).EvaluateExpression(param)
  error = value.GetError()
  if error.fail:
    print("Error evaluating {}\n{}".format(param, error))
    return (False, error, "")
  # Attempt to print, ignoring visualizers if they are enabled
  result = print_func(value.GetNonSyntheticValue())
  if not result[0]:
    print("{} cannot print a value of type {}".format(command_name,
                                                      value.type.name))
  return result


def print_direct(debugger, command_name, value):
  CMD = "_v8_internal_Print_Object((v8::internal::Address*)({}))"
  return ptr_arg_cmd(debugger, command_name, value, CMD.format(value))


def print_indirect(debugger, command_name, value):
  CMD = "_v8_internal_Print_Object(*(v8::internal::Object**)({}))"
  return ptr_arg_cmd(debugger, command_name, value, CMD.format(value))


V8_LLDB_COMMANDS = []


def lldbCommand(fn):
  V8_LLDB_COMMANDS.append(fn.__name__)
  return fn


#####################
# lldb commands.    #
#####################

@lldbCommand
def job(debugger, param, *args):
  """Print a v8 heap object"""
  ptr_arg_cmd(debugger, 'job', param, "_v8_internal_Print_Object({})")


@lldbCommand
def jh(debugger, param, *args):
  """Print v8::internal::(Maybe)?(Direct|Indirect)?Handle value"""

  def print_func(value):
    # Indirect handles contain a location_.
    field = value.GetValueForExpressionPath(".location_")
    if field.IsValid():
      return print_indirect(debugger, 'jh', field.value)
    # Direct handles contain a obj_.
    field = value.GetValueForExpressionPath(".obj_")
    if field.IsValid():
      return print_indirect(debugger, 'jh', field.value)
    # We don't know how to print this...
    return (False, None, "")

  return print_handle(debugger, 'jh', param, print_func)


@lldbCommand
def jlh(debugger, param, *args):
  """Print v8::(Maybe)?Local value"""

  def print_func(value):
    # After https://crrev.com/c/4335544, v8::MaybeLocal contains a local_.
    field = value.GetValueForExpressionPath(".local_")
    if field.IsValid():
      value = field
    # After https://crrev.com/c/4335544, v8::Local contains a location_.
    field = value.GetValueForExpressionPath(".location_")
    if field.IsValid():
      return print_indirect(debugger, 'jlh', field.value)
    # Before https://crrev.com/c/4335544, v8::Local contained a val_.
    field = value.GetValueForExpressionPath(".val_")
    if field.IsValid():
      return print_indirect(debugger, 'jlh', field.value)
    # With v8_enable_direct_handle=true, v8::Local contains a ptr_.
    field = value.GetValueForExpressionPath(".ptr_")
    if field.IsValid():
      return print_direct(debugger, 'jlh', field.value)
    # We don't know how to print this...
    return (False, None, "")

  return print_handle(debugger, 'jlh', param, print_func)


@lldbCommand
def jl(debugger, param, *args):
  """Print v8::Local handle value"""
  return jlh(debugger, param, *args)


@lldbCommand
def jco(debugger, param, *args):
  """Print the code object at the given pc (default: current pc)"""
  if not param:
    param = str(current_frame(debugger).FindRegister("pc").value)
  ptr_arg_cmd(debugger, 'jco', param, "_v8_internal_Print_Code({})")


@lldbCommand
def jtt(debugger, param, *args):
  """Print the transition tree of a v8 Map"""
  ptr_arg_cmd(debugger, 'jtt', param, "_v8_internal_Print_TransitionTree({})")


@lldbCommand
def jst(debugger, *args):
  """Print the current JavaScript stack trace"""
  no_arg_cmd(debugger, "_v8_internal_Print_StackTrace()")


@lldbCommand
def jss(debugger, *args):
  """Skip the jitted stack on x64 to where we entered JS last"""
  frame = current_frame(debugger)
  js_entry_sp = frame.EvaluateExpression(
      "v8::internal::Isolate::Current()->thread_local_top()->js_entry_sp_;") \
       .GetValue()
  sizeof_void = frame.EvaluateExpression("sizeof(void*)").GetValue()
  rbp = frame.FindRegister("rbp")
  rsp = frame.FindRegister("rsp")
  pc = frame.FindRegister("pc")
  rbp = js_entry_sp
  rsp = js_entry_sp + 2 *sizeof_void
  pc.value = js_entry_sp + sizeof_void


@lldbCommand
def bta(debugger, *args):
  """Print stack trace with assertion scopes"""
  func_name_re = re.compile("([^(<]+)(?:\(.+\))?")
  assert_re = re.compile(
      "^v8::internal::Per\w+AssertType::(\w+)_ASSERT, (false|true)>")
  thread = current_thread(debugger)
  for frame in thread:
    functionSignature = frame.GetDisplayFunctionName()
    if functionSignature is None:
      continue
    functionName = func_name_re.match(functionSignature)
    line = frame.GetLineEntry().GetLine()
    sourceFile = frame.GetLineEntry().GetFileSpec().GetFilename()
    if line:
      sourceFile = sourceFile + ":" + str(line)

    if sourceFile is None:
      sourceFile = ""
    print("[%-2s] %-60s %-40s" % (frame.GetFrameID(),
                                  functionName.group(1),
                                  sourceFile))
    match = assert_re.match(str(functionSignature))
    if match:
      if match.group(3) == "false":
        prefix = "Disallow"
        color = "\033[91m"
      else:
        prefix = "Allow"
        color = "\033[92m"
      print("%s -> %s %s (%s)\033[0m" % (
          color, prefix, match.group(2), match.group(1)))

def setup_source_map_for_relative_paths(debugger):
  # Copied from Chromium's tools/lldb/lldbinit.py.
  # When relative paths are used for debug symbols, lldb cannot find source
  # files. Set up a source map to point to V8's root.
  this_dir = os.path.dirname(os.path.abspath(__file__))
  source_dir = os.path.join(this_dir, os.pardir)

  debugger.HandleCommand(
    'settings set target.source-map ../.. ' + source_dir)


def __lldb_init_module(debugger, dict):
  setup_source_map_for_relative_paths(debugger)
  debugger.HandleCommand('settings set target.x86-disassembly-flavor intel')
  for cmd in V8_LLDB_COMMANDS:
    debugger.HandleCommand(
      'command script add -f lldb_commands.{} {}'.format(cmd, cmd))
                                                                                                     node-23.7.0/deps/v8/tools/lldb_visualizers.py                                                       0000664 0000000 0000000 00000025552 14746647661 0021145 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # Copyright 2023 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

# Load this file by adding this to your ~/.lldbinit or your launch.json:
# command script import <this_dir>/lldb_visualizers.py

# for py2/py3 compatibility
from __future__ import print_function

import collections
import functools
import re
import traceback

import lldb

######################
# custom visualizers #
######################


def lazy_unsigned_expression(expr):
  sb_value = None
  uint_value = 0

  def getter(fromValue):
    nonlocal sb_value
    nonlocal uint_value
    if sb_value is None:
      sb_value = fromValue.CreateValueFromExpression(expr, expr)
      uint_value = sb_value.GetValueAsUnsigned()
    return uint_value

  return getter


def lazy_unsigned_constant(name):
  return lazy_unsigned_expression('v8::internal::' + name)


# Values to only evaluate once
FrameSummary_Kind_JAVA_SCRIPT = lazy_unsigned_constant(
    'FrameSummary::Kind::JAVA_SCRIPT')


def field_from_address(parent_value, offset_getter, name, typename=None):
  addr = parent_value.GetValueAsUnsigned()
  try:
    tag_mask = kHeapObjectTagMask(parent_value)
    if (addr & tag_mask) == kHeapObjectTag(parent_value):
      heap_base = V8HeapCompressionScheme_base_(parent_value)
      if (addr & ~(kPtrComprCageBaseAlignment(parent_value) - 1)) == heap_base:
        field_address = (addr & ~tag_mask) + offset_getter(parent_value)
        if typename is None:
          return parent_value.CreateValueFromExpression(
              name, '(%s | (unsigned long)(*(int*)(%s)))' %
              (heap_base, field_address))
        else:
          return parent_value.CreateValueFromExpression(
              name, '*(%s *)%s' % (typename, field_address))
  except:
    print(traceback.format_exc())

  return None


class DictProvider:
  updating_for_formatter = False

  def __init__(self):
    self.children = None
    self.name_to_index = None
    self.update_only_for_formatter = False

  def populate_children(self, mapping):
    raise "Not implemented"

  def update(self):
    if self.update_only_for_formatter and not DictProvider.updating_for_formatter:
      return
    if DictProvider.updating_for_formatter:
      # in the future, only update when updating for formatter
      self.update_only_for_formatter = True
      # update only once
      DictProvider.updating_for_formatter = False
    self.children = None
    self.name_to_index = None

  def ensure_populated(self):
    if self.children is None:
      try:
        new_dict = collections.OrderedDict()
        self.populate_children(new_dict)
        self.children = list(new_dict.values())
        self.name_to_index = {k: v for (v, k) in enumerate(new_dict.keys())}
      except:
        print(traceback.format_exc())

  def num_children(self):
    self.ensure_populated()
    return len(self.children)

  def has_children(self):
    return True

  def get_child_index(self, name):
    self.ensure_populated()
    return self.name_to_index.get(name, None)

  def get_child_at_index(self, index):
    self.ensure_populated()
    return self.children[index]()


# Parse printed properties. May be a named property (rendered like " - name: val")
# or a list index (rendered like "    0: val"). If line ends with '{', it is a
# multiline property expected to continue until a line ends with '}'.
CHILD_RE = re.compile(
    r'((?<=^ - )[^:]+|(?<=\n    ) *[0-9]+): (.*(?:[^\{]|\{\n(?:.*\n)+.*\}))$',
    re.MULTILINE)
# Parse an address out of a value, so we can create an object that can be further
# expanded. Note that some things like Oddballs aren't worth trying to expand.
ADDRESS_RE = re.compile(
    r'^(?:\[[^\]]+\] )?(0x[0-9a-fA-F]{8,16})(?: (?!\[(?:Oddball|String)\]|\<(?:Symbol:|Code BUILTIN) .+\>).*)?$'
)
NUMERIC_RE = re.compile(r'^-?[0-9\.]+([eE][+\-]?[0-9]+)?$')
PROPERTY_RE = re.compile(r'    (0x(?:[^:]|:(?! 0x))+): (.+)$')
OBJECT_DUMP_NAME = '[Dump]'


def make_string(parent, pystring, name):
  # Planning on python string representations being valid C/C++
  # However, python repr usually gives single quoted reprs and we need double quotes
  converted = '"%s"' % repr(pystring)[1:-1].replace('"', '\\"')
  return parent.CreateValueFromExpression(name, converted)


def get_string_value(valobj):
  # Count on existing std::string visualizer to give us a summary so we don't
  # need to do valobj.__r_.__value_.__l.__data_
  summary = valobj.GetSummary()
  if summary and len(summary) >= 2 and summary[0] == '"' and summary[-1] == '"':
    # Also count on the std::string summary being a valid python string
    # representation.
    return eval(summary)
  return None


def make_synthetic_field(parent, summary, name):
  m = ADDRESS_RE.match(summary)
  if m:
    return parent.CreateValueFromExpression(
        name, '_v8_internal_Get_Object((void *)%s)' % m.group(1))
  elif NUMERIC_RE.match(summary):
    return parent.CreateValueFromExpression(name, summary)
  else:
    # Fallback to creating a C string of the dumped text
    return make_string(parent, summary, name)


class HeapObjectChildrenProvider(DictProvider):

  def __init__(self, valobj, internal_dict):
    self.valueobject = valobj
    super().__init__()

  def populate_children(self, mapping):
    expression = ('_v8_internal_Print_Object_To_String((void *)%s)' %
                  self.valueobject.GetValueAsUnsigned())
    dump = self.valueobject.CreateValueFromExpression(OBJECT_DUMP_NAME,
                                                      expression)
    stringdump = get_string_value(dump)
    if stringdump:
      for (name, val) in CHILD_RE.findall(stringdump):
        if val.startswith('{\n') and val.endswith('\n }') and name.find(
            'properties') >= 0:
          for index, line in enumerate(val.splitlines()[1:-1]):
            m = PROPERTY_RE.match(line)
            if m:
              mapping[m.group(1)] = functools.partial(make_synthetic_field,
                                                      self.valueobject,
                                                      m.group(2), m.group(1))
        else:
          mapping[name] = functools.partial(make_synthetic_field,
                                            self.valueobject, val, name)
      mapping[OBJECT_DUMP_NAME] = lambda: dump


def summarize_heap_object_internal(valueobject, inner_getter):
  # By indicating that this synthentic child provider is called from an object
  # with a formatter, we can ensure it is updated only when that formatter is
  # called, preventing it from being reevaluated multiple times on a single step
  DictProvider.updating_for_formatter = True
  dumpobj = valueobject.GetChildMemberWithName(OBJECT_DUMP_NAME)
  DictProvider.updating_for_formatter = False
  if dumpobj and dumpobj.GetError().Success():
    dump = get_string_value(dumpobj)
    if dump:
      oneline = dump.splitlines()[0]
      if oneline:
        return oneline
  return '%s: Address=0x%x' % (valueobject.GetDisplayTypeName(),
                               inner_getter().GetValueAsUnsigned())


class HandleChildrenProvider(HeapObjectChildrenProvider):

  def __init__(self, valobj, internal_dict):
    super().__init__(
        valobj.GetChildMemberWithName('location_').Dereference(), internal_dict)


def summarize_handle(valueobject, unused_dict):
  return summarize_heap_object_internal(
      valueobject, lambda: valueobject.GetNonSyntheticValue().
      GetChildMemberWithName('location_').Dereference())


class TaggedChildrenProvider(HeapObjectChildrenProvider):

  def __init__(self, valobj, internal_dict):
    super().__init__(valobj.GetChildMemberWithName('ptr_'), internal_dict)


def summarize_tagged(valueobject, unused_dict):
  return summarize_heap_object_internal(
      valueobject,
      lambda: valueobject.GetNonSyntheticValue().GetChildMemberWithName('ptr_'))


def read_pointer(ptrobject):
  if not ptrobject.TypeIsPointerType():
    ptrobject = ptrobject.AddressOf()
  ptr = ptrobject.GetValueAsUnsigned()
  # If it's not 8 byte aligned, assume it's uninitialized and return 0 instead.
  # Could we do more validation?
  if (ptr & 7) == 0:
    return ptr
  return 0


def summarize_stack_frame(valueobject, unused_dict):
  ptr = read_pointer(valueobject)
  if ptr:
    typeval = valueobject.CreateValueFromExpression(
        '[Type]', '((v8::internal::StackFrame *)%s)->type()' % ptr)
    return 'StackFrame: %s' % typeval.GetValue()
    # Is it worth getting more here?


def summarize_stack_trace_debug_details(valueobject, unused_dict):
  summary = get_string_value(valueobject.GetChildMemberWithName('summary'))
  frametype = valueobject.GetChildMemberWithName('type').GetValue()
  firstline, _, _ = summary.partition('\n')
  _, _, result = firstline.partition(':')
  return frametype + result


class IsolateChildrenProvider(DictProvider):

  def __init__(self, valobj, internal_dict):
    self.valueobject = valobj
    super().__init__()

  def populate_children(self, mapping):
    ptr = read_pointer(self.valueobject)
    if ptr:
      mapping[
          '[Stack Trace]'] = lambda: self.valueobject.CreateValueFromExpression(
              '[Stack Trace]',
              '_v8_internal_Expand_StackTrace((v8::internal::Isolate *)%s)' %
              ptr)


class FrameSummaryChildrenProvider(DictProvider):

  def __init__(self, valobj, internal_dict):
    self.valueobject = valobj
    super().__init__()

  def populate_children(self, mapping):
    unionelement = 'base_'
    kind = self.valueobject.GetChildMemberWithName(
        unionelement).GetChildMemberWithName('kind_').GetValueAsUnsigned()
    if kind == FrameSummary_Kind_JAVA_SCRIPT(self.valueobject):
      unionelement = 'java_script_summary_'
    # TODO: Add other summary kinds
    mapping[unionelement] = lambda: self.valueobject.GetChildMemberWithName(
        unionelement)


def __lldb_init_module(debugger, unused_dict):
  debugger.HandleCommand(
      'type summary add -p --summary-string "Address=0x${var%x}" v8::internal::Address'
  )
  debugger.HandleCommand(
      'type synthetic add -p -l lldb_visualizers.HandleChildrenProvider -x "^v8::internal::Handle<"'
  )
  debugger.HandleCommand(
      'type synthetic add -p -l lldb_visualizers.TaggedChildrenProvider -x "^v8::internal::Tagged<"'
  )
  debugger.HandleCommand(
      'type summary add -p -F lldb_visualizers.summarize_handle -x "^v8::internal::Handle<"'
  )
  debugger.HandleCommand(
      'type summary add -p -F lldb_visualizers.summarize_tagged -x "^v8::internal::Tagged<"'
  )
  debugger.HandleCommand(
      'type summary add -F lldb_visualizers.summarize_stack_frame v8::internal::StackFrame'
  )
  debugger.HandleCommand(
      'type summary add -F lldb_visualizers.summarize_stack_trace_debug_details _v8_internal_debugonly::StackTraceDebugDetails'
  )
  debugger.HandleCommand(
      'type synthetic add -l lldb_visualizers.IsolateChildrenProvider v8::internal::Isolate'
  )
  debugger.HandleCommand(
      'type synthetic add -l lldb_visualizers.FrameSummaryChildrenProvider v8::internal::FrameSummary'
  )
                                                                                                                                                      node-23.7.0/deps/v8/tools/locs.py                                                                   0000775 0000000 0000000 00000034510 14746647661 0016525 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3

# Copyright 2018 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

""" locs.py - Count lines of code before and after preprocessor expansion
  Consult --help for more information.
"""

# for py2/py3 compatibility
from __future__ import print_function

import argparse
import json
import multiprocessing
import os
import re
import subprocess
import sys
import tempfile
import time
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path

# for py2/py3 compatibility
try:
  FileNotFoundError
except NameError:
  FileNotFoundError = IOError

ARGPARSE = argparse.ArgumentParser(
    description=("A script that computes LoC for a build dir"),
    epilog="""Examples:
 Count with default settings for build in out/Default:
   locs.py --build-dir out/Default
 Count only a custom group of files settings for build in out/Default:
   tools/locs.py --build-dir out/Default
                 --group src-compiler '\.\./\.\./src/compiler'
                 --only src-compiler
 Report the 10 files with the worst expansion:
   tools/locs.py --build-dir out/Default --worst 10
 Report the 10 files with the worst expansion in src/compiler:
   tools/locs.py --build-dir out/Default --worst 10
                 --group src-compiler '\.\./\.\./src/compiler'
                 --only src-compiler
 Report the 10 largest files after preprocessing:
   tools/locs.py --build-dir out/Default --largest 10
 Report the 10 smallest input files:
   tools/locs.py --build-dir out/Default --smallest 10""",
    formatter_class=argparse.RawTextHelpFormatter
)

ARGPARSE.add_argument(
    '--json',
    action='store_true',
    default=False,
    help="output json instead of short summary")
ARGPARSE.add_argument(
    '--build-dir',
    type=str,
    help="Use specified build dir and generate necessary files",
    required=True)
ARGPARSE.add_argument(
    '--echocmd',
    action='store_true',
    default=False,
    help="output command used to compute LoC")
ARGPARSE.add_argument(
    '--only',
    action='append',
    default=[],
    help="Restrict counting to report group (can be passed multiple times)")
ARGPARSE.add_argument(
    '--not',
    action='append',
    default=[],
    help="Exclude specific group (can be passed multiple times)")
ARGPARSE.add_argument(
    '--list-groups',
    action='store_true',
    default=False,
    help="List groups and associated regular expressions")
ARGPARSE.add_argument(
    '--group',
    nargs=2,
    action='append',
    default=[],
    help="Add a report group (can be passed multiple times)")
ARGPARSE.add_argument(
    '--largest',
    type=int,
    nargs='?',
    default=0,
    const=3,
    help="Output the n largest files after preprocessing")
ARGPARSE.add_argument(
    '--worst',
    type=int,
    nargs='?',
    default=0,
    const=3,
    help="Output the n files with worst expansion by preprocessing")
ARGPARSE.add_argument(
    '--smallest',
    type=int,
    nargs='?',
    default=0,
    const=3,
    help="Output the n smallest input files")
ARGPARSE.add_argument(
    '--files',
    type=int,
    nargs='?',
    default=0,
    const=3,
    help="Output results for each file separately")
ARGPARSE.add_argument(
    '--jobs',
    type=int,
    default=multiprocessing.cpu_count(),
    help="Process specified number of files concurrently")

ARGS = vars(ARGPARSE.parse_args())


def MaxWidth(strings):
  max_width = 0
  for s in strings:
    max_width = max(max_width, len(s))
  return max_width


def GenerateCompileCommandsAndBuild(build_dir, out):
  if not os.path.isdir(build_dir):
    print("Error: Specified build dir {} is not a directory.".format(
        build_dir), file=sys.stderr)
    exit(1)

  autoninja = "autoninja -C {}".format(build_dir)
  if subprocess.call(autoninja, shell=True, stdout=out) != 0:
    print("Error: Building {} failed.".format(build_dir), file=sys.stderr)
    exit(1)

  compile_commands_file = "{}/compile_commands.json".format(build_dir)
  print("Generating compile commands in {}.".format(
      compile_commands_file), file=out)
  ninja = "ninja -C {} -t compdb cxx cc > {}".format(
      build_dir, compile_commands_file)
  if subprocess.call(ninja, shell=True, stdout=out) != 0:
    print("Error: Cound not generate {} for {}.".format(
        compile_commands_file, build_dir), file=sys.stderr)
    exit(1)

  ninja_deps_file = "{}/ninja-deps.txt".format(build_dir)
  print("Generating ninja dependencies in {}.".format(
      ninja_deps_file), file=out)
  ninja = "ninja -C {} -t deps > {}".format(
      build_dir, ninja_deps_file)
  if subprocess.call(ninja, shell=True, stdout=out) != 0:
    print("Error: Cound not generate {} for {}.".format(
        ninja_deps_file, build_dir), file=sys.stderr)
    exit(1)

  return compile_commands_file, ninja_deps_file


def fmt_bytes(num_bytes):
  if num_bytes > 1024*1024*1024:
    return int(num_bytes / (1024*1024)), "MB"
  elif num_bytes > 1024*1024:
    return int(num_bytes / (1024)), "kB"
  return int(num_bytes), " B"


class CompilationData:
  def __init__(self, loc, in_bytes, expanded, expanded_bytes):
    self.loc = loc
    self.in_bytes = in_bytes
    self.expanded = expanded
    self.expanded_bytes = expanded_bytes

  def ratio(self):
    return self.expanded / (self.loc+1)

  def to_string(self):
    exp_bytes, exp_unit = fmt_bytes(self.expanded_bytes)
    in_bytes, in_unit = fmt_bytes(self.in_bytes)
    return "{:>9,} LoC ({:>7,} {}) to {:>12,} LoC ({:>7,} {}) ({:>5.0f}x)".format(
        self.loc, in_bytes, in_unit, self.expanded, exp_bytes, exp_unit, self.ratio())


class File(CompilationData):
  def __init__(self, file, target, loc, in_bytes, expanded, expanded_bytes):
    super().__init__(loc, in_bytes, expanded, expanded_bytes)
    self.file = file
    self.target = target

  def to_string(self):
    return "{} {} {}".format(super().to_string(), self.file, self.target)


class Group(CompilationData):
  def __init__(self, name, regexp_string):
    super().__init__(0, 0, 0, 0)
    self.name = name
    self.count = 0
    self.regexp = re.compile(regexp_string)

  def account(self, unit):
    if (self.regexp.match(unit.file)):
      self.loc += unit.loc
      self.in_bytes += unit.in_bytes
      self.expanded += unit.expanded
      self.expanded_bytes += unit.expanded_bytes
      self.count += 1

  def to_string(self, name_width):
    return "{:<{}} ({:>5} files): {}".format(
        self.name, name_width, self.count, super().to_string())


def SetupReportGroups():
  default_report_groups = {"total": '.*',
                           "src": '\\.\\./\\.\\./src',
                           "test": '\\.\\./\\.\\./test',
                           "third_party": '\\.\\./\\.\\./third_party',
                           "gen": 'gen'}

  report_groups = default_report_groups.copy()
  report_groups.update(dict(ARGS['group']))

  if ARGS['only']:
    for only_arg in ARGS['only']:
      if not only_arg in report_groups.keys():
        print("Error: specified report group '{}' is not defined.".format(
            ARGS['only']))
        exit(1)
      else:
        report_groups = {
            k: v for (k, v) in report_groups.items() if k in ARGS['only']}

  if ARGS['not']:
    report_groups = {
        k: v for (k, v) in report_groups.items() if k not in ARGS['not']}

  if ARGS['list_groups']:
    print_cat_max_width = MaxWidth(list(report_groups.keys()) + ["Category"])
    print("  {:<{}}  {}".format("Category",
                                print_cat_max_width, "Regular expression"))
    for cat, regexp_string in report_groups.items():
      print("  {:<{}}: {}".format(
          cat, print_cat_max_width, regexp_string))

  report_groups = {k: Group(k, v) for (k, v) in report_groups.items()}

  return report_groups


class Results:
  def __init__(self):
    self.groups = SetupReportGroups()
    self.units = {}
    self.source_dependencies = {}
    self.header_dependents = {}

  def track(self, filename):
    is_tracked = False
    for group in self.groups.values():
      if group.regexp.match(filename):
        is_tracked = True
    return is_tracked

  def recordFile(self, filename, targetname, loc, in_bytes, expanded, expanded_bytes):
    unit = File(filename, targetname, loc, in_bytes, expanded, expanded_bytes)
    self.units[filename] = unit
    for group in self.groups.values():
      group.account(unit)

  def maxGroupWidth(self):
    return MaxWidth([v.name for v in self.groups.values()])

  def printGroupResults(self, file):
    for key in sorted(self.groups.keys()):
      print(self.groups[key].to_string(self.maxGroupWidth()), file=file)

  def printSorted(self, key, count, reverse, out):
    for unit in sorted(list(self.units.values()), key=key, reverse=reverse)[:count]:
      print(unit.to_string(), file=out)

  def addHeaderDeps(self, source_dependencies, header_dependents):
    self.source_dependencies = source_dependencies
    self.header_dependents = header_dependents


class LocsEncoder(json.JSONEncoder):
  def default(self, o):
    if isinstance(o, File):
      return {"file": o.file, "target": o.target, "loc": o.loc, "in_bytes": o.in_bytes,
              "expanded": o.expanded, "expanded_bytes": o.expanded_bytes}
    if isinstance(o, Group):
      return {"name": o.name, "loc": o.loc, "in_bytes": o.in_bytes,
              "expanded": o.expanded, "expanded_bytes": o.expanded_bytes}
    if isinstance(o, Results):
      return {"groups": o.groups, "units": o.units,
              "source_dependencies": o.source_dependencies,
              "header_dependents": o.header_dependents}
    return json.JSONEncoder.default(self, o)


class StatusLine:
  def __init__(self):
    self.max_width = 0

  def print(self, statusline, end="\r", file=sys.stdout):
    self.max_width = max(self.max_width, len(statusline))
    print("{0:<{1}}".format(statusline, self.max_width),
          end=end, file=file, flush=True)


class CommandSplitter:
  def __init__(self):
    self.cmd_pattern = re.compile(
        "([^\\s]*\\s+)?(?P<clangcmd>[^\\s]*clang.*)"
        " -c (?P<infile>.*) -o (?P<outfile>.*)")

  def process(self, compilation_unit):
    cmd = self.cmd_pattern.match(compilation_unit['command'])
    outfilename = cmd.group('outfile')
    infilename = cmd.group('infile')
    infile = Path(compilation_unit['directory']).joinpath(infilename)
    return (cmd.group('clangcmd'), infilename, infile, outfilename)


def parse_ninja_deps(ninja_deps):
  source_dependencies = {}
  header_dependents = defaultdict(int)
  current_target = None
  for line in ninja_deps:
    line = line.rstrip()
    # Ignore empty lines
    if not line:
      current_target = None
      continue
    if line[0] == ' ':
      # New dependency
      if len(line) < 5 or line[0:4] != '    ' or line[5] == ' ':
        sys.exit('Lines must have no indentation or exactly four ' +
                 'spaces.')
      dep = line[4:]
      if not re.search(r"\.(h|hpp)$", dep):
        continue
      header_dependents[dep] += 1
      continue
    # New target
    colon_pos = line.find(':')
    if colon_pos < 0:
      sys.exit('Unindented line must have a colon')
    if current_target is not None:
      sys.exit('Missing empty line before new target')
    current_target = line[0:colon_pos]
    match = re.search(r"#deps (\d+)", line)
    deps_number = match.group(1)
    source_dependencies[current_target] = int(deps_number)

  return (source_dependencies, header_dependents)


def Main():
  out = sys.stdout
  if ARGS['json']:
    out = sys.stderr

  compile_commands_file, ninja_deps_file = GenerateCompileCommandsAndBuild(
      ARGS['build_dir'], out)

  result = Results()
  status = StatusLine()

  try:
    with open(compile_commands_file) as file:
      compile_commands = json.load(file)
    with open(ninja_deps_file) as file:
      source_dependencies, header_dependents = parse_ninja_deps(file)
      result.addHeaderDeps(source_dependencies, header_dependents)
  except FileNotFoundError:
    print("Error: Cannot read '{}'. Consult --help to get started.".format(
        ninja_deps_file))
    exit(1)

  cmd_splitter = CommandSplitter()

  def count_lines_of_unit(ikey):
    i, key = ikey
    if not result.track(key['file']):
      return
    message = "[{}/{}] Counting LoCs of {}".format(
        i, len(compile_commands), key['file'])
    status.print(message, file=out)
    clangcmd, infilename, infile, outfilename = cmd_splitter.process(key)
    if not infile.is_file():
      return

    clangcmd = clangcmd + " -E -P " + \
        str(infile) + " -o /dev/stdout | sed '/^\\s*$/d' | wc -lc"
    loccmd = ("cat {}  | sed '\\;^\\s*//;d' | sed '\\;^/\\*;d'"
              " | sed '/^\\*/d' | sed '/^\\s*$/d' | wc -lc")
    loccmd = loccmd.format(infile)
    runcmd = " {} ; {}".format(clangcmd, loccmd)
    if ARGS['echocmd']:
      print(runcmd)
    process = subprocess.Popen(
        runcmd, shell=True, cwd=key['directory'], stdout=subprocess.PIPE)
    p = {'process': process, 'infile': infilename, 'outfile': outfilename}
    output, _ = p['process'].communicate()
    expanded, expanded_bytes, loc, in_bytes = list(map(int, output.split()))
    result.recordFile(p['infile'], p['outfile'], loc,
                      in_bytes, expanded, expanded_bytes)

  with tempfile.TemporaryDirectory(dir='/tmp/', prefix="locs.") as temp:
    start = time.time()

    with ThreadPoolExecutor(max_workers=ARGS['jobs']) as executor:
      list(executor.map(count_lines_of_unit, enumerate(compile_commands)))

    end = time.time()
    if ARGS['json']:
      print(json.dumps(result, ensure_ascii=False, cls=LocsEncoder))
    status.print("Processed {:,} files in {:,.2f} sec.".format(
        len(compile_commands), end-start), end="\n", file=out)
    result.printGroupResults(file=out)

    if ARGS['largest']:
      print("Largest {} files after expansion:".format(ARGS['largest']))
      result.printSorted(
          lambda v: v.expanded, ARGS['largest'], reverse=True, out=out)

    if ARGS['worst']:
      print("Worst expansion ({} files):".format(ARGS['worst']))
      result.printSorted(
          lambda v: v.ratio(), ARGS['worst'], reverse=True, out=out)

    if ARGS['smallest']:
      print("Smallest {} input files:".format(ARGS['smallest']))
      result.printSorted(
          lambda v: v.loc, ARGS['smallest'], reverse=False, out=out)

    if ARGS['files']:
      print("List of input files:")
      result.printSorted(
          lambda v: v.file, ARGS['files'], reverse=False, out=out)

  return 0


if __name__ == '__main__':
  sys.exit(Main())
                                                                                                                                                                                        node-23.7.0/deps/v8/tools/logreader.mjs                                                             0000664 0000000 0000000 00000021032 14746647661 0017662 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2011 the V8 project authors. All rights reserved.
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met:
//
//     * Redistributions of source code must retain the above copyright
//       notice, this list of conditions and the following disclaimer.
//     * Redistributions in binary form must reproduce the above
//       copyright notice, this list of conditions and the following
//       disclaimer in the documentation and/or other materials provided
//       with the distribution.
//     * Neither the name of Google Inc. nor the names of its
//       contributors may be used to endorse or promote products derived
//       from this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

/**
 * @fileoverview Log Reader is used to process log file produced by V8.
 */
 import { CsvParser } from "./csvparser.mjs";


// Parses dummy variable for readability;
export function parseString(field) { return field };
export const parseVarArgs = 'parse-var-args';

// Checks fields for numbers that are not safe integers. Returns true if any are
// found.
function containsUnsafeInts(fields) {
  for (let i = 0; i < fields.length; i++) {
    let field = fields[i];
    if ('number' == typeof(field) && !Number.isSafeInteger(field)) return true;
  }
  return false;
}

/**
 * Base class for processing log files.
 *
 * @param {boolean} timedRange Ignore ticks outside timed range.
 * @param {boolean} pairwiseTimedRange Ignore ticks outside pairs of timer
 *     markers.
 * @constructor
 */
export class LogReader {
  constructor(
        timedRange=false, pairwiseTimedRange=false, useBigIntAddresses=false) {
    this.dispatchTable_ = new Map();
    this.timedRange_ = timedRange;
    this.pairwiseTimedRange_ = pairwiseTimedRange;
    if (pairwiseTimedRange) this.timedRange_ = true;
    this.lineNum_ = 0;
    this.csvParser_ = new CsvParser();
    // Variables for tracking of 'current-time' log entries:
    this.hasSeenTimerMarker_ = false;
    this.logLinesSinceLastTimerMarker_ = [];
    // Flag to parse all numeric fields as BigInt to avoid arithmetic errors
    // caused by memory addresses being greater than MAX_SAFE_INTEGER
    this.useBigIntAddresses = useBigIntAddresses;
    this.parseFrame = useBigIntAddresses ? BigInt : parseInt;
    this.hasSeenUnsafeIntegers = false;
  }

/**
 * @param {Object} table A table used for parsing and processing
 *     log records.
 *     exampleDispatchTable = {
 *       "log-entry-XXX": {
 *          parser: [parseString, parseInt, ..., parseVarArgs],
 *          processor: this.processXXX.bind(this)
 *        },
 *        ...
 *      }
 */
  setDispatchTable(table) {
    if (Object.getPrototypeOf(table) !== null) {
      throw new Error("Dispatch expected table.__proto__=null for speedup");
    }
    for (let name in table) {
      const parser = table[name];
      if (parser === undefined) continue;
      if (!parser.isAsync) parser.isAsync = false;
      if (!Array.isArray(parser.parsers)) {
        throw new Error(`Invalid parsers: dispatchTable['${
            name}'].parsers should be an Array.`);
      }
      let type = typeof parser.processor;
      if (type !== 'function') {
       throw new Error(`Invalid processor: typeof dispatchTable['${
          name}'].processor is '${type}' instead of 'function'`);
      }
      if (!parser.processor.name.startsWith('bound ')) {
        parser.processor = parser.processor.bind(this);
      }
      this.dispatchTable_.set(name, parser);
    }
  }


  /**
   * A thin wrapper around shell's 'read' function showing a file name on error.
   */
  readFile(fileName) {
    try {
      return read(fileName);
    } catch (e) {
      printErr(`file="${fileName}": ${e.message || e}`);
      throw e;
    }
  }

  /**
   * Used for printing error messages.
   *
   * @param {string} str Error message.
   */
  printError(str) {
    // Do nothing.
  }

  /**
   * Processes a portion of V8 profiler event log.
   *
   * @param {string} chunk A portion of log.
   */
  async processLogChunk(chunk) {
    let end = chunk.length;
    let current = 0;
    // Kept for debugging in case of parsing errors.
    let lineNumber = 0;
    while (current < end) {
      const next = chunk.indexOf("\n", current);
      if (next === -1) break;
      lineNumber++;
      const line = chunk.substring(current, next);
      current = next + 1;
      await this.processLogLine(line);
    }
  }

  /**
   * Processes a line of V8 profiler event log.
   *
   * @param {string} line A line of log.
   */
  async processLogLine(line) {
    if (!this.timedRange_) {
      await this.processLogLine_(line);
      return;
    }
    if (line.startsWith("current-time")) {
      if (this.hasSeenTimerMarker_) {
        await this.processLog_(this.logLinesSinceLastTimerMarker_);
        this.logLinesSinceLastTimerMarker_ = [];
        // In pairwise mode, a "current-time" line ends the timed range.
        if (this.pairwiseTimedRange_) {
          this.hasSeenTimerMarker_ = false;
        }
      } else {
        this.hasSeenTimerMarker_ = true;
      }
    } else {
      if (this.hasSeenTimerMarker_) {
        this.logLinesSinceLastTimerMarker_.push(line);
      } else if (!line.startsWith("tick")) {
        await this.processLogLine_(line);
      }
    }
  }

  /**
   * Processes stack record.
   *
   * @param {number} pc Program counter.
   * @param {number} func JS Function.
   * @param {string[]} stack String representation of a stack.
   * @return {number[]} Processed stack.
   */
  processStack(pc, func, stack) {
    const fullStack = func ? [pc, func] : [pc];
    let prevFrame = pc;
    const length = stack.length;
    for (let i = 0, n = length; i < n; ++i) {
      const frame = stack[i];
      const firstChar = frame[0];
      if (firstChar === '+' || firstChar === '-') {
        // An offset from the previous frame.
        prevFrame += this.parseFrame(frame);
        fullStack.push(prevFrame);
      // Filter out possible 'overflow' string.
      } else if (firstChar !== 'o') {
        fullStack.push(this.parseFrame(frame));
      } else {
        console.error(`Dropping unknown tick frame: ${frame}`);
      }
    }
    return fullStack;
  }

  /**
   * Does a dispatch of a log record.
   *
   * @param {string[]} fields Log record.
   * @private
   */
  async dispatchLogRow_(fields) {
    // Obtain the dispatch.
    const command = fields[0];
    const dispatch = this.dispatchTable_.get(command);
    if (dispatch === undefined) return;
    const parsers = dispatch.parsers;
    const length = parsers.length;
    // Parse fields.
    const parsedFields = new Array(length);
    for (let i = 0; i < length; ++i) {
      const parser = parsers[i];
      if (parser === parseVarArgs) {
        parsedFields[i] = fields.slice(1 + i);
        break;
      } else {
        parsedFields[i] = parser(fields[1 + i]);
      }
    }
    if (!this.useBigIntAddresses) {
      if (!this.hasSeenUnsafeIntegers && containsUnsafeInts(parsedFields)) {
        console.warn(`Log line contains unsafe integers: ${fields}`);
        this.hasSeenUnsafeIntegers = true;
      }
    }
    // Run the processor.
    await dispatch.processor(...parsedFields);
  }

  /**
   * Processes log lines.
   *
   * @param {string[]} lines Log lines.
   * @private
   */
  async processLog_(lines) {
    for (let i = 0, n = lines.length; i < n; ++i) {
      await this.processLogLine_(lines[i]);
    }
  }

  /**
   * Processes a single log line.
   *
   * @param {String} a log line
   * @private
   */
  async processLogLine_(line) {
    if (line.length > 0) {
      try {
        const fields = this.csvParser_.parseLine(line);
        await this.dispatchLogRow_(fields);
      } catch (e) {
        this.printError(`line ${this.lineNum_ + 1}: ${e.message || e}\n${e.stack}`);
      }
    }
    this.lineNum_++;
  }
}
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      node-23.7.0/deps/v8/tools/mac-nm                                                                    0000775 0000000 0000000 00000001447 14746647661 0016311 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/bin/sh

# This script is a wrapper for OS X nm(1) tool. nm(1) perform C++ function
# names demangling, so we're piping its output to c++filt(1) tool which does it.
# But c++filt(1) comes with XCode (as a part of GNU binutils), so it doesn't
# guaranteed to exist on a system.
#
# An alternative approach is to perform demangling in tick processor, but
# for GNU C++ ABI this is a complex process (see cp-demangle.c sources), and
# can't be done partially, because term boundaries are plain text symbols, such
# as 'N', 'E', so one can't just do a search through a function name, it really
# needs to be parsed, which requires a lot of knowledge to be coded in.

if [ "`which c++filt`" == "" ]; then
  nm "$@"
else
  nm "$@" | sed -n "s/\([0-9a-fA-F]\{8,16\}\) [iItT] \(.*\)/\\1 \\2/p"\
    | c++filt 
fi
                                                                                                                                                                                                                         node-23.7.0/deps/v8/tools/mac-tick-processor                                                        0000775 0000000 0000000 00000000300 14746647661 0020631 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/bin/sh

# A wrapper script to call 'linux-tick-processor' with Mac-specific settings.

tools_path=`cd $(dirname "$0");pwd`
$tools_path/linux-tick-processor --mac --nm=$tools_path/mac-nm $@
                                                                                                                                                                                                                                                                                                                                node-23.7.0/deps/v8/tools/mb/                                                                       0000775 0000000 0000000 00000000000 14746647661 0015603 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/mb/OWNERS                                                                 0000664 0000000 0000000 00000000101 14746647661 0016533 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        brettw@chromium.org
dpranke@chromium.org
machenbach@chromium.org
                                                                                                                                                                                                                                                                                                                                                                                                                                                               node-23.7.0/deps/v8/tools/mb/PRESUBMIT.py                                                           0000664 0000000 0000000 00000003270 14746647661 0017531 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # Copyright 2016 the V8 project authors. All rights reserved.
# Copyright 2015 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

# This line is 'magic' in that git-cl looks for it to decide whether to
# use Python3 instead of Python2 when running the code in this file.
USE_PYTHON3 = True


def _CommonChecks(input_api, output_api):
  results = []

  # Run Pylint over the files in the directory.
  pylint_checks = input_api.canned_checks.GetPylint(input_api, output_api)
  results.extend(input_api.RunTests(pylint_checks))

  # Run the MB unittests.
  results.extend(
      input_api.canned_checks.RunUnitTestsInDirectory(input_api, output_api,
                                                      '.', [r'^.+_test\.py$'],
                                                      run_on_python2=False))

  # Validate the format of the mb_config.pyl file.
  cmd = [input_api.python3_executable, 'mb.py', 'validate']
  kwargs = {'cwd': input_api.PresubmitLocalPath()}
  results.extend(input_api.RunTests([
      input_api.Command(name='mb_validate',
                        cmd=cmd, kwargs=kwargs,
                        message=output_api.PresubmitError,
                        python3=True)]))

  is_mb_config = (lambda filepath: 'mb_config.pyl' in filepath.LocalPath())
  results.extend(
      input_api.canned_checks.CheckLongLines(
          input_api, output_api, maxlen=80, source_file_filter=is_mb_config))

  return results


def CheckChangeOnUpload(input_api, output_api):
  return _CommonChecks(input_api, output_api)


def CheckChangeOnCommit(input_api, output_api):
  return _CommonChecks(input_api, output_api)
                                                                                                                                                                                                                                                                                                                                        node-23.7.0/deps/v8/tools/mb/README.md                                                              0000664 0000000 0000000 00000001464 14746647661 0017067 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # MB - The Meta-Build wrapper

MB is a simple wrapper intended to provide a uniform interface to either
GYP or GN, such that users and bots can call one script and not need to
worry about whether a given bot is meant to use GN or GYP.

It supports two main functions:

1. "gen" - the main `gyp_chromium` / `gn gen` invocation that generates the
   Ninja files needed for the build.

2. "analyze" - the step that takes a list of modified files and a list of
   desired targets and reports which targets will need to be rebuilt.

We also use MB as a forcing function to collect all of the different 
build configurations that we actually support for Chromium builds into
one place, in `//tools/mb/mb_config.pyl`.

For more information, see:

* [The User Guide](docs/user_guide.md)
* [The Design Spec](docs/design_spec.md)
                                                                                                                                                                                                            node-23.7.0/deps/v8/tools/mb/docs/                                                                  0000775 0000000 0000000 00000000000 14746647661 0016533 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/mb/docs/README.md                                                         0000664 0000000 0000000 00000000163 14746647661 0020012 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # The MB (Meta-Build wrapper) documentation

* The [User Guide](user_guide.md)
* The [Design Spec](design_spec.md)
                                                                                                                                                                                                                                                                                                                                                                                                             node-23.7.0/deps/v8/tools/mb/docs/design_spec.md                                                    0000664 0000000 0000000 00000042463 14746647661 0021351 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # The MB (Meta-Build wrapper) design spec

[TOC]

## Intro

MB is intended to address two major aspects of the GYP -> GN transition
for Chromium:

1. "bot toggling" - make it so that we can easily flip a given bot
   back and forth between GN and GYP.

2. "bot configuration" - provide a single source of truth for all of
   the different configurations (os/arch/`gyp_define` combinations) of
   Chromium that are supported.

MB must handle at least the `gen` and `analyze` steps on the bots, i.e.,
we need to wrap both the `gyp_chromium` invocation to generate the
Ninja files, and the `analyze` step that takes a list of modified files
and a list of targets to build and returns which targets are affected by
the files.

For more information on how to actually use MB, see
[the user guide](user_guide.md).

## Design

MB is intended to be as simple as possible, and to defer as much work as
possible to GN or GYP. It should live as a very simple Python wrapper
that offers little in the way of surprises.

### Command line

It is structured as a single binary that supports a list of subcommands:

* `mb gen -c linux_rel_bot //out/Release`
* `mb analyze -m tryserver.chromium.linux -b linux_rel /tmp/input.json /tmp/output.json`

### Configurations

`mb` will first look for a bot config file in a set of different locations
(initially just in //ios/build/bots). Bot config files are JSON files that
contain keys for 'GYP_DEFINES' (a list of strings that will be joined together
with spaces and passed to GYP, or a dict that will be similarly converted),
'gn_args' (a list of strings that will be joined together), and an
'mb_type' field that says whether to use GN or GYP. Bot config files
require the full list of settings to be given explicitly.

If no matching bot config file is found, `mb` looks in the
`//tools/mb/mb_config.pyl` config file to determine whether to use GYP or GN
for a particular build directory, and what set of flags (`GYP_DEFINES` or `gn
args`) to use.

A config can either be specified directly (useful for testing) or by specifying
the master name and builder name (useful on the bots so that they do not need
to specify a config directly and can be hidden from the details).

See the [user guide](user_guide.md#mb_config.pyl) for details.

### Handling the analyze step

The interface to `mb analyze` is described in the
[user\_guide](user_guide.md#mb_analyze).

The way analyze works can be subtle and complicated (see below).

Since the interface basically mirrors the way the "analyze" step on the bots
invokes `gyp_chromium` today, when the config is found to be a gyp config,
the arguments are passed straight through.

It implements the equivalent functionality in GN by calling `gn refs
[list of files] --type=executable --all --as=output` and filtering the
output to match the list of targets.

## Analyze

The goal of the `analyze` step is to speed up the cycle time of the try servers
by only building and running the tests affected by the files in a patch, rather
than everything that might be out of date. Doing this ends up being tricky.

We start with the following requirements and observations:

* In an ideal (un-resource-constrained) world, we would build and test
  everything that a patch affected on every patch. This does not
  necessarily mean that we would build 'all' on every patch (see below).

* In the real world, however, we do not have an infinite number of machines,
  and try jobs are not infinitely fast, so we need to balance the desire
  to get maximum test coverage against the desire to have reasonable cycle
  times, given the number of machines we have.

* Also, since we run most try jobs against tip-of-tree Chromium, by
  the time one job completes on the bot, new patches have probably landed,
  rendering the build out of date.

* This means that the next try job may have to do a build that is out of
  date due to a combination of files affected by a given patch, and files
  affected for unrelated reasons. We want to rebuild and test only the
  targets affected by the patch, so that we don't blame or punish the
  patch author for unrelated changes.

So:

1. We need a way to indicate which changed files we care about and which
   we don't (the affected files of a patch).

2. We need to know which tests we might potentially want to run, and how
   those are mapped onto build targets. For some kinds of tests (like
   GTest-based tests), the mapping is 1:1 - if you want to run base_unittests,
   you need to build base_unittests. For others (like the telemetry and
   layout tests), you might need to build several executables in order to
   run the tests, and that mapping might best be captured by a *meta*
   target (a GN group or a GYP 'none' target like `webkit_tests`) that
   depends on the right list of files. Because the GN and GYP files know
   nothing about test steps, we have to have some way of mapping back
   and forth between test steps and build targets. That mapping
   is *not* currently available to MB (or GN or GYP), and so we have to 
   enough information to make it possible for the caller to do the mapping.

3. We might also want to know when test targets are affected by data files
   that aren't compiled (python scripts, or the layout tests themselves).
   There's no good way to do this in GYP, but GN supports this.

4. We also want to ensure that particular targets still compile even if they
   are not actually tested; consider testing the installers themselves, or
   targets that don't yet have good test coverage. We might want to use meta
   targets for this purpose as well.

5. However, for some meta targets, we don't necessarily want to rebuild the
   meta target itself, perhaps just the dependencies of the meta target that
   are affected by the patch. For example, if you have a meta target like
   `blink_tests` that might depend on ten different test binaries. If a patch
   only affects one of them (say `wtf_unittests`), you don't want to
   build `blink_tests`, because that might actually also build the other nine
   targets.  In other words, some meta targets are *prunable*.

6. As noted above, in the ideal case we actually have enough resources and
   things are fast enough that we can afford to build everything affected by a
   patch, but listing every possible target explicitly would be painful. The
   GYP and GN Ninja generators provide an 'all' target that captures (nearly,
   see [crbug.com/503241](crbug.com/503241)) everything, but unfortunately
   neither GN nor GYP actually represents 'all' as a meta target in the build
   graph, so we will need to write code to handle that specially.

7. In some cases, we will not be able to correctly analyze the build graph to
   determine the impact of a patch, and need to bail out (e.g,. if you change a
   build file itself, it may not be easy to tell how that affects the graph).
   In that case we should simply build and run everything.

The interaction between 2) and 5) means that we need to treat meta targets
two different ways, and so we need to know which targets should be
pruned in the sense of 5) and which targets should be returned unchanged
so that we can map them back to the appropriate tests.

So, we need three things as input:

* `files`: the list of files in the patch
* `test_targets`: the list of ninja targets which, if affected by a patch,
  should be reported back so that we can map them back to the appropriate
  tests to run. Any meta targets in this list should *not* be pruned.
* `additional_compile_targets`: the list of ninja targets we wish to compile
  *in addition to* the list in `test_targets`. Any meta targets
  present in this list should be pruned (we don't need to return the
  meta targets because they aren't mapped back to tests, and we don't want
  to build them because we might build too much).

We can then return two lists as output:

* `compile_targets`, which is a list of pruned targets to be
  passed to Ninja to build. It is acceptable to replace a list of
  pruned targets by a meta target if it turns out that all of the
  dependencies of the target are affected by the patch (i.e.,
  all ten binaries that blink_tests depends on), but doing so is
  not required.
* `test_targets`, which is a list of unpruned targets to be mapped
  back to determine which tests to run.

There may be substantial overlap between the two lists, but there is
no guarantee that one is a subset of the other and the two cannot be
used interchangeably or merged together without losing information and
causing the wrong thing to happen.

The implementation is responsible for recognizing 'all' as a magic string
and mapping it onto the list of all root nodes in the build graph.

There may be files listed in the input that don't actually exist in the build
graph: this could be either the result of an error (the file should be in the
build graph, but isn't), or perfectly fine (the file doesn't affect the build
graph at all). We can't tell these two apart, so we should ignore missing
files.

There may be targets listed in the input that don't exist in the build
graph; unlike missing files, this can only indicate a configuration error,
and so we should return which targets are missing so the caller can
treat this as an error, if so desired.

Any of the three inputs may be an empty list:

* It normally doesn't make sense to call analyze at all if no files
  were modified, but in rare cases we can hit a race where we try to
  test a patch after it has already been committed, in which case
  the list of modified files is empty. We should return 'no dependency'
  in that case.

* Passing an empty list for one or the other of test_targets and
  additional_compile_targets is perfectly sensible: in the former case,
  it can indicate that you don't want to run any tests, and in the latter,
  it can indicate that you don't want to do build anything else in
  addition to the test targets.

* It doesn't make sense to call analyze if you don't want to compile
  anything at all, so passing [] for both test_targets and 
  additional_compile_targets should probably return an error.

In the output case, an empty list indicates that there was nothing to
build, or that there were no affected test targets as appropriate.

Note that passing no arguments to Ninja is equivalent to passing
`all` to Ninja (at least given how GN and GYP work); however, we
don't want to take advantage of this in most cases because we don't
actually want to build every out of date target, only the targets
potentially affected by the files. One could try to indicate
to analyze that we wanted to use no arguments instead of an empty
list, but using the existing fields for this seems fragile and/or
confusing, and adding a new field for this seems unwarranted at this time.

There is an "error" field in case something goes wrong (like the
empty file list case, above, or an internal error in MB/GYP/GN). The
analyze code should also return an error code to the shell if appropriate
to indicate that the command failed.

In the case where build files themselves are modified and analyze may
not be able to determine a correct answer (point 7 above, where we return
"Found dependency (all)"), we should also return the `test_targets` unmodified
and return the union of `test_targets` and `additional_compile_targets` for
`compile_targets`, to avoid confusion.

### Examples

Continuing the example given above, suppose we have the following build
graph:

* `blink_tests` is a meta target that depends on `webkit_unit_tests`,
  `wtf_unittests`, and `webkit_tests` and represents all of the targets
  needed to fully test Blink. Each of those is a separate test step.
* `webkit_tests` is also a meta target; it depends on `content_shell`
  and `image_diff`.
* `base_unittests` is a separate test binary.
* `wtf_unittests` depends on `Assertions.cpp` and `AssertionsTest.cpp`.
* `webkit_unit_tests` depends on `WebNode.cpp` and `WebNodeTest.cpp`.
* `content_shell` depends on `WebNode.cpp` and `Assertions.cpp`.
* `base_unittests` depends on `logging.cc` and `logging_unittest.cc`.

#### Example 1

We wish to run 'wtf_unittests' and 'webkit_tests' on a bot, but not
compile any additional targets.

If a patch touches WebNode.cpp, then analyze gets as input:

    {
      "files": ["WebNode.cpp"],
      "test_targets": ["wtf_unittests", "webkit_tests"],
      "additional_compile_targets": []
    }

and should return as output:

    {
      "status": "Found dependency",
      "compile_targets": ["webkit_unit_tests"],
      "test_targets": ["webkit_tests"]
    }

Note how `webkit_tests` was pruned in compile_targets but not in test_targets.

#### Example 2

Using the same patch as Example 1, assume we wish to run only `wtf_unittests`,
but additionally build everything needed to test Blink (`blink_tests`):

We pass as input:

    {
      "files": ["WebNode.cpp"],
      "test_targets": ["wtf_unittests"],
      "additional_compile_targets": ["blink_tests"]
    }

And should get as output:

    {
      "status": "Found dependency",
      "compile_targets": ["webkit_unit_tests"],
      "test_targets": []
    }

Here `blink_tests` was pruned in the output compile_targets, and
test_targets was empty, since blink_tests was not listed in the input
test_targets.

#### Example 3

Build everything, but do not run any tests.

Input:

    {
      "files": ["WebNode.cpp"],
      "test_targets": [],
      "additional_compile_targets": ["all"]
    }

Output:

    {
      "status": "Found dependency",
      "compile_targets": ["webkit_unit_tests", "content_shell"],
      "test_targets": []
    }

#### Example 4

Same as Example 2, but a build file was modified instead of a source file.

Input:

    {
      "files": ["BUILD.gn"],
      "test_targets": ["wtf_unittests"],
      "additional_compile_targets": ["blink_tests"]
    }

Output:

    {
      "status": "Found dependency (all)",
      "compile_targets": ["webkit_unit_tests", "wtf_unittests"],
      "test_targets": ["wtf_unittests"]
    }

test_targets was returned unchanged, compile_targets was pruned.

## Random Requirements and Rationale

This section is collection of semi-organized notes on why MB is the way
it is ...

### in-tree or out-of-tree

The first issue is whether or not this should exist as a script in
Chromium at all; an alternative would be to simply change the bot
configurations to know whether to use GYP or GN, and which flags to
pass.

That would certainly work, but experience over the past two years
suggests a few things:

  * we should push as much logic as we can into the source repositories
    so that they can be versioned and changed atomically with changes to
    the product code; having to coordinate changes between src/ and
    build/ is at best annoying and can lead to weird errors.
  * the infra team would really like to move to providing
    product-independent services (i.e., not have to do one thing for
    Chromium, another for NaCl, a third for V8, etc.).
  * we found that during the SVN->GIT migration the ability to flip bot
    configurations between the two via changes to a file in chromium
    was very useful.

All of this suggests that the interface between bots and Chromium should
be a simple one, hiding as much of the chromium logic as possible.

### Why not have MB be smarter about de-duping flags?

This just adds complexity to the MB implementation, and duplicates logic
that GYP and GN already have to support anyway; in particular, it might
require MB to know how to parse GYP and GN values. The belief is that
if MB does *not* do this, it will lead to fewer surprises.

It will not be hard to change this if need be.

### Integration w/ gclient runhooks

On the bots, we will disable `gyp_chromium` as part of runhooks (using
`GYP_CHROMIUM_NO_ACTION=1`), so that mb shows up as a separate step.

At the moment, we expect most developers to either continue to use
`gyp_chromium` in runhooks or to disable at as above if they have no
use for GYP at all. We may revisit how this works once we encourage more
people to use GN full-time (i.e., we might take `gyp_chromium` out of
runhooks altogether).

### Config per flag set or config per (os/arch/flag set)?

Currently, mb_config.pyl does not specify the host_os, target_os, host_cpu, or
target_cpu values for every config that Chromium runs on, it only specifies
them for when the values need to be explicitly set on the command line.

Instead, we have one config per unique combination of flags only.

In other words, rather than having `linux_rel_bot`, `win_rel_bot`, and
`mac_rel_bot`, we just have `rel_bot`.

This design allows us to determine easily all of the different sets
of flags that we need to support, but *not* which flags are used on which
host/target combinations.

It may be that we should really track the latter. Doing so is just a
config file change, however.

### Non-goals

* MB is not intended to replace direct invocation of GN or GYP for
  complicated build scenarios (a.k.a. Chrome OS), where multiple flags need
  to be set to user-defined paths for specific toolchains (e.g., where
  Chrome OS needs to specify specific board types and compilers).

* MB is not intended at this time to be something developers use frequently,
  or to add a lot of features to. We hope to be able to get rid of it once
  the GYP->GN migration is done, and so we should not add things for
  developers that can't easily be added to GN itself.

* MB is not intended to replace the
  [CR tool](https://code.google.com/p/chromium/wiki/CRUserManual). Not
  only is it only intended to replace the gyp\_chromium part of `'gclient
  runhooks'`, it is not really meant as a developer-facing tool.
                                                                                                                                                                                                             node-23.7.0/deps/v8/tools/mb/docs/user_guide.md                                                     0000664 0000000 0000000 00000031142 14746647661 0021211 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # The MB (Meta-Build wrapper) user guide

[TOC]

## Introduction

`mb` is a simple python wrapper around the GYP and GN meta-build tools to
be used as part of the GYP->GN migration.

It is intended to be used by bots to make it easier to manage the configuration
each bot builds (i.e., the configurations can be changed from chromium
commits), and to consolidate the list of all of the various configurations
that Chromium is built in.

Ideally this tool will no longer be needed after the migration is complete.

For more discussion of MB, see also [the design spec](design_spec.md).

## MB subcommands

### `mb analyze`

`mb analyze` is responsible for determining what targets are affected by
a list of files (e.g., the list of files in a patch on a trybot):

```
mb analyze -c chromium_linux_rel //out/Release input.json output.json
```

Either the `-c/--config` flag or the `-m/--master` and `-b/--builder` flags
must be specified so that `mb` can figure out which config to use.

The first positional argument must be a GN-style "source-absolute" path
to the build directory.

The second positional argument is a (normal) path to a JSON file containing
a single object with the following fields:

  * `files`: an array of the modified filenames to check (as paths relative to
    the checkout root).
  * `test_targets`: an array of (ninja) build targets that needed to run the
    tests we wish to run. An empty array will be treated as if there are
    no tests that will be run.
  * `additional_compile_targets`: an array of (ninja) build targets that
    reflect the stuff we might want to build *in addition to* the list
    passed in `test_targets`. Targets in this list will be treated
    specially, in the following way: if a given target is a "meta"
    (GN: group, GYP: none) target like 'blink_tests' or or even the
    ninja-specific 'all' target, then only the *dependencies* of the
    target that are affected by the modified files will be rebuilt
    (not the target itself, which might also cause unaffected dependencies
    to be rebuilt). An empty list will be treated as if there are no additional
    targets to build.
    Empty lists for both `test_targets` and `additional_compile_targets`
    would cause no work to be done, so will result in an error.
  * `targets`: a legacy field that resembled a union of `compile_targets`
    and `test_targets`. Support for this field will be removed once the
    bots have been updated to use compile_targets and test_targets instead.

The third positional argument is a (normal) path to where mb will write
the result, also as a JSON object. This object may contain the following
fields:

  * `error`: this should only be present if something failed.
  * `compile_targets`: the list of ninja targets that should be passed
    directly to the corresponding ninja / compile.py invocation. This
    list may contain entries that are *not* listed in the input (see
    the description of `additional_compile_targets` above and
    [design_spec.md](the design spec) for how this works).
  * `invalid_targets`: a list of any targets that were passed in
    either of the input lists that weren't actually found in the graph.
  * `test_targets`: the subset of the input `test_targets` that are
    potentially out of date, indicating that the matching test steps
    should be re-run.
  * `targets`: a legacy field that indicates the subset of the input `targets`
    that depend on the input `files`.
  * `build_targets`: a legacy field that indicates the minimal subset of
    targets needed to build all of `targets` that were affected.
  * `status`: a field containing one of three strings:

    * `"Found dependency"` (build the `compile_targets`)
    * `"No dependency"` (i.e., no build needed)
    * `"Found dependency (all)"` (`test_targets` is returned as-is;
       `compile_targets` should contain the union of `test_targets` and
       `additional_compile_targets`. In this case the targets do not
       need to be pruned).

See [design_spec.md](the design spec) for more details and examples; the
differences can be subtle.  We won't even go into how the `targets` and
`build_targets` differ from each other or from `compile_targets` and
`test_targets`.

The `-b/--builder`, `-c/--config`, `-f/--config-file`, `-m/--master`,
`-q/--quiet`, and `-v/--verbose` flags work as documented for `mb gen`.

### `mb audit`

`mb audit` is used to track the progress of the GYP->GN migration. You can
use it to check a single master, or all the masters we care about. See
`mb help audit` for more details (most people are not expected to care about
this).

### `mb gen`

`mb gen` is responsible for generating the Ninja files by invoking either GYP
or GN as appropriate. It takes arguments to specify a build config and
a directory, then runs GYP or GN as appropriate:

```
% mb gen -m tryserver.chromium.linux -b linux_rel //out/Release
% mb gen -c linux_rel_trybot //out/Release
```

Either the `-c/--config` flag or the `-m/--master` and `-b/--builder` flags
must be specified so that `mb` can figure out which config to use. The
`--phase` flag must also be used with builders that have multiple
build/compile steps (and only with those builders).

By default, MB will look for a bot config file under `//ios/build/bots` (see
[design_spec.md](the design spec) for details of how the bot config files
work). If no matching one is found, will then look in
`//tools/mb/mb_config.pyl` to look up the config information, but you can
specify a custom config file using the `-f/--config-file` flag.

The path must be a GN-style "source-absolute" path (as above).

You can pass the `-n/--dryrun` flag to mb gen to see what will happen without
actually writing anything.

You can pass the `-q/--quiet` flag to get mb to be silent unless there is an
error, and pass the `-v/--verbose` flag to get mb to log all of the files
that are read and written, and all the commands that are run.

If gen ends up using GYP, the path must have a valid GYP configuration as the
last component of the path (i.e., specify `//out/Release_x64`, not `//out`).
The gyp script defaults to `//build/gyp_chromium`, but can be overridden with
the `--gyp-script` flag, e.g. `--gyp-script=gypfiles/gyp_v8`.

### `mb help`

Produces help output on the other subcommands

### `mb lookup`

Prints what command will be run by `mb gen` (like `mb gen -n` but does
not require you to specify a path).

The `-b/--builder`, `-c/--config`, `-f/--config-file`, `-m/--master`,
`--phase`, `-q/--quiet`, and `-v/--verbose` flags work as documented for
`mb gen`.

### `mb validate`

Does internal checking to make sure the config file is syntactically
valid and that all of the entries are used properly. It does not validate
that the flags make sense, or that the builder names are legal or
comprehensive, but it does complain about configs and mixins that aren't
used.

The `-f/--config-file` and `-q/--quiet` flags work as documented for
`mb gen`.

This is mostly useful as a presubmit check and for verifying changes to
the config file.

### `mb gerrit-buildbucket-config`

Generates a gerrit buildbucket configuration file and prints it to
stdout. This file contains the list of trybots shown in gerrit's UI.

The master copy of the buildbucket.config file lives
in a separate branch of the chromium repository. Run `mb
gerrit-buildbucket-config > buildbucket.config.new && git fetch origin
refs/meta/config:refs/remotes/origin/meta/config && git checkout
-t -b meta_config origin/meta/config && mv buildbucket.config.new
buildbucket.config` to update the file.

Note that after committing, `git cl upload` will not work. Instead, use `git
push origin HEAD:refs/for/refs/meta/config` to upload the CL for review.

## Isolates and Swarming

`mb gen` is also responsible for generating the `.isolate` and
`.isolated.gen.json` files needed to run test executables through swarming
in a GN build (in a GYP build, this is done as part of the compile step).

If you wish to generate the isolate files, pass `mb gen` the
`--swarming-targets-file` command line argument; that arg should be a path
to a file containing a list of ninja build targets to compute the runtime
dependencies for (on Windows, use the ninja target name, not the file, so
`base_unittests`, not `base_unittests.exe`).

MB will take this file, translate each build target to the matching GN
label (e.g., `base_unittests` -> `//base:base_unittests`, write that list
to a file called `runtime_deps` in the build directory, and pass that to
`gn gen $BUILD ... --runtime-deps-list-file=$BUILD/runtime_deps`.

Once GN has computed the lists of runtime dependencies, MB will then
look up the command line for each target (currently this is hard-coded
in [mb.py](https://code.google.com/p/chromium/codesearch?q=mb.py#chromium/src/tools/mb/mb.py&q=mb.py%20GetIsolateCommand&sq=package:chromium&type=cs)), and write out the
matching `.isolate` and `.isolated.gen.json` files.

## The `mb_config.pyl` config file

The `mb_config.pyl` config file is intended to enumerate all of the
supported build configurations for Chromium. Generally speaking, you
should never need to (or want to) build a configuration that isn't
listed here, and so by using the configs in this file you can avoid
having to juggle long lists of GYP_DEFINES and gn args by hand.

`mb_config.pyl` is structured as a file containing a single PYthon Literal
expression: a dictionary with three main keys, `masters`, `configs` and
`mixins`.

The `masters` key contains a nested series of dicts containing mappings
of master -> builder -> config . This allows us to isolate the buildbot
recipes from the actual details of the configs. The config should either
be a single string value representing a key in the `configs` dictionary,
or a list of strings, each of which is a key in the `configs` dictionary;
the latter case is for builders that do multiple compiles with different
arguments in a single build, and must *only* be used for such builders
(where a --phase argument must be supplied in each lookup or gen call).

The `configs` key points to a dictionary of named build configurations.

There should be an key in this dict for every supported configuration
of Chromium, meaning every configuration we have a bot for, and every
configuration commonly used by developers but that we may not have a bot
for.

The value of each key is a list of "mixins" that will define what that
build_config does. Each item in the list must be an entry in the dictionary
value of the `mixins` key.

Each mixin value is itself a dictionary that contains one or more of the
following keys:

  * `gyp_crosscompile`: a boolean; if true, GYP_CROSSCOMPILE=1 is set in
    the environment and passed to GYP.
  * `gyp_defines`: a string containing a list of GYP_DEFINES.
  * `gn_args`: a string containing a list of values passed to gn --args.
  * `mixins`: a list of other mixins that should be included.
  * `type`: a string with either the value `gyp` or `gn`;
    setting this indicates which meta-build tool to use.

When `mb gen` or `mb analyze` executes, it takes a config name, looks it
up in the 'configs' dict, and then does a left-to-right expansion of the
mixins; gyp_defines and gn_args values are concatenated, and the type values
override each other.

For example, if you had:

```
{
  'configs`: {
    'linux_release_trybot': ['gyp_release', 'trybot'],
    'gn_shared_debug': None,
  }
  'mixins': {
    'bot': {
      'gyp_defines': 'use_remoteexec=1 dcheck_always_on=0',
      'gn_args': 'use_remoteexec=true dcheck_always_on=false',
    },
    'debug': {
      'gn_args': 'is_debug=true',
    },
    'gn': {'type': 'gn'},
    'gyp_release': {
      'mixins': ['release'],
      'type': 'gyp',
    },
    'release': {
      'gn_args': 'is_debug=false',
    }
    'shared': {
      'gn_args': 'is_component_build=true',
      'gyp_defines': 'component=shared_library',
    },
    'trybot': {
      'gyp_defines': 'dcheck_always_on=1',
      'gn_args': 'dcheck_always_on=true',
    }
  }
}
```

and you ran `mb gen -c linux_release_trybot //out/Release`, it would
translate into a call to `gyp_chromium -G Release` with `GYP_DEFINES` set to
`"use_remoteexec=true dcheck_always_on=false dcheck_always_on=true"`.

(From that you can see that mb is intentionally dumb and does not
attempt to de-dup the flags, it lets gyp do that).

## Debugging MB

By design, MB should be simple enough that very little can go wrong.

The most obvious issue is that you might see different commands being
run than you expect; running `'mb -v'` will print what it's doing and
run the commands; `'mb -n'` will print what it will do but *not* run
the commands.

If you hit weirder things than that, add some print statements to the
python script, send a question to gn-dev@chromium.org, or
[file a bug](https://crbug.com/new) with the label
'mb' and cc: dpranke@chromium.org.
                                                                                                                                                                                                                                                                                                                                                                                                                              node-23.7.0/deps/v8/tools/mb/mb                                                                     0000775 0000000 0000000 00000000416 14746647661 0016130 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env bash
# Copyright 2015 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

base_dir=$(dirname "$0")

PYTHONDONTWRITEBYTECODE=1 exec python "$base_dir/mb.py" "$@"
                                                                                                                                                                                                                                                  node-23.7.0/deps/v8/tools/mb/mb.bat                                                                 0000775 0000000 0000000 00000000205 14746647661 0016671 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        @echo off
setlocal
:: This is required with cygwin only.
PATH=%~dp0;%PATH%
set PYTHONDONTWRITEBYTECODE=1
call python "%~dp0mb.py" %*
                                                                                                                                                                                                                                                                                                                                                                                           node-23.7.0/deps/v8/tools/mb/mb.py                                                                  0000775 0000000 0000000 00000127336 14746647661 0016572 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3
# Copyright 2016 the V8 project authors. All rights reserved.
# Copyright 2015 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

"""MB - the Meta-Build wrapper around GN.

MB is a wrapper script for GN that can be used to generate build files
for sets of canned configurations and analyze them.
"""

# for py2/py3 compatibility
from __future__ import print_function

import argparse
import ast
import errno
import json
import os
import pipes
import platform
import pprint
import re
import shutil
import sys
import subprocess
import tempfile
import traceback

# for py2/py3 compatibility
try:
  from urllib.parse import quote
except ImportError:
  from urllib2 import quote
try:
  from urllib.request import urlopen
except ImportError:
  from urllib2 import urlopen

CHROMIUM_SRC_DIR = os.path.dirname(os.path.dirname(os.path.dirname(
    os.path.abspath(__file__))))
sys.path = [os.path.join(CHROMIUM_SRC_DIR, 'build')] + sys.path

import gn_helpers

try:
  cmp              # Python 2
except NameError:  # Python 3
  def cmp(x, y):   # pylint: disable=redefined-builtin
    return (x > y) - (x < y)


def _v8_builder_fallback(builder, builder_group):
  """Fallback to V8 builder names before splitting builder/tester.

  This eases splitting builders and testers on release branches and
  can be removed as soon as all builder have been split and all MB configs
  exist on all branches.
  """
  builders = [builder]
  if builder.endswith(' - builder'):
    builders.append(builder[:-len(' - builder')])
  elif builder.endswith(' builder'):
    builders.append(builder[:-len(' builder')])

  for b in builders:
    if b in builder_group:
      return builder_group[b]
  return None


def main(args):
  mbw = MetaBuildWrapper()
  return mbw.Main(args)


class MetaBuildWrapper():
  def __init__(self):
    self.chromium_src_dir = CHROMIUM_SRC_DIR
    self.default_config = os.path.join(self.chromium_src_dir, 'infra', 'mb',
                                       'mb_config.pyl')
    self.default_isolate_map = os.path.join(self.chromium_src_dir, 'infra',
                                            'mb', 'gn_isolate_map.pyl')
    self.executable = sys.executable
    self.platform = sys.platform
    self.sep = os.sep
    self.args = argparse.Namespace()
    self.configs = {}
    self.luci_tryservers = {}
    self.builder_groups = {}
    self.mixins = {}
    self.isolate_exe = 'isolate.exe' if self.platform.startswith(
        'win') else 'isolate'

  def Main(self, args):
    self.ParseArgs(args)
    try:
      ret = self.args.func()
      if ret:
        self.DumpInputFiles()
      return ret
    except KeyboardInterrupt:
      self.Print('interrupted, exiting')
      return 130
    except Exception:
      self.DumpInputFiles()
      s = traceback.format_exc()
      for l in s.splitlines():
        self.Print(l)
      return 1

  def ParseArgs(self, argv):
    def AddCommonOptions(subp):
      subp.add_argument('-b', '--builder',
                        help='builder name to look up config from')
      subp.add_argument(
          '-m',  '--builder-group',
          help='builder group name to look up config from')
      subp.add_argument('-c', '--config',
                        help='configuration to analyze')
      subp.add_argument('--phase',
                        help='optional phase name (used when builders '
                             'do multiple compiles with different '
                             'arguments in a single build)')
      subp.add_argument('-f', '--config-file', metavar='PATH',
                        default=self.default_config,
                        help='path to config file '
                             '(default is %(default)s)')
      subp.add_argument(
          '-i',
          '--isolate-map-file',
          metavar='PATH',
          help='path to isolate map file '
          '(default is %(default)s)',
          default=[],
          action='append',
          dest='isolate_map_files')
      subp.add_argument(
          '--android-version-code',
          help='Sets GN arg android_default_version_code')
      subp.add_argument('--android-version-name',
                        help='Sets GN arg android_default_version_name')
      subp.add_argument('-n', '--dryrun', action='store_true',
                        help='Do a dry run (i.e., do nothing, just print '
                             'the commands that will run)')
      subp.add_argument('-v', '--verbose', action='store_true',
                        help='verbose logging')

    parser = argparse.ArgumentParser(prog='mb')
    subps = parser.add_subparsers()

    subp = subps.add_parser('analyze',
                            help='analyze whether changes to a set of files '
                                 'will cause a set of binaries to be rebuilt.')
    AddCommonOptions(subp)
    subp.add_argument('path', nargs=1,
                      help='path build was generated into.')
    subp.add_argument('input_path', nargs=1,
                      help='path to a file containing the input arguments '
                           'as a JSON object.')
    subp.add_argument('output_path', nargs=1,
                      help='path to a file containing the output arguments '
                           'as a JSON object.')
    subp.add_argument('--json-output',
                      help='Write errors to json.output')
    subp.set_defaults(func=self.CmdAnalyze)

    subp = subps.add_parser('export',
                            help='print out the expanded configuration for'
                                 'each builder as a JSON object')
    subp.add_argument(
        '-f',
        '--config-file',
        metavar='PATH',
        default=self.default_config,
        help='path to config file (default is %(default)s)')
    subp.set_defaults(func=self.CmdExport)

    subp = subps.add_parser('gen',
                            help='generate a new set of build files')
    AddCommonOptions(subp)
    subp.add_argument('--swarming-targets-file',
                      help='save runtime dependencies for targets listed '
                           'in file.')
    subp.add_argument('--json-output',
                      help='Write errors to json.output')
    subp.add_argument('path', nargs=1,
                      help='path to generate build into')
    subp.set_defaults(func=self.CmdGen)

    subp = subps.add_parser('isolate',
                            help='generate the .isolate files for a given'
                                 'binary')
    AddCommonOptions(subp)
    subp.add_argument('path', nargs=1,
                      help='path build was generated into')
    subp.add_argument('target', nargs=1,
                      help='ninja target to generate the isolate for')
    subp.set_defaults(func=self.CmdIsolate)

    subp = subps.add_parser('lookup',
                            help='look up the command for a given config or '
                                 'builder')
    AddCommonOptions(subp)
    subp.add_argument('--quiet', default=False, action='store_true',
                      help='Print out just the arguments, '
                           'do not emulate the output of the gen subcommand.')
    subp.add_argument('--recursive', default=False, action='store_true',
                      help='Lookup arguments from imported files, '
                           'implies --quiet')
    subp.set_defaults(func=self.CmdLookup)

    subp = subps.add_parser(
        'run',
        help='build and run the isolated version of a '
             'binary',
        formatter_class=argparse.RawDescriptionHelpFormatter)
    subp.description = (
        'Build, isolate, and run the given binary with the command line\n'
        'listed in the isolate. You may pass extra arguments after the\n'
        'target; use "--" if the extra arguments need to include switches.\n'
        '\n'
        'Examples:\n'
        '\n'
        '  % tools/mb/mb.py run -m chromium.linux -b "Linux Builder" \\\n'
        '    //out/Default content_browsertests\n'
        '\n'
        '  % tools/mb/mb.py run out/Default content_browsertests\n'
        '\n'
        '  % tools/mb/mb.py run out/Default content_browsertests -- \\\n'
        '    --test-launcher-retry-limit=0'
        '\n'
    )
    AddCommonOptions(subp)
    subp.add_argument('-j', '--jobs', dest='jobs', type=int,
                      help='Number of jobs to pass to ninja')
    subp.add_argument('--no-build', dest='build', default=True,
                      action='store_false',
                      help='Do not build, just isolate and run')
    subp.add_argument('path', nargs=1,
                      help=('path to generate build into (or use).'
                            ' This can be either a regular path or a '
                            'GN-style source-relative path like '
                            '//out/Default.'))
    subp.add_argument('-d', '--dimension', default=[], action='append', nargs=2,
                      dest='dimensions', metavar='FOO bar',
                      help='dimension to filter on')
    subp.add_argument('--no-default-dimensions', action='store_false',
                      dest='default_dimensions', default=True,
                      help='Do not automatically add dimensions to the task')
    subp.add_argument('target', nargs=1,
                      help='ninja target to build and run')
    subp.add_argument('extra_args', nargs='*',
                      help=('extra args to pass to the isolate to run. Use '
                            '"--" as the first arg if you need to pass '
                            'switches'))
    subp.set_defaults(func=self.CmdRun)

    subp = subps.add_parser('validate',
                            help='validate the config file')
    subp.add_argument('-f', '--config-file', metavar='PATH',
                      default=self.default_config,
                      help='path to config file (default is %(default)s)')
    subp.set_defaults(func=self.CmdValidate)

    subp = subps.add_parser('gerrit-buildbucket-config',
                            help='Print buildbucket.config for gerrit '
                            '(see MB user guide)')
    subp.add_argument('-f', '--config-file', metavar='PATH',
                      default=self.default_config,
                      help='path to config file (default is %(default)s)')
    subp.set_defaults(func=self.CmdBuildbucket)

    subp = subps.add_parser('help',
                            help='Get help on a subcommand.')
    subp.add_argument(nargs='?', action='store', dest='subcommand',
                      help='The command to get help for.')
    subp.set_defaults(func=self.CmdHelp)

    self.args = parser.parse_args(argv)

  def DumpInputFiles(self):

    def DumpContentsOfFilePassedTo(arg_name, path):
      if path and self.Exists(path):
        self.Print("\n# To recreate the file passed to %s:" % arg_name)
        self.Print("%% cat > %s <<EOF" % path)
        contents = self.ReadFile(path)
        self.Print(contents)
        self.Print("EOF\n%\n")

    if getattr(self.args, 'input_path', None):
      DumpContentsOfFilePassedTo(
          'argv[0] (input_path)', self.args.input_path[0])
    if getattr(self.args, 'swarming_targets_file', None):
      DumpContentsOfFilePassedTo(
          '--swarming-targets-file', self.args.swarming_targets_file)

  def CmdAnalyze(self):
    vals = self.Lookup()
    return self.RunGNAnalyze(vals)

  def CmdExport(self):
    self.ReadConfigFile()
    obj = {}
    for builder_group, builders in self.builder_groups.items():
      obj[builder_group] = {}
      for builder in builders:
        config = self.builder_groups[builder_group][builder]
        if not config:
          continue

        if isinstance(config, dict):
          args = {k: self.FlattenConfig(v)['gn_args']
                  for k, v in config.items()}
        elif config.startswith('//'):
          args = config
        else:
          args = self.FlattenConfig(config)['gn_args']
          if 'error' in args:
            continue

        obj[builder_group][builder] = args

    # Dump object and trim trailing whitespace.
    s = '\n'.join(l.rstrip() for l in
                  json.dumps(obj, sort_keys=True, indent=2).splitlines())
    self.Print(s)
    return 0

  def CmdGen(self):
    vals = self.Lookup()
    return self.RunGNGen(vals)

  def CmdHelp(self):
    if self.args.subcommand:
      self.ParseArgs([self.args.subcommand, '--help'])
    else:
      self.ParseArgs(['--help'])

  def CmdIsolate(self):
    vals = self.GetConfig()
    if not vals:
      return 1
    return self.RunGNIsolate()

  def CmdLookup(self):
    vals = self.Lookup()
    gn_args = self.GNArgs(vals, expand_imports=self.args.recursive)
    if self.args.quiet or self.args.recursive:
      self.Print(gn_args, end='')
    else:
      cmd = self.GNCmd('gen', '_path_')
      self.Print('\nWriting """\\\n%s""" to _path_/args.gn.\n' % gn_args)
      env = None

      self.PrintCmd(cmd, env)
    return 0

  def CmdRun(self):
    vals = self.GetConfig()
    if not vals:
      return 1

    build_dir = self.args.path[0]
    target = self.args.target[0]

    if self.args.build:
      ret = self.Build(target)
      if ret:
        return ret
    ret = self.RunGNIsolate()
    if ret:
      return ret

    return self._RunLocallyIsolated(build_dir, target)

  def _RunLocallyIsolated(self, build_dir, target):
    cmd = [
        self.PathJoin(self.chromium_src_dir, 'tools', 'luci-go',
                      self.isolate_exe),
        'run',
        '-i',
        self.ToSrcRelPath('%s/%s.isolate' % (build_dir, target)),
      ]
    if self.args.extra_args:
      cmd += ['--'] + self.args.extra_args
    ret, _, _ = self.Run(cmd, force_verbose=True, buffer_output=False)
    return ret

  def _DefaultDimensions(self):
    if not self.args.default_dimensions:
      return []

    # This code is naive and just picks reasonable defaults per platform.
    if self.platform == 'darwin':
      os_dim = ('os', 'Mac-10.12')
    elif self.platform.startswith('linux'):
      os_dim = ('os', 'Ubuntu-16.04')
    elif self.platform == 'win32':
      os_dim = ('os', 'Windows-10')
    else:
      raise MBErr('unrecognized platform string "%s"' % self.platform)

    return [('pool', 'Chrome'),
            ('cpu', 'x86-64'),
            os_dim]

  def CmdBuildbucket(self):
    self.ReadConfigFile()

    self.Print('# This file was generated using '
               '"tools/mb/mb.py gerrit-buildbucket-config".')

    for luci_tryserver in sorted(self.luci_tryservers):
      self.Print('[bucket "luci.%s"]' % luci_tryserver)
      for bot in sorted(self.luci_tryservers[luci_tryserver]):
        self.Print('\tbuilder = %s' % bot)

    for builder_group in sorted(self.builder_groups):
      if builder_group.startswith('tryserver.'):
        self.Print('[bucket "builder_group.%s"]' % builder_group)
        for bot in sorted(self.builder_groups[builder_group]):
          self.Print('\tbuilder = %s' % bot)

    return 0

  def CmdValidate(self, print_ok=True):
    errs = []

    # Read the file to make sure it parses.
    self.ReadConfigFile()

    # Build a list of all of the configs referenced by builders.
    all_configs = {}
    for builder_group in self.builder_groups:
      for config in self.builder_groups[builder_group].values():
        if isinstance(config, dict):
          for c in config.values():
            all_configs[c] = builder_group
        else:
          all_configs[config] = builder_group

    # Check that every referenced args file or config actually exists.
    for config, loc in all_configs.items():
      if config.startswith('//'):
        if not self.Exists(self.ToAbsPath(config)):
          errs.append('Unknown args file "%s" referenced from "%s".' %
                      (config, loc))
      elif not config in self.configs:
        errs.append('Unknown config "%s" referenced from "%s".' %
                    (config, loc))

    # Check that every actual config is actually referenced.
    for config in self.configs:
      if not config in all_configs:
        errs.append('Unused config "%s".' % config)

    # Figure out the whole list of mixins, and check that every mixin
    # listed by a config or another mixin actually exists.
    referenced_mixins = set()
    for config, mixins in self.configs.items():
      for mixin in mixins:
        if not mixin in self.mixins:
          errs.append('Unknown mixin "%s" referenced by config "%s".' %
                      (mixin, config))
        referenced_mixins.add(mixin)

    for mixin in self.mixins:
      for sub_mixin in self.mixins[mixin].get('mixins', []):
        if not sub_mixin in self.mixins:
          errs.append('Unknown mixin "%s" referenced by mixin "%s".' %
                      (sub_mixin, mixin))
        referenced_mixins.add(sub_mixin)

    # Check that every mixin defined is actually referenced somewhere.
    for mixin in self.mixins:
      if not mixin in referenced_mixins:
        errs.append('Unreferenced mixin "%s".' % mixin)

    if errs:
      raise MBErr(('mb config file %s has problems:' % self.args.config_file) +
                    '\n  ' + '\n  '.join(errs))

    if print_ok:
      self.Print('mb config file %s looks ok.' % self.args.config_file)
    return 0

  def GetConfig(self):
    build_dir = self.args.path[0]

    vals = self.DefaultVals()
    if self.args.builder or self.args.builder_group or self.args.config:
      vals = self.Lookup()
      # Re-run gn gen in order to ensure the config is consistent with the
      # build dir.
      self.RunGNGen(vals)
      return vals

    toolchain_path = self.PathJoin(self.ToAbsPath(build_dir),
                                   'toolchain.ninja')
    if not self.Exists(toolchain_path):
      self.Print('Must either specify a path to an existing GN build dir '
                 'or pass in a -m/-b pair or a -c flag to specify the '
                 'configuration')
      return {}

    vals['gn_args'] = self.GNArgsFromDir(build_dir)
    return vals

  def GNArgsFromDir(self, build_dir):
    args_contents = ""
    gn_args_path = self.PathJoin(self.ToAbsPath(build_dir), 'args.gn')
    if self.Exists(gn_args_path):
      args_contents = self.ReadFile(gn_args_path)
    gn_args = []
    for l in args_contents.splitlines():
      fields = l.split(' ')
      name = fields[0]
      val = ' '.join(fields[2:])
      gn_args.append('%s=%s' % (name, val))

    return ' '.join(gn_args)

  def Lookup(self):
    vals = self.ReadIOSBotConfig()
    if not vals:
      self.ReadConfigFile()
      config = self.ConfigFromArgs()
      if config.startswith('//'):
        if not self.Exists(self.ToAbsPath(config)):
          raise MBErr('args file "%s" not found' % config)
        vals = self.DefaultVals()
        vals['args_file'] = config
      else:
        if not config in self.configs:
          raise MBErr('Config "%s" not found in %s' %
                      (config, self.args.config_file))
        vals = self.FlattenConfig(config)
    return vals

  def ReadIOSBotConfig(self):
    if not self.args.builder_group or not self.args.builder:
      return {}
    path = self.PathJoin(self.chromium_src_dir, 'ios', 'build', 'bots',
                         self.args.builder_group, self.args.builder + '.json')
    if not self.Exists(path):
      return {}

    contents = json.loads(self.ReadFile(path))
    gn_args = ' '.join(contents.get('gn_args', []))

    vals = self.DefaultVals()
    vals['gn_args'] = gn_args
    return vals

  def ReadConfigFile(self):
    if not self.Exists(self.args.config_file):
      raise MBErr('config file not found at %s' % self.args.config_file)

    try:
      contents = ast.literal_eval(self.ReadFile(self.args.config_file))
    except SyntaxError as e:
      raise MBErr('Failed to parse config file "%s": %s' %
                 (self.args.config_file, e)) from e

    self.configs = contents['configs']
    self.luci_tryservers = contents.get('luci_tryservers', {})
    self.builder_groups = contents['builder_groups']
    self.mixins = contents['mixins']

  def ReadIsolateMap(self):
    if not self.args.isolate_map_files:
      self.args.isolate_map_files = [self.default_isolate_map]

    for f in self.args.isolate_map_files:
      if not self.Exists(f):
        raise MBErr('isolate map file not found at %s' % f)
    isolate_maps = {}
    for isolate_map in self.args.isolate_map_files:
      try:
        isolate_map = ast.literal_eval(self.ReadFile(isolate_map))
        duplicates = set(isolate_map).intersection(isolate_maps)
        if duplicates:
          raise MBErr(
              'Duplicate targets in isolate map files: %s.' %
              ', '.join(duplicates))
        isolate_maps.update(isolate_map)
      except SyntaxError as e:
        raise MBErr('Failed to parse isolate map file "%s": %s' %
                    (isolate_map, e)) from e
    return isolate_maps

  def ConfigFromArgs(self):
    if self.args.config:
      if self.args.builder_group or self.args.builder:
        raise MBErr(
          'Can not specific both -c/--config and -m/--builder-group or '
          '-b/--builder')

      return self.args.config

    if not self.args.builder_group or not self.args.builder:
      raise MBErr('Must specify either -c/--config or '
                  '(-m/--builder-group and -b/--builder)')

    if not self.args.builder_group in self.builder_groups:
      raise MBErr('Builder groups name "%s" not found in "%s"' %
                  (self.args.builder_group, self.args.config_file))

    config = _v8_builder_fallback(
        self.args.builder, self.builder_groups[self.args.builder_group])

    if not config:
      raise MBErr(
        'Builder name "%s"  not found under builder_groups[%s] in "%s"' %
        (self.args.builder, self.args.builder_group, self.args.config_file))

    if isinstance(config, dict):
      if self.args.phase is None:
        raise MBErr('Must specify a build --phase for %s on %s' %
                    (self.args.builder, self.args.builder_group))
      phase = str(self.args.phase)
      if phase not in config:
        raise MBErr('Phase %s doesn\'t exist for %s on %s' %
                    (phase, self.args.builder, self.args.builder_group))
      return config[phase]

    if self.args.phase is not None:
      raise MBErr('Must not specify a build --phase for %s on %s' %
                  (self.args.builder, self.args.builder_group))
    return config

  def FlattenConfig(self, config):
    mixins = self.configs[config]
    vals = self.DefaultVals()

    visited = []
    self.FlattenMixins(mixins, vals, visited)
    return vals

  def DefaultVals(self):
    return {
      'args_file': '',
      'cros_passthrough': False,
      'gn_args': '',
    }

  def FlattenMixins(self, mixins, vals, visited):
    for m in mixins:
      if m not in self.mixins:
        raise MBErr('Unknown mixin "%s"' % m)

      visited.append(m)

      mixin_vals = self.mixins[m]

      if 'cros_passthrough' in mixin_vals:
        vals['cros_passthrough'] = mixin_vals['cros_passthrough']
      if 'args_file' in mixin_vals:
        if vals['args_file']:
          raise MBErr('args_file specified multiple times in mixins '
                      'for %s on %s' %
                      (self.args.builder, self.args.builder_group))
        vals['args_file'] = mixin_vals['args_file']
      if 'gn_args' in mixin_vals:
        if vals['gn_args']:
          vals['gn_args'] += ' ' + mixin_vals['gn_args']
        else:
          vals['gn_args'] = mixin_vals['gn_args']

      if 'mixins' in mixin_vals:
        self.FlattenMixins(mixin_vals['mixins'], vals, visited)
    return vals

  def RunGNGen(self, vals, compute_grit_inputs_for_analyze=False):
    build_dir = self.args.path[0]

    cmd = self.GNCmd('gen', build_dir, '--check')
    gn_args = self.GNArgs(vals)
    if compute_grit_inputs_for_analyze:
      gn_args += ' compute_grit_inputs_for_analyze=true'

    # Since GN hasn't run yet, the build directory may not even exist.
    self.MaybeMakeDirectory(self.ToAbsPath(build_dir))

    gn_args_path = self.ToAbsPath(build_dir, 'args.gn')
    self.WriteFile(gn_args_path, gn_args, force_verbose=True)

    swarming_targets = []
    if getattr(self.args, 'swarming_targets_file', None):
      # We need GN to generate the list of runtime dependencies for
      # the compile targets listed (one per line) in the file so
      # we can run them via swarming. We use gn_isolate_map.pyl to convert
      # the compile targets to the matching GN labels.
      path = self.args.swarming_targets_file
      if not self.Exists(path):
        self.WriteFailureAndRaise('"%s" does not exist' % path,
                                  output_path=None)
      contents = self.ReadFile(path)
      swarming_targets = set(contents.splitlines())

      isolate_map = self.ReadIsolateMap()
      err, labels = self.MapTargetsToLabels(isolate_map, swarming_targets)
      if err:
        raise MBErr(err)

      gn_runtime_deps_path = self.ToAbsPath(build_dir, 'runtime_deps')
      self.WriteFile(gn_runtime_deps_path, '\n'.join(labels) + '\n')
      cmd.append('--runtime-deps-list-file=%s' % gn_runtime_deps_path)

    ret, output, _ = self.Run(cmd)
    if ret:
      if self.args.json_output:
        # write errors to json.output
        self.WriteJSON({'output': output}, self.args.json_output)
      # If `gn gen` failed, we should exit early rather than trying to
      # generate isolates. Run() will have already logged any error output.
      self.Print('GN gen failed: %d' % ret)
      return ret

    android = 'target_os="android"' in vals['gn_args']
    for target in swarming_targets:
      if android:
        # Android targets may be either android_apk or executable. The former
        # will result in runtime_deps associated with the stamp file, while the
        # latter will result in runtime_deps associated with the executable.
        label = isolate_map[target]['label']
        runtime_deps_targets = [
            target + '.runtime_deps',
            'obj/%s.stamp.runtime_deps' % label.replace(':', '/')]
      elif (isolate_map[target]['type'] == 'script' or
            isolate_map[target].get('label_type') == 'group'):
        # For script targets, the build target is usually a group,
        # for which gn generates the runtime_deps next to the stamp file
        # for the label, which lives under the obj/ directory, but it may
        # also be an executable.
        label = isolate_map[target]['label']
        runtime_deps_targets = [
            'obj/%s.stamp.runtime_deps' % label.replace(':', '/')]
        if self.platform == 'win32':
          runtime_deps_targets += [ target + '.exe.runtime_deps' ]
        else:
          runtime_deps_targets += [ target + '.runtime_deps' ]
      elif self.platform == 'win32':
        runtime_deps_targets = [target + '.exe.runtime_deps']
      else:
        runtime_deps_targets = [target + '.runtime_deps']

      for r in runtime_deps_targets:
        runtime_deps_path = self.ToAbsPath(build_dir, r)
        if self.Exists(runtime_deps_path):
          break
      else:
        raise MBErr('did not generate any of %s' %
                    ', '.join(runtime_deps_targets))

      runtime_deps = self.ReadFile(runtime_deps_path).splitlines()

      self.WriteIsolateFiles(build_dir, target, runtime_deps)

    return 0

  def RunGNIsolate(self):
    target = self.args.target[0]
    isolate_map = self.ReadIsolateMap()
    err, labels = self.MapTargetsToLabels(isolate_map, [target])
    if err:
      raise MBErr(err)
    label = labels[0]

    build_dir = self.args.path[0]

    cmd = self.GNCmd('desc', build_dir, label, 'runtime_deps')
    ret, out, _ = self.Call(cmd)
    if ret:
      if out:
        self.Print(out)
      return ret

    runtime_deps = out.splitlines()

    self.WriteIsolateFiles(build_dir, target, runtime_deps)

    ret, _, _ = self.Run([
        self.PathJoin(self.chromium_src_dir, 'tools', 'luci-go',
                      self.isolate_exe),
        'check',
        '-i',
        self.ToSrcRelPath('%s/%s.isolate' % (build_dir, target))],
        buffer_output=False)

    return ret

  def WriteIsolateFiles(self, build_dir, target, runtime_deps):
    isolate_path = self.ToAbsPath(build_dir, target + '.isolate')
    self.WriteFile(isolate_path,
      pprint.pformat({
        'variables': {
          'files': sorted(runtime_deps),
        }
      }) + '\n')

    self.WriteJSON(
      {
        'args': [
          '--isolate',
          self.ToSrcRelPath('%s/%s.isolate' % (build_dir, target)),
        ],
        'dir': self.chromium_src_dir,
        'version': 1,
      },
      isolate_path + 'd.gen.json',
    )

  def MapTargetsToLabels(self, isolate_map, targets):
    labels = []
    err = ''

    for target in targets:
      if target == 'all':
        labels.append(target)
      elif target.startswith('//'):
        labels.append(target)
      else:
        if target in isolate_map:
          if isolate_map[target]['type'] == 'unknown':
            err += ('test target "%s" type is unknown\n' % target)
          else:
            labels.append(isolate_map[target]['label'])
        else:
          err += ('target "%s" not found in '
                  '//infra/mb/gn_isolate_map.pyl\n' % target)

    return err, labels

  def GNCmd(self, subcommand, path, *args):
    if self.platform.startswith('linux'):
      subdir, exe = 'linux64', 'gn'
    elif self.platform == 'darwin':
      subdir, exe = 'mac', 'gn'
    else:
      subdir, exe = 'win', 'gn.exe'

    arch = platform.machine()
    if (arch.startswith('s390') or arch.startswith('ppc') or
        self.platform.startswith('aix')):
      # use gn in PATH
      gn_path = 'gn'
    else:
      gn_path = self.PathJoin(self.chromium_src_dir, 'buildtools', subdir, exe)
    return [gn_path, subcommand, path] + list(args)


  def GNArgs(self, vals, expand_imports=False):
    if vals['cros_passthrough']:
      if not 'GN_ARGS' in os.environ:
        raise MBErr('MB is expecting GN_ARGS to be in the environment')
      gn_args = os.environ['GN_ARGS']
      if not re.search('target_os.*=.*"chromeos"', gn_args):
        raise MBErr('GN_ARGS is missing target_os = "chromeos": (GN_ARGS=%s)' %
                    gn_args)
    else:
      gn_args = vals['gn_args']

    android_version_code = self.args.android_version_code
    if android_version_code:
      gn_args += ' android_default_version_code="%s"' % android_version_code

    android_version_name = self.args.android_version_name
    if android_version_name:
      gn_args += ' android_default_version_name="%s"' % android_version_name

    args_gn_lines = []
    parsed_gn_args = {}

    args_file = vals.get('args_file', None)
    if args_file:
      if expand_imports:
        content = self.ReadFile(self.ToAbsPath(args_file))
        parsed_gn_args = gn_helpers.FromGNArgs(content)
      else:
        args_gn_lines.append('import("%s")' % args_file)

    # Canonicalize the arg string into a sorted, newline-separated list
    # of key-value pairs, and de-dup the keys if need be so that only
    # the last instance of each arg is listed.
    parsed_gn_args.update(gn_helpers.FromGNArgs(gn_args))
    args_gn_lines.append(gn_helpers.ToGNString(parsed_gn_args))

    return '\n'.join(args_gn_lines)

  def ToAbsPath(self, build_path, *comps):
    return self.PathJoin(self.chromium_src_dir,
                         self.ToSrcRelPath(build_path),
                         *comps)

  def ToSrcRelPath(self, path):
    """Returns a relative path from the top of the repo."""
    if path.startswith('//'):
      return path[2:].replace('/', self.sep)
    return self.RelPath(path, self.chromium_src_dir)

  def RunGNAnalyze(self, vals):
    # Analyze runs before 'gn gen' now, so we need to run gn gen
    # in order to ensure that we have a build directory.
    ret = self.RunGNGen(vals, compute_grit_inputs_for_analyze=True)
    if ret:
      return ret

    build_path = self.args.path[0]
    input_path = self.args.input_path[0]
    gn_input_path = input_path + '.gn'
    output_path = self.args.output_path[0]
    gn_output_path = output_path + '.gn'

    inp = self.ReadInputJSON(['files', 'test_targets',
                              'additional_compile_targets'])
    if self.args.verbose:
      self.Print()
      self.Print('analyze input:')
      self.PrintJSON(inp)
      self.Print()


    # This shouldn't normally happen, but could due to unusual race conditions,
    # like a try job that gets scheduled before a patch lands but runs after
    # the patch has landed.
    if not inp['files']:
      self.Print('Warning: No files modified in patch, bailing out early.')
      self.WriteJSON({
            'status': 'No dependency',
            'compile_targets': [],
            'test_targets': [],
          }, output_path)
      return 0

    gn_inp = {}
    gn_inp['files'] = ['//' + f for f in inp['files'] if not f.startswith('//')]

    isolate_map = self.ReadIsolateMap()
    err, gn_inp['additional_compile_targets'] = self.MapTargetsToLabels(
        isolate_map, inp['additional_compile_targets'])
    if err:
      raise MBErr(err)

    err, gn_inp['test_targets'] = self.MapTargetsToLabels(
        isolate_map, inp['test_targets'])
    if err:
      raise MBErr(err)
    labels_to_targets = {}
    for i, label in enumerate(gn_inp['test_targets']):
      labels_to_targets[label] = inp['test_targets'][i]

    try:
      self.WriteJSON(gn_inp, gn_input_path)
      cmd = self.GNCmd('analyze', build_path, gn_input_path, gn_output_path)
      ret, output, _ = self.Run(cmd, force_verbose=True)
      if ret:
        if self.args.json_output:
          # write errors to json.output
          self.WriteJSON({'output': output}, self.args.json_output)
        return ret

      gn_outp_str = self.ReadFile(gn_output_path)
      try:
        gn_outp = json.loads(gn_outp_str)
      except Exception as e:
        self.Print("Failed to parse the JSON string GN returned: %s\n%s"
                   % (repr(gn_outp_str), str(e)))
        raise

      outp = {}
      if 'status' in gn_outp:
        outp['status'] = gn_outp['status']
      if 'error' in gn_outp:
        outp['error'] = gn_outp['error']
      if 'invalid_targets' in gn_outp:
        outp['invalid_targets'] = gn_outp['invalid_targets']
      if 'compile_targets' in gn_outp:
        all_input_compile_targets = sorted(
            set(inp['test_targets'] + inp['additional_compile_targets']))

        # If we're building 'all', we can throw away the rest of the targets
        # since they're redundant.
        if 'all' in gn_outp['compile_targets']:
          outp['compile_targets'] = ['all']
        else:
          outp['compile_targets'] = gn_outp['compile_targets']

        # crbug.com/736215: When GN returns targets back, for targets in
        # the default toolchain, GN will have generated a phony ninja
        # target matching the label, and so we can safely (and easily)
        # transform any GN label into the matching ninja target. For
        # targets in other toolchains, though, GN doesn't generate the
        # phony targets, and we don't know how to turn the labels into
        # compile targets. In this case, we also conservatively give up
        # and build everything. Probably the right thing to do here is
        # to have GN return the compile targets directly.
        if any("(" in target for target in outp['compile_targets']):
          self.Print('WARNING: targets with non-default toolchains were '
                     'found, building everything instead.')
          outp['compile_targets'] = all_input_compile_targets
        else:
          outp['compile_targets'] = [
              label.replace('//', '') for label in outp['compile_targets']]

        # Windows has a maximum command line length of 8k; even Linux
        # maxes out at 128k; if analyze returns a *really long* list of
        # targets, we just give up and conservatively build everything instead.
        # Probably the right thing here is for ninja to support response
        # files as input on the command line
        # (see https://github.com/ninja-build/ninja/issues/1355).
        if len(' '.join(outp['compile_targets'])) > 7*1024:
          self.Print('WARNING: Too many compile targets were affected.')
          self.Print('WARNING: Building everything instead to avoid '
                     'command-line length issues.')
          outp['compile_targets'] = all_input_compile_targets


      if 'test_targets' in gn_outp:
        outp['test_targets'] = [
          labels_to_targets[label] for label in gn_outp['test_targets']]

      if self.args.verbose:
        self.Print()
        self.Print('analyze output:')
        self.PrintJSON(outp)
        self.Print()

      self.WriteJSON(outp, output_path)

    finally:
      if self.Exists(gn_input_path):
        self.RemoveFile(gn_input_path)
      if self.Exists(gn_output_path):
        self.RemoveFile(gn_output_path)

    return 0

  def ReadInputJSON(self, required_keys):
    path = self.args.input_path[0]
    output_path = self.args.output_path[0]
    if not self.Exists(path):
      self.WriteFailureAndRaise('"%s" does not exist' % path, output_path)

    try:
      inp = json.loads(self.ReadFile(path))
    except Exception as e:
      self.WriteFailureAndRaise('Failed to read JSON input from "%s": %s' %
                                (path, e), output_path)

    for k in required_keys:
      if not k in inp:
        self.WriteFailureAndRaise('input file is missing a "%s" key' % k,
                                  output_path)

    return inp

  def WriteFailureAndRaise(self, msg, output_path):
    if output_path:
      self.WriteJSON({'error': msg}, output_path, force_verbose=True)
    raise MBErr(msg)

  def WriteJSON(self, obj, path, force_verbose=False):
    try:
      self.WriteFile(path, json.dumps(obj, indent=2, sort_keys=True) + '\n',
                     force_verbose=force_verbose)
    except Exception as e:
      raise MBErr('Error %s writing to the output path "%s"' %
                 (e, path)) from e

  def CheckCompile(self, builder_group, builder):
    url_template = self.args.url_template + '/{builder}/builds/_all?as_text=1'
    url = quote(
            url_template.format(builder_group=builder_group, builder=builder),
            safe=':/()?=')
    try:
      builds = json.loads(self.Fetch(url))
    except Exception as e:
      return str(e)
    successes = sorted(
        [int(x) for x in builds.keys() if "text" in builds[x] and
          cmp(builds[x]["text"][:2], ["build", "successful"]) == 0],
        reverse=True)
    if not successes:
      return "no successful builds"
    build = builds[str(successes[0])]
    step_names = {step["name"] for step in build["steps"]}
    compile_indicators = set(["compile", "compile (with patch)", "analyze"])
    if compile_indicators & step_names:
      return "compiles"
    return "does not compile"

  def PrintCmd(self, cmd, env):
    if self.platform == 'win32':
      env_prefix = 'set '
      env_quoter = QuoteForSet
      shell_quoter = QuoteForCmd
    else:
      env_prefix = ''
      env_quoter = pipes.quote
      shell_quoter = pipes.quote

    def print_env(var):
      if env and var in env:
        self.Print('%s%s=%s' % (env_prefix, var, env_quoter(env[var])))

    print_env('LLVM_FORCE_HEAD_REVISION')

    if cmd[0] == self.executable:
      cmd = ['python'] + cmd[1:]
    self.Print(*[shell_quoter(arg) for arg in cmd])

  def PrintJSON(self, obj):
    self.Print(json.dumps(obj, indent=2, sort_keys=True))

  def Build(self, target):
    build_dir = self.ToSrcRelPath(self.args.path[0])
    ninja_cmd = ['ninja', '-C', build_dir]
    if self.args.jobs:
      ninja_cmd.extend(['-j', '%d' % self.args.jobs])
    ninja_cmd.append(target)
    ret, _, _ = self.Run(ninja_cmd, force_verbose=False, buffer_output=False)
    return ret

  def Run(self, cmd, env=None, force_verbose=True, buffer_output=True):
    # This function largely exists so it can be overridden for testing.
    if self.args.dryrun or self.args.verbose or force_verbose:
      self.PrintCmd(cmd, env)
    if self.args.dryrun:
      return 0, '', ''

    ret, out, err = self.Call(cmd, env=env, buffer_output=buffer_output)
    if self.args.verbose or force_verbose:
      if ret:
        self.Print('  -> returned %d' % ret)
      if out:
        self.Print(out, end='')
      if err:
        self.Print(err, end='', file=sys.stderr)
    return ret, out, err

  def Call(self, cmd, env=None, buffer_output=True):
    if buffer_output:
      p = subprocess.Popen(cmd, shell=False, cwd=self.chromium_src_dir,
                           stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                           env=env)
      out, err = p.communicate()
      out = out.decode('utf-8')
      err = err.decode('utf-8')
    else:
      p = subprocess.Popen(cmd, shell=False, cwd=self.chromium_src_dir,
                           env=env)
      p.wait()
      out = err = ''
    return p.returncode, out, err

  def ExpandUser(self, path):
    # This function largely exists so it can be overridden for testing.
    return os.path.expanduser(path)

  def Exists(self, path):
    # This function largely exists so it can be overridden for testing.
    return os.path.exists(path)

  def Fetch(self, url):
    # This function largely exists so it can be overridden for testing.
    f = urlopen(url)
    contents = f.read()
    f.close()
    return contents

  def MaybeMakeDirectory(self, path):
    try:
      os.makedirs(path)
    except OSError as e:
      if e.errno != errno.EEXIST:
        raise

  def PathJoin(self, *comps):
    # This function largely exists so it can be overriden for testing.
    return os.path.join(*comps)

  def Print(self, *args, **kwargs):
    # This function largely exists so it can be overridden for testing.
    print(*args, **kwargs)
    if kwargs.get('stream', sys.stdout) == sys.stdout:
      sys.stdout.flush()

  def ReadFile(self, path):
    # This function largely exists so it can be overriden for testing.
    with open(path) as fp:
      return fp.read()

  def RelPath(self, path, start='.'):
    # This function largely exists so it can be overriden for testing.
    return os.path.relpath(path, start)

  def RemoveFile(self, path):
    # This function largely exists so it can be overriden for testing.
    os.remove(path)

  def RemoveDirectory(self, abs_path):
    if self.platform == 'win32':
      # In other places in chromium, we often have to retry this command
      # because we're worried about other processes still holding on to
      # file handles, but when MB is invoked, it will be early enough in the
      # build that their should be no other processes to interfere. We
      # can change this if need be.
      self.Run(['cmd.exe', '/c', 'rmdir', '/q', '/s', abs_path])
    else:
      shutil.rmtree(abs_path, ignore_errors=True)

  def TempFile(self, mode='w'):
    # This function largely exists so it can be overriden for testing.
    return tempfile.NamedTemporaryFile(mode=mode, delete=False)

  def WriteFile(self, path, contents, force_verbose=False):
    # This function largely exists so it can be overriden for testing.
    if self.args.dryrun or self.args.verbose or force_verbose:
      self.Print('\nWriting """\\\n%s""" to %s.\n' % (contents, path))
    with open(path, 'w') as fp:
      return fp.write(contents)


class MBErr(Exception):
  pass


# See http://goo.gl/l5NPDW and http://goo.gl/4Diozm for the painful
# details of this next section, which handles escaping command lines
# so that they can be copied and pasted into a cmd window.
UNSAFE_FOR_SET = set('^<>&|')
UNSAFE_FOR_CMD = UNSAFE_FOR_SET.union(set('()%'))
ALL_META_CHARS = UNSAFE_FOR_CMD.union(set('"'))


def QuoteForSet(arg):
  if any(a in UNSAFE_FOR_SET for a in arg):
    arg = ''.join('^' + a if a in UNSAFE_FOR_SET else a for a in arg)
  return arg


def QuoteForCmd(arg):
  # First, escape the arg so that CommandLineToArgvW will parse it properly.
  if arg == '' or ' ' in arg or '"' in arg:
    quote_re = re.compile(r'(\\*)"')
    arg = '"%s"' % (quote_re.sub(lambda mo: 2 * mo.group(1) + '\\"', arg))

  # Then check to see if the arg contains any metacharacters other than
  # double quotes; if it does, quote everything (including the double
  # quotes) for safety.
  if any(a in UNSAFE_FOR_CMD for a in arg):
    arg = ''.join('^' + a if a in ALL_META_CHARS else a for a in arg)
  return arg


if __name__ == '__main__':
  sys.exit(main(sys.argv[1:]))
                                                                                                                                                                                                                                                                                                  node-23.7.0/deps/v8/tools/mb/mb_test.py                                                             0000775 0000000 0000000 00000051721 14746647661 0017623 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/python3
# Copyright 2016 the V8 project authors. All rights reserved.
# Copyright 2015 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.
"""Tests for mb.py."""

import json
import io
import os
import sys
import unittest

import mb


class FakeMBW(mb.MetaBuildWrapper):

  def __init__(self, win32=False):
    super().__init__()

    # Override vars for test portability.
    if win32:
      self.chromium_src_dir = 'c:\\fake_src'
      self.default_config = 'c:\\fake_src\\tools\\mb\\mb_config.pyl'
      self.default_isolate_map = ('c:\\fake_src\\testing\\buildbot\\'
                                  'gn_isolate_map.pyl')
      self.platform = 'win32'
      self.executable = 'c:\\python\\python.exe'
      self.sep = '\\'
    else:
      self.chromium_src_dir = '/fake_src'
      self.default_config = '/fake_src/tools/mb/mb_config.pyl'
      self.default_isolate_map = '/fake_src/testing/buildbot/gn_isolate_map.pyl'
      self.executable = '/usr/bin/python'
      self.platform = 'linux2'
      self.sep = '/'

    self.files = {}
    self.calls = []
    self.cmds = []
    self.cross_compile = None
    self.out = ''
    self.err = ''
    self.rmdirs = []

  def ExpandUser(self, path):
    return '$HOME/%s' % path

  def Exists(self, path):
    return self.files.get(path) is not None

  def MaybeMakeDirectory(self, path):
    self.files[path] = True

  def PathJoin(self, *comps):
    return self.sep.join(comps)

  def ReadFile(self, path):
    return self.files[path]

  def WriteFile(self, path, contents, force_verbose=False):
    if self.args.dryrun or self.args.verbose or force_verbose:
      self.Print('\nWriting """\\\n%s""" to %s.\n' % (contents, path))
    self.files[path] = contents

  def Call(self, cmd, env=None, buffer_output=True):
    self.calls.append(cmd)
    if self.cmds:
      return self.cmds.pop(0)
    return 0, '', ''

  def Print(self, *args, **kwargs):
    sep = kwargs.get('sep', ' ')
    end = kwargs.get('end', '\n')
    f = kwargs.get('file', sys.stdout)
    if f == sys.stderr:
      self.err += sep.join(args) + end
    else:
      self.out += sep.join(args) + end

  def TempFile(self, mode='w'):
    return FakeFile(self.files)

  def RemoveFile(self, path):
    del self.files[path]

  def RemoveDirectory(self, abs_path):
    self.rmdirs.append(abs_path)
    files_to_delete = [f for f in self.files if f.startswith(abs_path)]
    for f in files_to_delete:
      self.files[f] = None


class FakeFile():

  def __init__(self, files):
    self.name = '/tmp/file'
    self.buf = ''
    self.files = files

  def write(self, contents):
    self.buf += contents

  def close(self):
    self.files[self.name] = self.buf


TEST_CONFIG = """\
{
  'builder_groups': {
    'chromium': {},
    'fake_builder_group': {
      'fake_builder': 'rel_bot',
      'fake_debug_builder': 'debug_remoteexec',
      'fake_args_bot': '//build/args/bots/fake_builder_group/fake_args_bot.gn',
      'fake_multi_phase': { 'phase_1': 'phase_1', 'phase_2': 'phase_2'},
      'fake_args_file': 'args_file_remoteexec',
      'fake_args_file_twice': 'args_file_twice',
    },
  },
  'configs': {
    'args_file_remoteexec': ['args_file', 'remoteexec'],
    'args_file_twice': ['args_file', 'args_file'],
    'rel_bot': ['rel', 'remoteexec', 'fake_feature1'],
    'debug_remoteexec': ['debug', 'remoteexec'],
    'phase_1': ['phase_1'],
    'phase_2': ['phase_2'],
  },
  'mixins': {
    'fake_feature1': {
      'gn_args': 'enable_doom_melon=true',
    },
    'remoteexec': {
      'gn_args': 'use_remoteexec=true',
    },
    'args_file': {
      'args_file': '//build/args/fake.gn',
    },
    'phase_1': {
      'gn_args': 'phase=1',
    },
    'phase_2': {
      'gn_args': 'phase=2',
    },
    'rel': {
      'gn_args': 'is_debug=false',
    },
    'debug': {
      'gn_args': 'is_debug=true',
    },
  },
}
"""

TRYSERVER_CONFIG = """\
{
  'builder_groups': {
    'not_a_tryserver': {
      'fake_builder': 'fake_config',
    },
    'tryserver.chromium.linux': {
      'try_builder': 'fake_config',
    },
    'tryserver.chromium.mac': {
      'try_builder2': 'fake_config',
    },
  },
  'luci_tryservers': {
    'luci_tryserver1': ['luci_builder1'],
    'luci_tryserver2': ['luci_builder2'],
  },
  'configs': {},
  'mixins': {},
}
"""


class UnitTest(unittest.TestCase):

  def fake_mbw(self, files=None, win32=False):
    mbw = FakeMBW(win32=win32)
    mbw.files.setdefault(mbw.default_config, TEST_CONFIG)
    mbw.files.setdefault(
        mbw.ToAbsPath('//testing/buildbot/gn_isolate_map.pyl'), '''{
        "foo_unittests": {
          "label": "//foo:foo_unittests",
          "type": "console_test_launcher",
          "args": [],
        },
      }''')
    mbw.files.setdefault(
        mbw.ToAbsPath('//build/args/bots/fake_builder_group/fake_args_bot.gn'),
        'is_debug = false\n')
    if files:
      for path, contents in files.items():
        mbw.files[path] = contents
    return mbw

  def check(self, args, mbw=None, files=None, out=None, err=None, ret=None):
    if not mbw:
      mbw = self.fake_mbw(files)

    actual_ret = mbw.Main(args)

    self.assertEqual(actual_ret, ret)
    if out is not None:
      self.assertEqual(mbw.out, out)
    if err is not None:
      self.assertEqual(mbw.err, err)
    return mbw

  def test_analyze(self):
    files = {
        '/tmp/in.json':
            '''{\
               "files": ["foo/foo_unittest.cc"],
               "test_targets": ["foo_unittests"],
               "additional_compile_targets": ["all"]
             }''',
        '/tmp/out.json.gn':
            '''{\
               "status": "Found dependency",
               "compile_targets": ["//foo:foo_unittests"],
               "test_targets": ["//foo:foo_unittests"]
             }'''
    }

    mbw = self.fake_mbw(files)
    mbw.Call = lambda cmd, env=None, buffer_output=True: (0, '', '')

    self.check([
        'analyze', '-c', 'debug_remoteexec', '//out/Default', '/tmp/in.json',
        '/tmp/out.json'
    ],
               mbw=mbw,
               ret=0)
    out = json.loads(mbw.files['/tmp/out.json'])
    self.assertEqual(
        out, {
            'status': 'Found dependency',
            'compile_targets': ['foo:foo_unittests'],
            'test_targets': ['foo_unittests']
        })

  def test_analyze_optimizes_compile_for_all(self):
    files = {
        '/tmp/in.json':
            '''{\
               "files": ["foo/foo_unittest.cc"],
               "test_targets": ["foo_unittests"],
               "additional_compile_targets": ["all"]
             }''',
        '/tmp/out.json.gn':
            '''{\
               "status": "Found dependency",
               "compile_targets": ["//foo:foo_unittests", "all"],
               "test_targets": ["//foo:foo_unittests"]
             }'''
    }

    mbw = self.fake_mbw(files)
    mbw.Call = lambda cmd, env=None, buffer_output=True: (0, '', '')

    self.check([
        'analyze', '-c', 'debug_remoteexec', '//out/Default', '/tmp/in.json',
        '/tmp/out.json'
    ],
               mbw=mbw,
               ret=0)
    out = json.loads(mbw.files['/tmp/out.json'])

    # check that 'foo_unittests' is not in the compile_targets
    self.assertEqual(['all'], out['compile_targets'])

  def test_analyze_handles_other_toolchains(self):
    files = {
        '/tmp/in.json':
            '''{\
               "files": ["foo/foo_unittest.cc"],
               "test_targets": ["foo_unittests"],
               "additional_compile_targets": ["all"]
             }''',
        '/tmp/out.json.gn':
            '''{\
               "status": "Found dependency",
               "compile_targets": ["//foo:foo_unittests",
                                   "//foo:foo_unittests(bar)"],
               "test_targets": ["//foo:foo_unittests"]
             }'''
    }

    mbw = self.fake_mbw(files)
    mbw.Call = lambda cmd, env=None, buffer_output=True: (0, '', '')

    self.check([
        'analyze', '-c', 'debug_remoteexec', '//out/Default', '/tmp/in.json',
        '/tmp/out.json'
    ],
               mbw=mbw,
               ret=0)
    out = json.loads(mbw.files['/tmp/out.json'])

    # crbug.com/736215: If GN returns a label containing a toolchain,
    # MB (and Ninja) don't know how to handle it; to work around this,
    # we give up and just build everything we were asked to build. The
    # output compile_targets should include all of the input test_targets and
    # additional_compile_targets.
    self.assertEqual(['all', 'foo_unittests'], out['compile_targets'])

  def test_analyze_handles_way_too_many_results(self):
    too_many_files = ', '.join(['"//foo:foo%d"' % i for i in range(4 * 1024)])
    files = {
        '/tmp/in.json':
            '''{\
               "files": ["foo/foo_unittest.cc"],
               "test_targets": ["foo_unittests"],
               "additional_compile_targets": ["all"]
             }''',
        '/tmp/out.json.gn':
            '''{\
               "status": "Found dependency",
               "compile_targets": [''' + too_many_files + '''],
               "test_targets": ["//foo:foo_unittests"]
             }'''
    }

    mbw = self.fake_mbw(files)
    mbw.Call = lambda cmd, env=None, buffer_output=True: (0, '', '')

    self.check([
        'analyze', '-c', 'debug_remoteexec', '//out/Default', '/tmp/in.json',
        '/tmp/out.json'
    ],
               mbw=mbw,
               ret=0)
    out = json.loads(mbw.files['/tmp/out.json'])

    # If GN returns so many compile targets that we might have command-line
    # issues, we should give up and just build everything we were asked to
    # build. The output compile_targets should include all of the input
    # test_targets and additional_compile_targets.
    self.assertEqual(['all', 'foo_unittests'], out['compile_targets'])

  def test_gen(self):
    mbw = self.fake_mbw()
    self.check(['gen', '-c', 'debug_remoteexec', '//out/Default'],
               mbw=mbw,
               ret=0)
    self.assertMultiLineEqual(mbw.files['/fake_src/out/Default/args.gn'],
                              ('is_debug = true\n'
                               'use_remoteexec = true\n'))

    # Make sure we log both what is written to args.gn and the command line.
    self.assertIn('Writing """', mbw.out)
    self.assertIn('/fake_src/buildtools/linux64/gn gen //out/Default --check',
                  mbw.out)

    mbw = self.fake_mbw(win32=True)
    self.check(['gen', '-c', 'debug_remoteexec', '//out/Debug'], mbw=mbw, ret=0)
    self.assertMultiLineEqual(mbw.files['c:\\fake_src\\out\\Debug\\args.gn'],
                              ('is_debug = true\n'
                               'use_remoteexec = true\n'))
    self.assertIn(
        'c:\\fake_src\\buildtools\\win\\gn.exe gen //out/Debug '
        '--check\n', mbw.out)

    mbw = self.fake_mbw()
    self.check([
        'gen', '-m', 'fake_builder_group', '-b', 'fake_args_bot', '//out/Debug'
    ],
               mbw=mbw,
               ret=0)
    # TODO(almuthanna): disable test temporarily to
    #   solve this issue https://crbug.com/v8/11102
    # self.assertEqual(
    #     mbw.files['/fake_src/out/Debug/args.gn'],
    #     'import("//build/args/bots/fake_builder_group/fake_args_bot.gn")\n')

  def test_gen_args_file_mixins(self):
    mbw = self.fake_mbw()
    self.check([
        'gen', '-m', 'fake_builder_group', '-b', 'fake_args_file', '//out/Debug'
    ],
               mbw=mbw,
               ret=0)

    self.assertEqual(mbw.files['/fake_src/out/Debug/args.gn'],
                     ('import("//build/args/fake.gn")\n'
                      'use_remoteexec = true\n'))

    mbw = self.fake_mbw()
    self.check([
        'gen', '-m', 'fake_builder_group', '-b', 'fake_args_file_twice',
        '//out/Debug'
    ],
               mbw=mbw,
               ret=1)

  def test_gen_fails(self):
    mbw = self.fake_mbw()
    mbw.Call = lambda cmd, env=None, buffer_output=True: (1, '', '')
    self.check(['gen', '-c', 'debug_remoteexec', '//out/Default'],
               mbw=mbw,
               ret=1)

  def test_gen_swarming(self):
    files = {
        '/tmp/swarming_targets':
            'base_unittests\n',
        '/fake_src/testing/buildbot/gn_isolate_map.pyl':
            ("{'base_unittests': {"
             "  'label': '//base:base_unittests',"
             "  'type': 'raw',"
             "  'args': [],"
             "}}\n"),
        '/fake_src/out/Default/base_unittests.runtime_deps':
            ("base_unittests\n"),
    }
    mbw = self.fake_mbw(files)
    self.check([
        'gen', '-c', 'debug_remoteexec', '--swarming-targets-file',
        '/tmp/swarming_targets', '//out/Default'
    ],
               mbw=mbw,
               ret=0)
    self.assertIn('/fake_src/out/Default/base_unittests.isolate', mbw.files)
    self.assertIn('/fake_src/out/Default/base_unittests.isolated.gen.json',
                  mbw.files)

  def test_gen_swarming_script(self):
    files = {
        '/tmp/swarming_targets':
            'cc_perftests\n',
        '/fake_src/testing/buildbot/gn_isolate_map.pyl':
            ("{'cc_perftests': {"
             "  'label': '//cc:cc_perftests',"
             "  'type': 'script',"
             "  'script': '/fake_src/out/Default/test_script.py',"
             "  'args': [],"
             "}}\n"),
        'c:\\fake_src\out\Default\cc_perftests.exe.runtime_deps':
            ("cc_perftests\n"),
    }
    mbw = self.fake_mbw(files=files, win32=True)
    self.check([
        'gen', '-c', 'debug_remoteexec', '--swarming-targets-file',
        '/tmp/swarming_targets', '--isolate-map-file',
        '/fake_src/testing/buildbot/gn_isolate_map.pyl', '//out/Default'
    ],
               mbw=mbw,
               ret=0)
    self.assertIn('c:\\fake_src\\out\\Default\\cc_perftests.isolate', mbw.files)
    self.assertIn('c:\\fake_src\\out\\Default\\cc_perftests.isolated.gen.json',
                  mbw.files)

  def test_multiple_isolate_maps(self):
    files = {
        '/tmp/swarming_targets':
            'cc_perftests\n',
        '/fake_src/testing/buildbot/gn_isolate_map.pyl':
            ("{'cc_perftests': {"
             "  'label': '//cc:cc_perftests',"
             "  'type': 'raw',"
             "  'args': [],"
             "}}\n"),
        '/fake_src/testing/buildbot/gn_isolate_map2.pyl':
            ("{'cc_perftests2': {"
             "  'label': '//cc:cc_perftests',"
             "  'type': 'raw',"
             "  'args': [],"
             "}}\n"),
        'c:\\fake_src\out\Default\cc_perftests.exe.runtime_deps':
            ("cc_perftests\n"),
    }
    mbw = self.fake_mbw(files=files, win32=True)
    self.check([
        'gen', '-c', 'debug_remoteexec', '--swarming-targets-file',
        '/tmp/swarming_targets', '--isolate-map-file',
        '/fake_src/testing/buildbot/gn_isolate_map.pyl', '--isolate-map-file',
        '/fake_src/testing/buildbot/gn_isolate_map2.pyl', '//out/Default'
    ],
               mbw=mbw,
               ret=0)
    self.assertIn('c:\\fake_src\\out\\Default\\cc_perftests.isolate', mbw.files)
    self.assertIn('c:\\fake_src\\out\\Default\\cc_perftests.isolated.gen.json',
                  mbw.files)

  def test_duplicate_isolate_maps(self):
    files = {
        '/tmp/swarming_targets':
            'cc_perftests\n',
        '/fake_src/testing/buildbot/gn_isolate_map.pyl':
            ("{'cc_perftests': {"
             "  'label': '//cc:cc_perftests',"
             "  'type': 'raw',"
             "  'args': [],"
             "}}\n"),
        '/fake_src/testing/buildbot/gn_isolate_map2.pyl':
            ("{'cc_perftests': {"
             "  'label': '//cc:cc_perftests',"
             "  'type': 'raw',"
             "  'args': [],"
             "}}\n"),
        'c:\\fake_src\out\Default\cc_perftests.exe.runtime_deps':
            ("cc_perftests\n"),
    }
    mbw = self.fake_mbw(files=files, win32=True)
    # Check that passing duplicate targets into mb fails.
    self.check([
        'gen', '-c', 'debug_remoteexec', '--swarming-targets-file',
        '/tmp/swarming_targets', '--isolate-map-file',
        '/fake_src/testing/buildbot/gn_isolate_map.pyl', '--isolate-map-file',
        '/fake_src/testing/buildbot/gn_isolate_map2.pyl', '//out/Default'
    ],
               mbw=mbw,
               ret=1)

  def test_isolate(self):
    files = {
        '/fake_src/out/Default/toolchain.ninja':
            "",
        '/fake_src/testing/buildbot/gn_isolate_map.pyl':
            ("{'base_unittests': {"
             "  'label': '//base:base_unittests',"
             "  'type': 'raw',"
             "  'args': [],"
             "}}\n"),
        '/fake_src/out/Default/base_unittests.runtime_deps':
            ("base_unittests\n"),
    }
    self.check([
        'isolate', '-c', 'debug_remoteexec', '//out/Default', 'base_unittests'
    ],
               files=files,
               ret=0)

    # test running isolate on an existing build_dir
    files['/fake_src/out/Default/args.gn'] = 'is_debug = True\n'
    self.check(['isolate', '//out/Default', 'base_unittests'],
               files=files,
               ret=0)

    self.check(['isolate', '//out/Default', 'base_unittests'],
               files=files,
               ret=0)

  def test_run(self):
    files = {
        '/fake_src/testing/buildbot/gn_isolate_map.pyl':
            ("{'base_unittests': {"
             "  'label': '//base:base_unittests',"
             "  'type': 'raw',"
             "  'args': [],"
             "}}\n"),
        '/fake_src/out/Default/base_unittests.runtime_deps':
            ("base_unittests\n"),
    }
    self.check(
        ['run', '-c', 'debug_remoteexec', '//out/Default', 'base_unittests'],
        files=files,
        ret=0)

  def test_lookup(self):
    self.check(['lookup', '-c', 'debug_remoteexec'],
               ret=0,
               out=('\n'
                    'Writing """\\\n'
                    'is_debug = true\n'
                    'use_remoteexec = true\n'
                    '""" to _path_/args.gn.\n\n'
                    '/fake_src/buildtools/linux64/gn gen _path_\n'))

  def test_quiet_lookup(self):
    self.check(['lookup', '-c', 'debug_remoteexec', '--quiet'],
               ret=0,
               out=('is_debug = true\n'
                    'use_remoteexec = true\n'))

  def test_help(self):
    orig_stdout = sys.stdout
    try:
      sys.stdout = io.StringIO()
      self.assertRaises(SystemExit, self.check, ['-h'])
      self.assertRaises(SystemExit, self.check, ['help'])
      self.assertRaises(SystemExit, self.check, ['help', 'gen'])
    finally:
      sys.stdout = orig_stdout

  def test_multiple_phases(self):
    # Check that not passing a --phase to a multi-phase builder fails.
    mbw = self.check(
        ['lookup', '-m', 'fake_builder_group', '-b', 'fake_multi_phase'], ret=1)
    self.assertIn('Must specify a build --phase', mbw.out)

    # Check that passing a --phase to a single-phase builder fails.
    mbw = self.check([
        'lookup', '-m', 'fake_builder_group', '-b', 'fake_builder', '--phase',
        'phase_1'
    ],
                     ret=1)
    self.assertIn('Must not specify a build --phase', mbw.out)

    # Check that passing a wrong phase key to a multi-phase builder fails.
    mbw = self.check([
        'lookup', '-m', 'fake_builder_group', '-b', 'fake_multi_phase',
        '--phase', 'wrong_phase'
    ],
                     ret=1)
    self.assertIn('Phase wrong_phase doesn\'t exist', mbw.out)

    # Check that passing a correct phase key to a multi-phase builder passes.
    mbw = self.check([
        'lookup', '-m', 'fake_builder_group', '-b', 'fake_multi_phase',
        '--phase', 'phase_1'
    ],
                     ret=0)
    self.assertIn('phase = 1', mbw.out)

    mbw = self.check([
        'lookup', '-m', 'fake_builder_group', '-b', 'fake_multi_phase',
        '--phase', 'phase_2'
    ],
                     ret=0)
    self.assertIn('phase = 2', mbw.out)

  def test_recursive_lookup(self):
    files = {
        '/fake_src/build/args/fake.gn': ('enable_doom_melon = true\n'
                                         'enable_antidoom_banana = true\n')
    }
    self.check([
        'lookup', '-m', 'fake_builder_group', '-b', 'fake_args_file',
        '--recursive'
    ],
               files=files,
               ret=0,
               out=('enable_antidoom_banana = true\n'
                    'enable_doom_melon = true\n'
                    'use_remoteexec = true\n'))

  def test_validate(self):
    mbw = self.fake_mbw()
    self.check(['validate'], mbw=mbw, ret=0)

  def test_buildbucket(self):
    mbw = self.fake_mbw()
    mbw.files[mbw.default_config] = TRYSERVER_CONFIG
    self.check(['gerrit-buildbucket-config'],
               mbw=mbw,
               ret=0,
               out=('# This file was generated using '
                    '"tools/mb/mb.py gerrit-buildbucket-config".\n'
                    '[bucket "luci.luci_tryserver1"]\n'
                    '\tbuilder = luci_builder1\n'
                    '[bucket "luci.luci_tryserver2"]\n'
                    '\tbuilder = luci_builder2\n'
                    '[bucket "builder_group.tryserver.chromium.linux"]\n'
                    '\tbuilder = try_builder\n'
                    '[bucket "builder_group.tryserver.chromium.mac"]\n'
                    '\tbuilder = try_builder2\n'))


if __name__ == '__main__':
  unittest.main()
                                               node-23.7.0/deps/v8/tools/memory/                                                                   0000775 0000000 0000000 00000000000 14746647661 0016515 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/memory/asan/                                                              0000775 0000000 0000000 00000000000 14746647661 0017437 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/memory/asan/blocklist_win.txt                                             0000664 0000000 0000000 00000000334 14746647661 0023043 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # The rules in this file are only applied at compile time. If you can modify the
# source in question, consider function attributes to disable instrumentation.
#
# Please think twice before you add or remove these rules.                                                                                                                                                                                                                                                                                                    node-23.7.0/deps/v8/tools/memory/rss.py                                                             0000775 0000000 0000000 00000005231 14746647661 0017702 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3
# Copyright 2022 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

import subprocess
import sys
import time

kDefaultSamplerateSecs = 0.001


def PrintHelp(returncode):
  print(f"""Usage: {sys.argv[0]} [--interval I] [--freq F] [--] COMMAND

Runs COMMAND, and samples its RSS memory usage every I milliseconds (or F \
times per second).
Default sample interval is {kDefaultSamplerateSecs * 1000} ms.
'--' as argument forces all further arguments to be part of COMMAND.
""")
  sys.exit(returncode)


def Main():
  # Parse arguments.
  args = []
  samplerate_secs = kDefaultSamplerateSecs
  idx = 1
  while idx < len(sys.argv):
    arg = sys.argv[idx]
    if arg == "--":
      args += sys.argv[(idx + 1):]
      break
    if arg in ("-h", "--help", "help"):
      PrintHelp(0)
    elif arg in ("--interval", "-I"):
      if idx + 1 >= len(sys.argv):
        PrintHelp(1)
      samplerate_secs = int(sys.argv[idx + 1]) / 1000
      idx += 1  # Skip the value.
    elif arg in ("--freq", "-F"):
      if idx + 1 >= len(sys.argv):
        PrintHelp(1)
      samplerate_secs = 1 / float(sys.argv[idx + 1])
      idx += 1  # Skip the value.
    else:
      # No match for known parameter; assume it's part of the command to run.
      args.append(arg)
    idx += 1  # Go to next arg.

  cmd = " ".join(args)
  print(f"sample rate: {samplerate_secs}")
  print(f"command: {cmd}")

  # Run the child process and observe it.
  process = subprocess.Popen(cmd, shell=True)
  pid = process.pid
  print(f"pid: {pid}")
  statusfile = f"/proc/{pid}/status"
  vmsum = 0
  observed_max = 0
  reported_max = 0
  sample_count = 0
  while process.poll() is None:
    with open(statusfile, 'r') as f:
      for line in f.read().splitlines():
        if line.startswith("VmRSS"):
          rss = int(line.split()[1])
          vmsum += rss
          if rss > observed_max:
            observed_max = rss
        elif line.startswith("VmHWM"):
          peak = int(line.split()[1])
          if peak > reported_max:
            reported_max = peak
      sample_count += 1
    time.sleep(samplerate_secs)

  # Report findings.
  print("\n")
  # TODO(jkummerow): See if this is accurate enough in practice.
  walltime = sample_count * samplerate_secs
  print(f"wall time:    {walltime:.3f} s")  # Sample rate precision!
  print("")
  avg = vmsum / sample_count / 1024
  reported_max /= 1024
  observed_max /= 1024
  print(f"average RSS:  {avg:.2f} MB")
  print(f"reported max: {reported_max:.2f} MB")
  print(f"observed max: {observed_max:.2f} MB")
  sys.exit(process.returncode)


if __name__ == "__main__":
  Main()
                                                                                                                                                                                                                                                                                                                                                                       node-23.7.0/deps/v8/tools/memory/sanitizer/                                                         0000775 0000000 0000000 00000000000 14746647661 0020525 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/memory/sanitizer/escalate_sanitizer_warnings.py                           0000664 0000000 0000000 00000010276 14746647661 0026666 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3

# Copyright 2024 the V8 project authors. All rights reserved.
# Copyright 2023 The Chromium Authors
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.
"""This script searches for sanitizer warnings in stdout that do not trigger
test failures in process, and when it finds one, it updates the test status
to FAILURE for that test case.

This script is added in test_env.py after the test process runs, but before
the results are returned to result_adpater."""

# TODO(349962576): This is a temporary fork of Chromium's:
# tools/memory/sanitizer/escalate_sanitizer_warnings.py
# We should rather share the Chromium script or avoid the necessity to
# include it.

import argparse
import json
import re
import sys
"""
We are looking for various types of sanitizer warnings. They have different
formats but all end in a line 'SUMMARY: (...)Sanitizer:'.
asan example:
=================================================================
==244157==ERROR: AddressSanitizer: heap-use-after-free on address 0x60b0000000f0
...
SUMMARY: AddressSanitizer:

lsan example:
=================================================================
==23646==ERROR: LeakSanitizer: detected memory leaks
...
SUMMARY: AddressSanitizer: 7 byte(s) leaked in 1 allocation(s)

msan example:
==51936==WARNING: MemorySanitizer: use-of-uninitialized-value
...
SUMMARY: MemorySanitizer: use-of-uninitialized-value (/tmp/build/a.out+0x9fd9a)

tsan example:
==================
WARNING: ThreadSanitizer: data race (pid=14909)
...
SUMMARY: ThreadSanitizer: data race base/.../typed_macros_internal.cc:135:8...

ubsan example:
../../content/browser/.../render_widget_host_impl.cc:603:35: runtime error:
member call on address 0x28dc001c8a00 which does not point to an object of type
...
SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior
"""
#pylint: disable=line-too-long
_SUMMARY_MESSAGE_STR = r'\nSUMMARY: (Address|Leak|Memory|Thread|UndefinedBehavior)Sanitizer:'
_SUMMARY_MESSAGE_REGEX = re.compile(_SUMMARY_MESSAGE_STR)


def escalate_test_status(test_name, test_run):
  original_status = test_run['status']
  # If test was not a SUCCESS, do not change it.
  if original_status != 'SUCCESS':
    return False

  regex_result = _SUMMARY_MESSAGE_REGEX.search(test_run['output_snippet'])
  if regex_result:
    sanitizer_type = regex_result.groups()[0]
    print('Found %sSanitizer Issue in test "%s"' % (sanitizer_type, test_name))
    test_run['original_status'] = test_run['status']
    test_run['status'] = 'FAILURE'
    test_run['status_processed_by'] = 'escalate_sanitizer_warnings.py'
    return True
  return False


def escalate_sanitizer_warnings(filename):
  with open(filename, 'r') as f:
    json_data = json.load(f)

  failed_test_names = []

  for iteration_data in json_data['per_iteration_data']:
    for test_name, test_runs in iteration_data.items():
      for test_run in test_runs:
        if escalate_test_status(test_name, test_run):
          failed_test_names.append(test_name)
  if not failed_test_names:
    return False
  print_sanitizer_results(failed_test_names)
  with open(filename, 'w') as f:
    json.dump(json_data, f, indent=3, sort_keys=True)
  return True


def print_sanitizer_results(failed_test_names):
  failure_count = len(failed_test_names)
  print('%d test%s failed via sanitizer warnings:' %
        (failure_count, ('s' if failure_count != 1 else '')))
  for failed_test_name in failed_test_names:
    print('    %s' % failed_test_name)


def main():
  parser = argparse.ArgumentParser(description='Escalate sanitizer warnings.')
  parser.add_argument(
      '--test-summary-json-file',
      required=True,
      help='Path to a JSON file produced by the test launcher. The script will '
      'parse output snippets to find sanitizer warnings that are shown as '
      'WARNINGS but should cause build failures in sanitizer versions. The '
      'status will be FAILED when found. The result will be written back '
      'to the JSON file.')
  args = parser.parse_args()

  if escalate_sanitizer_warnings(args.test_summary_json_file):
    # If tests failed due to sanitizer warnings, exit with 1 returncode to
    # influence task state.
    return 1


if __name__ == '__main__':
  sys.exit(main())
                                                                                                                                                                                                                                                                                                                                  node-23.7.0/deps/v8/tools/memory/tsan_v2/                                                           0000775 0000000 0000000 00000000000 14746647661 0020071 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/memory/tsan_v2/ignores.txt                                                0000664 0000000 0000000 00000000422 14746647661 0022276 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # The rules in this file are only applied at compile time. If you can modify the
# source in question, consider function attributes to disable instrumentation.
#
# Please think twice before you add or remove these rules.
# Data races should typically go to suppressions.txt.                                                                                                                                                                                                                                              node-23.7.0/deps/v8/tools/msan/                                                                     0000775 0000000 0000000 00000000000 14746647661 0016143 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/msan/ignorelist.txt                                                       0000664 0000000 0000000 00000000334 14746647661 0021063 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # The rules in this file are only applied at compile time. If you can modify the
# source in question, consider function attributes to disable instrumentation.
#
# Please think twice before you add or remove these rules.                                                                                                                                                                                                                                                                                                    node-23.7.0/deps/v8/tools/objdump-v8                                                                0000775 0000000 0000000 00000005655 14746647661 0017141 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3
#
# Copyright 2016 the V8 project authors. All rights reserved.
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are
# met:
#
#     * Redistributions of source code must retain the above copyright
#       notice, this list of conditions and the following disclaimer.
#     * Redistributions in binary form must reproduce the above
#       copyright notice, this list of conditions and the following
#       disclaimer in the documentation and/or other materials provided
#       with the distribution.
#     * Neither the name of Google Inc. nor the names of its
#       contributors may be used to endorse or promote products derived
#       from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

import os.path
import re
import subprocess
import sys


def get_address_bounds():
  start = -1
  end = -1
  for arg in sys.argv:
    if arg.startswith("--start-address="):
      start = int(arg[-12:], 16)
    if arg.startswith("--stop-address="):
      end = int(arg[-12:], 16)
  return start, end


def format_line(line):
  pieces = line.split(None, 3)
  return " " + pieces[0][2:] + ":\t" + pieces[3]


def is_comment(line):
  stripped = line.strip()
  return stripped.startswith("--") or stripped.startswith(";;")

def main():
  filename = sys.argv[-1]
  match = re.match(r"/tmp/perf-(.*)\.map", filename)
  if match:
    start, end = get_address_bounds()
    process_codefile = "code-" + match.group(1) + "-1.asm"
    if os.path.exists(process_codefile):
      codefile = open(process_codefile, "r")
    else:
      codefile = open("code.asm", "r")
    with codefile:
      printing = False
      for line in codefile:
        if line.startswith("0x"):
          addr = int(line.split()[0], 0)
          if start <= addr <= end:
            printing = True
            sys.stdout.write(format_line(line))
          elif printing:
            break
        elif printing:
          if not is_comment(line):
            break
          else:
            sys.stdout.write(line)
  else:
    sys.argv[0] = "objdump"
    sys.exit(subprocess.call(sys.argv))

if __name__ == "__main__":
  main()
                                                                                   node-23.7.0/deps/v8/tools/package-lock.json                                                         0000664 0000000 0000000 00000365215 14746647661 0020435 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        {
  "name": "v8-tools",
  "version": "1.0.0",
  "lockfileVersion": 2,
  "requires": true,
  "packages": {
    "": {
      "name": "v8-tools",
      "version": "1.0.0",
      "dependencies": {
        "local-web-server": "^5.3.1"
      }
    },
    "node_modules/@75lb/deep-merge": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@75lb/deep-merge/-/deep-merge-1.1.1.tgz",
      "integrity": "sha512-xvgv6pkMGBA6GwdyJbNAnDmfAIR/DfWhrj9jgWh3TY7gRm3KO46x/GPjRg6wJ0nOepwqrNxFfojebh0Df4h4Tw==",
      "dependencies": {
        "lodash.assignwith": "^4.2.0",
        "typical": "^7.1.1"
      },
      "engines": {
        "node": ">=12.17"
      }
    },
    "node_modules/@koa/cors": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/@koa/cors/-/cors-5.0.0.tgz",
      "integrity": "sha512-x/iUDjcS90W69PryLDIMgFyV21YLTnG9zOpPXS7Bkt2b8AsY3zZsIpOLBkYr9fBcF3HbkKaER5hOBZLfpLgYNw==",
      "dependencies": {
        "vary": "^1.1.2"
      },
      "engines": {
        "node": ">= 14.0.0"
      }
    },
    "node_modules/@tootallnate/once": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/@tootallnate/once/-/once-1.1.2.tgz",
      "integrity": "sha512-RbzJvlNzmRq5c3O09UipeuXno4tA1FE6ikOjxZK0tuxVv3412l64l5t1W5pj4+rJq9vpkm/kwiR07aZXnsKPxw==",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/accepts": {
      "version": "1.3.8",
      "resolved": "https://registry.npmjs.org/accepts/-/accepts-1.3.8.tgz",
      "integrity": "sha512-PYAthTa2m2VKxuvSD3DPC/Gy+U+sOA1LAuT8mkmRuvw+NACSaeXEQ+NHcVF7rONl6qcaxV3Uuemwawk+7+SJLw==",
      "dependencies": {
        "mime-types": "~2.1.34",
        "negotiator": "0.6.3"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/agent-base": {
      "version": "6.0.2",
      "resolved": "https://registry.npmjs.org/agent-base/-/agent-base-6.0.2.tgz",
      "integrity": "sha512-RZNwNclF7+MS/8bDg70amg32dyeZGZxiDuQmZxKLAlQjr3jGyLx+4Kkk58UO7D2QdgFIQCovuSuZESne6RG6XQ==",
      "dependencies": {
        "debug": "4"
      },
      "engines": {
        "node": ">= 6.0.0"
      }
    },
    "node_modules/ansi-escape-sequences": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/ansi-escape-sequences/-/ansi-escape-sequences-5.1.2.tgz",
      "integrity": "sha512-JcpoVp1W1bl1Qn4cVuiXEhD6+dyXKSOgCn2zlzE8inYgCJCBy1aPnUhlz6I4DFum8D4ovb9Qi/iAjUcGvG2lqw==",
      "dependencies": {
        "array-back": "^4.0.0"
      },
      "engines": {
        "node": ">=8.0.0"
      }
    },
    "node_modules/ansi-styles": {
      "version": "3.2.1",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-3.2.1.tgz",
      "integrity": "sha512-VT0ZI6kZRdTh8YyJw3SMbYm/u+NqfsAxEpWO0Pf9sq8/e94WxxOpPKx9FR1FlyCtOVDNOQ+8ntlqFxiRc+r5qA==",
      "dependencies": {
        "color-convert": "^1.9.0"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/any-promise": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/any-promise/-/any-promise-1.3.0.tgz",
      "integrity": "sha1-q8av7tzqUugJzcA3au0845Y10X8="
    },
    "node_modules/array-back": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/array-back/-/array-back-4.0.2.tgz",
      "integrity": "sha512-NbdMezxqf94cnNfWLL7V/im0Ub+Anbb0IoZhvzie8+4HJ4nMQuzHuy49FkGYCJK2yAloZ3meiB6AVMClbrI1vg==",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/basic-auth": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/basic-auth/-/basic-auth-2.0.1.tgz",
      "integrity": "sha512-NF+epuEdnUYVlGuhaxbbq+dvJttwLnGY+YixlXlME5KpQ5W3CnXA5cVTneY3SPbPDRkcjMbifrwmFYcClgOZeg==",
      "dependencies": {
        "safe-buffer": "5.1.2"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/batch": {
      "version": "0.6.1",
      "resolved": "https://registry.npmjs.org/batch/-/batch-0.6.1.tgz",
      "integrity": "sha512-x+VAiMRL6UPkx+kudNvxTl6hB2XNNCG2r+7wixVfIYwu/2HKRXimwQyaumLjMveWvT2Hkd/cAJw+QBMfJ/EKVw=="
    },
    "node_modules/byte-size": {
      "version": "6.2.0",
      "resolved": "https://registry.npmjs.org/byte-size/-/byte-size-6.2.0.tgz",
      "integrity": "sha512-6EspYUCAPMc7E2rltBgKwhG+Cmk0pDm9zDtF1Awe2dczNUL3YpZ8mTs/dueOTS1hqGWBOatqef4jYMGjln7WmA==",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/bytes": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/bytes/-/bytes-3.1.2.tgz",
      "integrity": "sha512-/Nf7TyzTx6S3yRJObOAV7956r8cr2+Oj8AC5dt8wSP3BQAoeX58NoHyCU8P8zGkNXStjTSi6fzO6F0pBdcYbEg==",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/cache-content-type": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/cache-content-type/-/cache-content-type-1.0.1.tgz",
      "integrity": "sha512-IKufZ1o4Ut42YUrZSo8+qnMTrFuKkvyoLXUywKz9GJ5BrhOFGhLdkx9sG4KAnVvbY6kEcSFjLQul+DVmBm2bgA==",
      "dependencies": {
        "mime-types": "^2.1.18",
        "ylru": "^1.2.0"
      },
      "engines": {
        "node": ">= 6.0.0"
      }
    },
    "node_modules/call-bind": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/call-bind/-/call-bind-1.0.5.tgz",
      "integrity": "sha512-C3nQxfFZxFRVoJoGKKI8y3MOEo129NQ+FgQ08iye+Mk4zNZZGdjfs06bVTr+DBSlA66Q2VEcMki/cUCP4SercQ==",
      "dependencies": {
        "function-bind": "^1.1.2",
        "get-intrinsic": "^1.2.1",
        "set-function-length": "^1.1.1"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/chalk": {
      "version": "2.4.2",
      "resolved": "https://registry.npmjs.org/chalk/-/chalk-2.4.2.tgz",
      "integrity": "sha512-Mti+f9lpJNcwF4tWV8/OrTTtF1gZi+f8FqlyAdouralcFWFQWF2+NgCHShjkCb+IFBLq9buZwE1xckQU4peSuQ==",
      "dependencies": {
        "ansi-styles": "^3.2.1",
        "escape-string-regexp": "^1.0.5",
        "supports-color": "^5.3.0"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/co": {
      "version": "4.6.0",
      "resolved": "https://registry.npmjs.org/co/-/co-4.6.0.tgz",
      "integrity": "sha512-QVb0dM5HvG+uaxitm8wONl7jltx8dqhfU33DcqtOZcLSVIKSDDLDi7+0LbAKiyI8hD9u42m2YxXSkMGWThaecQ==",
      "engines": {
        "iojs": ">= 1.0.0",
        "node": ">= 0.12.0"
      }
    },
    "node_modules/co-body": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/co-body/-/co-body-6.1.0.tgz",
      "integrity": "sha512-m7pOT6CdLN7FuXUcpuz/8lfQ/L77x8SchHCF4G0RBTJO20Wzmhn5Sp4/5WsKy8OSpifBSUrmg83qEqaDHdyFuQ==",
      "dependencies": {
        "inflation": "^2.0.0",
        "qs": "^6.5.2",
        "raw-body": "^2.3.3",
        "type-is": "^1.6.16"
      }
    },
    "node_modules/color-convert": {
      "version": "1.9.3",
      "resolved": "https://registry.npmjs.org/color-convert/-/color-convert-1.9.3.tgz",
      "integrity": "sha512-QfAUtd+vFdAtFQcC8CCyYt1fYWxSqAiK2cSD6zDB8N3cpsEBAvRxp9zOGg6G/SHHJYAT88/az/IuDGALsNVbGg==",
      "dependencies": {
        "color-name": "1.1.3"
      }
    },
    "node_modules/color-name": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/color-name/-/color-name-1.1.3.tgz",
      "integrity": "sha512-72fSenhMw2HZMTVHeCA9KCmpEIbzWiQsjN+BHcBbS9vr1mtt+vJjPdksIBNUmKAW8TFUDPJK5SUU3QhE9NEXDw=="
    },
    "node_modules/command-line-args": {
      "version": "5.2.1",
      "resolved": "https://registry.npmjs.org/command-line-args/-/command-line-args-5.2.1.tgz",
      "integrity": "sha512-H4UfQhZyakIjC74I9d34fGYDwk3XpSr17QhEd0Q3I9Xq1CETHo4Hcuo87WyWHpAF1aSLjLRf5lD9ZGX2qStUvg==",
      "dependencies": {
        "array-back": "^3.1.0",
        "find-replace": "^3.0.0",
        "lodash.camelcase": "^4.3.0",
        "typical": "^4.0.0"
      },
      "engines": {
        "node": ">=4.0.0"
      }
    },
    "node_modules/command-line-args/node_modules/array-back": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/array-back/-/array-back-3.1.0.tgz",
      "integrity": "sha512-TkuxA4UCOvxuDK6NZYXCalszEzj+TLszyASooky+i742l9TqsOdYCMJJupxRic61hwquNtppB3hgcuq9SVSH1Q==",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/command-line-args/node_modules/typical": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/typical/-/typical-4.0.0.tgz",
      "integrity": "sha512-VAH4IvQ7BDFYglMd7BPRDfLgxZZX4O4TFcRDA6EN5X7erNJJq+McIEp8np9aVtxrCJ6qx4GTYVfOWNjcqwZgRw==",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/command-line-usage": {
      "version": "6.1.3",
      "resolved": "https://registry.npmjs.org/command-line-usage/-/command-line-usage-6.1.3.tgz",
      "integrity": "sha512-sH5ZSPr+7UStsloltmDh7Ce5fb8XPlHyoPzTpyyMuYCtervL65+ubVZ6Q61cFtFl62UyJlc8/JwERRbAFPUqgw==",
      "dependencies": {
        "array-back": "^4.0.2",
        "chalk": "^2.4.2",
        "table-layout": "^1.0.2",
        "typical": "^5.2.0"
      },
      "engines": {
        "node": ">=8.0.0"
      }
    },
    "node_modules/command-line-usage/node_modules/typical": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/typical/-/typical-5.2.0.tgz",
      "integrity": "sha512-dvdQgNDNJo+8B2uBQoqdb11eUCE1JQXhvjC/CZtgvZseVd5TYMXnq0+vuUemXbd/Se29cTaUuPX3YIc2xgbvIg==",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/common-log-format": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/common-log-format/-/common-log-format-1.0.0.tgz",
      "integrity": "sha512-fFn/WPNbsTCGTTwdCpZfVZSa5mgqMEkA0gMTRApFSlEsYN+9B2FPfiqch5FT+jsv5IV1RHV3GeZvCa7Qg+jssw==",
      "bin": {
        "clf": "bin/cli.js"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/compressible": {
      "version": "2.0.18",
      "resolved": "https://registry.npmjs.org/compressible/-/compressible-2.0.18.tgz",
      "integrity": "sha512-AF3r7P5dWxL8MxyITRMlORQNaOA2IkAFaTr4k7BUumjPtRpGDTZpl0Pb1XCO6JeDCBdp126Cgs9sMxqSjgYyRg==",
      "dependencies": {
        "mime-db": ">= 1.43.0 < 2"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/content-disposition": {
      "version": "0.5.4",
      "resolved": "https://registry.npmjs.org/content-disposition/-/content-disposition-0.5.4.tgz",
      "integrity": "sha512-FveZTNuGw04cxlAiWbzi6zTAL/lhehaWbTtgluJh4/E95DqMwTmha3KZN1aAWA8cFIhHzMZUvLevkw5Rqk+tSQ==",
      "dependencies": {
        "safe-buffer": "5.2.1"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/content-disposition/node_modules/safe-buffer": {
      "version": "5.2.1",
      "resolved": "https://registry.npmjs.org/safe-buffer/-/safe-buffer-5.2.1.tgz",
      "integrity": "sha512-rp3So07KcdmmKbGvgaNxQSJr7bGVSVk5S9Eq1F+ppbRo70+YeaDxkw5Dd8NPN+GD6bjnYm2VuPuCXmpuYvmCXQ==",
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ]
    },
    "node_modules/content-type": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/content-type/-/content-type-1.0.5.tgz",
      "integrity": "sha512-nTjqfcBFEipKdXCv4YDQWCfmcLZKm81ldF0pAopTvyrFGVbcR6P/VAAd5G7N+0tTr8QqiU0tFadD6FK4NtJwOA==",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/cookies": {
      "version": "0.9.1",
      "resolved": "https://registry.npmjs.org/cookies/-/cookies-0.9.1.tgz",
      "integrity": "sha512-TG2hpqe4ELx54QER/S3HQ9SRVnQnGBtKUz5bLQWtYAQ+o6GpgMs6sYUvaiJjVxb+UXwhRhAEP3m7LbsIZ77Hmw==",
      "dependencies": {
        "depd": "~2.0.0",
        "keygrip": "~1.1.0"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/copy-to": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/copy-to/-/copy-to-2.0.1.tgz",
      "integrity": "sha512-3DdaFaU/Zf1AnpLiFDeNCD4TOWe3Zl2RZaTzUvWiIk5ERzcCodOE20Vqq4fzCbNoHURFHT4/us/Lfq+S2zyY4w=="
    },
    "node_modules/core-util-is": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/core-util-is/-/core-util-is-1.0.2.tgz",
      "integrity": "sha1-tf1UIgqivFq1eqtxQMlAdUUDwac="
    },
    "node_modules/create-mixin": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/create-mixin/-/create-mixin-3.0.0.tgz",
      "integrity": "sha512-LkdMqnWT9LaqBN4huqpUnMz56Yr1mVSoCduAd2xXefgH/YZP2sXCMAyztXjk4q8hTF/TlcDa+zQW2aTgGdjjKQ==",
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/current-module-paths": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/current-module-paths/-/current-module-paths-1.1.1.tgz",
      "integrity": "sha512-8Ga5T8oMXBaSsHq9Gj+bddX7kHSaJKsl2vaAd3ep51eQLkr4W18eFEmEZM5bLo1zrz8tt3jE1U8QK9QGhaLR4g==",
      "engines": {
        "node": ">=12.17"
      }
    },
    "node_modules/debug": {
      "version": "4.3.4",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.3.4.tgz",
      "integrity": "sha512-PRWFHuSU3eDtQJPvnNY7Jcket1j0t5OuOsFzPPzsekD52Zl8qUfFIPEiswXqIvHWGVHOgX+7G/vCNNhehwxfkQ==",
      "dependencies": {
        "ms": "2.1.2"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/debug/node_modules/ms": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.2.tgz",
      "integrity": "sha512-sGkPx+VjMtmA6MX27oA4FBFELFCZZ4S4XqeGOXCv68tT+jb3vk/RyaKWP0PTKyWtmLSM0b+adUTEvbs1PEaH2w=="
    },
    "node_modules/deep-equal": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/deep-equal/-/deep-equal-1.0.1.tgz",
      "integrity": "sha512-bHtC0iYvWhyaTzvV3CZgPeZQqCOBGyGsVV7v4eevpdkLHfiSrXUdBG+qAuSz4RI70sszvjQ1QSZ98An1yNwpSw=="
    },
    "node_modules/deep-extend": {
      "version": "0.6.0",
      "resolved": "https://registry.npmjs.org/deep-extend/-/deep-extend-0.6.0.tgz",
      "integrity": "sha512-LOHxIOaPYdHlJRtCQfDIVZtfw/ufM8+rVj649RIHzcm/vGwQRXFt6OPqIFWsm2XEMrNIEtWR64sY1LEKD2vAOA==",
      "engines": {
        "node": ">=4.0.0"
      }
    },
    "node_modules/define-data-property": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/define-data-property/-/define-data-property-1.1.1.tgz",
      "integrity": "sha512-E7uGkTzkk1d0ByLeSc6ZsFS79Axg+m1P/VsgYsxHgiuc3tFSj+MjMIwe90FC4lOAZzNBdY7kkO2P2wKdsQ1vgQ==",
      "dependencies": {
        "get-intrinsic": "^1.2.1",
        "gopd": "^1.0.1",
        "has-property-descriptors": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/define-lazy-prop": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/define-lazy-prop/-/define-lazy-prop-2.0.0.tgz",
      "integrity": "sha512-Ds09qNh8yw3khSjiJjiUInaGX9xlqZDY7JVryGxdxV7NPeuqQfplOpQ66yJFZut3jLa5zOwkXw1g9EI2uKh4Og==",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/delegates": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/delegates/-/delegates-1.0.0.tgz",
      "integrity": "sha512-bd2L678uiWATM6m5Z1VzNCErI3jiGzt6HGY8OVICs40JQq/HALfbyNJmp0UDakEY4pMMaN0Ly5om/B1VI/+xfQ=="
    },
    "node_modules/depd": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/depd/-/depd-2.0.0.tgz",
      "integrity": "sha512-g7nH6P6dyDioJogAAGprGpCtVImJhpPk/roCzdb3fIh61/s/nPsfR6onyMwkCAR/OlC3yBC0lESvUoQEAssIrw==",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/destroy": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/destroy/-/destroy-1.2.0.tgz",
      "integrity": "sha512-2sJGJTaXIIaR1w4iJSNoN0hnMY7Gpc/n8D4qSCJw8QqFWXf7cuAgnEHxBpweaVcPevC2l3KpjYCx3NypQQgaJg==",
      "engines": {
        "node": ">= 0.8",
        "npm": "1.2.8000 || >= 1.4.16"
      }
    },
    "node_modules/ee-first": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/ee-first/-/ee-first-1.1.1.tgz",
      "integrity": "sha1-WQxhFWsK4vTwJVcyoViyZrxWsh0="
    },
    "node_modules/encodeurl": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/encodeurl/-/encodeurl-1.0.2.tgz",
      "integrity": "sha512-TPJXq8JqFaVYm2CWmPvnP2Iyo4ZSM7/QKcSmuMLDObfpH5fi7RUGmd/rTDf+rut/saiDiQEeVTNgAmJEdAOx0w==",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/escape-html": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/escape-html/-/escape-html-1.0.3.tgz",
      "integrity": "sha512-NiSupZ4OeuGwr68lGIeym/ksIZMJodUGOSCZ/FSnTxcrekbvqrgdUxlJOMpijaKZVjAJrWrGs/6Jy8OMuyj9ow=="
    },
    "node_modules/escape-string-regexp": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-1.0.5.tgz",
      "integrity": "sha512-vbRorB5FUQWvla16U8R/qgaFIya2qGzwDrNmCZuYKrbdSUMG6I1ZCGQRefkRVhuOkIGVne7BQ35DSfo1qvJqFg==",
      "engines": {
        "node": ">=0.8.0"
      }
    },
    "node_modules/etag": {
      "version": "1.8.1",
      "resolved": "https://registry.npmjs.org/etag/-/etag-1.8.1.tgz",
      "integrity": "sha1-Qa4u62XvpiJorr/qg6x9eSmbCIc=",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/find-replace": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/find-replace/-/find-replace-3.0.0.tgz",
      "integrity": "sha512-6Tb2myMioCAgv5kfvP5/PkZZ/ntTpVK39fHY7WkWBgvbeE+VHd/tZuZ4mrC+bxh4cfOZeYKVPaJIZtZXV7GNCQ==",
      "dependencies": {
        "array-back": "^3.0.1"
      },
      "engines": {
        "node": ">=4.0.0"
      }
    },
    "node_modules/find-replace/node_modules/array-back": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/array-back/-/array-back-3.1.0.tgz",
      "integrity": "sha512-TkuxA4UCOvxuDK6NZYXCalszEzj+TLszyASooky+i742l9TqsOdYCMJJupxRic61hwquNtppB3hgcuq9SVSH1Q==",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/fresh": {
      "version": "0.5.2",
      "resolved": "https://registry.npmjs.org/fresh/-/fresh-0.5.2.tgz",
      "integrity": "sha512-zJ2mQYM18rEFOudeV4GShTGIQ7RbzA7ozbU9I/XBpm7kqgMywgmylMwXHxZJmkVoYkna9d2pVXVXPdYTP9ej8Q==",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/function-bind": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/function-bind/-/function-bind-1.1.2.tgz",
      "integrity": "sha512-7XHNxH7qX9xG5mIwxkhumTox/MIRNcOgDrxWsMt2pAr23WHp6MrRlN7FBSFpCpr+oVO0F744iUgR82nJMfG2SA==",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-intrinsic": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/get-intrinsic/-/get-intrinsic-1.2.2.tgz",
      "integrity": "sha512-0gSo4ml/0j98Y3lngkFEot/zhiCeWsbYIlZ+uZOVgzLyLaUw7wxUL+nCTP0XJvJg1AXulJRI3UJi8GsbDuxdGA==",
      "dependencies": {
        "function-bind": "^1.1.2",
        "has-proto": "^1.0.1",
        "has-symbols": "^1.0.3",
        "hasown": "^2.0.0"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/gopd": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/gopd/-/gopd-1.0.1.tgz",
      "integrity": "sha512-d65bNlIadxvpb/A2abVdlqKqV563juRnZ1Wtk6s1sIR8uNsXR70xqIzVqxVf1eTqDunwT2MkczEeaezCKTZhwA==",
      "dependencies": {
        "get-intrinsic": "^1.1.3"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-flag": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/has-flag/-/has-flag-3.0.0.tgz",
      "integrity": "sha512-sKJf1+ceQBr4SMkvQnBDNDtf4TXpVhVGateu0t918bl30FnbE2m4vNLX+VWe/dpjlb+HugGYzW7uQXH98HPEYw==",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/has-property-descriptors": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/has-property-descriptors/-/has-property-descriptors-1.0.1.tgz",
      "integrity": "sha512-VsX8eaIewvas0xnvinAe9bw4WfIeODpGYikiWYLH+dma0Jw6KHYqWiWfhQlgOVK8D6PvjubK5Uc4P0iIhIcNVg==",
      "dependencies": {
        "get-intrinsic": "^1.2.2"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/has-proto/-/has-proto-1.0.1.tgz",
      "integrity": "sha512-7qE+iP+O+bgF9clE5+UoBFzE65mlBiVj3tKCrlNQ0Ogwm0BjpT/gK4SlLYDMybDh5I3TCTKnPPa0oMG7JDYrhg==",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-symbols": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/has-symbols/-/has-symbols-1.0.3.tgz",
      "integrity": "sha512-l3LCuF6MgDNwTDKkdYGEihYjt5pRPbEg46rtlmnSPlUbgmB8LOIrKJbYYFBSbnPaJexMKtiPO8hmeRjRz2Td+A==",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-tostringtag": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/has-tostringtag/-/has-tostringtag-1.0.0.tgz",
      "integrity": "sha512-kFjcSNhnlGV1kyoGk7OXKSawH5JOb/LzUc5w9B02hOTO0dfFRjbHQKvg1d6cf3HbeUmtU9VbbV3qzZ2Teh97WQ==",
      "dependencies": {
        "has-symbols": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/hasown": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/hasown/-/hasown-2.0.0.tgz",
      "integrity": "sha512-vUptKVTpIJhcczKBbgnS+RtcuYMB8+oNzPK2/Hp3hanz8JmpATdmmgLgSaadVREkDm+e2giHwY3ZRkyjSIDDFA==",
      "dependencies": {
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/http-assert": {
      "version": "1.5.0",
      "resolved": "https://registry.npmjs.org/http-assert/-/http-assert-1.5.0.tgz",
      "integrity": "sha512-uPpH7OKX4H25hBmU6G1jWNaqJGpTXxey+YOUizJUAgu0AjLUeC8D73hTrhvDS5D+GJN1DN1+hhc/eF/wpxtp0w==",
      "dependencies": {
        "deep-equal": "~1.0.1",
        "http-errors": "~1.8.0"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/http-errors": {
      "version": "1.8.1",
      "resolved": "https://registry.npmjs.org/http-errors/-/http-errors-1.8.1.tgz",
      "integrity": "sha512-Kpk9Sm7NmI+RHhnj6OIWDI1d6fIoFAtFt9RLaTMRlg/8w49juAStsrBgp0Dp4OdxdVbRIeKhtCUvoi/RuAhO4g==",
      "dependencies": {
        "depd": "~1.1.2",
        "inherits": "2.0.4",
        "setprototypeof": "1.2.0",
        "statuses": ">= 1.5.0 < 2",
        "toidentifier": "1.0.1"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/http-errors/node_modules/depd": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/depd/-/depd-1.1.2.tgz",
      "integrity": "sha512-7emPTl6Dpo6JRXOXjLRxck+FlLRX5847cLKEn00PLAgc3g2hTZZgr+e4c2v6QpSmLeFP3n5yUo7ft6avBK/5jQ==",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/http-proxy-agent": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/http-proxy-agent/-/http-proxy-agent-4.0.1.tgz",
      "integrity": "sha512-k0zdNgqWTGA6aeIRVpvfVob4fL52dTfaehylg0Y4UvSySvOq/Y+BOyPrgpUrA7HylqvU8vIZGsRuXmspskV0Tg==",
      "dependencies": {
        "@tootallnate/once": "1",
        "agent-base": "6",
        "debug": "4"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/https-proxy-agent": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/https-proxy-agent/-/https-proxy-agent-5.0.0.tgz",
      "integrity": "sha512-EkYm5BcKUGiduxzSt3Eppko+PiNWNEpa4ySk9vTC6wDsQJW9rHSa+UhGNJoRYp7bz6Ht1eaRIa6QaJqO5rCFbA==",
      "dependencies": {
        "agent-base": "6",
        "debug": "4"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/iconv-lite": {
      "version": "0.4.24",
      "resolved": "https://registry.npmjs.org/iconv-lite/-/iconv-lite-0.4.24.tgz",
      "integrity": "sha512-v3MXnZAcvnywkTUEZomIActle7RXXeedOR31wwl7VlyoXO4Qi9arvSenNQWne1TcRwhCL1HwLI21bEqdpj8/rA==",
      "dependencies": {
        "safer-buffer": ">= 2.1.2 < 3"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/inflation": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/inflation/-/inflation-2.1.0.tgz",
      "integrity": "sha512-t54PPJHG1Pp7VQvxyVCJ9mBbjG3Hqryges9bXoOO6GExCPa+//i/d5GSuFtpx3ALLd7lgIAur6zrIlBQyJuMlQ==",
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/inherits": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/inherits/-/inherits-2.0.4.tgz",
      "integrity": "sha512-k/vGaX4/Yla3WzyMCvTQOXYeIHvqOKtnqBduzTHpzpQZzAskKMhZ2K+EnBiSM9zGSoIFeMpXKxa4dYeZIQqewQ=="
    },
    "node_modules/is-docker": {
      "version": "2.2.1",
      "resolved": "https://registry.npmjs.org/is-docker/-/is-docker-2.2.1.tgz",
      "integrity": "sha512-F+i2BKsFrH66iaUFc0woD8sLy8getkwTwtOBjvs56Cx4CgJDeKQeqfz8wAYiSb8JOprWhHH5p77PbmYCvvUuXQ==",
      "bin": {
        "is-docker": "cli.js"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/is-generator-function": {
      "version": "1.0.10",
      "resolved": "https://registry.npmjs.org/is-generator-function/-/is-generator-function-1.0.10.tgz",
      "integrity": "sha512-jsEjy9l3yiXEQ+PsXdmBwEPcOxaXWLspKdplFUVI9vq1iZgIekeC0L167qeu86czQaxed3q/Uzuw0swL0irL8A==",
      "dependencies": {
        "has-tostringtag": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-wsl": {
      "version": "2.2.0",
      "resolved": "https://registry.npmjs.org/is-wsl/-/is-wsl-2.2.0.tgz",
      "integrity": "sha512-fKzAra0rGJUUBwGBgNkHZuToZcn+TtXHpeCgmkMJMMYx1sQDYaCSyjJBSCa2nH1DGm7s3n1oBnohoVTBaN7Lww==",
      "dependencies": {
        "is-docker": "^2.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/isarray": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/isarray/-/isarray-1.0.0.tgz",
      "integrity": "sha1-u5NdSFgsuhaMBoNJV6VKPgcSTxE="
    },
    "node_modules/json-stringify-safe": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/json-stringify-safe/-/json-stringify-safe-5.0.1.tgz",
      "integrity": "sha1-Epai1Y/UXxmg9s4B1lcB4sc1tus="
    },
    "node_modules/jsonparse": {
      "version": "1.3.1",
      "resolved": "https://registry.npmjs.org/jsonparse/-/jsonparse-1.3.1.tgz",
      "integrity": "sha1-P02uSpH6wxX3EGL4UhzCOfE2YoA=",
      "engines": [
        "node >= 0.2.0"
      ]
    },
    "node_modules/JSONStream": {
      "version": "1.3.5",
      "resolved": "https://registry.npmjs.org/JSONStream/-/JSONStream-1.3.5.tgz",
      "integrity": "sha512-E+iruNOY8VV9s4JEbe1aNEm6MiszPRr/UfcHMz0TQh1BXSxHK+ASV1R6W4HpjBhSeS+54PIsAMCBmwD06LLsqQ==",
      "dependencies": {
        "jsonparse": "^1.2.0",
        "through": ">=2.2.7 <3"
      },
      "bin": {
        "JSONStream": "bin.js"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/keygrip": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/keygrip/-/keygrip-1.1.0.tgz",
      "integrity": "sha512-iYSchDJ+liQ8iwbSI2QqsQOvqv58eJCEanyJPJi+Khyu8smkcKSFUCbPwzFcL7YVtZ6eONjqRX/38caJ7QjRAQ==",
      "dependencies": {
        "tsscmp": "1.0.6"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/koa": {
      "version": "2.15.0",
      "resolved": "https://registry.npmjs.org/koa/-/koa-2.15.0.tgz",
      "integrity": "sha512-KEL/vU1knsoUvfP4MC4/GthpQrY/p6dzwaaGI6Rt4NQuFqkw3qrvsdYF5pz3wOfi7IGTvMPHC9aZIcUKYFNxsw==",
      "dependencies": {
        "accepts": "^1.3.5",
        "cache-content-type": "^1.0.0",
        "content-disposition": "~0.5.2",
        "content-type": "^1.0.4",
        "cookies": "~0.9.0",
        "debug": "^4.3.2",
        "delegates": "^1.0.0",
        "depd": "^2.0.0",
        "destroy": "^1.0.4",
        "encodeurl": "^1.0.2",
        "escape-html": "^1.0.3",
        "fresh": "~0.5.2",
        "http-assert": "^1.3.0",
        "http-errors": "^1.6.3",
        "is-generator-function": "^1.0.7",
        "koa-compose": "^4.1.0",
        "koa-convert": "^2.0.0",
        "on-finished": "^2.3.0",
        "only": "~0.0.2",
        "parseurl": "^1.3.2",
        "statuses": "^1.5.0",
        "type-is": "^1.6.16",
        "vary": "^1.1.2"
      },
      "engines": {
        "node": "^4.8.4 || ^6.10.1 || ^7.10.1 || >= 8.1.4"
      }
    },
    "node_modules/koa-bodyparser": {
      "version": "4.4.1",
      "resolved": "https://registry.npmjs.org/koa-bodyparser/-/koa-bodyparser-4.4.1.tgz",
      "integrity": "sha512-kBH3IYPMb+iAXnrxIhXnW+gXV8OTzCu8VPDqvcDHW9SQrbkHmqPQtiZwrltNmSq6/lpipHnT7k7PsjlVD7kK0w==",
      "dependencies": {
        "co-body": "^6.0.0",
        "copy-to": "^2.0.1",
        "type-is": "^1.6.18"
      },
      "engines": {
        "node": ">=8.0.0"
      }
    },
    "node_modules/koa-compose": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/koa-compose/-/koa-compose-4.1.0.tgz",
      "integrity": "sha512-8ODW8TrDuMYvXRwra/Kh7/rJo9BtOfPc6qO8eAfC80CnCvSjSl0bkRM24X6/XBBEyj0v1nRUQ1LyOy3dbqOWXw=="
    },
    "node_modules/koa-compress": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/koa-compress/-/koa-compress-5.1.1.tgz",
      "integrity": "sha512-UgMIN7ZoEP2DuoSQmD6CYvFSLt0NReGlc2qSY4bO4Oq0L56OiD9pDG41Kj/zFmVY/A3Wvmn4BqKcfq5H30LGIg==",
      "dependencies": {
        "bytes": "^3.1.2",
        "compressible": "^2.0.18",
        "http-errors": "^1.8.1",
        "koa-is-json": "^1.0.0"
      },
      "engines": {
        "node": ">= 12"
      }
    },
    "node_modules/koa-conditional-get": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/koa-conditional-get/-/koa-conditional-get-2.0.0.tgz",
      "integrity": "sha1-pD83I8HQFLcwo07Oit8wuTyCM/I="
    },
    "node_modules/koa-convert": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/koa-convert/-/koa-convert-2.0.0.tgz",
      "integrity": "sha512-asOvN6bFlSnxewce2e/DK3p4tltyfC4VM7ZwuTuepI7dEQVcvpyFuBcEARu1+Hxg8DIwytce2n7jrZtRlPrARA==",
      "dependencies": {
        "co": "^4.6.0",
        "koa-compose": "^4.1.0"
      },
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/koa-etag": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/koa-etag/-/koa-etag-3.0.0.tgz",
      "integrity": "sha1-nvc4Ld1agqsN6xU0FckVg293HT8=",
      "dependencies": {
        "etag": "^1.3.0",
        "mz": "^2.1.0"
      }
    },
    "node_modules/koa-is-json": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/koa-is-json/-/koa-is-json-1.0.0.tgz",
      "integrity": "sha1-JzwH7c3Ljfaiwat9We52SRRR7BQ="
    },
    "node_modules/koa-json": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/koa-json/-/koa-json-2.0.2.tgz",
      "integrity": "sha1-Nq8U5uofXWRtfESihXAcb4Wk/eQ=",
      "dependencies": {
        "koa-is-json": "1",
        "streaming-json-stringify": "3"
      }
    },
    "node_modules/koa-morgan": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/koa-morgan/-/koa-morgan-1.0.1.tgz",
      "integrity": "sha1-CAUuDODYOdPEMXi5CluzQkvvH5k=",
      "dependencies": {
        "morgan": "^1.6.1"
      }
    },
    "node_modules/koa-range": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/koa-range/-/koa-range-0.3.0.tgz",
      "integrity": "sha512-Ich3pCz6RhtbajYXRWjIl6O5wtrLs6kE3nkXc9XmaWe+MysJyZO7K4L3oce1Jpg/iMgCbj+5UCiMm/rqVtcDIg==",
      "dependencies": {
        "stream-slice": "^0.1.2"
      },
      "engines": {
        "node": ">=7"
      }
    },
    "node_modules/koa-route": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/koa-route/-/koa-route-3.2.0.tgz",
      "integrity": "sha1-dimLmaa8+p44yrb+XHmocz51i84=",
      "dependencies": {
        "debug": "*",
        "methods": "~1.1.0",
        "path-to-regexp": "^1.2.0"
      }
    },
    "node_modules/koa-route/node_modules/isarray": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/isarray/-/isarray-0.0.1.tgz",
      "integrity": "sha1-ihis/Kmo9Bd+Cav8YDiTmwXR7t8="
    },
    "node_modules/koa-route/node_modules/path-to-regexp": {
      "version": "1.8.0",
      "resolved": "https://registry.npmjs.org/path-to-regexp/-/path-to-regexp-1.8.0.tgz",
      "integrity": "sha512-n43JRhlUKUAlibEJhPeir1ncUID16QnEjNpwzNdO3Lm4ywrBpBZ5oLD0I6br9evr1Y9JTqwRtAh7JLoOzAQdVA==",
      "dependencies": {
        "isarray": "0.0.1"
      }
    },
    "node_modules/koa-send": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/koa-send/-/koa-send-5.0.1.tgz",
      "integrity": "sha512-tmcyQ/wXXuxpDxyNXv5yNNkdAMdFRqwtegBXUaowiQzUKqJehttS0x2j0eOZDQAyloAth5w6wwBImnFzkUz3pQ==",
      "dependencies": {
        "debug": "^4.1.1",
        "http-errors": "^1.7.3",
        "resolve-path": "^1.4.0"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/koa-static": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/koa-static/-/koa-static-5.0.0.tgz",
      "integrity": "sha512-UqyYyH5YEXaJrf9S8E23GoJFQZXkBVJ9zYYMPGz919MSX1KuvAcycIuS0ci150HCoPf4XQVhQ84Qf8xRPWxFaQ==",
      "dependencies": {
        "debug": "^3.1.0",
        "koa-send": "^5.0.0"
      },
      "engines": {
        "node": ">= 7.6.0"
      }
    },
    "node_modules/koa-static/node_modules/debug": {
      "version": "3.2.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-3.2.7.tgz",
      "integrity": "sha512-CFjzYYAi4ThfiQvizrFQevTTXHtnCqWfe7x1AhgEscTz6ZbLbfoLRLPugTQyBth6f8ZERVUSyWHFD/7Wu4t1XQ==",
      "dependencies": {
        "ms": "^2.1.1"
      }
    },
    "node_modules/koa-static/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA=="
    },
    "node_modules/load-module": {
      "version": "4.2.1",
      "resolved": "https://registry.npmjs.org/load-module/-/load-module-4.2.1.tgz",
      "integrity": "sha512-Sbfg6R4LjvyThJpqUoADHMjyoI2+cL4msbCQeZ9kkY/CqP/TT2938eftKm7x4I2gd4/A+DEe6nePkbfWYbXwSw==",
      "dependencies": {
        "array-back": "^6.2.0"
      },
      "engines": {
        "node": ">=12.17"
      }
    },
    "node_modules/load-module/node_modules/array-back": {
      "version": "6.2.2",
      "resolved": "https://registry.npmjs.org/array-back/-/array-back-6.2.2.tgz",
      "integrity": "sha512-gUAZ7HPyb4SJczXAMUXMGAvI976JoK3qEx9v1FTmeYuJj0IBiaKttG1ydtGKdkfqWkIkouke7nG8ufGy77+Cvw==",
      "engines": {
        "node": ">=12.17"
      }
    },
    "node_modules/local-web-server": {
      "version": "5.3.1",
      "resolved": "https://registry.npmjs.org/local-web-server/-/local-web-server-5.3.1.tgz",
      "integrity": "sha512-SYMIyQsyIGSlhZ+px0NgMumIzK69KCifweF24FApdNcRzMs/+ENlvesiGamBzEO6njljOvCbBuNQK/7hWMoCCA==",
      "dependencies": {
        "current-module-paths": "^1.1.1",
        "lws": "^4.1.2",
        "lws-basic-auth": "^2.0.0",
        "lws-blacklist": "^3.0.0",
        "lws-body-parser": "^3.0.0",
        "lws-compress": "^3.1.0",
        "lws-conditional-get": "^2.0.0",
        "lws-cors": "^4.2.1",
        "lws-index": "^3.1.1",
        "lws-json": "^2.0.0",
        "lws-log": "^2.0.0",
        "lws-mime": "^2.0.0",
        "lws-range": "^4.0.1",
        "lws-request-monitor": "^2.0.0",
        "lws-rewrite": "^3.1.1",
        "lws-spa": "^4.1.0",
        "lws-static": "^3.1.0"
      },
      "bin": {
        "ws": "bin/cli.mjs"
      },
      "engines": {
        "node": ">=12.20"
      }
    },
    "node_modules/lodash.assignwith": {
      "version": "4.2.0",
      "resolved": "https://registry.npmjs.org/lodash.assignwith/-/lodash.assignwith-4.2.0.tgz",
      "integrity": "sha512-ZznplvbvtjK2gMvnQ1BR/zqPFZmS6jbK4p+6Up4xcRYA7yMIwxHCfbTcrYxXKzzqLsQ05eJPVznEW3tuwV7k1g=="
    },
    "node_modules/lodash.camelcase": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/lodash.camelcase/-/lodash.camelcase-4.3.0.tgz",
      "integrity": "sha512-TwuEnCnxbc3rAvhf/LbG7tJUDzhqXyFnv3dtzLOPgCG/hODL7WFnsbwktkD7yUV0RrreP/l1PALq/YSg6VvjlA=="
    },
    "node_modules/lodash.throttle": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/lodash.throttle/-/lodash.throttle-4.1.1.tgz",
      "integrity": "sha1-wj6RtxAkKscMN/HhzaknTMOb8vQ="
    },
    "node_modules/lws": {
      "version": "4.1.2",
      "resolved": "https://registry.npmjs.org/lws/-/lws-4.1.2.tgz",
      "integrity": "sha512-hm6mlYa5ZM+iLbFIEiifGnXJWbNRQL80DZ5gXfkdgBJSMIvjnVyVIPpw1fCU/IMcgHBvn1iCrFc391FP12NguQ==",
      "dependencies": {
        "@75lb/deep-merge": "^1.1.1",
        "ansi-escape-sequences": "^6.2.1",
        "array-back": "^6.2.2",
        "byte-size": "^8.1.0",
        "command-line-args": "^5.2.1",
        "command-line-usage": "^6.1.3",
        "create-mixin": "^3.0.0",
        "current-module-paths": "^1.1.0",
        "koa": "^2.13.4",
        "load-module": "^4.2.1",
        "open": "^8.4.0",
        "qrcode-terminal": "^0.12.0",
        "typical": "^7.1.1",
        "walk-back": "^5.1.0"
      },
      "bin": {
        "lws": "bin/cli.mjs"
      },
      "engines": {
        "node": ">=12.20"
      }
    },
    "node_modules/lws-basic-auth": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/lws-basic-auth/-/lws-basic-auth-2.0.0.tgz",
      "integrity": "sha512-zzyoGFLQPuKaQJvHMLmmSyfT6lIvocwcDXllTVW5brD0t0YgHYopILkzja+x+MIlJX/YhNKniaTSasujniYVjw==",
      "dependencies": {
        "basic-auth": "^2.0.1"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/lws-blacklist": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/lws-blacklist/-/lws-blacklist-3.0.0.tgz",
      "integrity": "sha512-KNXGDBmbj+UGfWMBAefe2vrfuWpEQms/9Fd7kfMScTqAKF6nrVoEs4pkxfefArG3bX0bu7jWLyB4tJGma5WC6Q==",
      "dependencies": {
        "array-back": "^4.0.1",
        "path-to-regexp": "^6.1.0"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/lws-body-parser": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/lws-body-parser/-/lws-body-parser-3.0.0.tgz",
      "integrity": "sha512-led36Um61ppeQoMTG7yvphn+NQPMbzuFuGUYD09eEx1UT7e8bsaLw1gkBZB9vAIkeTlXRbXjPmOqlm26eUzhfg==",
      "dependencies": {
        "koa-bodyparser": "^4.3.0"
      },
      "engines": {
        "node": ">=12.17"
      }
    },
    "node_modules/lws-compress": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/lws-compress/-/lws-compress-3.1.0.tgz",
      "integrity": "sha512-uBlpYFNBUD3FuQjXbtwasvD90w3HH6GRivknvbibSSsDQf1MtIM8WZ5fS4795n1ozTYnQD+Ai8T+Cpy0q0xuhA==",
      "dependencies": {
        "koa-compress": "^5.0.1"
      },
      "engines": {
        "node": ">=12.17"
      }
    },
    "node_modules/lws-conditional-get": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/lws-conditional-get/-/lws-conditional-get-2.0.0.tgz",
      "integrity": "sha512-U05yDlFJKIYa7gJZYfnc1HIEuXbKpDJztgkvNYyxCqJC28j/k9ORoNnFNOIHpBh/jlPJgV8x7uH34mIxFAryWA==",
      "dependencies": {
        "koa-conditional-get": "^2.0.0",
        "koa-etag": "^3.0.0"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/lws-cors": {
      "version": "4.2.1",
      "resolved": "https://registry.npmjs.org/lws-cors/-/lws-cors-4.2.1.tgz",
      "integrity": "sha512-KXsAn0Wn8n0riJ3SDHQzEAuzTrdeQZDJIxPHWEupsImW2hnQuBZVW5zqsmfzxD8SkCDDnQyFNuQZjSlBZmexKg==",
      "dependencies": {
        "@koa/cors": "^5.0.0"
      },
      "engines": {
        "node": ">=12.17"
      }
    },
    "node_modules/lws-index": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/lws-index/-/lws-index-3.1.1.tgz",
      "integrity": "sha512-f1rjsCkrKHVbSe03lm6xQ1GNnqzq/tL5f0ge8kXJFRorpS8Sv7WDXzUsGswmGAgxPPvDj8L7E6zwD+BCjQRU8w==",
      "dependencies": {
        "serve-index-75lb": "^2.0.1"
      },
      "engines": {
        "node": ">=12.17"
      }
    },
    "node_modules/lws-json": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/lws-json/-/lws-json-2.0.0.tgz",
      "integrity": "sha512-vqUFrAQ5BGpkMS2Mm/ZhgvUMi6Tgia7YtESG7pKjNoiSsD+TxncG0nqp8YjUh2xrEzi/SYFc/ed+9ZOl/t0A0g==",
      "dependencies": {
        "koa-json": "^2.0.2"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/lws-log": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/lws-log/-/lws-log-2.0.0.tgz",
      "integrity": "sha512-YveoazSZ0Qb1Tljdm8G8yn9c+mAMXgvLMACZzh5aZIk7p8YJwiXf9r1S+xY7wbXEcKG629KfVO0B5G5gRFcyDQ==",
      "dependencies": {
        "koa-morgan": "^1.0.1",
        "stream-log-stats": "^3.0.2"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/lws-mime": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/lws-mime/-/lws-mime-2.0.0.tgz",
      "integrity": "sha512-mfrAgRQ5+hkQ7LJ6EAgwnUeymNeYxwLXZY3UQ6C2hSTr7BqMSzm9k5O0C8wWP2dzdhChzITYKwzWbUnAYVBwtA==",
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/lws-range": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/lws-range/-/lws-range-4.0.1.tgz",
      "integrity": "sha512-rUkHpsRv5Ixr+8/E4cDCz6jUi6En6hnEaDZhPb0a1GU1vasOHhGcW0qilkgf0dtS0xDJzdKixdfcCW40ankIeQ==",
      "dependencies": {
        "koa-range": "^0.3.0"
      },
      "engines": {
        "node": ">=12.17"
      }
    },
    "node_modules/lws-request-monitor": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/lws-request-monitor/-/lws-request-monitor-2.0.0.tgz",
      "integrity": "sha512-ZTo0/pS42qiejcYlL+wlpurSbDSS0J7pDDohqBx7jjUQkgni2Qd8cPzn/kW8QI82gXgDmdZH+ps0vheLHlgdgg==",
      "dependencies": {
        "byte-size": "^6.2.0"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/lws-rewrite": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/lws-rewrite/-/lws-rewrite-3.1.1.tgz",
      "integrity": "sha512-cOeaPXIlLUVLxS6BZ52QzZVzI8JjCzlWD4RWizB5Hd+0YGO0SPa3Vgk7CIghtAOsSdjtXg/wSOap2H1h+tw8BQ==",
      "dependencies": {
        "array-back": "^4.0.1",
        "http-proxy-agent": "^4.0.1",
        "https-proxy-agent": "^5.0.0",
        "koa-route": "^3.2.0",
        "path-to-regexp": "^6.1.0"
      },
      "bin": {
        "lws-rewrite": "bin/cli.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/lws-spa": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/lws-spa/-/lws-spa-4.1.0.tgz",
      "integrity": "sha512-B1YhxAY02EYu7J9dKBQMpYRwOd4iOtKK3TDdUR2GnJ4nsnvoxsJnMUpg8yxGmWZ6NI8itdUdQJlwqKg/Gji/vQ==",
      "dependencies": {
        "koa-send": "^5.0.1"
      },
      "engines": {
        "node": ">=12.17"
      }
    },
    "node_modules/lws-static": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/lws-static/-/lws-static-3.1.0.tgz",
      "integrity": "sha512-0fWZRluPda0raMEzTd2mY/REWsa5LxDz03j+Zer8yhFfbicJGaocTK1jOlRo/H5UEDImBdfSDZGlrmzMaF9Xcg==",
      "dependencies": {
        "koa-static": "^5.0.0"
      },
      "engines": {
        "node": ">=12.17"
      }
    },
    "node_modules/lws/node_modules/ansi-escape-sequences": {
      "version": "6.2.2",
      "resolved": "https://registry.npmjs.org/ansi-escape-sequences/-/ansi-escape-sequences-6.2.2.tgz",
      "integrity": "sha512-mBPG9BZy4dMOJQ9BehU6ph8IKslvVppbqZ8APHnpfP+Hsx/hGow5PY46lSQL1vPPi1F5XTtO6p3GcH8O9c0cUg==",
      "dependencies": {
        "array-back": "^6.2.2"
      },
      "engines": {
        "node": ">=12.17"
      }
    },
    "node_modules/lws/node_modules/array-back": {
      "version": "6.2.2",
      "resolved": "https://registry.npmjs.org/array-back/-/array-back-6.2.2.tgz",
      "integrity": "sha512-gUAZ7HPyb4SJczXAMUXMGAvI976JoK3qEx9v1FTmeYuJj0IBiaKttG1ydtGKdkfqWkIkouke7nG8ufGy77+Cvw==",
      "engines": {
        "node": ">=12.17"
      }
    },
    "node_modules/lws/node_modules/byte-size": {
      "version": "8.1.1",
      "resolved": "https://registry.npmjs.org/byte-size/-/byte-size-8.1.1.tgz",
      "integrity": "sha512-tUkzZWK0M/qdoLEqikxBWe4kumyuwjl3HO6zHTr4yEI23EojPtLYXdG1+AQY7MN0cGyNDvEaJ8wiYQm6P2bPxg==",
      "engines": {
        "node": ">=12.17"
      }
    },
    "node_modules/media-typer": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/media-typer/-/media-typer-0.3.0.tgz",
      "integrity": "sha512-dq+qelQ9akHpcOl/gUVRTxVIOkAJ1wR3QAvb4RsVjS8oVoFjDGTc679wJYmUmknUF5HwMLOgb5O+a3KxfWapPQ==",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/methods": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/methods/-/methods-1.1.2.tgz",
      "integrity": "sha1-VSmk1nZUE07cxSZmVoNbD4Ua/O4=",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/mime-db": {
      "version": "1.52.0",
      "resolved": "https://registry.npmjs.org/mime-db/-/mime-db-1.52.0.tgz",
      "integrity": "sha512-sPU4uV7dYlvtWJxwwxHD0PuihVNiE7TyAbQ5SWxDCB9mUYvOgroQOwYQQOKPJ8CIbE+1ETVlOoK1UC2nU3gYvg==",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/mime-types": {
      "version": "2.1.35",
      "resolved": "https://registry.npmjs.org/mime-types/-/mime-types-2.1.35.tgz",
      "integrity": "sha512-ZDY+bPm5zTTF+YpCrAU9nK0UgICYPT0QtT1NZWFv4s++TNkcgVaT0g6+4R2uI4MjQjzysHB1zxuWL50hzaeXiw==",
      "dependencies": {
        "mime-db": "1.52.0"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/morgan": {
      "version": "1.10.0",
      "resolved": "https://registry.npmjs.org/morgan/-/morgan-1.10.0.tgz",
      "integrity": "sha512-AbegBVI4sh6El+1gNwvD5YIck7nSA36weD7xvIxG4in80j/UoK8AEGaWnnz8v1GxonMCltmlNs5ZKbGvl9b1XQ==",
      "dependencies": {
        "basic-auth": "~2.0.1",
        "debug": "2.6.9",
        "depd": "~2.0.0",
        "on-finished": "~2.3.0",
        "on-headers": "~1.0.2"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/morgan/node_modules/debug": {
      "version": "2.6.9",
      "resolved": "https://registry.npmjs.org/debug/-/debug-2.6.9.tgz",
      "integrity": "sha512-bC7ElrdJaJnPbAP+1EotYvqZsb3ecl5wi6Bfi6BJTUcNowp6cvspg0jXznRTKDjm/E7AdgFBVeAPVMNcKGsHMA==",
      "dependencies": {
        "ms": "2.0.0"
      }
    },
    "node_modules/ms": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.0.0.tgz",
      "integrity": "sha1-VgiurfwAvmwpAd9fmGF4jeDVl8g="
    },
    "node_modules/mz": {
      "version": "2.7.0",
      "resolved": "https://registry.npmjs.org/mz/-/mz-2.7.0.tgz",
      "integrity": "sha512-z81GNO7nnYMEhrGh9LeymoE4+Yr0Wn5McHIZMK5cfQCl+NDX08sCZgUc9/6MHni9IWuFLm1Z3HTCXu2z9fN62Q==",
      "dependencies": {
        "any-promise": "^1.0.0",
        "object-assign": "^4.0.1",
        "thenify-all": "^1.0.0"
      }
    },
    "node_modules/negotiator": {
      "version": "0.6.3",
      "resolved": "https://registry.npmjs.org/negotiator/-/negotiator-0.6.3.tgz",
      "integrity": "sha512-+EUsqGPLsM+j/zdChZjsnX51g4XrHFOIXwfnCVPGlQk/k5giakcKsuxCObBRu6DSm9opw/O6slWbJdghQM4bBg==",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/object-assign": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/object-assign/-/object-assign-4.1.1.tgz",
      "integrity": "sha1-IQmtx5ZYh8/AXLvUQsrIv7s2CGM=",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/object-inspect": {
      "version": "1.13.1",
      "resolved": "https://registry.npmjs.org/object-inspect/-/object-inspect-1.13.1.tgz",
      "integrity": "sha512-5qoj1RUiKOMsCCNLV1CBiPYE10sziTsnmNxkAI/rZhiD63CF7IqdFGC/XzjWjpSgLf0LxXX3bDFIh0E18f6UhQ==",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/on-finished": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/on-finished/-/on-finished-2.3.0.tgz",
      "integrity": "sha1-IPEzZIGwg811M3mSoWlxqi2QaUc=",
      "dependencies": {
        "ee-first": "1.1.1"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/on-headers": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/on-headers/-/on-headers-1.0.2.tgz",
      "integrity": "sha512-pZAE+FJLoyITytdqK0U5s+FIpjN0JP3OzFi/u8Rx+EV5/W+JTWGXG8xFzevE7AjBfDqHv/8vL8qQsIhHnqRkrA==",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/only": {
      "version": "0.0.2",
      "resolved": "https://registry.npmjs.org/only/-/only-0.0.2.tgz",
      "integrity": "sha512-Fvw+Jemq5fjjyWz6CpKx6w9s7xxqo3+JCyM0WXWeCSOboZ8ABkyvP8ID4CZuChA/wxSx+XSJmdOm8rGVyJ1hdQ=="
    },
    "node_modules/open": {
      "version": "8.4.2",
      "resolved": "https://registry.npmjs.org/open/-/open-8.4.2.tgz",
      "integrity": "sha512-7x81NCL719oNbsq/3mh+hVrAWmFuEYUqrq/Iw3kUzH8ReypT9QQ0BLoJS7/G9k6N81XjW4qHWtjWwe/9eLy1EQ==",
      "dependencies": {
        "define-lazy-prop": "^2.0.0",
        "is-docker": "^2.1.1",
        "is-wsl": "^2.2.0"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/parseurl": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/parseurl/-/parseurl-1.3.3.tgz",
      "integrity": "sha512-CiyeOxFT/JZyN5m0z9PfXw4SCBJ6Sygz1Dpl0wqjlhDEGGBP1GnsUVEL0p63hoG1fcj3fHynXi9NYO4nWOL+qQ==",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/path-is-absolute": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/path-is-absolute/-/path-is-absolute-1.0.1.tgz",
      "integrity": "sha512-AVbw3UJ2e9bq64vSaS9Am0fje1Pa8pbGqTTsmXfaIiMpnr5DlDhfJOuLj9Sf95ZPVDAUerDfEk88MPmPe7UCQg==",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/path-to-regexp": {
      "version": "6.2.0",
      "resolved": "https://registry.npmjs.org/path-to-regexp/-/path-to-regexp-6.2.0.tgz",
      "integrity": "sha512-f66KywYG6+43afgE/8j/GoiNyygk/bnoCbps++3ErRKsIYkGGupyv07R2Ok5m9i67Iqc+T2g1eAUGUPzWhYTyg=="
    },
    "node_modules/process-nextick-args": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/process-nextick-args/-/process-nextick-args-2.0.1.tgz",
      "integrity": "sha512-3ouUOpQhtgrbOa17J7+uxOTpITYWaGP7/AhoR3+A+/1e9skrzelGi/dXzEYyvbxubEF6Wn2ypscTKiKJFFn1ag=="
    },
    "node_modules/qrcode-terminal": {
      "version": "0.12.0",
      "resolved": "https://registry.npmjs.org/qrcode-terminal/-/qrcode-terminal-0.12.0.tgz",
      "integrity": "sha512-EXtzRZmC+YGmGlDFbXKxQiMZNwCLEO6BANKXG4iCtSIM0yqc/pappSx3RIKr4r0uh5JsBckOXeKrB3Iz7mdQpQ==",
      "bin": {
        "qrcode-terminal": "bin/qrcode-terminal.js"
      }
    },
    "node_modules/qs": {
      "version": "6.11.2",
      "resolved": "https://registry.npmjs.org/qs/-/qs-6.11.2.tgz",
      "integrity": "sha512-tDNIz22aBzCDxLtVH++VnTfzxlfeK5CbqohpSqpJgj1Wg/cQbStNAz3NuqCs5vV+pjBsK4x4pN9HlVh7rcYRiA==",
      "dependencies": {
        "side-channel": "^1.0.4"
      },
      "engines": {
        "node": ">=0.6"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/raw-body": {
      "version": "2.5.2",
      "resolved": "https://registry.npmjs.org/raw-body/-/raw-body-2.5.2.tgz",
      "integrity": "sha512-8zGqypfENjCIqGhgXToC8aB2r7YrBX+AQAfIPs/Mlk+BtPTztOvTS01NRW/3Eh60J+a48lt8qsCzirQ6loCVfA==",
      "dependencies": {
        "bytes": "3.1.2",
        "http-errors": "2.0.0",
        "iconv-lite": "0.4.24",
        "unpipe": "1.0.0"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/raw-body/node_modules/http-errors": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/http-errors/-/http-errors-2.0.0.tgz",
      "integrity": "sha512-FtwrG/euBzaEjYeRqOgly7G0qviiXoJWnvEH2Z1plBdXgbyjv34pHTSb9zoeHMyDy33+DWy5Wt9Wo+TURtOYSQ==",
      "dependencies": {
        "depd": "2.0.0",
        "inherits": "2.0.4",
        "setprototypeof": "1.2.0",
        "statuses": "2.0.1",
        "toidentifier": "1.0.1"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/raw-body/node_modules/statuses": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/statuses/-/statuses-2.0.1.tgz",
      "integrity": "sha512-RwNA9Z/7PrK06rYLIzFMlaF+l73iwpzsqRIFgbMLbTcLD6cOao82TaWefPXQvB2fOC4AjuYSEndS7N/mTCbkdQ==",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/readable-stream": {
      "version": "2.3.7",
      "resolved": "https://registry.npmjs.org/readable-stream/-/readable-stream-2.3.7.tgz",
      "integrity": "sha512-Ebho8K4jIbHAxnuxi7o42OrZgF/ZTNcsZj6nRKyUmkhLFq8CHItp/fy6hQZuZmP/n3yZ9VBUbp4zz/mX8hmYPw==",
      "dependencies": {
        "core-util-is": "~1.0.0",
        "inherits": "~2.0.3",
        "isarray": "~1.0.0",
        "process-nextick-args": "~2.0.0",
        "safe-buffer": "~5.1.1",
        "string_decoder": "~1.1.1",
        "util-deprecate": "~1.0.1"
      }
    },
    "node_modules/resolve-path": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/resolve-path/-/resolve-path-1.4.0.tgz",
      "integrity": "sha512-i1xevIst/Qa+nA9olDxLWnLk8YZbi8R/7JPbCMcgyWaFR6bKWaexgJgEB5oc2PKMjYdrHynyz0NY+if+H98t1w==",
      "dependencies": {
        "http-errors": "~1.6.2",
        "path-is-absolute": "1.0.1"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/resolve-path/node_modules/depd": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/depd/-/depd-1.1.2.tgz",
      "integrity": "sha512-7emPTl6Dpo6JRXOXjLRxck+FlLRX5847cLKEn00PLAgc3g2hTZZgr+e4c2v6QpSmLeFP3n5yUo7ft6avBK/5jQ==",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/resolve-path/node_modules/http-errors": {
      "version": "1.6.3",
      "resolved": "https://registry.npmjs.org/http-errors/-/http-errors-1.6.3.tgz",
      "integrity": "sha512-lks+lVC8dgGyh97jxvxeYTWQFvh4uw4yC12gVl63Cg30sjPX4wuGcdkICVXDAESr6OJGjqGA8Iz5mkeN6zlD7A==",
      "dependencies": {
        "depd": "~1.1.2",
        "inherits": "2.0.3",
        "setprototypeof": "1.1.0",
        "statuses": ">= 1.4.0 < 2"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/resolve-path/node_modules/inherits": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/inherits/-/inherits-2.0.3.tgz",
      "integrity": "sha512-x00IRNXNy63jwGkJmzPigoySHbaqpNuzKbBOmzK+g2OdZpQ9w+sxCN+VSB3ja7IAge2OP2qpfxTjeNcyjmW1uw=="
    },
    "node_modules/resolve-path/node_modules/setprototypeof": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/setprototypeof/-/setprototypeof-1.1.0.tgz",
      "integrity": "sha512-BvE/TwpZX4FXExxOxZyRGQQv651MSwmWKZGqvmPcRIjDqWub67kTKuIMx43cZZrS/cBBzwBcNDWoFxt2XEFIpQ=="
    },
    "node_modules/safe-buffer": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/safe-buffer/-/safe-buffer-5.1.2.tgz",
      "integrity": "sha512-Gd2UZBJDkXlY7GbJxfsE8/nvKkUEU1G38c1siN6QP6a9PT9MmHB8GnpscSmMJSoF8LOIrt8ud/wPtojys4G6+g=="
    },
    "node_modules/safer-buffer": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/safer-buffer/-/safer-buffer-2.1.2.tgz",
      "integrity": "sha512-YZo3K82SD7Riyi0E1EQPojLz7kpepnSQI9IyPbHHg1XXXevb5dJI7tpyN2ADxGcQbHG7vcyRHk0cbwqcQriUtg=="
    },
    "node_modules/serve-index-75lb": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/serve-index-75lb/-/serve-index-75lb-2.0.1.tgz",
      "integrity": "sha512-/d9r8bqJlFQcwy0a0nb1KnWAA+Mno+V+VaoKocdkbW5aXKRQd/+4bfnRhQRQr6uEoYwTRJ4xgztOyCJvWcpBpQ==",
      "dependencies": {
        "accepts": "~1.3.4",
        "batch": "0.6.1",
        "debug": "2.6.9",
        "escape-html": "~1.0.3",
        "http-errors": "~1.6.2",
        "mime-types": "~2.1.18",
        "parseurl": "~1.3.2"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/serve-index-75lb/node_modules/debug": {
      "version": "2.6.9",
      "resolved": "https://registry.npmjs.org/debug/-/debug-2.6.9.tgz",
      "integrity": "sha512-bC7ElrdJaJnPbAP+1EotYvqZsb3ecl5wi6Bfi6BJTUcNowp6cvspg0jXznRTKDjm/E7AdgFBVeAPVMNcKGsHMA==",
      "dependencies": {
        "ms": "2.0.0"
      }
    },
    "node_modules/serve-index-75lb/node_modules/depd": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/depd/-/depd-1.1.2.tgz",
      "integrity": "sha512-7emPTl6Dpo6JRXOXjLRxck+FlLRX5847cLKEn00PLAgc3g2hTZZgr+e4c2v6QpSmLeFP3n5yUo7ft6avBK/5jQ==",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/serve-index-75lb/node_modules/http-errors": {
      "version": "1.6.3",
      "resolved": "https://registry.npmjs.org/http-errors/-/http-errors-1.6.3.tgz",
      "integrity": "sha512-lks+lVC8dgGyh97jxvxeYTWQFvh4uw4yC12gVl63Cg30sjPX4wuGcdkICVXDAESr6OJGjqGA8Iz5mkeN6zlD7A==",
      "dependencies": {
        "depd": "~1.1.2",
        "inherits": "2.0.3",
        "setprototypeof": "1.1.0",
        "statuses": ">= 1.4.0 < 2"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/serve-index-75lb/node_modules/inherits": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/inherits/-/inherits-2.0.3.tgz",
      "integrity": "sha512-x00IRNXNy63jwGkJmzPigoySHbaqpNuzKbBOmzK+g2OdZpQ9w+sxCN+VSB3ja7IAge2OP2qpfxTjeNcyjmW1uw=="
    },
    "node_modules/serve-index-75lb/node_modules/setprototypeof": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/setprototypeof/-/setprototypeof-1.1.0.tgz",
      "integrity": "sha512-BvE/TwpZX4FXExxOxZyRGQQv651MSwmWKZGqvmPcRIjDqWub67kTKuIMx43cZZrS/cBBzwBcNDWoFxt2XEFIpQ=="
    },
    "node_modules/set-function-length": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/set-function-length/-/set-function-length-1.1.1.tgz",
      "integrity": "sha512-VoaqjbBJKiWtg4yRcKBQ7g7wnGnLV3M8oLvVWwOk2PdYY6PEFegR1vezXR0tw6fZGF9csVakIRjrJiy2veSBFQ==",
      "dependencies": {
        "define-data-property": "^1.1.1",
        "get-intrinsic": "^1.2.1",
        "gopd": "^1.0.1",
        "has-property-descriptors": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/setprototypeof": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/setprototypeof/-/setprototypeof-1.2.0.tgz",
      "integrity": "sha512-E5LDX7Wrp85Kil5bhZv46j8jOeboKq5JMmYM3gVGdGH8xFpPWXUMsNrlODCrkoxMEeNi/XZIwuRvY4XNwYMJpw=="
    },
    "node_modules/side-channel": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/side-channel/-/side-channel-1.0.4.tgz",
      "integrity": "sha512-q5XPytqFEIKHkGdiMIrY10mvLRvnQh42/+GoBlFW3b2LXLE2xxJpZFdm94we0BaoV3RwJyGqg5wS7epxTv0Zvw==",
      "dependencies": {
        "call-bind": "^1.0.0",
        "get-intrinsic": "^1.0.2",
        "object-inspect": "^1.9.0"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/statuses": {
      "version": "1.5.0",
      "resolved": "https://registry.npmjs.org/statuses/-/statuses-1.5.0.tgz",
      "integrity": "sha512-OpZ3zP+jT1PI7I8nemJX4AKmAX070ZkYPVWV/AaKTJl+tXCTGyVdC1a4SL8RUQYEwk/f34ZX8UTykN68FwrqAA==",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/stream-log-stats": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/stream-log-stats/-/stream-log-stats-3.0.2.tgz",
      "integrity": "sha512-393j7aeF9iRdHvyANqEQU82UQmpw2CTxgsT83caefh+lOxavVLbVrw8Mr4zjXeZLh2+xeHZMKfVx4T0rJ/EchA==",
      "dependencies": {
        "ansi-escape-sequences": "^5.1.2",
        "byte-size": "^6.2.0",
        "common-log-format": "^1.0.0",
        "JSONStream": "^1.3.5",
        "lodash.throttle": "^4.1.1",
        "stream-via": "^1.0.4",
        "table-layout": "~1.0.0"
      },
      "bin": {
        "log-stats": "bin/cli.js"
      },
      "engines": {
        "node": ">=8.0.0"
      }
    },
    "node_modules/stream-slice": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/stream-slice/-/stream-slice-0.1.2.tgz",
      "integrity": "sha512-QzQxpoacatkreL6jsxnVb7X5R/pGw9OUv2qWTYWnmLpg4NdN31snPy/f3TdQE1ZUXaThRvj1Zw4/OGg0ZkaLMA=="
    },
    "node_modules/stream-via": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/stream-via/-/stream-via-1.0.4.tgz",
      "integrity": "sha512-DBp0lSvX5G9KGRDTkR/R+a29H+Wk2xItOF+MpZLLNDWbEV9tGPnqLPxHEYjmiz8xGtJHRIqmI+hCjmNzqoA4nQ==",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/streaming-json-stringify": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/streaming-json-stringify/-/streaming-json-stringify-3.1.0.tgz",
      "integrity": "sha1-gCAEN6mTzDnE/gAmO3s7kDrIevU=",
      "dependencies": {
        "json-stringify-safe": "5",
        "readable-stream": "2"
      }
    },
    "node_modules/string_decoder": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-1.1.1.tgz",
      "integrity": "sha512-n/ShnvDi6FHbbVfviro+WojiFzv+s8MPMHBczVePfUpDJLwoLT0ht1l4YwBCbi8pJAveEEdnkHyPyTP/mzRfwg==",
      "dependencies": {
        "safe-buffer": "~5.1.0"
      }
    },
    "node_modules/supports-color": {
      "version": "5.5.0",
      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-5.5.0.tgz",
      "integrity": "sha512-QjVjwdXIt408MIiAqCX4oUKsgU2EqAGzs2Ppkm4aQYbjm+ZEWEcW4SfFNTr4uMNZma0ey4f5lgLrkB0aX0QMow==",
      "dependencies": {
        "has-flag": "^3.0.0"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/table-layout": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/table-layout/-/table-layout-1.0.2.tgz",
      "integrity": "sha512-qd/R7n5rQTRFi+Zf2sk5XVVd9UQl6ZkduPFC3S7WEGJAmetDTjY3qPN50eSKzwuzEyQKy5TN2TiZdkIjos2L6A==",
      "dependencies": {
        "array-back": "^4.0.1",
        "deep-extend": "~0.6.0",
        "typical": "^5.2.0",
        "wordwrapjs": "^4.0.0"
      },
      "engines": {
        "node": ">=8.0.0"
      }
    },
    "node_modules/table-layout/node_modules/typical": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/typical/-/typical-5.2.0.tgz",
      "integrity": "sha512-dvdQgNDNJo+8B2uBQoqdb11eUCE1JQXhvjC/CZtgvZseVd5TYMXnq0+vuUemXbd/Se29cTaUuPX3YIc2xgbvIg==",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/thenify": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/thenify/-/thenify-3.3.1.tgz",
      "integrity": "sha512-RVZSIV5IG10Hk3enotrhvz0T9em6cyHBLkH/YAZuKqd8hRkKhSfCGIcP2KUY0EPxndzANBmNllzWPwak+bheSw==",
      "dependencies": {
        "any-promise": "^1.0.0"
      }
    },
    "node_modules/thenify-all": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/thenify-all/-/thenify-all-1.6.0.tgz",
      "integrity": "sha1-GhkY1ALY/D+Y+/I02wvMjMEOlyY=",
      "dependencies": {
        "thenify": ">= 3.1.0 < 4"
      },
      "engines": {
        "node": ">=0.8"
      }
    },
    "node_modules/through": {
      "version": "2.3.8",
      "resolved": "https://registry.npmjs.org/through/-/through-2.3.8.tgz",
      "integrity": "sha1-DdTJ/6q8NXlgsbckEV1+Doai4fU="
    },
    "node_modules/toidentifier": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/toidentifier/-/toidentifier-1.0.1.tgz",
      "integrity": "sha512-o5sSPKEkg/DIQNmH43V0/uerLrpzVedkUh8tGNvaeXpfpuwjKenlSox/2O/BTlZUtEe+JG7s5YhEz608PlAHRA==",
      "engines": {
        "node": ">=0.6"
      }
    },
    "node_modules/tsscmp": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/tsscmp/-/tsscmp-1.0.6.tgz",
      "integrity": "sha512-LxhtAkPDTkVCMQjt2h6eBVY28KCjikZqZfMcC15YBeNjkgUpdCfBu5HoiOTDu86v6smE8yOjyEktJ8hlbANHQA==",
      "engines": {
        "node": ">=0.6.x"
      }
    },
    "node_modules/type-is": {
      "version": "1.6.18",
      "resolved": "https://registry.npmjs.org/type-is/-/type-is-1.6.18.tgz",
      "integrity": "sha512-TkRKr9sUTxEH8MdfuCSP7VizJyzRNMjj2J2do2Jr3Kym598JVdEksuzPQCnlFPW4ky9Q+iA+ma9BGm06XQBy8g==",
      "dependencies": {
        "media-typer": "0.3.0",
        "mime-types": "~2.1.24"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/typical": {
      "version": "7.1.1",
      "resolved": "https://registry.npmjs.org/typical/-/typical-7.1.1.tgz",
      "integrity": "sha512-T+tKVNs6Wu7IWiAce5BgMd7OZfNYUndHwc5MknN+UHOudi7sGZzuHdCadllRuqJ3fPtgFtIH9+lt9qRv6lmpfA==",
      "engines": {
        "node": ">=12.17"
      }
    },
    "node_modules/unpipe": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/unpipe/-/unpipe-1.0.0.tgz",
      "integrity": "sha512-pjy2bYhSsufwWlKwPc+l3cN7+wuJlK6uz0YdJEOlQDbl6jo/YlPi4mb8agUkVC8BF7V8NuzeyPNqRksA3hztKQ==",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/util-deprecate": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/util-deprecate/-/util-deprecate-1.0.2.tgz",
      "integrity": "sha1-RQ1Nyfpw3nMnYvvS1KKJgUGaDM8="
    },
    "node_modules/vary": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/vary/-/vary-1.1.2.tgz",
      "integrity": "sha512-BNGbWLfd0eUPabhkXUVm0j8uuvREyTh5ovRa/dyow/BqAbZJyC+5fU+IzQOzmAKzYqYRAISoRhdQr3eIZ/PXqg==",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/walk-back": {
      "version": "5.1.0",
      "resolved": "https://registry.npmjs.org/walk-back/-/walk-back-5.1.0.tgz",
      "integrity": "sha512-Uhxps5yZcVNbLEAnb+xaEEMdgTXl9qAQDzKYejG2AZ7qPwRQ81lozY9ECDbjLPNWm7YsO1IK5rsP1KoQzXAcGA==",
      "engines": {
        "node": ">=12.17"
      }
    },
    "node_modules/wordwrapjs": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/wordwrapjs/-/wordwrapjs-4.0.1.tgz",
      "integrity": "sha512-kKlNACbvHrkpIw6oPeYDSmdCTu2hdMHoyXLTcUKala++lx5Y+wjJ/e474Jqv5abnVmwxw08DiTuHmw69lJGksA==",
      "dependencies": {
        "reduce-flatten": "^2.0.0",
        "typical": "^5.2.0"
      },
      "engines": {
        "node": ">=8.0.0"
      }
    },
    "node_modules/wordwrapjs/node_modules/reduce-flatten": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/reduce-flatten/-/reduce-flatten-2.0.0.tgz",
      "integrity": "sha512-EJ4UNY/U1t2P/2k6oqotuX2Cc3T6nxJwsM0N0asT7dhrtH1ltUxDn4NalSYmPE2rCkVpcf/X6R0wDwcFpzhd4w==",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/wordwrapjs/node_modules/typical": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/typical/-/typical-5.2.0.tgz",
      "integrity": "sha512-dvdQgNDNJo+8B2uBQoqdb11eUCE1JQXhvjC/CZtgvZseVd5TYMXnq0+vuUemXbd/Se29cTaUuPX3YIc2xgbvIg==",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/ylru": {
      "version": "1.3.2",
      "resolved": "https://registry.npmjs.org/ylru/-/ylru-1.3.2.tgz",
      "integrity": "sha512-RXRJzMiK6U2ye0BlGGZnmpwJDPgakn6aNQ0A7gHRbD4I0uvK4TW6UqkK1V0pp9jskjJBAXd3dRrbzWkqJ+6cxA==",
      "engines": {
        "node": ">= 4.0.0"
      }
    }
  },
  "dependencies": {
    "@75lb/deep-merge": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@75lb/deep-merge/-/deep-merge-1.1.1.tgz",
      "integrity": "sha512-xvgv6pkMGBA6GwdyJbNAnDmfAIR/DfWhrj9jgWh3TY7gRm3KO46x/GPjRg6wJ0nOepwqrNxFfojebh0Df4h4Tw==",
      "requires": {
        "lodash.assignwith": "^4.2.0",
        "typical": "^7.1.1"
      }
    },
    "@koa/cors": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/@koa/cors/-/cors-5.0.0.tgz",
      "integrity": "sha512-x/iUDjcS90W69PryLDIMgFyV21YLTnG9zOpPXS7Bkt2b8AsY3zZsIpOLBkYr9fBcF3HbkKaER5hOBZLfpLgYNw==",
      "requires": {
        "vary": "^1.1.2"
      }
    },
    "@tootallnate/once": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/@tootallnate/once/-/once-1.1.2.tgz",
      "integrity": "sha512-RbzJvlNzmRq5c3O09UipeuXno4tA1FE6ikOjxZK0tuxVv3412l64l5t1W5pj4+rJq9vpkm/kwiR07aZXnsKPxw=="
    },
    "accepts": {
      "version": "1.3.8",
      "resolved": "https://registry.npmjs.org/accepts/-/accepts-1.3.8.tgz",
      "integrity": "sha512-PYAthTa2m2VKxuvSD3DPC/Gy+U+sOA1LAuT8mkmRuvw+NACSaeXEQ+NHcVF7rONl6qcaxV3Uuemwawk+7+SJLw==",
      "requires": {
        "mime-types": "~2.1.34",
        "negotiator": "0.6.3"
      }
    },
    "agent-base": {
      "version": "6.0.2",
      "resolved": "https://registry.npmjs.org/agent-base/-/agent-base-6.0.2.tgz",
      "integrity": "sha512-RZNwNclF7+MS/8bDg70amg32dyeZGZxiDuQmZxKLAlQjr3jGyLx+4Kkk58UO7D2QdgFIQCovuSuZESne6RG6XQ==",
      "requires": {
        "debug": "4"
      }
    },
    "ansi-escape-sequences": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/ansi-escape-sequences/-/ansi-escape-sequences-5.1.2.tgz",
      "integrity": "sha512-JcpoVp1W1bl1Qn4cVuiXEhD6+dyXKSOgCn2zlzE8inYgCJCBy1aPnUhlz6I4DFum8D4ovb9Qi/iAjUcGvG2lqw==",
      "requires": {
        "array-back": "^4.0.0"
      }
    },
    "ansi-styles": {
      "version": "3.2.1",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-3.2.1.tgz",
      "integrity": "sha512-VT0ZI6kZRdTh8YyJw3SMbYm/u+NqfsAxEpWO0Pf9sq8/e94WxxOpPKx9FR1FlyCtOVDNOQ+8ntlqFxiRc+r5qA==",
      "requires": {
        "color-convert": "^1.9.0"
      }
    },
    "any-promise": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/any-promise/-/any-promise-1.3.0.tgz",
      "integrity": "sha1-q8av7tzqUugJzcA3au0845Y10X8="
    },
    "array-back": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/array-back/-/array-back-4.0.2.tgz",
      "integrity": "sha512-NbdMezxqf94cnNfWLL7V/im0Ub+Anbb0IoZhvzie8+4HJ4nMQuzHuy49FkGYCJK2yAloZ3meiB6AVMClbrI1vg=="
    },
    "basic-auth": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/basic-auth/-/basic-auth-2.0.1.tgz",
      "integrity": "sha512-NF+epuEdnUYVlGuhaxbbq+dvJttwLnGY+YixlXlME5KpQ5W3CnXA5cVTneY3SPbPDRkcjMbifrwmFYcClgOZeg==",
      "requires": {
        "safe-buffer": "5.1.2"
      }
    },
    "batch": {
      "version": "0.6.1",
      "resolved": "https://registry.npmjs.org/batch/-/batch-0.6.1.tgz",
      "integrity": "sha512-x+VAiMRL6UPkx+kudNvxTl6hB2XNNCG2r+7wixVfIYwu/2HKRXimwQyaumLjMveWvT2Hkd/cAJw+QBMfJ/EKVw=="
    },
    "byte-size": {
      "version": "6.2.0",
      "resolved": "https://registry.npmjs.org/byte-size/-/byte-size-6.2.0.tgz",
      "integrity": "sha512-6EspYUCAPMc7E2rltBgKwhG+Cmk0pDm9zDtF1Awe2dczNUL3YpZ8mTs/dueOTS1hqGWBOatqef4jYMGjln7WmA=="
    },
    "bytes": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/bytes/-/bytes-3.1.2.tgz",
      "integrity": "sha512-/Nf7TyzTx6S3yRJObOAV7956r8cr2+Oj8AC5dt8wSP3BQAoeX58NoHyCU8P8zGkNXStjTSi6fzO6F0pBdcYbEg=="
    },
    "cache-content-type": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/cache-content-type/-/cache-content-type-1.0.1.tgz",
      "integrity": "sha512-IKufZ1o4Ut42YUrZSo8+qnMTrFuKkvyoLXUywKz9GJ5BrhOFGhLdkx9sG4KAnVvbY6kEcSFjLQul+DVmBm2bgA==",
      "requires": {
        "mime-types": "^2.1.18",
        "ylru": "^1.2.0"
      }
    },
    "call-bind": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/call-bind/-/call-bind-1.0.5.tgz",
      "integrity": "sha512-C3nQxfFZxFRVoJoGKKI8y3MOEo129NQ+FgQ08iye+Mk4zNZZGdjfs06bVTr+DBSlA66Q2VEcMki/cUCP4SercQ==",
      "requires": {
        "function-bind": "^1.1.2",
        "get-intrinsic": "^1.2.1",
        "set-function-length": "^1.1.1"
      }
    },
    "chalk": {
      "version": "2.4.2",
      "resolved": "https://registry.npmjs.org/chalk/-/chalk-2.4.2.tgz",
      "integrity": "sha512-Mti+f9lpJNcwF4tWV8/OrTTtF1gZi+f8FqlyAdouralcFWFQWF2+NgCHShjkCb+IFBLq9buZwE1xckQU4peSuQ==",
      "requires": {
        "ansi-styles": "^3.2.1",
        "escape-string-regexp": "^1.0.5",
        "supports-color": "^5.3.0"
      }
    },
    "co": {
      "version": "4.6.0",
      "resolved": "https://registry.npmjs.org/co/-/co-4.6.0.tgz",
      "integrity": "sha512-QVb0dM5HvG+uaxitm8wONl7jltx8dqhfU33DcqtOZcLSVIKSDDLDi7+0LbAKiyI8hD9u42m2YxXSkMGWThaecQ=="
    },
    "co-body": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/co-body/-/co-body-6.1.0.tgz",
      "integrity": "sha512-m7pOT6CdLN7FuXUcpuz/8lfQ/L77x8SchHCF4G0RBTJO20Wzmhn5Sp4/5WsKy8OSpifBSUrmg83qEqaDHdyFuQ==",
      "requires": {
        "inflation": "^2.0.0",
        "qs": "^6.5.2",
        "raw-body": "^2.3.3",
        "type-is": "^1.6.16"
      }
    },
    "color-convert": {
      "version": "1.9.3",
      "resolved": "https://registry.npmjs.org/color-convert/-/color-convert-1.9.3.tgz",
      "integrity": "sha512-QfAUtd+vFdAtFQcC8CCyYt1fYWxSqAiK2cSD6zDB8N3cpsEBAvRxp9zOGg6G/SHHJYAT88/az/IuDGALsNVbGg==",
      "requires": {
        "color-name": "1.1.3"
      }
    },
    "color-name": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/color-name/-/color-name-1.1.3.tgz",
      "integrity": "sha512-72fSenhMw2HZMTVHeCA9KCmpEIbzWiQsjN+BHcBbS9vr1mtt+vJjPdksIBNUmKAW8TFUDPJK5SUU3QhE9NEXDw=="
    },
    "command-line-args": {
      "version": "5.2.1",
      "resolved": "https://registry.npmjs.org/command-line-args/-/command-line-args-5.2.1.tgz",
      "integrity": "sha512-H4UfQhZyakIjC74I9d34fGYDwk3XpSr17QhEd0Q3I9Xq1CETHo4Hcuo87WyWHpAF1aSLjLRf5lD9ZGX2qStUvg==",
      "requires": {
        "array-back": "^3.1.0",
        "find-replace": "^3.0.0",
        "lodash.camelcase": "^4.3.0",
        "typical": "^4.0.0"
      },
      "dependencies": {
        "array-back": {
          "version": "3.1.0",
          "resolved": "https://registry.npmjs.org/array-back/-/array-back-3.1.0.tgz",
          "integrity": "sha512-TkuxA4UCOvxuDK6NZYXCalszEzj+TLszyASooky+i742l9TqsOdYCMJJupxRic61hwquNtppB3hgcuq9SVSH1Q=="
        },
        "typical": {
          "version": "4.0.0",
          "resolved": "https://registry.npmjs.org/typical/-/typical-4.0.0.tgz",
          "integrity": "sha512-VAH4IvQ7BDFYglMd7BPRDfLgxZZX4O4TFcRDA6EN5X7erNJJq+McIEp8np9aVtxrCJ6qx4GTYVfOWNjcqwZgRw=="
        }
      }
    },
    "command-line-usage": {
      "version": "6.1.3",
      "resolved": "https://registry.npmjs.org/command-line-usage/-/command-line-usage-6.1.3.tgz",
      "integrity": "sha512-sH5ZSPr+7UStsloltmDh7Ce5fb8XPlHyoPzTpyyMuYCtervL65+ubVZ6Q61cFtFl62UyJlc8/JwERRbAFPUqgw==",
      "requires": {
        "array-back": "^4.0.2",
        "chalk": "^2.4.2",
        "table-layout": "^1.0.2",
        "typical": "^5.2.0"
      },
      "dependencies": {
        "typical": {
          "version": "5.2.0",
          "resolved": "https://registry.npmjs.org/typical/-/typical-5.2.0.tgz",
          "integrity": "sha512-dvdQgNDNJo+8B2uBQoqdb11eUCE1JQXhvjC/CZtgvZseVd5TYMXnq0+vuUemXbd/Se29cTaUuPX3YIc2xgbvIg=="
        }
      }
    },
    "common-log-format": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/common-log-format/-/common-log-format-1.0.0.tgz",
      "integrity": "sha512-fFn/WPNbsTCGTTwdCpZfVZSa5mgqMEkA0gMTRApFSlEsYN+9B2FPfiqch5FT+jsv5IV1RHV3GeZvCa7Qg+jssw=="
    },
    "compressible": {
      "version": "2.0.18",
      "resolved": "https://registry.npmjs.org/compressible/-/compressible-2.0.18.tgz",
      "integrity": "sha512-AF3r7P5dWxL8MxyITRMlORQNaOA2IkAFaTr4k7BUumjPtRpGDTZpl0Pb1XCO6JeDCBdp126Cgs9sMxqSjgYyRg==",
      "requires": {
        "mime-db": ">= 1.43.0 < 2"
      }
    },
    "content-disposition": {
      "version": "0.5.4",
      "resolved": "https://registry.npmjs.org/content-disposition/-/content-disposition-0.5.4.tgz",
      "integrity": "sha512-FveZTNuGw04cxlAiWbzi6zTAL/lhehaWbTtgluJh4/E95DqMwTmha3KZN1aAWA8cFIhHzMZUvLevkw5Rqk+tSQ==",
      "requires": {
        "safe-buffer": "5.2.1"
      },
      "dependencies": {
        "safe-buffer": {
          "version": "5.2.1",
          "resolved": "https://registry.npmjs.org/safe-buffer/-/safe-buffer-5.2.1.tgz",
          "integrity": "sha512-rp3So07KcdmmKbGvgaNxQSJr7bGVSVk5S9Eq1F+ppbRo70+YeaDxkw5Dd8NPN+GD6bjnYm2VuPuCXmpuYvmCXQ=="
        }
      }
    },
    "content-type": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/content-type/-/content-type-1.0.5.tgz",
      "integrity": "sha512-nTjqfcBFEipKdXCv4YDQWCfmcLZKm81ldF0pAopTvyrFGVbcR6P/VAAd5G7N+0tTr8QqiU0tFadD6FK4NtJwOA=="
    },
    "cookies": {
      "version": "0.9.1",
      "resolved": "https://registry.npmjs.org/cookies/-/cookies-0.9.1.tgz",
      "integrity": "sha512-TG2hpqe4ELx54QER/S3HQ9SRVnQnGBtKUz5bLQWtYAQ+o6GpgMs6sYUvaiJjVxb+UXwhRhAEP3m7LbsIZ77Hmw==",
      "requires": {
        "depd": "~2.0.0",
        "keygrip": "~1.1.0"
      }
    },
    "copy-to": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/copy-to/-/copy-to-2.0.1.tgz",
      "integrity": "sha512-3DdaFaU/Zf1AnpLiFDeNCD4TOWe3Zl2RZaTzUvWiIk5ERzcCodOE20Vqq4fzCbNoHURFHT4/us/Lfq+S2zyY4w=="
    },
    "core-util-is": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/core-util-is/-/core-util-is-1.0.2.tgz",
      "integrity": "sha1-tf1UIgqivFq1eqtxQMlAdUUDwac="
    },
    "create-mixin": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/create-mixin/-/create-mixin-3.0.0.tgz",
      "integrity": "sha512-LkdMqnWT9LaqBN4huqpUnMz56Yr1mVSoCduAd2xXefgH/YZP2sXCMAyztXjk4q8hTF/TlcDa+zQW2aTgGdjjKQ=="
    },
    "current-module-paths": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/current-module-paths/-/current-module-paths-1.1.1.tgz",
      "integrity": "sha512-8Ga5T8oMXBaSsHq9Gj+bddX7kHSaJKsl2vaAd3ep51eQLkr4W18eFEmEZM5bLo1zrz8tt3jE1U8QK9QGhaLR4g=="
    },
    "debug": {
      "version": "4.3.4",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.3.4.tgz",
      "integrity": "sha512-PRWFHuSU3eDtQJPvnNY7Jcket1j0t5OuOsFzPPzsekD52Zl8qUfFIPEiswXqIvHWGVHOgX+7G/vCNNhehwxfkQ==",
      "requires": {
        "ms": "2.1.2"
      },
      "dependencies": {
        "ms": {
          "version": "2.1.2",
          "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.2.tgz",
          "integrity": "sha512-sGkPx+VjMtmA6MX27oA4FBFELFCZZ4S4XqeGOXCv68tT+jb3vk/RyaKWP0PTKyWtmLSM0b+adUTEvbs1PEaH2w=="
        }
      }
    },
    "deep-equal": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/deep-equal/-/deep-equal-1.0.1.tgz",
      "integrity": "sha512-bHtC0iYvWhyaTzvV3CZgPeZQqCOBGyGsVV7v4eevpdkLHfiSrXUdBG+qAuSz4RI70sszvjQ1QSZ98An1yNwpSw=="
    },
    "deep-extend": {
      "version": "0.6.0",
      "resolved": "https://registry.npmjs.org/deep-extend/-/deep-extend-0.6.0.tgz",
      "integrity": "sha512-LOHxIOaPYdHlJRtCQfDIVZtfw/ufM8+rVj649RIHzcm/vGwQRXFt6OPqIFWsm2XEMrNIEtWR64sY1LEKD2vAOA=="
    },
    "define-data-property": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/define-data-property/-/define-data-property-1.1.1.tgz",
      "integrity": "sha512-E7uGkTzkk1d0ByLeSc6ZsFS79Axg+m1P/VsgYsxHgiuc3tFSj+MjMIwe90FC4lOAZzNBdY7kkO2P2wKdsQ1vgQ==",
      "requires": {
        "get-intrinsic": "^1.2.1",
        "gopd": "^1.0.1",
        "has-property-descriptors": "^1.0.0"
      }
    },
    "define-lazy-prop": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/define-lazy-prop/-/define-lazy-prop-2.0.0.tgz",
      "integrity": "sha512-Ds09qNh8yw3khSjiJjiUInaGX9xlqZDY7JVryGxdxV7NPeuqQfplOpQ66yJFZut3jLa5zOwkXw1g9EI2uKh4Og=="
    },
    "delegates": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/delegates/-/delegates-1.0.0.tgz",
      "integrity": "sha512-bd2L678uiWATM6m5Z1VzNCErI3jiGzt6HGY8OVICs40JQq/HALfbyNJmp0UDakEY4pMMaN0Ly5om/B1VI/+xfQ=="
    },
    "depd": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/depd/-/depd-2.0.0.tgz",
      "integrity": "sha512-g7nH6P6dyDioJogAAGprGpCtVImJhpPk/roCzdb3fIh61/s/nPsfR6onyMwkCAR/OlC3yBC0lESvUoQEAssIrw=="
    },
    "destroy": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/destroy/-/destroy-1.2.0.tgz",
      "integrity": "sha512-2sJGJTaXIIaR1w4iJSNoN0hnMY7Gpc/n8D4qSCJw8QqFWXf7cuAgnEHxBpweaVcPevC2l3KpjYCx3NypQQgaJg=="
    },
    "ee-first": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/ee-first/-/ee-first-1.1.1.tgz",
      "integrity": "sha1-WQxhFWsK4vTwJVcyoViyZrxWsh0="
    },
    "encodeurl": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/encodeurl/-/encodeurl-1.0.2.tgz",
      "integrity": "sha512-TPJXq8JqFaVYm2CWmPvnP2Iyo4ZSM7/QKcSmuMLDObfpH5fi7RUGmd/rTDf+rut/saiDiQEeVTNgAmJEdAOx0w=="
    },
    "escape-html": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/escape-html/-/escape-html-1.0.3.tgz",
      "integrity": "sha512-NiSupZ4OeuGwr68lGIeym/ksIZMJodUGOSCZ/FSnTxcrekbvqrgdUxlJOMpijaKZVjAJrWrGs/6Jy8OMuyj9ow=="
    },
    "escape-string-regexp": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-1.0.5.tgz",
      "integrity": "sha512-vbRorB5FUQWvla16U8R/qgaFIya2qGzwDrNmCZuYKrbdSUMG6I1ZCGQRefkRVhuOkIGVne7BQ35DSfo1qvJqFg=="
    },
    "etag": {
      "version": "1.8.1",
      "resolved": "https://registry.npmjs.org/etag/-/etag-1.8.1.tgz",
      "integrity": "sha1-Qa4u62XvpiJorr/qg6x9eSmbCIc="
    },
    "find-replace": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/find-replace/-/find-replace-3.0.0.tgz",
      "integrity": "sha512-6Tb2myMioCAgv5kfvP5/PkZZ/ntTpVK39fHY7WkWBgvbeE+VHd/tZuZ4mrC+bxh4cfOZeYKVPaJIZtZXV7GNCQ==",
      "requires": {
        "array-back": "^3.0.1"
      },
      "dependencies": {
        "array-back": {
          "version": "3.1.0",
          "resolved": "https://registry.npmjs.org/array-back/-/array-back-3.1.0.tgz",
          "integrity": "sha512-TkuxA4UCOvxuDK6NZYXCalszEzj+TLszyASooky+i742l9TqsOdYCMJJupxRic61hwquNtppB3hgcuq9SVSH1Q=="
        }
      }
    },
    "fresh": {
      "version": "0.5.2",
      "resolved": "https://registry.npmjs.org/fresh/-/fresh-0.5.2.tgz",
      "integrity": "sha512-zJ2mQYM18rEFOudeV4GShTGIQ7RbzA7ozbU9I/XBpm7kqgMywgmylMwXHxZJmkVoYkna9d2pVXVXPdYTP9ej8Q=="
    },
    "function-bind": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/function-bind/-/function-bind-1.1.2.tgz",
      "integrity": "sha512-7XHNxH7qX9xG5mIwxkhumTox/MIRNcOgDrxWsMt2pAr23WHp6MrRlN7FBSFpCpr+oVO0F744iUgR82nJMfG2SA=="
    },
    "get-intrinsic": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/get-intrinsic/-/get-intrinsic-1.2.2.tgz",
      "integrity": "sha512-0gSo4ml/0j98Y3lngkFEot/zhiCeWsbYIlZ+uZOVgzLyLaUw7wxUL+nCTP0XJvJg1AXulJRI3UJi8GsbDuxdGA==",
      "requires": {
        "function-bind": "^1.1.2",
        "has-proto": "^1.0.1",
        "has-symbols": "^1.0.3",
        "hasown": "^2.0.0"
      }
    },
    "gopd": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/gopd/-/gopd-1.0.1.tgz",
      "integrity": "sha512-d65bNlIadxvpb/A2abVdlqKqV563juRnZ1Wtk6s1sIR8uNsXR70xqIzVqxVf1eTqDunwT2MkczEeaezCKTZhwA==",
      "requires": {
        "get-intrinsic": "^1.1.3"
      }
    },
    "has-flag": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/has-flag/-/has-flag-3.0.0.tgz",
      "integrity": "sha512-sKJf1+ceQBr4SMkvQnBDNDtf4TXpVhVGateu0t918bl30FnbE2m4vNLX+VWe/dpjlb+HugGYzW7uQXH98HPEYw=="
    },
    "has-property-descriptors": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/has-property-descriptors/-/has-property-descriptors-1.0.1.tgz",
      "integrity": "sha512-VsX8eaIewvas0xnvinAe9bw4WfIeODpGYikiWYLH+dma0Jw6KHYqWiWfhQlgOVK8D6PvjubK5Uc4P0iIhIcNVg==",
      "requires": {
        "get-intrinsic": "^1.2.2"
      }
    },
    "has-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/has-proto/-/has-proto-1.0.1.tgz",
      "integrity": "sha512-7qE+iP+O+bgF9clE5+UoBFzE65mlBiVj3tKCrlNQ0Ogwm0BjpT/gK4SlLYDMybDh5I3TCTKnPPa0oMG7JDYrhg=="
    },
    "has-symbols": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/has-symbols/-/has-symbols-1.0.3.tgz",
      "integrity": "sha512-l3LCuF6MgDNwTDKkdYGEihYjt5pRPbEg46rtlmnSPlUbgmB8LOIrKJbYYFBSbnPaJexMKtiPO8hmeRjRz2Td+A=="
    },
    "has-tostringtag": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/has-tostringtag/-/has-tostringtag-1.0.0.tgz",
      "integrity": "sha512-kFjcSNhnlGV1kyoGk7OXKSawH5JOb/LzUc5w9B02hOTO0dfFRjbHQKvg1d6cf3HbeUmtU9VbbV3qzZ2Teh97WQ==",
      "requires": {
        "has-symbols": "^1.0.2"
      }
    },
    "hasown": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/hasown/-/hasown-2.0.0.tgz",
      "integrity": "sha512-vUptKVTpIJhcczKBbgnS+RtcuYMB8+oNzPK2/Hp3hanz8JmpATdmmgLgSaadVREkDm+e2giHwY3ZRkyjSIDDFA==",
      "requires": {
        "function-bind": "^1.1.2"
      }
    },
    "http-assert": {
      "version": "1.5.0",
      "resolved": "https://registry.npmjs.org/http-assert/-/http-assert-1.5.0.tgz",
      "integrity": "sha512-uPpH7OKX4H25hBmU6G1jWNaqJGpTXxey+YOUizJUAgu0AjLUeC8D73hTrhvDS5D+GJN1DN1+hhc/eF/wpxtp0w==",
      "requires": {
        "deep-equal": "~1.0.1",
        "http-errors": "~1.8.0"
      }
    },
    "http-errors": {
      "version": "1.8.1",
      "resolved": "https://registry.npmjs.org/http-errors/-/http-errors-1.8.1.tgz",
      "integrity": "sha512-Kpk9Sm7NmI+RHhnj6OIWDI1d6fIoFAtFt9RLaTMRlg/8w49juAStsrBgp0Dp4OdxdVbRIeKhtCUvoi/RuAhO4g==",
      "requires": {
        "depd": "~1.1.2",
        "inherits": "2.0.4",
        "setprototypeof": "1.2.0",
        "statuses": ">= 1.5.0 < 2",
        "toidentifier": "1.0.1"
      },
      "dependencies": {
        "depd": {
          "version": "1.1.2",
          "resolved": "https://registry.npmjs.org/depd/-/depd-1.1.2.tgz",
          "integrity": "sha512-7emPTl6Dpo6JRXOXjLRxck+FlLRX5847cLKEn00PLAgc3g2hTZZgr+e4c2v6QpSmLeFP3n5yUo7ft6avBK/5jQ=="
        }
      }
    },
    "http-proxy-agent": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/http-proxy-agent/-/http-proxy-agent-4.0.1.tgz",
      "integrity": "sha512-k0zdNgqWTGA6aeIRVpvfVob4fL52dTfaehylg0Y4UvSySvOq/Y+BOyPrgpUrA7HylqvU8vIZGsRuXmspskV0Tg==",
      "requires": {
        "@tootallnate/once": "1",
        "agent-base": "6",
        "debug": "4"
      }
    },
    "https-proxy-agent": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/https-proxy-agent/-/https-proxy-agent-5.0.0.tgz",
      "integrity": "sha512-EkYm5BcKUGiduxzSt3Eppko+PiNWNEpa4ySk9vTC6wDsQJW9rHSa+UhGNJoRYp7bz6Ht1eaRIa6QaJqO5rCFbA==",
      "requires": {
        "agent-base": "6",
        "debug": "4"
      }
    },
    "iconv-lite": {
      "version": "0.4.24",
      "resolved": "https://registry.npmjs.org/iconv-lite/-/iconv-lite-0.4.24.tgz",
      "integrity": "sha512-v3MXnZAcvnywkTUEZomIActle7RXXeedOR31wwl7VlyoXO4Qi9arvSenNQWne1TcRwhCL1HwLI21bEqdpj8/rA==",
      "requires": {
        "safer-buffer": ">= 2.1.2 < 3"
      }
    },
    "inflation": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/inflation/-/inflation-2.1.0.tgz",
      "integrity": "sha512-t54PPJHG1Pp7VQvxyVCJ9mBbjG3Hqryges9bXoOO6GExCPa+//i/d5GSuFtpx3ALLd7lgIAur6zrIlBQyJuMlQ=="
    },
    "inherits": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/inherits/-/inherits-2.0.4.tgz",
      "integrity": "sha512-k/vGaX4/Yla3WzyMCvTQOXYeIHvqOKtnqBduzTHpzpQZzAskKMhZ2K+EnBiSM9zGSoIFeMpXKxa4dYeZIQqewQ=="
    },
    "is-docker": {
      "version": "2.2.1",
      "resolved": "https://registry.npmjs.org/is-docker/-/is-docker-2.2.1.tgz",
      "integrity": "sha512-F+i2BKsFrH66iaUFc0woD8sLy8getkwTwtOBjvs56Cx4CgJDeKQeqfz8wAYiSb8JOprWhHH5p77PbmYCvvUuXQ=="
    },
    "is-generator-function": {
      "version": "1.0.10",
      "resolved": "https://registry.npmjs.org/is-generator-function/-/is-generator-function-1.0.10.tgz",
      "integrity": "sha512-jsEjy9l3yiXEQ+PsXdmBwEPcOxaXWLspKdplFUVI9vq1iZgIekeC0L167qeu86czQaxed3q/Uzuw0swL0irL8A==",
      "requires": {
        "has-tostringtag": "^1.0.0"
      }
    },
    "is-wsl": {
      "version": "2.2.0",
      "resolved": "https://registry.npmjs.org/is-wsl/-/is-wsl-2.2.0.tgz",
      "integrity": "sha512-fKzAra0rGJUUBwGBgNkHZuToZcn+TtXHpeCgmkMJMMYx1sQDYaCSyjJBSCa2nH1DGm7s3n1oBnohoVTBaN7Lww==",
      "requires": {
        "is-docker": "^2.0.0"
      }
    },
    "isarray": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/isarray/-/isarray-1.0.0.tgz",
      "integrity": "sha1-u5NdSFgsuhaMBoNJV6VKPgcSTxE="
    },
    "json-stringify-safe": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/json-stringify-safe/-/json-stringify-safe-5.0.1.tgz",
      "integrity": "sha1-Epai1Y/UXxmg9s4B1lcB4sc1tus="
    },
    "jsonparse": {
      "version": "1.3.1",
      "resolved": "https://registry.npmjs.org/jsonparse/-/jsonparse-1.3.1.tgz",
      "integrity": "sha1-P02uSpH6wxX3EGL4UhzCOfE2YoA="
    },
    "JSONStream": {
      "version": "1.3.5",
      "resolved": "https://registry.npmjs.org/JSONStream/-/JSONStream-1.3.5.tgz",
      "integrity": "sha512-E+iruNOY8VV9s4JEbe1aNEm6MiszPRr/UfcHMz0TQh1BXSxHK+ASV1R6W4HpjBhSeS+54PIsAMCBmwD06LLsqQ==",
      "requires": {
        "jsonparse": "^1.2.0",
        "through": ">=2.2.7 <3"
      }
    },
    "keygrip": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/keygrip/-/keygrip-1.1.0.tgz",
      "integrity": "sha512-iYSchDJ+liQ8iwbSI2QqsQOvqv58eJCEanyJPJi+Khyu8smkcKSFUCbPwzFcL7YVtZ6eONjqRX/38caJ7QjRAQ==",
      "requires": {
        "tsscmp": "1.0.6"
      }
    },
    "koa": {
      "version": "2.15.0",
      "resolved": "https://registry.npmjs.org/koa/-/koa-2.15.0.tgz",
      "integrity": "sha512-KEL/vU1knsoUvfP4MC4/GthpQrY/p6dzwaaGI6Rt4NQuFqkw3qrvsdYF5pz3wOfi7IGTvMPHC9aZIcUKYFNxsw==",
      "requires": {
        "accepts": "^1.3.5",
        "cache-content-type": "^1.0.0",
        "content-disposition": "~0.5.2",
        "content-type": "^1.0.4",
        "cookies": "~0.9.0",
        "debug": "^4.3.2",
        "delegates": "^1.0.0",
        "depd": "^2.0.0",
        "destroy": "^1.0.4",
        "encodeurl": "^1.0.2",
        "escape-html": "^1.0.3",
        "fresh": "~0.5.2",
        "http-assert": "^1.3.0",
        "http-errors": "^1.6.3",
        "is-generator-function": "^1.0.7",
        "koa-compose": "^4.1.0",
        "koa-convert": "^2.0.0",
        "on-finished": "^2.3.0",
        "only": "~0.0.2",
        "parseurl": "^1.3.2",
        "statuses": "^1.5.0",
        "type-is": "^1.6.16",
        "vary": "^1.1.2"
      }
    },
    "koa-bodyparser": {
      "version": "4.4.1",
      "resolved": "https://registry.npmjs.org/koa-bodyparser/-/koa-bodyparser-4.4.1.tgz",
      "integrity": "sha512-kBH3IYPMb+iAXnrxIhXnW+gXV8OTzCu8VPDqvcDHW9SQrbkHmqPQtiZwrltNmSq6/lpipHnT7k7PsjlVD7kK0w==",
      "requires": {
        "co-body": "^6.0.0",
        "copy-to": "^2.0.1",
        "type-is": "^1.6.18"
      }
    },
    "koa-compose": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/koa-compose/-/koa-compose-4.1.0.tgz",
      "integrity": "sha512-8ODW8TrDuMYvXRwra/Kh7/rJo9BtOfPc6qO8eAfC80CnCvSjSl0bkRM24X6/XBBEyj0v1nRUQ1LyOy3dbqOWXw=="
    },
    "koa-compress": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/koa-compress/-/koa-compress-5.1.1.tgz",
      "integrity": "sha512-UgMIN7ZoEP2DuoSQmD6CYvFSLt0NReGlc2qSY4bO4Oq0L56OiD9pDG41Kj/zFmVY/A3Wvmn4BqKcfq5H30LGIg==",
      "requires": {
        "bytes": "^3.1.2",
        "compressible": "^2.0.18",
        "http-errors": "^1.8.1",
        "koa-is-json": "^1.0.0"
      }
    },
    "koa-conditional-get": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/koa-conditional-get/-/koa-conditional-get-2.0.0.tgz",
      "integrity": "sha1-pD83I8HQFLcwo07Oit8wuTyCM/I="
    },
    "koa-convert": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/koa-convert/-/koa-convert-2.0.0.tgz",
      "integrity": "sha512-asOvN6bFlSnxewce2e/DK3p4tltyfC4VM7ZwuTuepI7dEQVcvpyFuBcEARu1+Hxg8DIwytce2n7jrZtRlPrARA==",
      "requires": {
        "co": "^4.6.0",
        "koa-compose": "^4.1.0"
      }
    },
    "koa-etag": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/koa-etag/-/koa-etag-3.0.0.tgz",
      "integrity": "sha1-nvc4Ld1agqsN6xU0FckVg293HT8=",
      "requires": {
        "etag": "^1.3.0",
        "mz": "^2.1.0"
      }
    },
    "koa-is-json": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/koa-is-json/-/koa-is-json-1.0.0.tgz",
      "integrity": "sha1-JzwH7c3Ljfaiwat9We52SRRR7BQ="
    },
    "koa-json": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/koa-json/-/koa-json-2.0.2.tgz",
      "integrity": "sha1-Nq8U5uofXWRtfESihXAcb4Wk/eQ=",
      "requires": {
        "koa-is-json": "1",
        "streaming-json-stringify": "3"
      }
    },
    "koa-morgan": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/koa-morgan/-/koa-morgan-1.0.1.tgz",
      "integrity": "sha1-CAUuDODYOdPEMXi5CluzQkvvH5k=",
      "requires": {
        "morgan": "^1.6.1"
      }
    },
    "koa-range": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/koa-range/-/koa-range-0.3.0.tgz",
      "integrity": "sha512-Ich3pCz6RhtbajYXRWjIl6O5wtrLs6kE3nkXc9XmaWe+MysJyZO7K4L3oce1Jpg/iMgCbj+5UCiMm/rqVtcDIg==",
      "requires": {
        "stream-slice": "^0.1.2"
      }
    },
    "koa-route": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/koa-route/-/koa-route-3.2.0.tgz",
      "integrity": "sha1-dimLmaa8+p44yrb+XHmocz51i84=",
      "requires": {
        "debug": "*",
        "methods": "~1.1.0",
        "path-to-regexp": "^1.2.0"
      },
      "dependencies": {
        "isarray": {
          "version": "0.0.1",
          "resolved": "https://registry.npmjs.org/isarray/-/isarray-0.0.1.tgz",
          "integrity": "sha1-ihis/Kmo9Bd+Cav8YDiTmwXR7t8="
        },
        "path-to-regexp": {
          "version": "1.8.0",
          "resolved": "https://registry.npmjs.org/path-to-regexp/-/path-to-regexp-1.8.0.tgz",
          "integrity": "sha512-n43JRhlUKUAlibEJhPeir1ncUID16QnEjNpwzNdO3Lm4ywrBpBZ5oLD0I6br9evr1Y9JTqwRtAh7JLoOzAQdVA==",
          "requires": {
            "isarray": "0.0.1"
          }
        }
      }
    },
    "koa-send": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/koa-send/-/koa-send-5.0.1.tgz",
      "integrity": "sha512-tmcyQ/wXXuxpDxyNXv5yNNkdAMdFRqwtegBXUaowiQzUKqJehttS0x2j0eOZDQAyloAth5w6wwBImnFzkUz3pQ==",
      "requires": {
        "debug": "^4.1.1",
        "http-errors": "^1.7.3",
        "resolve-path": "^1.4.0"
      }
    },
    "koa-static": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/koa-static/-/koa-static-5.0.0.tgz",
      "integrity": "sha512-UqyYyH5YEXaJrf9S8E23GoJFQZXkBVJ9zYYMPGz919MSX1KuvAcycIuS0ci150HCoPf4XQVhQ84Qf8xRPWxFaQ==",
      "requires": {
        "debug": "^3.1.0",
        "koa-send": "^5.0.0"
      },
      "dependencies": {
        "debug": {
          "version": "3.2.7",
          "resolved": "https://registry.npmjs.org/debug/-/debug-3.2.7.tgz",
          "integrity": "sha512-CFjzYYAi4ThfiQvizrFQevTTXHtnCqWfe7x1AhgEscTz6ZbLbfoLRLPugTQyBth6f8ZERVUSyWHFD/7Wu4t1XQ==",
          "requires": {
            "ms": "^2.1.1"
          }
        },
        "ms": {
          "version": "2.1.3",
          "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
          "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA=="
        }
      }
    },
    "load-module": {
      "version": "4.2.1",
      "resolved": "https://registry.npmjs.org/load-module/-/load-module-4.2.1.tgz",
      "integrity": "sha512-Sbfg6R4LjvyThJpqUoADHMjyoI2+cL4msbCQeZ9kkY/CqP/TT2938eftKm7x4I2gd4/A+DEe6nePkbfWYbXwSw==",
      "requires": {
        "array-back": "^6.2.0"
      },
      "dependencies": {
        "array-back": {
          "version": "6.2.2",
          "resolved": "https://registry.npmjs.org/array-back/-/array-back-6.2.2.tgz",
          "integrity": "sha512-gUAZ7HPyb4SJczXAMUXMGAvI976JoK3qEx9v1FTmeYuJj0IBiaKttG1ydtGKdkfqWkIkouke7nG8ufGy77+Cvw=="
        }
      }
    },
    "local-web-server": {
      "version": "5.3.1",
      "resolved": "https://registry.npmjs.org/local-web-server/-/local-web-server-5.3.1.tgz",
      "integrity": "sha512-SYMIyQsyIGSlhZ+px0NgMumIzK69KCifweF24FApdNcRzMs/+ENlvesiGamBzEO6njljOvCbBuNQK/7hWMoCCA==",
      "requires": {
        "current-module-paths": "^1.1.1",
        "lws": "^4.1.2",
        "lws-basic-auth": "^2.0.0",
        "lws-blacklist": "^3.0.0",
        "lws-body-parser": "^3.0.0",
        "lws-compress": "^3.1.0",
        "lws-conditional-get": "^2.0.0",
        "lws-cors": "^4.2.1",
        "lws-index": "^3.1.1",
        "lws-json": "^2.0.0",
        "lws-log": "^2.0.0",
        "lws-mime": "^2.0.0",
        "lws-range": "^4.0.1",
        "lws-request-monitor": "^2.0.0",
        "lws-rewrite": "^3.1.1",
        "lws-spa": "^4.1.0",
        "lws-static": "^3.1.0"
      }
    },
    "lodash.assignwith": {
      "version": "4.2.0",
      "resolved": "https://registry.npmjs.org/lodash.assignwith/-/lodash.assignwith-4.2.0.tgz",
      "integrity": "sha512-ZznplvbvtjK2gMvnQ1BR/zqPFZmS6jbK4p+6Up4xcRYA7yMIwxHCfbTcrYxXKzzqLsQ05eJPVznEW3tuwV7k1g=="
    },
    "lodash.camelcase": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/lodash.camelcase/-/lodash.camelcase-4.3.0.tgz",
      "integrity": "sha512-TwuEnCnxbc3rAvhf/LbG7tJUDzhqXyFnv3dtzLOPgCG/hODL7WFnsbwktkD7yUV0RrreP/l1PALq/YSg6VvjlA=="
    },
    "lodash.throttle": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/lodash.throttle/-/lodash.throttle-4.1.1.tgz",
      "integrity": "sha1-wj6RtxAkKscMN/HhzaknTMOb8vQ="
    },
    "lws": {
      "version": "4.1.2",
      "resolved": "https://registry.npmjs.org/lws/-/lws-4.1.2.tgz",
      "integrity": "sha512-hm6mlYa5ZM+iLbFIEiifGnXJWbNRQL80DZ5gXfkdgBJSMIvjnVyVIPpw1fCU/IMcgHBvn1iCrFc391FP12NguQ==",
      "requires": {
        "@75lb/deep-merge": "^1.1.1",
        "ansi-escape-sequences": "^6.2.1",
        "array-back": "^6.2.2",
        "byte-size": "^8.1.0",
        "command-line-args": "^5.2.1",
        "command-line-usage": "^6.1.3",
        "create-mixin": "^3.0.0",
        "current-module-paths": "^1.1.0",
        "koa": "^2.13.4",
        "load-module": "^4.2.1",
        "open": "^8.4.0",
        "qrcode-terminal": "^0.12.0",
        "typical": "^7.1.1",
        "walk-back": "^5.1.0"
      },
      "dependencies": {
        "ansi-escape-sequences": {
          "version": "6.2.2",
          "resolved": "https://registry.npmjs.org/ansi-escape-sequences/-/ansi-escape-sequences-6.2.2.tgz",
          "integrity": "sha512-mBPG9BZy4dMOJQ9BehU6ph8IKslvVppbqZ8APHnpfP+Hsx/hGow5PY46lSQL1vPPi1F5XTtO6p3GcH8O9c0cUg==",
          "requires": {
            "array-back": "^6.2.2"
          }
        },
        "array-back": {
          "version": "6.2.2",
          "resolved": "https://registry.npmjs.org/array-back/-/array-back-6.2.2.tgz",
          "integrity": "sha512-gUAZ7HPyb4SJczXAMUXMGAvI976JoK3qEx9v1FTmeYuJj0IBiaKttG1ydtGKdkfqWkIkouke7nG8ufGy77+Cvw=="
        },
        "byte-size": {
          "version": "8.1.1",
          "resolved": "https://registry.npmjs.org/byte-size/-/byte-size-8.1.1.tgz",
          "integrity": "sha512-tUkzZWK0M/qdoLEqikxBWe4kumyuwjl3HO6zHTr4yEI23EojPtLYXdG1+AQY7MN0cGyNDvEaJ8wiYQm6P2bPxg=="
        }
      }
    },
    "lws-basic-auth": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/lws-basic-auth/-/lws-basic-auth-2.0.0.tgz",
      "integrity": "sha512-zzyoGFLQPuKaQJvHMLmmSyfT6lIvocwcDXllTVW5brD0t0YgHYopILkzja+x+MIlJX/YhNKniaTSasujniYVjw==",
      "requires": {
        "basic-auth": "^2.0.1"
      }
    },
    "lws-blacklist": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/lws-blacklist/-/lws-blacklist-3.0.0.tgz",
      "integrity": "sha512-KNXGDBmbj+UGfWMBAefe2vrfuWpEQms/9Fd7kfMScTqAKF6nrVoEs4pkxfefArG3bX0bu7jWLyB4tJGma5WC6Q==",
      "requires": {
        "array-back": "^4.0.1",
        "path-to-regexp": "^6.1.0"
      }
    },
    "lws-body-parser": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/lws-body-parser/-/lws-body-parser-3.0.0.tgz",
      "integrity": "sha512-led36Um61ppeQoMTG7yvphn+NQPMbzuFuGUYD09eEx1UT7e8bsaLw1gkBZB9vAIkeTlXRbXjPmOqlm26eUzhfg==",
      "requires": {
        "koa-bodyparser": "^4.3.0"
      }
    },
    "lws-compress": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/lws-compress/-/lws-compress-3.1.0.tgz",
      "integrity": "sha512-uBlpYFNBUD3FuQjXbtwasvD90w3HH6GRivknvbibSSsDQf1MtIM8WZ5fS4795n1ozTYnQD+Ai8T+Cpy0q0xuhA==",
      "requires": {
        "koa-compress": "^5.0.1"
      }
    },
    "lws-conditional-get": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/lws-conditional-get/-/lws-conditional-get-2.0.0.tgz",
      "integrity": "sha512-U05yDlFJKIYa7gJZYfnc1HIEuXbKpDJztgkvNYyxCqJC28j/k9ORoNnFNOIHpBh/jlPJgV8x7uH34mIxFAryWA==",
      "requires": {
        "koa-conditional-get": "^2.0.0",
        "koa-etag": "^3.0.0"
      }
    },
    "lws-cors": {
      "version": "4.2.1",
      "resolved": "https://registry.npmjs.org/lws-cors/-/lws-cors-4.2.1.tgz",
      "integrity": "sha512-KXsAn0Wn8n0riJ3SDHQzEAuzTrdeQZDJIxPHWEupsImW2hnQuBZVW5zqsmfzxD8SkCDDnQyFNuQZjSlBZmexKg==",
      "requires": {
        "@koa/cors": "^5.0.0"
      }
    },
    "lws-index": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/lws-index/-/lws-index-3.1.1.tgz",
      "integrity": "sha512-f1rjsCkrKHVbSe03lm6xQ1GNnqzq/tL5f0ge8kXJFRorpS8Sv7WDXzUsGswmGAgxPPvDj8L7E6zwD+BCjQRU8w==",
      "requires": {
        "serve-index-75lb": "^2.0.1"
      }
    },
    "lws-json": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/lws-json/-/lws-json-2.0.0.tgz",
      "integrity": "sha512-vqUFrAQ5BGpkMS2Mm/ZhgvUMi6Tgia7YtESG7pKjNoiSsD+TxncG0nqp8YjUh2xrEzi/SYFc/ed+9ZOl/t0A0g==",
      "requires": {
        "koa-json": "^2.0.2"
      }
    },
    "lws-log": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/lws-log/-/lws-log-2.0.0.tgz",
      "integrity": "sha512-YveoazSZ0Qb1Tljdm8G8yn9c+mAMXgvLMACZzh5aZIk7p8YJwiXf9r1S+xY7wbXEcKG629KfVO0B5G5gRFcyDQ==",
      "requires": {
        "koa-morgan": "^1.0.1",
        "stream-log-stats": "^3.0.2"
      }
    },
    "lws-mime": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/lws-mime/-/lws-mime-2.0.0.tgz",
      "integrity": "sha512-mfrAgRQ5+hkQ7LJ6EAgwnUeymNeYxwLXZY3UQ6C2hSTr7BqMSzm9k5O0C8wWP2dzdhChzITYKwzWbUnAYVBwtA=="
    },
    "lws-range": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/lws-range/-/lws-range-4.0.1.tgz",
      "integrity": "sha512-rUkHpsRv5Ixr+8/E4cDCz6jUi6En6hnEaDZhPb0a1GU1vasOHhGcW0qilkgf0dtS0xDJzdKixdfcCW40ankIeQ==",
      "requires": {
        "koa-range": "^0.3.0"
      }
    },
    "lws-request-monitor": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/lws-request-monitor/-/lws-request-monitor-2.0.0.tgz",
      "integrity": "sha512-ZTo0/pS42qiejcYlL+wlpurSbDSS0J7pDDohqBx7jjUQkgni2Qd8cPzn/kW8QI82gXgDmdZH+ps0vheLHlgdgg==",
      "requires": {
        "byte-size": "^6.2.0"
      }
    },
    "lws-rewrite": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/lws-rewrite/-/lws-rewrite-3.1.1.tgz",
      "integrity": "sha512-cOeaPXIlLUVLxS6BZ52QzZVzI8JjCzlWD4RWizB5Hd+0YGO0SPa3Vgk7CIghtAOsSdjtXg/wSOap2H1h+tw8BQ==",
      "requires": {
        "array-back": "^4.0.1",
        "http-proxy-agent": "^4.0.1",
        "https-proxy-agent": "^5.0.0",
        "koa-route": "^3.2.0",
        "path-to-regexp": "^6.1.0"
      }
    },
    "lws-spa": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/lws-spa/-/lws-spa-4.1.0.tgz",
      "integrity": "sha512-B1YhxAY02EYu7J9dKBQMpYRwOd4iOtKK3TDdUR2GnJ4nsnvoxsJnMUpg8yxGmWZ6NI8itdUdQJlwqKg/Gji/vQ==",
      "requires": {
        "koa-send": "^5.0.1"
      }
    },
    "lws-static": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/lws-static/-/lws-static-3.1.0.tgz",
      "integrity": "sha512-0fWZRluPda0raMEzTd2mY/REWsa5LxDz03j+Zer8yhFfbicJGaocTK1jOlRo/H5UEDImBdfSDZGlrmzMaF9Xcg==",
      "requires": {
        "koa-static": "^5.0.0"
      }
    },
    "media-typer": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/media-typer/-/media-typer-0.3.0.tgz",
      "integrity": "sha512-dq+qelQ9akHpcOl/gUVRTxVIOkAJ1wR3QAvb4RsVjS8oVoFjDGTc679wJYmUmknUF5HwMLOgb5O+a3KxfWapPQ=="
    },
    "methods": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/methods/-/methods-1.1.2.tgz",
      "integrity": "sha1-VSmk1nZUE07cxSZmVoNbD4Ua/O4="
    },
    "mime-db": {
      "version": "1.52.0",
      "resolved": "https://registry.npmjs.org/mime-db/-/mime-db-1.52.0.tgz",
      "integrity": "sha512-sPU4uV7dYlvtWJxwwxHD0PuihVNiE7TyAbQ5SWxDCB9mUYvOgroQOwYQQOKPJ8CIbE+1ETVlOoK1UC2nU3gYvg=="
    },
    "mime-types": {
      "version": "2.1.35",
      "resolved": "https://registry.npmjs.org/mime-types/-/mime-types-2.1.35.tgz",
      "integrity": "sha512-ZDY+bPm5zTTF+YpCrAU9nK0UgICYPT0QtT1NZWFv4s++TNkcgVaT0g6+4R2uI4MjQjzysHB1zxuWL50hzaeXiw==",
      "requires": {
        "mime-db": "1.52.0"
      }
    },
    "morgan": {
      "version": "1.10.0",
      "resolved": "https://registry.npmjs.org/morgan/-/morgan-1.10.0.tgz",
      "integrity": "sha512-AbegBVI4sh6El+1gNwvD5YIck7nSA36weD7xvIxG4in80j/UoK8AEGaWnnz8v1GxonMCltmlNs5ZKbGvl9b1XQ==",
      "requires": {
        "basic-auth": "~2.0.1",
        "debug": "2.6.9",
        "depd": "~2.0.0",
        "on-finished": "~2.3.0",
        "on-headers": "~1.0.2"
      },
      "dependencies": {
        "debug": {
          "version": "2.6.9",
          "resolved": "https://registry.npmjs.org/debug/-/debug-2.6.9.tgz",
          "integrity": "sha512-bC7ElrdJaJnPbAP+1EotYvqZsb3ecl5wi6Bfi6BJTUcNowp6cvspg0jXznRTKDjm/E7AdgFBVeAPVMNcKGsHMA==",
          "requires": {
            "ms": "2.0.0"
          }
        }
      }
    },
    "ms": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.0.0.tgz",
      "integrity": "sha1-VgiurfwAvmwpAd9fmGF4jeDVl8g="
    },
    "mz": {
      "version": "2.7.0",
      "resolved": "https://registry.npmjs.org/mz/-/mz-2.7.0.tgz",
      "integrity": "sha512-z81GNO7nnYMEhrGh9LeymoE4+Yr0Wn5McHIZMK5cfQCl+NDX08sCZgUc9/6MHni9IWuFLm1Z3HTCXu2z9fN62Q==",
      "requires": {
        "any-promise": "^1.0.0",
        "object-assign": "^4.0.1",
        "thenify-all": "^1.0.0"
      }
    },
    "negotiator": {
      "version": "0.6.3",
      "resolved": "https://registry.npmjs.org/negotiator/-/negotiator-0.6.3.tgz",
      "integrity": "sha512-+EUsqGPLsM+j/zdChZjsnX51g4XrHFOIXwfnCVPGlQk/k5giakcKsuxCObBRu6DSm9opw/O6slWbJdghQM4bBg=="
    },
    "object-assign": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/object-assign/-/object-assign-4.1.1.tgz",
      "integrity": "sha1-IQmtx5ZYh8/AXLvUQsrIv7s2CGM="
    },
    "object-inspect": {
      "version": "1.13.1",
      "resolved": "https://registry.npmjs.org/object-inspect/-/object-inspect-1.13.1.tgz",
      "integrity": "sha512-5qoj1RUiKOMsCCNLV1CBiPYE10sziTsnmNxkAI/rZhiD63CF7IqdFGC/XzjWjpSgLf0LxXX3bDFIh0E18f6UhQ=="
    },
    "on-finished": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/on-finished/-/on-finished-2.3.0.tgz",
      "integrity": "sha1-IPEzZIGwg811M3mSoWlxqi2QaUc=",
      "requires": {
        "ee-first": "1.1.1"
      }
    },
    "on-headers": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/on-headers/-/on-headers-1.0.2.tgz",
      "integrity": "sha512-pZAE+FJLoyITytdqK0U5s+FIpjN0JP3OzFi/u8Rx+EV5/W+JTWGXG8xFzevE7AjBfDqHv/8vL8qQsIhHnqRkrA=="
    },
    "only": {
      "version": "0.0.2",
      "resolved": "https://registry.npmjs.org/only/-/only-0.0.2.tgz",
      "integrity": "sha512-Fvw+Jemq5fjjyWz6CpKx6w9s7xxqo3+JCyM0WXWeCSOboZ8ABkyvP8ID4CZuChA/wxSx+XSJmdOm8rGVyJ1hdQ=="
    },
    "open": {
      "version": "8.4.2",
      "resolved": "https://registry.npmjs.org/open/-/open-8.4.2.tgz",
      "integrity": "sha512-7x81NCL719oNbsq/3mh+hVrAWmFuEYUqrq/Iw3kUzH8ReypT9QQ0BLoJS7/G9k6N81XjW4qHWtjWwe/9eLy1EQ==",
      "requires": {
        "define-lazy-prop": "^2.0.0",
        "is-docker": "^2.1.1",
        "is-wsl": "^2.2.0"
      }
    },
    "parseurl": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/parseurl/-/parseurl-1.3.3.tgz",
      "integrity": "sha512-CiyeOxFT/JZyN5m0z9PfXw4SCBJ6Sygz1Dpl0wqjlhDEGGBP1GnsUVEL0p63hoG1fcj3fHynXi9NYO4nWOL+qQ=="
    },
    "path-is-absolute": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/path-is-absolute/-/path-is-absolute-1.0.1.tgz",
      "integrity": "sha512-AVbw3UJ2e9bq64vSaS9Am0fje1Pa8pbGqTTsmXfaIiMpnr5DlDhfJOuLj9Sf95ZPVDAUerDfEk88MPmPe7UCQg=="
    },
    "path-to-regexp": {
      "version": "6.2.0",
      "resolved": "https://registry.npmjs.org/path-to-regexp/-/path-to-regexp-6.2.0.tgz",
      "integrity": "sha512-f66KywYG6+43afgE/8j/GoiNyygk/bnoCbps++3ErRKsIYkGGupyv07R2Ok5m9i67Iqc+T2g1eAUGUPzWhYTyg=="
    },
    "process-nextick-args": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/process-nextick-args/-/process-nextick-args-2.0.1.tgz",
      "integrity": "sha512-3ouUOpQhtgrbOa17J7+uxOTpITYWaGP7/AhoR3+A+/1e9skrzelGi/dXzEYyvbxubEF6Wn2ypscTKiKJFFn1ag=="
    },
    "qrcode-terminal": {
      "version": "0.12.0",
      "resolved": "https://registry.npmjs.org/qrcode-terminal/-/qrcode-terminal-0.12.0.tgz",
      "integrity": "sha512-EXtzRZmC+YGmGlDFbXKxQiMZNwCLEO6BANKXG4iCtSIM0yqc/pappSx3RIKr4r0uh5JsBckOXeKrB3Iz7mdQpQ=="
    },
    "qs": {
      "version": "6.11.2",
      "resolved": "https://registry.npmjs.org/qs/-/qs-6.11.2.tgz",
      "integrity": "sha512-tDNIz22aBzCDxLtVH++VnTfzxlfeK5CbqohpSqpJgj1Wg/cQbStNAz3NuqCs5vV+pjBsK4x4pN9HlVh7rcYRiA==",
      "requires": {
        "side-channel": "^1.0.4"
      }
    },
    "raw-body": {
      "version": "2.5.2",
      "resolved": "https://registry.npmjs.org/raw-body/-/raw-body-2.5.2.tgz",
      "integrity": "sha512-8zGqypfENjCIqGhgXToC8aB2r7YrBX+AQAfIPs/Mlk+BtPTztOvTS01NRW/3Eh60J+a48lt8qsCzirQ6loCVfA==",
      "requires": {
        "bytes": "3.1.2",
        "http-errors": "2.0.0",
        "iconv-lite": "0.4.24",
        "unpipe": "1.0.0"
      },
      "dependencies": {
        "http-errors": {
          "version": "2.0.0",
          "resolved": "https://registry.npmjs.org/http-errors/-/http-errors-2.0.0.tgz",
          "integrity": "sha512-FtwrG/euBzaEjYeRqOgly7G0qviiXoJWnvEH2Z1plBdXgbyjv34pHTSb9zoeHMyDy33+DWy5Wt9Wo+TURtOYSQ==",
          "requires": {
            "depd": "2.0.0",
            "inherits": "2.0.4",
            "setprototypeof": "1.2.0",
            "statuses": "2.0.1",
            "toidentifier": "1.0.1"
          }
        },
        "statuses": {
          "version": "2.0.1",
          "resolved": "https://registry.npmjs.org/statuses/-/statuses-2.0.1.tgz",
          "integrity": "sha512-RwNA9Z/7PrK06rYLIzFMlaF+l73iwpzsqRIFgbMLbTcLD6cOao82TaWefPXQvB2fOC4AjuYSEndS7N/mTCbkdQ=="
        }
      }
    },
    "readable-stream": {
      "version": "2.3.7",
      "resolved": "https://registry.npmjs.org/readable-stream/-/readable-stream-2.3.7.tgz",
      "integrity": "sha512-Ebho8K4jIbHAxnuxi7o42OrZgF/ZTNcsZj6nRKyUmkhLFq8CHItp/fy6hQZuZmP/n3yZ9VBUbp4zz/mX8hmYPw==",
      "requires": {
        "core-util-is": "~1.0.0",
        "inherits": "~2.0.3",
        "isarray": "~1.0.0",
        "process-nextick-args": "~2.0.0",
        "safe-buffer": "~5.1.1",
        "string_decoder": "~1.1.1",
        "util-deprecate": "~1.0.1"
      }
    },
    "resolve-path": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/resolve-path/-/resolve-path-1.4.0.tgz",
      "integrity": "sha512-i1xevIst/Qa+nA9olDxLWnLk8YZbi8R/7JPbCMcgyWaFR6bKWaexgJgEB5oc2PKMjYdrHynyz0NY+if+H98t1w==",
      "requires": {
        "http-errors": "~1.6.2",
        "path-is-absolute": "1.0.1"
      },
      "dependencies": {
        "depd": {
          "version": "1.1.2",
          "resolved": "https://registry.npmjs.org/depd/-/depd-1.1.2.tgz",
          "integrity": "sha512-7emPTl6Dpo6JRXOXjLRxck+FlLRX5847cLKEn00PLAgc3g2hTZZgr+e4c2v6QpSmLeFP3n5yUo7ft6avBK/5jQ=="
        },
        "http-errors": {
          "version": "1.6.3",
          "resolved": "https://registry.npmjs.org/http-errors/-/http-errors-1.6.3.tgz",
          "integrity": "sha512-lks+lVC8dgGyh97jxvxeYTWQFvh4uw4yC12gVl63Cg30sjPX4wuGcdkICVXDAESr6OJGjqGA8Iz5mkeN6zlD7A==",
          "requires": {
            "depd": "~1.1.2",
            "inherits": "2.0.3",
            "setprototypeof": "1.1.0",
            "statuses": ">= 1.4.0 < 2"
          }
        },
        "inherits": {
          "version": "2.0.3",
          "resolved": "https://registry.npmjs.org/inherits/-/inherits-2.0.3.tgz",
          "integrity": "sha512-x00IRNXNy63jwGkJmzPigoySHbaqpNuzKbBOmzK+g2OdZpQ9w+sxCN+VSB3ja7IAge2OP2qpfxTjeNcyjmW1uw=="
        },
        "setprototypeof": {
          "version": "1.1.0",
          "resolved": "https://registry.npmjs.org/setprototypeof/-/setprototypeof-1.1.0.tgz",
          "integrity": "sha512-BvE/TwpZX4FXExxOxZyRGQQv651MSwmWKZGqvmPcRIjDqWub67kTKuIMx43cZZrS/cBBzwBcNDWoFxt2XEFIpQ=="
        }
      }
    },
    "safe-buffer": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/safe-buffer/-/safe-buffer-5.1.2.tgz",
      "integrity": "sha512-Gd2UZBJDkXlY7GbJxfsE8/nvKkUEU1G38c1siN6QP6a9PT9MmHB8GnpscSmMJSoF8LOIrt8ud/wPtojys4G6+g=="
    },
    "safer-buffer": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/safer-buffer/-/safer-buffer-2.1.2.tgz",
      "integrity": "sha512-YZo3K82SD7Riyi0E1EQPojLz7kpepnSQI9IyPbHHg1XXXevb5dJI7tpyN2ADxGcQbHG7vcyRHk0cbwqcQriUtg=="
    },
    "serve-index-75lb": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/serve-index-75lb/-/serve-index-75lb-2.0.1.tgz",
      "integrity": "sha512-/d9r8bqJlFQcwy0a0nb1KnWAA+Mno+V+VaoKocdkbW5aXKRQd/+4bfnRhQRQr6uEoYwTRJ4xgztOyCJvWcpBpQ==",
      "requires": {
        "accepts": "~1.3.4",
        "batch": "0.6.1",
        "debug": "2.6.9",
        "escape-html": "~1.0.3",
        "http-errors": "~1.6.2",
        "mime-types": "~2.1.18",
        "parseurl": "~1.3.2"
      },
      "dependencies": {
        "debug": {
          "version": "2.6.9",
          "resolved": "https://registry.npmjs.org/debug/-/debug-2.6.9.tgz",
          "integrity": "sha512-bC7ElrdJaJnPbAP+1EotYvqZsb3ecl5wi6Bfi6BJTUcNowp6cvspg0jXznRTKDjm/E7AdgFBVeAPVMNcKGsHMA==",
          "requires": {
            "ms": "2.0.0"
          }
        },
        "depd": {
          "version": "1.1.2",
          "resolved": "https://registry.npmjs.org/depd/-/depd-1.1.2.tgz",
          "integrity": "sha512-7emPTl6Dpo6JRXOXjLRxck+FlLRX5847cLKEn00PLAgc3g2hTZZgr+e4c2v6QpSmLeFP3n5yUo7ft6avBK/5jQ=="
        },
        "http-errors": {
          "version": "1.6.3",
          "resolved": "https://registry.npmjs.org/http-errors/-/http-errors-1.6.3.tgz",
          "integrity": "sha512-lks+lVC8dgGyh97jxvxeYTWQFvh4uw4yC12gVl63Cg30sjPX4wuGcdkICVXDAESr6OJGjqGA8Iz5mkeN6zlD7A==",
          "requires": {
            "depd": "~1.1.2",
            "inherits": "2.0.3",
            "setprototypeof": "1.1.0",
            "statuses": ">= 1.4.0 < 2"
          }
        },
        "inherits": {
          "version": "2.0.3",
          "resolved": "https://registry.npmjs.org/inherits/-/inherits-2.0.3.tgz",
          "integrity": "sha512-x00IRNXNy63jwGkJmzPigoySHbaqpNuzKbBOmzK+g2OdZpQ9w+sxCN+VSB3ja7IAge2OP2qpfxTjeNcyjmW1uw=="
        },
        "setprototypeof": {
          "version": "1.1.0",
          "resolved": "https://registry.npmjs.org/setprototypeof/-/setprototypeof-1.1.0.tgz",
          "integrity": "sha512-BvE/TwpZX4FXExxOxZyRGQQv651MSwmWKZGqvmPcRIjDqWub67kTKuIMx43cZZrS/cBBzwBcNDWoFxt2XEFIpQ=="
        }
      }
    },
    "set-function-length": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/set-function-length/-/set-function-length-1.1.1.tgz",
      "integrity": "sha512-VoaqjbBJKiWtg4yRcKBQ7g7wnGnLV3M8oLvVWwOk2PdYY6PEFegR1vezXR0tw6fZGF9csVakIRjrJiy2veSBFQ==",
      "requires": {
        "define-data-property": "^1.1.1",
        "get-intrinsic": "^1.2.1",
        "gopd": "^1.0.1",
        "has-property-descriptors": "^1.0.0"
      }
    },
    "setprototypeof": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/setprototypeof/-/setprototypeof-1.2.0.tgz",
      "integrity": "sha512-E5LDX7Wrp85Kil5bhZv46j8jOeboKq5JMmYM3gVGdGH8xFpPWXUMsNrlODCrkoxMEeNi/XZIwuRvY4XNwYMJpw=="
    },
    "side-channel": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/side-channel/-/side-channel-1.0.4.tgz",
      "integrity": "sha512-q5XPytqFEIKHkGdiMIrY10mvLRvnQh42/+GoBlFW3b2LXLE2xxJpZFdm94we0BaoV3RwJyGqg5wS7epxTv0Zvw==",
      "requires": {
        "call-bind": "^1.0.0",
        "get-intrinsic": "^1.0.2",
        "object-inspect": "^1.9.0"
      }
    },
    "statuses": {
      "version": "1.5.0",
      "resolved": "https://registry.npmjs.org/statuses/-/statuses-1.5.0.tgz",
      "integrity": "sha512-OpZ3zP+jT1PI7I8nemJX4AKmAX070ZkYPVWV/AaKTJl+tXCTGyVdC1a4SL8RUQYEwk/f34ZX8UTykN68FwrqAA=="
    },
    "stream-log-stats": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/stream-log-stats/-/stream-log-stats-3.0.2.tgz",
      "integrity": "sha512-393j7aeF9iRdHvyANqEQU82UQmpw2CTxgsT83caefh+lOxavVLbVrw8Mr4zjXeZLh2+xeHZMKfVx4T0rJ/EchA==",
      "requires": {
        "ansi-escape-sequences": "^5.1.2",
        "byte-size": "^6.2.0",
        "common-log-format": "^1.0.0",
        "JSONStream": "^1.3.5",
        "lodash.throttle": "^4.1.1",
        "stream-via": "^1.0.4",
        "table-layout": "~1.0.0"
      }
    },
    "stream-slice": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/stream-slice/-/stream-slice-0.1.2.tgz",
      "integrity": "sha512-QzQxpoacatkreL6jsxnVb7X5R/pGw9OUv2qWTYWnmLpg4NdN31snPy/f3TdQE1ZUXaThRvj1Zw4/OGg0ZkaLMA=="
    },
    "stream-via": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/stream-via/-/stream-via-1.0.4.tgz",
      "integrity": "sha512-DBp0lSvX5G9KGRDTkR/R+a29H+Wk2xItOF+MpZLLNDWbEV9tGPnqLPxHEYjmiz8xGtJHRIqmI+hCjmNzqoA4nQ=="
    },
    "streaming-json-stringify": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/streaming-json-stringify/-/streaming-json-stringify-3.1.0.tgz",
      "integrity": "sha1-gCAEN6mTzDnE/gAmO3s7kDrIevU=",
      "requires": {
        "json-stringify-safe": "5",
        "readable-stream": "2"
      }
    },
    "string_decoder": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-1.1.1.tgz",
      "integrity": "sha512-n/ShnvDi6FHbbVfviro+WojiFzv+s8MPMHBczVePfUpDJLwoLT0ht1l4YwBCbi8pJAveEEdnkHyPyTP/mzRfwg==",
      "requires": {
        "safe-buffer": "~5.1.0"
      }
    },
    "supports-color": {
      "version": "5.5.0",
      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-5.5.0.tgz",
      "integrity": "sha512-QjVjwdXIt408MIiAqCX4oUKsgU2EqAGzs2Ppkm4aQYbjm+ZEWEcW4SfFNTr4uMNZma0ey4f5lgLrkB0aX0QMow==",
      "requires": {
        "has-flag": "^3.0.0"
      }
    },
    "table-layout": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/table-layout/-/table-layout-1.0.2.tgz",
      "integrity": "sha512-qd/R7n5rQTRFi+Zf2sk5XVVd9UQl6ZkduPFC3S7WEGJAmetDTjY3qPN50eSKzwuzEyQKy5TN2TiZdkIjos2L6A==",
      "requires": {
        "array-back": "^4.0.1",
        "deep-extend": "~0.6.0",
        "typical": "^5.2.0",
        "wordwrapjs": "^4.0.0"
      },
      "dependencies": {
        "typical": {
          "version": "5.2.0",
          "resolved": "https://registry.npmjs.org/typical/-/typical-5.2.0.tgz",
          "integrity": "sha512-dvdQgNDNJo+8B2uBQoqdb11eUCE1JQXhvjC/CZtgvZseVd5TYMXnq0+vuUemXbd/Se29cTaUuPX3YIc2xgbvIg=="
        }
      }
    },
    "thenify": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/thenify/-/thenify-3.3.1.tgz",
      "integrity": "sha512-RVZSIV5IG10Hk3enotrhvz0T9em6cyHBLkH/YAZuKqd8hRkKhSfCGIcP2KUY0EPxndzANBmNllzWPwak+bheSw==",
      "requires": {
        "any-promise": "^1.0.0"
      }
    },
    "thenify-all": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/thenify-all/-/thenify-all-1.6.0.tgz",
      "integrity": "sha1-GhkY1ALY/D+Y+/I02wvMjMEOlyY=",
      "requires": {
        "thenify": ">= 3.1.0 < 4"
      }
    },
    "through": {
      "version": "2.3.8",
      "resolved": "https://registry.npmjs.org/through/-/through-2.3.8.tgz",
      "integrity": "sha1-DdTJ/6q8NXlgsbckEV1+Doai4fU="
    },
    "toidentifier": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/toidentifier/-/toidentifier-1.0.1.tgz",
      "integrity": "sha512-o5sSPKEkg/DIQNmH43V0/uerLrpzVedkUh8tGNvaeXpfpuwjKenlSox/2O/BTlZUtEe+JG7s5YhEz608PlAHRA=="
    },
    "tsscmp": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/tsscmp/-/tsscmp-1.0.6.tgz",
      "integrity": "sha512-LxhtAkPDTkVCMQjt2h6eBVY28KCjikZqZfMcC15YBeNjkgUpdCfBu5HoiOTDu86v6smE8yOjyEktJ8hlbANHQA=="
    },
    "type-is": {
      "version": "1.6.18",
      "resolved": "https://registry.npmjs.org/type-is/-/type-is-1.6.18.tgz",
      "integrity": "sha512-TkRKr9sUTxEH8MdfuCSP7VizJyzRNMjj2J2do2Jr3Kym598JVdEksuzPQCnlFPW4ky9Q+iA+ma9BGm06XQBy8g==",
      "requires": {
        "media-typer": "0.3.0",
        "mime-types": "~2.1.24"
      }
    },
    "typical": {
      "version": "7.1.1",
      "resolved": "https://registry.npmjs.org/typical/-/typical-7.1.1.tgz",
      "integrity": "sha512-T+tKVNs6Wu7IWiAce5BgMd7OZfNYUndHwc5MknN+UHOudi7sGZzuHdCadllRuqJ3fPtgFtIH9+lt9qRv6lmpfA=="
    },
    "unpipe": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/unpipe/-/unpipe-1.0.0.tgz",
      "integrity": "sha512-pjy2bYhSsufwWlKwPc+l3cN7+wuJlK6uz0YdJEOlQDbl6jo/YlPi4mb8agUkVC8BF7V8NuzeyPNqRksA3hztKQ=="
    },
    "util-deprecate": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/util-deprecate/-/util-deprecate-1.0.2.tgz",
      "integrity": "sha1-RQ1Nyfpw3nMnYvvS1KKJgUGaDM8="
    },
    "vary": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/vary/-/vary-1.1.2.tgz",
      "integrity": "sha512-BNGbWLfd0eUPabhkXUVm0j8uuvREyTh5ovRa/dyow/BqAbZJyC+5fU+IzQOzmAKzYqYRAISoRhdQr3eIZ/PXqg=="
    },
    "walk-back": {
      "version": "5.1.0",
      "resolved": "https://registry.npmjs.org/walk-back/-/walk-back-5.1.0.tgz",
      "integrity": "sha512-Uhxps5yZcVNbLEAnb+xaEEMdgTXl9qAQDzKYejG2AZ7qPwRQ81lozY9ECDbjLPNWm7YsO1IK5rsP1KoQzXAcGA=="
    },
    "wordwrapjs": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/wordwrapjs/-/wordwrapjs-4.0.1.tgz",
      "integrity": "sha512-kKlNACbvHrkpIw6oPeYDSmdCTu2hdMHoyXLTcUKala++lx5Y+wjJ/e474Jqv5abnVmwxw08DiTuHmw69lJGksA==",
      "requires": {
        "reduce-flatten": "^2.0.0",
        "typical": "^5.2.0"
      },
      "dependencies": {
        "reduce-flatten": {
          "version": "2.0.0",
          "resolved": "https://registry.npmjs.org/reduce-flatten/-/reduce-flatten-2.0.0.tgz",
          "integrity": "sha512-EJ4UNY/U1t2P/2k6oqotuX2Cc3T6nxJwsM0N0asT7dhrtH1ltUxDn4NalSYmPE2rCkVpcf/X6R0wDwcFpzhd4w=="
        },
        "typical": {
          "version": "5.2.0",
          "resolved": "https://registry.npmjs.org/typical/-/typical-5.2.0.tgz",
          "integrity": "sha512-dvdQgNDNJo+8B2uBQoqdb11eUCE1JQXhvjC/CZtgvZseVd5TYMXnq0+vuUemXbd/Se29cTaUuPX3YIc2xgbvIg=="
        }
      }
    },
    "ylru": {
      "version": "1.3.2",
      "resolved": "https://registry.npmjs.org/ylru/-/ylru-1.3.2.tgz",
      "integrity": "sha512-RXRJzMiK6U2ye0BlGGZnmpwJDPgakn6aNQ0A7gHRbD4I0uvK4TW6UqkK1V0pp9jskjJBAXd3dRrbzWkqJ+6cxA=="
    }
  }
}
                                                                                                                                                                                                                                                                                                                                                                                   node-23.7.0/deps/v8/tools/package.json                                                              0000664 0000000 0000000 00000000151 14746647661 0017470 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        {
  "name": "v8-tools",
  "version": "1.0.0",
  "dependencies": {
    "local-web-server": "^5.3.1"
  }
}
                                                                                                                                                                                                                                                                                                                                                                                                                       node-23.7.0/deps/v8/tools/parse-processor                                                           0000775 0000000 0000000 00000002122 14746647661 0020257 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/bin/sh

# find the name of the log file to process, it must not start with a dash.
log_file="v8.log"
for arg in "$@"
do
  if ! expr "X${arg}" : "^X-" > /dev/null; then
    log_file=${arg}
  fi
done

tools_path=`cd $(dirname "$0");pwd`
if [ ! "$D8_PATH" ]; then
  d8_public=`which d8`
  if [ -x "$d8_public" ]; then
    D8_PATH=$(dirname "$d8_public");
  fi
fi
if [ -z ${D8_PATH##*/d8} ]; then
  d8_exec=$D8_PATH
else
  d8_exec=$D8_PATH/d8
fi

if [ ! -x "$d8_exec" ]; then
  for platform in x64 arm64 ia32; do
    for release in release optdebug debug; do
      if [ -x "$d8_exec" ]; then
        continue
      fi
      d8_exec="${tools_path}/../out/${platform}.${release}/d8";
    done
  done
fi

if [ ! -x "$d8_exec" ]; then
  d8_exec=`grep -m 1 -o '".*/d8"' $log_file | sed 's/"//g'`;
fi

if [ ! -x "$d8_exec" ]; then
  echo "d8 shell not found in $D8_PATH"
  echo "Please provide path to d8 as env var in D8_PATH"
  exit 1
fi

# nm spits out 'no symbols found' messages to stderr.
cat $log_file | $d8_exec --allow-natives-syntax \
  --module $tools_path/parse-processor-driver.mjs -- $@ 2>/dev/null
                                                                                                                                                                                                                                                                                                                                                                                                                                              node-23.7.0/deps/v8/tools/parse-processor-driver.mjs                                                0000664 0000000 0000000 00000000621 14746647661 0022337 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2017 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

import { ParseProcessor, ArgumentsProcessor } from "./parse-processor.mjs";

const params = ArgumentsProcessor.process(arguments);
const parseProcessor = new ParseProcessor();
await parseProcessor.processLogFile(params.logFileName);
                                                                                                               node-23.7.0/deps/v8/tools/parse-processor.html                                                      0000664 0000000 0000000 00000030014 14746647661 0021220 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        <!DOCTYPE html>
<!--
Copyright 2016 the V8 project authors. All rights reserved.  Use of this source
code is governed by a BSD-style license that can be found in the LICENSE file.
-->
<html lang="en">
<head>
<!-- This will be overwritten by the v8.dev/tools exporter -->
<!-- ANALYTICS_PLACEHOLDER -->
<meta charset="utf-8">
<title>V8 Parse Processor</title>
<style>
  html {
    font-family: monospace;
  }

  .parse {
    background-color: red;
    border: 1px red solid;
  }

  .preparse {
    background-color: orange;
    border: 1px orange solid;
  }

  .resolution {
    background-color: green;
    border: 1px green solid;
  }

  .execution {
    background-color: black;
    border-left: 2px black solid;
    z-index: -1;
  }

  .script {
    margin-top: 1em;
    overflow: visible;
    clear: both;
      border-top: 2px black dotted;
  }
  .script h3 {
    height: 20px;
    margin-bottom: 0.5em;
    white-space: nowrap;
  }

  .script-details {
    float: left;
  }

  .chart {
    float: left;
    margin-right: 2em;
  }

  .funktion-list {
    float: left;
    height: 400px;
  }

  .funktion-list > ul {
    height: 80%;
    overflow-y: scroll;
  }

  .funktion {
  }

  .script-size {
    display: inline-flex;
    background-color: #505050;
    border-radius: 3px;
    padding: 3px;
    margin: 2px;
    white-space: nowrap;
    overflow: hidden;
    text-decoration: none;
    color: white;
    transition: auto ease-in-out 0.8s;
    max-width: 500px;
  }
  .script-size:hover {
    max-width: 100000px !important;
    transition: auto ease-in-out 0.8s;
  }
  .script-size.eval {
    background-color: #ee6300fc;
  }
  .script-size.streaming {
    background-color: #008aff;
  }
  .script-size.deserialized {
    background-color: #1fad00fc;
  }

  .script-details {
    padding-right: 5px;
    margin-right: 4px;
  }
  /* all but the last need a border  */
  .script-details:nth-last-child(n+2) {
    border-right: 1px white solid;
  }

  .script-details.id {
    min-width: 2em;
    text-align: right;
  }
</style>
<script src="https://www.gstatic.com/charts/loader.js"></script>
<script type="module">

import { ParseProcessor, kSecondsToMillis, BYTES, PERCENT } from "./parse-processor.mjs";

google.charts.load('current', {packages: ['corechart']});

function $(query) {
  return document.querySelector(query);
}

window.addEventListener('DOMContentLoaded', (event) => {
  $("#uploadInput").focus();
});

document.loadFile = function() {
  let files = $('#uploadInput').files;

  let file = files[0];
  let reader = new FileReader();

  reader.onload = async function(evt) {
    const kTimerName = 'parse log file';
    console.time(kTimerName);
    let parseProcessor = new ParseProcessor();
    await parseProcessor.processString(this.result);
    console.timeEnd(kTimerName);
    renderParseResults(parseProcessor);
    document.parseProcessor = parseProcessor;
  }
  reader.readAsText(file);
}

function createNode(tag, classNames) {
  let node = document.createElement(tag);
  if (classNames) {
    if (Array.isArray(classNames)) {
      node.classList.add(...classNames);
    } else {
      node.className = classNames;
    }
  }
  return node;
}

function div(...args) {
  return createNode('div', ...args);
}

function h1(string) {
  let node = createNode('h1');
  node.appendChild(text(string));
  return node;
}

function h3(string, ...args) {
  let node = createNode('h3', ...args);
  if (string) node.appendChild(text(string));
  return node;
}

function a(href, string, ...args) {
  let link = createNode('a', ...args);
  if (href.length) link.href = href;
  if (string) link.appendChild(text(string));
  return link;
}

function text(string) {
  return document.createTextNode(string);
}

function delay(t) {
  return new Promise(resolve => setTimeout(resolve, t));
}

function renderParseResults(parseProcessor) {
  let result = $('#result');
  // clear out all existing result pages;
  result.innerHTML = '';
  const start = parseProcessor.firstEventTimestamp;
  const end = parseProcessor.lastEventTimestamp;
  renderScript(result, parseProcessor.totalScript, start, end);
  // Build up the graphs lazily to keep the page responsive.
  parseProcessor.scripts.forEach(
      script => renderScript(result, script, start, end));
  renderScriptSizes(parseProcessor);
  // Install an intersection observer to lazily load the graphs when the script
  // div becomes visible for the first time.
  var io = new IntersectionObserver((entries, observer) => {
    entries.forEach(entry => {
      if (entry.intersectionRatio == 0) return;
      console.assert(!entry.target.querySelector('.graph'));
      let target = entry.target;
      appendGraph(target.script, target, start, end);
      observer.unobserve(entry.target);
    });
  }, {rootMargin: '400px'});
  document.querySelectorAll('.script').forEach(div => io.observe(div));
}

const kTimeFactor = 10;
const kHeight = 20;
const kFunktionTopOffset = 50;

function renderScript(result, script, start, end) {
  // Filter out empty scripts.
  if (script.isEmpty() || script.lastParseEvent == 0) return;

  let scriptDiv = div('script');
  scriptDiv.script = script;

  let scriptTitle = h3();
  let anchor = a("", 'Script #' + script.id);
  anchor.name = "script"+script.id
  scriptTitle.appendChild(anchor);
  scriptDiv.appendChild(scriptTitle);
  if (script.file) scriptTitle.appendChild(a(script.file, script.file));
  let summary = createNode('pre', 'script-details');
  summary.appendChild(text(script.summary));
  scriptDiv.appendChild(summary);
  result.appendChild(scriptDiv);
}

function renderScriptSizes(parseProcessor) {
  let scriptsDiv = $('#scripts');
  parseProcessor.scripts.forEach(
    script => {
      let scriptDiv = a(`#script${script.id}`, '', 'script-size');
      let scriptId = div('script-details');
      scriptId.classList.add('id');
      scriptId.innerText = `id=${script.id}`;
      scriptDiv.appendChild(scriptId);
      let scriptSize = div('script-details');
      scriptSize.innerText = BYTES(script.bytesTotal);
      scriptDiv.appendChild(scriptSize);
      let scriptUrl = div('script-details');
      if (script.isEval) {
        scriptUrl.innerText = "eval";
        scriptDiv.classList.add('eval');
      } else {
        scriptUrl.innerText = script.file.split("/").pop();
      }
      if (script.isStreamingCompiled ) {
        scriptDiv.classList.add('streaming');
      } else if (script.deserializationTimestamp > 0) {
        scriptDiv.classList.add('deserialized');
      }
      scriptDiv.appendChild(scriptUrl);
      scriptDiv.style.maxWidth = `${script.bytesTotal * 0.001}px`;
      scriptsDiv.appendChild(scriptDiv);
    });
}

const kMaxTime = 120 * kSecondsToMillis;
// Resolution of the graphs
const kTimeIncrement = 1;
const kSelectionTimespan = 2;
// TODO(cbruni): support compilation cache hit.
class Series {
  constructor(metricName, description, color, lineStyle, isArea=false) {
    this.metricName = metricName;
    this.description = description;
    this.color = color;
    this.lineStyle = lineStyle;
    this.isArea = isArea;
  }
}
const series = [
    new Series('firstParseEvent', 'Any Parse', '#4D4D4D', undefined, true),
    new Series('execution', '1st Exec', '#fff700',undefined, true),
    new Series('firstCompileEvent', 'Any Compile', '#5DA5DA', undefined, true),

    new Series('compile', 'Eager Compile', '#FAA43A'),
    new Series('lazyCompile', 'Lazy Compile','#FAA43A', 'dash'),

    new Series('parse', 'Parsing', '#F17CB0'),
    new Series('preparse', 'Preparse', '#B2912F'),
    new Series('resolution', 'Preparse with Var. Resolution', '#B276B2'),

    new Series('deserialization', 'Deserialization', '#DECF3F'),

    new Series('baseline', 'Baseline', '#606611', 'dash'),
    new Series('optimize', 'Optimize', '#F15854'),
];
const metricNames = series.map(each => each.metricName);
// Display cumulative values (useuful for bytes).
const kCumulative = true;
// Include durations in the graphs.
const kUseDuration = false;


function appendGraph(script, parentNode, start, end) {
  const timerLabel = 'graph script=' + script.id;
  // TODO(cbruni): add support for network events

  console.time(timerLabel);
  let data = new google.visualization.DataTable();
  data.addColumn('number', 'Duration');
  // The series are interleave bytes processed, time spent and thus have two
  // different vAxes.
  let seriesOptions = [];
  series.forEach(series => {
    // Add the bytes column.
    data.addColumn('number', series.description);
    let options = {targetAxisIndex: 0, color: series.color};
    if (series.isArea) options.type = 'area';
    if (series.lineStyle === 'dash') options.lineDashStyle = [4, 4];
    seriesOptions.push(options)
    // Add the time column.
    if (kUseDuration) {
      data.addColumn('number', series.description + ' Duration');
      seriesOptions.push(
          {targetAxisIndex: 1, color: series.color, lineDashStyle: [3, 2]});
    }
  });

  const maxTime = Math.min(kMaxTime, end);
  console.time('metrics');
  let metricValues =
    script.getAccumulatedTimeMetrics(metricNames , 0, maxTime, kTimeIncrement,
        kCumulative, kUseDuration);
  console.timeEnd('metrics');
  // Make sure that the series added to the graph matches the returned values.
  console.assert(metricValues[0].length == seriesOptions.length + 1);
  data.addRows(metricValues);

  let options = {
    explorer: {
      actions: ['dragToZoom', 'rightClickToReset'],
      maxZoomIn: 0.01
    },
    hAxis: {
      format: '#,###.##s'
    },
    vAxes: {
      0: {title: 'Bytes Touched', format: 'short'},
      1: {title: 'Duration', format: '#,###ms'}
    },
    height: 400,
    width: 1000,
    chartArea: {left: 70, top: 0, right: 160, height: "90%"},
    // The first series should be a area chart (total bytes touched),
    series: seriesOptions,
    // everthing else is a line.
    seriesType: 'line'
  };
  let graphNode = createNode('div', 'chart');
  let listNode = createNode('div', 'funktion-list');
  parentNode.appendChild(graphNode);
  parentNode.appendChild(listNode);
  let chart = new google.visualization.ComboChart(graphNode);
  google.visualization.events.addListener(chart, 'select',
      () => selectGraphPointHandler(chart, data, script, parentNode));
  chart.draw(data, options);
  // Add event listeners
  console.timeEnd(timerLabel);
}

function selectGraphPointHandler(chart, data, script, parentNode) {
  let selection = chart.getSelection();
  if (selection.length <= 0) return;
  // Display a list of funktions with events at the given time.
  let {row, column} = selection[0];
  if (row === null|| column === null) return;
  const kEntrySize = kUseDuration ? 2 : 1;
  let [metric, description] = series[((column-1)/ kEntrySize) | 0];
  let time = data.getValue(row, 0);
  let funktions = script.getFunktionsAtTime(
        time * kSecondsToMillis, kSelectionTimespan, metric);
  let oldList = parentNode.querySelector('.funktion-list');
  parentNode.replaceChild(
      createFunktionList(metric, description, time, funktions), oldList);
}

function createFunktionList(metric, description, time, funktions) {
  let container = createNode('div', 'funktion-list');
  container.appendChild(h3('Changes of "' + description + '" at ' +
        time + 's: ' + funktions.length));
  let listNode = createNode('ul');
  funktions.forEach(funktion => {
    let node = createNode('li', 'funktion');
    node.funktion = funktion;
    node.appendChild(text(funktion.toString(false) + " "));
    let script = funktion.script;
    if (script) {
      node.appendChild(a("#script" + script.id, "in script " + script.id));
    }
    listNode.appendChild(node);
  });
  container.appendChild(listNode);
  return container;
}
</script>
</head>

<body>
  <h1>BEHOLD, THIS IS PARSEROR!</h1>

  <h2>Usage</h2>
  Run your script with <code>--log-function-events</code> and upload <code>v8.log</code> on this page:<br/>
  <code>/path/to/d8 --log-function-events your_script.js</code>

  <h2>Data</h2>
  <form name="fileForm">
    <p>
      <input id="uploadInput" type="file" name="files" onchange="loadFile();" accept=".log"> trace entries: <span id="count">0</span>
    </p>
  </form>


  <h2>Scripts</h2>
  <div id="scripts"></div>

  <h2>Result</h2>
  <div id="result"></div>
</body>

</html>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    node-23.7.0/deps/v8/tools/parse-processor.mjs                                                       0000664 0000000 0000000 00000112567 14746647661 0021063 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2017 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.
import { LogReader, parseString } from "./logreader.mjs";
import { BaseArgumentsProcessor } from "./arguments.mjs";
import { formatBytes, formatMillis} from "./js/helper.mjs";

// ===========================================================================

// This is the only true formatting, why? For an international audience the
// confusion between the decimal and thousands separator is big (alternating
// between comma "," vs dot "."). The Swiss formatting uses "'" as a thousands
// separator, dropping most of that confusion.
const numberFormat = new Intl.NumberFormat('de-CH', {
  maximumFractionDigits: 2,
  minimumFractionDigits: 2,
});

function formatNumber(value) {
  return numberFormat.format(value);
}

export function BYTES(bytes, total) {
  let result = formatBytes(bytes)
  if (total !== undefined && total != 0) {
    result += PERCENT(bytes, total).padStart(5);
  }
  return result;
}

export function TIME(millis) {
  return formatMillis(millis, 1);
}

export function PERCENT(value, total) {
  return Math.round(value / total * 100) + "%";
}

// ===========================================================================
const kNoTimeMetrics = {
  __proto__: null,
  executionDuration: 0,
  firstEventTimestamp: 0,
  firstParseEventTimestamp: 0,
  lastParseEventTimestamp: 0,
  lastEventTimestamp: 0
};

class CompilationUnit {
  constructor() {
    this.isEval = false;
    this.isDeserialized = false;

    // Lazily computed properties.
    this.firstEventTimestamp = -1;
    this.firstParseEventTimestamp = -1;
    this.firstCompileEventTimestamp = -1;
    this.lastParseEventTimestamp = -1;
    this.lastEventTimestamp = -1;
    this.deserializationTimestamp = -1;

    this.preparseTimestamp = -1;
    this.parseTimestamp = -1;
    this.parse2Timestamp = -1;
    this.resolutionTimestamp = -1;
    this.compileTimestamp = -1;
    this.lazyCompileTimestamp = -1;
    this.executionTimestamp = -1;
    this.baselineTimestamp = -1;
    this.optimizeTimestamp = -1;

    this.deserializationDuration = -0.0;
    this.preparseDuration = -0.0;
    this.parseDuration = -0.0;
    this.parse2Duration = -0.0;
    this.resolutionDuration = -0.0;
    this.scopeResolutionDuration = -0.0;
    this.lazyCompileDuration = -0.0;
    this.compileDuration = -0.0;
    this.baselineDuration = -0.0;
    this.optimizeDuration = -0.0;

    this.ownBytes = -1;
    this.compilationCacheHits = [];
  }

  finalize() {
    this.firstEventTimestamp = this.timestampMin(
        this.deserializationTimestamp, this.parseTimestamp,
        this.preparseTimestamp, this.resolutionTimestamp,
        this.executionTimestamp);

    this.firstParseEventTimestamp = this.timestampMin(
        this.deserializationTimestamp, this.parseTimestamp,
        this.preparseTimestamp, this.resolutionTimestamp);

    this.firstCompileEventTimestamp = this.rawTimestampMin(
        this.deserializationTimestamp, this.compileTimestamp,
        this.baselineTimestamp, this.lazyCompileTimestamp);
    // Any excuted script needs to be compiled.
    if (this.hasBeenExecuted() &&
        (this.firstCompileEventTimestamp <= 0 ||
         this.executionTimestamp < this.firstCompileTimestamp)) {
      console.error('Compile < execution timestamp', this);
    }

    if (this.ownBytes < 0) console.error(this, 'Own bytes must be positive');
  }

  hasBeenExecuted() {
    return this.executionTimestamp > 0;
  }

  addCompilationCacheHit(timestamp) {
    this.compilationCacheHits.push(timestamp);
  }

  // Returns the smallest timestamp from the given list, ignoring
  // uninitialized (-1) values.
  rawTimestampMin(...timestamps) {
    timestamps = timestamps.length == 1 ? timestamps[0] : timestamps;
    let result = timestamps.reduce((min, item) => {
      return item == -1 ? min : (min == -1 ? item : Math.min(item, item));
    }, -1);
    return result;
  }
  timestampMin(...timestamps) {
    let result = this.rawTimestampMin(...timestamps);
    if (Number.isNaN(result) || result < 0) {
      console.error(
          'Invalid timestamp min:', {result, timestamps, script: this});
      return 0;
    }
    return result;
  }

  timestampMax(...timestamps) {
    timestamps = timestamps.length == 1 ? timestamps[0] : timestamps;
    let result = Math.max(...timestamps);
    if (Number.isNaN(result) || result < 0) {
      console.error(
          'Invalid timestamp max:', {result, timestamps, script: this});
      return 0;
    }
    return result;
  }
}

// ===========================================================================
class Script extends CompilationUnit {
  constructor(id) {
    super();
    if (id === undefined || id <= 0) {
      throw new Error(`Invalid id=${id} for script`);
    }
    this.file = '';
    this.id = id;

    this.isNative = false;
    this.isBackgroundCompiled = false;
    this.isStreamingCompiled = false;

    this.funktions = [];
    this.metrics = new Map();
    this.maxNestingLevel = 0;

    this.width = 0;
    this.bytesTotal = -1;
    this.finalized = false;
    this.summary = '';
    this.source = '';
  }

  setFile(name) {
    this.file = name;
    this.isNative = name.startsWith('native ');
  }

  isEmpty() {
    return this.funktions.length === 0;
  }

  getFunktionAtStartPosition(start) {
    if (!this.isEval && start === 0) {
      throw 'position 0 is reserved for the script';
    }
    if (this.finalized) {
      return this.funktions.find(funktion => funktion.start == start);
    }
    return this.funktions[start];
  }

  // Return the innermost function at the given source position.
  getFunktionForPosition(position) {
    if (!this.finalized) throw 'Incomplete script';
    for (let i = this.funktions.length - 1; i >= 0; i--) {
      let funktion = this.funktions[i];
      if (funktion.containsPosition(position)) return funktion;
    }
    return undefined;
  }

  addMissingFunktions(list) {
    if (this.finalized) throw 'script is finalized!';
    list.forEach(fn => {
      if (this.funktions[fn.start] === undefined) {
        this.addFunktion(fn);
      }
    });
  }

  addFunktion(fn) {
    if (this.finalized) throw 'script is finalized!';
    if (fn.start === undefined) throw "Funktion has no start position";
    if (this.funktions[fn.start] !== undefined) {
      fn.print();
      throw "adding same function twice to script";
    }
    this.funktions[fn.start] = fn;
  }

  finalize() {
    this.finalized = true;
    // Compact funktions as we no longer need access via start byte position.
    this.funktions = this.funktions.filter(each => true);
    let parent = null;
    let maxNesting = 0;
    // Iterate over the Funktions in byte position order.
    this.funktions.forEach(fn => {
      fn.isEval = this.isEval;
      if (parent === null) {
        parent = fn;
      } else {
        // Walk up the nested chain of Funktions to find the parent.
        while (parent !== null && !fn.isNestedIn(parent)) {
          parent = parent.parent;
        }
        fn.parent = parent;
        if (parent) {
          maxNesting = Math.max(maxNesting, parent.addNestedFunktion(fn));
        }
        parent = fn;
      }
    });
    // Sanity checks to ensure that scripts are executed and parsed before any
    // of its funktions.
    let funktionFirstParseEventTimestamp = -1;
    // Second iteration step to finalize the funktions once the proper
    // hierarchy has been set up.
    this.funktions.forEach(fn => {
      fn.finalize();

      funktionFirstParseEventTimestamp = this.timestampMin(
          funktionFirstParseEventTimestamp, fn.firstParseEventTimestamp);

      this.lastParseEventTimestamp = this.timestampMax(
          this.lastParseEventTimestamp, fn.lastParseEventTimestamp);

      this.lastEventTimestamp =
          this.timestampMax(this.lastEventTimestamp, fn.lastEventTimestamp);
    });
    this.maxNestingLevel = maxNesting;

    // Initialize sizes.
    if (this.ownBytes === -1) console.error('Invalid ownBytes');
    if (this.funktions.length == 0) {
      this.bytesTotal = this.ownBytes = 0;
      return;
    }
    let toplevelFunktionBytes = this.funktions.reduce(
        (bytes, each) => bytes + (each.isToplevel() ? each.getBytes() : 0), 0);
    if (this.isDeserialized || this.isEval || this.isStreamingCompiled) {
      if (this.getBytes() === -1) {
        this.bytesTotal = toplevelFunktionBytes;
      }
    }
    this.ownBytes = this.bytesTotal - toplevelFunktionBytes;
    // Initialize common properties.
    super.finalize();
    // Sanity checks after the minimum timestamps have been computed.
    if (funktionFirstParseEventTimestamp < this.firstParseEventTimestamp) {
      console.error(
          'invalid firstCompileEventTimestamp', this,
          funktionFirstParseEventTimestamp, this.firstParseEventTimestamp);
    }
  }

  print() {
    console.log(this.toString());
  }

  toString() {
    let str = `SCRIPT id=${this.id} file=${this.file}\n` +
      `functions[${this.funktions.length}]:`;
    this.funktions.forEach(fn => str += fn.toString());
    return str;
  }

  getBytes() {
    return this.bytesTotal;
  }

  getOwnBytes() {
    return this.ownBytes;
  }

  // Also see Funktion.prototype.getMetricBytes
  getMetricBytes(name) {
    if (name == 'lazyCompileTimestamp') return this.getOwnBytes();
    return this.getOwnBytes();
  }

  getMetricDuration(name) {
    return this[name];
  }

  forEach(fn) {
    fn(this);
    this.funktions.forEach(fn);
  }

  // Container helper for TotalScript / Script.
  getScripts() {
    return [this];
  }

  calculateMetrics(printSummary) {
    let log = (str) => this.summary += str + '\n';
    log(`SCRIPT: ${this.id}`);
    let all = this.funktions;
    if (all.length === 0) return;

    let nofFunktions = all.length;
    let ownBytesSum = list => {
      return list.reduce((bytes, each) => bytes + each.getOwnBytes(), 0)
    };

    let info = (name, funktions) => {
      let ownBytes = ownBytesSum(funktions);
      let nofPercent = Math.round(funktions.length / nofFunktions * 100);
      let value = (funktions.length + "#").padStart(7) +
        (nofPercent + "%").padStart(5) +
        BYTES(ownBytes, this.bytesTotal).padStart(16);
      log((`  - ${name}`).padEnd(20) + value);
      this.metrics.set(name + "-bytes", ownBytes);
      this.metrics.set(name + "-count", funktions.length);
      this.metrics.set(name + "-count-percent", nofPercent);
      this.metrics.set(name + "-bytes-percent",
        Math.round(ownBytes / this.bytesTotal * 100));
    };

    log(`  - file:         ${this.file}`);
    log('  - details:      ' +
        'isEval=' + this.isEval + ' deserialized=' + this.isDeserialized +
        ' streamed=' + this.isStreamingCompiled);
    log("    Category               Count           Bytes");
    info("scripts", this.getScripts());
    info("functions", all);
    info("toplevel fns", all.filter(each => each.isToplevel()));
    info('preparsed', all.filter(each => each.preparseDuration > 0));

    info('fully parsed', all.filter(each => each.parseDuration > 0));
    // info("fn parsed", all.filter(each => each.parse2Duration > 0));
    // info("resolved", all.filter(each => each.resolutionDuration > 0));
    info("executed", all.filter(each => each.executionTimestamp > 0));
    info('eval', all.filter(each => each.isEval));
    info("lazy compiled", all.filter(each => each.lazyCompileTimestamp > 0));
    info("eager compiled", all.filter(each => each.compileTimestamp > 0));

    info("baseline", all.filter(each => each.baselineTimestamp > 0));
    info("optimized", all.filter(each => each.optimizeTimestamp > 0));

    log("    Cost split: executed vs non-executed functions, max = longest single event");
    const costs = [
      ['parse', each => each.parseDuration],
      ['preparse', each => each.preparseDuration],
      ['resolution', each => each.resolutionDuration],
      ['compile-eager',  each => each.compileDuration],
      ['compile-lazy',  each => each.lazyCompileDuration],
      ['baseline',  each => each.baselineDuration],
      ['optimize', each => each.optimizeDuration],
    ];
    for (let [name, fn] of costs) {
      const executionCost = new ExecutionCost(name, all, fn);
      executionCost.setMetrics(this.metrics);
      log(executionCost.toString());
    }

    let nesting = new NestingDistribution(all);
    nesting.setMetrics(this.metrics);
    log(nesting.toString());

    if (printSummary) console.log(this.summary);
  }

  getAccumulatedTimeMetrics(
      metrics, start, end, delta, cumulative = true, useDuration = false) {
    // Returns an array of the following format:
    // [ [start,         acc(metric0, start, start), acc(metric1, ...), ...],
    //   [start+delta,   acc(metric0, start, start+delta), ...],
    //   [start+delta*2, acc(metric0, start, start+delta*2), ...],
    //   ...
    // ]
    if (end <= start) throw `Invalid ranges [${start},${end}]`;
    const timespan = end - start;
    const kSteps = Math.ceil(timespan / delta);
    // To reduce the time spent iterating over the funktions of this script
    // we iterate once over all funktions and add the metric changes to each
    // timepoint:
    // [ [0, 300, ...], [1,  15, ...], [2, 100, ...], [3,   0, ...] ... ]
    // In a second step we accumulate all values:
    // [ [0, 300, ...], [1, 315, ...], [2, 415, ...], [3, 415, ...] ... ]
    //
    // To limit the number of data points required in the resulting graphs,
    // only the rows for entries with actual changes are created.

    const metricProperties = ["time"];
    metrics.forEach(each => {
      metricProperties.push(each + 'Timestamp');
      if (useDuration) metricProperties.push(each + 'Duration');
    });
    // Create a packed {rowTemplate} which is copied later-on.
    let indexToTime = (t) => (start + t * delta) / kSecondsToMillis;
    let rowTemplate = [indexToTime(0)];
    for (let i = 1; i < metricProperties.length; i++) rowTemplate.push(0.0);
    // Create rows with 0-time entry.
    let rows = new Array(rowTemplate.slice());
    for (let t = 1; t <= kSteps; t++) rows.push(null);
    // Create the real metric's property name on the Funktion object.
    // Add the increments of each Funktion's metric to the result.
    this.forEach(funktionOrScript => {
      // Iterate over the Funktion's metric names, skipping position 0 which
      // is the time.
      const kMetricIncrement = useDuration ? 2 : 1;
      for (let i = 1; i < metricProperties.length; i += kMetricIncrement) {
        let timestampPropertyName = metricProperties[i];
        let timestamp = funktionOrScript[timestampPropertyName];
        if (timestamp === undefined) continue;
        if (timestamp < start || end < timestamp) continue;
        timestamp -= start;
        let index = Math.floor(timestamp / delta);
        let row = rows[index];
        if (row === null) {
          // Add a new row if it didn't exist,
          row = rows[index] = rowTemplate.slice();
          // .. add the time offset.
          row[0] = indexToTime(index);
        }
        // Add the metric value.
        row[i] += funktionOrScript.getMetricBytes(timestampPropertyName);
        if (!useDuration) continue;
        let durationPropertyName = metricProperties[i + 1];
        row[i + 1] += funktionOrScript.getMetricDuration(durationPropertyName);
      }
    });
    // Create a packed array again with only the valid entries.
    // Accumulate the incremental results by adding the metric values from
    // the previous time window.
    let previous = rows[0];
    let result = [previous];
    for (let t = 1; t < rows.length; t++) {
      let current = rows[t];
      if (current === null) {
        // Ensure a zero data-point after each non-zero point.
        if (!cumulative && rows[t - 1] !== null) {
          let duplicate = rowTemplate.slice();
          duplicate[0] = indexToTime(t);
          result.push(duplicate);
        }
        continue;
      }
      if (cumulative) {
        // Skip i==0 where the corresponding time value in seconds is.
        for (let i = 1; i < metricProperties.length; i++) {
          current[i] += previous[i];
        }
      }
      // Make sure we have a data-point in time right before the current one.
      if (rows[t - 1] === null) {
        let duplicate = (!cumulative ? rowTemplate : previous).slice();
        duplicate[0] = indexToTime(t - 1);
        result.push(duplicate);
      }
      previous = current;
      result.push(current);
    }
    // Make sure there is an entry at the last position to make sure all graphs
    // have the same width.
    const lastIndex = rows.length - 1;
    if (rows[lastIndex] === null) {
      let duplicate = previous.slice();
      duplicate[0] = indexToTime(lastIndex);
      result.push(duplicate);
    }
    return result;
  }

  getFunktionsAtTime(time, delta, metric) {
    // Returns a list of Funktions whose metric changed in the
    // [time-delta, time+delta] range.
    return this.funktions.filter(
      funktion => funktion.didMetricChange(time, delta, metric));
  }
}


class TotalScript extends Script {
  constructor() {
    super('all files', 'all files');
    this.scripts = [];
  }

  addAllFunktions(script) {
    // funktions is indexed by byte offset and as such not packed. Add every
    // Funktion one by one to keep this.funktions packed.
    script.funktions.forEach(fn => this.funktions.push(fn));
    this.scripts.push(script);
    this.bytesTotal += script.bytesTotal;
  }

  // Iterate over all Scripts and nested Funktions.
  forEach(fn) {
    this.scripts.forEach(script => script.forEach(fn));
  }

  getScripts() {
    return this.scripts;
  }
}


// ===========================================================================

class NestingDistribution {
  constructor(funktions) {
    // Stores the nof bytes per function nesting level.
    this.accumulator = [0, 0, 0, 0, 0];
    // Max nof bytes encountered at any nesting level.
    this.max = 0;
    // avg bytes per nesting level.
    this.avg = 0;
    this.totalBytes = 0;

    funktions.forEach(each => each.accumulateNestingLevel(this.accumulator));
    this.max = this.accumulator.reduce((max, each) => Math.max(max, each), 0);
    this.totalBytes = this.accumulator.reduce((sum, each) => sum + each, 0);
    for (let i = 0; i < this.accumulator.length; i++) {
      this.avg += this.accumulator[i] * i;
    }
    this.avg /= this.totalBytes;
  }

  print() {
    console.log(this.toString());
  }

  toString() {
    let ticks = " ";
    let accString = this.accumulator.reduce((str, each) => {
      let index = Math.round(each / this.max * (ticks.length - 1));
      return str + ticks[index];
    }, '');
    let percent0 = this.accumulator[0]
    let percent1 = this.accumulator[1];
    let percent2plus = this.accumulator.slice(2)
      .reduce((sum, each) => sum + each, 0);
    return "  - fn nesting level:     " +
      ' avg=' + formatNumber(this.avg) +
      ' l0=' + PERCENT(percent0, this.totalBytes) +
      ' l1=' + PERCENT(percent1, this.totalBytes) +
      ' l2+=' + PERCENT(percent2plus, this.totalBytes) +
      ' nesting-histogram=[' + accString + ']';

  }

  setMetrics(dict) {}
}

class ExecutionCost {
  constructor(prefix, funktions, time_fn) {
    this.prefix = prefix;
    // Time spent on executed functions.
    this.executedCost = 0;
    // Time spent on not executed functions.
    this.nonExecutedCost = 0;
    this.maxDuration = 0;

    for (let i = 0; i < funktions.length; i++) {
      const funktion = funktions[i];
      const value = time_fn(funktion);
      if (funktion.hasBeenExecuted()) {
        this.executedCost +=  value;
      } else {
        this.nonExecutedCost += value;
      }
      this.maxDuration = Math.max(this.maxDuration, value);
    }
  }

  print() {
    console.log(this.toString())
  }

  toString() {
    return `  - ${this.prefix}-time:`.padEnd(24) +
      `  executed=${TIME(this.executedCost)}`.padEnd(20) +
      `  non-executed=${TIME(this.nonExecutedCost)}`.padEnd(24) +
      ` max=${TIME(this.maxDuration)}`;
  }

  setMetrics(dict) {
    dict.set('parseMetric', this.executionCost);
    dict.set('parseMetricNegative', this.nonExecutionCost);
  }
}

// ===========================================================================

class Funktion extends CompilationUnit {
  constructor(name, start, end, script) {
    super();
    if (start < 0) throw `invalid start position: ${start}`;
    if (script.isEval) {
      if (end < start) throw 'invalid start end positions';
    } else {
      if (end <= 0) throw `invalid end position: ${end}`;
      if (end < start) throw 'invalid start end positions';
      if (end == start) console.error("Possibly invalid start/end position")
    }

    this.name = name;
    this.start = start;
    this.end = end;
    this.script = script;
    this.parent = null;
    this.nested = [];
    this.nestingLevel = 0;

    if (script) this.script.addFunktion(this);
  }

  finalize() {
    this.lastParseEventTimestamp = Math.max(
        this.preparseTimestamp + this.preparseDuration,
        this.parseTimestamp + this.parseDuration,
        this.resolutionTimestamp + this.resolutionDuration);
    if (!(this.lastParseEventTimestamp > 0)) this.lastParseEventTimestamp = 0;

    this.lastEventTimestamp =
        Math.max(this.lastParseEventTimestamp, this.executionTimestamp);
    if (!(this.lastEventTimestamp > 0)) this.lastEventTimestamp = 0;

    this.ownBytes = this.nested.reduce(
        (bytes, each) => bytes - each.getBytes(), this.getBytes());

    super.finalize();
  }

  getMetricBytes(name) {
    if (name == 'lazyCompileTimestamp') return this.getOwnBytes();
    return this.getOwnBytes();
  }

  getMetricDuration(name) {
    if (name in kNoTimeMetrics) return 0;
    return this[name];
  }

  isNestedIn(funktion) {
    if (this.script != funktion.script) throw "Incompatible script";
    return funktion.start < this.start && this.end <= funktion.end;
  }

  isToplevel() {
    return this.parent === null;
  }

  containsPosition(position) {
    return this.start <= position && position <= this.end;
  }

  accumulateNestingLevel(accumulator) {
    let value = accumulator[this.nestingLevel] || 0;
    accumulator[this.nestingLevel] = value + this.getOwnBytes();
  }

  addNestedFunktion(child) {
    if (this.script != child.script) throw "Incompatible script";
    if (child == null) throw "Nesting non child";
    this.nested.push(child);
    if (this.nested.length > 1) {
      // Make sure the nested children don't overlap and have been inserted in
      // byte start position order.
      let last = this.nested[this.nested.length - 2];
      if (last.end > child.start || last.start > child.start ||
        last.end > child.end || last.start > child.end) {
        throw "Wrongly nested child added";
      }
    }
    child.nestingLevel = this.nestingLevel + 1;
    return child.nestingLevel;
  }

  getBytes() {
    return this.end - this.start;
  }

  getOwnBytes() {
    return this.ownBytes;
  }

  didMetricChange(time, delta, name) {
    let value = this[name + 'Timestamp'];
    return (time - delta) <= value && value <= (time + delta);
  }

  print() {
    console.log(this.toString());
  }

  toString(details = true) {
    let result = `function${this.name ? ` ${this.name}` : ''}` +
        `() range=${this.start}-${this.end}`;
    if (details) result += ` script=${this.script ? this.script.id : 'X'}`;
    return result;
  }
}


// ===========================================================================

export const kTimestampFactor = 1000;
export const kSecondsToMillis = 1000;

function toTimestamp(microseconds) {
  return microseconds / kTimestampFactor
}

function startOf(timestamp, time) {
  let result = toTimestamp(timestamp) - time;
  if (result < 0) throw "start timestamp cannot be negative";
  return result;
}


export class ParseProcessor extends LogReader {
  constructor() {
    super();
    this.setDispatchTable({
      // Avoid accidental leaking of __proto__ properties and force this object
      // to be in dictionary-mode.
      __proto__: null,
      // "function",{event type},
      // {script id},{start position},{end position},{time},{timestamp},
      // {function name}
      'function': {
        parsers: [
          parseString, parseInt, parseInt, parseInt, parseFloat, parseInt,
          parseString
        ],
        processor: this.processFunctionEvent
      },
      // "compilation-cache","hit"|"put",{type},{scriptid},{start position},
      // {end position},{timestamp}
      'compilation-cache': {
        parsers:
            [parseString, parseString, parseInt, parseInt, parseInt, parseInt],
        processor: this.processCompilationCacheEvent
      },
      'script': {
        parsers: [parseString, parseInt, parseInt],
        processor: this.processScriptEvent
      },
      // "script-details", {script_id}, {file}, {line}, {column}, {size}
      'script-details': {
        parsers: [parseInt, parseString, parseInt, parseInt, parseInt],
        processor: this.processScriptDetails
      },
      'script-source': {
        parsers: [parseInt, parseString, parseString],
        processor: this.processScriptSource
      },
    });
    this.functionEventDispatchTable_ = {
      // Avoid accidental leaking of __proto__ properties and force this object
      // to be in dictionary-mode.
      __proto__: null,
      'full-parse': this.processFull.bind(this),
      'parse-function': this.processParseFunction.bind(this),
      // TODO(cbruni): make sure arrow functions emit a normal parse-function
      // event.
      'parse': this.processParseFunction.bind(this),
      'parse-script': this.processParseScript.bind(this),
      'parse-eval': this.processParseEval.bind(this),
      'preparse-no-resolution': this.processPreparseNoResolution.bind(this),
      'preparse-resolution': this.processPreparseResolution.bind(this),
      'first-execution': this.processFirstExecution.bind(this),
      'interpreter-lazy': this.processCompileLazy.bind(this),
      'interpreter': this.processCompile.bind(this),
      'interpreter-eval': this.processCompileEval.bind(this),
      'baseline': this.processBaselineLazy.bind(this),
      'baseline-lazy': this.processBaselineLazy.bind(this),
      'optimize-lazy': this.processOptimizeLazy.bind(this),
      'deserialize': this.processDeserialize.bind(this),
    };

    this.idToScript = new Map();
    this.fileToScript = new Map();
    this.nameToFunction = new Map();
    this.scripts = [];
    this.totalScript = new TotalScript();
    this.firstEventTimestamp = -1;
    this.lastParseEventTimestamp = -1;
    this.lastEventTimestamp = -1;
  }

  print() {
    console.log("scripts:");
    this.idToScript.forEach(script => script.print());
  }

  async processString(string) {
    await this.processLogChunk(string);
    this.postProcess();
  }

  async processLogFile(fileName) {
    this.collectEntries = true
    this.lastLogFileName_ = fileName;
    let line;
    while (line = readline()) {
      await this.processLogLine(line);
    }
    this.postProcess();
  }

  postProcess() {
    this.scripts = Array.from(this.idToScript.values())
      .filter(each => !each.isNative);

    if (this.scripts.length == 0) {
      console.error("Could not find any scripts!");
      return false;
    }

    this.scripts.forEach(script => {
      script.finalize();
      script.calculateMetrics(false);
    });

    this.scripts.forEach(script => this.totalScript.addAllFunktions(script));
    this.totalScript.calculateMetrics(true);

    this.firstEventTimestamp = this.totalScript.timestampMin(
        this.scripts.map(each => each.firstEventTimestamp));
    this.lastParseEventTimestamp = this.totalScript.timestampMax(
        this.scripts.map(each => each.lastParseEventTimestamp));
    this.lastEventTimestamp = this.totalScript.timestampMax(
        this.scripts.map(each => each.lastEventTimestamp));

    const series = {
      firstParseEvent: 'Any Parse Event',
      parse: 'Parsing',
      preparse: 'Preparsing',
      resolution: 'Preparsing with Var. Resolution',
      lazyCompile: 'Lazy Compilation',
      compile: 'Eager Compilation',
      execution: 'First Execution',
    };
    let metrics = Object.keys(series);
    this.totalScript.getAccumulatedTimeMetrics(
        metrics, 0, this.lastEventTimestamp, 10);
  }

  processFunctionEvent(
      eventName, scriptId, startPosition, endPosition, duration, timestamp,
      functionName) {
    let handlerFn = this.functionEventDispatchTable_[eventName];
    if (handlerFn === undefined) {
      console.error(`Couldn't find handler for function event:${eventName}`);
    }
    handlerFn(
        scriptId, startPosition, endPosition, duration, timestamp,
        functionName);
  }

  addEntry(entry) {
    this.entries.push(entry);
  }

  lookupScript(id) {
    return this.idToScript.get(id);
  }

  getOrCreateFunction(
      scriptId, startPosition, endPosition, duration, timestamp, functionName) {
    if (scriptId == -1) {
      return this.lookupFunktionByRange(startPosition, endPosition);
    }
    let script = this.lookupScript(scriptId);
    let funktion = script.getFunktionAtStartPosition(startPosition);
    if (funktion === undefined) {
      funktion = new Funktion(functionName, startPosition, endPosition, script);
    }
    return funktion;
  }

  // Iterates over all functions and tries to find matching ones.
  lookupFunktionsByRange(start, end) {
    let results = [];
    this.idToScript.forEach(script => {
      script.forEach(funktion => {
        if (funktion.startPosition == start && funktion.endPosition == end) {
          results.push(funktion);
        }
      });
    });
    return results;
  }
  lookupFunktionByRange(start, end) {
    let results = this.lookupFunktionsByRange(start, end);
    if (results.length != 1) throw "Could not find unique function by range";
    return results[0];
  }

  processScriptEvent(eventName, scriptId, timestamp) {
    let script = this.idToScript.get(scriptId);
    switch (eventName) {
      case 'create':
      case 'reserve-id':
      case 'deserialize': {
        if (script !== undefined) return;
        script = new Script(scriptId);
        this.idToScript.set(scriptId, script);
        if (eventName == 'deserialize') {
          script.deserializationTimestamp = toTimestamp(timestamp);
        }
        return;
      }
      case 'background-compile':
        if (script.isBackgroundCompiled) {
          throw 'Cannot background-compile twice';
        }
        script.isBackgroundCompiled = true;
        // TODO(cbruni): remove once backwards compatibility is no longer needed.
        script.isStreamingCompiled = true;
        // TODO(cbruni): fix parse events for background compilation scripts
        script.preparseTimestamp = toTimestamp(timestamp);
        return;
      case 'streaming-compile':
        if (script.isStreamingCompiled) throw 'Cannot stream-compile twice';
        // TODO(cbruni): remove once backwards compatibility is no longer needed.
        script.isBackgroundCompiled = true;
        script.isStreamingCompiled = true;
        // TODO(cbruni): fix parse events for background compilation scripts
        script.preparseTimestamp = toTimestamp(timestamp);
        return;
      default:
        console.error(`Unhandled script event: ${eventName}`);
    }
  }

  processScriptDetails(scriptId, file, startLine, startColumn, size) {
    let script = this.lookupScript(scriptId);
    script.setFile(file);
  }

  processScriptSource(scriptId, url, source) {
    let script = this.lookupScript(scriptId);
    script.source = source;
  }

  processParseEval(
      scriptId, startPosition, endPosition, duration, timestamp, functionName) {
    if (startPosition != 0 && startPosition != -1) {
      console.error('Invalid start position for parse-eval', arguments);
    }
    let script = this.processParseScript(...arguments);
    script.isEval = true;
  }

  processFull(
      scriptId, startPosition, endPosition, duration, timestamp, functionName) {
    if (startPosition == 0) {
      // This should only happen for eval.
      let script = this.lookupScript(scriptId);
      script.isEval = true;
      return;
    }
    let funktion = this.getOrCreateFunction(...arguments);
    // TODO(cbruni): this should never happen, emit differen event from the
    // parser.
    if (funktion.parseTimestamp > 0) return;
    funktion.parseTimestamp = startOf(timestamp, duration);
    funktion.parseDuration = duration;
  }

  processParseFunction(
      scriptId, startPosition, endPosition, duration, timestamp, functionName) {
    let funktion = this.getOrCreateFunction(...arguments);
    funktion.parseTimestamp = startOf(timestamp, duration);
    funktion.parseDuration = duration;
  }

  processParseScript(
      scriptId, startPosition, endPosition, duration, timestamp, functionName) {
    // TODO timestamp and duration
    let script = this.lookupScript(scriptId);
    let ts = startOf(timestamp, duration);
    script.parseTimestamp = ts;
    script.parseDuration = duration;
    return script;
  }

  processPreparseResolution(
      scriptId, startPosition, endPosition, duration, timestamp, functionName) {
    let funktion = this.getOrCreateFunction(...arguments);
    // TODO(cbruni): this should never happen, emit different event from the
    // parser.
    if (funktion.resolutionTimestamp > 0) return;
    funktion.resolutionTimestamp = startOf(timestamp, duration);
    funktion.resolutionDuration = duration;
  }

  processPreparseNoResolution(
      scriptId, startPosition, endPosition, duration, timestamp, functionName) {
    let funktion = this.getOrCreateFunction(...arguments);
    funktion.preparseTimestamp = startOf(timestamp, duration);
    funktion.preparseDuration = duration;
  }

  processFirstExecution(
      scriptId, startPosition, endPosition, duration, timestamp, functionName) {
    let script = this.lookupScript(scriptId);
    if (startPosition === 0) {
      // undefined = eval fn execution
      if (script) {
        script.executionTimestamp = toTimestamp(timestamp);
      }
    } else {
      let funktion = script.getFunktionAtStartPosition(startPosition);
      if (funktion) {
        funktion.executionTimestamp = toTimestamp(timestamp);
      } else {
        // TODO(cbruni): handle funktions from  compilation-cache hits.
      }
    }
  }

  processCompileLazy(
      scriptId, startPosition, endPosition, duration, timestamp, functionName) {
    let funktion = this.getOrCreateFunction(...arguments);
    funktion.lazyCompileTimestamp = startOf(timestamp, duration);
    funktion.lazyCompileDuration = duration;
  }

  processCompile(
      scriptId, startPosition, endPosition, duration, timestamp, functionName) {
    let script = this.lookupScript(scriptId);
    if (startPosition === 0) {
      script.compileTimestamp = startOf(timestamp, duration);
      script.compileDuration = duration;
      script.bytesTotal = endPosition;
      return script;
    } else {
      let funktion = script.getFunktionAtStartPosition(startPosition);
      if (funktion === undefined) {
        // This should not happen since any funktion has to be parsed first.
        console.error('processCompile funktion not found', ...arguments);
        return;
      }
      funktion.compileTimestamp = startOf(timestamp, duration);
      funktion.compileDuration = duration;
      return funktion;
    }
  }

  processCompileEval(
      scriptId, startPosition, endPosition, duration, timestamp, functionName) {
    let compilationUnit = this.processCompile(...arguments);
    compilationUnit.isEval = true;
  }

  processBaselineLazy(
      scriptId, startPosition, endPosition, duration, timestamp, functionName) {
    let compilationUnit = this.lookupScript(scriptId);
    if (startPosition > 0) {
      compilationUnit =
          compilationUnit.getFunktionAtStartPosition(startPosition);
      if (compilationUnit === undefined) {
        // This should not happen since any funktion has to be parsed first.
        console.error('processBaselineLazy funktion not found', ...arguments);
        return;
      }
    }
    compilationUnit.baselineTimestamp = startOf(timestamp, duration);
    compilationUnit.baselineDuration = duration;
  }

  processOptimizeLazy(
      scriptId, startPosition, endPosition, duration, timestamp, functionName) {
    let compilationUnit = this.lookupScript(scriptId);
    if (startPosition > 0) {
      compilationUnit =
          compilationUnit.getFunktionAtStartPosition(startPosition);
      if (compilationUnit === undefined) {
        // This should not happen since any funktion has to be parsed first.
        console.error('processOptimizeLazy funktion not found', ...arguments);
        return;
      }
    }
    compilationUnit.optimizeTimestamp = startOf(timestamp, duration);
    compilationUnit.optimizeDuration = duration;
  }

  processDeserialize(
      scriptId, startPosition, endPosition, duration, timestamp, functionName) {
    let compilationUnit = this.lookupScript(scriptId);
    if (startPosition === 0) {
      compilationUnit.bytesTotal = endPosition;
    } else {
      compilationUnit = this.getOrCreateFunction(...arguments);
    }
    compilationUnit.deserializationTimestamp = startOf(timestamp, duration);
    compilationUnit.deserializationDuration = duration;
    compilationUnit.isDeserialized = true;
  }

  processCompilationCacheEvent(
      eventType, cacheType, scriptId, startPosition, endPosition, timestamp) {
    if (eventType !== 'hit') return;
    let compilationUnit = this.lookupScript(scriptId);
    if (startPosition > 0) {
      compilationUnit =
          compilationUnit.getFunktionAtStartPosition(startPosition);
    }
    compilationUnit.addCompilationCacheHit(toTimestamp(timestamp));
  }

}


export class ArgumentsProcessor extends BaseArgumentsProcessor {
  getArgsDispatch() {
    return {};
  }

  getDefaultResults() {
    return {
      logFileName: 'v8.log',
      range: 'auto,auto',
    };
  }
}
                                                                                                                                         node-23.7.0/deps/v8/tools/perf-compare.py                                                           0000775 0000000 0000000 00000027561 14746647661 0020155 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3
# Copyright 2017 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.
'''
python %prog

Compare perf trybot JSON files and output the results into a pleasing HTML page.
Examples:
  %prog -t "ia32 results" Result,../result.json Master,/path-to/master.json -o results.html
  %prog -t "x64 results" ../result.json master.json -o results.html
'''

# for py2/py3 compatibility
from __future__ import print_function

from collections import OrderedDict
import json
import math
from argparse import ArgumentParser
import os
import sys

PERCENT_CONSIDERED_SIGNIFICANT = 0.5
PROBABILITY_CONSIDERED_SIGNIFICANT = 0.02
PROBABILITY_CONSIDERED_MEANINGLESS = 0.05

class Statistics:
  @staticmethod
  def Mean(values):
    return float(sum(values)) / len(values)

  @staticmethod
  def Variance(values, average):
    return map(lambda x: (x - average) ** 2, values)

  @staticmethod
  def StandardDeviation(values, average):
    return math.sqrt(Statistics.Mean(Statistics.Variance(values, average)))

  @staticmethod
  def ComputeZ(baseline_avg, baseline_sigma, mean, n):
    if baseline_sigma == 0:
      return 1000.0;
    return abs((mean - baseline_avg) / (baseline_sigma / math.sqrt(n)))

  # Values from http://www.fourmilab.ch/rpkp/experiments/analysis/zCalc.html
  @staticmethod
  def ComputeProbability(z):
    if z > 2.575829: # p 0.005: two sided < 0.01
      return 0
    if z > 2.326348: # p 0.010
      return 0.01
    if z > 2.170091: # p 0.015
      return 0.02
    if z > 2.053749: # p 0.020
      return 0.03
    if z > 1.959964: # p 0.025: two sided < 0.05
      return 0.04
    if z > 1.880793: # p 0.030
      return 0.05
    if z > 1.811910: # p 0.035
      return 0.06
    if z > 1.750686: # p 0.040
      return 0.07
    if z > 1.695397: # p 0.045
      return 0.08
    if z > 1.644853: # p 0.050: two sided < 0.10
      return 0.09
    if z > 1.281551: # p 0.100: two sided < 0.20
      return 0.10
    return 0.20 # two sided p >= 0.20


class ResultsDiff:
  def __init__(self, significant, notable, percentage_string):
    self.significant_ = significant
    self.notable_ = notable
    self.percentage_string_ = percentage_string

  def percentage_string(self):
    return self.percentage_string_;

  def isSignificant(self):
    return self.significant_

  def isNotablyPositive(self):
    return self.notable_ > 0

  def isNotablyNegative(self):
    return self.notable_ < 0


class BenchmarkResult:
  def __init__(self, units, count, result, sigma):
    self.units_ = units
    self.count_ = float(count)
    self.result_ = float(result)
    self.sigma_ = float(sigma)

  def Compare(self, other):
    if self.units_ != other.units_:
      print ("Incompatible units: %s and %s" % (self.units_, other.units_))
      sys.exit(1)

    significant = False
    notable = 0
    percentage_string = ""
    # compute notability and significance.
    if self.units_ == "score":
      compare_num = 100*self.result_/other.result_ - 100
    else:
      compare_num = 100*other.result_/self.result_ - 100
    if abs(compare_num) > 0.1:
      percentage_string = "%3.1f" % (compare_num)
      z = Statistics.ComputeZ(other.result_, other.sigma_,
                              self.result_, self.count_)
      p = Statistics.ComputeProbability(z)
      if p < PROBABILITY_CONSIDERED_SIGNIFICANT:
        significant = True
      if compare_num >= PERCENT_CONSIDERED_SIGNIFICANT:
        notable = 1
      elif compare_num <= -PERCENT_CONSIDERED_SIGNIFICANT:
        notable = -1
    return ResultsDiff(significant, notable, percentage_string)

  def result(self):
    return self.result_

  def sigma(self):
    return self.sigma_


class Benchmark:
  def __init__(self, name):
    self.name_ = name
    self.runs_ = {}

  def name(self):
    return self.name_

  def getResult(self, run_name):
    return self.runs_.get(run_name)

  def appendResult(self, run_name, trace):
    values = map(float, trace['results'])
    count = len(values)
    mean = Statistics.Mean(values)
    stddev = float(trace.get('stddev') or
                   Statistics.StandardDeviation(values, mean))
    units = trace["units"]
    # print run_name, units, count, mean, stddev
    self.runs_[run_name] = BenchmarkResult(units, count, mean, stddev)


class BenchmarkSuite:
  def __init__(self, name):
    self.name_ = name
    self.benchmarks_ = {}

  def SortedTestKeys(self):
    keys = self.benchmarks_.keys()
    keys.sort()
    t = "Total"
    if t in keys:
      keys.remove(t)
      keys.append(t)
    return keys

  def name(self):
    return self.name_

  def getBenchmark(self, benchmark_name):
    benchmark_object = self.benchmarks_.get(benchmark_name)
    if benchmark_object is None:
      benchmark_object = Benchmark(benchmark_name)
      self.benchmarks_[benchmark_name] = benchmark_object
    return benchmark_object


class ResultTableRenderer:
  def __init__(self, output_file):
    self.benchmarks_ = []
    self.print_output_ = []
    self.output_file_ = output_file

  def Print(self, str_data):
    self.print_output_.append(str_data)

  def FlushOutput(self):
    string_data = "\n".join(self.print_output_)
    if self.output_file_:
      # create a file
      with open(self.output_file_, "w") as text_file:
        text_file.write(string_data)
    else:
      print(string_data)

  def bold(self, data):
    return "<b>%s</b>" % data

  def red(self, data):
    return "<font color=\"red\">%s</font>" % data


  def green(self, data):
    return "<font color=\"green\">%s</font>" % data

  def PrintHeader(self):
    data = """<html>
<head>
<title>Output</title>
<style type="text/css">
/*
Style inspired by Andy Ferra's gist at https://gist.github.com/andyferra/2554919
*/
body {
  font-family: Helvetica, arial, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  padding-top: 10px;
  padding-bottom: 10px;
  background-color: white;
  padding: 30px;
}
h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
  cursor: text;
  position: relative;
}
h1 {
  font-size: 28px;
  color: black;
}

h2 {
  font-size: 24px;
  border-bottom: 1px solid #cccccc;
  color: black;
}

h3 {
  font-size: 18px;
}

h4 {
  font-size: 16px;
}

h5 {
  font-size: 14px;
}

h6 {
  color: #777777;
  font-size: 14px;
}

p, blockquote, ul, ol, dl, li, table, pre {
  margin: 15px 0;
}

li p.first {
  display: inline-block;
}

ul, ol {
  padding-left: 30px;
}

ul :first-child, ol :first-child {
  margin-top: 0;
}

ul :last-child, ol :last-child {
  margin-bottom: 0;
}

table {
  padding: 0;
}

table tr {
  border-top: 1px solid #cccccc;
  background-color: white;
  margin: 0;
  padding: 0;
}

table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

table tr th {
  font-weight: bold;
  border: 1px solid #cccccc;
  text-align: left;
  margin: 0;
  padding: 6px 13px;
}
table tr td {
  border: 1px solid #cccccc;
  text-align: right;
  margin: 0;
  padding: 6px 13px;
}
table tr td.name-column {
  text-align: left;
}
table tr th :first-child, table tr td :first-child {
  margin-top: 0;
}
table tr th :last-child, table tr td :last-child {
  margin-bottom: 0;
}
</style>
</head>
<body>
"""
    self.Print(data)

  def StartSuite(self, suite_name, run_names):
    self.Print("<h2>")
    self.Print("<a name=\"%s\">%s</a> <a href=\"#top\">(top)</a>" %
               (suite_name, suite_name))
    self.Print("</h2>");
    self.Print("<table class=\"benchmark\">")
    self.Print("<thead>")
    self.Print("  <th>Test</th>")
    main_run = None
    for run_name in run_names:
      self.Print("  <th>%s</th>" % run_name)
      if main_run is None:
        main_run = run_name
      else:
        self.Print("  <th>%</th>")
    self.Print("</thead>")
    self.Print("<tbody>")


  def FinishSuite(self):
    self.Print("</tbody>")
    self.Print("</table>")


  def StartBenchmark(self, benchmark_name):
    self.Print("  <tr>")
    self.Print("    <td class=\"name-column\">%s</td>" % benchmark_name)

  def FinishBenchmark(self):
    self.Print("  </tr>")


  def PrintResult(self, run):
    if run is None:
      self.PrintEmptyCell()
      return
    self.Print("    <td>%3.1f</td>" % run.result())


  def PrintComparison(self, run, main_run):
    if run is None or main_run is None:
      self.PrintEmptyCell()
      return
    diff = run.Compare(main_run)
    res = diff.percentage_string()
    if diff.isSignificant():
      res = self.bold(res)
    if diff.isNotablyPositive():
      res = self.green(res)
    elif diff.isNotablyNegative():
      res = self.red(res)
    self.Print("    <td>%s</td>" % res)


  def PrintEmptyCell(self):
    self.Print("    <td></td>")


  def StartTOC(self, title):
    self.Print("<h1>%s</h1>" % title)
    self.Print("<ul>")

  def FinishTOC(self):
    self.Print("</ul>")

  def PrintBenchmarkLink(self, benchmark):
    self.Print("<li><a href=\"#" + benchmark + "\">" + benchmark + "</a></li>")

  def PrintFooter(self):
    data = """</body>
</html>
"""
    self.Print(data)


def Render(args):
  benchmark_suites = {}
  run_names = OrderedDict()

  for json_file_list in args.json_file_list:
    run_name = json_file_list[0]
    if run_name.endswith(".json"):
      # The first item in the list is also a file name
      run_name = os.path.splitext(run_name)[0]
      filenames = json_file_list
    else:
      filenames = json_file_list[1:]

    for filename in filenames:
      print ("Processing result set \"%s\", file: %s" % (run_name, filename))
      with open(filename) as json_data:
        data = json.load(json_data)

      run_names[run_name] = 0

      for error in data["errors"]:
        print("Error:", error)

      for trace in data["traces"]:
        suite_name = trace["graphs"][0]
        benchmark_name = "/".join(trace["graphs"][1:])

        benchmark_suite_object = benchmark_suites.get(suite_name)
        if benchmark_suite_object is None:
          benchmark_suite_object = BenchmarkSuite(suite_name)
          benchmark_suites[suite_name] = benchmark_suite_object

        benchmark_object = benchmark_suite_object.getBenchmark(benchmark_name)
        benchmark_object.appendResult(run_name, trace);


  renderer = ResultTableRenderer(args.output)
  renderer.PrintHeader()

  title = args.title or "Benchmark results"
  renderer.StartTOC(title)
  for suite_name, benchmark_suite_object in sorted(benchmark_suites.iteritems()):
    renderer.PrintBenchmarkLink(suite_name)
  renderer.FinishTOC()

  for suite_name, benchmark_suite_object in sorted(benchmark_suites.iteritems()):
    renderer.StartSuite(suite_name, run_names)
    for benchmark_name in benchmark_suite_object.SortedTestKeys():
      benchmark_object = benchmark_suite_object.getBenchmark(benchmark_name)
      # print suite_name, benchmark_object.name()

      renderer.StartBenchmark(benchmark_name)
      main_run = None
      main_result = None
      for run_name in run_names:
        result = benchmark_object.getResult(run_name)
        renderer.PrintResult(result)
        if main_run is None:
          main_run = run_name
          main_result = result
        else:
          renderer.PrintComparison(result, main_result)
      renderer.FinishBenchmark()
    renderer.FinishSuite()

  renderer.PrintFooter()
  renderer.FlushOutput()

def CommaSeparatedList(arg):
  return [x for x in arg.split(',')]

if __name__ == '__main__':
  parser = ArgumentParser(description="Compare perf trybot JSON files and " +
                          "output the results into a pleasing HTML page.")
  parser.add_argument("-t", "--title", dest="title",
                      help="Optional title of the web page")
  parser.add_argument("-o", "--output", dest="output",
                      help="Write html output to this file rather than stdout")
  parser.add_argument("json_file_list", nargs="+", type=CommaSeparatedList,
                      help="[column name,]./path-to/result.json - a comma-separated" +
                      " list of optional column name and paths to json files")

  args = parser.parse_args()
  Render(args)
                                                                                                                                               node-23.7.0/deps/v8/tools/perf/                                                                     0000775 0000000 0000000 00000000000 14746647661 0016141 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/perf/statistics-for-json.R                                                0000664 0000000 0000000 00000012005 14746647661 0022207 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # Copyright 2016 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

# Do statistical tests on benchmark results
# This script requires the libraries rjson, R.utils, ggplot2 and data.table
# Install them prior to running

# To use the script, first get some benchmark results, for example via
# tools/run_perf.py ../v8-perf/benchmarks/Octane2.1/Octane2.1-TF.json
#  --outdir=out/x64.release-on --outdir-secondary=out/x64.release-off
# --json-test-results=results-on.json
# --json-test-results-secondary=results-off.json
# then run this script
# Rscript statistics-for-json.R results-on.json results-off.json ~/SVG
# to produce graphs (and get stdio output of statistical tests).


suppressMessages(library("rjson"))       # for fromJson
suppressMessages(library("R.utils"))     # for printf
suppressMessages(library("ggplot2"))     # for plotting
suppressMessages(library("data.table"))  # less broken than data.frame

# Clear all variables from environment
rm(list=ls())

args <- commandArgs(TRUE)
if (length(args) != 3) {
  printf(paste("usage: Rscript %%this_script patched-results.json",
               "unpatched-results.json\n"))
} else {
  patch <- fromJSON(file=args[1])
  nopatch <- fromJSON(file=args[2])
  outputPath <- args[3]
  df <- data.table(L = numeric(), R = numeric(), E = numeric(), 
                   p.value = numeric(), yL = character(), 
                   p.value.sig = logical())
  
  for (i in seq(1, length(patch$traces))) {
    testName <- patch$traces[[i]]$graphs[[2]]
    printf("%s\n", testName)
    
    nopatch_res <- as.integer(nopatch$traces[[i]]$results)
    patch_res <- as.integer(patch$traces[[i]]$results)
    if (length(nopatch_res) > 0) {
      patch_norm <- shapiro.test(patch_res);
      nopatch_norm <- shapiro.test(nopatch_res);

      # Shaprio-Wilk test indicates whether data is not likely to 
      # come from a normal distribution. The p-value is the probability
      # to obtain the sample from a normal distribution. This means, the
      # smaller p, the more likely the sample was not drawn from a normal
      # distribution. See [wikipedia:Shapiro-Wilk-Test].
      printf("  Patched scores look %s distributed (W=%.4f, p=%.4f)\n", 
             ifelse(patch_norm$p.value < 0.05, "not normally", "normally"), 
             patch_norm$statistic, patch_norm$p.value);
      printf("  Unpatched scores look %s distributed (W=%.4f, p=%.4f)\n", 
             ifelse(nopatch_norm$p.value < 0.05, "not normally", "normally"), 
             nopatch_norm$statistic, nopatch_norm$p.value);
      
      hist <- ggplot(data=data.frame(x=as.integer(patch_res)), aes(x)) +
        theme_bw() + 
        geom_histogram(bins=50) +
        ylab("Points") +
        xlab(patch$traces[[i]]$graphs[[2]])
      ggsave(filename=sprintf("%s/%s.svg", outputPath, testName), 
             plot=hist, width=7, height=7)
      
      hist <- ggplot(data=data.frame(x=as.integer(nopatch_res)), aes(x)) +
        theme_bw() + 
        geom_histogram(bins=50) +
        ylab("Points") +
        xlab(patch$traces[[i]]$graphs[[2]])
      ggsave(filename=sprintf("%s/%s-before.svg", outputPath, testName), 
             plot=hist, width=7, height=7)
      
      # The Wilcoxon rank-sum test 
      mww <- wilcox.test(patch_res, nopatch_res, conf.int = TRUE, exact=TRUE)
      printf(paste("  Wilcoxon U-test W=%.4f, p=%.4f,",
                   "confidence interval [%.1f, %.1f],",
                   "est. effect size %.1f \n"),
                   mww$statistic, mww$p.value,
                   mww$conf.int[1], mww$conf.int[2], mww$estimate);
      df <-rbind(df, list(mww$conf.int[1], mww$conf.int[2], 
                          unname(mww$estimate), unname(mww$p.value),
                          testName, ifelse(mww$p.value < 0.05, TRUE, FALSE)))
      # t-test
      t <- t.test(patch_res, nopatch_res, paired=FALSE)
      printf(paste("  Welch t-test t=%.4f, df = %.2f, p=%.4f,",
                   "confidence interval [%.1f, %.1f], mean diff %.1f \n"),
             t$statistic, t$parameter, t$p.value, 
             t$conf.int[1], t$conf.int[2], t$estimate[1]-t$estimate[2]);
    }
  }
  df2 <- cbind(x=1:nrow(df), df[order(E),])
  speedup <- ggplot(df2, aes(x = x, y = E, colour=p.value.sig)) +
    geom_errorbar(aes(ymax = L, ymin = R), colour="black") +
    geom_point(size = 4) +
    scale_x_discrete(limits=df2$yL,
                       name=paste("Benchmark, n=", length(patch_res))) +
    theme_bw() +
    geom_hline(yintercept = 0) +
    ylab("Est. Effect Size in Points") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust=0.5)) +
    theme(legend.position = "bottom") +
    scale_colour_manual(name="Statistical Significance (MWW, p < 0.05)",
                          values=c("red", "green"),
                          labels=c("not significant", "significant")) +
    theme(legend.justification=c(0,1), legend.position=c(0,1))
  print(speedup)
  ggsave(filename=sprintf("%s/speedup-estimates.svg", outputPath), 
         plot=speedup, width=7, height=7)
}
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           node-23.7.0/deps/v8/tools/predictable_wrapper.py                                                    0000664 0000000 0000000 00000004471 14746647661 0021603 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3
# Copyright 2017 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

"""
Wrapper script for verify-predictable mode. D8 is expected to be compiled with
v8_enable_verify_predictable.

The actual test command is expected to be passed to this wraper as is. E.g.:
predictable_wrapper.py path/to/d8 --test --predictable --flag1 --flag2

The command is run up to three times and the printed allocation hash is
compared. Differences are reported as errors.
"""

import sys

from testrunner.local import command
from testrunner.local import utils


MAX_TRIES = 3
TIMEOUT = 120

# Predictable mode works only when run on the host os.
command.setup(utils.GuessOS(), None)

def maybe_decode(message):
  if not isinstance(message, str):
    return message.decode()
  return message


def main(args):
  def allocation_str(stdout):
    for line in reversed((stdout or '').splitlines()):
      if maybe_decode(line).startswith('### Allocations = '):
        return line
    return None

  cmd = command.Command(
      args[0], args[1:], timeout=TIMEOUT, handle_sigterm=True)

  previous_allocations = None
  for run in range(1, MAX_TRIES + 1):
    print('### Predictable run #%d' % run)
    output = cmd.execute()
    if output.stdout:
      print('### Stdout:')
      print(output.stdout)
    if output.stderr:
      print('### Stderr:')
      print(output.stderr)
    print('### Return code: %s' % output.exit_code)
    if output.HasTimedOut():
      # If we get a timeout in any run, we are in an unpredictable state. Just
      # report it as a failure and don't rerun.
      print('### Test timed out')
      return 1
    allocations = allocation_str(output.stdout)
    if not allocations:
      print ('### Test had no allocation output. Ensure this is built '
             'with v8_enable_verify_predictable and that '
             '--verify-predictable is passed at the cmd line.')
      return 2
    if previous_allocations and previous_allocations != allocations:
      print('### Allocations differ')
      return 3
    if run >= MAX_TRIES:
      # No difference on the last run -> report a success.
      return 0
    previous_allocations = allocations
  # Unreachable.
  assert False


if __name__ == '__main__':
  sys.exit(main(sys.argv[1:]))
                                                                                                                                                                                                       node-23.7.0/deps/v8/tools/process-wasm-compilation-times.py                                         0000775 0000000 0000000 00000010177 14746647661 0023646 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3
# Copyright 2021 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

# Processes {stdout} output generated by --trace-wasm-compilation-times
# for easier consumption by human readers.

import sys

def SizeInternal(number, suffix):
  if suffix == "": return "%d" % number
  if number < 10: return "%.1f%s" % (number, suffix)
  return "%d%s" % (number, suffix)

def Size(number):
  if (number < 1024): return SizeInternal(number, "")
  number /= 1024
  if (number < 1024): return SizeInternal(number, "K")
  number /= 1024
  if (number < 1024): return SizeInternal(number, "M")
  number /= 1024
  if (number < 1024): return SizeInternal(number, "G")
  return SizeInternal(number / 1024, "T")

modules = {}
max_module = 0
total_lo_time = 0
total_lo_size = 0
total_tf_time = 0
total_tf_size = 0

def RegisterName(raw):
  global max_module
  parts = raw.split("#")
  m = parts[0]
  if m not in modules:
    modules[m] = max_module
    max_module += 1

def Name(raw):
  parts = raw.split("#")
  if len(modules) == 1: return "#%s" % parts[1]
  return "m%d#%s" % (modules[parts[0]], parts[1])

class Function:
  def __init__(self, index):
    self.index = index
    self.has_lo = False
    self.has_tf = False
    self.time_lo = -1
    self.time_tf = -1
    self.mem_lo = -1
    self.mem_tf_max = -1
    self.mem_tf_total = -1
    self.name = ""
    self.size_wasm = -1
    self.size_lo = -1
    self.size_tf = -1

  def AddLine(self, words):
    assert self.index == words[2], "wrong function"
    if words[4] == "TurboFan,":
      self.AddTFLine(words)
    elif words[4] == "Liftoff,":
      self.AddLiftoffLine(words)
    else:
      raise Exception("unknown compiler: %s" % words[4])

  def AddTFLine(self, words):
    assert not self.has_tf, "duplicate TF line for %s" % self.index
    self.has_tf = True
    # 0        1        2  3     4         5    6 7  8   9     10 11
    # Compiled function #6 using TurboFan, took 0 ms and 14440 / 44656
    # 12        13     14       15 16       17 18   19
    # max/total bytes; bodysize 12 codesize 24 name wasm-function#6
    self.time_tf = int(words[6])
    self.mem_tf_max = int(words[9])
    self.mem_tf_total = int(words[11])
    self.size_tf = int(words[17])
    self.name = words[19]

  def AddLiftoffLine(self, words):
    assert self.index == words[2], "wrong function"
    assert not self.has_lo, "duplicate Liftoff line for %s" % self.index
    self.has_lo = True
    # 0        1        2  3     4        5    6 7  8   9   10     11       12
    # Compiled function #6 using Liftoff, took 0 ms and 968 bytes; bodysize 4
    # 13       14
    # codesize 68
    self.time_lo = int(words[6])
    self.mem_lo = int(words[9])
    self.size_lo = int(words[14])
    self.size_wasm = int(words[12])

  def __str__(self):
    return "%s: time %d %d mem %s %s %s size %s %s %s name %s" % (
      Name(self.index), self.time_lo, self.time_tf,
      Size(self.mem_lo), Size(self.mem_tf_max), Size(self.mem_tf_total),
      Size(self.size_wasm), Size(self.size_lo), Size(self.size_tf), self.name
    )

funcs_dict = {}
funcs_list = []

if len(sys.argv) < 2 or sys.argv[1] in ("-h", "--help", "help"):
  print("Pass output file (generated with --trace-wasm-compilation-times) as "
        "argument")
  sys.exit(1)

with open(sys.argv[1], "r") as f:
  for line in f.readlines():
    words = line.strip().split(" ")
    if words[0] != "Compiled" or words[1] != "function":
      continue
    name = words[2]
    RegisterName(name)
    if name in funcs_dict:
      func = funcs_dict[name]
    else:
      func = Function(name)
      funcs_dict[name] = func
      funcs_list.append(func)
    func.AddLine(words)

funcs_list.sort(key=lambda fun: fun.time_tf)
for f in funcs_list:
  print(f)
  if f.time_tf > 0:
    total_tf_time += f.time_tf
  if f.size_tf > 0:
    total_tf_size += f.size_tf
  if f.time_lo > 0:
    total_lo_time += f.time_lo
  if f.size_lo > 0:
    total_lo_size += f.size_lo

print("Total TF time: %d" % total_tf_time)
print("Total TF size: %d" % total_tf_size)
print("Total LO time: %d" % total_lo_time)
print("Total LO size: %d" % total_lo_size)
                                                                                                                                                                                                                                                                                                                                                                                                 node-23.7.0/deps/v8/tools/profile.mjs                                                               0000664 0000000 0000000 00000120271 14746647661 0017363 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2009 the V8 project authors. All rights reserved.
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met:
//
//     * Redistributions of source code must retain the above copyright
//       notice, this list of conditions and the following disclaimer.
//     * Redistributions in binary form must reproduce the above
//       copyright notice, this list of conditions and the following
//       disclaimer in the documentation and/or other materials provided
//       with the distribution.
//     * Neither the name of Google Inc. nor the names of its
//       contributors may be used to endorse or promote products derived
//       from this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

import { CodeMap, CodeEntry } from "./codemap.mjs";
import { ConsArray } from "./consarray.mjs";
import { WebInspector } from "./sourcemap.mjs";

// Used to associate log entries with source positions in scripts.
// TODO: move to separate modules
export class SourcePosition {
  script = null;
  line = -1;
  column = -1;
  entries = [];
  isFunction = false;
  originalPosition = undefined;

  constructor(script, line, column) {
    this.script = script;
    this.line = line;
    this.column = column;
  }

  addEntry(entry) {
    this.entries.push(entry);
  }

  toString() {
    return `${this.script.name}:${this.line}:${this.column}`;
  }

  get functionPosition() {
    // TODO(cbruni)
    return undefined;
  }

  get toolTipDict() {
    return {
      title: this.toString(),
      __this__: this,
      script: this.script,
      entries: this.entries,
    }
  }
}

export class Script {
  url;
  source = "";
  name;
  sourcePosition = undefined;
  // Map<line, Map<column, SourcePosition>>
  lineToColumn = new Map();
  _entries = [];
  _sourceMapState = "unknown";

  constructor(id) {
    this.id = id;
    this.sourcePositions = [];
  }

  update(url, source) {
    this.url = url;
    this.name = Script.getShortestUniqueName(url, this);
    this.source = source;
  }

  get length() {
    return this.source.length;
  }

  get entries() {
    return this._entries;
  }

  get startLine() {
    return this.sourcePosition?.line ?? 1;
  }

  get sourceMapState() {
    return this._sourceMapState;
  }

  findFunctionSourcePosition(sourcePosition) {
    // TODO(cbruni): implement
    return undefined;
  }

  addSourcePosition(line, column, entry) {
    let sourcePosition = this.lineToColumn.get(line)?.get(column);
    if (sourcePosition === undefined) {
      sourcePosition = new SourcePosition(this, line, column,)
      this._addSourcePosition(line, column, sourcePosition);
    }
    if (this.sourcePosition === undefined && entry.entry?.type === "Script") {
      // Mark the source position of scripts, for inline scripts which don't
      // start at line 1.
      this.sourcePosition = sourcePosition;
    }
    sourcePosition.addEntry(entry);
    this._entries.push(entry);
    return sourcePosition;
  }

  _addSourcePosition(line, column, sourcePosition) {
    let columnToSourcePosition;
    if (this.lineToColumn.has(line)) {
      columnToSourcePosition = this.lineToColumn.get(line);
    } else {
      columnToSourcePosition = new Map();
      this.lineToColumn.set(line, columnToSourcePosition);
    }
    this.sourcePositions.push(sourcePosition);
    columnToSourcePosition.set(column, sourcePosition);
  }

  toString() {
    return `Script(${this.id}): ${this.name}`;
  }

  get toolTipDict() {
    return {
      title: this.toString(),
      __this__: this,
      id: this.id,
      url: this.url,
      source: this.source,
      sourcePositions: this.sourcePositions
    }
  }

  static getShortestUniqueName(url, script) {
    const parts = url.split('/');
    const filename = parts[parts.length -1];
    const dict = this._dict ?? (this._dict = new Map());
    const matchingScripts = dict.get(filename);
    if (matchingScripts == undefined) {
      dict.set(filename, [script]);
      return filename;
    }
    // TODO: find shortest unique substring
    // Update all matching scripts to have a unique filename again.
    for (let matchingScript of matchingScripts) {
      matchingScript.name = script.url
    }
    matchingScripts.push(script);
    return url;
  }

  ensureSourceMapCalculated(sourceMapFetchPrefix=undefined) {
    if (this._sourceMapState !== "unknown") return;

    const sourceMapURLMatch =
        this.source.match(/\/\/# sourceMappingURL=(.*)\n/);
    if (!sourceMapURLMatch) {
      this._sourceMapState = "none";
      return;
    }

    this._sourceMapState = "loading";
    let sourceMapURL = sourceMapURLMatch[1];
    (async () => {
      try {
        let sourceMapPayload;
        const options = { timeout: 15 };
        try {
          sourceMapPayload = await fetch(sourceMapURL, options);
        } catch (e) {
          if (e instanceof TypeError && sourceMapFetchPrefix) {
            // Try again with fetch prefix.
            // TODO(leszeks): Remove the retry once the prefix is
            // configurable.
            sourceMapPayload =
                await fetch(sourceMapFetchPrefix + sourceMapURL, options);
          } else {
            throw e;
          }
        }
        sourceMapPayload = await sourceMapPayload.text();

        if (sourceMapPayload.startsWith(')]}')) {
          sourceMapPayload =
              sourceMapPayload.substring(sourceMapPayload.indexOf('\n'));
        }
        sourceMapPayload = JSON.parse(sourceMapPayload);
        const sourceMap =
            new WebInspector.SourceMap(sourceMapURL, sourceMapPayload);

        const startLine = this.startLine;
        for (const sourcePosition of this.sourcePositions) {
          const line = sourcePosition.line - startLine;
          const column = sourcePosition.column - 1;
          const mapping = sourceMap.findEntry(line, column);
          if (mapping) {
            sourcePosition.originalPosition = {
              source: new URL(mapping[2], sourceMapURL).href,
              line: mapping[3] + 1,
              column: mapping[4] + 1
            };
          } else {
            sourcePosition.originalPosition = {source: null, line:0, column:0};
          }
        }
        this._sourceMapState = "loaded";
      } catch (e) {
        console.error(e);
        this._sourceMapState = "failed";
      }
    })();
  }
}


const kOffsetPairRegex = /C([0-9]+)O([0-9]+)/g;
class SourcePositionTable {
  constructor(encodedTable) {
    this._offsets = [];
    while (true) {
      const regexResult = kOffsetPairRegex.exec(encodedTable);
      if (!regexResult) break;
      const codeOffset = parseInt(regexResult[1]);
      const scriptOffset = parseInt(regexResult[2]);
      if (isNaN(codeOffset) || isNaN(scriptOffset)) continue;
      this._offsets.push({code: codeOffset, script: scriptOffset});
    }
  }

  getScriptOffset(codeOffset) {
    if (codeOffset < 0) {
      throw new Exception(`Invalid codeOffset=${codeOffset}, should be >= 0`);
    }
    for (let i = this.offsetTable.length - 1; i >= 0; i--) {
      const offset = this._offsets[i];
      if (offset.code <= codeOffset) {
        return offset.script;
      }
    }
    return this._offsets[0].script;
  }
}


class SourceInfo {
  script;
  start;
  end;
  positions;
  inlined;
  fns;
  disassemble;

  setSourcePositionInfo(
        script, startPos, endPos, sourcePositionTableData, inliningPositions,
        inlinedSFIs) {
    this.script = script;
    this.start = startPos;
    this.end = endPos;
    this.positions = sourcePositionTableData;
    this.inlined = inliningPositions;
    this.fns = inlinedSFIs;
    this.sourcePositionTable = new SourcePositionTable(sourcePositionTableData);
  }

  get sfis() {
    return this.fns;
  }

  setDisassemble(code) {
    this.disassemble = code;
  }

  getSourceCode() {
    return this.script.source?.substring(this.start, this.end);
  }
}

const kProfileOperationMove = 0;
const kProfileOperationDelete = 1;
const kProfileOperationTick = 2;

/**
 * Creates a profile object for processing profiling-related events
 * and calculating function execution times.
 *
 * @constructor
 */
export class Profile {
  topDownTree_ = new CallTree();
  bottomUpTree_ = new CallTree();
  c_entries_ = {__proto__:null};
  scripts_ = [];
  urlToScript_ = new Map();
  warnings = new Set();

  constructor(useBigIntAddresses=false) {
    this.useBigIntAddresses = useBigIntAddresses;
    this.codeMap_ = new CodeMap(useBigIntAddresses);
  }

  serializeVMSymbols() {
    let result = this.codeMap_.getAllStaticEntriesWithAddresses();
    result.concat(this.codeMap_.getAllLibraryEntriesWithAddresses())
    return result.map(([startAddress, codeEntry]) => {
      return [codeEntry.getName(), startAddress, startAddress + codeEntry.size]
    });
  }

  /**
   * Returns whether a function with the specified name must be skipped.
   * Should be overridden by subclasses.
   *
   * @param {string} name Function name.
   */
  skipThisFunction(name) {
    return false;
  }

  /**
   * Enum for profiler operations that involve looking up existing
   * code entries.
   *
   * @enum {number}
   */
  static Operation = {
    MOVE: kProfileOperationMove,
    DELETE: kProfileOperationDelete,
    TICK: kProfileOperationTick
  }

  /**
   * Enum for code state regarding its dynamic optimization.
   *
   * @enum {number}
   */
  static CodeState = {
    COMPILED: 0,
    IGNITION: 1,
    SPARKPLUG: 2,
    MAGLEV: 4,
    TURBOFAN: 5,
  }

  static VMState = {
    JS: 0,
    GC: 1,
    PARSER: 2,
    BYTECODE_COMPILER: 3,
    // TODO(cbruni): add SPARKPLUG_COMPILER
    COMPILER: 4,
    OTHER: 5,
    EXTERNAL: 6,
    IDLE: 7,
  }

  static CodeType = {
    CPP: 0,
    SHARED_LIB: 1
  }

  /**
   * Parser for dynamic code optimization state.
   */
  static parseState(s) {
    switch (s) {
      case '':
        return this.CodeState.COMPILED;
      case '~':
        return this.CodeState.IGNITION;
      case '^':
        return this.CodeState.SPARKPLUG;
      case '+':
        return this.CodeState.MAGLEV;
      case '*':
        return this.CodeState.TURBOFAN;
    }
    throw new Error(`unknown code state: ${s}`);
  }

  static getKindFromState(state) {
    if (state === this.CodeState.COMPILED) {
      return "Builtin";
    } else if (state === this.CodeState.IGNITION) {
      return "Unopt";
    } else if (state === this.CodeState.SPARKPLUG) {
      return "Sparkplug";
    } else if (state === this.CodeState.MAGLEV) {
      return "Maglev";
    } else if (state === this.CodeState.TURBOFAN) {
      return "Opt";
    }
    throw new Error(`unknown code state: ${state}`);
  }

  static vmStateString(state) {
    switch (state) {
      case this.VMState.JS:
        return 'JS';
      case this.VMState.GC:
        return 'GC';
      case this.VMState.PARSER:
        return 'Parse';
      case this.VMState.BYTECODE_COMPILER:
        return 'Compile Bytecode';
      case this.VMState.COMPILER:
        return 'Compile';
      case this.VMState.OTHER:
        return 'Other';
      case this.VMState.EXTERNAL:
        return 'External';
      case this.VMState.IDLE:
        return 'Idle';
    }
    return 'unknown';
  }

  /**
   * Called whenever the specified operation has failed finding a function
   * containing the specified address. Should be overridden by subclasses.
   * See the Profile.Operation enum for the list of
   * possible operations.
   *
   * @param {number} operation Operation.
   * @param {number} addr Address of the unknown code.
   * @param {number} opt_stackPos If an unknown address is encountered
   *     during stack strace processing, specifies a position of the frame
   *     containing the address.
   */
  handleUnknownCode(operation, addr, opt_stackPos) { }

  /**
   * Registers a library.
   *
   * @param {string} name Code entry name.
   * @param {number} startAddr Starting address.
   * @param {number} endAddr Ending address.
   */
  addLibrary(name, startAddr, endAddr) {
    const entry = new CodeEntry(endAddr - startAddr, name, 'SHARED_LIB');
    this.codeMap_.addLibrary(startAddr, entry);
    return entry;
  }

  /**
   * Registers statically compiled code entry.
   *
   * @param {string} name Code entry name.
   * @param {number} startAddr Starting address.
   * @param {number} endAddr Ending address.
   */
  addStaticCode(name, startAddr, endAddr) {
    const entry = new CodeEntry(endAddr - startAddr, name, 'CPP');
    this.codeMap_.addStaticCode(startAddr, entry);
    return entry;
  }

  /**
   * Registers dynamic (JIT-compiled) code entry.
   *
   * @param {string} type Code entry type.
   * @param {string} name Code entry name.
   * @param {number} start Starting address.
   * @param {number} size Code entry size.
   */
  addCode(type, name, timestamp, start, size) {
    const entry = new DynamicCodeEntry(size, type, name);
    this.codeMap_.addCode(start, entry);
    return entry;
  }

  /**
   * Registers dynamic (JIT-compiled) code entry or entries that overlap with
   * static entries (like builtins).
   *
   * @param {string} type Code entry type.
   * @param {string} name Code entry name.
   * @param {number} start Starting address.
   * @param {number} size Code entry size.
   */
  addAnyCode(type, name, timestamp, start, size) {
    const entry = new DynamicCodeEntry(size, type, name);
    this.codeMap_.addAnyCode(start, entry);
    return entry;
  }

  /**
   * Registers dynamic (JIT-compiled) code entry.
   *
   * @param {string} type Code entry type.
   * @param {string} name Code entry name.
   * @param {number} start Starting address.
   * @param {number} size Code entry size.
   * @param {number} sfiAddr Shared function object address.
   * @param {Profile.CodeState} state Optimization state.
   */
  addFuncCode(type, name, timestamp, start, size, sfiAddr, state) {
    // As code and functions are in the same address space,
    // it is safe to put them in a single code map.
    let sfi = this.codeMap_.findDynamicEntryByStartAddress(sfiAddr);
    // Overwrite any old (unused) code objects that overlap with the new SFI.
    const new_sfi_old_code = !(sfi instanceof SharedFunctionInfoEntry)
    if (sfi === null || new_sfi_old_code) {
      sfi = new SharedFunctionInfoEntry(name, this.useBigIntAddresses);
      this.codeMap_.addCode(sfiAddr, sfi);
    } else if (sfi.name !== name) {
      // SFI object has been overwritten with a new one.
      sfi.name = name;
    }
    let entry = this.codeMap_.findDynamicEntryByStartAddress(start);
    if (entry !== null) {
      if (entry.size === size && entry.sfi === sfi) {
        // Entry state has changed.
        entry.state = state;
      } else {
        this.codeMap_.deleteCode(start);
        entry = null;
      }
    }
    if (entry === null) {
      entry = new DynamicFuncCodeEntry(size, type, sfi, state);
      this.codeMap_.addCode(start, entry);
    }
    return entry;
  }

  /**
   * Reports about moving of a dynamic code entry.
   *
   * @param {number} from Current code entry address.
   * @param {number} to New code entry address.
   */
  moveCode(from, to) {
    try {
      this.codeMap_.moveCode(from, to);
    } catch (e) {
      this.handleUnknownCode(kProfileOperationMove, from);
    }
  }

  deoptCode(timestamp, code, inliningId, scriptOffset, bailoutType,
    sourcePositionText, deoptReasonText) {
  }

  /**
   * Reports about deletion of a dynamic code entry.
   *
   * @param {number} start Starting address.
   */
  deleteCode(start) {
    try {
      this.codeMap_.deleteCode(start);
    } catch (e) {
      this.handleUnknownCode(kProfileOperationDelete, start);
    }
  }

  /**
   * Adds source positions for given code.
   */
  addSourcePositions(start, scriptId, startPos, endPos, sourcePositionTable,
        inliningPositions, inlinedSFIs) {
    const script = this.getOrCreateScript(scriptId);
    const entry = this.codeMap_.findDynamicEntryByStartAddress(start);
    if (entry === null) return;
    // Resolve the inlined SharedFunctionInfo list.
    if (inlinedSFIs.length > 0) {
      inlinedSFIs = inlinedSFIs.substring(1).split("S");
      for (let i = 0; i < inlinedSFIs.length; i++) {
        const sfiAddr = parseInt(inlinedSFIs[i]);
        const sfi = this.codeMap_.findDynamicEntryByStartAddress(sfiAddr);
        if (sfi === null || sfi.funcId === undefined) {
          // TODO: fix
          this.warnings.add(`Could not find function ${inlinedSFIs[i]}`);
          inlinedSFIs[i] = null;
        } else {
          inlinedSFIs[i] = sfi.funcId;
        }
      }
    } else {
      inlinedSFIs = [];
    }

    this.getOrCreateSourceInfo(entry).setSourcePositionInfo(
      script, startPos, endPos, sourcePositionTable, inliningPositions,
      inlinedSFIs);
  }

  addDisassemble(start, kind, disassemble) {
    const entry = this.codeMap_.findDynamicEntryByStartAddress(start);
    if (entry !== null) {
      this.getOrCreateSourceInfo(entry).setDisassemble(disassemble);
    }
    return entry;
  }

  getOrCreateSourceInfo(entry) {
    return entry.source ?? (entry.source = new SourceInfo());
  }

  addScriptSource(id, url, source) {
    const script = this.getOrCreateScript(id);
    script.update(url, source);
    this.urlToScript_.set(url, script);
  }

  getOrCreateScript(id) {
    let script = this.scripts_[id];
    if (script === undefined) {
      script = new Script(id);
      this.scripts_[id] = script;
    }
    return script;
  }

  getScript(url) {
    return this.urlToScript_.get(url);
  }

  /**
   * Reports about moving of a dynamic code entry.
   *
   * @param {number} from Current code entry address.
   * @param {number} to New code entry address.
   */
  moveSharedFunctionInfo(from, to) {
    if (this.codeMap_.findDynamicEntryByStartAddress(from)) {
      this.codeMap_.moveCode(from, to);
    }
  }

  /**
   * Retrieves a code entry by an address.
   *
   * @param {number} addr Entry address.
   */
  findEntry(addr) {
    return this.codeMap_.findEntry(addr);
  }

  /**
   * Records a tick event. Stack must contain a sequence of
   * addresses starting with the program counter value.
   *
   * @param {number[]} stack Stack sample.
   */
  recordTick(time_ns, vmState, stack) {
    const {nameStack, entryStack} = this.resolveAndFilterFuncs_(stack);
    this.bottomUpTree_.addPath(nameStack);
    nameStack.reverse();
    this.topDownTree_.addPath(nameStack);
    return entryStack;
  }

  /**
   * Translates addresses into function names and filters unneeded
   * functions.
   *
   * @param {number[]} stack Stack sample.
   */
  resolveAndFilterFuncs_(stack) {
    const nameStack = [];
    const entryStack = [];
    let last_seen_c_function = '';
    let look_for_first_c_function = false;
    for (let i = 0; i < stack.length; ++i) {
      const pc = stack[i];
      const entry = this.codeMap_.findEntry(pc);
      if (entry !== null) {
        entryStack.push(entry);
        const name = entry.getName();
        if (i === 0 && (entry.type === 'CPP' || entry.type === 'SHARED_LIB')) {
          look_for_first_c_function = true;
        }
        if (look_for_first_c_function && entry.type === 'CPP') {
          last_seen_c_function = name;
        }
        if (!this.skipThisFunction(name)) {
          nameStack.push(name);
        }
      } else {
        this.handleUnknownCode(kProfileOperationTick, pc, i);
        if (i === 0) nameStack.push("UNKNOWN");
        entryStack.push(pc);
      }
      if (look_for_first_c_function && i > 0 &&
          (entry === null || entry.type !== 'CPP')
          && last_seen_c_function !== '') {
        if (this.c_entries_[last_seen_c_function] === undefined) {
          this.c_entries_[last_seen_c_function] = 0;
        }
        this.c_entries_[last_seen_c_function]++;
        look_for_first_c_function = false;  // Found it, we're done.
      }
    }
    return {nameStack, entryStack};
  }

  /**
   * Performs a BF traversal of the top down call graph.
   *
   * @param {function(CallTreeNode)} f Visitor function.
   */
  traverseTopDownTree(f) {
    this.topDownTree_.traverse(f);
  }

  /**
   * Performs a BF traversal of the bottom up call graph.
   *
   * @param {function(CallTreeNode)} f Visitor function.
   */
  traverseBottomUpTree(f) {
    this.bottomUpTree_.traverse(f);
  }

  /**
   * Calculates a top down profile for a node with the specified label.
   * If no name specified, returns the whole top down calls tree.
   *
   * @param {string} opt_label Node label.
   */
  getTopDownProfile(opt_label) {
    return this.getTreeProfile_(this.topDownTree_, opt_label);
  }

  /**
   * Calculates a bottom up profile for a node with the specified label.
   * If no name specified, returns the whole bottom up calls tree.
   *
   * @param {string} opt_label Node label.
   */
  getBottomUpProfile(opt_label) {
    return this.getTreeProfile_(this.bottomUpTree_, opt_label);
  }

  /**
   * Helper function for calculating a tree profile.
   *
   * @param {Profile.CallTree} tree Call tree.
   * @param {string} opt_label Node label.
   */
  getTreeProfile_(tree, opt_label) {
    if (!opt_label) {
      tree.computeTotalWeights();
      return tree;
    } else {
      const subTree = tree.cloneSubtree(opt_label);
      subTree.computeTotalWeights();
      return subTree;
    }
  }

  /**
   * Calculates a flat profile of callees starting from a node with
   * the specified label. If no name specified, starts from the root.
   *
   * @param {string} opt_label Starting node label.
   */
  getFlatProfile(opt_label) {
    const counters = new CallTree();
    const rootLabel = opt_label || CallTree.ROOT_NODE_LABEL;
    const precs = {__proto__:null};
    precs[rootLabel] = 0;
    const root = counters.findOrAddChild(rootLabel);

    this.topDownTree_.computeTotalWeights();
    this.topDownTree_.traverseInDepth(
      function onEnter(node) {
        if (!(node.label in precs)) {
          precs[node.label] = 0;
        }
        const nodeLabelIsRootLabel = node.label == rootLabel;
        if (nodeLabelIsRootLabel || precs[rootLabel] > 0) {
          if (precs[rootLabel] == 0) {
            root.selfWeight += node.selfWeight;
            root.totalWeight += node.totalWeight;
          } else {
            const rec = root.findOrAddChild(node.label);
            rec.selfWeight += node.selfWeight;
            if (nodeLabelIsRootLabel || precs[node.label] == 0) {
              rec.totalWeight += node.totalWeight;
            }
          }
          precs[node.label]++;
        }
      },
      function onExit(node) {
        if (node.label == rootLabel || precs[rootLabel] > 0) {
          precs[node.label]--;
        }
      },
      null);

    if (!opt_label) {
      // If we have created a flat profile for the whole program, we don't
      // need an explicit root in it. Thus, replace the counters tree
      // root with the node corresponding to the whole program.
      counters.root_ = root;
    } else {
      // Propagate weights so percents can be calculated correctly.
      counters.getRoot().selfWeight = root.selfWeight;
      counters.getRoot().totalWeight = root.totalWeight;
    }
    return counters;
  }

  getCEntryProfile() {
    const result = [new CEntryNode("TOTAL", 0)];
    let total_ticks = 0;
    for (let f in this.c_entries_) {
      const ticks = this.c_entries_[f];
      total_ticks += ticks;
      result.push(new CEntryNode(f, ticks));
    }
    result[0].ticks = total_ticks;  // Sorting will keep this at index 0.
    result.sort((n1, n2) => n2.ticks - n1.ticks || (n2.name < n1.name ? -1 : 1));
    return result;
  }


  /**
   * Cleans up function entries that are not referenced by code entries.
   */
  cleanUpFuncEntries() {
    const referencedFuncEntries = [];
    const entries = this.codeMap_.getAllDynamicEntriesWithAddresses();
    for (let i = 0, l = entries.length; i < l; ++i) {
      if (entries[i][1].constructor === SharedFunctionInfoEntry) {
        entries[i][1].used = false;
      }
    }
    for (let i = 0, l = entries.length; i < l; ++i) {
      if ("sfi" in entries[i][1]) {
        entries[i][1].sfi.used = true;
      }
    }
    for (let i = 0, l = entries.length; i < l; ++i) {
      if (entries[i][1].constructor === SharedFunctionInfoEntry &&
        !entries[i][1].used) {
        this.codeMap_.deleteCode(entries[i][0]);
      }
    }
  }
}

class CEntryNode {
  constructor(name, ticks) {
    this.name = name;
    this.ticks = ticks;
  }
}


/**
 * Creates a dynamic code entry.
 *
 * @param {number} size Code size.
 * @param {string} type Code type.
 * @param {string} name Function name.
 * @constructor
 */
class DynamicCodeEntry extends CodeEntry {
  constructor(size, type, name) {
    super(size, name, type);
  }

  getName() {
    return this.type + ': ' + this.name;
  }

  /**
   * Returns raw node name (without type decoration).
   */
  getRawName() {
    return this.name;
  }

  isJSFunction() {
    return false;
  }

  toString() {
    return this.getName() + ': ' + this.size.toString(16);
  }
}


/**
 * Creates a dynamic code entry.
 *
 * @param {number} size Code size.
 * @param {string} type Code type.
 * @param {SharedFunctionInfoEntry} sfi Shared function entry.
 * @param {Profile.CodeState} state Code optimization state.
 * @constructor
 */
class DynamicFuncCodeEntry extends CodeEntry {
  constructor(size, type, sfi, state) {
    super(size, '', type);
    this.sfi = sfi;
    sfi.addDynamicCode(this);
    this.state = state;
  }

  get functionName() {
    return this.sfi.functionName;
  }

  getSourceCode() {
    return this.source?.getSourceCode();
  }

  static STATE_PREFIX = ["", "~", "^", "-", "+", "*"];
  getState() {
    return DynamicFuncCodeEntry.STATE_PREFIX[this.state];
  }

  getName() {
    const name = this.sfi.getName();
    return this.type + ': ' + this.getState() + name;
  }

  /**
   * Returns raw node name (without type decoration).
   */
  getRawName() {
    return this.sfi.getName();
  }

  isJSFunction() {
    return true;
  }

  toString() {
    return this.getName() + ': ' + this.size.toString(16);
  }
}

/**
 * Creates a shared function object entry.
 *
 * @param {string} name Function name.
 * @constructor
 */
class SharedFunctionInfoEntry extends CodeEntry {

  // Contains the list of generated code for this function.
  /** @type {Set<DynamicCodeEntry>} */
  _codeEntries = new Set();

  constructor(name, useBigIntAddresses=false) {
    super(useBigIntAddresses ? 0n : 0, name);
    const index = name.lastIndexOf(' ');
    this.functionName = 1 <= index ? name.substring(0, index) : '<anonymous>';
  }

  addDynamicCode(code) {
    if (code.sfi != this) {
      throw new Error("Adding dynamic code to wrong function");
    }
    this._codeEntries.add(code);
  }

  getSourceCode() {
    // All code entries should map to the same source positions.
    return this._codeEntries.values().next().value.getSourceCode();
  }

  get codeEntries() {
    return this._codeEntries;
  }

  /**
   * Returns node name.
   */
  getName() {
    let name = this.name;
    if (name.length == 0) {
      return '<anonymous>';
    } else if (name.charAt(0) == ' ') {
      // An anonymous function with location: " aaa.js:10".
      return `<anonymous>${name}`;
    }
    return name;
  }
}

/**
 * Constructs a call graph.
 *
 * @constructor
 */
class CallTree {
  root_ = new CallTreeNode(CallTree.ROOT_NODE_LABEL);
  totalsComputed_ = false;

  /**
   * The label of the root node.
   */
  static ROOT_NODE_LABEL = '';

  /**
   * Returns the tree root.
   */
  getRoot() {
    return this.root_;
  }

  /**
   * Adds the specified call path, constructing nodes as necessary.
   *
   * @param {string[]} path Call path.
   */
  addPath(path) {
    if (path.length == 0) return;
    let curr = this.root_;
    for (let i = 0; i < path.length; ++i) {
      curr = curr.findOrAddChild(path[i]);
    }
    curr.selfWeight++;
    this.totalsComputed_ = false;
  }

  /**
   * Finds an immediate child of the specified parent with the specified
   * label, creates a child node if necessary. If a parent node isn't
   * specified, uses tree root.
   *
   * @param {string} label Child node label.
   */
  findOrAddChild(label) {
    return this.root_.findOrAddChild(label);
  }

  /**
   * Creates a subtree by cloning and merging all subtrees rooted at nodes
   * with a given label. E.g. cloning the following call tree on label 'A'
   * will give the following result:
   *
   *           <A>--<B>                                     <B>
   *          /                                            /
   *     <root>             == clone on 'A' ==>  <root>--<A>
   *          \                                            \
   *           <C>--<A>--<D>                                <D>
   *
   * And <A>'s selfWeight will be the sum of selfWeights of <A>'s from the
   * source call tree.
   *
   * @param {string} label The label of the new root node.
   */
  cloneSubtree(label) {
    const subTree = new CallTree();
    this.traverse((node, parent) => {
      if (!parent && node.label != label) {
        return null;
      }
      const child = (parent ? parent : subTree).findOrAddChild(node.label);
      child.selfWeight += node.selfWeight;
      return child;
    });
    return subTree;
  }

  /**
   * Computes total weights in the call graph.
   */
  computeTotalWeights() {
    if (this.totalsComputed_) return;
    this.root_.computeTotalWeight();
    this.totalsComputed_ = true;
  }

  /**
   * Traverses the call graph in preorder. This function can be used for
   * building optionally modified tree clones. This is the boilerplate code
   * for this scenario:
   *
   * callTree.traverse(function(node, parentClone) {
   *   var nodeClone = cloneNode(node);
   *   if (parentClone)
   *     parentClone.addChild(nodeClone);
   *   return nodeClone;
   * });
   *
   * @param {function(CallTreeNode, *)} f Visitor function.
   *    The second parameter is the result of calling 'f' on the parent node.
   */
  traverse(f) {
    const pairsToProcess = new ConsArray();
    pairsToProcess.concat([{ node: this.root_, param: null }]);
    while (!pairsToProcess.atEnd()) {
      const pair = pairsToProcess.next();
      const node = pair.node;
      const newParam = f(node, pair.param);
      const morePairsToProcess = [];
      node.forEachChild((child) => {
        morePairsToProcess.push({ node: child, param: newParam });
      });
      pairsToProcess.concat(morePairsToProcess);
    }
  }

  /**
   * Performs an indepth call graph traversal.
   *
   * @param {function(CallTreeNode)} enter A function called
   *     prior to visiting node's children.
   * @param {function(CallTreeNode)} exit A function called
   *     after visiting node's children.
   */
  traverseInDepth(enter, exit) {
    function traverse(node) {
      enter(node);
      node.forEachChild(traverse);
      exit(node);
    }
    traverse(this.root_);
  }
}


/**
 * Constructs a call graph node.
 *
 * @param {string} label Node label.
 * @param {CallTreeNode} opt_parent Node parent.
 */
class CallTreeNode {

  constructor(label, opt_parent) {
    // Node self weight (how many times this node was the last node in
    // a call path).
    this.selfWeight = 0;
    // Node total weight (includes weights of all children).
    this.totalWeight = 0;
    this. children = { __proto__:null };
    this.label = label;
    this.parent = opt_parent;
  }


  /**
   * Adds a child node.
   *
   * @param {string} label Child node label.
   */
  addChild(label) {
    const child = new CallTreeNode(label, this);
    this.children[label] = child;
    return child;
  }

  /**
   * Computes node's total weight.
   */
  computeTotalWeight() {
    let totalWeight = this.selfWeight;
    this.forEachChild(function (child) {
      totalWeight += child.computeTotalWeight();
    });
    return this.totalWeight = totalWeight;
  }

  /**
   * Returns all node's children as an array.
   */
  exportChildren() {
    const result = [];
    this.forEachChild(function (node) { result.push(node); });
    return result;
  }

  /**
   * Finds an immediate child with the specified label.
   *
   * @param {string} label Child node label.
   */
  findChild(label) {
    const found = this.children[label];
    return found === undefined ? null : found;
  }

  /**
   * Finds an immediate child with the specified label, creates a child
   * node if necessary.
   *
   * @param {string} label Child node label.
   */
  findOrAddChild(label) {
    const found = this.findChild(label)
    if (found === null) return this.addChild(label);
    return found;
  }

  /**
   * Calls the specified function for every child.
   *
   * @param {function(CallTreeNode)} f Visitor function.
   */
  forEachChild(f) {
    for (let c in this.children) {
      f(this.children[c]);
    }
  }

  /**
   * Walks up from the current node up to the call tree root.
   *
   * @param {function(CallTreeNode)} f Visitor function.
   */
  walkUpToRoot(f) {
    for (let curr = this; curr !== null; curr = curr.parent) {
      f(curr);
    }
  }

  /**
   * Tries to find a node with the specified path.
   *
   * @param {string[]} labels The path.
   * @param {function(CallTreeNode)} opt_f Visitor function.
   */
  descendToChild(labels, opt_f) {
    let curr = this;
    for (let pos = 0; pos < labels.length && curr != null; pos++) {
      const child = curr.findChild(labels[pos]);
      if (opt_f) {
        opt_f(child, pos);
      }
      curr = child;
    }
    return curr;
  }
}

export function JsonProfile(useBigIntAddresses=false) {
  this.codeMap_ = new CodeMap(useBigIntAddresses);
  this.codeEntries_ = [];
  this.functionEntries_ = [];
  this.ticks_ = [];
  this.scripts_ = [];
}

JsonProfile.prototype.addLibrary = function (
  name, startAddr, endAddr) {
  const entry = new CodeEntry(
    endAddr - startAddr, name, 'SHARED_LIB');
  this.codeMap_.addLibrary(startAddr, entry);

  entry.codeId = this.codeEntries_.length;
  this.codeEntries_.push({ name: entry.name, type: entry.type });
  return entry;
};

JsonProfile.prototype.addStaticCode = function (
  name, startAddr, endAddr) {
  const entry = new CodeEntry(
    endAddr - startAddr, name, 'CPP');
  this.codeMap_.addStaticCode(startAddr, entry);

  entry.codeId = this.codeEntries_.length;
  this.codeEntries_.push({ name: entry.name, type: entry.type });
  return entry;
};

JsonProfile.prototype.addCode = function (
  kind, name, timestamp, start, size) {
  let codeId = this.codeEntries_.length;
  // Find out if we have a static code entry for the code. If yes, we will
  // make sure it is written to the JSON file just once.
  let staticEntry = this.codeMap_.findAddress(start);
  if (staticEntry && staticEntry.entry.type === 'CPP') {
    codeId = staticEntry.entry.codeId;
  }

  const entry = new CodeEntry(size, name, 'CODE');
  this.codeMap_.addCode(start, entry);

  entry.codeId = codeId;
  this.codeEntries_[codeId] = {
    name: entry.name,
    timestamp: timestamp,
    type: entry.type,
    kind: kind,
  };

  return entry;
};

JsonProfile.prototype.addFuncCode = function (
  kind, name, timestamp, start, size, sfiAddr, state) {
  // As code and functions are in the same address space,
  // it is safe to put them in a single code map.
  let sfi = this.codeMap_.findDynamicEntryByStartAddress(sfiAddr);
  if (!sfi) {
    sfi = new CodeEntry(0, name, 'SFI');
    this.codeMap_.addCode(sfiAddr, sfi);

    sfi.funcId = this.functionEntries_.length;
    this.functionEntries_.push({ name, codes: [] });
  } else if (sfi.name !== name) {
    // Function object has been overwritten with a new one.
    sfi.name = name;

    sfi.funcId = this.functionEntries_.length;
    this.functionEntries_.push({ name, codes: [] });
  }
  // TODO(jarin): Insert the code object into the SFI's code list.
  let entry = this.codeMap_.findDynamicEntryByStartAddress(start);
  if (entry) {
    if (entry.size === size && entry.sfi === sfi) {
      // Entry state has changed.
      entry.state = state;
    } else {
      this.codeMap_.deleteCode(start);
      entry = null;
    }
  }
  if (!entry) {
    entry = new CodeEntry(size, name, 'JS');
    this.codeMap_.addCode(start, entry);

    entry.codeId = this.codeEntries_.length;

    this.functionEntries_[sfi.funcId].codes.push(entry.codeId);

    kind = Profile.getKindFromState(state);

    this.codeEntries_.push({
      name: entry.name,
      type: entry.type,
      kind: kind,
      func: sfi.funcId,
      tm: timestamp,
    });
  }
  return entry;
};

JsonProfile.prototype.moveCode = function (from, to) {
  try {
    this.codeMap_.moveCode(from, to);
  } catch (e) {
    printErr(`Move: unknown source ${from}`);
  }
};

JsonProfile.prototype.addSourcePositions = function (
  start, script, startPos, endPos, sourcePositions, inliningPositions,
  inlinedSFIs) {
  const entry = this.codeMap_.findDynamicEntryByStartAddress(start);
  if (!entry) return;
  const codeId = entry.codeId;

  // Resolve the inlined functions list.
  if (inlinedSFIs.length > 0) {
    inlinedSFIs = inlinedSFIs.substring(1).split("S");
    for (let i = 0; i < inlinedSFIs.length; i++) {
      const sfiAddr = parseInt(inlinedSFIs[i]);
      const sfi = this.codeMap_.findDynamicEntryByStartAddress(sfiAddr);
      if (!sfi || sfi.funcId === undefined) {
        printErr(`Could not find SFI ${inlinedSFIs[i]}`);
        inlinedSFIs[i] = null;
      } else {
        inlinedSFIs[i] = sfi.funcId;
      }
    }
  } else {
    inlinedSFIs = [];
  }

  this.codeEntries_[entry.codeId].source = {
    script: script,
    start: startPos,
    end: endPos,
    positions: sourcePositions,
    inlined: inliningPositions,
    fns: inlinedSFIs
  };
};

JsonProfile.prototype.addScriptSource = function (id, url, source) {
  const script = new Script(id);
  script.update(url, source);
  this.scripts_[id] = script;
};

JsonProfile.prototype.deoptCode = function (
  timestamp, code, inliningId, scriptOffset, bailoutType,
  sourcePositionText, deoptReasonText) {
  let entry = this.codeMap_.findDynamicEntryByStartAddress(code);
  if (entry) {
    let codeId = entry.codeId;
    if (!this.codeEntries_[codeId].deopt) {
      // Only add the deopt if there was no deopt before.
      // The subsequent deoptimizations should be lazy deopts for
      // other on-stack activations.
      this.codeEntries_[codeId].deopt = {
        tm: timestamp,
        inliningId: inliningId,
        scriptOffset: scriptOffset,
        posText: sourcePositionText,
        reason: deoptReasonText,
        bailoutType: bailoutType,
      };
    }
  }
};

JsonProfile.prototype.deleteCode = function (start) {
  try {
    this.codeMap_.deleteCode(start);
  } catch (e) {
    printErr(`Delete: unknown address ${start}`);
  }
};

JsonProfile.prototype.moveSharedFunctionInfo = function (from, to) {
  if (this.codeMap_.findDynamicEntryByStartAddress(from)) {
    this.codeMap_.moveCode(from, to);
  }
};

JsonProfile.prototype.findEntry = function (addr) {
  return this.codeMap_.findEntry(addr);
};

JsonProfile.prototype.recordTick = function (time_ns, vmState, stack) {
  // TODO(jarin) Resolve the frame-less case (when top of stack is
  // known code).
  const processedStack = [];
  for (let i = 0; i < stack.length; i++) {
    const resolved = this.codeMap_.findAddress(stack[i]);
    if (resolved) {
      processedStack.push(resolved.entry.codeId, resolved.offset);
    } else {
      processedStack.push(-1, stack[i]);
    }
  }
  this.ticks_.push({ tm: time_ns, vm: vmState, s: processedStack });
};

function writeJson(s) {
  write(JSON.stringify(s, null, 2));
}

JsonProfile.prototype.writeJson = function () {
  // Write out the JSON in a partially manual way to avoid creating too-large
  // strings in one JSON.stringify call when there are a lot of ticks.
  write('{\n')

  write('  "code": ');
  writeJson(this.codeEntries_);
  write(',\n');

  write('  "functions": ');
  writeJson(this.functionEntries_);
  write(',\n');

  write('  "ticks": [\n');
  for (let i = 0; i < this.ticks_.length; i++) {
    write('    ');
    writeJson(this.ticks_[i]);
    if (i < this.ticks_.length - 1) {
      write(',\n');
    } else {
      write('\n');
    }
  }
  write('  ],\n');

  write('  "scripts": ');
  writeJson(this.scripts_);

  write('}\n');
};
                                                                                                                                                                                                                                                                                                                                       node-23.7.0/deps/v8/tools/profile_view.js                                                           0000664 0000000 0000000 00000014266 14746647661 0020246 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2009 the V8 project authors. All rights reserved.
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met:
//
//     * Redistributions of source code must retain the above copyright
//       notice, this list of conditions and the following disclaimer.
//     * Redistributions in binary form must reproduce the above
//       copyright notice, this list of conditions and the following
//       disclaimer in the documentation and/or other materials provided
//       with the distribution.
//     * Neither the name of Google Inc. nor the names of its
//       contributors may be used to endorse or promote products derived
//       from this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


/**
 * Creates a Profile View builder object.
 *
 * @param {number} samplingRate Number of ms between profiler ticks.
 * @constructor
 */
function ViewBuilder(samplingRate) {
  this.samplingRate = samplingRate;
};


/**
 * Builds a profile view for the specified call tree.
 *
 * @param {CallTree} callTree A call tree.
 * @param {boolean} opt_bottomUpViewWeights Whether remapping
 *     of self weights for a bottom up view is needed.
 */
ViewBuilder.prototype.buildView = function(
    callTree, opt_bottomUpViewWeights) {
  var head;
  var samplingRate = this.samplingRate;
  var createViewNode = this.createViewNode;
  callTree.traverse(function(node, viewParent) {
    var totalWeight = node.totalWeight * samplingRate;
    var selfWeight = node.selfWeight * samplingRate;
    if (opt_bottomUpViewWeights === true) {
      if (viewParent === head) {
        selfWeight = totalWeight;
      } else {
        selfWeight = 0;
      }
    }
    var viewNode = createViewNode(node.label, totalWeight, selfWeight, head);
    if (viewParent) {
      viewParent.addChild(viewNode);
    } else {
      head = viewNode;
    }
    return viewNode;
  });
  var view = this.createView(head);
  return view;
};


/**
 * Factory method for a profile view.
 *
 * @param {ProfileView.Node} head View head node.
 * @return {ProfileView} Profile view.
 */
ViewBuilder.prototype.createView = function(head) {
  return new ProfileView(head);
};


/**
 * Factory method for a profile view node.
 *
 * @param {string} internalFuncName A fully qualified function name.
 * @param {number} totalTime Amount of time that application spent in the
 *     corresponding function and its descendants (not that depending on
 *     profile they can be either callees or callers.)
 * @param {number} selfTime Amount of time that application spent in the
 *     corresponding function only.
 * @param {ProfileView.Node} head Profile view head.
 * @return {ProfileView.Node} Profile view node.
 */
ViewBuilder.prototype.createViewNode = function(
    funcName, totalTime, selfTime, head) {
  return new ProfileView.Node(
      funcName, totalTime, selfTime, head);
};


/**
 * Creates a Profile View object. It allows to perform sorting
 * and filtering actions on the profile.
 *
 * @param {ProfileView.Node} head Head (root) node.
 * @constructor
 */
function ProfileView(head) {
  this.head = head;
};


/**
 * Sorts the profile view using the specified sort function.
 *
 * @param {function(ProfileView.Node,
 *     ProfileView.Node):number} sortFunc A sorting
 *     functions. Must comply with Array.sort sorting function requirements.
 */
ProfileView.prototype.sort = function(sortFunc) {
  this.traverse(function (node) {
    node.sortChildren(sortFunc);
  });
};


/**
 * Traverses profile view nodes in preorder.
 *
 * @param {function(ProfileView.Node)} f Visitor function.
 */
ProfileView.prototype.traverse = function(f) {
  var nodesToTraverse = new ConsArray();
  nodesToTraverse.concat([this.head]);
  while (!nodesToTraverse.atEnd()) {
    var node = nodesToTraverse.next();
    f(node);
    nodesToTraverse.concat(node.children);
  }
};


/**
 * Constructs a Profile View node object. Each node object corresponds to
 * a function call.
 *
 * @param {string} internalFuncName A fully qualified function name.
 * @param {number} totalTime Amount of time that application spent in the
 *     corresponding function and its descendants (not that depending on
 *     profile they can be either callees or callers.)
 * @param {number} selfTime Amount of time that application spent in the
 *     corresponding function only.
 * @param {ProfileView.Node} head Profile view head.
 * @constructor
 */
ProfileView.Node = function(
    internalFuncName, totalTime, selfTime, head) {
  this.internalFuncName = internalFuncName;
  this.totalTime = totalTime;
  this.selfTime = selfTime;
  this.head = head;
  this.parent = null;
  this.children = [];
};


/**
 * Returns a share of the function's total time in its parent's total time.
 */
ProfileView.Node.prototype.__defineGetter__(
    'parentTotalPercent',
    function() { return this.totalTime /
      (this.parent ? this.parent.totalTime : this.totalTime) * 100.0; });


/**
 * Adds a child to the node.
 *
 * @param {ProfileView.Node} node Child node.
 */
ProfileView.Node.prototype.addChild = function(node) {
  node.parent = this;
  this.children.push(node);
};


/**
 * Sorts all the node's children recursively.
 *
 * @param {function(ProfileView.Node,
 *     ProfileView.Node):number} sortFunc A sorting
 *     functions. Must comply with Array.sort sorting function requirements.
 */
ProfileView.Node.prototype.sortChildren = function(
    sortFunc) {
  this.children.sort(sortFunc);
};
                                                                                                                                                                                                                                                                                                                                          node-23.7.0/deps/v8/tools/profile_view.mjs                                                          0000664 0000000 0000000 00000014332 14746647661 0020415 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        // Copyright 2009 the V8 project authors. All rights reserved.
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met:
//
//     * Redistributions of source code must retain the above copyright
//       notice, this list of conditions and the following disclaimer.
//     * Redistributions in binary form must reproduce the above
//       copyright notice, this list of conditions and the following
//       disclaimer in the documentation and/or other materials provided
//       with the distribution.
//     * Neither the name of Google Inc. nor the names of its
//       contributors may be used to endorse or promote products derived
//       from this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

import { ConsArray } from "./consarray.mjs";

/**
 * Creates a Profile View builder object.
 *
 * @param {number} samplingRate Number of ms between profiler ticks.
 * @constructor
 */
export function ViewBuilder(samplingRate) {
  this.samplingRate = samplingRate;
};


/**
 * Builds a profile view for the specified call tree.
 *
 * @param {CallTree} callTree A call tree.
 * @param {boolean} opt_bottomUpViewWeights Whether remapping
 *     of self weights for a bottom up view is needed.
 */
ViewBuilder.prototype.buildView = function(
    callTree, opt_bottomUpViewWeights) {
  let head;
  const samplingRate = this.samplingRate;
  const createViewNode = this.createViewNode;
  callTree.traverse(function(node, viewParent) {
    const totalWeight = node.totalWeight * samplingRate;
    let selfWeight = node.selfWeight * samplingRate;
    if (opt_bottomUpViewWeights === true) {
      if (viewParent === head) {
        selfWeight = totalWeight;
      } else {
        selfWeight = 0;
      }
    }
    const viewNode = createViewNode(node.label, totalWeight, selfWeight, head);
    if (viewParent) {
      viewParent.addChild(viewNode);
    } else {
      head = viewNode;
    }
    return viewNode;
  });
  const view = this.createView(head);
  return view;
};


/**
 * Factory method for a profile view.
 *
 * @param {ProfileView.Node} head View head node.
 * @return {ProfileView} Profile view.
 */
ViewBuilder.prototype.createView = head => new ProfileView(head);


/**
 * Factory method for a profile view node.
 *
 * @param {string} internalFuncName A fully qualified function name.
 * @param {number} totalTime Amount of time that application spent in the
 *     corresponding function and its descendants (not that depending on
 *     profile they can be either callees or callers.)
 * @param {number} selfTime Amount of time that application spent in the
 *     corresponding function only.
 * @param {ProfileView.Node} head Profile view head.
 * @return {ProfileView.Node} Profile view node.
 */
ViewBuilder.prototype.createViewNode = (
    funcName, totalTime, selfTime, head) =>
  new ProfileView.Node(
      funcName, totalTime, selfTime, head)
;


/**
 * Creates a Profile View object. It allows to perform sorting
 * and filtering actions on the profile.
 *
 * @param {ProfileView.Node} head Head (root) node.
 * @constructor
 */
export function ProfileView(head) {
  this.head = head;
};


/**
 * Sorts the profile view using the specified sort function.
 *
 * @param {function(ProfileView.Node,
 *     ProfileView.Node):number} sortFunc A sorting
 *     functions. Must comply with Array.sort sorting function requirements.
 */
ProfileView.prototype.sort = function(sortFunc) {
  this.traverse(function (node) {
    node.sortChildren(sortFunc);
  });
};


/**
 * Traverses profile view nodes in preorder.
 *
 * @param {function(ProfileView.Node)} f Visitor function.
 */
ProfileView.prototype.traverse = function(f) {
  const nodesToTraverse = new ConsArray();
  nodesToTraverse.concat([this.head]);
  while (!nodesToTraverse.atEnd()) {
    const node = nodesToTraverse.next();
    f(node);
    nodesToTraverse.concat(node.children);
  }
};


/**
 * Constructs a Profile View node object. Each node object corresponds to
 * a function call.
 *
 * @param {string} internalFuncName A fully qualified function name.
 * @param {number} totalTime Amount of time that application spent in the
 *     corresponding function and its descendants (not that depending on
 *     profile they can be either callees or callers.)
 * @param {number} selfTime Amount of time that application spent in the
 *     corresponding function only.
 * @param {ProfileView.Node} head Profile view head.
 * @constructor
 */
ProfileView.Node = function(
    internalFuncName, totalTime, selfTime, head) {
  this.internalFuncName = internalFuncName;
  this.totalTime = totalTime;
  this.selfTime = selfTime;
  this.head = head;
  this.parent = null;
  this.children = [];
};


/**
 * Returns a share of the function's total time in its parent's total time.
 */
ProfileView.Node.prototype.__defineGetter__(
    'parentTotalPercent',
    function() { return this.totalTime /
      (this.parent ? this.parent.totalTime : this.totalTime) * 100.0; });


/**
 * Adds a child to the node.
 *
 * @param {ProfileView.Node} node Child node.
 */
ProfileView.Node.prototype.addChild = function(node) {
  node.parent = this;
  this.children.push(node);
};


/**
 * Sorts all the node's children recursively.
 *
 * @param {function(ProfileView.Node,
 *     ProfileView.Node):number} sortFunc A sorting
 *     functions. Must comply with Array.sort sorting function requirements.
 */
ProfileView.Node.prototype.sortChildren = function(
    sortFunc) {
  this.children.sort(sortFunc);
};
                                                                                                                                                                                                                                                                                                      node-23.7.0/deps/v8/tools/profiling/                                                                0000775 0000000 0000000 00000000000 14746647661 0017176 5                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        node-23.7.0/deps/v8/tools/profiling/README.md                                                       0000664 0000000 0000000 00000000411 14746647661 0020451 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        # Profiling Tools

This directory contains various helper scripts to assist with profiling
d8 and chrome.

## linux perf
 For [linux perf](https://perf.wiki.kernel.org/) support you can find more
 documentation and instructions at <https://v8.dev/docs/linux-perf>.
                                                                                                                                                                                                                                                       node-23.7.0/deps/v8/tools/profiling/android-ll-prof.sh                                              0000775 0000000 0000000 00000005663 14746647661 0022540 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/bin/bash
# Copyright 2012 the V8 project authors. All rights reserved.
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are
# met:
#
#     * Redistributions of source code must retain the above copyright
#       notice, this list of conditions and the following disclaimer.
#     * Redistributions in binary form must reproduce the above
#       copyright notice, this list of conditions and the following
#       disclaimer in the documentation and/or other materials provided
#       with the distribution.
#     * Neither the name of Google Inc. nor the names of its
#       contributors may be used to endorse or promote products derived
#       from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

# Runs d8 with the given arguments on the device under 'perf' and
# processes the profiler trace and v8 logs using ll_prof.py.
# 
# Usage:
# > ./tools/android-ll-prof.sh (debug|release) "args to d8" "args to ll_prof.py"
#
# The script creates deploy directory deploy/data/local/tmp/v8, copies there
# the d8 binary either from out/android_arm.release or out/android_arm.debug,
# and then sync the deploy directory with /data/local/tmp/v8 on the device.
# You can put JS files in the deploy directory before running the script.
# Note: $ANDROID_NDK_ROOT must be set.

MODE=$1
RUN_ARGS=$2
LL_PROF_ARGS=$3

BASE=`cd $(dirname "$0")/..; pwd`
DEPLOY="$BASE/deploy"

set +e
mkdir -p "$DEPLOY/data/local/tmp/v8"

cp "$BASE/out/android_arm.$MODE/d8" "$DEPLOY/data/local/tmp/v8/d8"

adb -p "$DEPLOY" sync data

adb shell "cd /data/local/tmp/v8;\
           perf record -R -e cycles -c 10000 -f -i \
           ./d8 --ll_prof --gc-fake-mmap=/data/local/tmp/__v8_gc__ $RUN_ARGS"

adb pull /data/local/tmp/v8/v8.log .
adb pull /data/local/tmp/v8/v8.log.ll .
adb pull /data/perf.data .

ARCH=arm-linux-androideabi-4.6
TOOLCHAIN="${ANDROID_NDK_ROOT}/toolchains/$ARCH/prebuilt/linux-x86/bin"

$BASE/tools/ll_prof.py --host-root="$BASE/deploy" \
                       --gc-fake-mmap=/data/local/tmp/__v8_gc__ \
                       --objdump="$TOOLCHAIN/arm-linux-androideabi-objdump" \
                       $LL_PROF_ARGS
                                                                             node-23.7.0/deps/v8/tools/profiling/linux-perf-chrome-renderer-cmd.sh                               0000775 0000000 0000000 00000003042 14746647661 0025445 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env bash
# Copyright 2022 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

PERF_DATA_DIR="."
PERF_DATA_PREFIX="chrome_renderer"
RENDERER_ID="0"
for i in "$@"; do
  case $i in
    -h|--help)
      echo "Usage: path/to/chrome --renderer-cmd-prefix='$0 [OPTION]' [CHROME OPTIONS]"
      echo "This script is mostly used in conjuction with linux_perf.py to run linux-perf"
      echo "for each renderer process."
      echo "It generates perf.data files that can be read by pprof or linux-perf."
      echo ""
      echo 'File naming: ${OUT_DIR}/${PREFIX}_${PARENT_PID}_${RENDERER_ID}.perf.data'
      echo ""
      echo "Options:"
      echo "  --perf-data-dir=OUT_DIR    Change the location where perf.data is written."
      echo "                             Default: '$PERF_DATA_DIR'"
      echo "  --perf-data-prefix=PREFIX  Set a custom prefex for all generated perf.data files."
      echo "                             Default: '$PERF_DATA_PREFIX'"
      exit
      ;;
    --perf-data-dir=*)
      PERF_DATA_DIR="${i#*=}"
      shift
    ;;
    --perf-data-prefix=*)
      PERF_DATA_PREFIX="${i#*=}"
      shift
    ;;
    --renderer-client-id=*)
      # Don't shift this option since it is passed in (and used by) chrome.
      RENDERER_ID="${i#*=}"
    ;;
    *)
      ;;
  esac
done

PERF_OUTPUT="$PERF_DATA_DIR/${PERF_DATA_PREFIX}_${PPID}_${RENDERER_ID}.perf.data"
perf record --call-graph=fp --clockid=mono --freq=max --output="${PERF_OUTPUT}" -- $@
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              node-23.7.0/deps/v8/tools/profiling/linux-perf-chrome.py                                            0000775 0000000 0000000 00000022112 14746647661 0023115 0                                                                                                    ustar 00root                            root                            0000000 0000000                                                                                                                                                                        #!/usr/bin/env python3
# Copyright 2022 the V8 project authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

from datetime import datetime
from datetime import timedelta
import multiprocessing
import optparse
import os
from pathlib import Path
import shlex
import shutil
import signal
import subprocess
import sys
import tempfile
import time

import psutil

renderer_cmd_file = (Path(__file__).parent /
                     'linux-perf-chrome-renderer-cmd.sh').resolve()
assert renderer_cmd_file.is_file()
renderer_cmd_prefix = f"{renderer_cmd_file} --perf-data-prefix=chrome_renderer"

# ==============================================================================

usage = """Usage: %prog $CHROME_BIN [OPTION]... -- [CHROME_OPTION]... [URL]

This script runs linux-perf on all render process with custom V8 logging to get
support to resolve JS function names.

The perf data is written to OUT_DIR separate by renderer process.

See https://v8.dev/docs/linux-perf for more detailed instructions.
"""
parser = optparse.OptionParser(usage=usage)
parser.add_option(
    '--perf-data-dir',
    default=None,
    metavar="OUT_DIR",
    help="Output directory for linux perf profile files")
parser.add_option(
    "--profile-browser-process",
    action="store_true",
    default=False,
    help="Also start linux-perf for the browser process. "
    "By default only renderer processes are sampled. "
    "Outputs 'browser_*.perf.data' in the CDW")
parser.add_option("--timeout", type=float, help="Stop chrome after N seconds")

chrome_options = optparse.OptionGroup(
    parser, "Chrome-forwarded Options",
    "These convenience for a better script experience that are forward directly"
    "to chrome. Any other chrome option can be passed after the '--' arguments"
    "separator.")
chrome_options.add_option(
    "--user-data-dir",
    dest="user_data_dir",
    default=None,
    help="Chrome's profile location. "
    "By default a temp directory is used.")
chrome_options.add_option(
    "--js-flags",
    dest="js_flags",
    help="Comma-separated list of flags passed to V8.")
chrome_options.add_option(
    "--renderer-cmd-prefix",
    default=None,
    help=f"Set command prefix, used for each new chrome renderer process."
    "Default: {renderer_cmd_prefix}")
FEATURES_DOC = "See chrome's base/feature_list.h source file for more dertails"
chrome_options.add_option(
    "--enable-features",
    help="Comma-separated list of enabled chrome features. " + FEATURES_DOC)
chrome_options.add_option(
    "--disable-features",
    help="Command-separated list of disabled chrome features. " + FEATURES_DOC)
parser.add_option_group(chrome_options)


# ==============================================================================
def log(*args):
  print("")
  print("=" * 80)
  print(*args)
  print("=" * 80)

# ==============================================================================

(options, args) = parser.parse_args()

if len(args) == 0:
  parser.error("No chrome binary provided")

chrome_bin = Path(args.pop(0)).absolute()
if not chrome_bin.exists():
  parser.error(f"Chrome '{chrome_bin}' does not exist")

if options.renderer_cmd_prefix is not None:
  if options.perf_data_dir is not None:
    parser.error("Cannot specify --perf-data-dir "
                 "if a custom --renderer-cmd-prefix is provided")
else:
  options.renderer_cmd_prefix = str(renderer_cmd_file)

if options.perf_data_dir is None:
  options.perf_data_dir = Path.cwd()
else:
  options.perf_data_dir = Path(options.perf_data_dir).absolute()
options.perf_data_dir.mkdir(parents=True, exist_ok=True)
if not options.perf_data_dir.is_dir():
  parser.error(f"--perf-data-dir={options.perf_data_dir} "
               "is not an directory or does not exist.")

if options.timeout and options.timeout < 2:
  parser.error("--timeout should be more than 2 seconds")

# ==============================================================================
old_cwd = Path.cwd()
os.chdir(options.perf_data_dir)

# ==============================================================================
JS_FLAGS_PERF = ("--perf-prof", "--interpreted-frames-native-stack")


def wait_for_process_timeout(process):
  delta = timedelta(seconds=options.timeout)
  start_time = datetime.now()
  while True:
    if (datetime.now() - start_time) >= delta:
      return False
    processHasStopped = process.poll() is not None
    if processHasStopped:
      return True
    time.sleep(0.5)
  return False


with tempfile.TemporaryDirectory(prefix="chrome-") as tmp_dir_path:
  tempdir = Path(tmp_dir_path)
  cmd = [
      str(chrome_bin),
  ]
  if options.user_data_dir is None:
    options.user_data_dir = tempdir
  cmd.append(f"--user-data-dir={options.user_data_dir}")
  cmd += [
      "--no-sandbox",
      "--enable-benchmarking",
      "--no-first-run",
      "--no-default-browser-check",
      f"--renderer-cmd-prefix={options.renderer_cmd_prefix}",
  ]

  # Do the magic js-flag concatenation to properly forward them to the
  # renderer command
  js_flags = set(JS_FLAGS_PERF)
  if options.js_flags:
    js_flags.update(shlex.split(options.js_flags))
  cmd += [f"--js-flags={','.join(list(js_flags))}"]

  if options.enable_features:
    cmd += [f"--enable-features={options.enable_features}"]
  if options.disable_features:
    cmd += [f"--disable-features={options.disable_features}"]
  cmd += args
  log("CHROME CMD: ", shlex.join(cmd))

  if options.profile_browser_process:
    perf_data_file = f"{tempdir.name}_browser.perf.data"
    perf_cmd = [
        "perf", "record", "--call-gr